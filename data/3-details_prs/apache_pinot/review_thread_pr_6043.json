{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDkwNjg1NDAy", "number": 6043, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMFQwNzowMzoyN1rOEsQbIw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMFQwNzoxNTowMVrOEsQeWw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE0ODQxODkxOnYy", "diffSide": "RIGHT", "path": "pinot-core/src/main/java/org/apache/pinot/core/query/executor/ServerQueryExecutorV1Impl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMFQwNzowMzoyN1rOHfd1jQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QyMDoxOTo1MVrOHg353A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjc1Njc0OQ==", "bodyText": "add java docs on what this method is doing", "url": "https://github.com/apache/pinot/pull/6043#discussion_r502756749", "createdAt": "2020-10-10T07:03:27Z", "author": {"login": "kishoreg"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/query/executor/ServerQueryExecutorV1Impl.java", "diffHunk": "@@ -277,4 +253,112 @@ public DataTable processQuery(ServerQueryRequest queryRequest, ExecutorService e\n     LOGGER.debug(\"InstanceResponse for request Id - {}: {}\", requestId, dataTable);\n     return dataTable;\n   }\n+\n+  private DataTable processQuery(List<IndexSegment> indexSegments, QueryContext queryContext, TimerContext timerContext,\n+      ExecutorService executorService, @Nullable StreamObserver<Server.ServerResponse> responseObserver, long endTimeMs,\n+      boolean enableStreaming)\n+      throws Exception {\n+    handleSubquery(queryContext, indexSegments, timerContext, executorService, endTimeMs);\n+\n+    // Compute total docs for the table before pruning the segments\n+    long numTotalDocs = 0;\n+    for (IndexSegment indexSegment : indexSegments) {\n+      numTotalDocs += indexSegment.getSegmentMetadata().getTotalDocs();\n+    }\n+\n+    TimerContext.Timer segmentPruneTimer = timerContext.startNewPhaseTimer(ServerQueryPhase.SEGMENT_PRUNING);\n+    List<IndexSegment> selectedSegments = _segmentPrunerService.prune(indexSegments, queryContext);\n+    segmentPruneTimer.stopAndRecord();\n+    int numSelectedSegments = selectedSegments.size();\n+    LOGGER.debug(\"Matched {} segments after pruning\", numSelectedSegments);\n+    if (numSelectedSegments == 0) {\n+      // Only return metadata for streaming query\n+      DataTable dataTable = enableStreaming ? new DataTableImplV2() : DataTableUtils.buildEmptyDataTable(queryContext);\n+      Map<String, String> metadata = dataTable.getMetadata();\n+      metadata.put(DataTable.TOTAL_DOCS_METADATA_KEY, String.valueOf(numTotalDocs));\n+      metadata.put(DataTable.NUM_DOCS_SCANNED_METADATA_KEY, \"0\");\n+      metadata.put(DataTable.NUM_ENTRIES_SCANNED_IN_FILTER_METADATA_KEY, \"0\");\n+      metadata.put(DataTable.NUM_ENTRIES_SCANNED_POST_FILTER_METADATA_KEY, \"0\");\n+      metadata.put(DataTable.NUM_SEGMENTS_PROCESSED, \"0\");\n+      metadata.put(DataTable.NUM_SEGMENTS_MATCHED, \"0\");\n+      return dataTable;\n+    } else {\n+      TimerContext.Timer planBuildTimer = timerContext.startNewPhaseTimer(ServerQueryPhase.BUILD_QUERY_PLAN);\n+      Plan queryPlan = enableStreaming ? _planMaker\n+          .makeStreamingInstancePlan(selectedSegments, queryContext, executorService, responseObserver, endTimeMs)\n+          : _planMaker.makeInstancePlan(selectedSegments, queryContext, executorService, endTimeMs);\n+      planBuildTimer.stopAndRecord();\n+\n+      TimerContext.Timer planExecTimer = timerContext.startNewPhaseTimer(ServerQueryPhase.QUERY_PLAN_EXECUTION);\n+      DataTable dataTable = queryPlan.execute();\n+      planExecTimer.stopAndRecord();\n+\n+      // Update the total docs in the metadata based on the un-pruned segments\n+      dataTable.getMetadata().put(DataTable.TOTAL_DOCS_METADATA_KEY, Long.toString(numTotalDocs));\n+\n+      return dataTable;\n+    }\n+  }\n+\n+  /**\n+   * Handles the subquery in the given query.\n+   * <p>Currently only supports subquery within IN_PARTITIONED_SUBQUERY function.\n+   */\n+  private void handleSubquery(QueryContext queryContext, List<IndexSegment> indexSegments, TimerContext timerContext,\n+      ExecutorService executorService, long endTimeMs)\n+      throws Exception {\n+    FilterContext filter = queryContext.getFilter();\n+    if (filter != null) {\n+      handleSubquery(filter, indexSegments, timerContext, executorService, endTimeMs);\n+    }\n+  }\n+\n+  /**\n+   * Handles the subquery in the filter.\n+   * <p>Currently only supports subquery within IN_PARTITIONED_SUBQUERY function.\n+   */\n+  private void handleSubquery(FilterContext filter, List<IndexSegment> indexSegments, TimerContext timerContext,\n+      ExecutorService executorService, long endTimeMs)\n+      throws Exception {\n+    Predicate predicate = filter.getPredicate();\n+    if (predicate != null) {\n+      handleSubquery(predicate.getLhs(), indexSegments, timerContext, executorService, endTimeMs);\n+    } else {\n+      for (FilterContext child : filter.getChildren()) {\n+        handleSubquery(child, indexSegments, timerContext, executorService, endTimeMs);\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Handles the subquery in the given expression.\n+   * <p>Currently only supports subquery within IN_PARTITIONED_SUBQUERY function.\n+   */\n+  private void handleSubquery(ExpressionContext expression, List<IndexSegment> indexSegments, TimerContext timerContext,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18ad00fa0c1cc938969839dacf8ada5c754a9f61"}, "originalPosition": 223}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDIzMjQxMg==", "bodyText": "Done", "url": "https://github.com/apache/pinot/pull/6043#discussion_r504232412", "createdAt": "2020-10-13T20:19:51Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/query/executor/ServerQueryExecutorV1Impl.java", "diffHunk": "@@ -277,4 +253,112 @@ public DataTable processQuery(ServerQueryRequest queryRequest, ExecutorService e\n     LOGGER.debug(\"InstanceResponse for request Id - {}: {}\", requestId, dataTable);\n     return dataTable;\n   }\n+\n+  private DataTable processQuery(List<IndexSegment> indexSegments, QueryContext queryContext, TimerContext timerContext,\n+      ExecutorService executorService, @Nullable StreamObserver<Server.ServerResponse> responseObserver, long endTimeMs,\n+      boolean enableStreaming)\n+      throws Exception {\n+    handleSubquery(queryContext, indexSegments, timerContext, executorService, endTimeMs);\n+\n+    // Compute total docs for the table before pruning the segments\n+    long numTotalDocs = 0;\n+    for (IndexSegment indexSegment : indexSegments) {\n+      numTotalDocs += indexSegment.getSegmentMetadata().getTotalDocs();\n+    }\n+\n+    TimerContext.Timer segmentPruneTimer = timerContext.startNewPhaseTimer(ServerQueryPhase.SEGMENT_PRUNING);\n+    List<IndexSegment> selectedSegments = _segmentPrunerService.prune(indexSegments, queryContext);\n+    segmentPruneTimer.stopAndRecord();\n+    int numSelectedSegments = selectedSegments.size();\n+    LOGGER.debug(\"Matched {} segments after pruning\", numSelectedSegments);\n+    if (numSelectedSegments == 0) {\n+      // Only return metadata for streaming query\n+      DataTable dataTable = enableStreaming ? new DataTableImplV2() : DataTableUtils.buildEmptyDataTable(queryContext);\n+      Map<String, String> metadata = dataTable.getMetadata();\n+      metadata.put(DataTable.TOTAL_DOCS_METADATA_KEY, String.valueOf(numTotalDocs));\n+      metadata.put(DataTable.NUM_DOCS_SCANNED_METADATA_KEY, \"0\");\n+      metadata.put(DataTable.NUM_ENTRIES_SCANNED_IN_FILTER_METADATA_KEY, \"0\");\n+      metadata.put(DataTable.NUM_ENTRIES_SCANNED_POST_FILTER_METADATA_KEY, \"0\");\n+      metadata.put(DataTable.NUM_SEGMENTS_PROCESSED, \"0\");\n+      metadata.put(DataTable.NUM_SEGMENTS_MATCHED, \"0\");\n+      return dataTable;\n+    } else {\n+      TimerContext.Timer planBuildTimer = timerContext.startNewPhaseTimer(ServerQueryPhase.BUILD_QUERY_PLAN);\n+      Plan queryPlan = enableStreaming ? _planMaker\n+          .makeStreamingInstancePlan(selectedSegments, queryContext, executorService, responseObserver, endTimeMs)\n+          : _planMaker.makeInstancePlan(selectedSegments, queryContext, executorService, endTimeMs);\n+      planBuildTimer.stopAndRecord();\n+\n+      TimerContext.Timer planExecTimer = timerContext.startNewPhaseTimer(ServerQueryPhase.QUERY_PLAN_EXECUTION);\n+      DataTable dataTable = queryPlan.execute();\n+      planExecTimer.stopAndRecord();\n+\n+      // Update the total docs in the metadata based on the un-pruned segments\n+      dataTable.getMetadata().put(DataTable.TOTAL_DOCS_METADATA_KEY, Long.toString(numTotalDocs));\n+\n+      return dataTable;\n+    }\n+  }\n+\n+  /**\n+   * Handles the subquery in the given query.\n+   * <p>Currently only supports subquery within IN_PARTITIONED_SUBQUERY function.\n+   */\n+  private void handleSubquery(QueryContext queryContext, List<IndexSegment> indexSegments, TimerContext timerContext,\n+      ExecutorService executorService, long endTimeMs)\n+      throws Exception {\n+    FilterContext filter = queryContext.getFilter();\n+    if (filter != null) {\n+      handleSubquery(filter, indexSegments, timerContext, executorService, endTimeMs);\n+    }\n+  }\n+\n+  /**\n+   * Handles the subquery in the filter.\n+   * <p>Currently only supports subquery within IN_PARTITIONED_SUBQUERY function.\n+   */\n+  private void handleSubquery(FilterContext filter, List<IndexSegment> indexSegments, TimerContext timerContext,\n+      ExecutorService executorService, long endTimeMs)\n+      throws Exception {\n+    Predicate predicate = filter.getPredicate();\n+    if (predicate != null) {\n+      handleSubquery(predicate.getLhs(), indexSegments, timerContext, executorService, endTimeMs);\n+    } else {\n+      for (FilterContext child : filter.getChildren()) {\n+        handleSubquery(child, indexSegments, timerContext, executorService, endTimeMs);\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Handles the subquery in the given expression.\n+   * <p>Currently only supports subquery within IN_PARTITIONED_SUBQUERY function.\n+   */\n+  private void handleSubquery(ExpressionContext expression, List<IndexSegment> indexSegments, TimerContext timerContext,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjc1Njc0OQ=="}, "originalCommit": {"oid": "18ad00fa0c1cc938969839dacf8ada5c754a9f61"}, "originalPosition": 223}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE0ODQyMDczOnYy", "diffSide": "RIGHT", "path": "pinot-core/src/main/java/org/apache/pinot/core/query/executor/ServerQueryExecutorV1Impl.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMFQwNzowNTo1MVrOHfd2Yg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QyMDoyNzoyNVrOHg4RVg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjc1Njk2Mg==", "bodyText": "docs, isn't it better to check for filter.getChildren and invert the if statement?", "url": "https://github.com/apache/pinot/pull/6043#discussion_r502756962", "createdAt": "2020-10-10T07:05:51Z", "author": {"login": "kishoreg"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/query/executor/ServerQueryExecutorV1Impl.java", "diffHunk": "@@ -277,4 +253,112 @@ public DataTable processQuery(ServerQueryRequest queryRequest, ExecutorService e\n     LOGGER.debug(\"InstanceResponse for request Id - {}: {}\", requestId, dataTable);\n     return dataTable;\n   }\n+\n+  private DataTable processQuery(List<IndexSegment> indexSegments, QueryContext queryContext, TimerContext timerContext,\n+      ExecutorService executorService, @Nullable StreamObserver<Server.ServerResponse> responseObserver, long endTimeMs,\n+      boolean enableStreaming)\n+      throws Exception {\n+    handleSubquery(queryContext, indexSegments, timerContext, executorService, endTimeMs);\n+\n+    // Compute total docs for the table before pruning the segments\n+    long numTotalDocs = 0;\n+    for (IndexSegment indexSegment : indexSegments) {\n+      numTotalDocs += indexSegment.getSegmentMetadata().getTotalDocs();\n+    }\n+\n+    TimerContext.Timer segmentPruneTimer = timerContext.startNewPhaseTimer(ServerQueryPhase.SEGMENT_PRUNING);\n+    List<IndexSegment> selectedSegments = _segmentPrunerService.prune(indexSegments, queryContext);\n+    segmentPruneTimer.stopAndRecord();\n+    int numSelectedSegments = selectedSegments.size();\n+    LOGGER.debug(\"Matched {} segments after pruning\", numSelectedSegments);\n+    if (numSelectedSegments == 0) {\n+      // Only return metadata for streaming query\n+      DataTable dataTable = enableStreaming ? new DataTableImplV2() : DataTableUtils.buildEmptyDataTable(queryContext);\n+      Map<String, String> metadata = dataTable.getMetadata();\n+      metadata.put(DataTable.TOTAL_DOCS_METADATA_KEY, String.valueOf(numTotalDocs));\n+      metadata.put(DataTable.NUM_DOCS_SCANNED_METADATA_KEY, \"0\");\n+      metadata.put(DataTable.NUM_ENTRIES_SCANNED_IN_FILTER_METADATA_KEY, \"0\");\n+      metadata.put(DataTable.NUM_ENTRIES_SCANNED_POST_FILTER_METADATA_KEY, \"0\");\n+      metadata.put(DataTable.NUM_SEGMENTS_PROCESSED, \"0\");\n+      metadata.put(DataTable.NUM_SEGMENTS_MATCHED, \"0\");\n+      return dataTable;\n+    } else {\n+      TimerContext.Timer planBuildTimer = timerContext.startNewPhaseTimer(ServerQueryPhase.BUILD_QUERY_PLAN);\n+      Plan queryPlan = enableStreaming ? _planMaker\n+          .makeStreamingInstancePlan(selectedSegments, queryContext, executorService, responseObserver, endTimeMs)\n+          : _planMaker.makeInstancePlan(selectedSegments, queryContext, executorService, endTimeMs);\n+      planBuildTimer.stopAndRecord();\n+\n+      TimerContext.Timer planExecTimer = timerContext.startNewPhaseTimer(ServerQueryPhase.QUERY_PLAN_EXECUTION);\n+      DataTable dataTable = queryPlan.execute();\n+      planExecTimer.stopAndRecord();\n+\n+      // Update the total docs in the metadata based on the un-pruned segments\n+      dataTable.getMetadata().put(DataTable.TOTAL_DOCS_METADATA_KEY, Long.toString(numTotalDocs));\n+\n+      return dataTable;\n+    }\n+  }\n+\n+  /**\n+   * Handles the subquery in the given query.\n+   * <p>Currently only supports subquery within IN_PARTITIONED_SUBQUERY function.\n+   */\n+  private void handleSubquery(QueryContext queryContext, List<IndexSegment> indexSegments, TimerContext timerContext,\n+      ExecutorService executorService, long endTimeMs)\n+      throws Exception {\n+    FilterContext filter = queryContext.getFilter();\n+    if (filter != null) {\n+      handleSubquery(filter, indexSegments, timerContext, executorService, endTimeMs);\n+    }\n+  }\n+\n+  /**\n+   * Handles the subquery in the filter.\n+   * <p>Currently only supports subquery within IN_PARTITIONED_SUBQUERY function.\n+   */\n+  private void handleSubquery(FilterContext filter, List<IndexSegment> indexSegments, TimerContext timerContext,\n+      ExecutorService executorService, long endTimeMs)\n+      throws Exception {\n+    Predicate predicate = filter.getPredicate();\n+    if (predicate != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18ad00fa0c1cc938969839dacf8ada5c754a9f61"}, "originalPosition": 210}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDIzODQyMg==", "bodyText": "Done", "url": "https://github.com/apache/pinot/pull/6043#discussion_r504238422", "createdAt": "2020-10-13T20:27:25Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/query/executor/ServerQueryExecutorV1Impl.java", "diffHunk": "@@ -277,4 +253,112 @@ public DataTable processQuery(ServerQueryRequest queryRequest, ExecutorService e\n     LOGGER.debug(\"InstanceResponse for request Id - {}: {}\", requestId, dataTable);\n     return dataTable;\n   }\n+\n+  private DataTable processQuery(List<IndexSegment> indexSegments, QueryContext queryContext, TimerContext timerContext,\n+      ExecutorService executorService, @Nullable StreamObserver<Server.ServerResponse> responseObserver, long endTimeMs,\n+      boolean enableStreaming)\n+      throws Exception {\n+    handleSubquery(queryContext, indexSegments, timerContext, executorService, endTimeMs);\n+\n+    // Compute total docs for the table before pruning the segments\n+    long numTotalDocs = 0;\n+    for (IndexSegment indexSegment : indexSegments) {\n+      numTotalDocs += indexSegment.getSegmentMetadata().getTotalDocs();\n+    }\n+\n+    TimerContext.Timer segmentPruneTimer = timerContext.startNewPhaseTimer(ServerQueryPhase.SEGMENT_PRUNING);\n+    List<IndexSegment> selectedSegments = _segmentPrunerService.prune(indexSegments, queryContext);\n+    segmentPruneTimer.stopAndRecord();\n+    int numSelectedSegments = selectedSegments.size();\n+    LOGGER.debug(\"Matched {} segments after pruning\", numSelectedSegments);\n+    if (numSelectedSegments == 0) {\n+      // Only return metadata for streaming query\n+      DataTable dataTable = enableStreaming ? new DataTableImplV2() : DataTableUtils.buildEmptyDataTable(queryContext);\n+      Map<String, String> metadata = dataTable.getMetadata();\n+      metadata.put(DataTable.TOTAL_DOCS_METADATA_KEY, String.valueOf(numTotalDocs));\n+      metadata.put(DataTable.NUM_DOCS_SCANNED_METADATA_KEY, \"0\");\n+      metadata.put(DataTable.NUM_ENTRIES_SCANNED_IN_FILTER_METADATA_KEY, \"0\");\n+      metadata.put(DataTable.NUM_ENTRIES_SCANNED_POST_FILTER_METADATA_KEY, \"0\");\n+      metadata.put(DataTable.NUM_SEGMENTS_PROCESSED, \"0\");\n+      metadata.put(DataTable.NUM_SEGMENTS_MATCHED, \"0\");\n+      return dataTable;\n+    } else {\n+      TimerContext.Timer planBuildTimer = timerContext.startNewPhaseTimer(ServerQueryPhase.BUILD_QUERY_PLAN);\n+      Plan queryPlan = enableStreaming ? _planMaker\n+          .makeStreamingInstancePlan(selectedSegments, queryContext, executorService, responseObserver, endTimeMs)\n+          : _planMaker.makeInstancePlan(selectedSegments, queryContext, executorService, endTimeMs);\n+      planBuildTimer.stopAndRecord();\n+\n+      TimerContext.Timer planExecTimer = timerContext.startNewPhaseTimer(ServerQueryPhase.QUERY_PLAN_EXECUTION);\n+      DataTable dataTable = queryPlan.execute();\n+      planExecTimer.stopAndRecord();\n+\n+      // Update the total docs in the metadata based on the un-pruned segments\n+      dataTable.getMetadata().put(DataTable.TOTAL_DOCS_METADATA_KEY, Long.toString(numTotalDocs));\n+\n+      return dataTable;\n+    }\n+  }\n+\n+  /**\n+   * Handles the subquery in the given query.\n+   * <p>Currently only supports subquery within IN_PARTITIONED_SUBQUERY function.\n+   */\n+  private void handleSubquery(QueryContext queryContext, List<IndexSegment> indexSegments, TimerContext timerContext,\n+      ExecutorService executorService, long endTimeMs)\n+      throws Exception {\n+    FilterContext filter = queryContext.getFilter();\n+    if (filter != null) {\n+      handleSubquery(filter, indexSegments, timerContext, executorService, endTimeMs);\n+    }\n+  }\n+\n+  /**\n+   * Handles the subquery in the filter.\n+   * <p>Currently only supports subquery within IN_PARTITIONED_SUBQUERY function.\n+   */\n+  private void handleSubquery(FilterContext filter, List<IndexSegment> indexSegments, TimerContext timerContext,\n+      ExecutorService executorService, long endTimeMs)\n+      throws Exception {\n+    Predicate predicate = filter.getPredicate();\n+    if (predicate != null) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjc1Njk2Mg=="}, "originalCommit": {"oid": "18ad00fa0c1cc938969839dacf8ada5c754a9f61"}, "originalPosition": 210}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE0ODQyMzk2OnYy", "diffSide": "RIGHT", "path": "pinot-core/src/main/java/org/apache/pinot/core/query/executor/ServerQueryExecutorV1Impl.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMFQwNzoxMDoyNVrOHfd35w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QyMDoyODo1NlrOHg4UUA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjc1NzM1MQ==", "bodyText": "more javadocs", "url": "https://github.com/apache/pinot/pull/6043#discussion_r502757351", "createdAt": "2020-10-10T07:10:25Z", "author": {"login": "kishoreg"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/query/executor/ServerQueryExecutorV1Impl.java", "diffHunk": "@@ -277,4 +253,112 @@ public DataTable processQuery(ServerQueryRequest queryRequest, ExecutorService e\n     LOGGER.debug(\"InstanceResponse for request Id - {}: {}\", requestId, dataTable);\n     return dataTable;\n   }\n+\n+  private DataTable processQuery(List<IndexSegment> indexSegments, QueryContext queryContext, TimerContext timerContext,\n+      ExecutorService executorService, @Nullable StreamObserver<Server.ServerResponse> responseObserver, long endTimeMs,\n+      boolean enableStreaming)\n+      throws Exception {\n+    handleSubquery(queryContext, indexSegments, timerContext, executorService, endTimeMs);\n+\n+    // Compute total docs for the table before pruning the segments\n+    long numTotalDocs = 0;\n+    for (IndexSegment indexSegment : indexSegments) {\n+      numTotalDocs += indexSegment.getSegmentMetadata().getTotalDocs();\n+    }\n+\n+    TimerContext.Timer segmentPruneTimer = timerContext.startNewPhaseTimer(ServerQueryPhase.SEGMENT_PRUNING);\n+    List<IndexSegment> selectedSegments = _segmentPrunerService.prune(indexSegments, queryContext);\n+    segmentPruneTimer.stopAndRecord();\n+    int numSelectedSegments = selectedSegments.size();\n+    LOGGER.debug(\"Matched {} segments after pruning\", numSelectedSegments);\n+    if (numSelectedSegments == 0) {\n+      // Only return metadata for streaming query\n+      DataTable dataTable = enableStreaming ? new DataTableImplV2() : DataTableUtils.buildEmptyDataTable(queryContext);\n+      Map<String, String> metadata = dataTable.getMetadata();\n+      metadata.put(DataTable.TOTAL_DOCS_METADATA_KEY, String.valueOf(numTotalDocs));\n+      metadata.put(DataTable.NUM_DOCS_SCANNED_METADATA_KEY, \"0\");\n+      metadata.put(DataTable.NUM_ENTRIES_SCANNED_IN_FILTER_METADATA_KEY, \"0\");\n+      metadata.put(DataTable.NUM_ENTRIES_SCANNED_POST_FILTER_METADATA_KEY, \"0\");\n+      metadata.put(DataTable.NUM_SEGMENTS_PROCESSED, \"0\");\n+      metadata.put(DataTable.NUM_SEGMENTS_MATCHED, \"0\");\n+      return dataTable;\n+    } else {\n+      TimerContext.Timer planBuildTimer = timerContext.startNewPhaseTimer(ServerQueryPhase.BUILD_QUERY_PLAN);\n+      Plan queryPlan = enableStreaming ? _planMaker\n+          .makeStreamingInstancePlan(selectedSegments, queryContext, executorService, responseObserver, endTimeMs)\n+          : _planMaker.makeInstancePlan(selectedSegments, queryContext, executorService, endTimeMs);\n+      planBuildTimer.stopAndRecord();\n+\n+      TimerContext.Timer planExecTimer = timerContext.startNewPhaseTimer(ServerQueryPhase.QUERY_PLAN_EXECUTION);\n+      DataTable dataTable = queryPlan.execute();\n+      planExecTimer.stopAndRecord();\n+\n+      // Update the total docs in the metadata based on the un-pruned segments\n+      dataTable.getMetadata().put(DataTable.TOTAL_DOCS_METADATA_KEY, Long.toString(numTotalDocs));\n+\n+      return dataTable;\n+    }\n+  }\n+\n+  /**\n+   * Handles the subquery in the given query.\n+   * <p>Currently only supports subquery within IN_PARTITIONED_SUBQUERY function.\n+   */\n+  private void handleSubquery(QueryContext queryContext, List<IndexSegment> indexSegments, TimerContext timerContext,\n+      ExecutorService executorService, long endTimeMs)\n+      throws Exception {\n+    FilterContext filter = queryContext.getFilter();\n+    if (filter != null) {\n+      handleSubquery(filter, indexSegments, timerContext, executorService, endTimeMs);\n+    }\n+  }\n+\n+  /**\n+   * Handles the subquery in the filter.\n+   * <p>Currently only supports subquery within IN_PARTITIONED_SUBQUERY function.\n+   */\n+  private void handleSubquery(FilterContext filter, List<IndexSegment> indexSegments, TimerContext timerContext,\n+      ExecutorService executorService, long endTimeMs)\n+      throws Exception {\n+    Predicate predicate = filter.getPredicate();\n+    if (predicate != null) {\n+      handleSubquery(predicate.getLhs(), indexSegments, timerContext, executorService, endTimeMs);\n+    } else {\n+      for (FilterContext child : filter.getChildren()) {\n+        handleSubquery(child, indexSegments, timerContext, executorService, endTimeMs);\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Handles the subquery in the given expression.\n+   * <p>Currently only supports subquery within IN_PARTITIONED_SUBQUERY function.\n+   */\n+  private void handleSubquery(ExpressionContext expression, List<IndexSegment> indexSegments, TimerContext timerContext,\n+      ExecutorService executorService, long endTimeMs)\n+      throws Exception {\n+    FunctionContext function = expression.getFunction();\n+    if (function == null) {\n+      return;\n+    }\n+    List<ExpressionContext> arguments = function.getArguments();\n+    if (StringUtils.remove(function.getFunctionName(), '_').equalsIgnoreCase(IN_PARTITIONED_SUBQUERY)) {\n+      Preconditions\n+          .checkState(arguments.size() == 2, \"IN_PARTITIONED_SUBQUERY requires 2 arguments: expression, subquery\");\n+      ExpressionContext subqueryExpression = arguments.get(1);\n+      Preconditions.checkState(subqueryExpression.getType() == ExpressionContext.Type.LITERAL,\n+          \"Second argument of IN_PARTITIONED_SUBQUERY must be a literal (subquery)\");\n+      QueryContext subquery = QueryContextConverterUtils.getQueryContextFromSQL(subqueryExpression.getLiteral());\n+      DataTable dataTable =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18ad00fa0c1cc938969839dacf8ada5c754a9f61"}, "originalPosition": 238}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDIzOTE4NA==", "bodyText": "Done", "url": "https://github.com/apache/pinot/pull/6043#discussion_r504239184", "createdAt": "2020-10-13T20:28:56Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/query/executor/ServerQueryExecutorV1Impl.java", "diffHunk": "@@ -277,4 +253,112 @@ public DataTable processQuery(ServerQueryRequest queryRequest, ExecutorService e\n     LOGGER.debug(\"InstanceResponse for request Id - {}: {}\", requestId, dataTable);\n     return dataTable;\n   }\n+\n+  private DataTable processQuery(List<IndexSegment> indexSegments, QueryContext queryContext, TimerContext timerContext,\n+      ExecutorService executorService, @Nullable StreamObserver<Server.ServerResponse> responseObserver, long endTimeMs,\n+      boolean enableStreaming)\n+      throws Exception {\n+    handleSubquery(queryContext, indexSegments, timerContext, executorService, endTimeMs);\n+\n+    // Compute total docs for the table before pruning the segments\n+    long numTotalDocs = 0;\n+    for (IndexSegment indexSegment : indexSegments) {\n+      numTotalDocs += indexSegment.getSegmentMetadata().getTotalDocs();\n+    }\n+\n+    TimerContext.Timer segmentPruneTimer = timerContext.startNewPhaseTimer(ServerQueryPhase.SEGMENT_PRUNING);\n+    List<IndexSegment> selectedSegments = _segmentPrunerService.prune(indexSegments, queryContext);\n+    segmentPruneTimer.stopAndRecord();\n+    int numSelectedSegments = selectedSegments.size();\n+    LOGGER.debug(\"Matched {} segments after pruning\", numSelectedSegments);\n+    if (numSelectedSegments == 0) {\n+      // Only return metadata for streaming query\n+      DataTable dataTable = enableStreaming ? new DataTableImplV2() : DataTableUtils.buildEmptyDataTable(queryContext);\n+      Map<String, String> metadata = dataTable.getMetadata();\n+      metadata.put(DataTable.TOTAL_DOCS_METADATA_KEY, String.valueOf(numTotalDocs));\n+      metadata.put(DataTable.NUM_DOCS_SCANNED_METADATA_KEY, \"0\");\n+      metadata.put(DataTable.NUM_ENTRIES_SCANNED_IN_FILTER_METADATA_KEY, \"0\");\n+      metadata.put(DataTable.NUM_ENTRIES_SCANNED_POST_FILTER_METADATA_KEY, \"0\");\n+      metadata.put(DataTable.NUM_SEGMENTS_PROCESSED, \"0\");\n+      metadata.put(DataTable.NUM_SEGMENTS_MATCHED, \"0\");\n+      return dataTable;\n+    } else {\n+      TimerContext.Timer planBuildTimer = timerContext.startNewPhaseTimer(ServerQueryPhase.BUILD_QUERY_PLAN);\n+      Plan queryPlan = enableStreaming ? _planMaker\n+          .makeStreamingInstancePlan(selectedSegments, queryContext, executorService, responseObserver, endTimeMs)\n+          : _planMaker.makeInstancePlan(selectedSegments, queryContext, executorService, endTimeMs);\n+      planBuildTimer.stopAndRecord();\n+\n+      TimerContext.Timer planExecTimer = timerContext.startNewPhaseTimer(ServerQueryPhase.QUERY_PLAN_EXECUTION);\n+      DataTable dataTable = queryPlan.execute();\n+      planExecTimer.stopAndRecord();\n+\n+      // Update the total docs in the metadata based on the un-pruned segments\n+      dataTable.getMetadata().put(DataTable.TOTAL_DOCS_METADATA_KEY, Long.toString(numTotalDocs));\n+\n+      return dataTable;\n+    }\n+  }\n+\n+  /**\n+   * Handles the subquery in the given query.\n+   * <p>Currently only supports subquery within IN_PARTITIONED_SUBQUERY function.\n+   */\n+  private void handleSubquery(QueryContext queryContext, List<IndexSegment> indexSegments, TimerContext timerContext,\n+      ExecutorService executorService, long endTimeMs)\n+      throws Exception {\n+    FilterContext filter = queryContext.getFilter();\n+    if (filter != null) {\n+      handleSubquery(filter, indexSegments, timerContext, executorService, endTimeMs);\n+    }\n+  }\n+\n+  /**\n+   * Handles the subquery in the filter.\n+   * <p>Currently only supports subquery within IN_PARTITIONED_SUBQUERY function.\n+   */\n+  private void handleSubquery(FilterContext filter, List<IndexSegment> indexSegments, TimerContext timerContext,\n+      ExecutorService executorService, long endTimeMs)\n+      throws Exception {\n+    Predicate predicate = filter.getPredicate();\n+    if (predicate != null) {\n+      handleSubquery(predicate.getLhs(), indexSegments, timerContext, executorService, endTimeMs);\n+    } else {\n+      for (FilterContext child : filter.getChildren()) {\n+        handleSubquery(child, indexSegments, timerContext, executorService, endTimeMs);\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Handles the subquery in the given expression.\n+   * <p>Currently only supports subquery within IN_PARTITIONED_SUBQUERY function.\n+   */\n+  private void handleSubquery(ExpressionContext expression, List<IndexSegment> indexSegments, TimerContext timerContext,\n+      ExecutorService executorService, long endTimeMs)\n+      throws Exception {\n+    FunctionContext function = expression.getFunction();\n+    if (function == null) {\n+      return;\n+    }\n+    List<ExpressionContext> arguments = function.getArguments();\n+    if (StringUtils.remove(function.getFunctionName(), '_').equalsIgnoreCase(IN_PARTITIONED_SUBQUERY)) {\n+      Preconditions\n+          .checkState(arguments.size() == 2, \"IN_PARTITIONED_SUBQUERY requires 2 arguments: expression, subquery\");\n+      ExpressionContext subqueryExpression = arguments.get(1);\n+      Preconditions.checkState(subqueryExpression.getType() == ExpressionContext.Type.LITERAL,\n+          \"Second argument of IN_PARTITIONED_SUBQUERY must be a literal (subquery)\");\n+      QueryContext subquery = QueryContextConverterUtils.getQueryContextFromSQL(subqueryExpression.getLiteral());\n+      DataTable dataTable =", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjc1NzM1MQ=="}, "originalCommit": {"oid": "18ad00fa0c1cc938969839dacf8ada5c754a9f61"}, "originalPosition": 238}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE0ODQyNzE1OnYy", "diffSide": "RIGHT", "path": "pinot-core/src/main/java/org/apache/pinot/core/query/request/context/QueryContext.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMFQwNzoxNTowMVrOHfd5Xw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QyMDoyOTo0MFrOHg4V7g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjc1NzcyNw==", "bodyText": "why is this a public method? who is invoking this and from where", "url": "https://github.com/apache/pinot/pull/6043#discussion_r502757727", "createdAt": "2020-10-10T07:15:01Z", "author": {"login": "kishoreg"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/query/request/context/QueryContext.java", "diffHunk": "@@ -372,5 +399,46 @@ private static void getAggregations(FilterContext filter, List<FunctionContext>\n         getAggregations(filter.getPredicate().getLhs(), aggregations);\n       }\n     }\n+\n+    /**\n+     * Helper method to extract the columns (IDENTIFIER expressions) for the query.\n+     */\n+    public void extractColumns(QueryContext query) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18ad00fa0c1cc938969839dacf8ada5c754a9f61"}, "originalPosition": 128}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDIzOTU5OA==", "bodyText": "Good catch, changed to private", "url": "https://github.com/apache/pinot/pull/6043#discussion_r504239598", "createdAt": "2020-10-13T20:29:40Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/query/request/context/QueryContext.java", "diffHunk": "@@ -372,5 +399,46 @@ private static void getAggregations(FilterContext filter, List<FunctionContext>\n         getAggregations(filter.getPredicate().getLhs(), aggregations);\n       }\n     }\n+\n+    /**\n+     * Helper method to extract the columns (IDENTIFIER expressions) for the query.\n+     */\n+    public void extractColumns(QueryContext query) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjc1NzcyNw=="}, "originalCommit": {"oid": "18ad00fa0c1cc938969839dacf8ada5c754a9f61"}, "originalPosition": 128}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3909, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}