{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzYzODk0OTc0", "number": 4993, "title": "Support Text column type in Pinot (both offline and realtime)", "bodyText": "Support for text column type for both offline and realtime. This has changed after cleaning up the POC code, addressing some review comments and making more changes based on the detailed design doc.\nIssue #4719\nDesign doc: https://docs.google.com/document/d/19uLti7wwl7nPlDuy6cUVnLOll2C8u3YtUITbNj0TT5o/edit#heading=h.sj2kenbac7uv\nPOC doc:\nhttps://docs.google.com/document/d/1P38NvfNfATiTzd8W_ZBzPyAnP50_lyFk-qm6syqeD2E/edit?ts=5da7619d#\nPOC PR:\n#4715\nFunctional tests used Lucene phrase, term, regex queries and combination of them using AND/OR.\nDatasets used:\n\n\nSkills file - each text line is a resume text. It is stored as a column in Pinot table and each line of text is a column value. We create a text index on this column.\n\n\nQuery log file - each log line is PQL/SQL query. It is stored as a column in Pinot table and each line of text is a column value. We create a text index on this column.\n\n\nAdditional tests to combine text search filters with other filters using AND/OR\n\n\nTests for near realtime search with Lucene\n-- Tests for multithreaded read/write scenario\n-- Tests for reference counting\n-- Cluster integration test that writes the skills file into AVRO followed by Kafka topic and starts\nconsuming.\n\n\nPerformance tests were done as part of POC PR. Will be checked-in separately.", "createdAt": "2020-01-16T23:26:41Z", "url": "https://github.com/apache/pinot/pull/4993", "merged": true, "mergeCommit": {"oid": "2a795310267e329c5b426dd639f65e510bcf1018"}, "closed": true, "closedAt": "2020-02-14T15:45:48Z", "author": {"login": "siddharthteotia"}, "timelineItems": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABb7FdmXgFqTM0NDI5OTQ3MQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcEL1a2gBqjMwMzc5Njk4Mzk=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ0Mjk5NDcx", "url": "https://github.com/apache/pinot/pull/4993#pullrequestreview-344299471", "createdAt": "2020-01-17T00:19:44Z", "commit": {"oid": "e6a0188b729974efca4077973684ae7f0f8e8652"}, "state": "COMMENTED", "comments": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QwMDoxOTo0NFrOFerkAA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QwMjozNjoyMVrOFetYGA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzcxNTMyOA==", "bodyText": "what will this look like when we move to calcite sql", "url": "https://github.com/apache/pinot/pull/4993#discussion_r367715328", "createdAt": "2020-01-17T00:19:44Z", "author": {"login": "kishoreg"}, "path": "pinot-common/src/main/antlr4/org/apache/pinot/pql/parsers/PQL2.g4", "diffHunk": "@@ -95,6 +96,9 @@ betweenClause:\n regexpLikeClause:\n   REGEXP_LIKE '(' expression ',' literal ')';\n \n+textMatchClause:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e6a0188b729974efca4077973684ae7f0f8e8652"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzcxNTgyMA==", "bodyText": "what is needed here?", "url": "https://github.com/apache/pinot/pull/4993#discussion_r367715820", "createdAt": "2020-01-17T00:21:43Z", "author": {"login": "kishoreg"}, "path": "pinot-common/src/main/java/org/apache/pinot/pql/parsers/pql2/ast/TextMatchPredicateAstNode.java", "diffHunk": "@@ -0,0 +1,82 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.pql.parsers.pql2.ast;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import org.apache.pinot.common.request.Expression;\n+import org.apache.pinot.common.request.FilterOperator;\n+import org.apache.pinot.common.utils.StringUtil;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.HavingQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.pql.parsers.Pql2CompilationException;\n+\n+\n+public class TextMatchPredicateAstNode extends PredicateAstNode {\n+\n+  private static final String SEPERATOR = \"\\t\\t\";\n+\n+  @Override\n+  public void addChild(AstNode childNode) {\n+    if (childNode instanceof IdentifierAstNode) {\n+      if (_identifier == null) {\n+        IdentifierAstNode node = (IdentifierAstNode) childNode;\n+        _identifier = node.getName();\n+      } else {\n+        throw new Pql2CompilationException(\"TEXT_MATCH predicate has more than one identifier.\");\n+      }\n+    } else if (childNode instanceof FunctionCallAstNode) {\n+      throw new Pql2CompilationException(\"TEXT_MATCH is not supported with function\");\n+    } else {\n+      super.addChild(childNode);\n+    }\n+  }\n+\n+  @Override\n+  public FilterQueryTree buildFilterQueryTree() {\n+    if (_identifier == null) {\n+      throw new Pql2CompilationException(\"TEXT_MATCH predicate has no identifier\");\n+    }\n+\n+    List<? extends AstNode> children = getChildren();\n+    Preconditions.checkState(children != null && children.size() == 1);\n+    AstNode child = children.get(0);\n+    Preconditions.checkState(child instanceof StringLiteralAstNode);\n+    String expr = ((StringLiteralAstNode)child).getValueAsString();\n+    FilterOperator filterOperator = FilterOperator.TEXT_MATCH;\n+    List<String> value = Collections.singletonList(expr);\n+    return new FilterQueryTree(_identifier, value, filterOperator, null);\n+  }\n+\n+  @Override\n+  public Expression buildFilterExpression() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e6a0188b729974efca4077973684ae7f0f8e8652"}, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzcxNTk5Nw==", "bodyText": "define lucene version in root pom", "url": "https://github.com/apache/pinot/pull/4993#discussion_r367715997", "createdAt": "2020-01-17T00:22:29Z", "author": {"login": "kishoreg"}, "path": "pinot-core/pom.xml", "diffHunk": "@@ -198,5 +198,20 @@\n       <type>test-jar</type>\n       <scope>test</scope>\n     </dependency>\n+    <dependency>\n+      <groupId>org.apache.lucene</groupId>\n+      <artifactId>lucene-core</artifactId>\n+      <version>8.2.0</version>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e6a0188b729974efca4077973684ae7f0f8e8652"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzcxNjgyNw==", "bodyText": "can we avoid concrete reference to RealtimeLuceneTextIndexReader and try to use InvertedIndexReader?", "url": "https://github.com/apache/pinot/pull/4993#discussion_r367716827", "createdAt": "2020-01-17T00:25:57Z", "author": {"login": "kishoreg"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/indexsegment/mutable/MutableSegmentImpl.java", "diffHunk": "@@ -45,10 +55,13 @@\n import org.apache.pinot.core.realtime.impl.dictionary.MutableDictionaryFactory;\n import org.apache.pinot.core.realtime.impl.invertedindex.RealtimeInvertedIndexReader;\n import org.apache.pinot.core.realtime.impl.nullvalue.RealtimeNullValueVectorReaderWriter;\n+import org.apache.pinot.core.realtime.impl.invertedindex.RealtimeLuceneTextIndexReader;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e6a0188b729974efca4077973684ae7f0f8e8652"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzcxNzQyOA==", "bodyText": "is there any way we can drive this through invertedindexreader interface", "url": "https://github.com/apache/pinot/pull/4993#discussion_r367717428", "createdAt": "2020-01-17T00:28:29Z", "author": {"login": "kishoreg"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/indexsegment/mutable/MutableSegmentImpl.java", "diffHunk": "@@ -118,6 +131,36 @@\n   private volatile long _lastIndexedTimeMs = Long.MIN_VALUE;\n   private volatile long _latestIngestionTimeMs = Long.MIN_VALUE;\n \n+  private static final ScheduledExecutorService _scheduledExecutorService;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e6a0188b729974efca4077973684ae7f0f8e8652"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzcxNzgwMA==", "bodyText": "not sure what happened here with formatting. are you using the checkstyle", "url": "https://github.com/apache/pinot/pull/4993#discussion_r367717800", "createdAt": "2020-01-17T00:30:14Z", "author": {"login": "kishoreg"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/indexsegment/mutable/MutableSegmentImpl.java", "diffHunk": "@@ -281,10 +334,14 @@ public long getLatestIngestionTimestamp() {\n    * @param column column name\n    * @return true if column is no-dictionary, false if dictionary encoded\n    */\n-  private boolean isNoDictionaryColumn(Set<String> noDictionaryColumns, Set<String> invertedIndexColumns,\n-      FieldSpec fieldSpec, String column) {\n-    return noDictionaryColumns.contains(column) && fieldSpec.isSingleValueField()\n-        && !invertedIndexColumns.contains(column);\n+  private boolean isNoDictionaryColumn(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e6a0188b729974efca4077973684ae7f0f8e8652"}, "originalPosition": 132}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzcxODI3Nw==", "bodyText": "what cant we pass the row to old interface and let the implementation use it or ignore it", "url": "https://github.com/apache/pinot/pull/4993#discussion_r367718277", "createdAt": "2020-01-17T00:32:22Z", "author": {"login": "kishoreg"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/indexsegment/mutable/MutableSegmentImpl.java", "diffHunk": "@@ -418,28 +474,35 @@ private void addForwardIndex(GenericRow row, int docId, Map<String, Object> dict\n           }\n         }\n       } else {\n+        // MV column: always dictionary encoded\n         int[] dictIds = (int[]) dictIdMap.get(column);\n         ((FixedByteSingleColumnMultiValueReaderWriter) _indexReaderWriterMap.get(column)).setIntArray(docId, dictIds);\n       }\n     }\n   }\n \n-  private void addInvertedIndex(int docId, Map<String, Object> dictIdMap) {\n+  private void addInvertedIndex(GenericRow row, int docId, Map<String, Object> dictIdMap) {\n     // Update inverted index at last\n     // NOTE: inverted index have to be updated at last because once it gets updated, the latest record will become\n     // queryable\n     for (FieldSpec fieldSpec : _physicalFieldSpecs) {\n       String column = fieldSpec.getName();\n-      RealtimeInvertedIndexReader invertedIndex = _invertedIndexMap.get(column);\n+      InvertedIndexReader invertedIndex = _invertedIndexMap.get(column);\n       if (invertedIndex != null) {\n-        if (fieldSpec.isSingleValueField()) {\n-          invertedIndex.add(((Integer) dictIdMap.get(column)), docId);\n+        if (invertedIndex instanceof RealtimeLuceneTextIndexReader) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e6a0188b729974efca4077973684ae7f0f8e8652"}, "originalPosition": 198}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzcxODQ5Mw==", "bodyText": "same here, lets think about folding this into invertedindexreader without having to check for the instanceof", "url": "https://github.com/apache/pinot/pull/4993#discussion_r367718493", "createdAt": "2020-01-17T00:33:17Z", "author": {"login": "kishoreg"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/indexsegment/mutable/MutableSegmentImpl.java", "diffHunk": "@@ -608,8 +671,27 @@ public void destroy() {\n     // clear map now that index is closed to prevent accidental usage\n     _indexReaderWriterMap.clear();\n \n-    for (RealtimeInvertedIndexReader index : _invertedIndexMap.values()) {\n-      index.close();\n+    for (InvertedIndexReader index : _invertedIndexMap.values()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e6a0188b729974efca4077973684ae7f0f8e8652"}, "originalPosition": 224}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc0MDc5OQ==", "bodyText": "nit _docId", "url": "https://github.com/apache/pinot/pull/4993#discussion_r367740799", "createdAt": "2020-01-17T02:14:15Z", "author": {"login": "kishoreg"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/operator/dociditerators/LuceneIndexScanDocIdIterator.java", "diffHunk": "@@ -0,0 +1,90 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.operator.dociditerators;\n+\n+import org.apache.lucene.document.Document;\n+import org.apache.lucene.search.IndexSearcher;\n+import org.apache.pinot.core.common.Constants;\n+import org.apache.pinot.core.segment.creator.impl.V1Constants;\n+import org.apache.pinot.core.segment.index.readers.text.LuceneIndexSearcherReferenceManager;\n+import org.apache.pinot.core.segment.index.readers.text.LuceneTextIndexReader;\n+import org.roaringbitmap.IntIterator;\n+\n+\n+public class LuceneIndexScanDocIdIterator implements IndexBasedDocIdIterator {\n+\n+  private int _currentDocId = -1;\n+  private int _startDocId;\n+  private int _endDocId;\n+  private final IntIterator _docIDIterator;\n+  private final IndexSearcher _indexSearcher;\n+  private final LuceneIndexSearcherReferenceManager _searcherReferenceManager;\n+  private final int _numDocs;\n+\n+  public LuceneIndexScanDocIdIterator(LuceneTextIndexReader.LuceneSearchResult luceneSearchResult) {\n+    _docIDIterator = luceneSearchResult.getDocIDs().getIntIterator();\n+    _numDocs = luceneSearchResult.getDocIDs().getCardinality();\n+    _searcherReferenceManager = luceneSearchResult.getIndexSearcherReferenceManager();\n+    _indexSearcher = _searcherReferenceManager.getIndexSearcher();\n+  }\n+\n+  public void setStartDocId(int startDocId) {\n+    _startDocId = startDocId;\n+  }\n+\n+  public void setEndDocId(int endDocId) {\n+    _endDocId = endDocId;\n+  }\n+\n+  @Override\n+  public int next() {\n+    if (_currentDocId == Constants.EOF || !_docIDIterator.hasNext()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e6a0188b729974efca4077973684ae7f0f8e8652"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc0MzM4Nw==", "bodyText": "why not just get the bitmap and reused all the iterators on top of bitmap", "url": "https://github.com/apache/pinot/pull/4993#discussion_r367743387", "createdAt": "2020-01-17T02:27:44Z", "author": {"login": "kishoreg"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/operator/dociditerators/LuceneIndexScanDocIdIterator.java", "diffHunk": "@@ -0,0 +1,90 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.operator.dociditerators;\n+\n+import org.apache.lucene.document.Document;\n+import org.apache.lucene.search.IndexSearcher;\n+import org.apache.pinot.core.common.Constants;\n+import org.apache.pinot.core.segment.creator.impl.V1Constants;\n+import org.apache.pinot.core.segment.index.readers.text.LuceneIndexSearcherReferenceManager;\n+import org.apache.pinot.core.segment.index.readers.text.LuceneTextIndexReader;\n+import org.roaringbitmap.IntIterator;\n+\n+\n+public class LuceneIndexScanDocIdIterator implements IndexBasedDocIdIterator {\n+\n+  private int _currentDocId = -1;\n+  private int _startDocId;\n+  private int _endDocId;\n+  private final IntIterator _docIDIterator;\n+  private final IndexSearcher _indexSearcher;\n+  private final LuceneIndexSearcherReferenceManager _searcherReferenceManager;\n+  private final int _numDocs;\n+\n+  public LuceneIndexScanDocIdIterator(LuceneTextIndexReader.LuceneSearchResult luceneSearchResult) {\n+    _docIDIterator = luceneSearchResult.getDocIDs().getIntIterator();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e6a0188b729974efca4077973684ae7f0f8e8652"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc0MzQ5NQ==", "bodyText": "dont think we need this class", "url": "https://github.com/apache/pinot/pull/4993#discussion_r367743495", "createdAt": "2020-01-17T02:28:11Z", "author": {"login": "kishoreg"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/operator/docidsets/LuceneIndexDocIdSet.java", "diffHunk": "@@ -0,0 +1,84 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.operator.docidsets;\n+\n+import org.apache.pinot.core.common.BlockDocIdIterator;\n+import org.apache.pinot.core.operator.dociditerators.LuceneIndexScanDocIdIterator;\n+import org.apache.pinot.core.segment.index.readers.text.LuceneTextIndexReader;\n+\n+\n+public class LuceneIndexDocIdSet implements FilterBlockDocIdSet {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e6a0188b729974efca4077973684ae7f0f8e8652"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc0NDc3NA==", "bodyText": "why is it below AND/OR?\nlets say the query is  (a>10 or b<10) and (text_match(c, \"\"). It's better to evaluate text match before evaluating OR and use the results from text_match to restrict the scope of OR.\nI think the priority of this should be similar to bitmap. WDYT?", "url": "https://github.com/apache/pinot/pull/4993#discussion_r367744774", "createdAt": "2020-01-17T02:34:56Z", "author": {"login": "kishoreg"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/operator/filter/FilterOperatorUtils.java", "diffHunk": "@@ -148,8 +153,11 @@ int getPriority(BaseFilterOperator filterOperator) {\n         if (filterOperator instanceof OrFilterOperator) {\n           return 3;\n         }\n+        if (filterOperator instanceof TextMatchFilterOperator) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e6a0188b729974efca4077973684ae7f0f8e8652"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc0NDkyNg==", "bodyText": "I think modelling this as a BitmapFilterOperator will simplify lot of things.", "url": "https://github.com/apache/pinot/pull/4993#discussion_r367744926", "createdAt": "2020-01-17T02:35:39Z", "author": {"login": "kishoreg"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/operator/filter/TextMatchFilterOperator.java", "diffHunk": "@@ -0,0 +1,67 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.operator.filter;\n+\n+import com.google.common.base.Preconditions;\n+import org.apache.pinot.core.common.DataSource;\n+import org.apache.pinot.core.common.Predicate;\n+import org.apache.pinot.core.operator.blocks.FilterBlock;\n+import org.apache.pinot.core.operator.docidsets.LuceneIndexDocIdSet;\n+import org.apache.pinot.core.operator.filter.predicate.PredicateEvaluator;\n+import org.apache.pinot.core.operator.filter.predicate.TextMatchPredicateEvaluatorFactory;\n+import org.apache.pinot.core.segment.index.readers.InvertedIndexReader;\n+import org.apache.pinot.core.segment.index.readers.text.LuceneTextIndexReader;\n+\n+\n+/**\n+ * Filter operator for supporting the execution of text search\n+ * queries: WHERE TEXT_MATCH(column_name, query_string....)\n+ */\n+public class TextMatchFilterOperator extends BaseFilterOperator {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e6a0188b729974efca4077973684ae7f0f8e8652"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc0NTA0OA==", "bodyText": "lets do this in this iteration, its much cleaner, and easier", "url": "https://github.com/apache/pinot/pull/4993#discussion_r367745048", "createdAt": "2020-01-17T02:36:21Z", "author": {"login": "kishoreg"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/operator/filter/TextMatchFilterOperator.java", "diffHunk": "@@ -0,0 +1,67 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.operator.filter;\n+\n+import com.google.common.base.Preconditions;\n+import org.apache.pinot.core.common.DataSource;\n+import org.apache.pinot.core.common.Predicate;\n+import org.apache.pinot.core.operator.blocks.FilterBlock;\n+import org.apache.pinot.core.operator.docidsets.LuceneIndexDocIdSet;\n+import org.apache.pinot.core.operator.filter.predicate.PredicateEvaluator;\n+import org.apache.pinot.core.operator.filter.predicate.TextMatchPredicateEvaluatorFactory;\n+import org.apache.pinot.core.segment.index.readers.InvertedIndexReader;\n+import org.apache.pinot.core.segment.index.readers.text.LuceneTextIndexReader;\n+\n+\n+/**\n+ * Filter operator for supporting the execution of text search\n+ * queries: WHERE TEXT_MATCH(column_name, query_string....)\n+ */\n+public class TextMatchFilterOperator extends BaseFilterOperator {\n+  private static final String OPERATOR_NAME = \"TextMatchFilterOperator\";\n+\n+  private final Predicate _predicate;\n+  private final DataSource _dataSource;\n+  private final int _startDocId;\n+  private final int _endDocId;\n+\n+  public TextMatchFilterOperator(PredicateEvaluator predicateEvaluator, DataSource dataSource, int startDocId, int endDocId) {\n+    Preconditions.checkArgument(predicateEvaluator instanceof TextMatchPredicateEvaluatorFactory.RawValueBasedTextMatchPredicateEvaluator &&\n+    !predicateEvaluator.isAlwaysTrue() && !predicateEvaluator.isAlwaysFalse());\n+    TextMatchPredicateEvaluatorFactory.RawValueBasedTextMatchPredicateEvaluator evaluator = (TextMatchPredicateEvaluatorFactory.RawValueBasedTextMatchPredicateEvaluator)predicateEvaluator;\n+    _predicate = evaluator.getPredicate();\n+    _dataSource = dataSource;\n+    _startDocId = startDocId;\n+    _endDocId = endDocId;\n+  }\n+\n+  @Override\n+  protected FilterBlock getNextBlock() {\n+    InvertedIndexReader textIndexReader = _dataSource.getInvertedIndex();\n+    Preconditions.checkNotNull(textIndexReader, \"Error: expecting non-null text index\");\n+    LuceneTextIndexReader.LuceneSearchResult luceneSearchResult = (LuceneTextIndexReader.LuceneSearchResult)textIndexReader.getDocIds(_predicate);\n+    // TODO: For the next iteration of this feature, consider using BitMapDocIdSet (and BitMapDocIdIterator)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e6a0188b729974efca4077973684ae7f0f8e8652"}, "originalPosition": 59}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "eaf74497252745ee12ea264d1d0c24f070513e3c", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/eaf74497252745ee12ea264d1d0c24f070513e3c", "committedDate": "2020-01-17T07:07:20Z", "message": "Use BitMapDocIdSet and Iterator to iterate on\nlucene search result"}, "afterCommit": {"oid": "67e6a79e68fa1e5b5bc8e0bab5d028e6aa3f0cd3", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/67e6a79e68fa1e5b5bc8e0bab5d028e6aa3f0cd3", "committedDate": "2020-01-17T21:33:03Z", "message": "Support Text Search"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "7f424bb253949e5b86a5e8bb43a1a904489ebc21", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/7f424bb253949e5b86a5e8bb43a1a904489ebc21", "committedDate": "2020-01-17T23:44:16Z", "message": "fix test failure"}, "afterCommit": {"oid": "e09476aef8795db4fbfc42f7541a9ab3cf848c50", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/e09476aef8795db4fbfc42f7541a9ab3cf848c50", "committedDate": "2020-01-18T07:27:57Z", "message": "Support Text Search"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ0OTc1ODAw", "url": "https://github.com/apache/pinot/pull/4993#pullrequestreview-344975800", "createdAt": "2020-01-19T04:11:40Z", "commit": {"oid": "e09476aef8795db4fbfc42f7541a9ab3cf848c50"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ1MDM3MTk4", "url": "https://github.com/apache/pinot/pull/4993#pullrequestreview-345037198", "createdAt": "2020-01-19T23:56:31Z", "commit": {"oid": "e09476aef8795db4fbfc42f7541a9ab3cf848c50"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOVQyMzo1NjozMVrOFfRWRQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMFQwMDoyMToxOVrOFfRdMw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMzNDQwNQ==", "bodyText": "Is there a compilation check that this is validated? If not, then throwing a runtime error on a query that is invalid in the first place seems to be wrong. We will end up returning 5xx instead of 4xx on the query, right?", "url": "https://github.com/apache/pinot/pull/4993#discussion_r368334405", "createdAt": "2020-01-19T23:56:31Z", "author": {"login": "mcvsubbu"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/common/predicate/TextMatchPredicate.java", "diffHunk": "@@ -0,0 +1,45 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.common.predicate;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.Arrays;\n+import java.util.List;\n+import org.apache.pinot.core.common.Predicate;\n+\n+\n+public class TextMatchPredicate extends Predicate {\n+  String _searchQuery;\n+\n+  public TextMatchPredicate(String lhs, List<String> rhs) {\n+    super(lhs, Predicate.Type.TEXT_MATCH, rhs);\n+    Preconditions.checkArgument(rhs.size() == 1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e09476aef8795db4fbfc42f7541a9ab3cf848c50"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMzNDc1OQ==", "bodyText": "This code should go into the segment data manager instead of a static here.", "url": "https://github.com/apache/pinot/pull/4993#discussion_r368334759", "createdAt": "2020-01-20T00:01:51Z", "author": {"login": "mcvsubbu"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/indexsegment/mutable/MutableSegmentImpl.java", "diffHunk": "@@ -118,6 +131,54 @@\n   private volatile long _lastIndexedTimeMs = Long.MIN_VALUE;\n   private volatile long _latestIngestionTimeMs = Long.MIN_VALUE;\n \n+  private static final ScheduledExecutorService _scheduledExecutorService;\n+  private static final ConcurrentLinkedQueue<RealtimeLuceneReadersForRealtimeSegment> _luceneRealtimeReaders;\n+  private static final ConcurrentHashMap<String, RealtimeLuceneReadersForRealtimeSegment> _segmentToRealtimeLuceneReadersMap;\n+\n+  static {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e09476aef8795db4fbfc42f7541a9ab3cf848c50"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMzNTAyNg==", "bodyText": "I guess we need to handle the case when a text column is added to a consuming segment and a reload is issued. See PR 4954 in the brew. Lists are not thread-safe, but it depends on how we handle this.", "url": "https://github.com/apache/pinot/pull/4993#discussion_r368335026", "createdAt": "2020-01-20T00:05:57Z", "author": {"login": "mcvsubbu"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/indexsegment/mutable/MutableSegmentImpl.java", "diffHunk": "@@ -118,6 +131,54 @@\n   private volatile long _lastIndexedTimeMs = Long.MIN_VALUE;\n   private volatile long _latestIngestionTimeMs = Long.MIN_VALUE;\n \n+  private static final ScheduledExecutorService _scheduledExecutorService;\n+  private static final ConcurrentLinkedQueue<RealtimeLuceneReadersForRealtimeSegment> _luceneRealtimeReaders;\n+  private static final ConcurrentHashMap<String, RealtimeLuceneReadersForRealtimeSegment> _segmentToRealtimeLuceneReadersMap;\n+\n+  static {\n+    _scheduledExecutorService = Executors.newSingleThreadScheduledExecutor();\n+    _luceneRealtimeReaders = new ConcurrentLinkedQueue<>();\n+    _segmentToRealtimeLuceneReadersMap = new ConcurrentHashMap<>();\n+    _scheduledExecutorService.scheduleWithFixedDelay(new RealtimeLuceneIndexReaderRefreshTask(_luceneRealtimeReaders),\n+        RealtimeLuceneIndexReaderRefreshTask.INITIAL_DELAY_MS_DEFAULT, RealtimeLuceneIndexReaderRefreshTask.DELAY_BETWEEN_SUCCESSIVE_EXECUTION_MS_DEFAULT, TimeUnit.MILLISECONDS);\n+  }\n+\n+  /**\n+   * Since the text index is maintained per TEXT column (similar to other Pinot indexes),\n+   * there could be multiple lucene indexes for a given segment and therefore there can be\n+   * multiple realtime lucene readers (one for each index/column) for the particular\n+   * realtime segment.\n+   */\n+  public static class RealtimeLuceneReadersForRealtimeSegment {\n+    private final String segmentName;\n+    private final Lock lock;\n+    private volatile boolean segmentAboutToBeDestroyed;\n+    private final List<RealtimeLuceneTextIndexReader> realtimeLuceneReaders;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e09476aef8795db4fbfc42f7541a9ab3cf848c50"}, "originalPosition": 81}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMzNTU4Mg==", "bodyText": "Suggest rename to RealtimeLuceneIndexReaderRefreshThread since \"task\" has a different meaning in pinot (see minion)", "url": "https://github.com/apache/pinot/pull/4993#discussion_r368335582", "createdAt": "2020-01-20T00:13:22Z", "author": {"login": "mcvsubbu"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/realtime/impl/invertedindex/RealtimeLuceneIndexReaderRefreshTask.java", "diffHunk": "@@ -0,0 +1,106 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.realtime.impl.invertedindex;\n+\n+import java.util.List;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import org.apache.lucene.search.SearcherManager;\n+import org.apache.pinot.core.indexsegment.mutable.MutableSegmentImpl;\n+import org.apache.pinot.core.segment.creator.impl.SegmentColumnarIndexCreator;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Background thread to refresh the realtime lucene index readers for supporting\n+ * near-realtime text search. The task maintains a queue of realtime segments.\n+ * This queue is global (across all realtime segments of all realtime/hybrid tables).\n+ *\n+ * Each element in the queue is of type\n+ * {@link org.apache.pinot.core.indexsegment.mutable.MutableSegmentImpl.RealtimeLuceneReadersForRealtimeSegment}.\n+ * It encapsulate a lock and all the realtime lucene readers for the particular realtime segment.\n+ * Since text index is also create on a per column basis, there will be as many realtime lucene\n+ * readers as the number of columns with text search enabled.\n+ *\n+ * Between each successive execution of the task, there is a fixed delay (regardless of how long\n+ * each execution took). When the task wakes up, it pick the RealtimeLuceneReadersForRealtimeSegment\n+ * from the head of queue, refresh it's readers and adds this at the tail of queue.\n+ */\n+public class RealtimeLuceneIndexReaderRefreshTask implements Runnable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e09476aef8795db4fbfc42f7541a9ab3cf848c50"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMzNTcwNw==", "bodyText": "default should not be this value. In fact, the default should be to disable the task. Ideally, the thread should be scheduled only when there is at least one text column added", "url": "https://github.com/apache/pinot/pull/4993#discussion_r368335707", "createdAt": "2020-01-20T00:14:46Z", "author": {"login": "mcvsubbu"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/realtime/impl/invertedindex/RealtimeLuceneIndexReaderRefreshTask.java", "diffHunk": "@@ -0,0 +1,106 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.realtime.impl.invertedindex;\n+\n+import java.util.List;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import org.apache.lucene.search.SearcherManager;\n+import org.apache.pinot.core.indexsegment.mutable.MutableSegmentImpl;\n+import org.apache.pinot.core.segment.creator.impl.SegmentColumnarIndexCreator;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Background thread to refresh the realtime lucene index readers for supporting\n+ * near-realtime text search. The task maintains a queue of realtime segments.\n+ * This queue is global (across all realtime segments of all realtime/hybrid tables).\n+ *\n+ * Each element in the queue is of type\n+ * {@link org.apache.pinot.core.indexsegment.mutable.MutableSegmentImpl.RealtimeLuceneReadersForRealtimeSegment}.\n+ * It encapsulate a lock and all the realtime lucene readers for the particular realtime segment.\n+ * Since text index is also create on a per column basis, there will be as many realtime lucene\n+ * readers as the number of columns with text search enabled.\n+ *\n+ * Between each successive execution of the task, there is a fixed delay (regardless of how long\n+ * each execution took). When the task wakes up, it pick the RealtimeLuceneReadersForRealtimeSegment\n+ * from the head of queue, refresh it's readers and adds this at the tail of queue.\n+ */\n+public class RealtimeLuceneIndexReaderRefreshTask implements Runnable {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(SegmentColumnarIndexCreator.class);\n+  public static final int INITIAL_DELAY_MS_DEFAULT = 1000;\n+  // TODO: make this configurable and choose a higher default value\n+  public static final int DELAY_BETWEEN_SUCCESSIVE_EXECUTION_MS_DEFAULT = 10;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e09476aef8795db4fbfc42f7541a9ab3cf848c50"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODMzNjE3OQ==", "bodyText": "why is this volatile?", "url": "https://github.com/apache/pinot/pull/4993#discussion_r368336179", "createdAt": "2020-01-20T00:21:19Z", "author": {"login": "mcvsubbu"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/realtime/impl/invertedindex/RealtimeLuceneTextIndexReader.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.realtime.impl.invertedindex;\n+\n+import java.io.File;\n+import org.apache.lucene.analysis.standard.StandardAnalyzer;\n+import org.apache.lucene.index.IndexWriter;\n+import org.apache.lucene.queryparser.classic.QueryParser;\n+import org.apache.lucene.search.Collector;\n+import org.apache.lucene.search.IndexSearcher;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.search.SearcherManager;\n+import org.apache.pinot.core.common.Predicate;\n+import org.apache.pinot.core.common.predicate.TextMatchPredicate;\n+import org.apache.pinot.core.segment.creator.impl.inv.text.LuceneTextIndexCreator;\n+import org.apache.pinot.core.segment.index.readers.InvertedIndexReader;\n+import org.apache.pinot.core.segment.index.readers.text.LuceneDocIdCollector;\n+import org.apache.pinot.core.segment.index.readers.text.LuceneIndexSearcherReferenceManager;\n+import org.apache.pinot.core.segment.index.readers.text.LuceneTextIndexReader;\n+import org.roaringbitmap.buffer.MutableRoaringBitmap;\n+\n+\n+/**\n+ * Lucene text index reader supporting near realtime search. An instance of this\n+ * is created per consuming segment by {@link org.apache.pinot.core.indexsegment.mutable.MutableSegmentImpl}.\n+ * Internally it uses {@link LuceneTextIndexCreator} for adding documents to the lucene index\n+ * as and when they are indexed by the consuming segment.\n+ */\n+public class RealtimeLuceneTextIndexReader implements InvertedIndexReader<LuceneTextIndexReader.LuceneSearchResult> {\n+  private final QueryParser _queryParser;\n+  private final LuceneTextIndexCreator _indexCreator;\n+  private volatile SearcherManager _searcherManager;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e09476aef8795db4fbfc42f7541a9ab3cf848c50"}, "originalPosition": 48}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ1MDQwMDgy", "url": "https://github.com/apache/pinot/pull/4993#pullrequestreview-345040082", "createdAt": "2020-01-20T00:31:05Z", "commit": {"oid": "e09476aef8795db4fbfc42f7541a9ab3cf848c50"}, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e43a1e9885d9839143bb35337e382788d35d5cb4", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/e43a1e9885d9839143bb35337e382788d35d5cb4", "committedDate": "2020-01-20T23:53:01Z", "message": "Address review comments"}, "afterCommit": {"oid": "96995745f539b86352df9199e33670e26442efb4", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/96995745f539b86352df9199e33670e26442efb4", "committedDate": "2020-02-12T21:28:48Z", "message": "Support Text Search"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU3ODA5Mjk4", "url": "https://github.com/apache/pinot/pull/4993#pullrequestreview-357809298", "createdAt": "2020-02-12T21:43:26Z", "commit": {"oid": "96995745f539b86352df9199e33670e26442efb4"}, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMlQyMTo0MzoyNlrOFo_n4Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMlQyMzo0Nzo1OVrOFpClIg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODUyOTc2MQ==", "bodyText": "Why do we need a map here?  There is one MutableSegmentImpl per segment, so it looks like we just need one instance of RealtimeLuceneReadersForRealtimeSegment. Or, is this a reader per column (in which case the key should be column name instead of segment name)", "url": "https://github.com/apache/pinot/pull/4993#discussion_r378529761", "createdAt": "2020-02-12T21:43:26Z", "author": {"login": "mcvsubbu"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/indexsegment/mutable/MutableSegmentImpl.java", "diffHunk": "@@ -118,6 +124,8 @@\n   private volatile long _lastIndexedTimeMs = Long.MIN_VALUE;\n   private volatile long _latestIngestionTimeMs = Long.MIN_VALUE;\n \n+  private final Map<String, RealtimeLuceneReadersForRealtimeSegment> _segmentToRealtimeLuceneReadersMap;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "96995745f539b86352df9199e33670e26442efb4"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODU3NTg5Nw==", "bodyText": "One too many {}. Also, e should be the last argument", "url": "https://github.com/apache/pinot/pull/4993#discussion_r378575897", "createdAt": "2020-02-12T23:40:34Z", "author": {"login": "mcvsubbu"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/realtime/impl/invertedindex/RealtimeLuceneIndexReaderRefreshThread.java", "diffHunk": "@@ -0,0 +1,105 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.realtime.impl.invertedindex;\n+\n+import java.util.List;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import org.apache.lucene.search.SearcherManager;\n+import org.apache.pinot.core.segment.creator.impl.SegmentColumnarIndexCreator;\n+import org.apache.pinot.core.realtime.impl.invertedindex.RealtimeLuceneIndexRefreshState.RealtimeLuceneReadersForRealtimeSegment;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Background thread to refresh the realtime lucene index readers for supporting\n+ * near-realtime text search. The task maintains a queue of realtime segments.\n+ * This queue is global (across all realtime segments of all realtime/hybrid tables).\n+ *\n+ * Each element in the queue is of type {@link RealtimeLuceneReadersForRealtimeSegment}.\n+ * It encapsulate a lock and all the realtime lucene readers for the particular realtime segment.\n+ * Since text index is also create on a per column basis, there will be as many realtime lucene\n+ * readers as the number of columns with text search enabled.\n+ *\n+ * Between each successive execution of the task, there is a fixed delay (regardless of how long\n+ * each execution took). When the task wakes up, it pick the RealtimeLuceneReadersForRealtimeSegment\n+ * from the head of queue, refresh it's readers and adds this at the tail of queue.\n+ */\n+public class RealtimeLuceneIndexReaderRefreshThread implements Runnable {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(SegmentColumnarIndexCreator.class);\n+  public static final int INITIAL_DELAY_MS_DEFAULT = 1000;\n+  // TODO: make this configurable and choose a higher default value\n+  public static final int DELAY_BETWEEN_SUCCESSIVE_EXECUTION_MS_DEFAULT = 10;\n+\n+  private final ConcurrentLinkedQueue<RealtimeLuceneReadersForRealtimeSegment> _luceneRealtimeReaders;\n+\n+  public RealtimeLuceneIndexReaderRefreshThread(ConcurrentLinkedQueue<RealtimeLuceneReadersForRealtimeSegment> luceneRealtimeReaders) {\n+    _luceneRealtimeReaders = luceneRealtimeReaders;\n+  }\n+\n+  @Override\n+  public void run() {\n+    RealtimeLuceneReadersForRealtimeSegment realtimeReadersForSegment = _luceneRealtimeReaders.poll();\n+    if (realtimeReadersForSegment != null) {\n+      String segmentName = realtimeReadersForSegment.getSegmentName();\n+      if (!realtimeReadersForSegment.isSegmentAboutToBeDestroyed()) {\n+        // If segmentAboutToBeDestroyed is false, it implies MutableSegmentImpl\n+        // code hasn't yet started to destroy the segment. So the refresh task\n+        // can proceed for now.\n+        boolean refreshed = true;\n+        if (realtimeReadersForSegment.getLock().tryLock()) {\n+          // got the lock\n+          try {\n+            List<RealtimeLuceneTextIndexReader> realtimeLuceneReaders = realtimeReadersForSegment.getRealtimeLuceneReaders();\n+            for (RealtimeLuceneTextIndexReader realtimeReader : realtimeLuceneReaders) {\n+              if (realtimeReadersForSegment.isSegmentAboutToBeDestroyed()) {\n+                // Check this here to know if MutableSegmentImpl wants to start destroying the\n+                // realtime segment but is unable to proceed since we hold the lock. So we will stop\n+                // in the middle, abort the refresh and let MutableSegmentImpl proceed with destroying\n+                // the segment.\n+                refreshed = false;\n+                break;\n+              }\n+              SearcherManager searcherManager = realtimeReader.getSearcherManager();\n+              try {\n+                searcherManager.maybeRefresh();\n+              } catch (Exception e) {\n+                LOGGER.warn(\"Caught exception {} while refreshing realtime lucene reader for segment: {}\", e, segmentName);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "96995745f539b86352df9199e33670e26442efb4"}, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODU3NjU1Ng==", "bodyText": "please change the comment, we dont have TEXT columns anymore.", "url": "https://github.com/apache/pinot/pull/4993#discussion_r378576556", "createdAt": "2020-02-12T23:42:46Z", "author": {"login": "mcvsubbu"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/realtime/impl/invertedindex/RealtimeLuceneIndexRefreshState.java", "diffHunk": "@@ -0,0 +1,98 @@\n+package org.apache.pinot.core.realtime.impl.invertedindex;\n+\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.Lock;\n+import java.util.concurrent.locks.ReentrantLock;\n+\n+\n+/**\n+ * This class manages the realtime lucene index readers. Creates a global\n+ * queue with all the realtime segment lucene index readers across\n+ * all tables and manages their refresh using {@link RealtimeLuceneIndexReaderRefreshThread}\n+ */\n+public class RealtimeLuceneIndexRefreshState {\n+  private static RealtimeLuceneIndexRefreshState _singletonInstance;\n+  private static ScheduledExecutorService _scheduledExecutorService;\n+  private static ConcurrentLinkedQueue<RealtimeLuceneReadersForRealtimeSegment> _luceneRealtimeReaders;\n+\n+  private RealtimeLuceneIndexRefreshState() {\n+    // This constructor is called by getInstance() exactly once. Since\n+    // getInstance() is invoked by MutableSegmentImpl only if it encounters\n+    // a TEXT index column, we ensure that background refresh thread is not created\n+    // if there is no column with TEXT index enabled\n+    _scheduledExecutorService = Executors.newSingleThreadScheduledExecutor();\n+    // TODO: eventually we should explore partitioning this queue on per table basis\n+    _luceneRealtimeReaders = new ConcurrentLinkedQueue<>();\n+    _scheduledExecutorService.scheduleWithFixedDelay(new RealtimeLuceneIndexReaderRefreshThread(_luceneRealtimeReaders),\n+        RealtimeLuceneIndexReaderRefreshThread.INITIAL_DELAY_MS_DEFAULT, RealtimeLuceneIndexReaderRefreshThread.DELAY_BETWEEN_SUCCESSIVE_EXECUTION_MS_DEFAULT, TimeUnit.MILLISECONDS);\n+  }\n+\n+  public static RealtimeLuceneIndexRefreshState getInstance() {\n+    if (_singletonInstance == null) {\n+      synchronized (RealtimeLuceneIndexRefreshState.class) {\n+        if (_singletonInstance == null) {\n+          _singletonInstance = new RealtimeLuceneIndexRefreshState();\n+        }\n+      }\n+    }\n+    return _singletonInstance;\n+  }\n+\n+  public void addRealtimeReadersToQueue(RealtimeLuceneReadersForRealtimeSegment readersForRealtimeSegment) {\n+    _luceneRealtimeReaders.offer(readersForRealtimeSegment);\n+  }\n+\n+  /**\n+   * Since the text index is maintained per TEXT column (similar to other Pinot indexes),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "96995745f539b86352df9199e33670e26442efb4"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODU3NzE1OQ==", "bodyText": "please include name of the column in the exception. I suggest you log an error with the message, and not include the word \"Error\" in the exception string. Did you mean + e.getMessage() instead of +e?", "url": "https://github.com/apache/pinot/pull/4993#discussion_r378577159", "createdAt": "2020-02-12T23:44:43Z", "author": {"login": "mcvsubbu"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/segment/creator/impl/inv/text/LuceneTextIndexCreator.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.segment.creator.impl.inv.text;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import org.apache.lucene.analysis.standard.StandardAnalyzer;\n+import org.apache.lucene.document.Document;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.StoredField;\n+import org.apache.lucene.document.TextField;\n+import org.apache.lucene.index.IndexWriter;\n+import org.apache.lucene.index.IndexWriterConfig;\n+import org.apache.lucene.store.Directory;\n+import org.apache.lucene.store.FSDirectory;\n+import org.apache.pinot.core.segment.creator.InvertedIndexCreator;\n+\n+\n+/**\n+ * This is used to create Lucene based text index.\n+ * Used for both offline from {@link org.apache.pinot.core.segment.creator.impl.SegmentColumnarIndexCreator}\n+ * and realtime from {@link org.apache.pinot.core.realtime.impl.invertedindex.RealtimeLuceneTextIndexReader}\n+ */\n+public class LuceneTextIndexCreator implements InvertedIndexCreator {\n+  // TODO: make buffer size configurable choosing a default value based on the heap usage results in design doc\n+  private static final int LUCENE_INDEX_MAX_BUFFER_SIZE_MB = 500;\n+  public static final String LUCENE_INDEX_DOC_ID_COLUMN_NAME = \"DocID\";\n+  public static final String LUCENE_TEXT_INDEX_FILE_EXTENSION = \".lucene.index\";\n+\n+  private final String _textColumn;\n+  private final Directory _indexDirectory;\n+  private final IndexWriter _indexWriter;\n+\n+  /**\n+   * Called by {@link org.apache.pinot.core.segment.creator.impl.SegmentColumnarIndexCreator}\n+   * when building an offline segment. Similar to how it creates per column\n+   * dictionary, forward and inverted index, a text index is also created\n+   * if text search is enabled on a column.\n+   * @param column column name\n+   * @param segmentIndexDir segment index directory\n+   * @param commit true if the index should be committed (at the end after all documents have\n+   *               been added), false if index should not be committed\n+   * Note on commit:\n+   *               Once {@link org.apache.pinot.core.segment.creator.impl.SegmentColumnarIndexCreator}\n+   *               finishes indexing all documents/rows for the segment, we need to commit and close\n+   *               the Lucene index which will internally persist the index on disk, do the necessary\n+   *               resource cleanup etc. We commit during {@link InvertedIndexCreator#seal()}\n+   *               and close during {@link InvertedIndexCreator#close()}.\n+   *               This lucene index writer is used by both offline and realtime (both during\n+   *               indexing in-memory MutableSegment and later during conversion to offline).\n+   *               Since realtime segment conversion is again going to go through the offline\n+   *               indexing path and will do everything (indexing, commit, close etc), there is\n+   *               no need to commit the index from the realtime side. So when the realtime segment\n+   *               is destroyed (which is after the realtime segment has been committed and converted\n+   *               to offline), we close this lucene index writer to release resources but don't commit.\n+   *               This is the reason to have commit flag part of the constructor.\n+   */\n+  public LuceneTextIndexCreator(String column, File segmentIndexDir, boolean commit) {\n+    _textColumn = column;\n+    try {\n+      File indexFile = new File(segmentIndexDir.getPath() + \"/\" + _textColumn + LUCENE_TEXT_INDEX_FILE_EXTENSION);\n+      _indexDirectory = FSDirectory.open(indexFile.toPath());\n+      StandardAnalyzer standardAnalyzer = new StandardAnalyzer();\n+      IndexWriterConfig indexWriterConfig = new IndexWriterConfig(standardAnalyzer);\n+      indexWriterConfig.setRAMBufferSizeMB(LUCENE_INDEX_MAX_BUFFER_SIZE_MB);\n+      indexWriterConfig.setCommitOnClose(commit);\n+      _indexWriter = new IndexWriter(_indexDirectory, indexWriterConfig);\n+    } catch (Exception e) {\n+      throw new RuntimeException(\"Failed to instantiate Lucene text index creator. Error: \" + e);\n+    }\n+  }\n+\n+  public IndexWriter getIndexWriter() {\n+    return _indexWriter;\n+  }\n+\n+  @Override\n+  public void addDoc(Object document, int docIdCounter) {\n+    Document docToIndex = new Document();\n+    docToIndex.add(new TextField(_textColumn, document.toString(), Field.Store.NO));\n+    docToIndex.add(new StoredField(LUCENE_INDEX_DOC_ID_COLUMN_NAME, docIdCounter));\n+    try {\n+      _indexWriter.addDocument(docToIndex);\n+    } catch (Exception e) {\n+      throw new RuntimeException(\"Failure while adding a new document to index. Error: \" + e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "96995745f539b86352df9199e33670e26442efb4"}, "originalPosition": 101}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODU3NzY5OQ==", "bodyText": "Same comment as above", "url": "https://github.com/apache/pinot/pull/4993#discussion_r378577699", "createdAt": "2020-02-12T23:46:18Z", "author": {"login": "mcvsubbu"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/segment/creator/impl/inv/text/LuceneTextIndexCreator.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.segment.creator.impl.inv.text;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import org.apache.lucene.analysis.standard.StandardAnalyzer;\n+import org.apache.lucene.document.Document;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.StoredField;\n+import org.apache.lucene.document.TextField;\n+import org.apache.lucene.index.IndexWriter;\n+import org.apache.lucene.index.IndexWriterConfig;\n+import org.apache.lucene.store.Directory;\n+import org.apache.lucene.store.FSDirectory;\n+import org.apache.pinot.core.segment.creator.InvertedIndexCreator;\n+\n+\n+/**\n+ * This is used to create Lucene based text index.\n+ * Used for both offline from {@link org.apache.pinot.core.segment.creator.impl.SegmentColumnarIndexCreator}\n+ * and realtime from {@link org.apache.pinot.core.realtime.impl.invertedindex.RealtimeLuceneTextIndexReader}\n+ */\n+public class LuceneTextIndexCreator implements InvertedIndexCreator {\n+  // TODO: make buffer size configurable choosing a default value based on the heap usage results in design doc\n+  private static final int LUCENE_INDEX_MAX_BUFFER_SIZE_MB = 500;\n+  public static final String LUCENE_INDEX_DOC_ID_COLUMN_NAME = \"DocID\";\n+  public static final String LUCENE_TEXT_INDEX_FILE_EXTENSION = \".lucene.index\";\n+\n+  private final String _textColumn;\n+  private final Directory _indexDirectory;\n+  private final IndexWriter _indexWriter;\n+\n+  /**\n+   * Called by {@link org.apache.pinot.core.segment.creator.impl.SegmentColumnarIndexCreator}\n+   * when building an offline segment. Similar to how it creates per column\n+   * dictionary, forward and inverted index, a text index is also created\n+   * if text search is enabled on a column.\n+   * @param column column name\n+   * @param segmentIndexDir segment index directory\n+   * @param commit true if the index should be committed (at the end after all documents have\n+   *               been added), false if index should not be committed\n+   * Note on commit:\n+   *               Once {@link org.apache.pinot.core.segment.creator.impl.SegmentColumnarIndexCreator}\n+   *               finishes indexing all documents/rows for the segment, we need to commit and close\n+   *               the Lucene index which will internally persist the index on disk, do the necessary\n+   *               resource cleanup etc. We commit during {@link InvertedIndexCreator#seal()}\n+   *               and close during {@link InvertedIndexCreator#close()}.\n+   *               This lucene index writer is used by both offline and realtime (both during\n+   *               indexing in-memory MutableSegment and later during conversion to offline).\n+   *               Since realtime segment conversion is again going to go through the offline\n+   *               indexing path and will do everything (indexing, commit, close etc), there is\n+   *               no need to commit the index from the realtime side. So when the realtime segment\n+   *               is destroyed (which is after the realtime segment has been committed and converted\n+   *               to offline), we close this lucene index writer to release resources but don't commit.\n+   *               This is the reason to have commit flag part of the constructor.\n+   */\n+  public LuceneTextIndexCreator(String column, File segmentIndexDir, boolean commit) {\n+    _textColumn = column;\n+    try {\n+      File indexFile = new File(segmentIndexDir.getPath() + \"/\" + _textColumn + LUCENE_TEXT_INDEX_FILE_EXTENSION);\n+      _indexDirectory = FSDirectory.open(indexFile.toPath());\n+      StandardAnalyzer standardAnalyzer = new StandardAnalyzer();\n+      IndexWriterConfig indexWriterConfig = new IndexWriterConfig(standardAnalyzer);\n+      indexWriterConfig.setRAMBufferSizeMB(LUCENE_INDEX_MAX_BUFFER_SIZE_MB);\n+      indexWriterConfig.setCommitOnClose(commit);\n+      _indexWriter = new IndexWriter(_indexDirectory, indexWriterConfig);\n+    } catch (Exception e) {\n+      throw new RuntimeException(\"Failed to instantiate Lucene text index creator. Error: \" + e);\n+    }\n+  }\n+\n+  public IndexWriter getIndexWriter() {\n+    return _indexWriter;\n+  }\n+\n+  @Override\n+  public void addDoc(Object document, int docIdCounter) {\n+    Document docToIndex = new Document();\n+    docToIndex.add(new TextField(_textColumn, document.toString(), Field.Store.NO));\n+    docToIndex.add(new StoredField(LUCENE_INDEX_DOC_ID_COLUMN_NAME, docIdCounter));\n+    try {\n+      _indexWriter.addDocument(docToIndex);\n+    } catch (Exception e) {\n+      throw new RuntimeException(\"Failure while adding a new document to index. Error: \" + e);\n+    }\n+  }\n+\n+  @Override\n+  public void seal() {\n+    try {\n+      // Do this one time operation of combining the multiple lucene index files (if any)\n+      // into a single index file. Based on flush threshold and size of data, Lucene\n+      // can create index in multiple files and then uses a merge criteria to decide\n+      // if a single compound file (similar to Pinot's V3 format) should be created\n+      // holding all the index data.\n+      // Depending on the size of data, flush threshold (during index building) and the\n+      // outcome of Lucene's internal merge criteria, the final lucene index can have\n+      // multiple files. Since these files will be kept opened during segment load/mmap,\n+      // we want to minimize the number of situations that can lead to \"too many open files\"\n+      // error.\n+      // Of course, there is a worst case where there could be a table with 20k segments\n+      // and each segment has 3 TEXT columns, thus 3 Lucene indexes. So even with a compound\n+      // file, we are likely to exhaust the number of open file descriptors. In future, we\n+      // should probably explore a global lucene index (a single index for all TEXT columns)\n+      // as opposed to per column index.\n+      _indexWriter.forceMerge(1);\n+    } catch (Exception e) {\n+      throw new RuntimeException(\"Lucene index writer failed to commit. Error: \" + e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "96995745f539b86352df9199e33670e26442efb4"}, "originalPosition": 125}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODU3Nzc2Mg==", "bodyText": "Same comment as above", "url": "https://github.com/apache/pinot/pull/4993#discussion_r378577762", "createdAt": "2020-02-12T23:46:30Z", "author": {"login": "mcvsubbu"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/segment/creator/impl/inv/text/LuceneTextIndexCreator.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.segment.creator.impl.inv.text;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import org.apache.lucene.analysis.standard.StandardAnalyzer;\n+import org.apache.lucene.document.Document;\n+import org.apache.lucene.document.Field;\n+import org.apache.lucene.document.StoredField;\n+import org.apache.lucene.document.TextField;\n+import org.apache.lucene.index.IndexWriter;\n+import org.apache.lucene.index.IndexWriterConfig;\n+import org.apache.lucene.store.Directory;\n+import org.apache.lucene.store.FSDirectory;\n+import org.apache.pinot.core.segment.creator.InvertedIndexCreator;\n+\n+\n+/**\n+ * This is used to create Lucene based text index.\n+ * Used for both offline from {@link org.apache.pinot.core.segment.creator.impl.SegmentColumnarIndexCreator}\n+ * and realtime from {@link org.apache.pinot.core.realtime.impl.invertedindex.RealtimeLuceneTextIndexReader}\n+ */\n+public class LuceneTextIndexCreator implements InvertedIndexCreator {\n+  // TODO: make buffer size configurable choosing a default value based on the heap usage results in design doc\n+  private static final int LUCENE_INDEX_MAX_BUFFER_SIZE_MB = 500;\n+  public static final String LUCENE_INDEX_DOC_ID_COLUMN_NAME = \"DocID\";\n+  public static final String LUCENE_TEXT_INDEX_FILE_EXTENSION = \".lucene.index\";\n+\n+  private final String _textColumn;\n+  private final Directory _indexDirectory;\n+  private final IndexWriter _indexWriter;\n+\n+  /**\n+   * Called by {@link org.apache.pinot.core.segment.creator.impl.SegmentColumnarIndexCreator}\n+   * when building an offline segment. Similar to how it creates per column\n+   * dictionary, forward and inverted index, a text index is also created\n+   * if text search is enabled on a column.\n+   * @param column column name\n+   * @param segmentIndexDir segment index directory\n+   * @param commit true if the index should be committed (at the end after all documents have\n+   *               been added), false if index should not be committed\n+   * Note on commit:\n+   *               Once {@link org.apache.pinot.core.segment.creator.impl.SegmentColumnarIndexCreator}\n+   *               finishes indexing all documents/rows for the segment, we need to commit and close\n+   *               the Lucene index which will internally persist the index on disk, do the necessary\n+   *               resource cleanup etc. We commit during {@link InvertedIndexCreator#seal()}\n+   *               and close during {@link InvertedIndexCreator#close()}.\n+   *               This lucene index writer is used by both offline and realtime (both during\n+   *               indexing in-memory MutableSegment and later during conversion to offline).\n+   *               Since realtime segment conversion is again going to go through the offline\n+   *               indexing path and will do everything (indexing, commit, close etc), there is\n+   *               no need to commit the index from the realtime side. So when the realtime segment\n+   *               is destroyed (which is after the realtime segment has been committed and converted\n+   *               to offline), we close this lucene index writer to release resources but don't commit.\n+   *               This is the reason to have commit flag part of the constructor.\n+   */\n+  public LuceneTextIndexCreator(String column, File segmentIndexDir, boolean commit) {\n+    _textColumn = column;\n+    try {\n+      File indexFile = new File(segmentIndexDir.getPath() + \"/\" + _textColumn + LUCENE_TEXT_INDEX_FILE_EXTENSION);\n+      _indexDirectory = FSDirectory.open(indexFile.toPath());\n+      StandardAnalyzer standardAnalyzer = new StandardAnalyzer();\n+      IndexWriterConfig indexWriterConfig = new IndexWriterConfig(standardAnalyzer);\n+      indexWriterConfig.setRAMBufferSizeMB(LUCENE_INDEX_MAX_BUFFER_SIZE_MB);\n+      indexWriterConfig.setCommitOnClose(commit);\n+      _indexWriter = new IndexWriter(_indexDirectory, indexWriterConfig);\n+    } catch (Exception e) {\n+      throw new RuntimeException(\"Failed to instantiate Lucene text index creator. Error: \" + e);\n+    }\n+  }\n+\n+  public IndexWriter getIndexWriter() {\n+    return _indexWriter;\n+  }\n+\n+  @Override\n+  public void addDoc(Object document, int docIdCounter) {\n+    Document docToIndex = new Document();\n+    docToIndex.add(new TextField(_textColumn, document.toString(), Field.Store.NO));\n+    docToIndex.add(new StoredField(LUCENE_INDEX_DOC_ID_COLUMN_NAME, docIdCounter));\n+    try {\n+      _indexWriter.addDocument(docToIndex);\n+    } catch (Exception e) {\n+      throw new RuntimeException(\"Failure while adding a new document to index. Error: \" + e);\n+    }\n+  }\n+\n+  @Override\n+  public void seal() {\n+    try {\n+      // Do this one time operation of combining the multiple lucene index files (if any)\n+      // into a single index file. Based on flush threshold and size of data, Lucene\n+      // can create index in multiple files and then uses a merge criteria to decide\n+      // if a single compound file (similar to Pinot's V3 format) should be created\n+      // holding all the index data.\n+      // Depending on the size of data, flush threshold (during index building) and the\n+      // outcome of Lucene's internal merge criteria, the final lucene index can have\n+      // multiple files. Since these files will be kept opened during segment load/mmap,\n+      // we want to minimize the number of situations that can lead to \"too many open files\"\n+      // error.\n+      // Of course, there is a worst case where there could be a table with 20k segments\n+      // and each segment has 3 TEXT columns, thus 3 Lucene indexes. So even with a compound\n+      // file, we are likely to exhaust the number of open file descriptors. In future, we\n+      // should probably explore a global lucene index (a single index for all TEXT columns)\n+      // as opposed to per column index.\n+      _indexWriter.forceMerge(1);\n+    } catch (Exception e) {\n+      throw new RuntimeException(\"Lucene index writer failed to commit. Error: \" + e);\n+    }\n+  }\n+\n+  @Override\n+  public void close() throws IOException {\n+    try {\n+      // based on the commit flag set in IndexWriterConfig, this will decide to commit or not\n+      _indexWriter.close();\n+      _indexDirectory.close();\n+    } catch (Exception e) {\n+      throw new RuntimeException(\"Lucene index writer failed to close. Error: \" + e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "96995745f539b86352df9199e33670e26442efb4"}, "originalPosition": 136}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODU3ODIxMA==", "bodyText": "Please remove the word \"Error\". You can log an error log. Also, e.getMessage()?", "url": "https://github.com/apache/pinot/pull/4993#discussion_r378578210", "createdAt": "2020-02-12T23:47:59Z", "author": {"login": "mcvsubbu"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/segment/index/readers/text/LuceneIndexSearcherReferenceManager.java", "diffHunk": "@@ -0,0 +1,57 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.segment.index.readers.text;\n+\n+import org.apache.lucene.search.IndexSearcher;\n+import org.apache.lucene.search.SearcherManager;\n+\n+\n+/**\n+ * A reference manager to help release the Lucene text index reader/searcher.\n+ * This is used only in the context of realtime search with Lucene. To avoid\n+ * introducing a release() API on the index reader interface, this wrapper is\n+ * created over SearcherManager and returned to the caller. The caller can\n+ * then appropriately call the release once the searcher associated with\n+ * SearcherManager is no longer needed.\n+ */\n+public class LuceneIndexSearcherReferenceManager {\n+\n+  private final SearcherManager _searcherManager;\n+  private final IndexSearcher _indexSearcher;\n+\n+  public LuceneIndexSearcherReferenceManager(SearcherManager searcherManager, IndexSearcher indexSearcher) {\n+    _searcherManager = searcherManager;\n+    _indexSearcher = indexSearcher;\n+  }\n+\n+  public void release() {\n+    try {\n+      // Only used for realtime search with Lucene\n+      if (_searcherManager != null) {\n+        _searcherManager.release(_indexSearcher);\n+      }\n+    } catch (Exception e) {\n+      throw new RuntimeException(\"Error: failed while releasing a previously acquired searcher. \" + e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "96995745f539b86352df9199e33670e26442efb4"}, "originalPosition": 50}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU4NDYwNTY0", "url": "https://github.com/apache/pinot/pull/4993#pullrequestreview-358460564", "createdAt": "2020-02-13T18:42:43Z", "commit": {"oid": "d6a4fe43b15b4bf5d7ca4e67330d4a47d35650b0"}, "state": "APPROVED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xM1QxODo0Mjo0M1rOFpfP7Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xM1QxODo0ODoxMFrOFpfbVQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTA0NzkxNw==", "bodyText": "is this formatted?", "url": "https://github.com/apache/pinot/pull/4993#discussion_r379047917", "createdAt": "2020-02-13T18:42:43Z", "author": {"login": "kishoreg"}, "path": "pinot-common/src/main/java/org/apache/pinot/pql/parsers/Pql2AstListener.java", "diffHunk": "@@ -429,4 +430,14 @@ public void enterOptions(PQL2Parser.OptionsContext ctx) {\n   public void exitOptions(PQL2Parser.OptionsContext ctx) {\n     popNode();\n   }\n+\n+  @Override\n+  public void enterTextMatchPredicate(@NotNull PQL2Parser.TextMatchPredicateContext ctx) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d6a4fe43b15b4bf5d7ca4e67330d4a47d35650b0"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTA0ODE0NA==", "bodyText": "why is this needed?", "url": "https://github.com/apache/pinot/pull/4993#discussion_r379048144", "createdAt": "2020-02-13T18:43:11Z", "author": {"login": "kishoreg"}, "path": "pinot-common/src/main/java/org/apache/pinot/pql/parsers/Pql2Compiler.java", "diffHunk": "@@ -72,7 +72,8 @@\n       Boolean.valueOf(System.getProperty(\"pinot.query.converter.fail_on_error\", \"false\"));\n   public static String ENABLE_DISTINCT_KEY = \"pinot.distinct.enabled\";\n   public static boolean ENABLE_DISTINCT = Boolean.valueOf(System.getProperty(ENABLE_DISTINCT_KEY, \"true\"));\n-\n+  public static String ENABLE_TEXT_MATCH_KEY = \"pinot.textmatch.enabled\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d6a4fe43b15b4bf5d7ca4e67330d4a47d35650b0"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTA0ODk1Mw==", "bodyText": "this is an unnecessary check. when we are adding the code why would one have to set an additional flag to use this feature?", "url": "https://github.com/apache/pinot/pull/4993#discussion_r379048953", "createdAt": "2020-02-13T18:44:40Z", "author": {"login": "kishoreg"}, "path": "pinot-common/src/main/java/org/apache/pinot/pql/parsers/pql2/ast/TextMatchPredicateAstNode.java", "diffHunk": "@@ -0,0 +1,96 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.pql.parsers.pql2.ast;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import org.apache.pinot.common.request.Expression;\n+import org.apache.pinot.common.request.FilterOperator;\n+import org.apache.pinot.common.request.Function;\n+import org.apache.pinot.common.utils.StringUtil;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.HavingQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.pql.parsers.Pql2CompilationException;\n+import org.apache.pinot.pql.parsers.Pql2Compiler;\n+\n+\n+public class TextMatchPredicateAstNode extends PredicateAstNode {\n+\n+  private static final String SEPERATOR = \"\\t\\t\";\n+\n+  @Override\n+  public void addChild(AstNode childNode) {\n+    if (!Pql2Compiler.ENABLE_TEXT_MATCH) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d6a4fe43b15b4bf5d7ca4e67330d4a47d35650b0"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTA0OTkzNw==", "bodyText": "thanks", "url": "https://github.com/apache/pinot/pull/4993#discussion_r379049937", "createdAt": "2020-02-13T18:46:31Z", "author": {"login": "kishoreg"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/operator/filter/TextMatchFilterOperator.java", "diffHunk": "@@ -0,0 +1,67 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.operator.filter;\n+\n+import com.google.common.base.Preconditions;\n+import org.apache.pinot.core.common.DataSource;\n+import org.apache.pinot.core.common.Predicate;\n+import org.apache.pinot.core.operator.blocks.FilterBlock;\n+import org.apache.pinot.core.operator.docidsets.LuceneIndexDocIdSet;\n+import org.apache.pinot.core.operator.filter.predicate.PredicateEvaluator;\n+import org.apache.pinot.core.operator.filter.predicate.TextMatchPredicateEvaluatorFactory;\n+import org.apache.pinot.core.segment.index.readers.InvertedIndexReader;\n+import org.apache.pinot.core.segment.index.readers.text.LuceneTextIndexReader;\n+\n+\n+/**\n+ * Filter operator for supporting the execution of text search\n+ * queries: WHERE TEXT_MATCH(column_name, query_string....)\n+ */\n+public class TextMatchFilterOperator extends BaseFilterOperator {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc0NDkyNg=="}, "originalCommit": {"oid": "e6a0188b729974efca4077973684ae7f0f8e8652"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTA1MDgzNw==", "bodyText": "please fix this. what is the likelihood of this exception?", "url": "https://github.com/apache/pinot/pull/4993#discussion_r379050837", "createdAt": "2020-02-13T18:48:10Z", "author": {"login": "kishoreg"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/realtime/impl/invertedindex/RealtimeLuceneIndexReaderRefreshThread.java", "diffHunk": "@@ -0,0 +1,105 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.realtime.impl.invertedindex;\n+\n+import java.util.List;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import org.apache.lucene.search.SearcherManager;\n+import org.apache.pinot.core.segment.creator.impl.SegmentColumnarIndexCreator;\n+import org.apache.pinot.core.realtime.impl.invertedindex.RealtimeLuceneIndexRefreshState.RealtimeLuceneReadersForRealtimeSegment;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Background thread to refresh the realtime lucene index readers for supporting\n+ * near-realtime text search. The task maintains a queue of realtime segments.\n+ * This queue is global (across all realtime segments of all realtime/hybrid tables).\n+ *\n+ * Each element in the queue is of type {@link RealtimeLuceneReadersForRealtimeSegment}.\n+ * It encapsulate a lock and all the realtime lucene readers for the particular realtime segment.\n+ * Since text index is also create on a per column basis, there will be as many realtime lucene\n+ * readers as the number of columns with text search enabled.\n+ *\n+ * Between each successive execution of the task, there is a fixed delay (regardless of how long\n+ * each execution took). When the task wakes up, it pick the RealtimeLuceneReadersForRealtimeSegment\n+ * from the head of queue, refresh it's readers and adds this at the tail of queue.\n+ */\n+public class RealtimeLuceneIndexReaderRefreshThread implements Runnable {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(SegmentColumnarIndexCreator.class);\n+  public static final int INITIAL_DELAY_MS_DEFAULT = 1000;\n+  // TODO: make this configurable and choose a higher default value\n+  public static final int DELAY_BETWEEN_SUCCESSIVE_EXECUTION_MS_DEFAULT = 10;\n+\n+  private final ConcurrentLinkedQueue<RealtimeLuceneReadersForRealtimeSegment> _luceneRealtimeReaders;\n+\n+  public RealtimeLuceneIndexReaderRefreshThread(ConcurrentLinkedQueue<RealtimeLuceneReadersForRealtimeSegment> luceneRealtimeReaders) {\n+    _luceneRealtimeReaders = luceneRealtimeReaders;\n+  }\n+\n+  @Override\n+  public void run() {\n+    RealtimeLuceneReadersForRealtimeSegment realtimeReadersForSegment = _luceneRealtimeReaders.poll();\n+    if (realtimeReadersForSegment != null) {\n+      String segmentName = realtimeReadersForSegment.getSegmentName();\n+      if (!realtimeReadersForSegment.isSegmentAboutToBeDestroyed()) {\n+        // If segmentAboutToBeDestroyed is false, it implies MutableSegmentImpl\n+        // code hasn't yet started to destroy the segment. So the refresh task\n+        // can proceed for now.\n+        boolean refreshed = true;\n+        if (realtimeReadersForSegment.getLock().tryLock()) {\n+          // got the lock\n+          try {\n+            List<RealtimeLuceneTextIndexReader> realtimeLuceneReaders = realtimeReadersForSegment.getRealtimeLuceneReaders();\n+            for (RealtimeLuceneTextIndexReader realtimeReader : realtimeLuceneReaders) {\n+              if (realtimeReadersForSegment.isSegmentAboutToBeDestroyed()) {\n+                // Check this here to know if MutableSegmentImpl wants to start destroying the\n+                // realtime segment but is unable to proceed since we hold the lock. So we will stop\n+                // in the middle, abort the refresh and let MutableSegmentImpl proceed with destroying\n+                // the segment.\n+                refreshed = false;\n+                break;\n+              }\n+              SearcherManager searcherManager = realtimeReader.getSearcherManager();\n+              try {\n+                searcherManager.maybeRefresh();\n+              } catch (Exception e) {\n+                LOGGER.warn(\"Caught exception {} while refreshing realtime lucene reader for segment: {}\", e, segmentName);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODU3NTg5Nw=="}, "originalCommit": {"oid": "96995745f539b86352df9199e33670e26442efb4"}, "originalPosition": 83}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU4NTgxMzYz", "url": "https://github.com/apache/pinot/pull/4993#pullrequestreview-358581363", "createdAt": "2020-02-13T21:57:49Z", "commit": {"oid": "d6a4fe43b15b4bf5d7ca4e67330d4a47d35650b0"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xM1QyMTo1Nzo0OVrOFpk_hw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xM1QyMTo1OTozN1rOFplDJQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTE0MjAyMw==", "bodyText": "Why do you need to keep reference count for inverted index result? The bitmap is new created right?", "url": "https://github.com/apache/pinot/pull/4993#discussion_r379142023", "createdAt": "2020-02-13T21:57:49Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/segment/index/readers/text/LuceneTextIndexReader.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.segment.index.readers.text;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import org.apache.lucene.analysis.standard.StandardAnalyzer;\n+import org.apache.lucene.index.DirectoryReader;\n+import org.apache.lucene.index.IndexReader;\n+import org.apache.lucene.queryparser.classic.QueryParser;\n+import org.apache.lucene.search.Collector;\n+import org.apache.lucene.search.IndexSearcher;\n+import org.apache.lucene.search.Query;\n+import org.apache.lucene.store.Directory;\n+import org.apache.lucene.store.FSDirectory;\n+import org.apache.pinot.core.common.Predicate;\n+import org.apache.pinot.core.common.predicate.TextMatchPredicate;\n+import org.apache.pinot.core.indexsegment.generator.SegmentVersion;\n+import org.apache.pinot.core.segment.creator.impl.inv.text.LuceneTextIndexCreator;\n+import org.apache.pinot.core.segment.index.readers.InvertedIndexReader;\n+import org.roaringbitmap.buffer.MutableRoaringBitmap;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * This is used to read/search the Lucene text index.\n+ * When {@link org.apache.pinot.core.indexsegment.immutable.ImmutableSegmentLoader} loads the segment,\n+ * it also loads (mmaps) the Lucene text index if the segment has TEXT column(s).\n+ */\n+public class LuceneTextIndexReader implements InvertedIndexReader<LuceneTextIndexReader.LuceneSearchResult> {\n+  private static final org.slf4j.Logger LOGGER = LoggerFactory.getLogger(LuceneTextIndexReader.class);\n+\n+  private final IndexReader _indexReader;\n+  private final Directory _indexDirectory;\n+  private final IndexSearcher _indexSearcher;\n+  private final QueryParser _queryParser;\n+  private final String _column;\n+\n+  /**\n+   * As part of loading the segment in ImmutableSegmentLoader,\n+   * we load the text index (per column if it exists) and store\n+   * the reference in {@link org.apache.pinot.core.segment.index.column.PhysicalColumnIndexContainer}\n+   * similar to how it is done for other types of indexes.\n+   * @param column column name\n+   * @param segmentIndexDir segment index directory\n+   */\n+  public LuceneTextIndexReader(String column, File segmentIndexDir) {\n+    _column = column;\n+    try {\n+      File indexFile = new File(segmentIndexDir.getPath() + \"/\" + SegmentVersion.v3.name() + \"/\" + column + LuceneTextIndexCreator.LUCENE_TEXT_INDEX_FILE_EXTENSION);\n+      _indexDirectory = FSDirectory.open(indexFile.toPath());\n+      _indexReader = DirectoryReader.open(_indexDirectory);\n+      _indexSearcher = new IndexSearcher(_indexReader);\n+      // Disable Lucene query result cache. While it helps a lot with performance for\n+      // repeated queries, on the downside it cause heap issues.\n+      _indexSearcher.setQueryCache(null);\n+    } catch (Exception e) {\n+      LOGGER.error(\"Failed to instantiate Lucene text index reader for column {}, exception {}\", column, e.getMessage());\n+      throw new RuntimeException(e);\n+    }\n+    StandardAnalyzer analyzer = new StandardAnalyzer();\n+    _queryParser = new QueryParser(column, analyzer);\n+  }\n+\n+  @Override\n+  public LuceneSearchResult getDocIds(int dictId) {\n+    // This should not be called from anywhere. If it happens, there is a bug in the current implementation\n+    // and that's why we throw illegal state exception\n+    throw new IllegalStateException(\"Using dictionary ID is not supported on Lucene inverted index\");\n+  }\n+\n+  /**\n+   * Called during filter operator execution\n+   * by {@link org.apache.pinot.core.operator.filter.TextMatchFilterOperator}\n+   * @param predicate text search predicate\n+   * @return search results\n+   */\n+  @Override\n+  public LuceneSearchResult getDocIds(Predicate predicate) {\n+    String searchQuery = ((TextMatchPredicate)predicate).getSearchQuery();\n+    MutableRoaringBitmap docIDs = new MutableRoaringBitmap();\n+    Collector docIDCollector = new LuceneDocIdCollector(docIDs);\n+    try {\n+      Query query = _queryParser.parse(searchQuery);\n+      _indexSearcher.search(query, docIDCollector);\n+      return new LuceneSearchResult(docIDs, new LuceneIndexSearcherReferenceManager(null, _indexSearcher));\n+    } catch (Exception e) {\n+      LOGGER.error(\"Failed while searching the text index for column {}, search query {}, exception {}\",\n+          _column, searchQuery, e.getMessage());\n+      throw new RuntimeException(e);\n+    }\n+  }\n+\n+  /**\n+   * When we destroy the loaded ImmutableSegment, all the indexes\n+   * (for each column) are destroyed and as part of that\n+   * we release the text index\n+   * @throws IOException\n+   */\n+  @Override\n+  public void close() throws IOException {\n+    _indexReader.close();\n+    _indexDirectory.close();\n+  }\n+\n+  public static class LuceneSearchResult {\n+    final MutableRoaringBitmap luceneDocIDs;\n+    final LuceneIndexSearcherReferenceManager referenceManager;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d6a4fe43b15b4bf5d7ca4e67330d4a47d35650b0"}, "originalPosition": 124}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTE0Mjk0OQ==", "bodyText": "I would recommend splitting this API into a separate interface, e.g. TextInvertedIndexReader, and make it another entry in the IndexContainer. You won't be able to share any implementation among these 2 APIs.", "url": "https://github.com/apache/pinot/pull/4993#discussion_r379142949", "createdAt": "2020-02-13T21:59:37Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/segment/index/readers/InvertedIndexReader.java", "diffHunk": "@@ -19,12 +19,20 @@\n package org.apache.pinot.core.segment.index.readers;\n \n import java.io.Closeable;\n+import org.apache.pinot.core.common.Predicate;\n \n \n public interface InvertedIndexReader<T> extends Closeable {\n \n   /**\n    * Get the document ids for the given dictionary id.\n+   * @param dictId dictionary ID\n    */\n   T getDocIds(int dictId);\n+\n+  /**\n+   * Get the document ids after evaluating the given predicate\n+   * @param predicate predicate\n+   */\n+  T getDocIds(Predicate predicate);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d6a4fe43b15b4bf5d7ca4e67330d4a47d35650b0"}, "originalPosition": 19}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU4NTgyODMx", "url": "https://github.com/apache/pinot/pull/4993#pullrequestreview-358582831", "createdAt": "2020-02-13T22:00:09Z", "commit": {"oid": "d6a4fe43b15b4bf5d7ca4e67330d4a47d35650b0"}, "state": "COMMENTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xM1QyMjowMDoxMFrOFplEHw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xM1QyMjozNDoyN1rOFpl8yQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTE0MzE5OQ==", "bodyText": "You can choose to do this in another PR, but does it make sense to call the class MutableLuceneReaders?", "url": "https://github.com/apache/pinot/pull/4993#discussion_r379143199", "createdAt": "2020-02-13T22:00:10Z", "author": {"login": "mcvsubbu"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/indexsegment/mutable/MutableSegmentImpl.java", "diffHunk": "@@ -118,6 +124,8 @@\n   private volatile long _lastIndexedTimeMs = Long.MIN_VALUE;\n   private volatile long _latestIngestionTimeMs = Long.MIN_VALUE;\n \n+  private RealtimeLuceneReadersForRealtimeSegment _realtimeLuceneReadersForRealtimeSegment;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d6a4fe43b15b4bf5d7ca4e67330d4a47d35650b0"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTE0NDMxOQ==", "bodyText": "Also, does it make sense to make this a final and create it right here? It is only memory, and we can add it to the refresh thead if we find that are there any columns that have lucene indexing. You can skip some if checks in the code below", "url": "https://github.com/apache/pinot/pull/4993#discussion_r379144319", "createdAt": "2020-02-13T22:02:31Z", "author": {"login": "mcvsubbu"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/indexsegment/mutable/MutableSegmentImpl.java", "diffHunk": "@@ -118,6 +124,8 @@\n   private volatile long _lastIndexedTimeMs = Long.MIN_VALUE;\n   private volatile long _latestIngestionTimeMs = Long.MIN_VALUE;\n \n+  private RealtimeLuceneReadersForRealtimeSegment _realtimeLuceneReadersForRealtimeSegment;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d6a4fe43b15b4bf5d7ca4e67330d4a47d35650b0"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTE0ODAxMg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                while (_stopped) {\n          \n          \n            \n                while (!_stopped) {", "url": "https://github.com/apache/pinot/pull/4993#discussion_r379148012", "createdAt": "2020-02-13T22:11:01Z", "author": {"login": "mcvsubbu"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/realtime/impl/invertedindex/RealtimeLuceneIndexReaderRefreshThread.java", "diffHunk": "@@ -0,0 +1,133 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.realtime.impl.invertedindex;\n+\n+import java.util.List;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.locks.Condition;\n+import java.util.concurrent.locks.Lock;\n+import org.apache.lucene.search.SearcherManager;\n+import org.apache.lucene.store.AlreadyClosedException;\n+import org.apache.pinot.core.segment.creator.impl.SegmentColumnarIndexCreator;\n+import org.apache.pinot.core.realtime.impl.invertedindex.RealtimeLuceneIndexRefreshState.RealtimeLuceneReadersForRealtimeSegment;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Background thread to refresh the realtime lucene index readers for supporting\n+ * near-realtime text search. The task maintains a queue of realtime segments.\n+ * This queue is global (across all realtime segments of all realtime/hybrid tables).\n+ *\n+ * Each element in the queue is of type {@link RealtimeLuceneReadersForRealtimeSegment}.\n+ * It encapsulates a lock and all the realtime lucene readers for the particular realtime segment.\n+ * Since text index is also create on a per column basis, there will be as many realtime lucene\n+ * readers as the number of columns with text search enabled.\n+ *\n+ * Between each successive execution of the task, there is a fixed delay (regardless of how long\n+ * each execution took). When the task wakes up, it pick the RealtimeLuceneReadersForRealtimeSegment\n+ * from the head of queue, refresh it's readers and adds this at the tail of queue.\n+ */\n+public class RealtimeLuceneIndexReaderRefreshThread implements Runnable {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(SegmentColumnarIndexCreator.class);\n+  // TODO: make this configurable and choose a higher default value\n+  public static final int DELAY_BETWEEN_SUCCESSIVE_EXECUTION_MS_DEFAULT = 10;\n+\n+  private final ConcurrentLinkedQueue<RealtimeLuceneReadersForRealtimeSegment> _luceneRealtimeReaders;\n+  private final Lock _mutex;\n+  private final Condition _conditionVariable;\n+\n+  private volatile boolean _stopped = false;\n+\n+  RealtimeLuceneIndexReaderRefreshThread(\n+      ConcurrentLinkedQueue<RealtimeLuceneReadersForRealtimeSegment> luceneRealtimeReaders,\n+      Lock mutex, Condition conditionVariable) {\n+    _luceneRealtimeReaders = luceneRealtimeReaders;\n+    _mutex = mutex;\n+    _conditionVariable = conditionVariable;\n+  }\n+\n+  void setStopped() {\n+    _stopped = true;\n+  }\n+\n+  @Override\n+  public void run() {\n+    while (_stopped) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d6a4fe43b15b4bf5d7ca4e67330d4a47d35650b0"}, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTE0ODMwMA==", "bodyText": "as many times as there are mutable segments", "url": "https://github.com/apache/pinot/pull/4993#discussion_r379148300", "createdAt": "2020-02-13T22:11:44Z", "author": {"login": "mcvsubbu"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/realtime/impl/invertedindex/RealtimeLuceneIndexReaderRefreshThread.java", "diffHunk": "@@ -0,0 +1,133 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.realtime.impl.invertedindex;\n+\n+import java.util.List;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.locks.Condition;\n+import java.util.concurrent.locks.Lock;\n+import org.apache.lucene.search.SearcherManager;\n+import org.apache.lucene.store.AlreadyClosedException;\n+import org.apache.pinot.core.segment.creator.impl.SegmentColumnarIndexCreator;\n+import org.apache.pinot.core.realtime.impl.invertedindex.RealtimeLuceneIndexRefreshState.RealtimeLuceneReadersForRealtimeSegment;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Background thread to refresh the realtime lucene index readers for supporting\n+ * near-realtime text search. The task maintains a queue of realtime segments.\n+ * This queue is global (across all realtime segments of all realtime/hybrid tables).\n+ *\n+ * Each element in the queue is of type {@link RealtimeLuceneReadersForRealtimeSegment}.\n+ * It encapsulates a lock and all the realtime lucene readers for the particular realtime segment.\n+ * Since text index is also create on a per column basis, there will be as many realtime lucene\n+ * readers as the number of columns with text search enabled.\n+ *\n+ * Between each successive execution of the task, there is a fixed delay (regardless of how long\n+ * each execution took). When the task wakes up, it pick the RealtimeLuceneReadersForRealtimeSegment\n+ * from the head of queue, refresh it's readers and adds this at the tail of queue.\n+ */\n+public class RealtimeLuceneIndexReaderRefreshThread implements Runnable {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(SegmentColumnarIndexCreator.class);\n+  // TODO: make this configurable and choose a higher default value\n+  public static final int DELAY_BETWEEN_SUCCESSIVE_EXECUTION_MS_DEFAULT = 10;\n+\n+  private final ConcurrentLinkedQueue<RealtimeLuceneReadersForRealtimeSegment> _luceneRealtimeReaders;\n+  private final Lock _mutex;\n+  private final Condition _conditionVariable;\n+\n+  private volatile boolean _stopped = false;\n+\n+  RealtimeLuceneIndexReaderRefreshThread(\n+      ConcurrentLinkedQueue<RealtimeLuceneReadersForRealtimeSegment> luceneRealtimeReaders,\n+      Lock mutex, Condition conditionVariable) {\n+    _luceneRealtimeReaders = luceneRealtimeReaders;\n+    _mutex = mutex;\n+    _conditionVariable = conditionVariable;\n+  }\n+\n+  void setStopped() {\n+    _stopped = true;\n+  }\n+\n+  @Override\n+  public void run() {\n+    while (_stopped) {\n+      _mutex.lock();\n+      while (_luceneRealtimeReaders.isEmpty()) {\n+        try {\n+          // During instantiation of MutableSegmentImpl, we will signal on this condition variable once", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d6a4fe43b15b4bf5d7ca4e67330d4a47d35650b0"}, "originalPosition": 76}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTE1MDY0MQ==", "bodyText": "we should check for _stopped after exiting from the condition variable and break out", "url": "https://github.com/apache/pinot/pull/4993#discussion_r379150641", "createdAt": "2020-02-13T22:17:12Z", "author": {"login": "mcvsubbu"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/realtime/impl/invertedindex/RealtimeLuceneIndexReaderRefreshThread.java", "diffHunk": "@@ -0,0 +1,133 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.realtime.impl.invertedindex;\n+\n+import java.util.List;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.locks.Condition;\n+import java.util.concurrent.locks.Lock;\n+import org.apache.lucene.search.SearcherManager;\n+import org.apache.lucene.store.AlreadyClosedException;\n+import org.apache.pinot.core.segment.creator.impl.SegmentColumnarIndexCreator;\n+import org.apache.pinot.core.realtime.impl.invertedindex.RealtimeLuceneIndexRefreshState.RealtimeLuceneReadersForRealtimeSegment;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Background thread to refresh the realtime lucene index readers for supporting\n+ * near-realtime text search. The task maintains a queue of realtime segments.\n+ * This queue is global (across all realtime segments of all realtime/hybrid tables).\n+ *\n+ * Each element in the queue is of type {@link RealtimeLuceneReadersForRealtimeSegment}.\n+ * It encapsulates a lock and all the realtime lucene readers for the particular realtime segment.\n+ * Since text index is also create on a per column basis, there will be as many realtime lucene\n+ * readers as the number of columns with text search enabled.\n+ *\n+ * Between each successive execution of the task, there is a fixed delay (regardless of how long\n+ * each execution took). When the task wakes up, it pick the RealtimeLuceneReadersForRealtimeSegment\n+ * from the head of queue, refresh it's readers and adds this at the tail of queue.\n+ */\n+public class RealtimeLuceneIndexReaderRefreshThread implements Runnable {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(SegmentColumnarIndexCreator.class);\n+  // TODO: make this configurable and choose a higher default value\n+  public static final int DELAY_BETWEEN_SUCCESSIVE_EXECUTION_MS_DEFAULT = 10;\n+\n+  private final ConcurrentLinkedQueue<RealtimeLuceneReadersForRealtimeSegment> _luceneRealtimeReaders;\n+  private final Lock _mutex;\n+  private final Condition _conditionVariable;\n+\n+  private volatile boolean _stopped = false;\n+\n+  RealtimeLuceneIndexReaderRefreshThread(\n+      ConcurrentLinkedQueue<RealtimeLuceneReadersForRealtimeSegment> luceneRealtimeReaders,\n+      Lock mutex, Condition conditionVariable) {\n+    _luceneRealtimeReaders = luceneRealtimeReaders;\n+    _mutex = mutex;\n+    _conditionVariable = conditionVariable;\n+  }\n+\n+  void setStopped() {\n+    _stopped = true;\n+  }\n+\n+  @Override\n+  public void run() {\n+    while (_stopped) {\n+      _mutex.lock();\n+      while (_luceneRealtimeReaders.isEmpty()) {\n+        try {\n+          // During instantiation of MutableSegmentImpl, we will signal on this condition variable once\n+          // one or more realtime lucene readers (one per column) belonging to the MutableSegment\n+          // are added to the global queue managed by this thread. The thread that signals will\n+          // grab this mutex and signal on the condition variable.\n+          //\n+          // This refresh thread will be woken up (and grab the mutex automatically as per the\n+          // implementation of await) and check if the queue is non-empty. It will then proceed to\n+          // poll the queue and refresh the realtime index readers for the polled segment.\n+          //\n+          // The mutex and condition-variable semantics take care of the scenario when on\n+          // a given Pinot server, there is no realtime segment with text index enabled. In such\n+          // cases, there is no need for this thread to wake up simply after every few seconds/minutes\n+          // only to find that there is nothing to be refreshed. The thread should simply be\n+          // off CPU until signalled specifically. This also covers the situation where initially\n+          // there were few realtime segments of a table with text index. Later if they got\n+          // moved to another server as part of rebalance, then again there is no need for this thread\n+          // to do anything until some realtime segment is created with text index enabled.\n+          _conditionVariable.await();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d6a4fe43b15b4bf5d7ca4e67330d4a47d35650b0"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTE1MTQ1MQ==", "bodyText": "If we find that the segment is destroyed after we acquire the lock, then we don't release the lock. Does that matter?", "url": "https://github.com/apache/pinot/pull/4993#discussion_r379151451", "createdAt": "2020-02-13T22:19:14Z", "author": {"login": "mcvsubbu"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/realtime/impl/invertedindex/RealtimeLuceneIndexReaderRefreshThread.java", "diffHunk": "@@ -0,0 +1,133 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.realtime.impl.invertedindex;\n+\n+import java.util.List;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.locks.Condition;\n+import java.util.concurrent.locks.Lock;\n+import org.apache.lucene.search.SearcherManager;\n+import org.apache.lucene.store.AlreadyClosedException;\n+import org.apache.pinot.core.segment.creator.impl.SegmentColumnarIndexCreator;\n+import org.apache.pinot.core.realtime.impl.invertedindex.RealtimeLuceneIndexRefreshState.RealtimeLuceneReadersForRealtimeSegment;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Background thread to refresh the realtime lucene index readers for supporting\n+ * near-realtime text search. The task maintains a queue of realtime segments.\n+ * This queue is global (across all realtime segments of all realtime/hybrid tables).\n+ *\n+ * Each element in the queue is of type {@link RealtimeLuceneReadersForRealtimeSegment}.\n+ * It encapsulates a lock and all the realtime lucene readers for the particular realtime segment.\n+ * Since text index is also create on a per column basis, there will be as many realtime lucene\n+ * readers as the number of columns with text search enabled.\n+ *\n+ * Between each successive execution of the task, there is a fixed delay (regardless of how long\n+ * each execution took). When the task wakes up, it pick the RealtimeLuceneReadersForRealtimeSegment\n+ * from the head of queue, refresh it's readers and adds this at the tail of queue.\n+ */\n+public class RealtimeLuceneIndexReaderRefreshThread implements Runnable {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(SegmentColumnarIndexCreator.class);\n+  // TODO: make this configurable and choose a higher default value\n+  public static final int DELAY_BETWEEN_SUCCESSIVE_EXECUTION_MS_DEFAULT = 10;\n+\n+  private final ConcurrentLinkedQueue<RealtimeLuceneReadersForRealtimeSegment> _luceneRealtimeReaders;\n+  private final Lock _mutex;\n+  private final Condition _conditionVariable;\n+\n+  private volatile boolean _stopped = false;\n+\n+  RealtimeLuceneIndexReaderRefreshThread(\n+      ConcurrentLinkedQueue<RealtimeLuceneReadersForRealtimeSegment> luceneRealtimeReaders,\n+      Lock mutex, Condition conditionVariable) {\n+    _luceneRealtimeReaders = luceneRealtimeReaders;\n+    _mutex = mutex;\n+    _conditionVariable = conditionVariable;\n+  }\n+\n+  void setStopped() {\n+    _stopped = true;\n+  }\n+\n+  @Override\n+  public void run() {\n+    while (_stopped) {\n+      _mutex.lock();\n+      while (_luceneRealtimeReaders.isEmpty()) {\n+        try {\n+          // During instantiation of MutableSegmentImpl, we will signal on this condition variable once\n+          // one or more realtime lucene readers (one per column) belonging to the MutableSegment\n+          // are added to the global queue managed by this thread. The thread that signals will\n+          // grab this mutex and signal on the condition variable.\n+          //\n+          // This refresh thread will be woken up (and grab the mutex automatically as per the\n+          // implementation of await) and check if the queue is non-empty. It will then proceed to\n+          // poll the queue and refresh the realtime index readers for the polled segment.\n+          //\n+          // The mutex and condition-variable semantics take care of the scenario when on\n+          // a given Pinot server, there is no realtime segment with text index enabled. In such\n+          // cases, there is no need for this thread to wake up simply after every few seconds/minutes\n+          // only to find that there is nothing to be refreshed. The thread should simply be\n+          // off CPU until signalled specifically. This also covers the situation where initially\n+          // there were few realtime segments of a table with text index. Later if they got\n+          // moved to another server as part of rebalance, then again there is no need for this thread\n+          // to do anything until some realtime segment is created with text index enabled.\n+          _conditionVariable.await();\n+        } catch (InterruptedException e) {\n+          LOGGER.warn(\"Realtime lucene reader refresh thread got interrupted while waiting on condition variable: \", e);\n+          Thread.currentThread().interrupt();\n+        } finally {\n+          _mutex.unlock();\n+        }\n+      }\n+      RealtimeLuceneReadersForRealtimeSegment realtimeReadersForSegment = _luceneRealtimeReaders.poll();\n+      if (realtimeReadersForSegment != null) {\n+        String segmentName = realtimeReadersForSegment.getSegmentName();\n+        realtimeReadersForSegment.getLock().lock();\n+        if (!realtimeReadersForSegment.isSegmentDestroyed()) {\n+          // If the segment already got destroyed before this task picked up the segment\n+          // from queue, we don't have to do anything\n+          try {\n+            List<RealtimeLuceneTextIndexReader> realtimeLuceneReaders = realtimeReadersForSegment.getRealtimeLuceneReaders();\n+            for (RealtimeLuceneTextIndexReader realtimeReader : realtimeLuceneReaders) {\n+              SearcherManager searcherManager = realtimeReader.getSearcherManager();\n+              try {\n+                searcherManager.maybeRefresh();\n+              } catch (Exception e) {\n+                LOGGER.warn(\"Caught exception {} while refreshing realtime lucene reader for segment: {}\", e, segmentName);\n+              }\n+            }\n+            _luceneRealtimeReaders.offer(realtimeReadersForSegment);\n+          } finally {\n+            realtimeReadersForSegment.getLock().unlock();\n+          }\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d6a4fe43b15b4bf5d7ca4e67330d4a47d35650b0"}, "originalPosition": 122}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTE1NTg4OA==", "bodyText": "I think we should also check for the q not being empty upon exiting the cond var to handle spurious wakeups, then unlock and loop back.", "url": "https://github.com/apache/pinot/pull/4993#discussion_r379155888", "createdAt": "2020-02-13T22:29:57Z", "author": {"login": "mcvsubbu"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/realtime/impl/invertedindex/RealtimeLuceneIndexReaderRefreshThread.java", "diffHunk": "@@ -0,0 +1,133 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.realtime.impl.invertedindex;\n+\n+import java.util.List;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.locks.Condition;\n+import java.util.concurrent.locks.Lock;\n+import org.apache.lucene.search.SearcherManager;\n+import org.apache.lucene.store.AlreadyClosedException;\n+import org.apache.pinot.core.segment.creator.impl.SegmentColumnarIndexCreator;\n+import org.apache.pinot.core.realtime.impl.invertedindex.RealtimeLuceneIndexRefreshState.RealtimeLuceneReadersForRealtimeSegment;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Background thread to refresh the realtime lucene index readers for supporting\n+ * near-realtime text search. The task maintains a queue of realtime segments.\n+ * This queue is global (across all realtime segments of all realtime/hybrid tables).\n+ *\n+ * Each element in the queue is of type {@link RealtimeLuceneReadersForRealtimeSegment}.\n+ * It encapsulates a lock and all the realtime lucene readers for the particular realtime segment.\n+ * Since text index is also create on a per column basis, there will be as many realtime lucene\n+ * readers as the number of columns with text search enabled.\n+ *\n+ * Between each successive execution of the task, there is a fixed delay (regardless of how long\n+ * each execution took). When the task wakes up, it pick the RealtimeLuceneReadersForRealtimeSegment\n+ * from the head of queue, refresh it's readers and adds this at the tail of queue.\n+ */\n+public class RealtimeLuceneIndexReaderRefreshThread implements Runnable {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(SegmentColumnarIndexCreator.class);\n+  // TODO: make this configurable and choose a higher default value\n+  public static final int DELAY_BETWEEN_SUCCESSIVE_EXECUTION_MS_DEFAULT = 10;\n+\n+  private final ConcurrentLinkedQueue<RealtimeLuceneReadersForRealtimeSegment> _luceneRealtimeReaders;\n+  private final Lock _mutex;\n+  private final Condition _conditionVariable;\n+\n+  private volatile boolean _stopped = false;\n+\n+  RealtimeLuceneIndexReaderRefreshThread(\n+      ConcurrentLinkedQueue<RealtimeLuceneReadersForRealtimeSegment> luceneRealtimeReaders,\n+      Lock mutex, Condition conditionVariable) {\n+    _luceneRealtimeReaders = luceneRealtimeReaders;\n+    _mutex = mutex;\n+    _conditionVariable = conditionVariable;\n+  }\n+\n+  void setStopped() {\n+    _stopped = true;\n+  }\n+\n+  @Override\n+  public void run() {\n+    while (_stopped) {\n+      _mutex.lock();\n+      while (_luceneRealtimeReaders.isEmpty()) {\n+        try {\n+          // During instantiation of MutableSegmentImpl, we will signal on this condition variable once\n+          // one or more realtime lucene readers (one per column) belonging to the MutableSegment\n+          // are added to the global queue managed by this thread. The thread that signals will\n+          // grab this mutex and signal on the condition variable.\n+          //\n+          // This refresh thread will be woken up (and grab the mutex automatically as per the\n+          // implementation of await) and check if the queue is non-empty. It will then proceed to\n+          // poll the queue and refresh the realtime index readers for the polled segment.\n+          //\n+          // The mutex and condition-variable semantics take care of the scenario when on\n+          // a given Pinot server, there is no realtime segment with text index enabled. In such\n+          // cases, there is no need for this thread to wake up simply after every few seconds/minutes\n+          // only to find that there is nothing to be refreshed. The thread should simply be\n+          // off CPU until signalled specifically. This also covers the situation where initially\n+          // there were few realtime segments of a table with text index. Later if they got\n+          // moved to another server as part of rebalance, then again there is no need for this thread\n+          // to do anything until some realtime segment is created with text index enabled.\n+          _conditionVariable.await();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTE1MDY0MQ=="}, "originalCommit": {"oid": "d6a4fe43b15b4bf5d7ca4e67330d4a47d35650b0"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTE1NzIyNA==", "bodyText": "should also signal condition variable so that we get shutdown signal", "url": "https://github.com/apache/pinot/pull/4993#discussion_r379157224", "createdAt": "2020-02-13T22:33:11Z", "author": {"login": "mcvsubbu"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/realtime/impl/invertedindex/RealtimeLuceneIndexReaderRefreshThread.java", "diffHunk": "@@ -0,0 +1,133 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.realtime.impl.invertedindex;\n+\n+import java.util.List;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.locks.Condition;\n+import java.util.concurrent.locks.Lock;\n+import org.apache.lucene.search.SearcherManager;\n+import org.apache.lucene.store.AlreadyClosedException;\n+import org.apache.pinot.core.segment.creator.impl.SegmentColumnarIndexCreator;\n+import org.apache.pinot.core.realtime.impl.invertedindex.RealtimeLuceneIndexRefreshState.RealtimeLuceneReadersForRealtimeSegment;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Background thread to refresh the realtime lucene index readers for supporting\n+ * near-realtime text search. The task maintains a queue of realtime segments.\n+ * This queue is global (across all realtime segments of all realtime/hybrid tables).\n+ *\n+ * Each element in the queue is of type {@link RealtimeLuceneReadersForRealtimeSegment}.\n+ * It encapsulates a lock and all the realtime lucene readers for the particular realtime segment.\n+ * Since text index is also create on a per column basis, there will be as many realtime lucene\n+ * readers as the number of columns with text search enabled.\n+ *\n+ * Between each successive execution of the task, there is a fixed delay (regardless of how long\n+ * each execution took). When the task wakes up, it pick the RealtimeLuceneReadersForRealtimeSegment\n+ * from the head of queue, refresh it's readers and adds this at the tail of queue.\n+ */\n+public class RealtimeLuceneIndexReaderRefreshThread implements Runnable {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(SegmentColumnarIndexCreator.class);\n+  // TODO: make this configurable and choose a higher default value\n+  public static final int DELAY_BETWEEN_SUCCESSIVE_EXECUTION_MS_DEFAULT = 10;\n+\n+  private final ConcurrentLinkedQueue<RealtimeLuceneReadersForRealtimeSegment> _luceneRealtimeReaders;\n+  private final Lock _mutex;\n+  private final Condition _conditionVariable;\n+\n+  private volatile boolean _stopped = false;\n+\n+  RealtimeLuceneIndexReaderRefreshThread(\n+      ConcurrentLinkedQueue<RealtimeLuceneReadersForRealtimeSegment> luceneRealtimeReaders,\n+      Lock mutex, Condition conditionVariable) {\n+    _luceneRealtimeReaders = luceneRealtimeReaders;\n+    _mutex = mutex;\n+    _conditionVariable = conditionVariable;\n+  }\n+\n+  void setStopped() {\n+    _stopped = true;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d6a4fe43b15b4bf5d7ca4e67330d4a47d35650b0"}, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTE1NzcwNQ==", "bodyText": "also worth checking stopped here, so we don't do another segment during stop", "url": "https://github.com/apache/pinot/pull/4993#discussion_r379157705", "createdAt": "2020-02-13T22:34:27Z", "author": {"login": "mcvsubbu"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/realtime/impl/invertedindex/RealtimeLuceneIndexReaderRefreshThread.java", "diffHunk": "@@ -0,0 +1,133 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.realtime.impl.invertedindex;\n+\n+import java.util.List;\n+import java.util.concurrent.ConcurrentLinkedQueue;\n+import java.util.concurrent.locks.Condition;\n+import java.util.concurrent.locks.Lock;\n+import org.apache.lucene.search.SearcherManager;\n+import org.apache.lucene.store.AlreadyClosedException;\n+import org.apache.pinot.core.segment.creator.impl.SegmentColumnarIndexCreator;\n+import org.apache.pinot.core.realtime.impl.invertedindex.RealtimeLuceneIndexRefreshState.RealtimeLuceneReadersForRealtimeSegment;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Background thread to refresh the realtime lucene index readers for supporting\n+ * near-realtime text search. The task maintains a queue of realtime segments.\n+ * This queue is global (across all realtime segments of all realtime/hybrid tables).\n+ *\n+ * Each element in the queue is of type {@link RealtimeLuceneReadersForRealtimeSegment}.\n+ * It encapsulates a lock and all the realtime lucene readers for the particular realtime segment.\n+ * Since text index is also create on a per column basis, there will be as many realtime lucene\n+ * readers as the number of columns with text search enabled.\n+ *\n+ * Between each successive execution of the task, there is a fixed delay (regardless of how long\n+ * each execution took). When the task wakes up, it pick the RealtimeLuceneReadersForRealtimeSegment\n+ * from the head of queue, refresh it's readers and adds this at the tail of queue.\n+ */\n+public class RealtimeLuceneIndexReaderRefreshThread implements Runnable {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(SegmentColumnarIndexCreator.class);\n+  // TODO: make this configurable and choose a higher default value\n+  public static final int DELAY_BETWEEN_SUCCESSIVE_EXECUTION_MS_DEFAULT = 10;\n+\n+  private final ConcurrentLinkedQueue<RealtimeLuceneReadersForRealtimeSegment> _luceneRealtimeReaders;\n+  private final Lock _mutex;\n+  private final Condition _conditionVariable;\n+\n+  private volatile boolean _stopped = false;\n+\n+  RealtimeLuceneIndexReaderRefreshThread(\n+      ConcurrentLinkedQueue<RealtimeLuceneReadersForRealtimeSegment> luceneRealtimeReaders,\n+      Lock mutex, Condition conditionVariable) {\n+    _luceneRealtimeReaders = luceneRealtimeReaders;\n+    _mutex = mutex;\n+    _conditionVariable = conditionVariable;\n+  }\n+\n+  void setStopped() {\n+    _stopped = true;\n+  }\n+\n+  @Override\n+  public void run() {\n+    while (_stopped) {\n+      _mutex.lock();\n+      while (_luceneRealtimeReaders.isEmpty()) {\n+        try {\n+          // During instantiation of MutableSegmentImpl, we will signal on this condition variable once\n+          // one or more realtime lucene readers (one per column) belonging to the MutableSegment\n+          // are added to the global queue managed by this thread. The thread that signals will\n+          // grab this mutex and signal on the condition variable.\n+          //\n+          // This refresh thread will be woken up (and grab the mutex automatically as per the\n+          // implementation of await) and check if the queue is non-empty. It will then proceed to\n+          // poll the queue and refresh the realtime index readers for the polled segment.\n+          //\n+          // The mutex and condition-variable semantics take care of the scenario when on\n+          // a given Pinot server, there is no realtime segment with text index enabled. In such\n+          // cases, there is no need for this thread to wake up simply after every few seconds/minutes\n+          // only to find that there is nothing to be refreshed. The thread should simply be\n+          // off CPU until signalled specifically. This also covers the situation where initially\n+          // there were few realtime segments of a table with text index. Later if they got\n+          // moved to another server as part of rebalance, then again there is no need for this thread\n+          // to do anything until some realtime segment is created with text index enabled.\n+          _conditionVariable.await();\n+        } catch (InterruptedException e) {\n+          LOGGER.warn(\"Realtime lucene reader refresh thread got interrupted while waiting on condition variable: \", e);\n+          Thread.currentThread().interrupt();\n+        } finally {\n+          _mutex.unlock();\n+        }\n+      }\n+      RealtimeLuceneReadersForRealtimeSegment realtimeReadersForSegment = _luceneRealtimeReaders.poll();\n+      if (realtimeReadersForSegment != null) {\n+        String segmentName = realtimeReadersForSegment.getSegmentName();\n+        realtimeReadersForSegment.getLock().lock();\n+        if (!realtimeReadersForSegment.isSegmentDestroyed()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d6a4fe43b15b4bf5d7ca4e67330d4a47d35650b0"}, "originalPosition": 105}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d6a4fe43b15b4bf5d7ca4e67330d4a47d35650b0", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/d6a4fe43b15b4bf5d7ca4e67330d4a47d35650b0", "committedDate": "2020-02-13T18:19:38Z", "message": "fix build"}, "afterCommit": {"oid": "ff9c94959846164cc66aa1fdb25be19aa58cc2bd", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/ff9c94959846164cc66aa1fdb25be19aa58cc2bd", "committedDate": "2020-02-14T08:22:48Z", "message": "Support Text Search"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f82cfa605a7d292fab59fcf84b74e6441507da01", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/f82cfa605a7d292fab59fcf84b74e6441507da01", "committedDate": "2020-02-14T09:08:44Z", "message": "Support Text Search"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ff9c94959846164cc66aa1fdb25be19aa58cc2bd", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/ff9c94959846164cc66aa1fdb25be19aa58cc2bd", "committedDate": "2020-02-14T08:22:48Z", "message": "Support Text Search"}, "afterCommit": {"oid": "f82cfa605a7d292fab59fcf84b74e6441507da01", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/f82cfa605a7d292fab59fcf84b74e6441507da01", "committedDate": "2020-02-14T09:08:44Z", "message": "Support Text Search"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1490, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}