{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzcyMTY5Nzg0", "number": 5056, "reviewThreads": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QwMDoxOTowOFrODd3_IQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QyMzowODoxOFrODeLU5g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyNjUyNTc3OnYy", "diffSide": "RIGHT", "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/ThirdEyeAnomalyApplication.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QwMDoxOTowOFrOFmuqkw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMVQyMjozNzo1N1rOFobvbw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjE1NDc3MQ==", "bodyText": "I think these name changes are great for adding clarity and consistency", "url": "https://github.com/apache/pinot/pull/5056#discussion_r376154771", "createdAt": "2020-02-07T00:19:08Z", "author": {"login": "harleyjj"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/ThirdEyeAnomalyApplication.java", "diffHunk": "@@ -41,8 +41,8 @@\n import org.apache.pinot.thirdeye.datasource.DAORegistry;\n import org.apache.pinot.thirdeye.datasource.ThirdEyeCacheRegistry;\n import org.apache.pinot.thirdeye.datasource.pinot.resources.PinotDataSourceResource;\n-import org.apache.pinot.thirdeye.detection.DetectionPipelineScheduler;\n-import org.apache.pinot.thirdeye.detection.alert.DetectionAlertScheduler;\n+import org.apache.pinot.thirdeye.scheduler.DetectionScheduler;\n+import org.apache.pinot.thirdeye.scheduler.SubscriptionScheduler;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU1MDcwNw==", "bodyText": "Do you suggest to change the naming convention?\nFrom DetectionAlert -> Subscription? We have detection_alert_config_index table and all the subscription tasks are with the name \"detection_alert_xxx\".", "url": "https://github.com/apache/pinot/pull/5056#discussion_r376550707", "createdAt": "2020-02-07T18:52:53Z", "author": {"login": "xiaohui-sun"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/ThirdEyeAnomalyApplication.java", "diffHunk": "@@ -41,8 +41,8 @@\n import org.apache.pinot.thirdeye.datasource.DAORegistry;\n import org.apache.pinot.thirdeye.datasource.ThirdEyeCacheRegistry;\n import org.apache.pinot.thirdeye.datasource.pinot.resources.PinotDataSourceResource;\n-import org.apache.pinot.thirdeye.detection.DetectionPipelineScheduler;\n-import org.apache.pinot.thirdeye.detection.alert.DetectionAlertScheduler;\n+import org.apache.pinot.thirdeye.scheduler.DetectionScheduler;\n+import org.apache.pinot.thirdeye.scheduler.SubscriptionScheduler;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjE1NDc3MQ=="}, "originalCommit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjYzOTkwOA==", "bodyText": "DetectionScheduler can probably be changed to DetectionCronScheduler, since it is not the only scheduler to schedule detection tasks and it is the only cron based scheduler for detection.", "url": "https://github.com/apache/pinot/pull/5056#discussion_r376639908", "createdAt": "2020-02-07T22:36:11Z", "author": {"login": "vincentchenjl"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/ThirdEyeAnomalyApplication.java", "diffHunk": "@@ -41,8 +41,8 @@\n import org.apache.pinot.thirdeye.datasource.DAORegistry;\n import org.apache.pinot.thirdeye.datasource.ThirdEyeCacheRegistry;\n import org.apache.pinot.thirdeye.datasource.pinot.resources.PinotDataSourceResource;\n-import org.apache.pinot.thirdeye.detection.DetectionPipelineScheduler;\n-import org.apache.pinot.thirdeye.detection.alert.DetectionAlertScheduler;\n+import org.apache.pinot.thirdeye.scheduler.DetectionScheduler;\n+import org.apache.pinot.thirdeye.scheduler.SubscriptionScheduler;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjE1NDc3MQ=="}, "originalCommit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzk0MTg3MQ==", "bodyText": "@xiaohui-sun, yes, I have been consistently trying to enforce the usage of subscription rather than detection_alert in our code (this pr and in the past). detection_alert is a very confusing term.\nThe database still holds the references as detection_alert which is a little harder to migrate but eventually we should.", "url": "https://github.com/apache/pinot/pull/5056#discussion_r377941871", "createdAt": "2020-02-11T22:37:57Z", "author": {"login": "akshayrai"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/ThirdEyeAnomalyApplication.java", "diffHunk": "@@ -41,8 +41,8 @@\n import org.apache.pinot.thirdeye.datasource.DAORegistry;\n import org.apache.pinot.thirdeye.datasource.ThirdEyeCacheRegistry;\n import org.apache.pinot.thirdeye.datasource.pinot.resources.PinotDataSourceResource;\n-import org.apache.pinot.thirdeye.detection.DetectionPipelineScheduler;\n-import org.apache.pinot.thirdeye.detection.alert.DetectionAlertScheduler;\n+import org.apache.pinot.thirdeye.scheduler.DetectionScheduler;\n+import org.apache.pinot.thirdeye.scheduler.SubscriptionScheduler;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjE1NDc3MQ=="}, "originalCommit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyOTEwMDQxOnYy", "diffSide": "RIGHT", "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/detection/trigger/DataAvailabilityTaskScheduler.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QxOTowNDozMVrOFnHJ7A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMlQwNTo1Mzo1OFrOFoie_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU1NjAxMg==", "bodyText": "\"DataAvailability\" is a heavily overloaded term now.\nWe have DataAvailabilityTaskScheduler which is actually \"EventTriggerTaskScheduler\".\nHere we have another \"data availability\" task. It is too confusing.\nCan you do a refactoring?\nAlso @vincentchenjl  FYI", "url": "https://github.com/apache/pinot/pull/5056#discussion_r376556012", "createdAt": "2020-02-07T19:04:31Z", "author": {"login": "xiaohui-sun"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/detection/trigger/DataAvailabilityTaskScheduler.java", "diffHunk": "@@ -176,35 +198,43 @@ private void populateDetectionMapAndDatasetConfigMap(\n     return res;\n   }\n \n-  private long createDetectionTask(DetectionConfigDTO detectionConfig) throws JsonProcessingException {\n-    long detectionConfigId = detectionConfig.getId();\n+  private DetectionPipelineTaskInfo getDetectionPipelineTaskInfo(DetectionConfigDTO detectionConfig, long end) {\n     // Make sure start time is not out of DETECTION_TASK_MAX_LOOKBACK_WINDOW\n-    long end = System.currentTimeMillis();\n     long start = Math.max(detectionConfig.getLastTimestamp(),\n         end - ThirdEyeUtils.DETECTION_TASK_MAX_LOOKBACK_WINDOW);\n-    DetectionPipelineTaskInfo taskInfo = new DetectionPipelineTaskInfo(detectionConfigId, start, end);\n+\n+    return new DetectionPipelineTaskInfo(detectionConfig.getId(), start, end);\n+  }\n+\n+  private long createTask(TaskConstants.TaskType taskType, DetectionConfigDTO detectionConfig, long end)\n+      throws JsonProcessingException {\n+    DetectionPipelineTaskInfo taskInfo = getDetectionPipelineTaskInfo(detectionConfig, end);\n     String taskInfoJson = OBJECT_MAPPER.writeValueAsString(taskInfo);\n-    TaskDTO taskDTO = new TaskDTO();\n-    taskDTO.setTaskType(TaskConstants.TaskType.DETECTION);\n-    taskDTO.setJobName(TaskConstants.TaskType.DETECTION.toString() + \"_\" + detectionConfigId);\n-    taskDTO.setStatus(TaskConstants.TaskStatus.WAITING);\n-    taskDTO.setTaskInfo(taskInfoJson);\n-    long taskId = taskDAO.save(taskDTO);\n-    LOG.info(\"Created detection pipeline task {} with taskId {}\", taskDTO, taskId);\n-    taskLastCreateTimeMap.put(detectionConfigId, end);\n-    return taskId;\n+    TaskDTO taskDTO = TaskUtils.buildTask(detectionConfig.getId(), taskInfoJson, taskType);\n+    long id = taskDAO.save(taskDTO);\n+    LOG.info(\"Created {} task {} with taskId {}\", taskType, taskDTO, id);\n+    return id;\n+  }\n+\n+  private long createDetectionTask(DetectionConfigDTO detectionConfig, long end) throws JsonProcessingException {\n+    return createTask(TaskConstants.TaskType.DETECTION, detectionConfig, end);\n+  }\n+\n+  private long createDataAvailabilityTask(DetectionConfigDTO detectionConfig, long end) throws JsonProcessingException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "originalPosition": 112}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjY0MzYyNw==", "bodyText": "My thought here is that we keep DataAvailabilityTaskScheduler here, because all these tasks are scheduled based on data availability.  I agree that createDataAvailabilityTask is still confusing with the DataAvailabilityTaskScheduler, so maybe we can change it to createDataSLACheckTask, which is more descriptive.", "url": "https://github.com/apache/pinot/pull/5056#discussion_r376643627", "createdAt": "2020-02-07T22:49:12Z", "author": {"login": "vincentchenjl"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/detection/trigger/DataAvailabilityTaskScheduler.java", "diffHunk": "@@ -176,35 +198,43 @@ private void populateDetectionMapAndDatasetConfigMap(\n     return res;\n   }\n \n-  private long createDetectionTask(DetectionConfigDTO detectionConfig) throws JsonProcessingException {\n-    long detectionConfigId = detectionConfig.getId();\n+  private DetectionPipelineTaskInfo getDetectionPipelineTaskInfo(DetectionConfigDTO detectionConfig, long end) {\n     // Make sure start time is not out of DETECTION_TASK_MAX_LOOKBACK_WINDOW\n-    long end = System.currentTimeMillis();\n     long start = Math.max(detectionConfig.getLastTimestamp(),\n         end - ThirdEyeUtils.DETECTION_TASK_MAX_LOOKBACK_WINDOW);\n-    DetectionPipelineTaskInfo taskInfo = new DetectionPipelineTaskInfo(detectionConfigId, start, end);\n+\n+    return new DetectionPipelineTaskInfo(detectionConfig.getId(), start, end);\n+  }\n+\n+  private long createTask(TaskConstants.TaskType taskType, DetectionConfigDTO detectionConfig, long end)\n+      throws JsonProcessingException {\n+    DetectionPipelineTaskInfo taskInfo = getDetectionPipelineTaskInfo(detectionConfig, end);\n     String taskInfoJson = OBJECT_MAPPER.writeValueAsString(taskInfo);\n-    TaskDTO taskDTO = new TaskDTO();\n-    taskDTO.setTaskType(TaskConstants.TaskType.DETECTION);\n-    taskDTO.setJobName(TaskConstants.TaskType.DETECTION.toString() + \"_\" + detectionConfigId);\n-    taskDTO.setStatus(TaskConstants.TaskStatus.WAITING);\n-    taskDTO.setTaskInfo(taskInfoJson);\n-    long taskId = taskDAO.save(taskDTO);\n-    LOG.info(\"Created detection pipeline task {} with taskId {}\", taskDTO, taskId);\n-    taskLastCreateTimeMap.put(detectionConfigId, end);\n-    return taskId;\n+    TaskDTO taskDTO = TaskUtils.buildTask(detectionConfig.getId(), taskInfoJson, taskType);\n+    long id = taskDAO.save(taskDTO);\n+    LOG.info(\"Created {} task {} with taskId {}\", taskType, taskDTO, id);\n+    return id;\n+  }\n+\n+  private long createDetectionTask(DetectionConfigDTO detectionConfig, long end) throws JsonProcessingException {\n+    return createTask(TaskConstants.TaskType.DETECTION, detectionConfig, end);\n+  }\n+\n+  private long createDataAvailabilityTask(DetectionConfigDTO detectionConfig, long end) throws JsonProcessingException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU1NjAxMg=="}, "originalCommit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "originalPosition": 112}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzk0MTkwMw==", "bodyText": "@vincentchenjl agreed. Let's use data availability term for referring to the event (data available or not) and use Data SLA for the alerts that are setup based on these data availability events.\nI will update accordingly.", "url": "https://github.com/apache/pinot/pull/5056#discussion_r377941903", "createdAt": "2020-02-11T22:38:02Z", "author": {"login": "akshayrai"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/detection/trigger/DataAvailabilityTaskScheduler.java", "diffHunk": "@@ -176,35 +198,43 @@ private void populateDetectionMapAndDatasetConfigMap(\n     return res;\n   }\n \n-  private long createDetectionTask(DetectionConfigDTO detectionConfig) throws JsonProcessingException {\n-    long detectionConfigId = detectionConfig.getId();\n+  private DetectionPipelineTaskInfo getDetectionPipelineTaskInfo(DetectionConfigDTO detectionConfig, long end) {\n     // Make sure start time is not out of DETECTION_TASK_MAX_LOOKBACK_WINDOW\n-    long end = System.currentTimeMillis();\n     long start = Math.max(detectionConfig.getLastTimestamp(),\n         end - ThirdEyeUtils.DETECTION_TASK_MAX_LOOKBACK_WINDOW);\n-    DetectionPipelineTaskInfo taskInfo = new DetectionPipelineTaskInfo(detectionConfigId, start, end);\n+\n+    return new DetectionPipelineTaskInfo(detectionConfig.getId(), start, end);\n+  }\n+\n+  private long createTask(TaskConstants.TaskType taskType, DetectionConfigDTO detectionConfig, long end)\n+      throws JsonProcessingException {\n+    DetectionPipelineTaskInfo taskInfo = getDetectionPipelineTaskInfo(detectionConfig, end);\n     String taskInfoJson = OBJECT_MAPPER.writeValueAsString(taskInfo);\n-    TaskDTO taskDTO = new TaskDTO();\n-    taskDTO.setTaskType(TaskConstants.TaskType.DETECTION);\n-    taskDTO.setJobName(TaskConstants.TaskType.DETECTION.toString() + \"_\" + detectionConfigId);\n-    taskDTO.setStatus(TaskConstants.TaskStatus.WAITING);\n-    taskDTO.setTaskInfo(taskInfoJson);\n-    long taskId = taskDAO.save(taskDTO);\n-    LOG.info(\"Created detection pipeline task {} with taskId {}\", taskDTO, taskId);\n-    taskLastCreateTimeMap.put(detectionConfigId, end);\n-    return taskId;\n+    TaskDTO taskDTO = TaskUtils.buildTask(detectionConfig.getId(), taskInfoJson, taskType);\n+    long id = taskDAO.save(taskDTO);\n+    LOG.info(\"Created {} task {} with taskId {}\", taskType, taskDTO, id);\n+    return id;\n+  }\n+\n+  private long createDetectionTask(DetectionConfigDTO detectionConfig, long end) throws JsonProcessingException {\n+    return createTask(TaskConstants.TaskType.DETECTION, detectionConfig, end);\n+  }\n+\n+  private long createDataAvailabilityTask(DetectionConfigDTO detectionConfig, long end) throws JsonProcessingException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU1NjAxMg=="}, "originalCommit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "originalPosition": 112}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODA1MjM0OQ==", "bodyText": "I like the term SLA since it is easy to understand.", "url": "https://github.com/apache/pinot/pull/5056#discussion_r378052349", "createdAt": "2020-02-12T05:53:58Z", "author": {"login": "xiaohui-sun"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/detection/trigger/DataAvailabilityTaskScheduler.java", "diffHunk": "@@ -176,35 +198,43 @@ private void populateDetectionMapAndDatasetConfigMap(\n     return res;\n   }\n \n-  private long createDetectionTask(DetectionConfigDTO detectionConfig) throws JsonProcessingException {\n-    long detectionConfigId = detectionConfig.getId();\n+  private DetectionPipelineTaskInfo getDetectionPipelineTaskInfo(DetectionConfigDTO detectionConfig, long end) {\n     // Make sure start time is not out of DETECTION_TASK_MAX_LOOKBACK_WINDOW\n-    long end = System.currentTimeMillis();\n     long start = Math.max(detectionConfig.getLastTimestamp(),\n         end - ThirdEyeUtils.DETECTION_TASK_MAX_LOOKBACK_WINDOW);\n-    DetectionPipelineTaskInfo taskInfo = new DetectionPipelineTaskInfo(detectionConfigId, start, end);\n+\n+    return new DetectionPipelineTaskInfo(detectionConfig.getId(), start, end);\n+  }\n+\n+  private long createTask(TaskConstants.TaskType taskType, DetectionConfigDTO detectionConfig, long end)\n+      throws JsonProcessingException {\n+    DetectionPipelineTaskInfo taskInfo = getDetectionPipelineTaskInfo(detectionConfig, end);\n     String taskInfoJson = OBJECT_MAPPER.writeValueAsString(taskInfo);\n-    TaskDTO taskDTO = new TaskDTO();\n-    taskDTO.setTaskType(TaskConstants.TaskType.DETECTION);\n-    taskDTO.setJobName(TaskConstants.TaskType.DETECTION.toString() + \"_\" + detectionConfigId);\n-    taskDTO.setStatus(TaskConstants.TaskStatus.WAITING);\n-    taskDTO.setTaskInfo(taskInfoJson);\n-    long taskId = taskDAO.save(taskDTO);\n-    LOG.info(\"Created detection pipeline task {} with taskId {}\", taskDTO, taskId);\n-    taskLastCreateTimeMap.put(detectionConfigId, end);\n-    return taskId;\n+    TaskDTO taskDTO = TaskUtils.buildTask(detectionConfig.getId(), taskInfoJson, taskType);\n+    long id = taskDAO.save(taskDTO);\n+    LOG.info(\"Created {} task {} with taskId {}\", taskType, taskDTO, id);\n+    return id;\n+  }\n+\n+  private long createDetectionTask(DetectionConfigDTO detectionConfig, long end) throws JsonProcessingException {\n+    return createTask(TaskConstants.TaskType.DETECTION, detectionConfig, end);\n+  }\n+\n+  private long createDataAvailabilityTask(DetectionConfigDTO detectionConfig, long end) throws JsonProcessingException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU1NjAxMg=="}, "originalCommit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "originalPosition": 112}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyOTExNTM5OnYy", "diffSide": "RIGHT", "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/detection/trigger/DataAvailabilityTaskScheduler.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QxOToxMDowN1rOFnHTkA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMlQwNTo1NToyMVrOFoigAg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU1ODQ4MA==", "bodyText": "Why changing the interface to add endtime?", "url": "https://github.com/apache/pinot/pull/5056#discussion_r376558480", "createdAt": "2020-02-07T19:10:07Z", "author": {"login": "xiaohui-sun"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/detection/trigger/DataAvailabilityTaskScheduler.java", "diffHunk": "@@ -95,16 +103,30 @@ public void run() {\n           if (isAllDatasetUpdated(detectionConfig, detection2DatasetMap.get(detectionConfig), datasetConfigMap)) {\n             if (isWithinSchedulingWindow(detection2DatasetMap.get(detectionConfig), datasetConfigMap)) {\n               //TODO: additional check is required if detection is based on aggregated value across multiple data points\n-              createDetectionTask(detectionConfig);\n+              long endtime = System.currentTimeMillis();\n+              createDetectionTask(detectionConfig, endtime);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzk0NTUyNg==", "bodyText": "This is just a utility method ensuring both the detection and SLA task have the same end time.", "url": "https://github.com/apache/pinot/pull/5056#discussion_r377945526", "createdAt": "2020-02-11T22:46:42Z", "author": {"login": "akshayrai"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/detection/trigger/DataAvailabilityTaskScheduler.java", "diffHunk": "@@ -95,16 +103,30 @@ public void run() {\n           if (isAllDatasetUpdated(detectionConfig, detection2DatasetMap.get(detectionConfig), datasetConfigMap)) {\n             if (isWithinSchedulingWindow(detection2DatasetMap.get(detectionConfig), datasetConfigMap)) {\n               //TODO: additional check is required if detection is based on aggregated value across multiple data points\n-              createDetectionTask(detectionConfig);\n+              long endtime = System.currentTimeMillis();\n+              createDetectionTask(detectionConfig, endtime);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU1ODQ4MA=="}, "originalCommit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODA1MjYxMA==", "bodyText": "It is an overkill to add one additional parameter just for \"ensuring both the detection and SLA task have the same end time\".\nPeople look at the util function will probably wonder - \"why there is only endtime not starttime\".", "url": "https://github.com/apache/pinot/pull/5056#discussion_r378052610", "createdAt": "2020-02-12T05:55:21Z", "author": {"login": "xiaohui-sun"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/detection/trigger/DataAvailabilityTaskScheduler.java", "diffHunk": "@@ -95,16 +103,30 @@ public void run() {\n           if (isAllDatasetUpdated(detectionConfig, detection2DatasetMap.get(detectionConfig), datasetConfigMap)) {\n             if (isWithinSchedulingWindow(detection2DatasetMap.get(detectionConfig), datasetConfigMap)) {\n               //TODO: additional check is required if detection is based on aggregated value across multiple data points\n-              createDetectionTask(detectionConfig);\n+              long endtime = System.currentTimeMillis();\n+              createDetectionTask(detectionConfig, endtime);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU1ODQ4MA=="}, "originalCommit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "originalPosition": 46}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyOTEyNTc5OnYy", "diffSide": "RIGHT", "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/detection/trigger/DataAvailabilityTaskScheduler.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QxOToxNDowNFrOFnHaMA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMVQyMjozODowNVrOFobvrA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU2MDE3Ng==", "bodyText": "Do you create data availability task elsewhere? Is this the only place to trigger data availability task?", "url": "https://github.com/apache/pinot/pull/5056#discussion_r376560176", "createdAt": "2020-02-07T19:14:04Z", "author": {"login": "xiaohui-sun"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/detection/trigger/DataAvailabilityTaskScheduler.java", "diffHunk": "@@ -95,16 +103,30 @@ public void run() {\n           if (isAllDatasetUpdated(detectionConfig, detection2DatasetMap.get(detectionConfig), datasetConfigMap)) {\n             if (isWithinSchedulingWindow(detection2DatasetMap.get(detectionConfig), datasetConfigMap)) {\n               //TODO: additional check is required if detection is based on aggregated value across multiple data points\n-              createDetectionTask(detectionConfig);\n+              long endtime = System.currentTimeMillis();\n+              createDetectionTask(detectionConfig, endtime);\n+              detectionIdToWatermarkMap.put(detectionConfig.getId(), endtime);\n               ThirdeyeMetricsUtil.eventScheduledTaskCounter.inc();\n               taskCount++;\n             } else {\n               LOG.warn(\"Unable to schedule a task for {}, because it is out of scheduling window.\", detectionConfigId);\n             }\n           }\n+\n+          // Note: Fallback SLA & Data availability SLA are independent of each other.\n+          // For example, if an event doesn't arrive within 24 hours, do a fallback.\n+          // On the other hand, a user can setup an SLA alert if there is no data for 3 days.\n           if (needFallback(detectionConfig)) {\n             LOG.info(\"Scheduling a task for detection {} due to the fallback mechanism.\", detectionConfigId);\n-            createDetectionTask(detectionConfig);\n+            long endtime = System.currentTimeMillis();\n+            createDetectionTask(detectionConfig, endtime);\n+\n+            if (DetectionUtils.isDataAvailabilityCheckEnabled(detectionConfig)) {\n+              createDataAvailabilityTask(detectionConfig, endtime);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzk0MTkzMg==", "bodyText": "Discussed offline. Data SLA task will be created in 2 cases.\na. Whenever the DetectionCronScheduler schedules a detection task.\nb. Whenever the DataAvailabilityTaskScheduler does a fallback.\nNote that we do not need to schedule a Data SLA task when a Data availability event arrives.", "url": "https://github.com/apache/pinot/pull/5056#discussion_r377941932", "createdAt": "2020-02-11T22:38:05Z", "author": {"login": "akshayrai"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/detection/trigger/DataAvailabilityTaskScheduler.java", "diffHunk": "@@ -95,16 +103,30 @@ public void run() {\n           if (isAllDatasetUpdated(detectionConfig, detection2DatasetMap.get(detectionConfig), datasetConfigMap)) {\n             if (isWithinSchedulingWindow(detection2DatasetMap.get(detectionConfig), datasetConfigMap)) {\n               //TODO: additional check is required if detection is based on aggregated value across multiple data points\n-              createDetectionTask(detectionConfig);\n+              long endtime = System.currentTimeMillis();\n+              createDetectionTask(detectionConfig, endtime);\n+              detectionIdToWatermarkMap.put(detectionConfig.getId(), endtime);\n               ThirdeyeMetricsUtil.eventScheduledTaskCounter.inc();\n               taskCount++;\n             } else {\n               LOG.warn(\"Unable to schedule a task for {}, because it is out of scheduling window.\", detectionConfigId);\n             }\n           }\n+\n+          // Note: Fallback SLA & Data availability SLA are independent of each other.\n+          // For example, if an event doesn't arrive within 24 hours, do a fallback.\n+          // On the other hand, a user can setup an SLA alert if there is no data for 3 days.\n           if (needFallback(detectionConfig)) {\n             LOG.info(\"Scheduling a task for detection {} due to the fallback mechanism.\", detectionConfigId);\n-            createDetectionTask(detectionConfig);\n+            long endtime = System.currentTimeMillis();\n+            createDetectionTask(detectionConfig, endtime);\n+\n+            if (DetectionUtils.isDataAvailabilityCheckEnabled(detectionConfig)) {\n+              createDataAvailabilityTask(detectionConfig, endtime);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU2MDE3Ng=="}, "originalCommit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "originalPosition": 65}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyOTEzMjExOnYy", "diffSide": "RIGHT", "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/scheduler/DetectionScheduler.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QxOToxNjozNlrOFnHeXg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMVQyMjozODoyMFrOFobwGw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU2MTI0Ng==", "bodyText": "Do we only run availability detection together with the normal detection job?", "url": "https://github.com/apache/pinot/pull/5056#discussion_r376561246", "createdAt": "2020-02-07T19:16:36Z", "author": {"login": "xiaohui-sun"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/scheduler/DetectionScheduler.java", "diffHunk": "@@ -120,34 +126,41 @@ public void run() {\n           LOG.error(\"Error removing job key {}\", jobKey);\n         }\n       }\n-\n     } catch (SchedulerException e) {\n       LOG.error(\"Error while scheduling detection pipeline\", e);\n     }\n   }\n \n-  private boolean jobUpdated(DetectionConfigDTO config, JobKey key) throws SchedulerException {\n-    List<Trigger> triggers = (List<Trigger>) scheduler.getTriggersOfJob(key);\n-    CronTrigger cronTrigger = (CronTrigger) triggers.get(0);\n-    String cronInSchedule = cronTrigger.getCronExpression();\n+  @Override\n+  public Set<JobKey> getScheduledJobs() throws SchedulerException {\n+    return this.scheduler.getJobKeys(GroupMatcher.jobGroupEquals(TaskConstants.TaskType.DETECTION.toString()));\n+  }\n \n-    if (!config.getCron().equals(cronInSchedule)) {\n-      LOG.info(\"Cron expression for detection pipeline {} has been changed from {}  to {}. \" + \"Restarting schedule\",\n-          config.getId(), cronInSchedule, config.getCron());\n-      return true;\n-    }\n-    return false;\n+  @Override\n+  public void shutdown() throws SchedulerException {\n+    AnomalyUtils.safelyShutdownExecutionService(executorService, this.getClass());\n+    scheduler.shutdown();\n   }\n \n-  private void startJob(DetectionConfigDTO config, JobKey key) throws SchedulerException {\n-    Trigger trigger =\n-        TriggerBuilder.newTrigger().withSchedule(CronScheduleBuilder.cronSchedule(config.getCron())).build();\n-    JobDetail job = JobBuilder.newJob(DetectionPipelineJob.class).withIdentity(key).build();\n-    this.scheduler.scheduleJob(job, trigger);\n-    LOG.info(String.format(\"scheduled detection pipeline job %s.\", key.getName()));\n+  @Override\n+  public void startJob(AbstractBean config, JobKey key) throws SchedulerException {\n+    Trigger trigger = TriggerBuilder.newTrigger().withSchedule(\n+        CronScheduleBuilder.cronSchedule(((DetectionConfigBean) config).getCron())).build();\n+    JobDetail detectionJob = JobBuilder.newJob(DetectionPipelineJob.class).withIdentity(key).build();\n+\n+    this.scheduler.scheduleJob(detectionJob, trigger);\n+    LOG.info(String.format(\"scheduled detection pipeline job %s\", detectionJob.getKey().getName()));\n+\n+    // Data availability alerts will be scheduled only when enabled by the user.\n+    if (DetectionUtils.isDataAvailabilityCheckEnabled((DetectionConfigDTO) config)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "originalPosition": 150}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzk0MjA0Mw==", "bodyText": "In this PR yes. This PR is only addressing the availability of data for detection jobs. In the next phase, we will have a DataSLACronScheduler which will allow users to define custom SLAs independent of detection.\nUpdated description to reflect this.", "url": "https://github.com/apache/pinot/pull/5056#discussion_r377942043", "createdAt": "2020-02-11T22:38:20Z", "author": {"login": "akshayrai"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/scheduler/DetectionScheduler.java", "diffHunk": "@@ -120,34 +126,41 @@ public void run() {\n           LOG.error(\"Error removing job key {}\", jobKey);\n         }\n       }\n-\n     } catch (SchedulerException e) {\n       LOG.error(\"Error while scheduling detection pipeline\", e);\n     }\n   }\n \n-  private boolean jobUpdated(DetectionConfigDTO config, JobKey key) throws SchedulerException {\n-    List<Trigger> triggers = (List<Trigger>) scheduler.getTriggersOfJob(key);\n-    CronTrigger cronTrigger = (CronTrigger) triggers.get(0);\n-    String cronInSchedule = cronTrigger.getCronExpression();\n+  @Override\n+  public Set<JobKey> getScheduledJobs() throws SchedulerException {\n+    return this.scheduler.getJobKeys(GroupMatcher.jobGroupEquals(TaskConstants.TaskType.DETECTION.toString()));\n+  }\n \n-    if (!config.getCron().equals(cronInSchedule)) {\n-      LOG.info(\"Cron expression for detection pipeline {} has been changed from {}  to {}. \" + \"Restarting schedule\",\n-          config.getId(), cronInSchedule, config.getCron());\n-      return true;\n-    }\n-    return false;\n+  @Override\n+  public void shutdown() throws SchedulerException {\n+    AnomalyUtils.safelyShutdownExecutionService(executorService, this.getClass());\n+    scheduler.shutdown();\n   }\n \n-  private void startJob(DetectionConfigDTO config, JobKey key) throws SchedulerException {\n-    Trigger trigger =\n-        TriggerBuilder.newTrigger().withSchedule(CronScheduleBuilder.cronSchedule(config.getCron())).build();\n-    JobDetail job = JobBuilder.newJob(DetectionPipelineJob.class).withIdentity(key).build();\n-    this.scheduler.scheduleJob(job, trigger);\n-    LOG.info(String.format(\"scheduled detection pipeline job %s.\", key.getName()));\n+  @Override\n+  public void startJob(AbstractBean config, JobKey key) throws SchedulerException {\n+    Trigger trigger = TriggerBuilder.newTrigger().withSchedule(\n+        CronScheduleBuilder.cronSchedule(((DetectionConfigBean) config).getCron())).build();\n+    JobDetail detectionJob = JobBuilder.newJob(DetectionPipelineJob.class).withIdentity(key).build();\n+\n+    this.scheduler.scheduleJob(detectionJob, trigger);\n+    LOG.info(String.format(\"scheduled detection pipeline job %s\", detectionJob.getKey().getName()));\n+\n+    // Data availability alerts will be scheduled only when enabled by the user.\n+    if (DetectionUtils.isDataAvailabilityCheckEnabled((DetectionConfigDTO) config)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU2MTI0Ng=="}, "originalCommit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "originalPosition": 150}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyOTMwOTgzOnYy", "diffSide": "RIGHT", "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/detection/trigger/DataAvailabilityTaskScheduler.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QyMDoyMjo0MFrOFnJNzg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMVQyMjozOTozOFrOFobyXg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU4OTc3NA==", "bodyText": "Maybe we can rename it to something like detectionIdToLastTaskCreateTimeMap? Because I think watermark is also overloaded in the context.  \ud83d\ude42\nNot clear whether it's the detection last time stamp, task create time or the latest data point.", "url": "https://github.com/apache/pinot/pull/5056#discussion_r376589774", "createdAt": "2020-02-07T20:22:40Z", "author": {"login": "jihaozh"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/detection/trigger/DataAvailabilityTaskScheduler.java", "diffHunk": "@@ -74,7 +82,7 @@ public DataAvailabilityTaskScheduler(long delayInSec, long fallBackTimeInSec, lo\n     this.delayInSec = delayInSec;\n     this.fallBackTimeInSec = fallBackTimeInSec;\n     this.schedulingWindowInSec = schedulingWindowInSec;\n-    this.taskLastCreateTimeMap = new HashMap<>();\n+    this.detectionIdToWatermarkMap = new HashMap<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjYzNzU3Ng==", "bodyText": "+1\nThe only case that it stores watermark is when there is no task for the detection at all, which should be minor case.", "url": "https://github.com/apache/pinot/pull/5056#discussion_r376637576", "createdAt": "2020-02-07T22:28:45Z", "author": {"login": "vincentchenjl"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/detection/trigger/DataAvailabilityTaskScheduler.java", "diffHunk": "@@ -74,7 +82,7 @@ public DataAvailabilityTaskScheduler(long delayInSec, long fallBackTimeInSec, lo\n     this.delayInSec = delayInSec;\n     this.fallBackTimeInSec = fallBackTimeInSec;\n     this.schedulingWindowInSec = schedulingWindowInSec;\n-    this.taskLastCreateTimeMap = new HashMap<>();\n+    this.detectionIdToWatermarkMap = new HashMap<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU4OTc3NA=="}, "originalCommit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzk0MjYyMg==", "bodyText": "Done", "url": "https://github.com/apache/pinot/pull/5056#discussion_r377942622", "createdAt": "2020-02-11T22:39:38Z", "author": {"login": "akshayrai"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/detection/trigger/DataAvailabilityTaskScheduler.java", "diffHunk": "@@ -74,7 +82,7 @@ public DataAvailabilityTaskScheduler(long delayInSec, long fallBackTimeInSec, lo\n     this.delayInSec = delayInSec;\n     this.fallBackTimeInSec = fallBackTimeInSec;\n     this.schedulingWindowInSec = schedulingWindowInSec;\n-    this.taskLastCreateTimeMap = new HashMap<>();\n+    this.detectionIdToWatermarkMap = new HashMap<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU4OTc3NA=="}, "originalCommit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "originalPosition": 36}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyOTU3MDExOnYy", "diffSide": "RIGHT", "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/scheduler/DetectionScheduler.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QyMjowOTowOVrOFnLtww==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMlQwNTo1Njo1MlrOFoihgg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjYzMDcyMw==", "bodyText": "Does the availability task and the detection task share the same cron?", "url": "https://github.com/apache/pinot/pull/5056#discussion_r376630723", "createdAt": "2020-02-07T22:09:09Z", "author": {"login": "jihaozh"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/scheduler/DetectionScheduler.java", "diffHunk": "@@ -120,34 +126,41 @@ public void run() {\n           LOG.error(\"Error removing job key {}\", jobKey);\n         }\n       }\n-\n     } catch (SchedulerException e) {\n       LOG.error(\"Error while scheduling detection pipeline\", e);\n     }\n   }\n \n-  private boolean jobUpdated(DetectionConfigDTO config, JobKey key) throws SchedulerException {\n-    List<Trigger> triggers = (List<Trigger>) scheduler.getTriggersOfJob(key);\n-    CronTrigger cronTrigger = (CronTrigger) triggers.get(0);\n-    String cronInSchedule = cronTrigger.getCronExpression();\n+  @Override\n+  public Set<JobKey> getScheduledJobs() throws SchedulerException {\n+    return this.scheduler.getJobKeys(GroupMatcher.jobGroupEquals(TaskConstants.TaskType.DETECTION.toString()));\n+  }\n \n-    if (!config.getCron().equals(cronInSchedule)) {\n-      LOG.info(\"Cron expression for detection pipeline {} has been changed from {}  to {}. \" + \"Restarting schedule\",\n-          config.getId(), cronInSchedule, config.getCron());\n-      return true;\n-    }\n-    return false;\n+  @Override\n+  public void shutdown() throws SchedulerException {\n+    AnomalyUtils.safelyShutdownExecutionService(executorService, this.getClass());\n+    scheduler.shutdown();\n   }\n \n-  private void startJob(DetectionConfigDTO config, JobKey key) throws SchedulerException {\n-    Trigger trigger =\n-        TriggerBuilder.newTrigger().withSchedule(CronScheduleBuilder.cronSchedule(config.getCron())).build();\n-    JobDetail job = JobBuilder.newJob(DetectionPipelineJob.class).withIdentity(key).build();\n-    this.scheduler.scheduleJob(job, trigger);\n-    LOG.info(String.format(\"scheduled detection pipeline job %s.\", key.getName()));\n+  @Override\n+  public void startJob(AbstractBean config, JobKey key) throws SchedulerException {\n+    Trigger trigger = TriggerBuilder.newTrigger().withSchedule(\n+        CronScheduleBuilder.cronSchedule(((DetectionConfigBean) config).getCron())).build();\n+    JobDetail detectionJob = JobBuilder.newJob(DetectionPipelineJob.class).withIdentity(key).build();\n+\n+    this.scheduler.scheduleJob(detectionJob, trigger);\n+    LOG.info(String.format(\"scheduled detection pipeline job %s\", detectionJob.getKey().getName()));\n+\n+    // Data availability alerts will be scheduled only when enabled by the user.\n+    if (DetectionUtils.isDataAvailabilityCheckEnabled((DetectionConfigDTO) config)) {\n+      JobDetail dataAvailabilityJob = JobBuilder.newJob(DetectionDataAvailabilityJob.class).withIdentity(key).build();\n+      this.scheduler.scheduleJob(dataAvailabilityJob, trigger);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "originalPosition": 152}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzk0MzIzNA==", "bodyText": "Yes. This PR is only addressing the availability of data for detection jobs. In the next phase, we will have a DataSLACronScheduler which can have a different cron schedule.", "url": "https://github.com/apache/pinot/pull/5056#discussion_r377943234", "createdAt": "2020-02-11T22:41:05Z", "author": {"login": "akshayrai"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/scheduler/DetectionScheduler.java", "diffHunk": "@@ -120,34 +126,41 @@ public void run() {\n           LOG.error(\"Error removing job key {}\", jobKey);\n         }\n       }\n-\n     } catch (SchedulerException e) {\n       LOG.error(\"Error while scheduling detection pipeline\", e);\n     }\n   }\n \n-  private boolean jobUpdated(DetectionConfigDTO config, JobKey key) throws SchedulerException {\n-    List<Trigger> triggers = (List<Trigger>) scheduler.getTriggersOfJob(key);\n-    CronTrigger cronTrigger = (CronTrigger) triggers.get(0);\n-    String cronInSchedule = cronTrigger.getCronExpression();\n+  @Override\n+  public Set<JobKey> getScheduledJobs() throws SchedulerException {\n+    return this.scheduler.getJobKeys(GroupMatcher.jobGroupEquals(TaskConstants.TaskType.DETECTION.toString()));\n+  }\n \n-    if (!config.getCron().equals(cronInSchedule)) {\n-      LOG.info(\"Cron expression for detection pipeline {} has been changed from {}  to {}. \" + \"Restarting schedule\",\n-          config.getId(), cronInSchedule, config.getCron());\n-      return true;\n-    }\n-    return false;\n+  @Override\n+  public void shutdown() throws SchedulerException {\n+    AnomalyUtils.safelyShutdownExecutionService(executorService, this.getClass());\n+    scheduler.shutdown();\n   }\n \n-  private void startJob(DetectionConfigDTO config, JobKey key) throws SchedulerException {\n-    Trigger trigger =\n-        TriggerBuilder.newTrigger().withSchedule(CronScheduleBuilder.cronSchedule(config.getCron())).build();\n-    JobDetail job = JobBuilder.newJob(DetectionPipelineJob.class).withIdentity(key).build();\n-    this.scheduler.scheduleJob(job, trigger);\n-    LOG.info(String.format(\"scheduled detection pipeline job %s.\", key.getName()));\n+  @Override\n+  public void startJob(AbstractBean config, JobKey key) throws SchedulerException {\n+    Trigger trigger = TriggerBuilder.newTrigger().withSchedule(\n+        CronScheduleBuilder.cronSchedule(((DetectionConfigBean) config).getCron())).build();\n+    JobDetail detectionJob = JobBuilder.newJob(DetectionPipelineJob.class).withIdentity(key).build();\n+\n+    this.scheduler.scheduleJob(detectionJob, trigger);\n+    LOG.info(String.format(\"scheduled detection pipeline job %s\", detectionJob.getKey().getName()));\n+\n+    // Data availability alerts will be scheduled only when enabled by the user.\n+    if (DetectionUtils.isDataAvailabilityCheckEnabled((DetectionConfigDTO) config)) {\n+      JobDetail dataAvailabilityJob = JobBuilder.newJob(DetectionDataAvailabilityJob.class).withIdentity(key).build();\n+      this.scheduler.scheduleJob(dataAvailabilityJob, trigger);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjYzMDcyMw=="}, "originalCommit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "originalPosition": 152}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3ODA1Mjk5NA==", "bodyText": "DataAvailabilityScheduler should be used for it. Probably we don't need another scheduler.", "url": "https://github.com/apache/pinot/pull/5056#discussion_r378052994", "createdAt": "2020-02-12T05:56:52Z", "author": {"login": "xiaohui-sun"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/scheduler/DetectionScheduler.java", "diffHunk": "@@ -120,34 +126,41 @@ public void run() {\n           LOG.error(\"Error removing job key {}\", jobKey);\n         }\n       }\n-\n     } catch (SchedulerException e) {\n       LOG.error(\"Error while scheduling detection pipeline\", e);\n     }\n   }\n \n-  private boolean jobUpdated(DetectionConfigDTO config, JobKey key) throws SchedulerException {\n-    List<Trigger> triggers = (List<Trigger>) scheduler.getTriggersOfJob(key);\n-    CronTrigger cronTrigger = (CronTrigger) triggers.get(0);\n-    String cronInSchedule = cronTrigger.getCronExpression();\n+  @Override\n+  public Set<JobKey> getScheduledJobs() throws SchedulerException {\n+    return this.scheduler.getJobKeys(GroupMatcher.jobGroupEquals(TaskConstants.TaskType.DETECTION.toString()));\n+  }\n \n-    if (!config.getCron().equals(cronInSchedule)) {\n-      LOG.info(\"Cron expression for detection pipeline {} has been changed from {}  to {}. \" + \"Restarting schedule\",\n-          config.getId(), cronInSchedule, config.getCron());\n-      return true;\n-    }\n-    return false;\n+  @Override\n+  public void shutdown() throws SchedulerException {\n+    AnomalyUtils.safelyShutdownExecutionService(executorService, this.getClass());\n+    scheduler.shutdown();\n   }\n \n-  private void startJob(DetectionConfigDTO config, JobKey key) throws SchedulerException {\n-    Trigger trigger =\n-        TriggerBuilder.newTrigger().withSchedule(CronScheduleBuilder.cronSchedule(config.getCron())).build();\n-    JobDetail job = JobBuilder.newJob(DetectionPipelineJob.class).withIdentity(key).build();\n-    this.scheduler.scheduleJob(job, trigger);\n-    LOG.info(String.format(\"scheduled detection pipeline job %s.\", key.getName()));\n+  @Override\n+  public void startJob(AbstractBean config, JobKey key) throws SchedulerException {\n+    Trigger trigger = TriggerBuilder.newTrigger().withSchedule(\n+        CronScheduleBuilder.cronSchedule(((DetectionConfigBean) config).getCron())).build();\n+    JobDetail detectionJob = JobBuilder.newJob(DetectionPipelineJob.class).withIdentity(key).build();\n+\n+    this.scheduler.scheduleJob(detectionJob, trigger);\n+    LOG.info(String.format(\"scheduled detection pipeline job %s\", detectionJob.getKey().getName()));\n+\n+    // Data availability alerts will be scheduled only when enabled by the user.\n+    if (DetectionUtils.isDataAvailabilityCheckEnabled((DetectionConfigDTO) config)) {\n+      JobDetail dataAvailabilityJob = JobBuilder.newJob(DetectionDataAvailabilityJob.class).withIdentity(key).build();\n+      this.scheduler.scheduleJob(dataAvailabilityJob, trigger);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjYzMDcyMw=="}, "originalCommit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "originalPosition": 152}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyOTY1NjU0OnYy", "diffSide": "RIGHT", "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/detection/trigger/DataAvailabilityTaskScheduler.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QyMjo1MDoyMlrOFnMhcw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMVQyMzoyNzoxMlrOFoc4sw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjY0Mzk1NQ==", "bodyText": "Why this line is only executed whenDetectionUtils.isDataAvailabilityCheckEnabled(detectionConfig) is true?", "url": "https://github.com/apache/pinot/pull/5056#discussion_r376643955", "createdAt": "2020-02-07T22:50:22Z", "author": {"login": "vincentchenjl"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/detection/trigger/DataAvailabilityTaskScheduler.java", "diffHunk": "@@ -95,16 +103,30 @@ public void run() {\n           if (isAllDatasetUpdated(detectionConfig, detection2DatasetMap.get(detectionConfig), datasetConfigMap)) {\n             if (isWithinSchedulingWindow(detection2DatasetMap.get(detectionConfig), datasetConfigMap)) {\n               //TODO: additional check is required if detection is based on aggregated value across multiple data points\n-              createDetectionTask(detectionConfig);\n+              long endtime = System.currentTimeMillis();\n+              createDetectionTask(detectionConfig, endtime);\n+              detectionIdToWatermarkMap.put(detectionConfig.getId(), endtime);\n               ThirdeyeMetricsUtil.eventScheduledTaskCounter.inc();\n               taskCount++;\n             } else {\n               LOG.warn(\"Unable to schedule a task for {}, because it is out of scheduling window.\", detectionConfigId);\n             }\n           }\n+\n+          // Note: Fallback SLA & Data availability SLA are independent of each other.\n+          // For example, if an event doesn't arrive within 24 hours, do a fallback.\n+          // On the other hand, a user can setup an SLA alert if there is no data for 3 days.\n           if (needFallback(detectionConfig)) {\n             LOG.info(\"Scheduling a task for detection {} due to the fallback mechanism.\", detectionConfigId);\n-            createDetectionTask(detectionConfig);\n+            long endtime = System.currentTimeMillis();\n+            createDetectionTask(detectionConfig, endtime);\n+\n+            if (DetectionUtils.isDataAvailabilityCheckEnabled(detectionConfig)) {\n+              createDataAvailabilityTask(detectionConfig, endtime);\n+              LOG.info(\"Scheduling a task for data availability {} due to the fallback mechanism.\", detectionConfigId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzk2MDYyNw==", "bodyText": "This is a flag to enable/disable data sla checks.", "url": "https://github.com/apache/pinot/pull/5056#discussion_r377960627", "createdAt": "2020-02-11T23:27:12Z", "author": {"login": "akshayrai"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/detection/trigger/DataAvailabilityTaskScheduler.java", "diffHunk": "@@ -95,16 +103,30 @@ public void run() {\n           if (isAllDatasetUpdated(detectionConfig, detection2DatasetMap.get(detectionConfig), datasetConfigMap)) {\n             if (isWithinSchedulingWindow(detection2DatasetMap.get(detectionConfig), datasetConfigMap)) {\n               //TODO: additional check is required if detection is based on aggregated value across multiple data points\n-              createDetectionTask(detectionConfig);\n+              long endtime = System.currentTimeMillis();\n+              createDetectionTask(detectionConfig, endtime);\n+              detectionIdToWatermarkMap.put(detectionConfig.getId(), endtime);\n               ThirdeyeMetricsUtil.eventScheduledTaskCounter.inc();\n               taskCount++;\n             } else {\n               LOG.warn(\"Unable to schedule a task for {}, because it is out of scheduling window.\", detectionConfigId);\n             }\n           }\n+\n+          // Note: Fallback SLA & Data availability SLA are independent of each other.\n+          // For example, if an event doesn't arrive within 24 hours, do a fallback.\n+          // On the other hand, a user can setup an SLA alert if there is no data for 3 days.\n           if (needFallback(detectionConfig)) {\n             LOG.info(\"Scheduling a task for detection {} due to the fallback mechanism.\", detectionConfigId);\n-            createDetectionTask(detectionConfig);\n+            long endtime = System.currentTimeMillis();\n+            createDetectionTask(detectionConfig, endtime);\n+\n+            if (DetectionUtils.isDataAvailabilityCheckEnabled(detectionConfig)) {\n+              createDataAvailabilityTask(detectionConfig, endtime);\n+              LOG.info(\"Scheduling a task for data availability {} due to the fallback mechanism.\", detectionConfigId);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjY0Mzk1NQ=="}, "originalCommit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "originalPosition": 66}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyOTY5NDQ2OnYy", "diffSide": "RIGHT", "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/scheduler/ThirdEyeScheduler.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QyMzowODoxOFrOFnM3Kg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMVQyMjo0NzoyOFrOFob-9g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjY0OTUxNA==", "bodyText": "Should we can call it ThirdEyeCronScheduler to be more specific? I am not sure the interfaces defined here apply to any scheduler that listens to external events, data availability for instance. Even we can put the instance of Quatz scheuler here.", "url": "https://github.com/apache/pinot/pull/5056#discussion_r376649514", "createdAt": "2020-02-07T23:08:18Z", "author": {"login": "vincentchenjl"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/scheduler/ThirdEyeScheduler.java", "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ *\n+ *  * Licensed to the Apache Software Foundation (ASF) under one\n+ *  * or more contributor license agreements.  See the NOTICE file\n+ *  * distributed with this work for additional information\n+ *  * regarding copyright ownership.  The ASF licenses this file\n+ *  * to you under the Apache License, Version 2.0 (the\n+ *  * \"License\"); you may not use this file except in compliance\n+ *  * with the License.  You may obtain a copy of the License at\n+ *  *\n+ *  *   http://www.apache.org/licenses/LICENSE-2.0\n+ *  *\n+ *  * Unless required by applicable law or agreed to in writing,\n+ *  * software distributed under the License is distributed on an\n+ *  * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ *  * KIND, either express or implied.  See the License for the\n+ *  * specific language governing permissions and limitations\n+ *  * under the License.\n+ *\n+ *\n+ */\n+\n+package org.apache.pinot.thirdeye.scheduler;\n+\n+import java.util.Set;\n+import org.apache.pinot.thirdeye.datalayer.pojo.AbstractBean;\n+import org.quartz.JobKey;\n+import org.quartz.SchedulerException;\n+\n+\n+/**\n+ * Interface for ThirdEye's scheduling components\n+ */\n+public interface ThirdEyeScheduler extends Runnable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzk0NTg0Ng==", "bodyText": "Makes sense. Updated it.", "url": "https://github.com/apache/pinot/pull/5056#discussion_r377945846", "createdAt": "2020-02-11T22:47:28Z", "author": {"login": "akshayrai"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/scheduler/ThirdEyeScheduler.java", "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ *\n+ *  * Licensed to the Apache Software Foundation (ASF) under one\n+ *  * or more contributor license agreements.  See the NOTICE file\n+ *  * distributed with this work for additional information\n+ *  * regarding copyright ownership.  The ASF licenses this file\n+ *  * to you under the Apache License, Version 2.0 (the\n+ *  * \"License\"); you may not use this file except in compliance\n+ *  * with the License.  You may obtain a copy of the License at\n+ *  *\n+ *  *   http://www.apache.org/licenses/LICENSE-2.0\n+ *  *\n+ *  * Unless required by applicable law or agreed to in writing,\n+ *  * software distributed under the License is distributed on an\n+ *  * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ *  * KIND, either express or implied.  See the License for the\n+ *  * specific language governing permissions and limitations\n+ *  * under the License.\n+ *\n+ *\n+ */\n+\n+package org.apache.pinot.thirdeye.scheduler;\n+\n+import java.util.Set;\n+import org.apache.pinot.thirdeye.datalayer.pojo.AbstractBean;\n+import org.quartz.JobKey;\n+import org.quartz.SchedulerException;\n+\n+\n+/**\n+ * Interface for ThirdEye's scheduling components\n+ */\n+public interface ThirdEyeScheduler extends Runnable {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjY0OTUxNA=="}, "originalCommit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "originalPosition": 34}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3435, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}