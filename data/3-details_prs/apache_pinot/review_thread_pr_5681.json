{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQ3MzA1ODM5", "number": 5681, "reviewThreads": {"totalCount": 18, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxODoxOToyMlrOEN70kg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QyMjo1ODo1MlrOEOCE6Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzMDQ3MDU4OnYy", "diffSide": "RIGHT", "path": "pinot-core/src/main/java/org/apache/pinot/core/data/recordtransformer/ExpressionTransformer.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxODoxOToyMlrOGw0Swg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxODoxOToyMlrOGw0Swg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg0MTYwMg==", "bodyText": "(nit) Let's put tableConfig in front of schema", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453841602", "createdAt": "2020-07-13T18:19:22Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/data/recordtransformer/ExpressionTransformer.java", "diffHunk": "@@ -36,12 +38,19 @@\n \n   private final Map<String, FunctionEvaluator> _expressionEvaluators = new HashMap<>();\n \n-  public ExpressionTransformer(Schema schema) {\n+  public ExpressionTransformer(Schema schema, TableConfig tableConfig) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0fc85a2dcea04a6d5448bb92cff68b7e00c36548"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzMDQ4OTkyOnYy", "diffSide": "RIGHT", "path": "pinot-core/src/main/java/org/apache/pinot/core/util/TableConfigUtils.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxODoyNDo0NlrOGw0evQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QyMzozODoyMlrOGw-hVA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg0NDY2OQ==", "bodyText": "This will have conflict with #5667. Let's figure out the sequence of merging these 2 PRs", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453844669", "createdAt": "2020-07-13T18:24:46Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/util/TableConfigUtils.java", "diffHunk": "@@ -0,0 +1,145 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.util;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import javax.annotation.Nullable;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.core.data.function.FunctionEvaluator;\n+import org.apache.pinot.core.data.function.FunctionEvaluatorFactory;\n+import org.apache.pinot.spi.config.table.FieldConfig;\n+import org.apache.pinot.spi.config.table.IngestionConfig;\n+import org.apache.pinot.spi.config.table.SegmentsValidationAndRetentionConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.TableType;\n+import org.apache.pinot.spi.config.table.ingestion.FilterConfig;\n+import org.apache.pinot.spi.config.table.ingestion.TransformConfig;\n+\n+\n+/**\n+ * Utils related to table config operations\n+ * FIXME: Merge this TableConfigUtils with the TableConfigUtils from pinot-common when merging of modules is done\n+ */\n+public final class TableConfigUtils {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0fc85a2dcea04a6d5448bb92cff68b7e00c36548"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDAwOTE3Mg==", "bodyText": "I am yet to address a few comments on mine. Will do by EOD. This one can go first and I will rebase.", "url": "https://github.com/apache/pinot/pull/5681#discussion_r454009172", "createdAt": "2020-07-13T23:38:22Z", "author": {"login": "siddharthteotia"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/util/TableConfigUtils.java", "diffHunk": "@@ -0,0 +1,145 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.util;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import javax.annotation.Nullable;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.core.data.function.FunctionEvaluator;\n+import org.apache.pinot.core.data.function.FunctionEvaluatorFactory;\n+import org.apache.pinot.spi.config.table.FieldConfig;\n+import org.apache.pinot.spi.config.table.IngestionConfig;\n+import org.apache.pinot.spi.config.table.SegmentsValidationAndRetentionConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.TableType;\n+import org.apache.pinot.spi.config.table.ingestion.FilterConfig;\n+import org.apache.pinot.spi.config.table.ingestion.TransformConfig;\n+\n+\n+/**\n+ * Utils related to table config operations\n+ * FIXME: Merge this TableConfigUtils with the TableConfigUtils from pinot-common when merging of modules is done\n+ */\n+public final class TableConfigUtils {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg0NDY2OQ=="}, "originalCommit": {"oid": "0fc85a2dcea04a6d5448bb92cff68b7e00c36548"}, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzMDQ5MzcxOnYy", "diffSide": "RIGHT", "path": "pinot-core/src/main/java/org/apache/pinot/core/util/IngestionUtils.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxODoyNTo0NFrOGw0hGQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QyMjoyNjozNFrOGw8tKw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg0NTI3Mw==", "bodyText": "Please comment on why we extract both input and output column", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453845273", "createdAt": "2020-07-13T18:25:44Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/util/IngestionUtils.java", "diffHunk": "@@ -67,12 +70,24 @@ private static void extractFieldsFromSchema(Schema schema, Set<String> fields) {\n    * Extracts the fields needed by a RecordExtractor from given {@link IngestionConfig}\n    */\n   private static void extractFieldsFromIngestionConfig(@Nullable IngestionConfig ingestionConfig, Set<String> fields) {\n-    if (ingestionConfig != null && ingestionConfig.getFilterConfig() != null) {\n-      String filterFunction = ingestionConfig.getFilterConfig().getFilterFunction();\n-      if (filterFunction != null) {\n-        FunctionEvaluator functionEvaluator = FunctionEvaluatorFactory.getExpressionEvaluator(filterFunction);\n-        if (functionEvaluator != null) {\n-          fields.addAll(functionEvaluator.getArguments());\n+    if (ingestionConfig != null) {\n+      FilterConfig filterConfig = ingestionConfig.getFilterConfig();\n+      if (filterConfig != null) {\n+        String filterFunction = filterConfig.getFilterFunction();\n+        if (filterFunction != null) {\n+          FunctionEvaluator functionEvaluator = FunctionEvaluatorFactory.getExpressionEvaluator(filterFunction);\n+          if (functionEvaluator != null) {\n+            fields.addAll(functionEvaluator.getArguments());\n+          }\n+        }\n+      }\n+      List<TransformConfig> transformConfigs = ingestionConfig.getTransformConfigs();\n+      if (transformConfigs != null) {\n+        for (TransformConfig transformConfig : transformConfigs) {\n+          FunctionEvaluator expressionEvaluator =\n+              FunctionEvaluatorFactory.getExpressionEvaluator(transformConfig.getTransformFunction());\n+          fields.addAll(expressionEvaluator.getArguments());\n+          fields.add(transformConfig.getColumnName());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0fc85a2dcea04a6d5448bb92cff68b7e00c36548"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk3OTQzNQ==", "bodyText": "if transformation is already done at source, this ensures we avoid doing it again. This behavior is being carried over from previous behavior when it used to be in schema.\nAdded a comment too", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453979435", "createdAt": "2020-07-13T22:26:34Z", "author": {"login": "npawar"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/util/IngestionUtils.java", "diffHunk": "@@ -67,12 +70,24 @@ private static void extractFieldsFromSchema(Schema schema, Set<String> fields) {\n    * Extracts the fields needed by a RecordExtractor from given {@link IngestionConfig}\n    */\n   private static void extractFieldsFromIngestionConfig(@Nullable IngestionConfig ingestionConfig, Set<String> fields) {\n-    if (ingestionConfig != null && ingestionConfig.getFilterConfig() != null) {\n-      String filterFunction = ingestionConfig.getFilterConfig().getFilterFunction();\n-      if (filterFunction != null) {\n-        FunctionEvaluator functionEvaluator = FunctionEvaluatorFactory.getExpressionEvaluator(filterFunction);\n-        if (functionEvaluator != null) {\n-          fields.addAll(functionEvaluator.getArguments());\n+    if (ingestionConfig != null) {\n+      FilterConfig filterConfig = ingestionConfig.getFilterConfig();\n+      if (filterConfig != null) {\n+        String filterFunction = filterConfig.getFilterFunction();\n+        if (filterFunction != null) {\n+          FunctionEvaluator functionEvaluator = FunctionEvaluatorFactory.getExpressionEvaluator(filterFunction);\n+          if (functionEvaluator != null) {\n+            fields.addAll(functionEvaluator.getArguments());\n+          }\n+        }\n+      }\n+      List<TransformConfig> transformConfigs = ingestionConfig.getTransformConfigs();\n+      if (transformConfigs != null) {\n+        for (TransformConfig transformConfig : transformConfigs) {\n+          FunctionEvaluator expressionEvaluator =\n+              FunctionEvaluatorFactory.getExpressionEvaluator(transformConfig.getTransformFunction());\n+          fields.addAll(expressionEvaluator.getArguments());\n+          fields.add(transformConfig.getColumnName());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg0NTI3Mw=="}, "originalCommit": {"oid": "0fc85a2dcea04a6d5448bb92cff68b7e00c36548"}, "originalPosition": 42}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzMDUwMzY2OnYy", "diffSide": "RIGHT", "path": "pinot-core/src/main/java/org/apache/pinot/core/util/TableConfigUtils.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxODoyODoxM1rOGw0nEw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxODoyODoxM1rOGw0nEw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg0NjgwMw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                      if (transformColumns.contains(columnName)) {\n          \n          \n            \n                        throw new IllegalStateException(\"Duplicate transform config found for column '\" + columnName + \"'\");\n          \n          \n            \n                      }\n          \n          \n            \n                      transformColumns.add(columnName);\n          \n          \n            \n                      if (!transformColumns.add(columnName)) {\n          \n          \n            \n                        throw new IllegalStateException(\"Duplicate transform config found for column '\" + columnName + \"'\");\n          \n          \n            \n                      }", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453846803", "createdAt": "2020-07-13T18:28:13Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/util/TableConfigUtils.java", "diffHunk": "@@ -0,0 +1,145 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.util;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import javax.annotation.Nullable;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.core.data.function.FunctionEvaluator;\n+import org.apache.pinot.core.data.function.FunctionEvaluatorFactory;\n+import org.apache.pinot.spi.config.table.FieldConfig;\n+import org.apache.pinot.spi.config.table.IngestionConfig;\n+import org.apache.pinot.spi.config.table.SegmentsValidationAndRetentionConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.TableType;\n+import org.apache.pinot.spi.config.table.ingestion.FilterConfig;\n+import org.apache.pinot.spi.config.table.ingestion.TransformConfig;\n+\n+\n+/**\n+ * Utils related to table config operations\n+ * FIXME: Merge this TableConfigUtils with the TableConfigUtils from pinot-common when merging of modules is done\n+ */\n+public final class TableConfigUtils {\n+\n+  private TableConfigUtils() {\n+\n+  }\n+\n+  /**\n+   * Validates the table config with the following rules:\n+   * <ul>\n+   *   <li>Text index column must be raw</li>\n+   *   <li>peerSegmentDownloadScheme in ValidationConfig must be http or https</li>\n+   * </ul>\n+   */\n+  public static void validate(TableConfig tableConfig) {\n+    validateFieldConfigList(tableConfig);\n+    validateValidationConfig(tableConfig);\n+    validateIngestionConfig(tableConfig.getIngestionConfig());\n+  }\n+\n+  private static void validateFieldConfigList(TableConfig tableConfig) {\n+    List<FieldConfig> fieldConfigList = tableConfig.getFieldConfigList();\n+    if (fieldConfigList != null) {\n+      List<String> noDictionaryColumns = tableConfig.getIndexingConfig().getNoDictionaryColumns();\n+      for (FieldConfig fieldConfig : fieldConfigList) {\n+        if (fieldConfig.getIndexType() == FieldConfig.IndexType.TEXT) {\n+          // For Text index column, it must be raw (no-dictionary)\n+          // NOTE: Check both encodingType and noDictionaryColumns before migrating indexing configs into field configs\n+          String column = fieldConfig.getName();\n+          if (fieldConfig.getEncodingType() != FieldConfig.EncodingType.RAW || noDictionaryColumns == null\n+              || !noDictionaryColumns.contains(column)) {\n+            throw new IllegalStateException(\n+                \"Text index column: \" + column + \" must be raw (no-dictionary) in both FieldConfig and IndexingConfig\");\n+          }\n+        }\n+      }\n+    }\n+  }\n+\n+  private static void validateValidationConfig(TableConfig tableConfig) {\n+    SegmentsValidationAndRetentionConfig validationConfig = tableConfig.getValidationConfig();\n+    if (validationConfig != null) {\n+      if (tableConfig.getTableType() == TableType.REALTIME && validationConfig.getTimeColumnName() == null) {\n+        throw new IllegalStateException(\"Must provide time column in real-time table config\");\n+      }\n+      String peerSegmentDownloadScheme = validationConfig.getPeerSegmentDownloadScheme();\n+      if (peerSegmentDownloadScheme != null) {\n+        if (!CommonConstants.HTTP_PROTOCOL.equalsIgnoreCase(peerSegmentDownloadScheme) && !CommonConstants.HTTPS_PROTOCOL.equalsIgnoreCase(peerSegmentDownloadScheme)) {\n+          throw new IllegalStateException(\"Invalid value '\" + peerSegmentDownloadScheme + \"' for peerSegmentDownloadScheme. Must be one of http nor https\" );\n+        }\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Validates the following:\n+   * 1. validity of filter function\n+   * 2. checks for duplicate transform configs\n+   * 3. checks for null column name or transform function in transform config\n+   * 4. validity of transform function string\n+   * 5. checks for source fields used in destination columns\n+   */\n+  private static void validateIngestionConfig(@Nullable IngestionConfig ingestionConfig) {\n+    if (ingestionConfig != null) {\n+      FilterConfig filterConfig = ingestionConfig.getFilterConfig();\n+      if (filterConfig != null) {\n+        String filterFunction = filterConfig.getFilterFunction();\n+        if (filterFunction != null) {\n+          try {\n+            FunctionEvaluatorFactory.getExpressionEvaluator(filterFunction);\n+          } catch (Exception e) {\n+            throw new IllegalStateException(\"Invalid filter function \" + filterFunction, e);\n+          }\n+        }\n+      }\n+      List<TransformConfig> transformConfigs = ingestionConfig.getTransformConfigs();\n+      if (transformConfigs != null) {\n+        Set<String> transformColumns = new HashSet<>();\n+        for (TransformConfig transformConfig : transformConfigs) {\n+          String columnName = transformConfig.getColumnName();\n+          if (transformColumns.contains(columnName)) {\n+            throw new IllegalStateException(\"Duplicate transform config found for column '\" + columnName + \"'\");\n+          }\n+          transformColumns.add(columnName);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0fc85a2dcea04a6d5448bb92cff68b7e00c36548"}, "originalPosition": 123}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzMDUwODU5OnYy", "diffSide": "RIGHT", "path": "pinot-core/src/main/java/org/apache/pinot/core/util/TableConfigUtils.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxODoyOToyMlrOGw0qKQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxODoyOToyMlrOGw0qKQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg0NzU5Mw==", "bodyText": "Perform null check before the set check", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453847593", "createdAt": "2020-07-13T18:29:22Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/util/TableConfigUtils.java", "diffHunk": "@@ -0,0 +1,145 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.util;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import javax.annotation.Nullable;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.core.data.function.FunctionEvaluator;\n+import org.apache.pinot.core.data.function.FunctionEvaluatorFactory;\n+import org.apache.pinot.spi.config.table.FieldConfig;\n+import org.apache.pinot.spi.config.table.IngestionConfig;\n+import org.apache.pinot.spi.config.table.SegmentsValidationAndRetentionConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.TableType;\n+import org.apache.pinot.spi.config.table.ingestion.FilterConfig;\n+import org.apache.pinot.spi.config.table.ingestion.TransformConfig;\n+\n+\n+/**\n+ * Utils related to table config operations\n+ * FIXME: Merge this TableConfigUtils with the TableConfigUtils from pinot-common when merging of modules is done\n+ */\n+public final class TableConfigUtils {\n+\n+  private TableConfigUtils() {\n+\n+  }\n+\n+  /**\n+   * Validates the table config with the following rules:\n+   * <ul>\n+   *   <li>Text index column must be raw</li>\n+   *   <li>peerSegmentDownloadScheme in ValidationConfig must be http or https</li>\n+   * </ul>\n+   */\n+  public static void validate(TableConfig tableConfig) {\n+    validateFieldConfigList(tableConfig);\n+    validateValidationConfig(tableConfig);\n+    validateIngestionConfig(tableConfig.getIngestionConfig());\n+  }\n+\n+  private static void validateFieldConfigList(TableConfig tableConfig) {\n+    List<FieldConfig> fieldConfigList = tableConfig.getFieldConfigList();\n+    if (fieldConfigList != null) {\n+      List<String> noDictionaryColumns = tableConfig.getIndexingConfig().getNoDictionaryColumns();\n+      for (FieldConfig fieldConfig : fieldConfigList) {\n+        if (fieldConfig.getIndexType() == FieldConfig.IndexType.TEXT) {\n+          // For Text index column, it must be raw (no-dictionary)\n+          // NOTE: Check both encodingType and noDictionaryColumns before migrating indexing configs into field configs\n+          String column = fieldConfig.getName();\n+          if (fieldConfig.getEncodingType() != FieldConfig.EncodingType.RAW || noDictionaryColumns == null\n+              || !noDictionaryColumns.contains(column)) {\n+            throw new IllegalStateException(\n+                \"Text index column: \" + column + \" must be raw (no-dictionary) in both FieldConfig and IndexingConfig\");\n+          }\n+        }\n+      }\n+    }\n+  }\n+\n+  private static void validateValidationConfig(TableConfig tableConfig) {\n+    SegmentsValidationAndRetentionConfig validationConfig = tableConfig.getValidationConfig();\n+    if (validationConfig != null) {\n+      if (tableConfig.getTableType() == TableType.REALTIME && validationConfig.getTimeColumnName() == null) {\n+        throw new IllegalStateException(\"Must provide time column in real-time table config\");\n+      }\n+      String peerSegmentDownloadScheme = validationConfig.getPeerSegmentDownloadScheme();\n+      if (peerSegmentDownloadScheme != null) {\n+        if (!CommonConstants.HTTP_PROTOCOL.equalsIgnoreCase(peerSegmentDownloadScheme) && !CommonConstants.HTTPS_PROTOCOL.equalsIgnoreCase(peerSegmentDownloadScheme)) {\n+          throw new IllegalStateException(\"Invalid value '\" + peerSegmentDownloadScheme + \"' for peerSegmentDownloadScheme. Must be one of http nor https\" );\n+        }\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Validates the following:\n+   * 1. validity of filter function\n+   * 2. checks for duplicate transform configs\n+   * 3. checks for null column name or transform function in transform config\n+   * 4. validity of transform function string\n+   * 5. checks for source fields used in destination columns\n+   */\n+  private static void validateIngestionConfig(@Nullable IngestionConfig ingestionConfig) {\n+    if (ingestionConfig != null) {\n+      FilterConfig filterConfig = ingestionConfig.getFilterConfig();\n+      if (filterConfig != null) {\n+        String filterFunction = filterConfig.getFilterFunction();\n+        if (filterFunction != null) {\n+          try {\n+            FunctionEvaluatorFactory.getExpressionEvaluator(filterFunction);\n+          } catch (Exception e) {\n+            throw new IllegalStateException(\"Invalid filter function \" + filterFunction, e);\n+          }\n+        }\n+      }\n+      List<TransformConfig> transformConfigs = ingestionConfig.getTransformConfigs();\n+      if (transformConfigs != null) {\n+        Set<String> transformColumns = new HashSet<>();\n+        for (TransformConfig transformConfig : transformConfigs) {\n+          String columnName = transformConfig.getColumnName();\n+          if (transformColumns.contains(columnName)) {\n+            throw new IllegalStateException(\"Duplicate transform config found for column '\" + columnName + \"'\");\n+          }\n+          transformColumns.add(columnName);\n+          String transformFunction = transformConfig.getTransformFunction();\n+          if (columnName == null || transformFunction == null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0fc85a2dcea04a6d5448bb92cff68b7e00c36548"}, "originalPosition": 125}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzMDUxNzA2OnYy", "diffSide": "RIGHT", "path": "pinot-core/src/main/java/org/apache/pinot/core/util/TableConfigUtils.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxODozMTozMlrOGw0vYw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QyMjoyNzoyNFrOGw8u-A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg0ODkzMQ==", "bodyText": "Should we check that arguments are not contained in the transformColumns? We do not support chained transforms currently", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453848931", "createdAt": "2020-07-13T18:31:32Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/util/TableConfigUtils.java", "diffHunk": "@@ -0,0 +1,145 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.util;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import javax.annotation.Nullable;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.core.data.function.FunctionEvaluator;\n+import org.apache.pinot.core.data.function.FunctionEvaluatorFactory;\n+import org.apache.pinot.spi.config.table.FieldConfig;\n+import org.apache.pinot.spi.config.table.IngestionConfig;\n+import org.apache.pinot.spi.config.table.SegmentsValidationAndRetentionConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.TableType;\n+import org.apache.pinot.spi.config.table.ingestion.FilterConfig;\n+import org.apache.pinot.spi.config.table.ingestion.TransformConfig;\n+\n+\n+/**\n+ * Utils related to table config operations\n+ * FIXME: Merge this TableConfigUtils with the TableConfigUtils from pinot-common when merging of modules is done\n+ */\n+public final class TableConfigUtils {\n+\n+  private TableConfigUtils() {\n+\n+  }\n+\n+  /**\n+   * Validates the table config with the following rules:\n+   * <ul>\n+   *   <li>Text index column must be raw</li>\n+   *   <li>peerSegmentDownloadScheme in ValidationConfig must be http or https</li>\n+   * </ul>\n+   */\n+  public static void validate(TableConfig tableConfig) {\n+    validateFieldConfigList(tableConfig);\n+    validateValidationConfig(tableConfig);\n+    validateIngestionConfig(tableConfig.getIngestionConfig());\n+  }\n+\n+  private static void validateFieldConfigList(TableConfig tableConfig) {\n+    List<FieldConfig> fieldConfigList = tableConfig.getFieldConfigList();\n+    if (fieldConfigList != null) {\n+      List<String> noDictionaryColumns = tableConfig.getIndexingConfig().getNoDictionaryColumns();\n+      for (FieldConfig fieldConfig : fieldConfigList) {\n+        if (fieldConfig.getIndexType() == FieldConfig.IndexType.TEXT) {\n+          // For Text index column, it must be raw (no-dictionary)\n+          // NOTE: Check both encodingType and noDictionaryColumns before migrating indexing configs into field configs\n+          String column = fieldConfig.getName();\n+          if (fieldConfig.getEncodingType() != FieldConfig.EncodingType.RAW || noDictionaryColumns == null\n+              || !noDictionaryColumns.contains(column)) {\n+            throw new IllegalStateException(\n+                \"Text index column: \" + column + \" must be raw (no-dictionary) in both FieldConfig and IndexingConfig\");\n+          }\n+        }\n+      }\n+    }\n+  }\n+\n+  private static void validateValidationConfig(TableConfig tableConfig) {\n+    SegmentsValidationAndRetentionConfig validationConfig = tableConfig.getValidationConfig();\n+    if (validationConfig != null) {\n+      if (tableConfig.getTableType() == TableType.REALTIME && validationConfig.getTimeColumnName() == null) {\n+        throw new IllegalStateException(\"Must provide time column in real-time table config\");\n+      }\n+      String peerSegmentDownloadScheme = validationConfig.getPeerSegmentDownloadScheme();\n+      if (peerSegmentDownloadScheme != null) {\n+        if (!CommonConstants.HTTP_PROTOCOL.equalsIgnoreCase(peerSegmentDownloadScheme) && !CommonConstants.HTTPS_PROTOCOL.equalsIgnoreCase(peerSegmentDownloadScheme)) {\n+          throw new IllegalStateException(\"Invalid value '\" + peerSegmentDownloadScheme + \"' for peerSegmentDownloadScheme. Must be one of http nor https\" );\n+        }\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Validates the following:\n+   * 1. validity of filter function\n+   * 2. checks for duplicate transform configs\n+   * 3. checks for null column name or transform function in transform config\n+   * 4. validity of transform function string\n+   * 5. checks for source fields used in destination columns\n+   */\n+  private static void validateIngestionConfig(@Nullable IngestionConfig ingestionConfig) {\n+    if (ingestionConfig != null) {\n+      FilterConfig filterConfig = ingestionConfig.getFilterConfig();\n+      if (filterConfig != null) {\n+        String filterFunction = filterConfig.getFilterFunction();\n+        if (filterFunction != null) {\n+          try {\n+            FunctionEvaluatorFactory.getExpressionEvaluator(filterFunction);\n+          } catch (Exception e) {\n+            throw new IllegalStateException(\"Invalid filter function \" + filterFunction, e);\n+          }\n+        }\n+      }\n+      List<TransformConfig> transformConfigs = ingestionConfig.getTransformConfigs();\n+      if (transformConfigs != null) {\n+        Set<String> transformColumns = new HashSet<>();\n+        for (TransformConfig transformConfig : transformConfigs) {\n+          String columnName = transformConfig.getColumnName();\n+          if (transformColumns.contains(columnName)) {\n+            throw new IllegalStateException(\"Duplicate transform config found for column '\" + columnName + \"'\");\n+          }\n+          transformColumns.add(columnName);\n+          String transformFunction = transformConfig.getTransformFunction();\n+          if (columnName == null || transformFunction == null) {\n+            throw new IllegalStateException(\"columnName/transformFunction cannot be null in TransformConfig \" + transformConfig);\n+          }\n+          FunctionEvaluator expressionEvaluator;\n+          try {\n+            expressionEvaluator = FunctionEvaluatorFactory.getExpressionEvaluator(transformFunction);\n+          } catch (Exception e) {\n+            throw new IllegalStateException(\n+                \"Invalid transform function '\" + transformFunction + \"' for column '\" + columnName + \"'\");\n+          }\n+          List<String> arguments = expressionEvaluator.getArguments();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0fc85a2dcea04a6d5448bb92cff68b7e00c36548"}, "originalPosition": 135}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk3OTg5Ng==", "bodyText": "yes sounds good. added", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453979896", "createdAt": "2020-07-13T22:27:24Z", "author": {"login": "npawar"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/util/TableConfigUtils.java", "diffHunk": "@@ -0,0 +1,145 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.util;\n+\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import javax.annotation.Nullable;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.core.data.function.FunctionEvaluator;\n+import org.apache.pinot.core.data.function.FunctionEvaluatorFactory;\n+import org.apache.pinot.spi.config.table.FieldConfig;\n+import org.apache.pinot.spi.config.table.IngestionConfig;\n+import org.apache.pinot.spi.config.table.SegmentsValidationAndRetentionConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.TableType;\n+import org.apache.pinot.spi.config.table.ingestion.FilterConfig;\n+import org.apache.pinot.spi.config.table.ingestion.TransformConfig;\n+\n+\n+/**\n+ * Utils related to table config operations\n+ * FIXME: Merge this TableConfigUtils with the TableConfigUtils from pinot-common when merging of modules is done\n+ */\n+public final class TableConfigUtils {\n+\n+  private TableConfigUtils() {\n+\n+  }\n+\n+  /**\n+   * Validates the table config with the following rules:\n+   * <ul>\n+   *   <li>Text index column must be raw</li>\n+   *   <li>peerSegmentDownloadScheme in ValidationConfig must be http or https</li>\n+   * </ul>\n+   */\n+  public static void validate(TableConfig tableConfig) {\n+    validateFieldConfigList(tableConfig);\n+    validateValidationConfig(tableConfig);\n+    validateIngestionConfig(tableConfig.getIngestionConfig());\n+  }\n+\n+  private static void validateFieldConfigList(TableConfig tableConfig) {\n+    List<FieldConfig> fieldConfigList = tableConfig.getFieldConfigList();\n+    if (fieldConfigList != null) {\n+      List<String> noDictionaryColumns = tableConfig.getIndexingConfig().getNoDictionaryColumns();\n+      for (FieldConfig fieldConfig : fieldConfigList) {\n+        if (fieldConfig.getIndexType() == FieldConfig.IndexType.TEXT) {\n+          // For Text index column, it must be raw (no-dictionary)\n+          // NOTE: Check both encodingType and noDictionaryColumns before migrating indexing configs into field configs\n+          String column = fieldConfig.getName();\n+          if (fieldConfig.getEncodingType() != FieldConfig.EncodingType.RAW || noDictionaryColumns == null\n+              || !noDictionaryColumns.contains(column)) {\n+            throw new IllegalStateException(\n+                \"Text index column: \" + column + \" must be raw (no-dictionary) in both FieldConfig and IndexingConfig\");\n+          }\n+        }\n+      }\n+    }\n+  }\n+\n+  private static void validateValidationConfig(TableConfig tableConfig) {\n+    SegmentsValidationAndRetentionConfig validationConfig = tableConfig.getValidationConfig();\n+    if (validationConfig != null) {\n+      if (tableConfig.getTableType() == TableType.REALTIME && validationConfig.getTimeColumnName() == null) {\n+        throw new IllegalStateException(\"Must provide time column in real-time table config\");\n+      }\n+      String peerSegmentDownloadScheme = validationConfig.getPeerSegmentDownloadScheme();\n+      if (peerSegmentDownloadScheme != null) {\n+        if (!CommonConstants.HTTP_PROTOCOL.equalsIgnoreCase(peerSegmentDownloadScheme) && !CommonConstants.HTTPS_PROTOCOL.equalsIgnoreCase(peerSegmentDownloadScheme)) {\n+          throw new IllegalStateException(\"Invalid value '\" + peerSegmentDownloadScheme + \"' for peerSegmentDownloadScheme. Must be one of http nor https\" );\n+        }\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Validates the following:\n+   * 1. validity of filter function\n+   * 2. checks for duplicate transform configs\n+   * 3. checks for null column name or transform function in transform config\n+   * 4. validity of transform function string\n+   * 5. checks for source fields used in destination columns\n+   */\n+  private static void validateIngestionConfig(@Nullable IngestionConfig ingestionConfig) {\n+    if (ingestionConfig != null) {\n+      FilterConfig filterConfig = ingestionConfig.getFilterConfig();\n+      if (filterConfig != null) {\n+        String filterFunction = filterConfig.getFilterFunction();\n+        if (filterFunction != null) {\n+          try {\n+            FunctionEvaluatorFactory.getExpressionEvaluator(filterFunction);\n+          } catch (Exception e) {\n+            throw new IllegalStateException(\"Invalid filter function \" + filterFunction, e);\n+          }\n+        }\n+      }\n+      List<TransformConfig> transformConfigs = ingestionConfig.getTransformConfigs();\n+      if (transformConfigs != null) {\n+        Set<String> transformColumns = new HashSet<>();\n+        for (TransformConfig transformConfig : transformConfigs) {\n+          String columnName = transformConfig.getColumnName();\n+          if (transformColumns.contains(columnName)) {\n+            throw new IllegalStateException(\"Duplicate transform config found for column '\" + columnName + \"'\");\n+          }\n+          transformColumns.add(columnName);\n+          String transformFunction = transformConfig.getTransformFunction();\n+          if (columnName == null || transformFunction == null) {\n+            throw new IllegalStateException(\"columnName/transformFunction cannot be null in TransformConfig \" + transformConfig);\n+          }\n+          FunctionEvaluator expressionEvaluator;\n+          try {\n+            expressionEvaluator = FunctionEvaluatorFactory.getExpressionEvaluator(transformFunction);\n+          } catch (Exception e) {\n+            throw new IllegalStateException(\n+                \"Invalid transform function '\" + transformFunction + \"' for column '\" + columnName + \"'\");\n+          }\n+          List<String> arguments = expressionEvaluator.getArguments();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg0ODkzMQ=="}, "originalCommit": {"oid": "0fc85a2dcea04a6d5448bb92cff68b7e00c36548"}, "originalPosition": 135}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzMDUzOTI4OnYy", "diffSide": "RIGHT", "path": "pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/Temp.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxODozNzoyNFrOGw09Ag==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxODozNzoyNFrOGw09Ag==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg1MjQxOA==", "bodyText": "Remove this class", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453852418", "createdAt": "2020-07-13T18:37:24Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/Temp.java", "diffHunk": "@@ -0,0 +1,224 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.integration.tests;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.node.ArrayNode;\n+import java.io.File;\n+import java.io.FileNotFoundException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.commons.io.FileUtils;\n+import org.apache.pinot.controller.ControllerConf;\n+import org.apache.pinot.spi.config.table.IngestionConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.ingestion.FilterConfig;\n+import org.apache.pinot.spi.config.table.ingestion.TransformConfig;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.util.TestUtils;\n+import org.testng.Assert;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+\n+import static org.testng.Assert.assertEquals;\n+import static org.testng.Assert.assertTrue;\n+\n+\n+/**\n+ * Hybrid cluster integration test that uses one of the DateTimeFieldSpec as primary time column\n+ */\n+public class Temp extends BaseClusterIntegrationTest {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0fc85a2dcea04a6d5448bb92cff68b7e00c36548"}, "originalPosition": 47}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzMDU0MzQ5OnYy", "diffSide": "RIGHT", "path": "pinot-integration-tests/src/test/resources/On_Time_On_Time_Performance_2014_100k_subset_nonulls_ingestion_config.schema", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxODozODo0MFrOGw0_0A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QyMjoyODozMVrOGw8x4A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg1MzEzNg==", "bodyText": "Why do we need this new schema?", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453853136", "createdAt": "2020-07-13T18:38:40Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-integration-tests/src/test/resources/On_Time_On_Time_Performance_2014_100k_subset_nonulls_ingestion_config.schema", "diffHunk": "@@ -0,0 +1,342 @@\n+{", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0fc85a2dcea04a6d5448bb92cff68b7e00c36548"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk4MDY0MA==", "bodyText": "schema contains some fields which are not in the source data. I preferred adding a new file instead of putting it directly in the test file. But changed it now to override createSchema", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453980640", "createdAt": "2020-07-13T22:28:31Z", "author": {"login": "npawar"}, "path": "pinot-integration-tests/src/test/resources/On_Time_On_Time_Performance_2014_100k_subset_nonulls_ingestion_config.schema", "diffHunk": "@@ -0,0 +1,342 @@\n+{", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg1MzEzNg=="}, "originalCommit": {"oid": "0fc85a2dcea04a6d5448bb92cff68b7e00c36548"}, "originalPosition": 1}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzMDU1MjY4OnYy", "diffSide": "LEFT", "path": "pinot-core/src/test/java/org/apache/pinot/core/data/recordtransformer/ExpressionTransformerTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxODo0MTowOVrOGw1FaQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QyMjoyOToxNlrOGw8z4A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg1NDU2OQ==", "bodyText": "Should we keep a test for transform in schema to ensure this change is backward-compatible? We can remove the test when we remove the schema transform support.", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453854569", "createdAt": "2020-07-13T18:41:09Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/test/java/org/apache/pinot/core/data/recordtransformer/ExpressionTransformerTest.java", "diffHunk": "@@ -43,14 +43,28 @@\n public class ExpressionTransformerTest {\n \n   @Test\n-  public void testGroovyExpressionTransformer()\n-      throws IOException {\n-    URL resource = AbstractRecordExtractorTest.class.getClassLoader()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0fc85a2dcea04a6d5448bb92cff68b7e00c36548"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk4MTE1Mg==", "bodyText": "i've split this test into 2 - testTransformFunctionsInSchema testTransformFunctionsInTable. They are both in the same file", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453981152", "createdAt": "2020-07-13T22:29:16Z", "author": {"login": "npawar"}, "path": "pinot-core/src/test/java/org/apache/pinot/core/data/recordtransformer/ExpressionTransformerTest.java", "diffHunk": "@@ -43,14 +43,28 @@\n public class ExpressionTransformerTest {\n \n   @Test\n-  public void testGroovyExpressionTransformer()\n-      throws IOException {\n-    URL resource = AbstractRecordExtractorTest.class.getClassLoader()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg1NDU2OQ=="}, "originalCommit": {"oid": "0fc85a2dcea04a6d5448bb92cff68b7e00c36548"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzMDU2MzQ5OnYy", "diffSide": "RIGHT", "path": "pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/IngestionConfigIntegrationTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxODo0NDoyMFrOGw1MNw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxODo0NDoyMFrOGw1MNw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg1NjMxMQ==", "bodyText": "(nit) remove empty line", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453856311", "createdAt": "2020-07-13T18:44:20Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/IngestionConfigIntegrationTest.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.integration.tests;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.google.common.collect.Lists;\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.commons.io.FileUtils;\n+import org.apache.pinot.spi.config.table.IngestionConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.ingestion.FilterConfig;\n+import org.apache.pinot.spi.config.table.ingestion.TransformConfig;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.util.TestUtils;\n+import org.testng.Assert;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+\n+import static org.testng.Assert.assertEquals;\n+\n+\n+/**\n+ * Integration test that converts Avro data for 12 segments and runs queries against it.\n+ */\n+public class IngestionConfigIntegrationTest extends BaseClusterIntegrationTestSet {\n+\n+  private static final String TIME_COLUMN_NAME = \"millisSinceEpoch\";\n+  private static final String SCHEMA_FILE_NAME = \"On_Time_On_Time_Performance_2014_100k_subset_nonulls_ingestion_config.schema\";\n+\n+  @Override\n+  protected String getSchemaFileName() {\n+    return SCHEMA_FILE_NAME;\n+  }\n+\n+  @Override\n+  protected String getTimeColumnName() {\n+    return TIME_COLUMN_NAME;\n+  }\n+\n+  @Override\n+  protected long getCountStarResult() {\n+    return 22300;\n+  }\n+\n+  @Override\n+  protected boolean useLlc() {\n+    return true;\n+  }\n+\n+  @Override\n+  protected IngestionConfig getIngestionConfig() {\n+    FilterConfig filterConfig = new FilterConfig(\"Groovy({AirlineID == 19393 || ArrDelayMinutes <= 5 }, AirlineID, ArrDelayMinutes)\");\n+    List<TransformConfig> transformConfigs = new ArrayList<>();\n+    transformConfigs.add(new TransformConfig(\"AmPm\", \"Groovy({DepTime < 1200 ? \\\"AM\\\": \\\"PM\\\"}, DepTime)\"));\n+    transformConfigs.add(new TransformConfig(\"millisSinceEpoch\", \"fromEpochDays(DaysSinceEpoch)\"));\n+    transformConfigs.add(new TransformConfig(\"lowerCaseDestCityName\", \"lower(DestCityName)\"));\n+    return new IngestionConfig(filterConfig, transformConfigs);\n+  }\n+\n+  @BeforeClass\n+  public void setUp()\n+      throws Exception {\n+    TestUtils.ensureDirectoriesExistAndEmpty(_tempDir, _segmentDir, _tarDir);\n+\n+    // Start the Pinot cluster\n+    startZk();\n+    startController();\n+    startBroker();\n+    startServer();\n+    startKafka();\n+\n+    // Create and upload the schema and table config\n+    Schema schema = createSchema();\n+    addSchema(schema);\n+    TableConfig tableConfig = createOfflineTableConfig();\n+    addTableConfig(tableConfig);\n+\n+    // Unpack the Avro files\n+    List<File> avroFiles = unpackAvroData(_tempDir);\n+\n+    // Create and upload segments\n+    ClusterIntegrationTestUtils.buildSegmentsFromAvro(avroFiles.subList(0, avroFiles.size() -1), tableConfig, schema, 0, _segmentDir, _tarDir);\n+    uploadSegments(getTableName(), _tarDir);\n+\n+    List<File> realtimeAvroFile = Lists.newArrayList(avroFiles.get(avroFiles.size() - 1));\n+    addTableConfig(createRealtimeTableConfig(realtimeAvroFile.get(0)));\n+    pushAvroIntoKafka(realtimeAvroFile);\n+\n+    // Wait for all documents loaded\n+    waitForAllDocsLoaded(600_000L);\n+  }\n+\n+  @Test\n+  public void testQueries()\n+      throws Exception {\n+    // Select column created with transform function\n+    String sqlQuery = \"Select millisSinceEpoch from \" + DEFAULT_TABLE_NAME;\n+    JsonNode response = postSqlQuery(sqlQuery);\n+    assertEquals(response.get(\"resultTable\").get(\"dataSchema\").get(\"columnNames\").get(0).asText(), \"millisSinceEpoch\");\n+    assertEquals(response.get(\"resultTable\").get(\"dataSchema\").get(\"columnDataTypes\").get(0).asText(), \"LONG\");\n+\n+    // Select column created with transform function\n+    sqlQuery = \"Select AmPm, DepTime from \" + DEFAULT_TABLE_NAME;\n+    response = postSqlQuery(sqlQuery);\n+    assertEquals(response.get(\"resultTable\").get(\"dataSchema\").get(\"columnNames\").get(0).asText(), \"AmPm\");\n+    assertEquals(response.get(\"resultTable\").get(\"dataSchema\").get(\"columnNames\").get(1).asText(), \"DepTime\");\n+    assertEquals(response.get(\"resultTable\").get(\"dataSchema\").get(\"columnDataTypes\").get(0).asText(), \"STRING\");\n+    assertEquals(response.get(\"resultTable\").get(\"dataSchema\").get(\"columnDataTypes\").get(1).asText(), \"INT\");\n+    for (int i = 0; i < response.get(\"resultTable\").get(\"rows\").size(); i++) {\n+      String amPm = response.get(\"resultTable\").get(\"rows\").get(i).get(0).asText();\n+      int depTime = response.get(\"resultTable\").get(\"rows\").get(i).get(1).asInt();\n+      Assert.assertEquals(amPm, (depTime < 1200) ? \"AM\" : \"PM\");\n+    }\n+\n+    // Select column created with transform function - offline table\n+    sqlQuery = \"Select AmPm, DepTime from \" + DEFAULT_TABLE_NAME + \"_OFFLINE\";\n+    response = postSqlQuery(sqlQuery);\n+    assertEquals(response.get(\"resultTable\").get(\"dataSchema\").get(\"columnNames\").get(0).asText(), \"AmPm\");\n+    assertEquals(response.get(\"resultTable\").get(\"dataSchema\").get(\"columnNames\").get(1).asText(), \"DepTime\");\n+    assertEquals(response.get(\"resultTable\").get(\"dataSchema\").get(\"columnDataTypes\").get(0).asText(), \"STRING\");\n+    assertEquals(response.get(\"resultTable\").get(\"dataSchema\").get(\"columnDataTypes\").get(1).asText(), \"INT\");\n+    for (int i = 0; i < response.get(\"resultTable\").get(\"rows\").size(); i++) {\n+      String amPm = response.get(\"resultTable\").get(\"rows\").get(i).get(0).asText();\n+      int depTime = response.get(\"resultTable\").get(\"rows\").get(i).get(1).asInt();\n+      Assert.assertEquals(amPm, (depTime < 1200) ? \"AM\" : \"PM\");\n+    }\n+\n+    // Select column created with transform - realtime table\n+    sqlQuery = \"Select AmPm, DepTime from \" + DEFAULT_TABLE_NAME + \"_REALTIME\";\n+    response = postSqlQuery(sqlQuery);\n+    assertEquals(response.get(\"resultTable\").get(\"dataSchema\").get(\"columnNames\").get(0).asText(), \"AmPm\");\n+    assertEquals(response.get(\"resultTable\").get(\"dataSchema\").get(\"columnNames\").get(1).asText(), \"DepTime\");\n+    assertEquals(response.get(\"resultTable\").get(\"dataSchema\").get(\"columnDataTypes\").get(0).asText(), \"STRING\");\n+    assertEquals(response.get(\"resultTable\").get(\"dataSchema\").get(\"columnDataTypes\").get(1).asText(), \"INT\");\n+    for (int i = 0; i < response.get(\"resultTable\").get(\"rows\").size(); i++) {\n+      String amPm = response.get(\"resultTable\").get(\"rows\").get(i).get(0).asText();\n+      int depTime = response.get(\"resultTable\").get(\"rows\").get(i).get(1).asInt();\n+      Assert.assertEquals(amPm, (depTime < 1200) ? \"AM\" : \"PM\");\n+    }\n+\n+    // Check there's no values that should've been filtered\n+    sqlQuery = \"Select * from \" + DEFAULT_TABLE_NAME\n+        + \"  where AirlineID = 19393 or ArrDelayMinutes <= 5\";\n+    response = postSqlQuery(sqlQuery);\n+    Assert.assertEquals(response.get(\"resultTable\").get(\"rows\").size(), 0);\n+\n+    // Check there's no values that should've been filtered - realtime table\n+    sqlQuery = \"Select * from \" + DEFAULT_TABLE_NAME + \"_REALTIME\"\n+        + \"  where AirlineID = 19393 or ArrDelayMinutes <= 5\";\n+    response = postSqlQuery(sqlQuery);\n+    Assert.assertEquals(response.get(\"resultTable\").get(\"rows\").size(), 0);\n+\n+    // Check there's no values that should've been filtered - offline table\n+    sqlQuery = \"Select * from \" + DEFAULT_TABLE_NAME + \"_OFFLINE\"\n+        + \"  where AirlineID = 19393 or ArrDelayMinutes <= 5\";\n+    response = postSqlQuery(sqlQuery);\n+    Assert.assertEquals(response.get(\"resultTable\").get(\"rows\").size(), 0);\n+  }\n+\n+  @AfterClass\n+  public void tearDown()\n+      throws Exception {\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0fc85a2dcea04a6d5448bb92cff68b7e00c36548"}, "originalPosition": 182}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzMDU4NDMyOnYy", "diffSide": "RIGHT", "path": "pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/IngestionConfigIntegrationTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxODo0OTozN1rOGw1YhA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxODo0OTozN1rOGw1YhA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg1OTQ2MA==", "bodyText": "extend BaseClusterIntegrationTest instead of BaseClusterIntegrationTestSet", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453859460", "createdAt": "2020-07-13T18:49:37Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/IngestionConfigIntegrationTest.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.integration.tests;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.google.common.collect.Lists;\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.commons.io.FileUtils;\n+import org.apache.pinot.spi.config.table.IngestionConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.ingestion.FilterConfig;\n+import org.apache.pinot.spi.config.table.ingestion.TransformConfig;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.util.TestUtils;\n+import org.testng.Assert;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+\n+import static org.testng.Assert.assertEquals;\n+\n+\n+/**\n+ * Integration test that converts Avro data for 12 segments and runs queries against it.\n+ */\n+public class IngestionConfigIntegrationTest extends BaseClusterIntegrationTestSet {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0fc85a2dcea04a6d5448bb92cff68b7e00c36548"}, "originalPosition": 44}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzMDU4OTc1OnYy", "diffSide": "RIGHT", "path": "pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/IngestionConfigIntegrationTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxODo1MTowOFrOGw1b1Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxODo1MTowOFrOGw1b1Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg2MDMwOQ==", "bodyText": "Make a simplified schema (only contains the columns needed for the test).\nYou can directly override createSchema()", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453860309", "createdAt": "2020-07-13T18:51:08Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/IngestionConfigIntegrationTest.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.integration.tests;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.google.common.collect.Lists;\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.commons.io.FileUtils;\n+import org.apache.pinot.spi.config.table.IngestionConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.ingestion.FilterConfig;\n+import org.apache.pinot.spi.config.table.ingestion.TransformConfig;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.util.TestUtils;\n+import org.testng.Assert;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+\n+import static org.testng.Assert.assertEquals;\n+\n+\n+/**\n+ * Integration test that converts Avro data for 12 segments and runs queries against it.\n+ */\n+public class IngestionConfigIntegrationTest extends BaseClusterIntegrationTestSet {\n+\n+  private static final String TIME_COLUMN_NAME = \"millisSinceEpoch\";\n+  private static final String SCHEMA_FILE_NAME = \"On_Time_On_Time_Performance_2014_100k_subset_nonulls_ingestion_config.schema\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0fc85a2dcea04a6d5448bb92cff68b7e00c36548"}, "originalPosition": 47}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzMDU5NTk4OnYy", "diffSide": "RIGHT", "path": "pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/IngestionConfigIntegrationTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxODo1Mjo0OFrOGw1flQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxODo1Mjo0OFrOGw1flQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg2MTI2OQ==", "bodyText": "No overlapping segments? The result won't be correct. Please use the set up  logic as in the HybridClusterIntegrationTest", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453861269", "createdAt": "2020-07-13T18:52:48Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/IngestionConfigIntegrationTest.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.integration.tests;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.google.common.collect.Lists;\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.commons.io.FileUtils;\n+import org.apache.pinot.spi.config.table.IngestionConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.ingestion.FilterConfig;\n+import org.apache.pinot.spi.config.table.ingestion.TransformConfig;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.util.TestUtils;\n+import org.testng.Assert;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+\n+import static org.testng.Assert.assertEquals;\n+\n+\n+/**\n+ * Integration test that converts Avro data for 12 segments and runs queries against it.\n+ */\n+public class IngestionConfigIntegrationTest extends BaseClusterIntegrationTestSet {\n+\n+  private static final String TIME_COLUMN_NAME = \"millisSinceEpoch\";\n+  private static final String SCHEMA_FILE_NAME = \"On_Time_On_Time_Performance_2014_100k_subset_nonulls_ingestion_config.schema\";\n+\n+  @Override\n+  protected String getSchemaFileName() {\n+    return SCHEMA_FILE_NAME;\n+  }\n+\n+  @Override\n+  protected String getTimeColumnName() {\n+    return TIME_COLUMN_NAME;\n+  }\n+\n+  @Override\n+  protected long getCountStarResult() {\n+    return 22300;\n+  }\n+\n+  @Override\n+  protected boolean useLlc() {\n+    return true;\n+  }\n+\n+  @Override\n+  protected IngestionConfig getIngestionConfig() {\n+    FilterConfig filterConfig = new FilterConfig(\"Groovy({AirlineID == 19393 || ArrDelayMinutes <= 5 }, AirlineID, ArrDelayMinutes)\");\n+    List<TransformConfig> transformConfigs = new ArrayList<>();\n+    transformConfigs.add(new TransformConfig(\"AmPm\", \"Groovy({DepTime < 1200 ? \\\"AM\\\": \\\"PM\\\"}, DepTime)\"));\n+    transformConfigs.add(new TransformConfig(\"millisSinceEpoch\", \"fromEpochDays(DaysSinceEpoch)\"));\n+    transformConfigs.add(new TransformConfig(\"lowerCaseDestCityName\", \"lower(DestCityName)\"));\n+    return new IngestionConfig(filterConfig, transformConfigs);\n+  }\n+\n+  @BeforeClass\n+  public void setUp()\n+      throws Exception {\n+    TestUtils.ensureDirectoriesExistAndEmpty(_tempDir, _segmentDir, _tarDir);\n+\n+    // Start the Pinot cluster\n+    startZk();\n+    startController();\n+    startBroker();\n+    startServer();\n+    startKafka();\n+\n+    // Create and upload the schema and table config\n+    Schema schema = createSchema();\n+    addSchema(schema);\n+    TableConfig tableConfig = createOfflineTableConfig();\n+    addTableConfig(tableConfig);\n+\n+    // Unpack the Avro files\n+    List<File> avroFiles = unpackAvroData(_tempDir);\n+\n+    // Create and upload segments\n+    ClusterIntegrationTestUtils.buildSegmentsFromAvro(avroFiles.subList(0, avroFiles.size() -1), tableConfig, schema, 0, _segmentDir, _tarDir);\n+    uploadSegments(getTableName(), _tarDir);\n+\n+    List<File> realtimeAvroFile = Lists.newArrayList(avroFiles.get(avroFiles.size() - 1));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0fc85a2dcea04a6d5448bb92cff68b7e00c36548"}, "originalPosition": 104}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzMDYyNDM4OnYy", "diffSide": "RIGHT", "path": "pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/IngestionConfigIntegrationTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxOTowMDozN1rOGw1w-w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QyMjozMDozM1rOGw83ng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg2NTcyMw==", "bodyText": "This result should be the same as select count(*) from mytable where AirlineID != 19393 AND ArrDelayMinutes > 5 within other integration test, where I got 24047.\nPlease document how this number is calculated. When we add a test, we should not run the test and directly put the result as the expected value because that won't catch the bug of the code or the test logic", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453865723", "createdAt": "2020-07-13T19:00:37Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/IngestionConfigIntegrationTest.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.integration.tests;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.google.common.collect.Lists;\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.commons.io.FileUtils;\n+import org.apache.pinot.spi.config.table.IngestionConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.ingestion.FilterConfig;\n+import org.apache.pinot.spi.config.table.ingestion.TransformConfig;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.util.TestUtils;\n+import org.testng.Assert;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+\n+import static org.testng.Assert.assertEquals;\n+\n+\n+/**\n+ * Integration test that converts Avro data for 12 segments and runs queries against it.\n+ */\n+public class IngestionConfigIntegrationTest extends BaseClusterIntegrationTestSet {\n+\n+  private static final String TIME_COLUMN_NAME = \"millisSinceEpoch\";\n+  private static final String SCHEMA_FILE_NAME = \"On_Time_On_Time_Performance_2014_100k_subset_nonulls_ingestion_config.schema\";\n+\n+  @Override\n+  protected String getSchemaFileName() {\n+    return SCHEMA_FILE_NAME;\n+  }\n+\n+  @Override\n+  protected String getTimeColumnName() {\n+    return TIME_COLUMN_NAME;\n+  }\n+\n+  @Override\n+  protected long getCountStarResult() {\n+    return 22300;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0fc85a2dcea04a6d5448bb92cff68b7e00c36548"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk4MjExMA==", "bodyText": "it was an effect of using different number of files as compared to Hybrid test. Changed it to be exactly like Hybrid test. Now number is 24047", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453982110", "createdAt": "2020-07-13T22:30:33Z", "author": {"login": "npawar"}, "path": "pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/IngestionConfigIntegrationTest.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.integration.tests;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.google.common.collect.Lists;\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.commons.io.FileUtils;\n+import org.apache.pinot.spi.config.table.IngestionConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.ingestion.FilterConfig;\n+import org.apache.pinot.spi.config.table.ingestion.TransformConfig;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.util.TestUtils;\n+import org.testng.Assert;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+\n+import static org.testng.Assert.assertEquals;\n+\n+\n+/**\n+ * Integration test that converts Avro data for 12 segments and runs queries against it.\n+ */\n+public class IngestionConfigIntegrationTest extends BaseClusterIntegrationTestSet {\n+\n+  private static final String TIME_COLUMN_NAME = \"millisSinceEpoch\";\n+  private static final String SCHEMA_FILE_NAME = \"On_Time_On_Time_Performance_2014_100k_subset_nonulls_ingestion_config.schema\";\n+\n+  @Override\n+  protected String getSchemaFileName() {\n+    return SCHEMA_FILE_NAME;\n+  }\n+\n+  @Override\n+  protected String getTimeColumnName() {\n+    return TIME_COLUMN_NAME;\n+  }\n+\n+  @Override\n+  protected long getCountStarResult() {\n+    return 22300;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzg2NTcyMw=="}, "originalCommit": {"oid": "0fc85a2dcea04a6d5448bb92cff68b7e00c36548"}, "originalPosition": 61}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzMTQ4MTg2OnYy", "diffSide": "RIGHT", "path": "pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/IngestionConfigHybridIntegrationTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QyMjo1Mjo0MlrOGw9evA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QyMjo1Mjo0MlrOGw9evA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5MjEyNA==", "bodyText": "Remove this line", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453992124", "createdAt": "2020-07-13T22:52:42Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/IngestionConfigHybridIntegrationTest.java", "diffHunk": "@@ -0,0 +1,227 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.integration.tests;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import org.apache.pinot.controller.ControllerConf;\n+import org.apache.pinot.spi.config.table.IngestionConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.ingestion.FilterConfig;\n+import org.apache.pinot.spi.config.table.ingestion.TransformConfig;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.util.TestUtils;\n+import org.testng.Assert;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+\n+import static org.testng.Assert.assertEquals;\n+\n+\n+/**\n+ * Tests ingestion configs on a hybrid table\n+ */\n+public class IngestionConfigHybridIntegrationTest extends BaseClusterIntegrationTest {\n+  private static final int NUM_OFFLINE_SEGMENTS = 8;\n+  private static final int NUM_REALTIME_SEGMENTS = 6;\n+  private static final String TIME_COLUMN_NAME = \"millisSinceEpoch\";\n+  private static final String SCHEMA_FILE_NAME = \"On_Time_On_Time_Performance_2014_100k_subset_nonulls_ingestion_config.schema\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f3ef701d78488ae3c9363ec4d134a0446bf15766"}, "originalPosition": 50}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzMTQ4MjIwOnYy", "diffSide": "RIGHT", "path": "pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/IngestionConfigHybridIntegrationTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QyMjo1Mjo1MlrOGw9e8g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QyMjo1Mjo1MlrOGw9e8g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5MjE3OA==", "bodyText": "Remove", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453992178", "createdAt": "2020-07-13T22:52:52Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/IngestionConfigHybridIntegrationTest.java", "diffHunk": "@@ -0,0 +1,227 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.integration.tests;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import org.apache.pinot.controller.ControllerConf;\n+import org.apache.pinot.spi.config.table.IngestionConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.ingestion.FilterConfig;\n+import org.apache.pinot.spi.config.table.ingestion.TransformConfig;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.util.TestUtils;\n+import org.testng.Assert;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+\n+import static org.testng.Assert.assertEquals;\n+\n+\n+/**\n+ * Tests ingestion configs on a hybrid table\n+ */\n+public class IngestionConfigHybridIntegrationTest extends BaseClusterIntegrationTest {\n+  private static final int NUM_OFFLINE_SEGMENTS = 8;\n+  private static final int NUM_REALTIME_SEGMENTS = 6;\n+  private static final String TIME_COLUMN_NAME = \"millisSinceEpoch\";\n+  private static final String SCHEMA_FILE_NAME = \"On_Time_On_Time_Performance_2014_100k_subset_nonulls_ingestion_config.schema\";\n+  private static final long FILTERED_COUNT_STAR_RESULT = 24047L;\n+\n+  @Override\n+  protected String getSchemaFileName() {\n+    return SCHEMA_FILE_NAME;\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f3ef701d78488ae3c9363ec4d134a0446bf15766"}, "originalPosition": 56}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzMTQ4NjAzOnYy", "diffSide": "RIGHT", "path": "pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/IngestionConfigHybridIntegrationTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QyMjo1NDozN1rOGw9hUg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QyMjo1NDozN1rOGw9hUg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5Mjc4Ng==", "bodyText": "Let's document how this value is calculated (query result of SELECT COUNT(*) FROM mytable WHERE AirlineID != 19393 AND ArrDelayMinutes > 5 on unfiltered data)", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453992786", "createdAt": "2020-07-13T22:54:37Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/IngestionConfigHybridIntegrationTest.java", "diffHunk": "@@ -0,0 +1,227 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.integration.tests;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import org.apache.pinot.controller.ControllerConf;\n+import org.apache.pinot.spi.config.table.IngestionConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.ingestion.FilterConfig;\n+import org.apache.pinot.spi.config.table.ingestion.TransformConfig;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.util.TestUtils;\n+import org.testng.Assert;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+\n+import static org.testng.Assert.assertEquals;\n+\n+\n+/**\n+ * Tests ingestion configs on a hybrid table\n+ */\n+public class IngestionConfigHybridIntegrationTest extends BaseClusterIntegrationTest {\n+  private static final int NUM_OFFLINE_SEGMENTS = 8;\n+  private static final int NUM_REALTIME_SEGMENTS = 6;\n+  private static final String TIME_COLUMN_NAME = \"millisSinceEpoch\";\n+  private static final String SCHEMA_FILE_NAME = \"On_Time_On_Time_Performance_2014_100k_subset_nonulls_ingestion_config.schema\";\n+  private static final long FILTERED_COUNT_STAR_RESULT = 24047L;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f3ef701d78488ae3c9363ec4d134a0446bf15766"}, "originalPosition": 51}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzMTQ5NTQ1OnYy", "diffSide": "RIGHT", "path": "pinot-core/src/test/java/org/apache/pinot/core/data/recordtransformer/ExpressionTransformerTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QyMjo1ODo1MlrOGw9nAg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QyMjo1ODo1MlrOGw9nAg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5NDI0Mg==", "bodyText": "(nit)\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              public void testTransformConfigsFromTable() {\n          \n          \n            \n              public void testTransformConfigsFromTableConfig() {", "url": "https://github.com/apache/pinot/pull/5681#discussion_r453994242", "createdAt": "2020-07-13T22:58:52Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/test/java/org/apache/pinot/core/data/recordtransformer/ExpressionTransformerTest.java", "diffHunk": "@@ -43,14 +43,28 @@\n public class ExpressionTransformerTest {\n \n   @Test\n-  public void testGroovyExpressionTransformer()\n-      throws IOException {\n-    URL resource = AbstractRecordExtractorTest.class.getClassLoader()\n-        .getResource(\"data/expression_transformer/groovy_expression_transformer.json\");\n-    File schemaFile = new File(resource.getFile());\n-    Schema pinotSchema = Schema.fromFile(schemaFile);\n-\n-    ExpressionTransformer expressionTransformer = new ExpressionTransformer(pinotSchema);\n+  public void testTransformConfigsFromTable() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f3ef701d78488ae3c9363ec4d134a0446bf15766"}, "originalPosition": 39}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4095, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}