{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDU5NTgxMTcz", "number": 5778, "title": "[TE] The endpoint for searching anomalies and pagination", "bodyText": "This PR creates the endpoints for searching and paginate the anomalies. The endpoint is built for the anomaly page v3. It brings the response time from ~30s to around 300ms. We should see a ~100x speedup of the page load time.\nThe current Anomaly list page is loading slowly because of calling legacy endpoints. Although the old endpoint works ok when the scale is small, it responses very slowly when handling anomalies on a large scale. (above 100k+ anomalies)\nThis endpoint pushes the filtering and pagination of the anomalies into backend and database servers instead of doing it in the UI.", "createdAt": "2020-07-30T20:35:04Z", "url": "https://github.com/apache/pinot/pull/5778", "merged": true, "mergeCommit": {"oid": "5d66b9e8962f23990a121a36bf9593c396f7805e"}, "closed": true, "closedAt": "2020-08-04T20:03:07Z", "author": {"login": "jihaozh"}, "timelineItems": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc6GA9VABqjM2MDU3NjA3NTg=", "endCursor": "Y3Vyc29yOnYyOpPPAAABc7rucwAFqTQ2MTEwNzQ2MA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a9d4aea4e27122f9b103b4bdb813d97e5c77f8af", "author": {"user": {"login": "jihaozh", "name": "Jihao Zhang"}}, "url": "https://github.com/apache/pinot/commit/a9d4aea4e27122f9b103b4bdb813d97e5c77f8af", "committedDate": "2020-07-29T23:56:06Z", "message": "unit tests"}, "afterCommit": {"oid": "ee879b17116fe46cb33b5cdb548ea602313692e0", "author": {"user": {"login": "jihaozh", "name": "Jihao Zhang"}}, "url": "https://github.com/apache/pinot/commit/ee879b17116fe46cb33b5cdb548ea602313692e0", "committedDate": "2020-07-30T20:53:30Z", "message": "- new anomalies endpoint and unit tests"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU4Nzc5NDY1", "url": "https://github.com/apache/pinot/pull/5778#pullrequestreview-458779465", "createdAt": "2020-07-30T21:47:12Z", "commit": {"oid": "ee879b17116fe46cb33b5cdb548ea602313692e0"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU4ODE1NjIw", "url": "https://github.com/apache/pinot/pull/5778#pullrequestreview-458815620", "createdAt": "2020-07-30T22:50:43Z", "commit": {"oid": "ee879b17116fe46cb33b5cdb548ea602313692e0"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQyMjo1MDo0M1rOG52d3g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQyMjo1OToxM1rOG52oQQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzMxNDM5OA==", "bodyText": "add header", "url": "https://github.com/apache/pinot/pull/5778#discussion_r463314398", "createdAt": "2020-07-30T22:50:43Z", "author": {"login": "bxji"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/dashboard/resources/v2/anomalies/AnomalySearchFilter.java", "diffHunk": "@@ -0,0 +1,132 @@\n+package org.apache.pinot.thirdeye.dashboard.resources.v2.anomalies;\n+\n+import java.util.Collections;\n+import java.util.List;\n+\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ee879b17116fe46cb33b5cdb548ea602313692e0"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzMxNDQ1NA==", "bodyText": "add header", "url": "https://github.com/apache/pinot/pull/5778#discussion_r463314454", "createdAt": "2020-07-30T22:50:55Z", "author": {"login": "bxji"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/dashboard/resources/v2/anomalies/AnomalySearchResource.java", "diffHunk": "@@ -0,0 +1,61 @@\n+package org.apache.pinot.thirdeye.dashboard.resources.v2.anomalies;\n+\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import java.util.List;\n+import javax.ws.rs.DefaultValue;\n+import javax.ws.rs.GET;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ee879b17116fe46cb33b5cdb548ea602313692e0"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzMxNDUzNg==", "bodyText": "add header", "url": "https://github.com/apache/pinot/pull/5778#discussion_r463314536", "createdAt": "2020-07-30T22:51:13Z", "author": {"login": "bxji"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/dashboard/resources/v2/anomalies/AnomalySearcher.java", "diffHunk": "@@ -0,0 +1,142 @@\n+package org.apache.pinot.thirdeye.dashboard.resources.v2.anomalies;\n+\n+import com.google.common.collect.ImmutableMap;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.HashSet;\n+import java.util.List;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ee879b17116fe46cb33b5cdb548ea602313692e0"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzMxNDY1Ng==", "bodyText": "header", "url": "https://github.com/apache/pinot/pull/5778#discussion_r463314656", "createdAt": "2020-07-30T22:51:34Z", "author": {"login": "bxji"}, "path": "thirdeye/thirdeye-pinot/src/test/java/org/apache/pinot/thirdeye/dashboard/resources/v2/anomalies/AnomalySearcherTest.java", "diffHunk": "@@ -0,0 +1,68 @@\n+package org.apache.pinot.thirdeye.dashboard.resources.v2.anomalies;\n+\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ee879b17116fe46cb33b5cdb548ea602313692e0"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzMxNzA1Nw==", "bodyText": "Just want to check my understanding; I see that we are starting with offset of 0. So my understanding is that if we have limit 25, the anomalies returned should be 0-24?\nIf so, since we are starting with offset of 0, do we need >= as the equality check here?", "url": "https://github.com/apache/pinot/pull/5778#discussion_r463317057", "createdAt": "2020-07-30T22:59:13Z", "author": {"login": "bxji"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/dashboard/resources/v2/anomalies/AnomalySearcher.java", "diffHunk": "@@ -0,0 +1,142 @@\n+package org.apache.pinot.thirdeye.dashboard.resources.v2.anomalies;\n+\n+import com.google.common.collect.ImmutableMap;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.pinot.thirdeye.constant.AnomalyFeedbackType;\n+import org.apache.pinot.thirdeye.datalayer.bao.DetectionAlertConfigManager;\n+import org.apache.pinot.thirdeye.datalayer.bao.DetectionConfigManager;\n+import org.apache.pinot.thirdeye.datalayer.bao.MergedAnomalyResultManager;\n+import org.apache.pinot.thirdeye.datalayer.dto.AbstractDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.MergedAnomalyResultDTO;\n+import org.apache.pinot.thirdeye.datalayer.pojo.DetectionConfigBean;\n+import org.apache.pinot.thirdeye.datalayer.util.Predicate;\n+import org.apache.pinot.thirdeye.datasource.DAORegistry;\n+\n+import static org.apache.pinot.thirdeye.constant.AnomalyFeedbackType.*;\n+\n+\n+/**\n+ * The type Anomaly searcher.\n+ */\n+public class AnomalySearcher {\n+  private final MergedAnomalyResultManager anomalyDAO;\n+  private final DetectionConfigManager detectionConfigDAO;\n+  private final DetectionAlertConfigManager detectionAlertConfigDAO;\n+\n+  /**\n+   * Instantiates a new Anomaly searcher.\n+   */\n+  public AnomalySearcher() {\n+    this.anomalyDAO = DAORegistry.getInstance().getMergedAnomalyResultDAO();\n+    this.detectionConfigDAO = DAORegistry.getInstance().getDetectionConfigManager();\n+    this.detectionAlertConfigDAO = DAORegistry.getInstance().getDetectionAlertConfigManager();\n+  }\n+\n+  /**\n+   * Search and retrieve all the anomalies matching to the search filter and limits.\n+   *\n+   * @param searchFilter the search filter\n+   * @param limit the limit\n+   * @param offset the offset\n+   * @return the result\n+   */\n+  public Map<String, Object> search(AnomalySearchFilter searchFilter, int limit, int offset) {\n+    Predicate predicate = Predicate.EQ(\"child\", false);\n+    if (searchFilter.getStartTime() != null) {\n+      predicate = Predicate.AND(predicate, Predicate.LT(\"startTime\", searchFilter.getEndTime()));\n+    }\n+    if (searchFilter.getEndTime() != null) {\n+      predicate = Predicate.AND(predicate, Predicate.GT(\"endTime\", searchFilter.getStartTime()));\n+    }\n+    // search by detections or subscription groups\n+    Set<Long> detectionConfigIds = new HashSet<>();\n+    Set<Long> subscribedDetectionConfigIds = new HashSet<>();\n+    if (!searchFilter.getDetectionNames().isEmpty()) {\n+      detectionConfigIds =\n+          this.detectionConfigDAO.findByPredicate(Predicate.IN(\"name\", searchFilter.getDetectionNames().toArray()))\n+              .stream()\n+              .map(DetectionConfigBean::getId)\n+              .collect(Collectors.toSet());\n+    }\n+    if (!searchFilter.getSubscriptionGroups().isEmpty()) {\n+      subscribedDetectionConfigIds = this.detectionAlertConfigDAO.findByPredicate(\n+          Predicate.IN(\"name\", searchFilter.getSubscriptionGroups().toArray()))\n+          .stream()\n+          .map(detectionAlertConfigDTO -> detectionAlertConfigDTO.getVectorClocks().keySet())\n+          .flatMap(Collection::stream)\n+          .collect(Collectors.toSet());\n+    }\n+    if (!searchFilter.getDetectionNames().isEmpty() && !searchFilter.getSubscriptionGroups().isEmpty()) {\n+      // intersect the detection config ids if searching by both\n+      detectionConfigIds.retainAll(subscribedDetectionConfigIds);\n+    } else {\n+      detectionConfigIds.addAll(subscribedDetectionConfigIds);\n+    }\n+    if (!searchFilter.getDetectionNames().isEmpty() || !searchFilter.getSubscriptionGroups().isEmpty()) {\n+      // add the predicate using detection config id\n+      if (detectionConfigIds.isEmpty()) {\n+        // if detection not found, return empty result\n+        return ImmutableMap.of(\"count\", 0, \"limit\", limit, \"offset\", offset, \"elements\", Collections.emptyList());\n+      }\n+      predicate = Predicate.AND(predicate, Predicate.IN(\"detectionConfigId\", detectionConfigIds.toArray()));\n+    }\n+\n+    // search by datasets\n+    if (!searchFilter.getDatasets().isEmpty()) {\n+      List<Predicate> datasetPredicates = new ArrayList<>();\n+      for (String dataset : searchFilter.getDatasets()) {\n+        datasetPredicates.add(Predicate.LIKE(\"collection\", \"%\" + dataset + \"%\"));\n+      }\n+      predicate = Predicate.AND(predicate, Predicate.OR(datasetPredicates.toArray(new Predicate[0])));\n+    }\n+    // search by metrics\n+    if (!searchFilter.getMetrics().isEmpty()) {\n+      predicate = Predicate.AND(predicate, Predicate.IN(\"metric\", searchFilter.getMetrics().toArray()));\n+    }\n+    // search by ids\n+    if (!searchFilter.getAnomalyIds().isEmpty()) {\n+      predicate = Predicate.AND(predicate, Predicate.IN(\"baseId\", searchFilter.getAnomalyIds().toArray()));\n+    }\n+\n+    long count;\n+    List<MergedAnomalyResultDTO> results;\n+    if (searchFilter.getFeedbacks().isEmpty()) {\n+      List<Long> anomalyIds = this.anomalyDAO.findIdsByPredicate(predicate)\n+          .stream()\n+          .sorted(Comparator.reverseOrder())\n+          .collect(Collectors.toList());\n+      count = anomalyIds.size();\n+      results = anomalyIds.isEmpty() ? Collections.emptyList()\n+          : this.anomalyDAO.findByIds(paginateResults(anomalyIds, offset, limit));\n+    } else {\n+      // filter by feedback types if requested\n+      List<MergedAnomalyResultDTO> anomalies = this.anomalyDAO.findByPredicate(predicate);\n+      Set<AnomalyFeedbackType> feedbackFilters =\n+          searchFilter.getFeedbacks().stream().map(AnomalyFeedbackType::valueOf).collect(Collectors.toSet());\n+      results = anomalies.stream()\n+          .filter(anomaly -> (anomaly.getFeedback() == null && feedbackFilters.contains(NO_FEEDBACK)) || (\n+              anomaly.getFeedback() != null && feedbackFilters.contains(anomaly.getFeedback().getFeedbackType())))\n+          .sorted(Comparator.comparingLong(AbstractDTO::getId).reversed())\n+          .collect(Collectors.toList());\n+      count = results.size();\n+      results = paginateResults(results, offset, limit);\n+    }\n+    return ImmutableMap.of(\"count\", count, \"limit\", limit, \"offset\", offset, \"elements\", results);\n+  }\n+\n+  private <T> List<T> paginateResults(List<T> list, int offset, int limit) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ee879b17116fe46cb33b5cdb548ea602313692e0"}, "originalPosition": 135}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDYxMDA2OTQ1", "url": "https://github.com/apache/pinot/pull/5778#pullrequestreview-461006945", "createdAt": "2020-08-04T17:07:30Z", "commit": {"oid": "9586523bc5505524dfc7d985321f96f9130bae10"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQxNzoxMzozNlrOG7pz1g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQxODoxNjoxMFrOG7r-hw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTIwNDE4Mg==", "bodyText": "You might want to describe these fields better or if they are intuitive enough I would usually not make an entry at all.", "url": "https://github.com/apache/pinot/pull/5778#discussion_r465204182", "createdAt": "2020-08-04T17:13:36Z", "author": {"login": "akshayrai"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/dashboard/resources/v2/anomalies/AnomalySearchResource.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ *\n+ */\n+\n+package org.apache.pinot.thirdeye.dashboard.resources.v2.anomalies;\n+\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import java.util.List;\n+import javax.ws.rs.DefaultValue;\n+import javax.ws.rs.GET;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.QueryParam;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import org.apache.pinot.thirdeye.api.Constants;\n+\n+\n+/**\n+ * The type Anomaly search resource.\n+ */\n+@Path(value = \"/anomaly-search\")\n+@Produces(MediaType.APPLICATION_JSON)\n+@Api(tags = {Constants.DETECTION_TAG})\n+public class AnomalySearchResource {\n+\n+  private final AnomalySearcher anomalySearcher;\n+\n+  /**\n+   * Instantiates a new Anomaly search resource.\n+   */\n+  public AnomalySearchResource() {\n+    this.anomalySearcher = new AnomalySearcher();\n+  }\n+\n+  /**\n+   * Search and paginate the anomalies according to the parameters.\n+   *\n+   * @param limit the limit\n+   * @param offset the offset\n+   * @param startTime the start time\n+   * @param endTime the end time\n+   * @param feedbacks the feedback types, e.g. ANOMALY, NOT_ANOMALY\n+   * @param subscriptionGroups the subscription groups\n+   * @param detectionNames the detection names\n+   * @param metrics the metrics\n+   * @param datasets the datasets\n+   * @param anomalyIds the anomaly ids\n+   * @return the response", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9586523bc5505524dfc7d985321f96f9130bae10"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTIxMDE5Mg==", "bodyText": "How about merging and enriching the existing query anomalies endpoint in UserDashboardResource?", "url": "https://github.com/apache/pinot/pull/5778#discussion_r465210192", "createdAt": "2020-08-04T17:24:00Z", "author": {"login": "akshayrai"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/dashboard/resources/v2/anomalies/AnomalySearchResource.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ *\n+ */\n+\n+package org.apache.pinot.thirdeye.dashboard.resources.v2.anomalies;\n+\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import java.util.List;\n+import javax.ws.rs.DefaultValue;\n+import javax.ws.rs.GET;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.QueryParam;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import org.apache.pinot.thirdeye.api.Constants;\n+\n+\n+/**\n+ * The type Anomaly search resource.\n+ */\n+@Path(value = \"/anomaly-search\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9586523bc5505524dfc7d985321f96f9130bae10"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTIxMzMyNw==", "bodyText": "This is generic enough to move out into a utility?", "url": "https://github.com/apache/pinot/pull/5778#discussion_r465213327", "createdAt": "2020-08-04T17:29:17Z", "author": {"login": "akshayrai"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/dashboard/resources/v2/anomalies/AnomalySearcher.java", "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ *\n+ */\n+\n+package org.apache.pinot.thirdeye.dashboard.resources.v2.anomalies;\n+\n+import com.google.common.collect.ImmutableMap;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.pinot.thirdeye.constant.AnomalyFeedbackType;\n+import org.apache.pinot.thirdeye.datalayer.bao.DetectionAlertConfigManager;\n+import org.apache.pinot.thirdeye.datalayer.bao.DetectionConfigManager;\n+import org.apache.pinot.thirdeye.datalayer.bao.MergedAnomalyResultManager;\n+import org.apache.pinot.thirdeye.datalayer.dto.AbstractDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.MergedAnomalyResultDTO;\n+import org.apache.pinot.thirdeye.datalayer.pojo.DetectionConfigBean;\n+import org.apache.pinot.thirdeye.datalayer.util.Predicate;\n+import org.apache.pinot.thirdeye.datasource.DAORegistry;\n+\n+import static org.apache.pinot.thirdeye.constant.AnomalyFeedbackType.*;\n+\n+\n+/**\n+ * The type Anomaly searcher.\n+ */\n+public class AnomalySearcher {\n+  private final MergedAnomalyResultManager anomalyDAO;\n+  private final DetectionConfigManager detectionConfigDAO;\n+  private final DetectionAlertConfigManager detectionAlertConfigDAO;\n+\n+  /**\n+   * Instantiates a new Anomaly searcher.\n+   */\n+  public AnomalySearcher() {\n+    this.anomalyDAO = DAORegistry.getInstance().getMergedAnomalyResultDAO();\n+    this.detectionConfigDAO = DAORegistry.getInstance().getDetectionConfigManager();\n+    this.detectionAlertConfigDAO = DAORegistry.getInstance().getDetectionAlertConfigManager();\n+  }\n+\n+  /**\n+   * Search and retrieve all the anomalies matching to the search filter and limits.\n+   *\n+   * @param searchFilter the search filter\n+   * @param limit the limit\n+   * @param offset the offset\n+   * @return the result\n+   */\n+  public Map<String, Object> search(AnomalySearchFilter searchFilter, int limit, int offset) {\n+    Predicate predicate = Predicate.EQ(\"child\", false);\n+    if (searchFilter.getStartTime() != null) {\n+      predicate = Predicate.AND(predicate, Predicate.LT(\"startTime\", searchFilter.getEndTime()));\n+    }\n+    if (searchFilter.getEndTime() != null) {\n+      predicate = Predicate.AND(predicate, Predicate.GT(\"endTime\", searchFilter.getStartTime()));\n+    }\n+    // search by detections or subscription groups\n+    Set<Long> detectionConfigIds = new HashSet<>();\n+    Set<Long> subscribedDetectionConfigIds = new HashSet<>();\n+    if (!searchFilter.getDetectionNames().isEmpty()) {\n+      detectionConfigIds =\n+          this.detectionConfigDAO.findByPredicate(Predicate.IN(\"name\", searchFilter.getDetectionNames().toArray()))\n+              .stream()\n+              .map(DetectionConfigBean::getId)\n+              .collect(Collectors.toSet());\n+    }\n+    if (!searchFilter.getSubscriptionGroups().isEmpty()) {\n+      subscribedDetectionConfigIds = this.detectionAlertConfigDAO.findByPredicate(\n+          Predicate.IN(\"name\", searchFilter.getSubscriptionGroups().toArray()))\n+          .stream()\n+          .map(detectionAlertConfigDTO -> detectionAlertConfigDTO.getVectorClocks().keySet())\n+          .flatMap(Collection::stream)\n+          .collect(Collectors.toSet());\n+    }\n+    if (!searchFilter.getDetectionNames().isEmpty() && !searchFilter.getSubscriptionGroups().isEmpty()) {\n+      // intersect the detection config ids if searching by both\n+      detectionConfigIds.retainAll(subscribedDetectionConfigIds);\n+    } else {\n+      detectionConfigIds.addAll(subscribedDetectionConfigIds);\n+    }\n+    if (!searchFilter.getDetectionNames().isEmpty() || !searchFilter.getSubscriptionGroups().isEmpty()) {\n+      // add the predicate using detection config id\n+      if (detectionConfigIds.isEmpty()) {\n+        // if detection not found, return empty result\n+        return ImmutableMap.of(\"count\", 0, \"limit\", limit, \"offset\", offset, \"elements\", Collections.emptyList());\n+      }\n+      predicate = Predicate.AND(predicate, Predicate.IN(\"detectionConfigId\", detectionConfigIds.toArray()));\n+    }\n+\n+    // search by datasets\n+    if (!searchFilter.getDatasets().isEmpty()) {\n+      List<Predicate> datasetPredicates = new ArrayList<>();\n+      for (String dataset : searchFilter.getDatasets()) {\n+        datasetPredicates.add(Predicate.LIKE(\"collection\", \"%\" + dataset + \"%\"));\n+      }\n+      predicate = Predicate.AND(predicate, Predicate.OR(datasetPredicates.toArray(new Predicate[0])));\n+    }\n+    // search by metrics\n+    if (!searchFilter.getMetrics().isEmpty()) {\n+      predicate = Predicate.AND(predicate, Predicate.IN(\"metric\", searchFilter.getMetrics().toArray()));\n+    }\n+    // search by ids\n+    if (!searchFilter.getAnomalyIds().isEmpty()) {\n+      predicate = Predicate.AND(predicate, Predicate.IN(\"baseId\", searchFilter.getAnomalyIds().toArray()));\n+    }\n+\n+    long count;\n+    List<MergedAnomalyResultDTO> results;\n+    if (searchFilter.getFeedbacks().isEmpty()) {\n+      List<Long> anomalyIds = this.anomalyDAO.findIdsByPredicate(predicate)\n+          .stream()\n+          .sorted(Comparator.reverseOrder())\n+          .collect(Collectors.toList());\n+      count = anomalyIds.size();\n+      results = anomalyIds.isEmpty() ? Collections.emptyList()\n+          : this.anomalyDAO.findByIds(paginateResults(anomalyIds, offset, limit));\n+    } else {\n+      // filter by feedback types if requested\n+      List<MergedAnomalyResultDTO> anomalies = this.anomalyDAO.findByPredicate(predicate);\n+      Set<AnomalyFeedbackType> feedbackFilters =\n+          searchFilter.getFeedbacks().stream().map(AnomalyFeedbackType::valueOf).collect(Collectors.toSet());\n+      results = anomalies.stream()\n+          .filter(anomaly -> (anomaly.getFeedback() == null && feedbackFilters.contains(NO_FEEDBACK)) || (\n+              anomaly.getFeedback() != null && feedbackFilters.contains(anomaly.getFeedback().getFeedbackType())))\n+          .sorted(Comparator.comparingLong(AbstractDTO::getId).reversed())\n+          .collect(Collectors.toList());\n+      count = results.size();\n+      results = paginateResults(results, offset, limit);\n+    }\n+    return ImmutableMap.of(\"count\", count, \"limit\", limit, \"offset\", offset, \"elements\", results);\n+  }\n+\n+  private <T> List<T> paginateResults(List<T> list, int offset, int limit) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9586523bc5505524dfc7d985321f96f9130bae10"}, "originalPosition": 155}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTIzOTY4Nw==", "bodyText": "+1, good to see you Bryan!", "url": "https://github.com/apache/pinot/pull/5778#discussion_r465239687", "createdAt": "2020-08-04T18:16:10Z", "author": {"login": "akshayrai"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/dashboard/resources/v2/anomalies/AnomalySearcher.java", "diffHunk": "@@ -0,0 +1,142 @@\n+package org.apache.pinot.thirdeye.dashboard.resources.v2.anomalies;\n+\n+import com.google.common.collect.ImmutableMap;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.pinot.thirdeye.constant.AnomalyFeedbackType;\n+import org.apache.pinot.thirdeye.datalayer.bao.DetectionAlertConfigManager;\n+import org.apache.pinot.thirdeye.datalayer.bao.DetectionConfigManager;\n+import org.apache.pinot.thirdeye.datalayer.bao.MergedAnomalyResultManager;\n+import org.apache.pinot.thirdeye.datalayer.dto.AbstractDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.MergedAnomalyResultDTO;\n+import org.apache.pinot.thirdeye.datalayer.pojo.DetectionConfigBean;\n+import org.apache.pinot.thirdeye.datalayer.util.Predicate;\n+import org.apache.pinot.thirdeye.datasource.DAORegistry;\n+\n+import static org.apache.pinot.thirdeye.constant.AnomalyFeedbackType.*;\n+\n+\n+/**\n+ * The type Anomaly searcher.\n+ */\n+public class AnomalySearcher {\n+  private final MergedAnomalyResultManager anomalyDAO;\n+  private final DetectionConfigManager detectionConfigDAO;\n+  private final DetectionAlertConfigManager detectionAlertConfigDAO;\n+\n+  /**\n+   * Instantiates a new Anomaly searcher.\n+   */\n+  public AnomalySearcher() {\n+    this.anomalyDAO = DAORegistry.getInstance().getMergedAnomalyResultDAO();\n+    this.detectionConfigDAO = DAORegistry.getInstance().getDetectionConfigManager();\n+    this.detectionAlertConfigDAO = DAORegistry.getInstance().getDetectionAlertConfigManager();\n+  }\n+\n+  /**\n+   * Search and retrieve all the anomalies matching to the search filter and limits.\n+   *\n+   * @param searchFilter the search filter\n+   * @param limit the limit\n+   * @param offset the offset\n+   * @return the result\n+   */\n+  public Map<String, Object> search(AnomalySearchFilter searchFilter, int limit, int offset) {\n+    Predicate predicate = Predicate.EQ(\"child\", false);\n+    if (searchFilter.getStartTime() != null) {\n+      predicate = Predicate.AND(predicate, Predicate.LT(\"startTime\", searchFilter.getEndTime()));\n+    }\n+    if (searchFilter.getEndTime() != null) {\n+      predicate = Predicate.AND(predicate, Predicate.GT(\"endTime\", searchFilter.getStartTime()));\n+    }\n+    // search by detections or subscription groups\n+    Set<Long> detectionConfigIds = new HashSet<>();\n+    Set<Long> subscribedDetectionConfigIds = new HashSet<>();\n+    if (!searchFilter.getDetectionNames().isEmpty()) {\n+      detectionConfigIds =\n+          this.detectionConfigDAO.findByPredicate(Predicate.IN(\"name\", searchFilter.getDetectionNames().toArray()))\n+              .stream()\n+              .map(DetectionConfigBean::getId)\n+              .collect(Collectors.toSet());\n+    }\n+    if (!searchFilter.getSubscriptionGroups().isEmpty()) {\n+      subscribedDetectionConfigIds = this.detectionAlertConfigDAO.findByPredicate(\n+          Predicate.IN(\"name\", searchFilter.getSubscriptionGroups().toArray()))\n+          .stream()\n+          .map(detectionAlertConfigDTO -> detectionAlertConfigDTO.getVectorClocks().keySet())\n+          .flatMap(Collection::stream)\n+          .collect(Collectors.toSet());\n+    }\n+    if (!searchFilter.getDetectionNames().isEmpty() && !searchFilter.getSubscriptionGroups().isEmpty()) {\n+      // intersect the detection config ids if searching by both\n+      detectionConfigIds.retainAll(subscribedDetectionConfigIds);\n+    } else {\n+      detectionConfigIds.addAll(subscribedDetectionConfigIds);\n+    }\n+    if (!searchFilter.getDetectionNames().isEmpty() || !searchFilter.getSubscriptionGroups().isEmpty()) {\n+      // add the predicate using detection config id\n+      if (detectionConfigIds.isEmpty()) {\n+        // if detection not found, return empty result\n+        return ImmutableMap.of(\"count\", 0, \"limit\", limit, \"offset\", offset, \"elements\", Collections.emptyList());\n+      }\n+      predicate = Predicate.AND(predicate, Predicate.IN(\"detectionConfigId\", detectionConfigIds.toArray()));\n+    }\n+\n+    // search by datasets\n+    if (!searchFilter.getDatasets().isEmpty()) {\n+      List<Predicate> datasetPredicates = new ArrayList<>();\n+      for (String dataset : searchFilter.getDatasets()) {\n+        datasetPredicates.add(Predicate.LIKE(\"collection\", \"%\" + dataset + \"%\"));\n+      }\n+      predicate = Predicate.AND(predicate, Predicate.OR(datasetPredicates.toArray(new Predicate[0])));\n+    }\n+    // search by metrics\n+    if (!searchFilter.getMetrics().isEmpty()) {\n+      predicate = Predicate.AND(predicate, Predicate.IN(\"metric\", searchFilter.getMetrics().toArray()));\n+    }\n+    // search by ids\n+    if (!searchFilter.getAnomalyIds().isEmpty()) {\n+      predicate = Predicate.AND(predicate, Predicate.IN(\"baseId\", searchFilter.getAnomalyIds().toArray()));\n+    }\n+\n+    long count;\n+    List<MergedAnomalyResultDTO> results;\n+    if (searchFilter.getFeedbacks().isEmpty()) {\n+      List<Long> anomalyIds = this.anomalyDAO.findIdsByPredicate(predicate)\n+          .stream()\n+          .sorted(Comparator.reverseOrder())\n+          .collect(Collectors.toList());\n+      count = anomalyIds.size();\n+      results = anomalyIds.isEmpty() ? Collections.emptyList()\n+          : this.anomalyDAO.findByIds(paginateResults(anomalyIds, offset, limit));\n+    } else {\n+      // filter by feedback types if requested\n+      List<MergedAnomalyResultDTO> anomalies = this.anomalyDAO.findByPredicate(predicate);\n+      Set<AnomalyFeedbackType> feedbackFilters =\n+          searchFilter.getFeedbacks().stream().map(AnomalyFeedbackType::valueOf).collect(Collectors.toSet());\n+      results = anomalies.stream()\n+          .filter(anomaly -> (anomaly.getFeedback() == null && feedbackFilters.contains(NO_FEEDBACK)) || (\n+              anomaly.getFeedback() != null && feedbackFilters.contains(anomaly.getFeedback().getFeedbackType())))\n+          .sorted(Comparator.comparingLong(AbstractDTO::getId).reversed())\n+          .collect(Collectors.toList());\n+      count = results.size();\n+      results = paginateResults(results, offset, limit);\n+    }\n+    return ImmutableMap.of(\"count\", count, \"limit\", limit, \"offset\", offset, \"elements\", results);\n+  }\n+\n+  private <T> List<T> paginateResults(List<T> list, int offset, int limit) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzMxNzA1Nw=="}, "originalCommit": {"oid": "ee879b17116fe46cb33b5cdb548ea602313692e0"}, "originalPosition": 135}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bc2a834ad4443a7f7de77b454993e8de25d90d0b", "author": {"user": {"login": "jihaozh", "name": "Jihao Zhang"}}, "url": "https://github.com/apache/pinot/commit/bc2a834ad4443a7f7de77b454993e8de25d90d0b", "committedDate": "2020-08-04T18:40:52Z", "message": "- new anomalies endpoint and unit tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d411dcdd2902a4fb42c2f88e39f8c4aba4b5bd03", "author": {"user": {"login": "jihaozh", "name": "Jihao Zhang"}}, "url": "https://github.com/apache/pinot/commit/d411dcdd2902a4fb42c2f88e39f8c4aba4b5bd03", "committedDate": "2020-08-04T18:44:37Z", "message": "address comments"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9586523bc5505524dfc7d985321f96f9130bae10", "author": {"user": {"login": "jihaozh", "name": "Jihao Zhang"}}, "url": "https://github.com/apache/pinot/commit/9586523bc5505524dfc7d985321f96f9130bae10", "committedDate": "2020-08-03T20:26:22Z", "message": "address comments"}, "afterCommit": {"oid": "d411dcdd2902a4fb42c2f88e39f8c4aba4b5bd03", "author": {"user": {"login": "jihaozh", "name": "Jihao Zhang"}}, "url": "https://github.com/apache/pinot/commit/d411dcdd2902a4fb42c2f88e39f8c4aba4b5bd03", "committedDate": "2020-08-04T18:44:37Z", "message": "address comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDYxMDk2ODg5", "url": "https://github.com/apache/pinot/pull/5778#pullrequestreview-461096889", "createdAt": "2020-08-04T19:17:26Z", "commit": {"oid": "d411dcdd2902a4fb42c2f88e39f8c4aba4b5bd03"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDYxMTA3NDYw", "url": "https://github.com/apache/pinot/pull/5778#pullrequestreview-461107460", "createdAt": "2020-08-04T19:24:16Z", "commit": {"oid": "d411dcdd2902a4fb42c2f88e39f8c4aba4b5bd03"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 507, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}