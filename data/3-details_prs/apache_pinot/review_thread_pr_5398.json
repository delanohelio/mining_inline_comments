{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE4ODc3Mjgy", "number": 5398, "reviewThreads": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQyMjowNTo1NVrOD9_TSw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxOToxMzozNVrOD-t5mQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2MzI2ODU5OnYy", "diffSide": "RIGHT", "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/dataquality/DataQualityPipelineJob.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQyMjowNTo1NVrOGX0U1Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQwMDoxMTo1MFrOGYiC6g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzYyNzczMw==", "bodyText": "Add some documents on public class.", "url": "https://github.com/apache/pinot/pull/5398#discussion_r427627733", "createdAt": "2020-05-19T22:05:55Z", "author": {"login": "xiaohui-sun"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/dataquality/DataQualityPipelineJob.java", "diffHunk": "@@ -26,14 +26,16 @@\n import org.apache.pinot.thirdeye.datalayer.bao.TaskManager;\n import org.apache.pinot.thirdeye.datalayer.dto.TaskDTO;\n import org.apache.pinot.thirdeye.datasource.DAORegistry;\n+import org.apache.pinot.thirdeye.detection.DetectionPipelineTaskInfo;\n+import org.apache.pinot.thirdeye.detection.TaskUtils;\n import org.quartz.Job;\n import org.quartz.JobExecutionContext;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n \n-public class DetectionDataSLAJob implements Job {\n-  private static final Logger LOG = LoggerFactory.getLogger(DetectionDataSLAJob.class);\n+public class DataQualityPipelineJob implements Job {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "de00983f3fad38b47a3f073386998b3c9e2a4ee7"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODM3NjgxMA==", "bodyText": "Added", "url": "https://github.com/apache/pinot/pull/5398#discussion_r428376810", "createdAt": "2020-05-21T00:11:50Z", "author": {"login": "akshayrai"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/dataquality/DataQualityPipelineJob.java", "diffHunk": "@@ -26,14 +26,16 @@\n import org.apache.pinot.thirdeye.datalayer.bao.TaskManager;\n import org.apache.pinot.thirdeye.datalayer.dto.TaskDTO;\n import org.apache.pinot.thirdeye.datasource.DAORegistry;\n+import org.apache.pinot.thirdeye.detection.DetectionPipelineTaskInfo;\n+import org.apache.pinot.thirdeye.detection.TaskUtils;\n import org.quartz.Job;\n import org.quartz.JobExecutionContext;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n \n-public class DetectionDataSLAJob implements Job {\n-  private static final Logger LOG = LoggerFactory.getLogger(DetectionDataSLAJob.class);\n+public class DataQualityPipelineJob implements Job {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzYyNzczMw=="}, "originalCommit": {"oid": "de00983f3fad38b47a3f073386998b3c9e2a4ee7"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2NjM1NjkyOnYy", "diffSide": "RIGHT", "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/detection/trigger/DataAvailabilityTaskScheduler.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMFQxNTo1MzoyNVrOGYSkJw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQwMjoxOTowMVrOGYkAjQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODEyMzE3NQ==", "bodyText": "We need to have a unified naming convention for this alert.\nI think DQ is too broad. Availability is overloaded as it is used for triggering as well.\nLet's discuss.", "url": "https://github.com/apache/pinot/pull/5398#discussion_r428123175", "createdAt": "2020-05-20T15:53:25Z", "author": {"login": "xiaohui-sun"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/detection/trigger/DataAvailabilityTaskScheduler.java", "diffHunk": "@@ -122,9 +122,10 @@ public void run() {\n             long endtime = System.currentTimeMillis();\n             createDetectionTask(detectionConfig, endtime);\n \n-            if (DetectionUtils.isDataAvailabilityCheckEnabled(detectionConfig)) {\n-              createDataSLACheckTask(detectionConfig, endtime);\n-              LOG.info(\"Scheduling a task for data availability {} due to the fallback mechanism.\", detectionConfigId);\n+            if (DetectionUtils.isDataQualityCheckEnabled(detectionConfig)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "de00983f3fad38b47a3f073386998b3c9e2a4ee7"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODM3NjgwMw==", "bodyText": "Here are the conventions I am following.\n\n\"Data Availability\" refers to the event trigger pipeline and refers to dataset availability. This is not referred to in the context for the alert.\n\"Detection\" refers to all the time-series detection rules like ALGORITHM, THRESHOLD, PERCENTAGE etc.\n\"Data Quality\" refers to all the quality rules like DATA_SLA, DATA_COMPLETENESS, etc.", "url": "https://github.com/apache/pinot/pull/5398#discussion_r428376803", "createdAt": "2020-05-21T00:11:48Z", "author": {"login": "akshayrai"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/detection/trigger/DataAvailabilityTaskScheduler.java", "diffHunk": "@@ -122,9 +122,10 @@ public void run() {\n             long endtime = System.currentTimeMillis();\n             createDetectionTask(detectionConfig, endtime);\n \n-            if (DetectionUtils.isDataAvailabilityCheckEnabled(detectionConfig)) {\n-              createDataSLACheckTask(detectionConfig, endtime);\n-              LOG.info(\"Scheduling a task for data availability {} due to the fallback mechanism.\", detectionConfigId);\n+            if (DetectionUtils.isDataQualityCheckEnabled(detectionConfig)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODEyMzE3NQ=="}, "originalCommit": {"oid": "de00983f3fad38b47a3f073386998b3c9e2a4ee7"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODQwODk3Mw==", "bodyText": "That makes sense. Thanks.", "url": "https://github.com/apache/pinot/pull/5398#discussion_r428408973", "createdAt": "2020-05-21T02:19:01Z", "author": {"login": "xiaohui-sun"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/detection/trigger/DataAvailabilityTaskScheduler.java", "diffHunk": "@@ -122,9 +122,10 @@ public void run() {\n             long endtime = System.currentTimeMillis();\n             createDetectionTask(detectionConfig, endtime);\n \n-            if (DetectionUtils.isDataAvailabilityCheckEnabled(detectionConfig)) {\n-              createDataSLACheckTask(detectionConfig, endtime);\n-              LOG.info(\"Scheduling a task for data availability {} due to the fallback mechanism.\", detectionConfigId);\n+            if (DetectionUtils.isDataQualityCheckEnabled(detectionConfig)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODEyMzE3NQ=="}, "originalCommit": {"oid": "de00983f3fad38b47a3f073386998b3c9e2a4ee7"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2NjY4Mjk2OnYy", "diffSide": "RIGHT", "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/dataquality/spec/DataSlaQualityCheckerSpec.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMFQxNzoxNTowOVrOGYV4Fw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQwMDoxMTo0NlrOGYiC3Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODE3NzQzMQ==", "bodyText": "Why it is 1 day here instead of 3 days?", "url": "https://github.com/apache/pinot/pull/5398#discussion_r428177431", "createdAt": "2020-05-20T17:15:09Z", "author": {"login": "xiaohui-sun"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/dataquality/spec/DataSlaQualityCheckerSpec.java", "diffHunk": "@@ -0,0 +1,38 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.pinot.thirdeye.detection.dataquality.spec;\n+\n+import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n+import org.apache.pinot.thirdeye.dataframe.util.MetricSlice;\n+import org.apache.pinot.thirdeye.detection.spec.AbstractSpec;\n+\n+\n+@JsonIgnoreProperties(ignoreUnknown = true)\n+public class DataSlaQualityCheckerSpec extends AbstractSpec {\n+  private String sla = \"1_DAYS\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "de00983f3fad38b47a3f073386998b3c9e2a4ee7"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODM3Njc5Nw==", "bodyText": "updated", "url": "https://github.com/apache/pinot/pull/5398#discussion_r428376797", "createdAt": "2020-05-21T00:11:46Z", "author": {"login": "akshayrai"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/dataquality/spec/DataSlaQualityCheckerSpec.java", "diffHunk": "@@ -0,0 +1,38 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.pinot.thirdeye.detection.dataquality.spec;\n+\n+import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n+import org.apache.pinot.thirdeye.dataframe.util.MetricSlice;\n+import org.apache.pinot.thirdeye.detection.spec.AbstractSpec;\n+\n+\n+@JsonIgnoreProperties(ignoreUnknown = true)\n+public class DataSlaQualityCheckerSpec extends AbstractSpec {\n+  private String sla = \"1_DAYS\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODE3NzQzMQ=="}, "originalCommit": {"oid": "de00983f3fad38b47a3f073386998b3c9e2a4ee7"}, "originalPosition": 29}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2NjY5NTQzOnYy", "diffSide": "RIGHT", "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/dataquality/components/DataSlaQualityChecker.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMFQxNzoxODozOVrOGYWAKA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQwMjoxOToyN1rOGYkA9g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODE3OTQ5Ng==", "bodyText": "Why the logic is so complicated?\nCan we just compare the data last time vs the expected refresh time?", "url": "https://github.com/apache/pinot/pull/5398#discussion_r428179496", "createdAt": "2020-05-20T17:18:39Z", "author": {"login": "xiaohui-sun"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/dataquality/components/DataSlaQualityChecker.java", "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.pinot.thirdeye.detection.dataquality.components;\n+\n+import com.google.common.collect.ArrayListMultimap;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.pinot.thirdeye.anomaly.AnomalyType;\n+import org.apache.pinot.thirdeye.common.time.TimeGranularity;\n+import org.apache.pinot.thirdeye.dataframe.DataFrame;\n+import org.apache.pinot.thirdeye.dataframe.util.MetricSlice;\n+import org.apache.pinot.thirdeye.datalayer.dto.DatasetConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.MergedAnomalyResultDTO;\n+import org.apache.pinot.thirdeye.detection.DetectionUtils;\n+import org.apache.pinot.thirdeye.detection.InputDataFetcher;\n+import org.apache.pinot.thirdeye.detection.annotation.Components;\n+import org.apache.pinot.thirdeye.detection.annotation.DetectionTag;\n+import org.apache.pinot.thirdeye.detection.annotation.Param;\n+import org.apache.pinot.thirdeye.detection.annotation.PresentationOption;\n+import org.apache.pinot.thirdeye.detection.dataquality.spec.DataSlaQualityCheckerSpec;\n+import org.apache.pinot.thirdeye.detection.spi.components.AnomalyDetector;\n+import org.apache.pinot.thirdeye.detection.spi.components.BaselineProvider;\n+import org.apache.pinot.thirdeye.detection.spi.model.DetectionResult;\n+import org.apache.pinot.thirdeye.detection.spi.model.InputData;\n+import org.apache.pinot.thirdeye.detection.spi.model.InputDataSpec;\n+import org.apache.pinot.thirdeye.detection.spi.model.TimeSeries;\n+import org.apache.pinot.thirdeye.rootcause.impl.MetricEntity;\n+import org.joda.time.DateTime;\n+import org.joda.time.DateTimeZone;\n+import org.joda.time.Interval;\n+import org.joda.time.Period;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Performs data sla checks for the window and generates DATA_MISSING anomalies.\n+ */\n+@Components(title = \"Data Sla Quality Checker\",\n+    type = \"DATA_SLA\",\n+    tags = {DetectionTag.RULE_DETECTION},\n+    description = \"Checks if data is missing or not based on the configured sla\",\n+    presentation = {\n+        @PresentationOption(name = \"data sla\", template = \"is ${sla}\")\n+    },\n+    params = {\n+        @Param(name = \"sla\", placeholder = \"value\")\n+    })\n+public class DataSlaQualityChecker implements AnomalyDetector<DataSlaQualityCheckerSpec>, BaselineProvider<DataSlaQualityCheckerSpec> {\n+  private static final Logger LOG = LoggerFactory.getLogger(DataSlaQualityChecker.class);\n+\n+  private String sla;\n+  private InputDataFetcher dataFetcher;\n+  private final String DEFAULT_DATA_SLA = \"3_DAYS\";\n+\n+  @Override\n+  public DetectionResult runDetection(Interval window, String metricUrn) {\n+    return DetectionResult.from(runSLACheck(MetricEntity.fromURN(metricUrn), window));\n+  }\n+\n+  @Override\n+  public TimeSeries computePredictedTimeSeries(MetricSlice slice) {\n+    return TimeSeries.empty();\n+  }\n+\n+  @Override\n+  public void init(DataSlaQualityCheckerSpec spec, InputDataFetcher dataFetcher) {\n+    this.sla = spec.getSla();\n+    this.dataFetcher = dataFetcher;\n+  }\n+\n+  /**\n+   * Runs the data sla check for the window on the given metric\n+   */\n+  private List<MergedAnomalyResultDTO> runSLACheck(MetricEntity me, Interval window) {\n+    List<MergedAnomalyResultDTO> anomalies = new ArrayList<>();\n+\n+    // We want to measure the overall dataset availability (filters can be ignored)\n+    long startTime = window.getStart().getMillis();\n+    long endTime = window.getEnd().getMillis();\n+    MetricSlice metricSlice = MetricSlice.from(me.getId(), startTime, endTime, ArrayListMultimap.<String, String>create());\n+    InputData data = this.dataFetcher.fetchData(new InputDataSpec()\n+        .withTimeseriesSlices(Collections.singletonList(metricSlice))\n+        .withMetricIdsForDataset(Collections.singletonList(me.getId()))\n+        .withMetricIds(Collections.singletonList(me.getId())));\n+    DatasetConfigDTO datasetConfig = data.getDatasetForMetricId().get(me.getId());\n+\n+    try {\n+      long datasetLastRefreshTime = datasetConfig.getLastRefreshTime();\n+      if (datasetLastRefreshTime <= 0) {\n+        // no availability event -> assume we have processed data till the current detection start\n+        datasetLastRefreshTime = startTime - 1;\n+      }\n+\n+      MetricSlice slice = MetricSlice.from(me.getId(), datasetLastRefreshTime + 1, endTime);\n+      if (isMissingData(datasetLastRefreshTime, startTime)) {\n+        // Double check with data source as 2 things are possible.\n+        // 1. This dataset/source may not support availability events\n+        // 2. The data availability event pipeline has some issue.\n+\n+        DataFrame dataFrame = data.getTimeseries().get(metricSlice);\n+        if (dataFrame == null || dataFrame.isEmpty()) {\n+          // no data\n+          if (hasMissedSLA(datasetLastRefreshTime, endTime)) {\n+            anomalies.add(createDataSLAAnomaly(slice, datasetConfig));\n+          }\n+        } else {\n+          datasetLastRefreshTime = dataFrame.getDoubles(\"timestamp\").max().longValue();\n+          if (isPartialData(datasetLastRefreshTime, endTime, datasetConfig)) {\n+            if (hasMissedSLA(datasetLastRefreshTime, endTime)) {\n+              slice = MetricSlice.from(me.getId(), datasetLastRefreshTime + 1, endTime);\n+              anomalies.add(createDataSLAAnomaly(slice, datasetConfig));\n+            }\n+          }\n+        }\n+      } else if (isPartialData(datasetLastRefreshTime, endTime, datasetConfig)) {\n+        // Optimize for the common case - the common case is that the data availability events are arriving\n+        // correctly and we need not re-fetch the data to double check.\n+        if (hasMissedSLA(datasetLastRefreshTime, endTime)) {\n+          anomalies.add(createDataSLAAnomaly(slice, datasetConfig));\n+        }\n+      }\n+    } catch (Exception e) {\n+      LOG.error(String.format(\"Failed to run sla check on metric URN %s\", me.getUrn()), e);\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "de00983f3fad38b47a3f073386998b3c9e2a4ee7"}, "originalPosition": 146}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODM3Njc5OA==", "bodyText": "Not quite! We do have that core logic but the complexity comes while dealing with \"partial data\" and also trying to optimize for the common case at the same time (reduce unnecessary querying of data source).\nI have updated this section of code to make it more readable. Please review. Also, this section of code comes from the previous PR (listed here due to refactoring).", "url": "https://github.com/apache/pinot/pull/5398#discussion_r428376798", "createdAt": "2020-05-21T00:11:46Z", "author": {"login": "akshayrai"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/dataquality/components/DataSlaQualityChecker.java", "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.pinot.thirdeye.detection.dataquality.components;\n+\n+import com.google.common.collect.ArrayListMultimap;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.pinot.thirdeye.anomaly.AnomalyType;\n+import org.apache.pinot.thirdeye.common.time.TimeGranularity;\n+import org.apache.pinot.thirdeye.dataframe.DataFrame;\n+import org.apache.pinot.thirdeye.dataframe.util.MetricSlice;\n+import org.apache.pinot.thirdeye.datalayer.dto.DatasetConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.MergedAnomalyResultDTO;\n+import org.apache.pinot.thirdeye.detection.DetectionUtils;\n+import org.apache.pinot.thirdeye.detection.InputDataFetcher;\n+import org.apache.pinot.thirdeye.detection.annotation.Components;\n+import org.apache.pinot.thirdeye.detection.annotation.DetectionTag;\n+import org.apache.pinot.thirdeye.detection.annotation.Param;\n+import org.apache.pinot.thirdeye.detection.annotation.PresentationOption;\n+import org.apache.pinot.thirdeye.detection.dataquality.spec.DataSlaQualityCheckerSpec;\n+import org.apache.pinot.thirdeye.detection.spi.components.AnomalyDetector;\n+import org.apache.pinot.thirdeye.detection.spi.components.BaselineProvider;\n+import org.apache.pinot.thirdeye.detection.spi.model.DetectionResult;\n+import org.apache.pinot.thirdeye.detection.spi.model.InputData;\n+import org.apache.pinot.thirdeye.detection.spi.model.InputDataSpec;\n+import org.apache.pinot.thirdeye.detection.spi.model.TimeSeries;\n+import org.apache.pinot.thirdeye.rootcause.impl.MetricEntity;\n+import org.joda.time.DateTime;\n+import org.joda.time.DateTimeZone;\n+import org.joda.time.Interval;\n+import org.joda.time.Period;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Performs data sla checks for the window and generates DATA_MISSING anomalies.\n+ */\n+@Components(title = \"Data Sla Quality Checker\",\n+    type = \"DATA_SLA\",\n+    tags = {DetectionTag.RULE_DETECTION},\n+    description = \"Checks if data is missing or not based on the configured sla\",\n+    presentation = {\n+        @PresentationOption(name = \"data sla\", template = \"is ${sla}\")\n+    },\n+    params = {\n+        @Param(name = \"sla\", placeholder = \"value\")\n+    })\n+public class DataSlaQualityChecker implements AnomalyDetector<DataSlaQualityCheckerSpec>, BaselineProvider<DataSlaQualityCheckerSpec> {\n+  private static final Logger LOG = LoggerFactory.getLogger(DataSlaQualityChecker.class);\n+\n+  private String sla;\n+  private InputDataFetcher dataFetcher;\n+  private final String DEFAULT_DATA_SLA = \"3_DAYS\";\n+\n+  @Override\n+  public DetectionResult runDetection(Interval window, String metricUrn) {\n+    return DetectionResult.from(runSLACheck(MetricEntity.fromURN(metricUrn), window));\n+  }\n+\n+  @Override\n+  public TimeSeries computePredictedTimeSeries(MetricSlice slice) {\n+    return TimeSeries.empty();\n+  }\n+\n+  @Override\n+  public void init(DataSlaQualityCheckerSpec spec, InputDataFetcher dataFetcher) {\n+    this.sla = spec.getSla();\n+    this.dataFetcher = dataFetcher;\n+  }\n+\n+  /**\n+   * Runs the data sla check for the window on the given metric\n+   */\n+  private List<MergedAnomalyResultDTO> runSLACheck(MetricEntity me, Interval window) {\n+    List<MergedAnomalyResultDTO> anomalies = new ArrayList<>();\n+\n+    // We want to measure the overall dataset availability (filters can be ignored)\n+    long startTime = window.getStart().getMillis();\n+    long endTime = window.getEnd().getMillis();\n+    MetricSlice metricSlice = MetricSlice.from(me.getId(), startTime, endTime, ArrayListMultimap.<String, String>create());\n+    InputData data = this.dataFetcher.fetchData(new InputDataSpec()\n+        .withTimeseriesSlices(Collections.singletonList(metricSlice))\n+        .withMetricIdsForDataset(Collections.singletonList(me.getId()))\n+        .withMetricIds(Collections.singletonList(me.getId())));\n+    DatasetConfigDTO datasetConfig = data.getDatasetForMetricId().get(me.getId());\n+\n+    try {\n+      long datasetLastRefreshTime = datasetConfig.getLastRefreshTime();\n+      if (datasetLastRefreshTime <= 0) {\n+        // no availability event -> assume we have processed data till the current detection start\n+        datasetLastRefreshTime = startTime - 1;\n+      }\n+\n+      MetricSlice slice = MetricSlice.from(me.getId(), datasetLastRefreshTime + 1, endTime);\n+      if (isMissingData(datasetLastRefreshTime, startTime)) {\n+        // Double check with data source as 2 things are possible.\n+        // 1. This dataset/source may not support availability events\n+        // 2. The data availability event pipeline has some issue.\n+\n+        DataFrame dataFrame = data.getTimeseries().get(metricSlice);\n+        if (dataFrame == null || dataFrame.isEmpty()) {\n+          // no data\n+          if (hasMissedSLA(datasetLastRefreshTime, endTime)) {\n+            anomalies.add(createDataSLAAnomaly(slice, datasetConfig));\n+          }\n+        } else {\n+          datasetLastRefreshTime = dataFrame.getDoubles(\"timestamp\").max().longValue();\n+          if (isPartialData(datasetLastRefreshTime, endTime, datasetConfig)) {\n+            if (hasMissedSLA(datasetLastRefreshTime, endTime)) {\n+              slice = MetricSlice.from(me.getId(), datasetLastRefreshTime + 1, endTime);\n+              anomalies.add(createDataSLAAnomaly(slice, datasetConfig));\n+            }\n+          }\n+        }\n+      } else if (isPartialData(datasetLastRefreshTime, endTime, datasetConfig)) {\n+        // Optimize for the common case - the common case is that the data availability events are arriving\n+        // correctly and we need not re-fetch the data to double check.\n+        if (hasMissedSLA(datasetLastRefreshTime, endTime)) {\n+          anomalies.add(createDataSLAAnomaly(slice, datasetConfig));\n+        }\n+      }\n+    } catch (Exception e) {\n+      LOG.error(String.format(\"Failed to run sla check on metric URN %s\", me.getUrn()), e);\n+    }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODE3OTQ5Ng=="}, "originalCommit": {"oid": "de00983f3fad38b47a3f073386998b3c9e2a4ee7"}, "originalPosition": 146}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODQwOTA3OA==", "bodyText": "Thanks. That looks much more clear.", "url": "https://github.com/apache/pinot/pull/5398#discussion_r428409078", "createdAt": "2020-05-21T02:19:27Z", "author": {"login": "xiaohui-sun"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/dataquality/components/DataSlaQualityChecker.java", "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.pinot.thirdeye.detection.dataquality.components;\n+\n+import com.google.common.collect.ArrayListMultimap;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.pinot.thirdeye.anomaly.AnomalyType;\n+import org.apache.pinot.thirdeye.common.time.TimeGranularity;\n+import org.apache.pinot.thirdeye.dataframe.DataFrame;\n+import org.apache.pinot.thirdeye.dataframe.util.MetricSlice;\n+import org.apache.pinot.thirdeye.datalayer.dto.DatasetConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.MergedAnomalyResultDTO;\n+import org.apache.pinot.thirdeye.detection.DetectionUtils;\n+import org.apache.pinot.thirdeye.detection.InputDataFetcher;\n+import org.apache.pinot.thirdeye.detection.annotation.Components;\n+import org.apache.pinot.thirdeye.detection.annotation.DetectionTag;\n+import org.apache.pinot.thirdeye.detection.annotation.Param;\n+import org.apache.pinot.thirdeye.detection.annotation.PresentationOption;\n+import org.apache.pinot.thirdeye.detection.dataquality.spec.DataSlaQualityCheckerSpec;\n+import org.apache.pinot.thirdeye.detection.spi.components.AnomalyDetector;\n+import org.apache.pinot.thirdeye.detection.spi.components.BaselineProvider;\n+import org.apache.pinot.thirdeye.detection.spi.model.DetectionResult;\n+import org.apache.pinot.thirdeye.detection.spi.model.InputData;\n+import org.apache.pinot.thirdeye.detection.spi.model.InputDataSpec;\n+import org.apache.pinot.thirdeye.detection.spi.model.TimeSeries;\n+import org.apache.pinot.thirdeye.rootcause.impl.MetricEntity;\n+import org.joda.time.DateTime;\n+import org.joda.time.DateTimeZone;\n+import org.joda.time.Interval;\n+import org.joda.time.Period;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Performs data sla checks for the window and generates DATA_MISSING anomalies.\n+ */\n+@Components(title = \"Data Sla Quality Checker\",\n+    type = \"DATA_SLA\",\n+    tags = {DetectionTag.RULE_DETECTION},\n+    description = \"Checks if data is missing or not based on the configured sla\",\n+    presentation = {\n+        @PresentationOption(name = \"data sla\", template = \"is ${sla}\")\n+    },\n+    params = {\n+        @Param(name = \"sla\", placeholder = \"value\")\n+    })\n+public class DataSlaQualityChecker implements AnomalyDetector<DataSlaQualityCheckerSpec>, BaselineProvider<DataSlaQualityCheckerSpec> {\n+  private static final Logger LOG = LoggerFactory.getLogger(DataSlaQualityChecker.class);\n+\n+  private String sla;\n+  private InputDataFetcher dataFetcher;\n+  private final String DEFAULT_DATA_SLA = \"3_DAYS\";\n+\n+  @Override\n+  public DetectionResult runDetection(Interval window, String metricUrn) {\n+    return DetectionResult.from(runSLACheck(MetricEntity.fromURN(metricUrn), window));\n+  }\n+\n+  @Override\n+  public TimeSeries computePredictedTimeSeries(MetricSlice slice) {\n+    return TimeSeries.empty();\n+  }\n+\n+  @Override\n+  public void init(DataSlaQualityCheckerSpec spec, InputDataFetcher dataFetcher) {\n+    this.sla = spec.getSla();\n+    this.dataFetcher = dataFetcher;\n+  }\n+\n+  /**\n+   * Runs the data sla check for the window on the given metric\n+   */\n+  private List<MergedAnomalyResultDTO> runSLACheck(MetricEntity me, Interval window) {\n+    List<MergedAnomalyResultDTO> anomalies = new ArrayList<>();\n+\n+    // We want to measure the overall dataset availability (filters can be ignored)\n+    long startTime = window.getStart().getMillis();\n+    long endTime = window.getEnd().getMillis();\n+    MetricSlice metricSlice = MetricSlice.from(me.getId(), startTime, endTime, ArrayListMultimap.<String, String>create());\n+    InputData data = this.dataFetcher.fetchData(new InputDataSpec()\n+        .withTimeseriesSlices(Collections.singletonList(metricSlice))\n+        .withMetricIdsForDataset(Collections.singletonList(me.getId()))\n+        .withMetricIds(Collections.singletonList(me.getId())));\n+    DatasetConfigDTO datasetConfig = data.getDatasetForMetricId().get(me.getId());\n+\n+    try {\n+      long datasetLastRefreshTime = datasetConfig.getLastRefreshTime();\n+      if (datasetLastRefreshTime <= 0) {\n+        // no availability event -> assume we have processed data till the current detection start\n+        datasetLastRefreshTime = startTime - 1;\n+      }\n+\n+      MetricSlice slice = MetricSlice.from(me.getId(), datasetLastRefreshTime + 1, endTime);\n+      if (isMissingData(datasetLastRefreshTime, startTime)) {\n+        // Double check with data source as 2 things are possible.\n+        // 1. This dataset/source may not support availability events\n+        // 2. The data availability event pipeline has some issue.\n+\n+        DataFrame dataFrame = data.getTimeseries().get(metricSlice);\n+        if (dataFrame == null || dataFrame.isEmpty()) {\n+          // no data\n+          if (hasMissedSLA(datasetLastRefreshTime, endTime)) {\n+            anomalies.add(createDataSLAAnomaly(slice, datasetConfig));\n+          }\n+        } else {\n+          datasetLastRefreshTime = dataFrame.getDoubles(\"timestamp\").max().longValue();\n+          if (isPartialData(datasetLastRefreshTime, endTime, datasetConfig)) {\n+            if (hasMissedSLA(datasetLastRefreshTime, endTime)) {\n+              slice = MetricSlice.from(me.getId(), datasetLastRefreshTime + 1, endTime);\n+              anomalies.add(createDataSLAAnomaly(slice, datasetConfig));\n+            }\n+          }\n+        }\n+      } else if (isPartialData(datasetLastRefreshTime, endTime, datasetConfig)) {\n+        // Optimize for the common case - the common case is that the data availability events are arriving\n+        // correctly and we need not re-fetch the data to double check.\n+        if (hasMissedSLA(datasetLastRefreshTime, endTime)) {\n+          anomalies.add(createDataSLAAnomaly(slice, datasetConfig));\n+        }\n+      }\n+    } catch (Exception e) {\n+      LOG.error(String.format(\"Failed to run sla check on metric URN %s\", me.getUrn()), e);\n+    }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODE3OTQ5Ng=="}, "originalCommit": {"oid": "de00983f3fad38b47a3f073386998b3c9e2a4ee7"}, "originalPosition": 146}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2Nzk5MDczOnYy", "diffSide": "RIGHT", "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/yaml/translator/builder/DetectionConfigTranslatorBuilder.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQwMDo1Mjo1MVrOGYitjw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxOToxMDoxN1rOGY_VZQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODM4NzcyNw==", "bodyText": "nit: Why it's called DetectionConfigTranslatorBuilder instead of DetectionConfigBuilder or DetectionPropertyBuilder. Because it seems the result it produces is a config property, not the translator.", "url": "https://github.com/apache/pinot/pull/5398#discussion_r428387727", "createdAt": "2020-05-21T00:52:51Z", "author": {"login": "jihaozh"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/yaml/translator/builder/DetectionConfigTranslatorBuilder.java", "diffHunk": "@@ -0,0 +1,223 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.pinot.thirdeye.detection.yaml.translator.builder;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.commons.collections4.MapUtils;\n+import org.apache.pinot.thirdeye.datalayer.dto.MetricConfigDTO;\n+import org.apache.pinot.thirdeye.detection.ConfigUtils;\n+import org.apache.pinot.thirdeye.detection.DataProvider;\n+import org.apache.pinot.thirdeye.detection.DetectionUtils;\n+import org.apache.pinot.thirdeye.detection.annotation.registry.DetectionRegistry;\n+import org.apache.pinot.thirdeye.detection.wrapper.ChildKeepingMergeWrapper;\n+import org.apache.pinot.thirdeye.detection.wrapper.EntityAnomalyMergeWrapper;\n+import org.apache.pinot.thirdeye.detection.wrapper.GrouperWrapper;\n+import org.apache.pinot.thirdeye.detection.yaml.translator.DetectionMetricAttributeHolder;\n+import org.apache.pinot.thirdeye.rootcause.impl.MetricEntity;\n+\n+import static org.apache.pinot.thirdeye.detection.yaml.DetectionConfigTuner.*;\n+\n+\n+/**\n+ * This is the root of the detection config translator builder. Other translators\n+ * extend from this class.\n+ */\n+public abstract class DetectionConfigTranslatorBuilder {\n+\n+  public static final String PROP_SUB_ENTITY_NAME = \"subEntityName\";\n+  public static final String PROP_DIMENSION_EXPLORATION = \"dimensionExploration\";\n+  public static final String PROP_FILTERS = \"filters\";\n+\n+  static final String PROP_DETECTION = \"detection\";\n+  static final String PROP_FILTER = \"filter\";\n+  static final String PROP_QUALITY = \"quality\";\n+  static final String PROP_TYPE = \"type\";\n+  static final String PROP_CLASS_NAME = \"className\";\n+  static final String PROP_PARAMS = \"params\";\n+  static final String PROP_METRIC_URN = \"metricUrn\";\n+  static final String PROP_DIMENSION_FILTER_METRIC = \"dimensionFilterMetric\";\n+  static final String PROP_NESTED_METRIC_URNS = \"nestedMetricUrns\";\n+  static final String PROP_RULES = \"rules\";\n+  static final String PROP_GROUPER = \"grouper\";\n+  static final String PROP_NESTED = \"nested\";\n+  static final String PROP_BASELINE_PROVIDER = \"baselineValueProvider\";\n+  static final String PROP_DETECTOR = \"detector\";\n+  static final String PROP_MOVING_WINDOW_DETECTION = \"isMovingWindowDetection\";\n+  static final String PROP_WINDOW_DELAY = \"windowDelay\";\n+  static final String PROP_WINDOW_DELAY_UNIT = \"windowDelayUnit\";\n+  static final String PROP_WINDOW_SIZE = \"windowSize\";\n+  static final String PROP_WINDOW_UNIT = \"windowUnit\";\n+  static final String PROP_FREQUENCY = \"frequency\";\n+  static final String PROP_MERGER = \"merger\";\n+  static final String PROP_TIMEZONE = \"timezone\";\n+  static final String PROP_NAME = \"name\";\n+\n+  static final String DEFAULT_BASELINE_PROVIDER_YAML_TYPE = \"RULE_BASELINE\";\n+  static final String PROP_BUCKET_PERIOD = \"bucketPeriod\";\n+  static final String PROP_CACHE_PERIOD_LOOKBACK = \"cachingPeriodLookback\";\n+\n+  static final String PROP_ALERTS = \"alerts\";\n+  static final String COMPOSITE_ALERT = \"COMPOSITE_ALERT\";\n+\n+  final DetectionMetricAttributeHolder metricAttributesMap;\n+  final DataProvider dataProvider;\n+  static final DetectionRegistry DETECTION_REGISTRY = DetectionRegistry.getInstance();\n+\n+  DetectionConfigTranslatorBuilder(DetectionMetricAttributeHolder metricAttributesMap, DataProvider dataProvider) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6e19edebe46759370a8e243aa3f8594c6b0d69bd"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODg1NjY3Nw==", "bodyText": "Renamed them to ...PropertiesBuilder", "url": "https://github.com/apache/pinot/pull/5398#discussion_r428856677", "createdAt": "2020-05-21T19:10:17Z", "author": {"login": "akshayrai"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/yaml/translator/builder/DetectionConfigTranslatorBuilder.java", "diffHunk": "@@ -0,0 +1,223 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.pinot.thirdeye.detection.yaml.translator.builder;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.commons.collections4.MapUtils;\n+import org.apache.pinot.thirdeye.datalayer.dto.MetricConfigDTO;\n+import org.apache.pinot.thirdeye.detection.ConfigUtils;\n+import org.apache.pinot.thirdeye.detection.DataProvider;\n+import org.apache.pinot.thirdeye.detection.DetectionUtils;\n+import org.apache.pinot.thirdeye.detection.annotation.registry.DetectionRegistry;\n+import org.apache.pinot.thirdeye.detection.wrapper.ChildKeepingMergeWrapper;\n+import org.apache.pinot.thirdeye.detection.wrapper.EntityAnomalyMergeWrapper;\n+import org.apache.pinot.thirdeye.detection.wrapper.GrouperWrapper;\n+import org.apache.pinot.thirdeye.detection.yaml.translator.DetectionMetricAttributeHolder;\n+import org.apache.pinot.thirdeye.rootcause.impl.MetricEntity;\n+\n+import static org.apache.pinot.thirdeye.detection.yaml.DetectionConfigTuner.*;\n+\n+\n+/**\n+ * This is the root of the detection config translator builder. Other translators\n+ * extend from this class.\n+ */\n+public abstract class DetectionConfigTranslatorBuilder {\n+\n+  public static final String PROP_SUB_ENTITY_NAME = \"subEntityName\";\n+  public static final String PROP_DIMENSION_EXPLORATION = \"dimensionExploration\";\n+  public static final String PROP_FILTERS = \"filters\";\n+\n+  static final String PROP_DETECTION = \"detection\";\n+  static final String PROP_FILTER = \"filter\";\n+  static final String PROP_QUALITY = \"quality\";\n+  static final String PROP_TYPE = \"type\";\n+  static final String PROP_CLASS_NAME = \"className\";\n+  static final String PROP_PARAMS = \"params\";\n+  static final String PROP_METRIC_URN = \"metricUrn\";\n+  static final String PROP_DIMENSION_FILTER_METRIC = \"dimensionFilterMetric\";\n+  static final String PROP_NESTED_METRIC_URNS = \"nestedMetricUrns\";\n+  static final String PROP_RULES = \"rules\";\n+  static final String PROP_GROUPER = \"grouper\";\n+  static final String PROP_NESTED = \"nested\";\n+  static final String PROP_BASELINE_PROVIDER = \"baselineValueProvider\";\n+  static final String PROP_DETECTOR = \"detector\";\n+  static final String PROP_MOVING_WINDOW_DETECTION = \"isMovingWindowDetection\";\n+  static final String PROP_WINDOW_DELAY = \"windowDelay\";\n+  static final String PROP_WINDOW_DELAY_UNIT = \"windowDelayUnit\";\n+  static final String PROP_WINDOW_SIZE = \"windowSize\";\n+  static final String PROP_WINDOW_UNIT = \"windowUnit\";\n+  static final String PROP_FREQUENCY = \"frequency\";\n+  static final String PROP_MERGER = \"merger\";\n+  static final String PROP_TIMEZONE = \"timezone\";\n+  static final String PROP_NAME = \"name\";\n+\n+  static final String DEFAULT_BASELINE_PROVIDER_YAML_TYPE = \"RULE_BASELINE\";\n+  static final String PROP_BUCKET_PERIOD = \"bucketPeriod\";\n+  static final String PROP_CACHE_PERIOD_LOOKBACK = \"cachingPeriodLookback\";\n+\n+  static final String PROP_ALERTS = \"alerts\";\n+  static final String COMPOSITE_ALERT = \"COMPOSITE_ALERT\";\n+\n+  final DetectionMetricAttributeHolder metricAttributesMap;\n+  final DataProvider dataProvider;\n+  static final DetectionRegistry DETECTION_REGISTRY = DetectionRegistry.getInstance();\n+\n+  DetectionConfigTranslatorBuilder(DetectionMetricAttributeHolder metricAttributesMap, DataProvider dataProvider) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODM4NzcyNw=="}, "originalCommit": {"oid": "6e19edebe46759370a8e243aa3f8594c6b0d69bd"}, "originalPosition": 88}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2Nzk5MzEzOnYy", "diffSide": "RIGHT", "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/wrapper/DataQualityMergeWrapper.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQwMDo1NDowOVrOGYiu-Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxOToxMDoxNVrOGY_VWA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODM4ODA4OQ==", "bodyText": "should this merger only retrieve and handle the anomalies with SLA type?", "url": "https://github.com/apache/pinot/pull/5398#discussion_r428388089", "createdAt": "2020-05-21T00:54:09Z", "author": {"login": "jihaozh"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/wrapper/DataQualityMergeWrapper.java", "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.pinot.thirdeye.detection.wrapper;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import org.apache.pinot.thirdeye.datalayer.dto.DetectionConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.MergedAnomalyResultDTO;\n+import org.apache.pinot.thirdeye.detection.DataProvider;\n+import org.apache.pinot.thirdeye.detection.algorithm.MergeWrapper;\n+import org.apache.pinot.thirdeye.detection.spi.model.AnomalySlice;\n+\n+\n+/**\n+ * The Data Quality Merge Wrapper. This merge wrapper is specifically designed keeping the sla anomalies in mind.\n+ * We might need to revisit this when more data quality rules are added. Fundamentally, the data sla anomalies are never\n+ * merged as we want to keep re-notifying users if the sla is missed after every detection. This merger will ensure no\n+ * duplicate sla anomalies are created if the detection runs more frequently and will serve as a placeholder for future\n+ * merging logic.\n+ */\n+public class DataQualityMergeWrapper extends MergeWrapper {\n+  private static final String PROP_GROUP_KEY = \"groupKey\";\n+\n+  public DataQualityMergeWrapper(DataProvider provider, DetectionConfigDTO config, long startTime, long endTime) {\n+    super(provider, config, startTime, endTime);\n+  }\n+\n+  @Override\n+  protected List<MergedAnomalyResultDTO> retrieveAnomaliesFromDatabase(List<MergedAnomalyResultDTO> generated) {\n+    AnomalySlice effectiveSlice = this.slice.withDetectionId(this.config.getId())\n+        .withStart(this.getStartTime(generated) - this.maxGap - 1)\n+        .withEnd(this.getEndTime(generated) + this.maxGap + 1);\n+\n+    Collection<MergedAnomalyResultDTO> anomalies =\n+        this.provider.fetchAnomalies(Collections.singleton(effectiveSlice)).get(effectiveSlice);\n+\n+    return anomalies.stream().filter(anomaly -> !anomaly.isChild()).collect(Collectors.toList());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6e19edebe46759370a8e243aa3f8594c6b0d69bd"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODg1NjY2NA==", "bodyText": "The merger anyways has an anomaly key but makes sense to logically filter out. Updated here and the ChildKeepingMerger.", "url": "https://github.com/apache/pinot/pull/5398#discussion_r428856664", "createdAt": "2020-05-21T19:10:15Z", "author": {"login": "akshayrai"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/wrapper/DataQualityMergeWrapper.java", "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.pinot.thirdeye.detection.wrapper;\n+\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import org.apache.pinot.thirdeye.datalayer.dto.DetectionConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.MergedAnomalyResultDTO;\n+import org.apache.pinot.thirdeye.detection.DataProvider;\n+import org.apache.pinot.thirdeye.detection.algorithm.MergeWrapper;\n+import org.apache.pinot.thirdeye.detection.spi.model.AnomalySlice;\n+\n+\n+/**\n+ * The Data Quality Merge Wrapper. This merge wrapper is specifically designed keeping the sla anomalies in mind.\n+ * We might need to revisit this when more data quality rules are added. Fundamentally, the data sla anomalies are never\n+ * merged as we want to keep re-notifying users if the sla is missed after every detection. This merger will ensure no\n+ * duplicate sla anomalies are created if the detection runs more frequently and will serve as a placeholder for future\n+ * merging logic.\n+ */\n+public class DataQualityMergeWrapper extends MergeWrapper {\n+  private static final String PROP_GROUP_KEY = \"groupKey\";\n+\n+  public DataQualityMergeWrapper(DataProvider provider, DetectionConfigDTO config, long startTime, long endTime) {\n+    super(provider, config, startTime, endTime);\n+  }\n+\n+  @Override\n+  protected List<MergedAnomalyResultDTO> retrieveAnomaliesFromDatabase(List<MergedAnomalyResultDTO> generated) {\n+    AnomalySlice effectiveSlice = this.slice.withDetectionId(this.config.getId())\n+        .withStart(this.getStartTime(generated) - this.maxGap - 1)\n+        .withEnd(this.getEndTime(generated) + this.maxGap + 1);\n+\n+    Collection<MergedAnomalyResultDTO> anomalies =\n+        this.provider.fetchAnomalies(Collections.singleton(effectiveSlice)).get(effectiveSlice);\n+\n+    return anomalies.stream().filter(anomaly -> !anomaly.isChild()).collect(Collectors.toList());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODM4ODA4OQ=="}, "originalCommit": {"oid": "6e19edebe46759370a8e243aa3f8594c6b0d69bd"}, "originalPosition": 59}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2ODAxNDgyOnYy", "diffSide": "RIGHT", "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/scheduler/DetectionCronScheduler.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQwMTowODowMFrOGYi8Vw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxOToxMDoxNVrOGY_VUw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODM5MTUxMQ==", "bodyText": "will there be a case that the detection and data quality check has different corn?", "url": "https://github.com/apache/pinot/pull/5398#discussion_r428391511", "createdAt": "2020-05-21T01:08:00Z", "author": {"login": "jihaozh"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/scheduler/DetectionCronScheduler.java", "diffHunk": "@@ -79,28 +81,45 @@ public void run() {\n \n       // add or update\n       for (DetectionConfigDTO config : configs) {\n-        JobKey key = new JobKey(getJobKey(config.getId()), TaskConstants.TaskType.DETECTION.toString());\n         if (!config.isActive()) {\n-          LOG.debug(\"Detection config \" + key + \" is inactive. Skipping.\");\n+          LOG.debug(\"Detection config \" + config.getId() + \" is inactive. Skipping.\");\n           continue;\n         }\n-        if (DetectionUtils.isDataAvailabilityCheckEnabled(config)) {\n-          LOG.debug(\"Detection config \" + key + \" is enabled for data availability scheduling. Skipping.\");\n+        if (config.isDataAvailabilitySchedule()) {\n+          LOG.debug(\"Detection config \" + config.getId() + \" is enabled for data availability scheduling. Skipping.\");\n           continue;\n         }\n+\n         try {\n-          if (scheduler.checkExists(key)) {\n-            LOG.info(\"Detection config  \" + key.getName() + \" is already scheduled\");\n-            if (isJobUpdated(config, key)) {\n-              // restart job\n-              stopJob(key);\n-              startJob(config, key);\n+          // Schedule detection jobs\n+          JobKey detectionJobKey = new JobKey(getJobKey(config.getId(), TaskConstants.TaskType.DETECTION),\n+              QUARTZ_DETECTION_GROUPER);\n+          JobDetail detectionJob = JobBuilder.newJob(DetectionPipelineJob.class).withIdentity(detectionJobKey).build();\n+          if (scheduler.checkExists(detectionJobKey)) {\n+            LOG.info(\"Detection config \" + detectionJobKey.getName() + \" is already scheduled for detection\");\n+            if (isJobUpdated(config, detectionJobKey)) {\n+              restartJob(config, detectionJob);\n+            }\n+          } else {\n+            startJob(config, detectionJob);\n+          }\n+\n+          // Schedule data quality jobs\n+          JobKey dataQualityJobKey = new JobKey(getJobKey(config.getId(), TaskConstants.TaskType.DATA_QUALITY),\n+              QUARTZ_DETECTION_GROUPER);\n+          JobDetail dataQualityJob = JobBuilder.newJob(DataQualityPipelineJob.class).withIdentity(dataQualityJobKey).build();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6e19edebe46759370a8e243aa3f8594c6b0d69bd"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODg1NjY1OQ==", "bodyText": "By design the detection config supports only 1 cron. If we need a different cron, then we can setup another alert.", "url": "https://github.com/apache/pinot/pull/5398#discussion_r428856659", "createdAt": "2020-05-21T19:10:15Z", "author": {"login": "akshayrai"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/scheduler/DetectionCronScheduler.java", "diffHunk": "@@ -79,28 +81,45 @@ public void run() {\n \n       // add or update\n       for (DetectionConfigDTO config : configs) {\n-        JobKey key = new JobKey(getJobKey(config.getId()), TaskConstants.TaskType.DETECTION.toString());\n         if (!config.isActive()) {\n-          LOG.debug(\"Detection config \" + key + \" is inactive. Skipping.\");\n+          LOG.debug(\"Detection config \" + config.getId() + \" is inactive. Skipping.\");\n           continue;\n         }\n-        if (DetectionUtils.isDataAvailabilityCheckEnabled(config)) {\n-          LOG.debug(\"Detection config \" + key + \" is enabled for data availability scheduling. Skipping.\");\n+        if (config.isDataAvailabilitySchedule()) {\n+          LOG.debug(\"Detection config \" + config.getId() + \" is enabled for data availability scheduling. Skipping.\");\n           continue;\n         }\n+\n         try {\n-          if (scheduler.checkExists(key)) {\n-            LOG.info(\"Detection config  \" + key.getName() + \" is already scheduled\");\n-            if (isJobUpdated(config, key)) {\n-              // restart job\n-              stopJob(key);\n-              startJob(config, key);\n+          // Schedule detection jobs\n+          JobKey detectionJobKey = new JobKey(getJobKey(config.getId(), TaskConstants.TaskType.DETECTION),\n+              QUARTZ_DETECTION_GROUPER);\n+          JobDetail detectionJob = JobBuilder.newJob(DetectionPipelineJob.class).withIdentity(detectionJobKey).build();\n+          if (scheduler.checkExists(detectionJobKey)) {\n+            LOG.info(\"Detection config \" + detectionJobKey.getName() + \" is already scheduled for detection\");\n+            if (isJobUpdated(config, detectionJobKey)) {\n+              restartJob(config, detectionJob);\n+            }\n+          } else {\n+            startJob(config, detectionJob);\n+          }\n+\n+          // Schedule data quality jobs\n+          JobKey dataQualityJobKey = new JobKey(getJobKey(config.getId(), TaskConstants.TaskType.DATA_QUALITY),\n+              QUARTZ_DETECTION_GROUPER);\n+          JobDetail dataQualityJob = JobBuilder.newJob(DataQualityPipelineJob.class).withIdentity(dataQualityJobKey).build();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODM5MTUxMQ=="}, "originalCommit": {"oid": "6e19edebe46759370a8e243aa3f8594c6b0d69bd"}, "originalPosition": 65}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY3MDkwMzI5OnYy", "diffSide": "RIGHT", "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/dataquality/components/DataSlaQualityChecker.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxOToxMzozNVrOGY_bOg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQyMToyMjozMVrOGZDVCQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODg1ODE3MA==", "bodyText": "Should we use Duration or TimeGranularity instead of String, since we are converting it anyway?", "url": "https://github.com/apache/pinot/pull/5398#discussion_r428858170", "createdAt": "2020-05-21T19:13:35Z", "author": {"login": "vincentchenjl"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/dataquality/components/DataSlaQualityChecker.java", "diffHunk": "@@ -0,0 +1,216 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.pinot.thirdeye.detection.dataquality.components;\n+\n+import com.google.common.collect.ArrayListMultimap;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.pinot.thirdeye.anomaly.AnomalyType;\n+import org.apache.pinot.thirdeye.common.time.TimeGranularity;\n+import org.apache.pinot.thirdeye.constant.AnomalyResultSource;\n+import org.apache.pinot.thirdeye.dataframe.DataFrame;\n+import org.apache.pinot.thirdeye.dataframe.util.MetricSlice;\n+import org.apache.pinot.thirdeye.datalayer.dto.DatasetConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.MergedAnomalyResultDTO;\n+import org.apache.pinot.thirdeye.detection.DetectionUtils;\n+import org.apache.pinot.thirdeye.detection.InputDataFetcher;\n+import org.apache.pinot.thirdeye.detection.annotation.Components;\n+import org.apache.pinot.thirdeye.detection.annotation.DetectionTag;\n+import org.apache.pinot.thirdeye.detection.annotation.Param;\n+import org.apache.pinot.thirdeye.detection.annotation.PresentationOption;\n+import org.apache.pinot.thirdeye.detection.dataquality.spec.DataSlaQualityCheckerSpec;\n+import org.apache.pinot.thirdeye.detection.spi.components.AnomalyDetector;\n+import org.apache.pinot.thirdeye.detection.spi.components.BaselineProvider;\n+import org.apache.pinot.thirdeye.detection.spi.model.DetectionResult;\n+import org.apache.pinot.thirdeye.detection.spi.model.InputData;\n+import org.apache.pinot.thirdeye.detection.spi.model.InputDataSpec;\n+import org.apache.pinot.thirdeye.detection.spi.model.TimeSeries;\n+import org.apache.pinot.thirdeye.rootcause.impl.MetricEntity;\n+import org.joda.time.DateTime;\n+import org.joda.time.DateTimeZone;\n+import org.joda.time.Interval;\n+import org.joda.time.Period;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Performs data sla checks for the window and generates DATA_SLA anomalies.\n+ *\n+ * Data SLA is verified based on the following information.\n+ * a. The dataset refresh timestamp updated by the event based data availability pipeline (if applicable).\n+ * b. Otherwise, we will query the data source and run sla checks.\n+ */\n+@Components(title = \"Data Sla Quality Checker\",\n+    type = \"DATA_SLA\",\n+    tags = {DetectionTag.RULE_DETECTION},\n+    description = \"Checks if data is missing or not based on the configured sla\",\n+    presentation = {\n+        @PresentationOption(name = \"data sla\", template = \"is ${sla}\")\n+    },\n+    params = {\n+        @Param(name = \"sla\", placeholder = \"value\")\n+    })\n+public class DataSlaQualityChecker implements AnomalyDetector<DataSlaQualityCheckerSpec>, BaselineProvider<DataSlaQualityCheckerSpec> {\n+  private static final Logger LOG = LoggerFactory.getLogger(DataSlaQualityChecker.class);\n+\n+  private String sla;\n+  private InputDataFetcher dataFetcher;\n+  private final String DEFAULT_DATA_SLA = \"3_DAYS\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c7b9caf0df72eb9106b6c9c5d5f482a38a601a84"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODkyMjEyMQ==", "bodyText": "I kept it this way as the sla parameter is also configured by the user in the same format in their yaml config.", "url": "https://github.com/apache/pinot/pull/5398#discussion_r428922121", "createdAt": "2020-05-21T21:22:31Z", "author": {"login": "akshayrai"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/dataquality/components/DataSlaQualityChecker.java", "diffHunk": "@@ -0,0 +1,216 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.pinot.thirdeye.detection.dataquality.components;\n+\n+import com.google.common.collect.ArrayListMultimap;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.pinot.thirdeye.anomaly.AnomalyType;\n+import org.apache.pinot.thirdeye.common.time.TimeGranularity;\n+import org.apache.pinot.thirdeye.constant.AnomalyResultSource;\n+import org.apache.pinot.thirdeye.dataframe.DataFrame;\n+import org.apache.pinot.thirdeye.dataframe.util.MetricSlice;\n+import org.apache.pinot.thirdeye.datalayer.dto.DatasetConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.MergedAnomalyResultDTO;\n+import org.apache.pinot.thirdeye.detection.DetectionUtils;\n+import org.apache.pinot.thirdeye.detection.InputDataFetcher;\n+import org.apache.pinot.thirdeye.detection.annotation.Components;\n+import org.apache.pinot.thirdeye.detection.annotation.DetectionTag;\n+import org.apache.pinot.thirdeye.detection.annotation.Param;\n+import org.apache.pinot.thirdeye.detection.annotation.PresentationOption;\n+import org.apache.pinot.thirdeye.detection.dataquality.spec.DataSlaQualityCheckerSpec;\n+import org.apache.pinot.thirdeye.detection.spi.components.AnomalyDetector;\n+import org.apache.pinot.thirdeye.detection.spi.components.BaselineProvider;\n+import org.apache.pinot.thirdeye.detection.spi.model.DetectionResult;\n+import org.apache.pinot.thirdeye.detection.spi.model.InputData;\n+import org.apache.pinot.thirdeye.detection.spi.model.InputDataSpec;\n+import org.apache.pinot.thirdeye.detection.spi.model.TimeSeries;\n+import org.apache.pinot.thirdeye.rootcause.impl.MetricEntity;\n+import org.joda.time.DateTime;\n+import org.joda.time.DateTimeZone;\n+import org.joda.time.Interval;\n+import org.joda.time.Period;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Performs data sla checks for the window and generates DATA_SLA anomalies.\n+ *\n+ * Data SLA is verified based on the following information.\n+ * a. The dataset refresh timestamp updated by the event based data availability pipeline (if applicable).\n+ * b. Otherwise, we will query the data source and run sla checks.\n+ */\n+@Components(title = \"Data Sla Quality Checker\",\n+    type = \"DATA_SLA\",\n+    tags = {DetectionTag.RULE_DETECTION},\n+    description = \"Checks if data is missing or not based on the configured sla\",\n+    presentation = {\n+        @PresentationOption(name = \"data sla\", template = \"is ${sla}\")\n+    },\n+    params = {\n+        @Param(name = \"sla\", placeholder = \"value\")\n+    })\n+public class DataSlaQualityChecker implements AnomalyDetector<DataSlaQualityCheckerSpec>, BaselineProvider<DataSlaQualityCheckerSpec> {\n+  private static final Logger LOG = LoggerFactory.getLogger(DataSlaQualityChecker.class);\n+\n+  private String sla;\n+  private InputDataFetcher dataFetcher;\n+  private final String DEFAULT_DATA_SLA = \"3_DAYS\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODg1ODE3MA=="}, "originalCommit": {"oid": "c7b9caf0df72eb9106b6c9c5d5f482a38a601a84"}, "originalPosition": 80}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3283, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}