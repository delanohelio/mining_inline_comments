{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzYzMzA5MTA3", "number": 4988, "title": "[TE] Support weekly anomaly detection", "bodyText": "This PR adds the capability to run anomaly detection on a weekly aggregated data on an hourly/daily metric. It will aggregate the data into weekly data and run the detection algorithm (Percentage change). Users can specify the desired week start day for aggregation.", "createdAt": "2020-01-15T19:51:34Z", "url": "https://github.com/apache/pinot/pull/4988", "merged": true, "mergeCommit": {"oid": "71b0b58c106db62f034be816babdf9f03ff2157a"}, "closed": true, "closedAt": "2020-01-17T01:06:41Z", "author": {"login": "jihaozh"}, "timelineItems": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABb6qt4kAH2gAyMzYzMzA5MTA3OjUxYTUxZjg0ZjIxZGVhYTZiMTA1YjQ2MDBjNjE3MDg5MTAzNGJiOWY=", "endCursor": "Y3Vyc29yOnYyOpPPAAABb7C0jCAFqTM0NDI4NTE0OQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "51a51f84f21deaa6b105b4600c6170891034bb9f", "author": {"user": {"login": "jihaozh", "name": "Jihao Zhang"}}, "url": "https://github.com/apache/pinot/commit/51a51f84f21deaa6b105b4600c6170891034bb9f", "committedDate": "2020-01-15T19:28:40Z", "message": "[TE] Support weekly anomaly detection"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQzNTIyNjg3", "url": "https://github.com/apache/pinot/pull/4988#pullrequestreview-343522687", "createdAt": "2020-01-15T21:09:36Z", "commit": {"oid": "51a51f84f21deaa6b105b4600c6170891034bb9f"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMTowOTozN1rOFeGfzQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMToxNTowM1rOFeGo-g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzEwODA0NQ==", "bodyText": "Consider renaming the function - it is not clear what is \"check\".\nThis is actually filterIncompleteAggregation?", "url": "https://github.com/apache/pinot/pull/4988#discussion_r367108045", "createdAt": "2020-01-15T21:09:37Z", "author": {"login": "xiaohui-sun"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/DetectionUtils.java", "diffHunk": "@@ -288,4 +288,39 @@ public static Period periodFromTimeUnit(int size, TimeUnit unit) {\n         return new Period(TimeUnit.MILLISECONDS.convert(size, unit));\n     }\n   }\n+\n+  /**\n+   * Aggregate the time series data frame's value to specified granularity\n+   * @param df the data frame\n+   * @param origin the aggregation origin time stamp\n+   * @param granularityPeriod the aggregation granularity in period\n+   * @return the aggregated time series data frame\n+   */\n+  public static DataFrame aggregateByPeriod(DataFrame df, long origin, Period granularityPeriod) {\n+    return df.groupByPeriod(df.getLongs(COL_TIME), new DateTime(origin), granularityPeriod).sum(COL_TIME, COL_VALUE);\n+  }\n+\n+  /**\n+   * Check if the aggregation result is complete or not, if not, remove it from the aggregated result.\n+   *\n+   * For example, say the weekStart is Monday and current data is available through Jan 8, Wednesday.\n+   * the latest data time stamp will be Jan 8. The latest aggregation start time stamp should be Jan 6, Monday.\n+   * In such case, the latest data point is incomplete and should be filtered. If the latest data time stamp is\n+   * Jan 12, Sunday instead, the data is complete and good to use because the week's data is complete.\n+   *\n+   * @param df the aggregated data frame to check\n+   * @param latestDataTimeStamp the latest data time stamp\n+   * @param bucketTimeGranularity the metric's original granularity\n+   * @param aggregationGranularityPeriod the granularity after aggregation\n+   * @return the filtered data frame\n+   */\n+  public static DataFrame checkIncompleteAggregation(DataFrame df, long latestDataTimeStamp,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "51a51f84f21deaa6b105b4600c6170891034bb9f"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzEwODI3MQ==", "bodyText": "Why use Objects.notNull instead of this.weekStart == null?", "url": "https://github.com/apache/pinot/pull/4988#discussion_r367108271", "createdAt": "2020-01-15T21:10:13Z", "author": {"login": "xiaohui-sun"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/components/PercentageChangeRuleDetector.java", "diffHunk": "@@ -76,16 +80,34 @@\n \n   @Override\n   public DetectionResult runDetection(Interval window, String metricUrn) {\n+    long startMillis = window.getStartMillis();\n+\n+    // align start day to the user specified week start\n+    if (Objects.nonNull(this.weekStart)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "51a51f84f21deaa6b105b4600c6170891034bb9f"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzEwOTk0Mw==", "bodyText": "The startMills calculation should be done when creating the task. Why calculating this again?", "url": "https://github.com/apache/pinot/pull/4988#discussion_r367109943", "createdAt": "2020-01-15T21:14:02Z", "author": {"login": "xiaohui-sun"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/components/PercentageChangeRuleDetector.java", "diffHunk": "@@ -76,16 +80,34 @@\n \n   @Override\n   public DetectionResult runDetection(Interval window, String metricUrn) {\n+    long startMillis = window.getStartMillis();\n+\n+    // align start day to the user specified week start\n+    if (Objects.nonNull(this.weekStart)) {\n+      startMillis = window.getStart().withDayOfWeek(weekStart.getValue()).minusWeeks(1).getMillis();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "51a51f84f21deaa6b105b4600c6170891034bb9f"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzExMDM5NA==", "bodyText": "Should we check the aggregation function? Are we assuming the aggregation is always SUM?", "url": "https://github.com/apache/pinot/pull/4988#discussion_r367110394", "createdAt": "2020-01-15T21:15:03Z", "author": {"login": "xiaohui-sun"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/DetectionUtils.java", "diffHunk": "@@ -288,4 +288,39 @@ public static Period periodFromTimeUnit(int size, TimeUnit unit) {\n         return new Period(TimeUnit.MILLISECONDS.convert(size, unit));\n     }\n   }\n+\n+  /**\n+   * Aggregate the time series data frame's value to specified granularity\n+   * @param df the data frame\n+   * @param origin the aggregation origin time stamp\n+   * @param granularityPeriod the aggregation granularity in period\n+   * @return the aggregated time series data frame\n+   */\n+  public static DataFrame aggregateByPeriod(DataFrame df, long origin, Period granularityPeriod) {\n+    return df.groupByPeriod(df.getLongs(COL_TIME), new DateTime(origin), granularityPeriod).sum(COL_TIME, COL_VALUE);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "51a51f84f21deaa6b105b4600c6170891034bb9f"}, "originalPosition": 39}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQzNTU5NDU4", "url": "https://github.com/apache/pinot/pull/4988#pullrequestreview-343559458", "createdAt": "2020-01-15T22:16:07Z", "commit": {"oid": "51a51f84f21deaa6b105b4600c6170891034bb9f"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMjoxNjowN1rOFeINuw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMzoyNjoyM1rOFeJsJQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzEzNjE4Nw==", "bodyText": "Are we using this?", "url": "https://github.com/apache/pinot/pull/4988#discussion_r367136187", "createdAt": "2020-01-15T22:16:07Z", "author": {"login": "vincentchenjl"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/DefaultDataProvider.java", "diffHunk": "@@ -26,6 +26,7 @@\n import com.google.common.collect.ArrayListMultimap;\n import com.google.common.collect.Lists;\n import com.google.common.collect.Multimap;\n+import com.ibm.icu.util.TimeZone;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "51a51f84f21deaa6b105b4600c6170891034bb9f"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE1ODg3OA==", "bodyText": "Can we pass the aggregation function as an argument", "url": "https://github.com/apache/pinot/pull/4988#discussion_r367158878", "createdAt": "2020-01-15T23:21:13Z", "author": {"login": "vincentchenjl"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/DetectionUtils.java", "diffHunk": "@@ -288,4 +288,39 @@ public static Period periodFromTimeUnit(int size, TimeUnit unit) {\n         return new Period(TimeUnit.MILLISECONDS.convert(size, unit));\n     }\n   }\n+\n+  /**\n+   * Aggregate the time series data frame's value to specified granularity\n+   * @param df the data frame\n+   * @param origin the aggregation origin time stamp\n+   * @param granularityPeriod the aggregation granularity in period\n+   * @return the aggregated time series data frame\n+   */\n+  public static DataFrame aggregateByPeriod(DataFrame df, long origin, Period granularityPeriod) {\n+    return df.groupByPeriod(df.getLongs(COL_TIME), new DateTime(origin), granularityPeriod).sum(COL_TIME, COL_VALUE);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzExMDM5NA=="}, "originalCommit": {"oid": "51a51f84f21deaa6b105b4600c6170891034bb9f"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzE2MDM1Nw==", "bodyText": "Do we also support MONTHS?", "url": "https://github.com/apache/pinot/pull/4988#discussion_r367160357", "createdAt": "2020-01-15T23:26:23Z", "author": {"login": "vincentchenjl"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/components/PercentageChangeRuleDetector.java", "diffHunk": "@@ -76,16 +80,34 @@\n \n   @Override\n   public DetectionResult runDetection(Interval window, String metricUrn) {\n+    long startMillis = window.getStartMillis();\n+\n+    // align start day to the user specified week start\n+    if (Objects.nonNull(this.weekStart)) {\n+      startMillis = window.getStart().withDayOfWeek(weekStart.getValue()).minusWeeks(1).getMillis();\n+    }\n+\n     MetricEntity me = MetricEntity.fromURN(metricUrn);\n-    MetricSlice slice = MetricSlice.from(me.getId(), window.getStartMillis(), window.getEndMillis(), me.getFilters(), timeGranularity);\n+    MetricSlice slice = MetricSlice.from(me.getId(), startMillis, window.getEndMillis(), me.getFilters(), timeGranularity);\n     List<MetricSlice> slices = new ArrayList<>(this.baseline.scatter(slice));\n     slices.add(slice);\n \n     InputData data = this.dataFetcher.fetchData(new InputDataSpec().withTimeseriesSlices(slices)\n         .withMetricIdsForDataset(Collections.singletonList(slice.getMetricId())));\n-    DataFrame dfCurr = data.getTimeseries().get(slice).renameSeries(COL_VALUE, COL_CURR);\n     DataFrame dfBase = this.baseline.gather(slice, data.getTimeseries());\n+    DataFrame dfCurr = data.getTimeseries().get(slice);\n+    DatasetConfigDTO datasetConfig = data.getDatasetForMetricId().get(me.getId());\n \n+    // aggregate data to specified weekly granularity\n+    if (this.monitoringGranularity.endsWith(\"WEEKS\")) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "51a51f84f21deaa6b105b4600c6170891034bb9f"}, "originalPosition": 53}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e442c819bafcfce0e42b50dd27b9553f5a457576", "author": {"user": {"login": "jihaozh", "name": "Jihao Zhang"}}, "url": "https://github.com/apache/pinot/commit/e442c819bafcfce0e42b50dd27b9553f5a457576", "committedDate": "2020-01-16T18:48:55Z", "message": "address comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ0MTgwNjAx", "url": "https://github.com/apache/pinot/pull/4988#pullrequestreview-344180601", "createdAt": "2020-01-16T20:03:23Z", "commit": {"oid": "e442c819bafcfce0e42b50dd27b9553f5a457576"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQyMDowMzoyM1rOFel6Mg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQyMDowMzoyM1rOFel6Mg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzYyMjcwNg==", "bodyText": "Should we define \"MONTHS\" and \"WEEKS\" as constants?", "url": "https://github.com/apache/pinot/pull/4988#discussion_r367622706", "createdAt": "2020-01-16T20:03:23Z", "author": {"login": "vincentchenjl"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/components/HoltWintersDetector.java", "diffHunk": "@@ -114,31 +120,27 @@ public void init(HoltWintersDetectorSpec spec, InputDataFetcher dataFetcher) {\n     this.sensitivity = spec.getSensitivity();\n     this.monitoringGranularity = spec.getMonitoringGranularity();\n \n-    if (this.monitoringGranularity.equals(\"1_MONTHS\")) {\n+    if (this.monitoringGranularity.endsWith(\"MONTHS\") || this.monitoringGranularity.endsWith(\"WEEKS\")) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e442c819bafcfce0e42b50dd27b9553f5a457576"}, "originalPosition": 63}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f8441e4a58021c8c5c342afb7783fee22b567a3d", "author": {"user": {"login": "jihaozh", "name": "Jihao Zhang"}}, "url": "https://github.com/apache/pinot/commit/f8441e4a58021c8c5c342afb7783fee22b567a3d", "committedDate": "2020-01-16T23:28:47Z", "message": "address comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ0Mjg1MTQ5", "url": "https://github.com/apache/pinot/pull/4988#pullrequestreview-344285149", "createdAt": "2020-01-16T23:33:40Z", "commit": {"oid": "f8441e4a58021c8c5c342afb7783fee22b567a3d"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1479, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}