{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDY5MjIzNzQ0", "number": 5889, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQyMTo0OToxN1rOEZrAdQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQxNjo1MjozNlrOEan8zw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk1MzU0NDg1OnYy", "diffSide": "RIGHT", "path": "pinot-core/src/main/java/org/apache/pinot/core/query/reduce/GroupByDataTableReducer.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQyMTo0OToxN1rOHCn5wg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQyMTo0OToxN1rOHCn5wg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUxMjk2Mg==", "bodyText": "NOTE: Change this to per-value switch based because we have found that this way has better performance (similar change in #4788 for performance improvement)", "url": "https://github.com/apache/pinot/pull/5889#discussion_r472512962", "createdAt": "2020-08-18T21:49:17Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/query/reduce/GroupByDataTableReducer.java", "diffHunk": "@@ -208,50 +232,42 @@ private DataSchema getPrePostAggregationDataSchema(DataSchema dataSchema) {\n   }\n \n   private IndexedTable getIndexedTable(DataSchema dataSchema, Collection<DataTable> dataTables) {\n-    int indexedTableCapacity = GroupByUtils.getTableCapacity(_queryContext);\n-    IndexedTable indexedTable = new ConcurrentIndexedTable(dataSchema, _queryContext, indexedTableCapacity);\n-\n+    int capacity = GroupByUtils.getTableCapacity(_queryContext);\n+    IndexedTable indexedTable = new SimpleIndexedTable(dataSchema, _queryContext, capacity);\n+    ColumnDataType[] columnDataTypes = dataSchema.getColumnDataTypes();\n     for (DataTable dataTable : dataTables) {\n-      BiFunction[] functions = new BiFunction[_numColumns];\n-      for (int i = 0; i < _numColumns; i++) {\n-        ColumnDataType columnDataType = dataSchema.getColumnDataType(i);\n-        BiFunction<Integer, Integer, Object> function;\n-        switch (columnDataType) {\n-          case INT:\n-            function = dataTable::getInt;\n-            break;\n-          case LONG:\n-            function = dataTable::getLong;\n-            break;\n-          case FLOAT:\n-            function = dataTable::getFloat;\n-            break;\n-          case DOUBLE:\n-            function = dataTable::getDouble;\n-            break;\n-          case STRING:\n-            function = dataTable::getString;\n-            break;\n-          case BYTES:\n-            function = dataTable::getBytes;\n-            break;\n-          case OBJECT:\n-            function = dataTable::getObject;\n-            break;\n-          // Add other aggregation intermediate result / group-by column type supports here\n-          default:\n-            throw new IllegalStateException();\n-        }\n-        functions[i] = function;\n-      }\n-\n-      for (int row = 0; row < dataTable.getNumberOfRows(); row++) {\n-        Object[] columns = new Object[_numColumns];\n-        for (int col = 0; col < _numColumns; col++) {\n-          columns[col] = functions[col].apply(row, col);\n+      int numRows = dataTable.getNumberOfRows();\n+      for (int rowId = 0; rowId < numRows; rowId++) {\n+        Object[] values = new Object[_numColumns];\n+        for (int colId = 0; colId < _numColumns; colId++) {\n+          switch (columnDataTypes[colId]) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fc8d3c485f126626587fef163f7f685a6525b834"}, "originalPosition": 145}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2MzUyMzA5OnYy", "diffSide": "RIGHT", "path": "pinot-core/src/main/java/org/apache/pinot/core/query/reduce/HavingFilterHandler.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQxNjo1MDozNlrOHEK1PA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQxODo0MzoyNlrOHEOofA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDEzMzgyMA==", "bodyText": "some message?", "url": "https://github.com/apache/pinot/pull/5889#discussion_r474133820", "createdAt": "2020-08-20T16:50:36Z", "author": {"login": "npawar"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/query/reduce/HavingFilterHandler.java", "diffHunk": "@@ -0,0 +1,182 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.query.reduce;\n+\n+import java.util.List;\n+import org.apache.pinot.core.operator.filter.predicate.PredicateEvaluator;\n+import org.apache.pinot.core.operator.filter.predicate.PredicateEvaluatorProvider;\n+import org.apache.pinot.core.query.request.context.FilterContext;\n+import org.apache.pinot.core.query.request.context.predicate.Predicate;\n+import org.apache.pinot.spi.data.FieldSpec.DataType;\n+import org.apache.pinot.spi.utils.ByteArray;\n+\n+\n+/**\n+ * Handler for HAVING clause.\n+ */\n+public class HavingFilterHandler {\n+  private final PostAggregationHandler _postAggregationHandler;\n+  private final RowMatcher _rowMatcher;\n+\n+  public HavingFilterHandler(FilterContext havingFilter, PostAggregationHandler postAggregationHandler) {\n+    _postAggregationHandler = postAggregationHandler;\n+    _rowMatcher = getRowMatcher(havingFilter);\n+  }\n+\n+  /**\n+   * Returns {@code true} if the given row matches the HAVING clause, {@code false} otherwise.\n+   */\n+  public boolean isMatch(Object[] row) {\n+    return _rowMatcher.isMatch(row);\n+  }\n+\n+  /**\n+   * Helper method to construct a RowMatcher based on the given filter.\n+   */\n+  private RowMatcher getRowMatcher(FilterContext filter) {\n+    switch (filter.getType()) {\n+      case AND:\n+        return new AndRowMatcher(filter.getChildren());\n+      case OR:\n+        return new OrRowMatcher(filter.getChildren());\n+      case PREDICATE:\n+        return new PredicateRowMatcher(filter.getPredicate());\n+      default:\n+        throw new IllegalStateException();\n+    }\n+  }\n+\n+  /**\n+   * Filter matcher for the row.\n+   */\n+  private interface RowMatcher {\n+\n+    /**\n+     * Returns {@code true} if the given row matches the filter, {@code false} otherwise.\n+     */\n+    boolean isMatch(Object[] row);\n+  }\n+\n+  /**\n+   * AND filter matcher.\n+   */\n+  private class AndRowMatcher implements RowMatcher {\n+    RowMatcher[] _childMatchers;\n+\n+    AndRowMatcher(List<FilterContext> childFilters) {\n+      int numChildren = childFilters.size();\n+      _childMatchers = new RowMatcher[numChildren];\n+      for (int i = 0; i < numChildren; i++) {\n+        _childMatchers[i] = getRowMatcher(childFilters.get(i));\n+      }\n+    }\n+\n+    @Override\n+    public boolean isMatch(Object[] row) {\n+      for (RowMatcher childMatcher : _childMatchers) {\n+        if (!childMatcher.isMatch(row)) {\n+          return false;\n+        }\n+      }\n+      return true;\n+    }\n+  }\n+\n+  /**\n+   * OR filter matcher.\n+   */\n+  private class OrRowMatcher implements RowMatcher {\n+    RowMatcher[] _childMatchers;\n+\n+    OrRowMatcher(List<FilterContext> childFilters) {\n+      int numChildren = childFilters.size();\n+      _childMatchers = new RowMatcher[numChildren];\n+      for (int i = 0; i < numChildren; i++) {\n+        _childMatchers[i] = getRowMatcher(childFilters.get(i));\n+      }\n+    }\n+\n+    @Override\n+    public boolean isMatch(Object[] row) {\n+      for (RowMatcher childMatcher : _childMatchers) {\n+        if (childMatcher.isMatch(row)) {\n+          return true;\n+        }\n+      }\n+      return false;\n+    }\n+  }\n+\n+  /**\n+   * Predicate matcher.\n+   */\n+  private class PredicateRowMatcher implements RowMatcher {\n+    PostAggregationHandler.ValueExtractor _valueExtractor;\n+    DataType _valueType;\n+    PredicateEvaluator _predicateEvaluator;\n+\n+    PredicateRowMatcher(Predicate predicate) {\n+      _valueExtractor = _postAggregationHandler.getValueExtractor(predicate.getLhs());\n+      switch (_valueExtractor.getColumnDataType()) {\n+        case INT:\n+          _valueType = DataType.INT;\n+          break;\n+        case LONG:\n+          _valueType = DataType.LONG;\n+          break;\n+        case FLOAT:\n+          _valueType = DataType.FLOAT;\n+          break;\n+        case DOUBLE:\n+          _valueType = DataType.DOUBLE;\n+          break;\n+        case STRING:\n+          _valueType = DataType.STRING;\n+          break;\n+        case BYTES:\n+          _valueType = DataType.BYTES;\n+          break;\n+        default:\n+          throw new IllegalStateException();\n+      }\n+      _predicateEvaluator = PredicateEvaluatorProvider.getPredicateEvaluator(predicate, null, _valueType);\n+    }\n+\n+    @Override\n+    public boolean isMatch(Object[] row) {\n+      Object value = _valueExtractor.extract(row);\n+      switch (_valueType) {\n+        case INT:\n+          return _predicateEvaluator.applySV((int) value);\n+        case LONG:\n+          return _predicateEvaluator.applySV((long) value);\n+        case FLOAT:\n+          return _predicateEvaluator.applySV((float) value);\n+        case DOUBLE:\n+          return _predicateEvaluator.applySV((double) value);\n+        case STRING:\n+          return _predicateEvaluator.applySV((String) value);\n+        case BYTES:\n+          return _predicateEvaluator.applySV(((ByteArray) value).getBytes());\n+        default:\n+          throw new IllegalStateException();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fc8d3c485f126626587fef163f7f685a6525b834"}, "originalPosition": 178}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE5NjA5Mg==", "bodyText": "It is not possible to run into this branch as the _valueType is set inside the class", "url": "https://github.com/apache/pinot/pull/5889#discussion_r474196092", "createdAt": "2020-08-20T18:43:26Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/query/reduce/HavingFilterHandler.java", "diffHunk": "@@ -0,0 +1,182 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.query.reduce;\n+\n+import java.util.List;\n+import org.apache.pinot.core.operator.filter.predicate.PredicateEvaluator;\n+import org.apache.pinot.core.operator.filter.predicate.PredicateEvaluatorProvider;\n+import org.apache.pinot.core.query.request.context.FilterContext;\n+import org.apache.pinot.core.query.request.context.predicate.Predicate;\n+import org.apache.pinot.spi.data.FieldSpec.DataType;\n+import org.apache.pinot.spi.utils.ByteArray;\n+\n+\n+/**\n+ * Handler for HAVING clause.\n+ */\n+public class HavingFilterHandler {\n+  private final PostAggregationHandler _postAggregationHandler;\n+  private final RowMatcher _rowMatcher;\n+\n+  public HavingFilterHandler(FilterContext havingFilter, PostAggregationHandler postAggregationHandler) {\n+    _postAggregationHandler = postAggregationHandler;\n+    _rowMatcher = getRowMatcher(havingFilter);\n+  }\n+\n+  /**\n+   * Returns {@code true} if the given row matches the HAVING clause, {@code false} otherwise.\n+   */\n+  public boolean isMatch(Object[] row) {\n+    return _rowMatcher.isMatch(row);\n+  }\n+\n+  /**\n+   * Helper method to construct a RowMatcher based on the given filter.\n+   */\n+  private RowMatcher getRowMatcher(FilterContext filter) {\n+    switch (filter.getType()) {\n+      case AND:\n+        return new AndRowMatcher(filter.getChildren());\n+      case OR:\n+        return new OrRowMatcher(filter.getChildren());\n+      case PREDICATE:\n+        return new PredicateRowMatcher(filter.getPredicate());\n+      default:\n+        throw new IllegalStateException();\n+    }\n+  }\n+\n+  /**\n+   * Filter matcher for the row.\n+   */\n+  private interface RowMatcher {\n+\n+    /**\n+     * Returns {@code true} if the given row matches the filter, {@code false} otherwise.\n+     */\n+    boolean isMatch(Object[] row);\n+  }\n+\n+  /**\n+   * AND filter matcher.\n+   */\n+  private class AndRowMatcher implements RowMatcher {\n+    RowMatcher[] _childMatchers;\n+\n+    AndRowMatcher(List<FilterContext> childFilters) {\n+      int numChildren = childFilters.size();\n+      _childMatchers = new RowMatcher[numChildren];\n+      for (int i = 0; i < numChildren; i++) {\n+        _childMatchers[i] = getRowMatcher(childFilters.get(i));\n+      }\n+    }\n+\n+    @Override\n+    public boolean isMatch(Object[] row) {\n+      for (RowMatcher childMatcher : _childMatchers) {\n+        if (!childMatcher.isMatch(row)) {\n+          return false;\n+        }\n+      }\n+      return true;\n+    }\n+  }\n+\n+  /**\n+   * OR filter matcher.\n+   */\n+  private class OrRowMatcher implements RowMatcher {\n+    RowMatcher[] _childMatchers;\n+\n+    OrRowMatcher(List<FilterContext> childFilters) {\n+      int numChildren = childFilters.size();\n+      _childMatchers = new RowMatcher[numChildren];\n+      for (int i = 0; i < numChildren; i++) {\n+        _childMatchers[i] = getRowMatcher(childFilters.get(i));\n+      }\n+    }\n+\n+    @Override\n+    public boolean isMatch(Object[] row) {\n+      for (RowMatcher childMatcher : _childMatchers) {\n+        if (childMatcher.isMatch(row)) {\n+          return true;\n+        }\n+      }\n+      return false;\n+    }\n+  }\n+\n+  /**\n+   * Predicate matcher.\n+   */\n+  private class PredicateRowMatcher implements RowMatcher {\n+    PostAggregationHandler.ValueExtractor _valueExtractor;\n+    DataType _valueType;\n+    PredicateEvaluator _predicateEvaluator;\n+\n+    PredicateRowMatcher(Predicate predicate) {\n+      _valueExtractor = _postAggregationHandler.getValueExtractor(predicate.getLhs());\n+      switch (_valueExtractor.getColumnDataType()) {\n+        case INT:\n+          _valueType = DataType.INT;\n+          break;\n+        case LONG:\n+          _valueType = DataType.LONG;\n+          break;\n+        case FLOAT:\n+          _valueType = DataType.FLOAT;\n+          break;\n+        case DOUBLE:\n+          _valueType = DataType.DOUBLE;\n+          break;\n+        case STRING:\n+          _valueType = DataType.STRING;\n+          break;\n+        case BYTES:\n+          _valueType = DataType.BYTES;\n+          break;\n+        default:\n+          throw new IllegalStateException();\n+      }\n+      _predicateEvaluator = PredicateEvaluatorProvider.getPredicateEvaluator(predicate, null, _valueType);\n+    }\n+\n+    @Override\n+    public boolean isMatch(Object[] row) {\n+      Object value = _valueExtractor.extract(row);\n+      switch (_valueType) {\n+        case INT:\n+          return _predicateEvaluator.applySV((int) value);\n+        case LONG:\n+          return _predicateEvaluator.applySV((long) value);\n+        case FLOAT:\n+          return _predicateEvaluator.applySV((float) value);\n+        case DOUBLE:\n+          return _predicateEvaluator.applySV((double) value);\n+        case STRING:\n+          return _predicateEvaluator.applySV((String) value);\n+        case BYTES:\n+          return _predicateEvaluator.applySV(((ByteArray) value).getBytes());\n+        default:\n+          throw new IllegalStateException();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDEzMzgyMA=="}, "originalCommit": {"oid": "fc8d3c485f126626587fef163f7f685a6525b834"}, "originalPosition": 178}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2MzUyOTc1OnYy", "diffSide": "RIGHT", "path": "pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/BaseClusterIntegrationTestSet.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQxNjo1MjozNlrOHEK5ig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQxOTowNDo1OVrOHEPUcA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDEzNDkyMg==", "bodyText": "how about some queries with AND and OR RowMatchers as well?", "url": "https://github.com/apache/pinot/pull/5889#discussion_r474134922", "createdAt": "2020-08-20T16:52:36Z", "author": {"login": "npawar"}, "path": "pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/BaseClusterIntegrationTestSet.java", "diffHunk": "@@ -241,6 +241,13 @@ public void testHardcodedSqlQueries()\n     query =\n         \"SELECT DaysSinceEpoch, MAX(ArrDelay) * 2 - MAX(AirTime) - 3 FROM mytable GROUP BY DaysSinceEpoch ORDER BY MAX(ArrDelay) - MIN(AirTime) DESC\";\n     testSqlQuery(query, Collections.singletonList(query));\n+\n+    // Having\n+    query = \"SELECT COUNT(*) AS Count, DaysSinceEpoch FROM mytable GROUP BY DaysSinceEpoch HAVING Count > 350\";\n+    testSqlQuery(query, Collections.singletonList(query));\n+    query =\n+        \"SELECT MAX(ArrDelay) - MAX(AirTime) AS Diff, DaysSinceEpoch FROM mytable GROUP BY DaysSinceEpoch HAVING Diff * 2 > 1000 ORDER BY Diff ASC\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fc8d3c485f126626587fef163f7f685a6525b834"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDIwNzM0NA==", "bodyText": "Added", "url": "https://github.com/apache/pinot/pull/5889#discussion_r474207344", "createdAt": "2020-08-20T19:04:59Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/BaseClusterIntegrationTestSet.java", "diffHunk": "@@ -241,6 +241,13 @@ public void testHardcodedSqlQueries()\n     query =\n         \"SELECT DaysSinceEpoch, MAX(ArrDelay) * 2 - MAX(AirTime) - 3 FROM mytable GROUP BY DaysSinceEpoch ORDER BY MAX(ArrDelay) - MIN(AirTime) DESC\";\n     testSqlQuery(query, Collections.singletonList(query));\n+\n+    // Having\n+    query = \"SELECT COUNT(*) AS Count, DaysSinceEpoch FROM mytable GROUP BY DaysSinceEpoch HAVING Count > 350\";\n+    testSqlQuery(query, Collections.singletonList(query));\n+    query =\n+        \"SELECT MAX(ArrDelay) - MAX(AirTime) AS Diff, DaysSinceEpoch FROM mytable GROUP BY DaysSinceEpoch HAVING Diff * 2 > 1000 ORDER BY Diff ASC\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDEzNDkyMg=="}, "originalCommit": {"oid": "fc8d3c485f126626587fef163f7f685a6525b834"}, "originalPosition": 9}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4019, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}