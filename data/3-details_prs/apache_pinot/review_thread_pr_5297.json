{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDA4NzU1Njg1", "number": 5297, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQyMToxMTowNFrOD19T1Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQyMToxMTowNFrOD19T1Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU3OTA1NjIxOnYy", "diffSide": "RIGHT", "path": "pinot-core/src/main/java/org/apache/pinot/core/segment/creator/impl/inv/text/LuceneTextIndexCreator.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yNFQyMToxMTowNFrOGLpX1A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yN1QyMjoyNTo1NFrOGM6TqQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDg2NTM2NA==", "bodyText": "Dont we have this in Lucene StopAnalyzer?\nStopAnalyzer.ENGLISH_STOP_WORDS_SET", "url": "https://github.com/apache/pinot/pull/5297#discussion_r414865364", "createdAt": "2020-04-24T21:11:04Z", "author": {"login": "kishoreg"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/segment/creator/impl/inv/text/LuceneTextIndexCreator.java", "diffHunk": "@@ -50,6 +58,15 @@\n   private final Directory _indexDirectory;\n   private final IndexWriter _indexWriter;\n \n+  public static final CharArraySet ENGLISH_STOP_WORDS_SET =\n+      new CharArraySet(Arrays.asList(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46169700283dd09ea836eaba8bddd2a44dc8031e"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDg2Njc5Nw==", "bodyText": "No this is not in StopAnalyzer. That also takes a passed list of stopwords.\nThe list is borrowed from EnglishAnalyzer. The reason for not directly using EnglishAnalyzer is because it does word stemming and reduces words to their root form. I don't think we need that.", "url": "https://github.com/apache/pinot/pull/5297#discussion_r414866797", "createdAt": "2020-04-24T21:13:52Z", "author": {"login": "siddharthteotia"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/segment/creator/impl/inv/text/LuceneTextIndexCreator.java", "diffHunk": "@@ -50,6 +58,15 @@\n   private final Directory _indexDirectory;\n   private final IndexWriter _indexWriter;\n \n+  public static final CharArraySet ENGLISH_STOP_WORDS_SET =\n+      new CharArraySet(Arrays.asList(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDg2NTM2NA=="}, "originalCommit": {"oid": "46169700283dd09ea836eaba8bddd2a44dc8031e"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDg2NzQwMQ==", "bodyText": "StopAnalyzer can't be used either because it tokenizes input text at each character. So we stick to StandardAnalyzer which uses StandardTokenizer (based on unicode general purpose text segmentation algorithm)", "url": "https://github.com/apache/pinot/pull/5297#discussion_r414867401", "createdAt": "2020-04-24T21:15:15Z", "author": {"login": "siddharthteotia"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/segment/creator/impl/inv/text/LuceneTextIndexCreator.java", "diffHunk": "@@ -50,6 +58,15 @@\n   private final Directory _indexDirectory;\n   private final IndexWriter _indexWriter;\n \n+  public static final CharArraySet ENGLISH_STOP_WORDS_SET =\n+      new CharArraySet(Arrays.asList(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDg2NTM2NA=="}, "originalCommit": {"oid": "46169700283dd09ea836eaba8bddd2a44dc8031e"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjE5MTQwMQ==", "bodyText": "Thanks add this comment in the code.", "url": "https://github.com/apache/pinot/pull/5297#discussion_r416191401", "createdAt": "2020-04-27T22:25:54Z", "author": {"login": "kishoreg"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/segment/creator/impl/inv/text/LuceneTextIndexCreator.java", "diffHunk": "@@ -50,6 +58,15 @@\n   private final Directory _indexDirectory;\n   private final IndexWriter _indexWriter;\n \n+  public static final CharArraySet ENGLISH_STOP_WORDS_SET =\n+      new CharArraySet(Arrays.asList(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDg2NTM2NA=="}, "originalCommit": {"oid": "46169700283dd09ea836eaba8bddd2a44dc8031e"}, "originalPosition": 21}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3184, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}