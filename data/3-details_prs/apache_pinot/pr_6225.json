{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTE0OTA5NzM4", "number": 6225, "title": "Perf optimization for SQL GROUP BY ORDER BY", "bodyText": "This PR optimizes the performance of SQL GROUP BY ORDER BY.\nProblem:\nWe recently observed that GROUP BY ORDER BY queries having a large (we are having as high as 166million) numDocsScanned are 5x-6x slower as compared to PQL. Removing ORDER BY from the queries made the performance on par or even faster than PQL in some cases. So ORDER BY code was the reason for degradation during server-combine and broker-reduce phases since segment level execution between PQL and SQL is the same for GROUP BY ORDER BY.\nCouple of factors in the order by code are contributing to degradation:\n\n\nMore resizes: Resizes are essentially not the internal resize of the ConcurrentHashMap used by IndexedTable. The resize here is the trimming operation done by TableResizer everytime the map reaches the trimThreshold. The resize requires inserting items in PQ (sorting) and evicting the trimThreshold - trimSize number of items from the map.\n\n\nretainAll() - The TableResizer's resizeRecordsMap() method is invoked under 2 circumstances (1) resize during upsert, (2) resize during finish(false) from server combine. If TableResizer builds a PQ to retain the records, it then invokes retainAll() method on hashmap which we have seen to take > 1sec\n\n\nreadLock.lock and readLock.unlock - The upsert method takes a readlock to prevent the race condition that might arise due to another thread concurrently trimming (under write lock). The overhead of this operation is non-negligible for very high number of records. The total cumulative time spent in lock and unlock operations was just under 1sec\n`\n\n\n\n\n\n\u00a0\nPQL\nSQL\nSQL optimized\n\n\n\n\nServer Combine\n\n\n\n\n\ntrimSize for server combine\nmax(TOP * 5, 5000)\nmax(LIMIT * 5, 5000)\nmax(LIMIT * 5, 5000)\n\n\ntrimThreshold for segment combine\ntrimSize * 4\ntrimSize <= 100_000 trimThreshold = 1m else trimThreshold = trimSize * 1.2\ntrimThreshold is configurable\n\n\nNum resizes/sort during segment execution\n0\n0\n0\n\n\nNum resizes/sort during server combine\nAt most once - when the server combine is done, if numGroups > trimThreshold, trim to trimSize.\nDuring upsert every time we hit trimThreshold, trim to trimSize.During finish, we trim again to trimSize\nDuring upsert, no trimming. During finish, if numGroups > trimThreshold, trim to trimSize. Finish is called when the server combine is over.\n\n\nBroker Reduce\n\n\n\n\n\ntrimSize for broker reduce\nTOP\nmax(LIMIT * 5, 5000)\nLIMIT\n\n\ntrimThreshold for broker reduce\nN.A\ntrimSize <= 100_000 trimThreshold = 1m else trimThreshold = trimSize * 1.2\nN.A\n\n\nNum resizes/sort during broker combine\nExactly once - after adding results from all DataTables to the finalMap, trim to TOP\nWe upsert rows from each DataTable into IndexedTable. During upsert every time we hit trimThreshold, trim to trimSize. During finish, we resize again to trimSize Finally use LIMIT number of rows from the trimmed set as the final result set\nDuring upsert, no trimming. Exactly once - when finish is called after upserting rows from each DataTable into indexed table. Trimmed to LIMIT\n\n\n\n`\nFor a given SQL query with LIMIT 50000 and numDocsScanned 160million:\n\ntrimSize -> max (50000 * 5, 5000) -> 250000\ntrimThreshold -> trimSize * 1.2 -> 300000\nnum resizes(trims) during server combine - ~20\ncumulative resize/trim time during server combine - 3000ms\nnum resizes (trims) during broker reduce - ~10\ncumulative resize/trim time during broker reduce - 1600ms\nreadLock.lock, unlock - 900ms\nretainAll -  1100ms\n\nTotal SQL query time ~7000ms\nTotal PQL query time ~1800ms\nSolution\nThe solution is aimed at bringing the resize/trim code on par with PQL to get similar performance for such use cases\n\n\nTo better control the frequency of trimming (and accuracy, latency), introduce a new server side and broker side config for trimThreshold. To be used for SQL group by.\n\n\ntrimThreshold = configuredTrimThreshold\n\n\ntrimSize = limit N * 5 (same as PQL, not changed by this PR)\n\n\ntrimSize = min (trimSize, trimThreshold / 2) - to protect the server with queries having high LIMIT N\n\n\nIf the configured value is infinite (1B), we use a sub-class of ConcurrentIndexedTable that doesn't use any locks in upsert() method since we know that trimThreshold being infinite wouldn't require any trimming in upsert.\n\n\nInstead of retainAll(), build a new result map with the records to be retained just like it is done in PQL.\n\n\nDuring server combine, trim at most once when indexedTable.finish (false) is called by combiner if numGroups > trimThreshold. Trim to trimSize\n\n\nDuring broker reduce, trim exactly once when indexedTable.finish(true) is called. Trim to LIMIT N\n\n\nFor the same query, with the above changes\nSQL - 2200ms (multiple runs also give < 2secs)\nPQL - 1800ms", "createdAt": "2020-11-03T18:10:33Z", "url": "https://github.com/apache/pinot/pull/6225", "merged": true, "mergeCommit": {"oid": "fa7b0e4ea05a02855b87e70b50bfd3f76e6afe02"}, "closed": true, "closedAt": "2020-11-19T10:31:55Z", "author": {"login": "siddharthteotia"}, "timelineItems": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdY-CTjgFqTUyMjc4ODI2MQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdd_YIcgH2gAyNTE0OTA5NzM4OmU4YmNiODBmMzAwYzZjNjExODk1NDA1OTdmYzNiMDEyYzI3YmIwODE=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIyNzg4MjYx", "url": "https://github.com/apache/pinot/pull/6225#pullrequestreview-522788261", "createdAt": "2020-11-03T18:53:57Z", "commit": {"oid": "beb196d39c79012efaa4fdbe927e887a48624e7a"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QxODo1Mzo1OFrOHs8QMw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QxODo1ODo1M1rOHs8abg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjg4NjU3OQ==", "bodyText": "(Critical) This will break Having clause", "url": "https://github.com/apache/pinot/pull/6225#discussion_r516886579", "createdAt": "2020-11-03T18:53:58Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/query/reduce/GroupByDataTableReducer.java", "diffHunk": "@@ -265,7 +265,7 @@ private IndexedTable getIndexedTable(DataSchema dataSchema, Collection<DataTable\n     int numReduceThreadsToUse = getNumReduceThreadsToUse(numDataTables, reducerContext.getMaxReduceThreadsPerQuery());\n \n     // In case of single reduce thread, fall back to SimpleIndexedTable to avoid redundant locking/unlocking calls.\n-    int capacity = GroupByUtils.getTableCapacity(_queryContext);\n+    int capacity = _queryContext.getLimit();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "beb196d39c79012efaa4fdbe927e887a48624e7a"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjg4OTE5OA==", "bodyText": "I don't think we should embed Key inside Record, especially when the key is extracted from the Record, and then set back into Record using a setter.\nIt's okay to merge Key class into the Record class so that we have a central place for all the record information. The constructor should initialize both keys and values, and they should be final.", "url": "https://github.com/apache/pinot/pull/6225#discussion_r516889198", "createdAt": "2020-11-03T18:58:53Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/data/table/Record.java", "diffHunk": "@@ -45,6 +45,7 @@\n public class Record {\n   private final Object[] _values;\n \n+  private Key _key;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "beb196d39c79012efaa4fdbe927e887a48624e7a"}, "originalPosition": 4}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "beb196d39c79012efaa4fdbe927e887a48624e7a", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/beb196d39c79012efaa4fdbe927e887a48624e7a", "committedDate": "2020-11-03T17:40:21Z", "message": "Perf optimization for SQL GROUP BY ORDER BY"}, "afterCommit": {"oid": "ea600cf017fe973115a223d68ac33adabf3c1495", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/ea600cf017fe973115a223d68ac33adabf3c1495", "committedDate": "2020-11-17T02:30:09Z", "message": "SQL group by order by perf optimization"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMxOTgzMTI4", "url": "https://github.com/apache/pinot/pull/6225#pullrequestreview-531983128", "createdAt": "2020-11-17T02:47:55Z", "commit": {"oid": "de485c52302eba27197b98bb084e68973166e779"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QwMjo0Nzo1NVrOH0iT7w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QwMjo0Nzo1NVrOH0iT7w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDg1MDE1OQ==", "bodyText": "Forgot to undo info. Will revert to debug", "url": "https://github.com/apache/pinot/pull/6225#discussion_r524850159", "createdAt": "2020-11-17T02:47:55Z", "author": {"login": "siddharthteotia"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/data/table/SimpleIndexedTable.java", "diffHunk": "@@ -136,20 +125,16 @@ public int size() {\n \n   @Override\n   public void finish(boolean sort) {\n-\n     if (_hasOrderBy) {\n-\n       if (sort) {\n-        List<Record> sortedRecords = resizeAndSort(_capacity);\n+        List<Record> sortedRecords = resizeAndSort(_trimSize);\n         _iterator = sortedRecords.iterator();\n       } else {\n-        resize(_capacity);\n+        resize(_trimSize);\n       }\n-      LOGGER\n-          .debug(\"Num resizes : {}, Total time spent in resizing : {}, Avg resize time : {}\", _numResizes, _resizeTime,\n-              _numResizes == 0 ? 0 : _resizeTime / _numResizes);\n+      LOGGER.info(\"Num resizes : {}, Total time spent in resizing : {}, Avg resize time : {}, trimSize: {}, trimThresholdForUpsert: {},  trimThresholdForFinish: {}\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "de485c52302eba27197b98bb084e68973166e779"}, "originalPosition": 91}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMyNjQ3NTkz", "url": "https://github.com/apache/pinot/pull/6225#pullrequestreview-532647593", "createdAt": "2020-11-17T18:02:04Z", "commit": {"oid": "686ba2283dc7292fb8d88a45b9528af30e9d93f1"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QxODowMjowNFrOH1CQcA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QxODoxMTo0MlrOH1Co2g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM3MzU1Mg==", "bodyText": "Can we reuse existing PQL configs?", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525373552", "createdAt": "2020-11-17T18:02:04Z", "author": {"login": "mayankshriv"}, "path": "pinot-common/src/main/java/org/apache/pinot/common/utils/CommonConstants.java", "diffHunk": "@@ -173,6 +173,10 @@\n     public static final int DEFAULT_MAX_REDUCE_THREADS_PER_QUERY =\n         Math.max(1, Math.min(10, Runtime.getRuntime().availableProcessors() / 2)); // Same logic as CombineOperatorUtils\n \n+    // used for SQL GROUP BY ORDER BY\n+    public static final String CONFIG_OF_BROKER_SQL_GROUPBY_TRIM_THRESHOLD = \"pinot.broker.sql.groupby.trim.threshold\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "686ba2283dc7292fb8d88a45b9528af30e9d93f1"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM3NTI0Mg==", "bodyText": "Please add javadoc for the class and public methods.", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525375242", "createdAt": "2020-11-17T18:04:47Z", "author": {"login": "mayankshriv"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/data/table/ConcurrentIndexedTableOptimizedForLargeGroups.java", "diffHunk": "@@ -0,0 +1,70 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.data.table;\n+\n+import com.google.common.base.Preconditions;\n+import org.apache.pinot.common.utils.DataSchema;\n+import org.apache.pinot.core.query.request.context.QueryContext;\n+\n+\n+public class ConcurrentIndexedTableOptimizedForLargeGroups extends ConcurrentIndexedTable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "686ba2283dc7292fb8d88a45b9528af30e9d93f1"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM3NTcwMA==", "bodyText": "Could be skipped for perf?", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525375700", "createdAt": "2020-11-17T18:05:24Z", "author": {"login": "mayankshriv"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/data/table/ConcurrentIndexedTableOptimizedForLargeGroups.java", "diffHunk": "@@ -0,0 +1,70 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.data.table;\n+\n+import com.google.common.base.Preconditions;\n+import org.apache.pinot.common.utils.DataSchema;\n+import org.apache.pinot.core.query.request.context.QueryContext;\n+\n+\n+public class ConcurrentIndexedTableOptimizedForLargeGroups extends ConcurrentIndexedTable {\n+\n+  public ConcurrentIndexedTableOptimizedForLargeGroups(DataSchema dataSchema,\n+      QueryContext queryContext, int trimSize, int trimThreshold) {\n+    super(dataSchema, queryContext, trimSize, trimThreshold);\n+  }\n+\n+  @Override\n+  public boolean upsert(Key key, Record newRecord) {\n+    Preconditions.checkNotNull(key, \"Cannot upsert record with null keys\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "686ba2283dc7292fb8d88a45b9528af30e9d93f1"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM3OTgwMg==", "bodyText": "Use >= instead of ==?", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525379802", "createdAt": "2020-11-17T18:11:42Z", "author": {"login": "mayankshriv"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/query/reduce/GroupByDataTableReducer.java", "diffHunk": "@@ -262,13 +264,24 @@ private IndexedTable getIndexedTable(DataSchema dataSchema, Collection<DataTable\n     int numDataTables = dataTablesToReduce.size();\n \n     // Get the number of threads to use for reducing.\n-    int numReduceThreadsToUse = getNumReduceThreadsToUse(numDataTables, reducerContext.getMaxReduceThreadsPerQuery());\n-\n     // In case of single reduce thread, fall back to SimpleIndexedTable to avoid redundant locking/unlocking calls.\n-    int capacity = GroupByUtils.getTableCapacity(_queryContext);\n-    IndexedTable indexedTable =\n-        (numReduceThreadsToUse > 1) ? new ConcurrentIndexedTable(dataSchema, _queryContext, capacity)\n-            : new SimpleIndexedTable(dataSchema, _queryContext, capacity);\n+    int numReduceThreadsToUse = getNumReduceThreadsToUse(numDataTables, reducerContext.getMaxReduceThreadsPerQuery());\n+    int trimSize = GroupByUtils.getTableCapacity(_queryContext);\n+    int trimThreshold = reducerContext.getSqlGroupByTrimThreshold();\n+    IndexedTable indexedTable;\n+    if (numReduceThreadsToUse <= 1) {\n+      indexedTable = new SimpleIndexedTable(dataSchema, _queryContext, trimSize, trimThreshold);\n+    } else {\n+      if (trimThreshold == GroupByOrderByCombineOperator.INFINITE_INTER_SEGMENT_GROUPS_LIMIT) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "686ba2283dc7292fb8d88a45b9528af30e9d93f1"}, "originalPosition": 30}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMyNzgwMzU3", "url": "https://github.com/apache/pinot/pull/6225#pullrequestreview-532780357", "createdAt": "2020-11-17T20:23:45Z", "commit": {"oid": "686ba2283dc7292fb8d88a45b9528af30e9d93f1"}, "state": "COMMENTED", "comments": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QyMDoyMzo0NVrOH1Jlng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QyMTowNzoxNVrOH1Lfog==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQ5MzY2Mg==", "bodyText": "Why do we need a trim threshold for finish? We should always trim it to the _trimSize right?", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525493662", "createdAt": "2020-11-17T20:23:45Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/data/table/IndexedTable.java", "diffHunk": "@@ -37,39 +37,48 @@\n   protected final boolean _hasOrderBy;\n   protected final TableResizer _tableResizer;\n \n-  // The capacity we need to trim to\n-  protected final int _capacity;\n-  // The capacity with added buffer, in order to collect more records than capacity for better precision\n-  protected final int _maxCapacity;\n+  // The size we need to trim to\n+  protected final int _trimSize;\n+  // The size with added buffer, in order to collect more records than capacity for better precision\n+  protected final int _trimThresholdForUpsert;\n+  protected final int _trimThresholdForFinish;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "686ba2283dc7292fb8d88a45b9528af30e9d93f1"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUwODk3Mg==", "bodyText": "We should reuse the map to prevent growing the map again and again", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525508972", "createdAt": "2020-11-17T20:38:28Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/data/table/ConcurrentIndexedTable.java", "diffHunk": "@@ -125,50 +124,44 @@ public int size() {\n   }\n \n   private void resize(int trimToSize) {\n-\n     long startTime = System.currentTimeMillis();\n-\n-    _tableResizer.resizeRecordsMap(_lookupMap, trimToSize);\n-\n+    // when the resizer trims using a PQ, it will return a new trimmed map.\n+    // the reference held by the indexed table needs to be updated. this is also\n+    // the reason why it is volatile since the thread doing the resize will result in\n+    // a new reference\n+    _lookupMap = (ConcurrentMap)_tableResizer.resizeRecordsMap(_lookupMap, trimToSize);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "686ba2283dc7292fb8d88a45b9528af30e9d93f1"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUxMzQ1OQ==", "bodyText": "Rename this class to better reflect the purpose? Maybe UnboundedConcurrentIndexedTable?", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525513459", "createdAt": "2020-11-17T20:46:15Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/data/table/ConcurrentIndexedTableOptimizedForLargeGroups.java", "diffHunk": "@@ -0,0 +1,70 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.data.table;\n+\n+import com.google.common.base.Preconditions;\n+import org.apache.pinot.common.utils.DataSchema;\n+import org.apache.pinot.core.query.request.context.QueryContext;\n+\n+\n+public class ConcurrentIndexedTableOptimizedForLargeGroups extends ConcurrentIndexedTable {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM3NTI0Mg=="}, "originalCommit": {"oid": "686ba2283dc7292fb8d88a45b9528af30e9d93f1"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUxNzE1Mw==", "bodyText": "Prevent int overflow\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                _trimThreshold = Math.min(segmentLevelNumGroupsLimit * 2, Integer.MAX_VALUE);\n          \n          \n            \n                _trimThreshold = (int) Math.min((long) segmentLevelNumGroupsLimit * 2, Integer.MAX_VALUE);", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525517153", "createdAt": "2020-11-17T20:52:54Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/operator/combine/GroupByOrderByCombineOperator.java", "diffHunk": "@@ -62,24 +63,28 @@\n public class GroupByOrderByCombineOperator extends BaseOperator<IntermediateResultsBlock> {\n   private static final Logger LOGGER = LoggerFactory.getLogger(GroupByOrderByCombineOperator.class);\n   private static final String OPERATOR_NAME = \"GroupByOrderByCombineOperator\";\n+  public static final int INFINITE_INTER_SEGMENT_GROUPS_LIMIT = 2 * 1_000_000_000;\n \n   private final List<Operator> _operators;\n   private final QueryContext _queryContext;\n   private final ExecutorService _executorService;\n   private final long _endTimeMs;\n-  private final int _indexedTableCapacity;\n+  private final int _trimSize;\n   private final Lock _initLock;\n   private DataSchema _dataSchema;\n   private ConcurrentIndexedTable _indexedTable;\n+  private final int _trimThreshold;\n+\n \n   public GroupByOrderByCombineOperator(List<Operator> operators, QueryContext queryContext,\n-      ExecutorService executorService, long endTimeMs) {\n+      ExecutorService executorService, long endTimeMs, int segmentLevelNumGroupsLimit) {\n     _operators = operators;\n     _queryContext = queryContext;\n     _executorService = executorService;\n     _endTimeMs = endTimeMs;\n     _initLock = new ReentrantLock();\n-    _indexedTableCapacity = GroupByUtils.getTableCapacity(_queryContext);\n+    _trimSize = GroupByUtils.getTableCapacity(_queryContext);\n+    _trimThreshold = Math.min(segmentLevelNumGroupsLimit * 2, Integer.MAX_VALUE);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "686ba2283dc7292fb8d88a45b9528af30e9d93f1"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUxNzY3Nw==", "bodyText": "(nit) move to line 73", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525517677", "createdAt": "2020-11-17T20:53:56Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/operator/combine/GroupByOrderByCombineOperator.java", "diffHunk": "@@ -62,24 +63,28 @@\n public class GroupByOrderByCombineOperator extends BaseOperator<IntermediateResultsBlock> {\n   private static final Logger LOGGER = LoggerFactory.getLogger(GroupByOrderByCombineOperator.class);\n   private static final String OPERATOR_NAME = \"GroupByOrderByCombineOperator\";\n+  public static final int INFINITE_INTER_SEGMENT_GROUPS_LIMIT = 2 * 1_000_000_000;\n \n   private final List<Operator> _operators;\n   private final QueryContext _queryContext;\n   private final ExecutorService _executorService;\n   private final long _endTimeMs;\n-  private final int _indexedTableCapacity;\n+  private final int _trimSize;\n   private final Lock _initLock;\n   private DataSchema _dataSchema;\n   private ConcurrentIndexedTable _indexedTable;\n+  private final int _trimThreshold;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "686ba2283dc7292fb8d88a45b9528af30e9d93f1"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUyMDcxNQ==", "bodyText": "Please rename this method accordingly as it no longer resizes the map", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525520715", "createdAt": "2020-11-17T20:59:32Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/data/table/TableResizer.java", "diffHunk": "@@ -183,62 +192,26 @@ public void resizeRecordsMap(Map<Key, Record> recordsMap, int trimToSize) {\n     return priorityQueue;\n   }\n \n-  private List<Record> sortRecordsMap(Map<Key, Record> recordsMap) {\n-    int numRecords = recordsMap.size();\n-    List<Record> sortedRecords = new ArrayList<>(numRecords);\n-    List<IntermediateRecord> intermediateRecords = new ArrayList<>(numRecords);\n-    for (Map.Entry<Key, Record> entry : recordsMap.entrySet()) {\n-      intermediateRecords.add(getIntermediateRecord(entry.getKey(), entry.getValue()));\n-    }\n-    intermediateRecords.sort(_intermediateRecordComparator);\n-    for (IntermediateRecord intermediateRecord : intermediateRecords) {\n-      sortedRecords.add(recordsMap.get(intermediateRecord._key));\n-    }\n-    return sortedRecords;\n-  }\n-\n   /**\n    * Resizes the recordsMap and returns a sorted list of records.\n    * This method is to be called from IndexedTable::finish, if both resize and sort is needed\n-   *\n-   * If numRecordsToEvict > numRecordsToRetain, resize with PQ of records to evict, and then sort\n-   * Else, resize with PQ of record to retain, then use the PQ to create sorted list\n+   * Resize with PQ of record to retain, then use the PQ to create sorted list\n    */\n   public List<Record> resizeAndSortRecordsMap(Map<Key, Record> recordsMap, int trimToSize) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "686ba2283dc7292fb8d88a45b9528af30e9d93f1"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUyMTQ5Mg==", "bodyText": "Try to not create a new map as growing the map again is very expensive", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525521492", "createdAt": "2020-11-17T21:00:55Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/data/table/TableResizer.java", "diffHunk": "@@ -136,39 +138,46 @@ private IntermediateRecord getIntermediateRecord(Key key, Record record) {\n    * Resize only if number of records is greater than trimToSize\n    * The resizer smartly chooses to create PQ of records to evict or records to retain, based on the number of records and the number of records to evict\n    */\n-  public void resizeRecordsMap(Map<Key, Record> recordsMap, int trimToSize) {\n+  public Map<Key, Record> resizeRecordsMap(Map<Key, Record> recordsMap, int trimToSize) {\n     int numRecordsToEvict = recordsMap.size() - trimToSize;\n-\n     if (numRecordsToEvict > 0) {\n       // TODO: compare the performance of converting to IntermediateRecord vs keeping Record, in cases where we do not need to extract final results\n-\n-      if (numRecordsToEvict < trimToSize) { // num records to evict is smaller than num records to retain\n+      if (numRecordsToEvict < trimToSize) {\n+        // num records to evict is smaller than num records to retain\n         // make PQ of records to evict\n         PriorityQueue<IntermediateRecord> priorityQueue =\n             convertToIntermediateRecordsPQ(recordsMap, numRecordsToEvict, _intermediateRecordComparator);\n         for (IntermediateRecord evictRecord : priorityQueue) {\n           recordsMap.remove(evictRecord._key);\n         }\n-      } else { // num records to retain is smaller than num records to evict\n+        return recordsMap;\n+      } else {\n+        // num records to retain is smaller than num records to evict\n         // make PQ of records to retain\n+        Map<Key, Record> trimmedRecordsMap;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "686ba2283dc7292fb8d88a45b9528af30e9d93f1"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUyMTc5Nw==", "bodyText": "Not used?", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525521797", "createdAt": "2020-11-17T21:01:25Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/operator/blocks/IntermediateResultsBlock.java", "diffHunk": "@@ -40,16 +40,20 @@\n import org.apache.pinot.core.common.datatable.DataTableImplV2;\n import org.apache.pinot.core.data.table.Record;\n import org.apache.pinot.core.data.table.Table;\n+import org.apache.pinot.core.operator.combine.GroupByCombineOperator;\n import org.apache.pinot.core.query.aggregation.function.AggregationFunction;\n import org.apache.pinot.core.query.aggregation.groupby.AggregationGroupByResult;\n import org.apache.pinot.core.query.selection.SelectionOperatorUtils;\n import org.apache.pinot.spi.utils.ByteArray;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n \n /**\n  * The <code>IntermediateResultsBlock</code> class is the holder of the server side inter-segment results.\n  */\n public class IntermediateResultsBlock implements Block {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(IntermediateResultsBlock.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "686ba2283dc7292fb8d88a45b9528af30e9d93f1"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUyMjQ2Mw==", "bodyText": "(nit) Don't remove these empty lines for better readability", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525522463", "createdAt": "2020-11-17T21:02:38Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/operator/blocks/IntermediateResultsBlock.java", "diffHunk": "@@ -388,7 +391,6 @@ private DataTable getAggregationGroupByResultDataTable()\n       throws Exception {\n     String[] columnNames = new String[]{\"functionName\", \"GroupByResultMap\"};\n     ColumnDataType[] columnDataTypes = new ColumnDataType[]{ColumnDataType.STRING, ColumnDataType.OBJECT};\n-", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "686ba2283dc7292fb8d88a45b9528af30e9d93f1"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUyMzA4NQ==", "bodyText": "+1", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525523085", "createdAt": "2020-11-17T21:03:49Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/query/reduce/GroupByDataTableReducer.java", "diffHunk": "@@ -262,13 +264,24 @@ private IndexedTable getIndexedTable(DataSchema dataSchema, Collection<DataTable\n     int numDataTables = dataTablesToReduce.size();\n \n     // Get the number of threads to use for reducing.\n-    int numReduceThreadsToUse = getNumReduceThreadsToUse(numDataTables, reducerContext.getMaxReduceThreadsPerQuery());\n-\n     // In case of single reduce thread, fall back to SimpleIndexedTable to avoid redundant locking/unlocking calls.\n-    int capacity = GroupByUtils.getTableCapacity(_queryContext);\n-    IndexedTable indexedTable =\n-        (numReduceThreadsToUse > 1) ? new ConcurrentIndexedTable(dataSchema, _queryContext, capacity)\n-            : new SimpleIndexedTable(dataSchema, _queryContext, capacity);\n+    int numReduceThreadsToUse = getNumReduceThreadsToUse(numDataTables, reducerContext.getMaxReduceThreadsPerQuery());\n+    int trimSize = GroupByUtils.getTableCapacity(_queryContext);\n+    int trimThreshold = reducerContext.getSqlGroupByTrimThreshold();\n+    IndexedTable indexedTable;\n+    if (numReduceThreadsToUse <= 1) {\n+      indexedTable = new SimpleIndexedTable(dataSchema, _queryContext, trimSize, trimThreshold);\n+    } else {\n+      if (trimThreshold == GroupByOrderByCombineOperator.INFINITE_INTER_SEGMENT_GROUPS_LIMIT) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM3OTgwMg=="}, "originalCommit": {"oid": "686ba2283dc7292fb8d88a45b9528af30e9d93f1"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUyNDg5OA==", "bodyText": "We should not have this max because the trimThreshold is already the higher bound allowed", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525524898", "createdAt": "2020-11-17T21:07:15Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/data/table/IndexedTable.java", "diffHunk": "@@ -37,39 +37,48 @@\n   protected final boolean _hasOrderBy;\n   protected final TableResizer _tableResizer;\n \n-  // The capacity we need to trim to\n-  protected final int _capacity;\n-  // The capacity with added buffer, in order to collect more records than capacity for better precision\n-  protected final int _maxCapacity;\n+  // The size we need to trim to\n+  protected final int _trimSize;\n+  // The size with added buffer, in order to collect more records than capacity for better precision\n+  protected final int _trimThresholdForUpsert;\n+  protected final int _trimThresholdForFinish;\n \n-  protected IndexedTable(DataSchema dataSchema, QueryContext queryContext, int capacity) {\n-    super(dataSchema);\n+  protected List<Record> _sortedRecords;\n \n+  public IndexedTable(DataSchema dataSchema, QueryContext queryContext, int trimSize, int trimThreshold) {\n+    super(dataSchema);\n     List<ExpressionContext> groupByExpressions = queryContext.getGroupByExpressions();\n     assert groupByExpressions != null;\n     _numKeyColumns = groupByExpressions.size();\n-\n     _aggregationFunctions = queryContext.getAggregationFunctions();\n-\n     List<OrderByExpressionContext> orderByExpressions = queryContext.getOrderByExpressions();\n     if (orderByExpressions != null) {\n+      // SQL GROUP BY with ORDER BY\n+      // trimSize = max (limit N * 5, 5000) (see GroupByUtils.getTableCapacity)\n+      // to keep parity with PQL for some use cases with infinitely large group by,\n+      // we have different trim thresholds for upsert and finish.\n+      // for such cases, trimThresholdForUpsert will be 1_000_000_000 * 2\n+      // (exactly same as PQL). this essentially implies there will be no\n+      // resizing/trimming during upsert. during finish (called after server combine is over),\n+      // we still want to trim the results and trimThreshold is computed in the\n+      // same manner as PQL (trimSize * 4)\n       _hasOrderBy = true;\n       _tableResizer = new TableResizer(dataSchema, queryContext);\n-      _capacity = capacity;\n-\n-      // TODO: tune these numbers and come up with a better formula (github ISSUE-4801)\n-      // Based on the capacity and maxCapacity, the resizer will smartly choose to evict/retain recors from the PQ\n-      if (capacity\n-          <= 100_000) { // Capacity is small, make a very large buffer. Make PQ of records to retain, during resize\n-        _maxCapacity = 1_000_000;\n-      } else { // Capacity is large, make buffer only slightly bigger. Make PQ of records to evict, during resize\n-        _maxCapacity = (int) (capacity * 1.2);\n-      }\n+      _trimSize = trimSize;\n+      _trimThresholdForUpsert = Math.max(trimSize * 4, trimThreshold);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "686ba2283dc7292fb8d88a45b9528af30e9d93f1"}, "originalPosition": 50}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMyODYzNDY0", "url": "https://github.com/apache/pinot/pull/6225#pullrequestreview-532863464", "createdAt": "2020-11-17T22:24:35Z", "commit": {"oid": "686ba2283dc7292fb8d88a45b9528af30e9d93f1"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "686ba2283dc7292fb8d88a45b9528af30e9d93f1", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/686ba2283dc7292fb8d88a45b9528af30e9d93f1", "committedDate": "2020-11-17T07:22:53Z", "message": "fix tests"}, "afterCommit": {"oid": "b3eb38e348892144267aaa568d85e3208417a637", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/b3eb38e348892144267aaa568d85e3208417a637", "committedDate": "2020-11-17T23:35:29Z", "message": "SQL group by order by perf optimization"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMyOTA0MTEz", "url": "https://github.com/apache/pinot/pull/6225#pullrequestreview-532904113", "createdAt": "2020-11-17T23:43:32Z", "commit": {"oid": "b3eb38e348892144267aaa568d85e3208417a637"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QyMzo0MzozMlrOH1QB-w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QyMzo1NTo0M1rOH1QTQQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU5OTIyNw==", "bodyText": "PQL builds a new map because the new map is final and won't grow again. We cannot use retainAll() because looking up values in PQ is expensive, but we should try to use the existing map to avoid the overhead of growing the map.\nI'm okay keeping it this way for now, but please add a TODO", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525599227", "createdAt": "2020-11-17T23:43:32Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/data/table/ConcurrentIndexedTable.java", "diffHunk": "@@ -125,50 +124,44 @@ public int size() {\n   }\n \n   private void resize(int trimToSize) {\n-\n     long startTime = System.currentTimeMillis();\n-\n-    _tableResizer.resizeRecordsMap(_lookupMap, trimToSize);\n-\n+    // when the resizer trims using a PQ, it will return a new trimmed map.\n+    // the reference held by the indexed table needs to be updated. this is also\n+    // the reason why it is volatile since the thread doing the resize will result in\n+    // a new reference\n+    _lookupMap = (ConcurrentMap)_tableResizer.resizeRecordsMap(_lookupMap, trimToSize);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUwODk3Mg=="}, "originalCommit": {"oid": "686ba2283dc7292fb8d88a45b9528af30e9d93f1"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYwMTIyMA==", "bodyText": "This is incorrect. We should always trim the result in finish to reduce the records sent from broker to server. We should also change the code in PQL path", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525601220", "createdAt": "2020-11-17T23:49:24Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/data/table/IndexedTable.java", "diffHunk": "@@ -37,39 +37,48 @@\n   protected final boolean _hasOrderBy;\n   protected final TableResizer _tableResizer;\n \n-  // The capacity we need to trim to\n-  protected final int _capacity;\n-  // The capacity with added buffer, in order to collect more records than capacity for better precision\n-  protected final int _maxCapacity;\n+  // The size we need to trim to\n+  protected final int _trimSize;\n+  // The size with added buffer, in order to collect more records than capacity for better precision\n+  protected final int _trimThresholdForUpsert;\n+  protected final int _trimThresholdForFinish;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTQ5MzY2Mg=="}, "originalCommit": {"oid": "686ba2283dc7292fb8d88a45b9528af30e9d93f1"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYwMTYwOQ==", "bodyText": "We need to avoid retainAll() on PQ for sure, but we should also try to reuse the existing map", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525601609", "createdAt": "2020-11-17T23:50:21Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/data/table/TableResizer.java", "diffHunk": "@@ -136,39 +138,46 @@ private IntermediateRecord getIntermediateRecord(Key key, Record record) {\n    * Resize only if number of records is greater than trimToSize\n    * The resizer smartly chooses to create PQ of records to evict or records to retain, based on the number of records and the number of records to evict\n    */\n-  public void resizeRecordsMap(Map<Key, Record> recordsMap, int trimToSize) {\n+  public Map<Key, Record> resizeRecordsMap(Map<Key, Record> recordsMap, int trimToSize) {\n     int numRecordsToEvict = recordsMap.size() - trimToSize;\n-\n     if (numRecordsToEvict > 0) {\n       // TODO: compare the performance of converting to IntermediateRecord vs keeping Record, in cases where we do not need to extract final results\n-\n-      if (numRecordsToEvict < trimToSize) { // num records to evict is smaller than num records to retain\n+      if (numRecordsToEvict < trimToSize) {\n+        // num records to evict is smaller than num records to retain\n         // make PQ of records to evict\n         PriorityQueue<IntermediateRecord> priorityQueue =\n             convertToIntermediateRecordsPQ(recordsMap, numRecordsToEvict, _intermediateRecordComparator);\n         for (IntermediateRecord evictRecord : priorityQueue) {\n           recordsMap.remove(evictRecord._key);\n         }\n-      } else { // num records to retain is smaller than num records to evict\n+        return recordsMap;\n+      } else {\n+        // num records to retain is smaller than num records to evict\n         // make PQ of records to retain\n+        Map<Key, Record> trimmedRecordsMap;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTUyMTQ5Mg=="}, "originalCommit": {"oid": "686ba2283dc7292fb8d88a45b9528af30e9d93f1"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYwMjYxNw==", "bodyText": "(nit) reformat", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525602617", "createdAt": "2020-11-17T23:53:02Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/operator/combine/GroupByOrderByCombineOperator.java", "diffHunk": "@@ -62,24 +63,27 @@\n public class GroupByOrderByCombineOperator extends BaseOperator<IntermediateResultsBlock> {\n   private static final Logger LOGGER = LoggerFactory.getLogger(GroupByOrderByCombineOperator.class);\n   private static final String OPERATOR_NAME = \"GroupByOrderByCombineOperator\";\n+  public static final int INFINITE_INTER_SEGMENT_GROUPS_LIMIT = 2 * 1_000_000_000;\n \n   private final List<Operator> _operators;\n   private final QueryContext _queryContext;\n   private final ExecutorService _executorService;\n   private final long _endTimeMs;\n-  private final int _indexedTableCapacity;\n+  private final int _trimSize;\n+  private final int _trimThreshold;\n   private final Lock _initLock;\n   private DataSchema _dataSchema;\n   private ConcurrentIndexedTable _indexedTable;\n \n   public GroupByOrderByCombineOperator(List<Operator> operators, QueryContext queryContext,\n-      ExecutorService executorService, long endTimeMs) {\n+      ExecutorService executorService, long endTimeMs, int segmentLevelNumGroupsLimit) {\n     _operators = operators;\n     _queryContext = queryContext;\n     _executorService = executorService;\n     _endTimeMs = endTimeMs;\n     _initLock = new ReentrantLock();\n-    _indexedTableCapacity = GroupByUtils.getTableCapacity(_queryContext);\n+    _trimSize = GroupByUtils.getTableCapacity(_queryContext);\n+    _trimThreshold = (int)Math.min((long)segmentLevelNumGroupsLimit * 2, Integer.MAX_VALUE);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b3eb38e348892144267aaa568d85e3208417a637"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYwMzY0OQ==", "bodyText": "(Critical) This is incorrect. Indexed table size can be the same as trim size in regular cases.", "url": "https://github.com/apache/pinot/pull/6225#discussion_r525603649", "createdAt": "2020-11-17T23:55:43Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/operator/combine/GroupByOrderByCombineOperator.java", "diffHunk": "@@ -242,7 +255,7 @@ public void runJob() {\n       // Set the execution statistics.\n       CombineOperatorUtils.setExecutionStatistics(mergedBlock, _operators);\n \n-      if (_indexedTable.size() >= _indexedTableCapacity) {\n+      if (_indexedTable.size() >= _trimSize) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b3eb38e348892144267aaa568d85e3208417a637"}, "originalPosition": 62}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b3eb38e348892144267aaa568d85e3208417a637", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/b3eb38e348892144267aaa568d85e3208417a637", "committedDate": "2020-11-17T23:35:29Z", "message": "SQL group by order by perf optimization"}, "afterCommit": {"oid": "67410cd450aff9f6699470ebfd379f3403c1a96f", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/67410cd450aff9f6699470ebfd379f3403c1a96f", "committedDate": "2020-11-18T20:38:02Z", "message": "SQL group by order by perf optimization"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMzOTYxODI0", "url": "https://github.com/apache/pinot/pull/6225#pullrequestreview-533961824", "createdAt": "2020-11-18T23:23:17Z", "commit": {"oid": "67410cd450aff9f6699470ebfd379f3403c1a96f"}, "state": "APPROVED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQyMzoyMzoxN1rOH2GVeg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQyMzozODoxOVrOH2Gq_w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ4ODk1NA==", "bodyText": "(optional) Suggest removing the sql (rename to pinot.broker.groupby.trim.threshold) because we are going to deprecate pql and sql will be the standard", "url": "https://github.com/apache/pinot/pull/6225#discussion_r526488954", "createdAt": "2020-11-18T23:23:17Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-common/src/main/java/org/apache/pinot/common/utils/CommonConstants.java", "diffHunk": "@@ -173,6 +173,10 @@\n     public static final int DEFAULT_MAX_REDUCE_THREADS_PER_QUERY =\n         Math.max(1, Math.min(10, Runtime.getRuntime().availableProcessors() / 2)); // Same logic as CombineOperatorUtils\n \n+    // used for SQL GROUP BY ORDER BY\n+    public static final String CONFIG_OF_BROKER_SQL_GROUPBY_TRIM_THRESHOLD = \"pinot.broker.sql.groupby.trim.threshold\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTM3MzU1Mg=="}, "originalCommit": {"oid": "686ba2283dc7292fb8d88a45b9528af30e9d93f1"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ5MDE4OA==", "bodyText": "(nit) remove", "url": "https://github.com/apache/pinot/pull/6225#discussion_r526490188", "createdAt": "2020-11-18T23:26:47Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/data/table/ConcurrentIndexedTable.java", "diffHunk": "@@ -125,52 +120,47 @@ public int size() {\n   }\n \n   private void resize(int trimToSize) {\n-\n     long startTime = System.currentTimeMillis();\n-\n-    _tableResizer.resizeRecordsMap(_lookupMap, trimToSize);\n-\n+    // when the resizer trims using a PQ, it will return a new trimmed map.\n+    // the reference held by the indexed table needs to be updated. this is also\n+    // the reason why it is volatile since the thread doing the resize will result in\n+    // a new reference\n+    _lookupMap = (ConcurrentMap)_tableResizer.resizeRecordsMap(_lookupMap, trimToSize);\n     long endTime = System.currentTimeMillis();\n     long timeElapsed = endTime - startTime;\n-\n     _numResizes.incrementAndGet();\n     _resizeTime.addAndGet(timeElapsed);\n   }\n \n   private List<Record> resizeAndSort(int trimToSize) {\n-\n     long startTime = System.currentTimeMillis();\n-\n-    List<Record> sortedRecords = _tableResizer.resizeAndSortRecordsMap(_lookupMap, trimToSize);\n-\n+    List<Record> sortedRecords = _tableResizer.sortRecordsMap(_lookupMap, trimToSize);\n     long endTime = System.currentTimeMillis();\n     long timeElapsed = endTime - startTime;\n-\n     _numResizes.incrementAndGet();\n     _resizeTime.addAndGet(timeElapsed);\n-\n     return sortedRecords;\n   }\n \n   @Override\n   public void finish(boolean sort) {\n-\n     if (_hasOrderBy) {\n-\n       if (sort) {\n-        List<Record> sortedRecords = resizeAndSort(_capacity);\n-        _iterator = sortedRecords.iterator();\n+        _sortedRecords = resizeAndSort(_trimSize);\n+        _iterator = _sortedRecords.iterator();\n       } else {\n-        resize(_capacity);\n+        resize(_trimSize);\n       }\n       int numResizes = _numResizes.get();\n       long resizeTime = _resizeTime.get();\n-      LOGGER.debug(\"Num resizes : {}, Total time spent in resizing : {}, Avg resize time : {}\", numResizes, resizeTime,\n-          numResizes == 0 ? 0 : resizeTime / numResizes);\n+      LOGGER.debug(\n+          \"Num resizes : {}, Total time spent in resizing : {}, Avg resize time : {}, trimSize: {}, trimThreshold: {}\",\n+          numResizes, resizeTime, numResizes == 0 ? 0 : resizeTime / numResizes, _trimSize, _trimThreshold);\n     }\n-\n     if (_iterator == null) {\n       _iterator = _lookupMap.values().iterator();\n     }\n   }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "67410cd450aff9f6699470ebfd379f3403c1a96f"}, "originalPosition": 126}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ5MTI0MQ==", "bodyText": "(nit) _resizeTimeMs", "url": "https://github.com/apache/pinot/pull/6225#discussion_r526491241", "createdAt": "2020-11-18T23:30:00Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/data/table/IndexedTable.java", "diffHunk": "@@ -36,40 +38,46 @@\n   protected final AggregationFunction[] _aggregationFunctions;\n   protected final boolean _hasOrderBy;\n   protected final TableResizer _tableResizer;\n+  protected final AtomicInteger _numResizes = new AtomicInteger();\n+  protected final AtomicLong _resizeTime = new AtomicLong();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "67410cd450aff9f6699470ebfd379f3403c1a96f"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ5MTM0Mw==", "bodyText": "(nit) reformat", "url": "https://github.com/apache/pinot/pull/6225#discussion_r526491343", "createdAt": "2020-11-18T23:30:13Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/data/table/IndexedTable.java", "diffHunk": "@@ -36,40 +38,46 @@\n   protected final AggregationFunction[] _aggregationFunctions;\n   protected final boolean _hasOrderBy;\n   protected final TableResizer _tableResizer;\n+  protected final AtomicInteger _numResizes = new AtomicInteger();\n+  protected final AtomicLong _resizeTime = new AtomicLong();\n+  protected List<Record> _sortedRecords;\n \n-  // The capacity we need to trim to\n-  protected final int _capacity;\n-  // The capacity with added buffer, in order to collect more records than capacity for better precision\n-  protected final int _maxCapacity;\n+  // The size we need to trim to\n+  protected final int _trimSize;\n+  // The size with added buffer, in order to collect more records than capacity for better precision\n+  protected final int _trimThreshold;\n \n-  protected IndexedTable(DataSchema dataSchema, QueryContext queryContext, int capacity) {\n+  public IndexedTable(DataSchema dataSchema, QueryContext queryContext, int trimSize, int trimThreshold) {\n     super(dataSchema);\n-\n     List<ExpressionContext> groupByExpressions = queryContext.getGroupByExpressions();\n     assert groupByExpressions != null;\n     _numKeyColumns = groupByExpressions.size();\n-\n     _aggregationFunctions = queryContext.getAggregationFunctions();\n-\n     List<OrderByExpressionContext> orderByExpressions = queryContext.getOrderByExpressions();\n     if (orderByExpressions != null) {\n+      // SQL GROUP BY with ORDER BY\n+      // trimSize = max (limit N * 5, 5000) (see GroupByUtils.getTableCapacity).\n+      // trimSize is also bound by trimThreshold/2 to protect the server in case\n+      // when user specifies a very high value of LIMIT N.\n+      // trimThreshold is configurable. to keep parity with PQL for some use\n+      // cases with infinitely large group by, trimThreshold will be >= 1B\n+      // (exactly same as PQL). This essentially implies there will be no\n+      // resizing/trimming during upsert and exactly one trim during finish.\n       _hasOrderBy = true;\n       _tableResizer = new TableResizer(dataSchema, queryContext);\n-      _capacity = capacity;\n-\n-      // TODO: tune these numbers and come up with a better formula (github ISSUE-4801)\n-      // Based on the capacity and maxCapacity, the resizer will smartly choose to evict/retain recors from the PQ\n-      if (capacity\n-          <= 100_000) { // Capacity is small, make a very large buffer. Make PQ of records to retain, during resize\n-        _maxCapacity = 1_000_000;\n-      } else { // Capacity is large, make buffer only slightly bigger. Make PQ of records to evict, during resize\n-        _maxCapacity = (int) (capacity * 1.2);\n-      }\n+      _trimSize = Math.min(trimSize, trimThreshold/2);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "67410cd450aff9f6699470ebfd379f3403c1a96f"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ5MTQ1MQ==", "bodyText": "Should still be protected?", "url": "https://github.com/apache/pinot/pull/6225#discussion_r526491451", "createdAt": "2020-11-18T23:30:31Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/data/table/IndexedTable.java", "diffHunk": "@@ -36,40 +38,46 @@\n   protected final AggregationFunction[] _aggregationFunctions;\n   protected final boolean _hasOrderBy;\n   protected final TableResizer _tableResizer;\n+  protected final AtomicInteger _numResizes = new AtomicInteger();\n+  protected final AtomicLong _resizeTime = new AtomicLong();\n+  protected List<Record> _sortedRecords;\n \n-  // The capacity we need to trim to\n-  protected final int _capacity;\n-  // The capacity with added buffer, in order to collect more records than capacity for better precision\n-  protected final int _maxCapacity;\n+  // The size we need to trim to\n+  protected final int _trimSize;\n+  // The size with added buffer, in order to collect more records than capacity for better precision\n+  protected final int _trimThreshold;\n \n-  protected IndexedTable(DataSchema dataSchema, QueryContext queryContext, int capacity) {\n+  public IndexedTable(DataSchema dataSchema, QueryContext queryContext, int trimSize, int trimThreshold) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "67410cd450aff9f6699470ebfd379f3403c1a96f"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ5MjIxMA==", "bodyText": "(nit)\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              public void setResizeTimeMs(long resizeTime) {\n          \n          \n            \n              public void setResizeTimeMs(long resizeTimeMs) {", "url": "https://github.com/apache/pinot/pull/6225#discussion_r526492210", "createdAt": "2020-11-18T23:32:40Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/operator/blocks/IntermediateResultsBlock.java", "diffHunk": "@@ -218,6 +223,14 @@ public void setNumGroupsLimitReached(boolean numGroupsLimitReached) {\n     _numGroupsLimitReached = numGroupsLimitReached;\n   }\n \n+  public void setNumResizes(int numResizes) {\n+    _numResizes = numResizes;\n+  }\n+\n+  public void setResizeTimeMs(long resizeTime) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "67410cd450aff9f6699470ebfd379f3403c1a96f"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ5MzE5Mg==", "bodyText": "Move it into InstancePlanMakerImplV2 along with the num.groups.limit. Also suggest removing the sql", "url": "https://github.com/apache/pinot/pull/6225#discussion_r526493192", "createdAt": "2020-11-18T23:35:07Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/operator/combine/GroupByOrderByCombineOperator.java", "diffHunk": "@@ -62,24 +63,29 @@\n public class GroupByOrderByCombineOperator extends BaseOperator<IntermediateResultsBlock> {\n   private static final Logger LOGGER = LoggerFactory.getLogger(GroupByOrderByCombineOperator.class);\n   private static final String OPERATOR_NAME = \"GroupByOrderByCombineOperator\";\n+  public static final int INFINITE_TRIM_THRESHOLD = 1_000_000_000;\n+  public static final String SQL_GROUPBY_TRIM_THRESHOLD = \"sql.groupby.trim.threshold\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "67410cd450aff9f6699470ebfd379f3403c1a96f"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ5MzQxNA==", "bodyText": "(nit)\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  ExecutorService executorService, long endTimeMs, int sqlGroupByTrimThreshold) {\n          \n          \n            \n                  ExecutorService executorService, long endTimeMs, int trimThreshold) {", "url": "https://github.com/apache/pinot/pull/6225#discussion_r526493414", "createdAt": "2020-11-18T23:35:41Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/operator/combine/GroupByOrderByCombineOperator.java", "diffHunk": "@@ -62,24 +63,29 @@\n public class GroupByOrderByCombineOperator extends BaseOperator<IntermediateResultsBlock> {\n   private static final Logger LOGGER = LoggerFactory.getLogger(GroupByOrderByCombineOperator.class);\n   private static final String OPERATOR_NAME = \"GroupByOrderByCombineOperator\";\n+  public static final int INFINITE_TRIM_THRESHOLD = 1_000_000_000;\n+  public static final String SQL_GROUPBY_TRIM_THRESHOLD = \"sql.groupby.trim.threshold\";\n+  public static final int DEFAULT_SQL_GROUPBY_TRIM_THRESHOLD = 1_000_000;\n \n   private final List<Operator> _operators;\n   private final QueryContext _queryContext;\n   private final ExecutorService _executorService;\n   private final long _endTimeMs;\n-  private final int _indexedTableCapacity;\n+  private final int _trimSize;\n+  private final int _trimThreshold;\n   private final Lock _initLock;\n   private DataSchema _dataSchema;\n   private ConcurrentIndexedTable _indexedTable;\n \n   public GroupByOrderByCombineOperator(List<Operator> operators, QueryContext queryContext,\n-      ExecutorService executorService, long endTimeMs) {\n+      ExecutorService executorService, long endTimeMs, int sqlGroupByTrimThreshold) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "67410cd450aff9f6699470ebfd379f3403c1a96f"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ5NDQ2Mw==", "bodyText": "It is correctly set for PQL. Please remove this if block, and maybe add a TODO to properly set this flag", "url": "https://github.com/apache/pinot/pull/6225#discussion_r526494463", "createdAt": "2020-11-18T23:38:19Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/operator/combine/GroupByOrderByCombineOperator.java", "diffHunk": "@@ -242,7 +255,7 @@ public void runJob() {\n       // Set the execution statistics.\n       CombineOperatorUtils.setExecutionStatistics(mergedBlock, _operators);\n \n-      if (_indexedTable.size() >= _indexedTableCapacity) {\n+      if (_indexedTable.size() >= _trimSize) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYwMzY0OQ=="}, "originalCommit": {"oid": "b3eb38e348892144267aaa568d85e3208417a637"}, "originalPosition": 62}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM0MDAwNDE0", "url": "https://github.com/apache/pinot/pull/6225#pullrequestreview-534000414", "createdAt": "2020-11-19T00:57:26Z", "commit": {"oid": "67410cd450aff9f6699470ebfd379f3403c1a96f"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMDo1NzoyNlrOH2IW8w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMDo1NzoyNlrOH2IW8w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUyMjA5OQ==", "bodyText": "Maybe better to use MAX_TRIM_THRESHOLD?", "url": "https://github.com/apache/pinot/pull/6225#discussion_r526522099", "createdAt": "2020-11-19T00:57:26Z", "author": {"login": "snleee"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/operator/combine/GroupByOrderByCombineOperator.java", "diffHunk": "@@ -62,24 +63,29 @@\n public class GroupByOrderByCombineOperator extends BaseOperator<IntermediateResultsBlock> {\n   private static final Logger LOGGER = LoggerFactory.getLogger(GroupByOrderByCombineOperator.class);\n   private static final String OPERATOR_NAME = \"GroupByOrderByCombineOperator\";\n+  public static final int INFINITE_TRIM_THRESHOLD = 1_000_000_000;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "67410cd450aff9f6699470ebfd379f3403c1a96f"}, "originalPosition": 12}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d6eef58ea01f6acc801b10e0ffb4e8c91e2b900f", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/d6eef58ea01f6acc801b10e0ffb4e8c91e2b900f", "committedDate": "2020-11-19T09:12:46Z", "message": "SQL group by order by perf optimization"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "67410cd450aff9f6699470ebfd379f3403c1a96f", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/67410cd450aff9f6699470ebfd379f3403c1a96f", "committedDate": "2020-11-18T20:38:02Z", "message": "SQL group by order by perf optimization"}, "afterCommit": {"oid": "d6eef58ea01f6acc801b10e0ffb4e8c91e2b900f", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/d6eef58ea01f6acc801b10e0ffb4e8c91e2b900f", "committedDate": "2020-11-19T09:12:46Z", "message": "SQL group by order by perf optimization"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e8bcb80f300c6c61189540597fc3b012c27bb081", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/e8bcb80f300c6c61189540597fc3b012c27bb081", "committedDate": "2020-11-19T09:31:25Z", "message": "cleanup"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1729, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}