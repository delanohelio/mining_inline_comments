{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDU4Njk5NjEz", "number": 5769, "title": "[TE] add anomaly detection as a service - Phase 1", "bodyText": "This PR creates three endpoints for providing anomaly detection as the REST API service. Endpoints are provided in a new class called AnomalyDetectionResource.\n\nThe 1st endpoint is /anomaly-detection which allows users to send requests with ad-hoc data (JSON file), run AD task synchronously, and return anomalies after task completed. A new class called OnlineThirdEyeDataSource is created.\nThe 2nd endpoint is /anomaly-detection/task which allows users to send requests to run an AD task via existing configurations asynchronously and will return a task ID.\nThe 3rd endpoint is /anomaly-detection/{taskId} which allows users querying task status.\n\nThis is phase 1 for this feature. During phase 2, a new table for ad-hoc data will be created. And logic will be optimized to have shorter querying time for the ad-hoc endpoint.\nTestings are added for some methods in AnomalyDetectionResource. More testings will be added in phase 2.", "createdAt": "2020-07-29T21:08:17Z", "url": "https://github.com/apache/pinot/pull/5769", "merged": true, "mergeCommit": {"oid": "b2680122469441ac9a02e4c146002618218383d8"}, "closed": true, "closedAt": "2020-08-11T18:42:23Z", "author": {"login": "jasonyanwenl"}, "timelineItems": {"totalCount": 21, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc5zQr8gBqjM2MDEyNjM4NTQ=", "endCursor": "Y3Vyc29yOnYyOpPPAAABc-T9YvAFqTQ2NjM0MTYxNQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f3160f2b640041f1e1d917fe8b0e74174bdcb686", "author": {"user": {"login": "jasonyanwenl", "name": "Yanwen(Jason) Lin"}}, "url": "https://github.com/apache/pinot/commit/f3160f2b640041f1e1d917fe8b0e74174bdcb686", "committedDate": "2020-07-29T22:28:21Z", "message": "rename adhoc to online;"}, "afterCommit": {"oid": "6d91338441effdb3e94eface7664035757ae2e4d", "author": {"user": {"login": "jasonyanwenl", "name": "Yanwen(Jason) Lin"}}, "url": "https://github.com/apache/pinot/commit/6d91338441effdb3e94eface7664035757ae2e4d", "committedDate": "2020-07-29T22:40:52Z", "message": "[TE] add anomaly detection as a service - Phase 1"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU4NzQyOTAw", "url": "https://github.com/apache/pinot/pull/5769#pullrequestreview-458742900", "createdAt": "2020-07-30T20:44:52Z", "commit": {"oid": "6d91338441effdb3e94eface7664035757ae2e4d"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU4ODA5Mjgw", "url": "https://github.com/apache/pinot/pull/5769#pullrequestreview-458809280", "createdAt": "2020-07-30T22:33:46Z", "commit": {"oid": "6d91338441effdb3e94eface7664035757ae2e4d"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQyMjozMzo0N1rOG52IoQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQyMjo1NDo0MFrOG52ioA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzMwODk2MQ==", "bodyText": "Why hard code that one user can only send one request at a time? Would it make more sense to give it more flexibility here? for example, control the overall API QPS, or have a backoff mechanism, or a per-user quota?", "url": "https://github.com/apache/pinot/pull/5769#discussion_r463308961", "createdAt": "2020-07-30T22:33:47Z", "author": {"login": "jihaozh"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/api/detection/AnomalyDetectionResource.java", "diffHunk": "@@ -0,0 +1,756 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.pinot.thirdeye.api.detection;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ArrayNode;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.fasterxml.jackson.databind.node.TextNode;\n+import io.dropwizard.auth.Auth;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import io.swagger.annotations.ApiParam;\n+import org.apache.pinot.thirdeye.anomaly.task.TaskConstants;\n+import org.apache.pinot.thirdeye.api.Constants;\n+import org.apache.pinot.thirdeye.api.user.dashboard.UserDashboardResource;\n+import org.apache.pinot.thirdeye.auth.ThirdEyePrincipal;\n+import org.apache.pinot.thirdeye.common.metric.MetricType;\n+import org.apache.pinot.thirdeye.constant.MetricAggFunction;\n+import org.apache.pinot.thirdeye.dashboard.resources.v2.pojo.AnomalySummary;\n+import org.apache.pinot.thirdeye.datalayer.bao.*;\n+import org.apache.pinot.thirdeye.datalayer.dto.DatasetConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.DetectionConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.MetricConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.TaskDTO;\n+import org.apache.pinot.thirdeye.datalayer.util.Predicate;\n+import org.apache.pinot.thirdeye.datasource.DAORegistry;\n+import org.apache.pinot.thirdeye.datasource.ThirdEyeCacheRegistry;\n+import org.apache.pinot.thirdeye.datasource.loader.AggregationLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.DefaultAggregationLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.DefaultTimeSeriesLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.TimeSeriesLoader;\n+import org.apache.pinot.thirdeye.detection.*;\n+import org.apache.pinot.thirdeye.detection.cache.builder.AnomaliesCacheBuilder;\n+import org.apache.pinot.thirdeye.detection.cache.builder.TimeSeriesCacheBuilder;\n+import org.apache.pinot.thirdeye.detection.validators.DatasetConfigValidator;\n+import org.apache.pinot.thirdeye.detection.validators.DetectionConfigValidator;\n+import org.apache.pinot.thirdeye.detection.validators.MetricConfigValidator;\n+import org.apache.pinot.thirdeye.detection.yaml.DetectionConfigTuner;\n+import org.apache.pinot.thirdeye.detection.yaml.translator.DetectionConfigTranslator;\n+import org.apache.pinot.thirdeye.util.ThirdEyeUtils;\n+import org.jfree.util.Log;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.yaml.snakeyaml.Yaml;\n+import javax.ws.rs.*;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import javax.ws.rs.core.UriBuilder;\n+import java.util.*;\n+import java.util.concurrent.TimeUnit;\n+\n+@Path(\"/anomaly-detection\")\n+@Api(tags = { Constants.DETECTION_TAG })\n+public class AnomalyDetectionResource {\n+  protected static final Logger LOG = LoggerFactory.getLogger(AnomalyDetectionResource.class);\n+\n+  private static final String TEMPLATE_DETECTION_PATH = \"detection-config-template.yml\";\n+\n+  /* -------- Detection config fields -------- */\n+  private static final String DETECTION_YAML_FIELD = \"detectionName\";\n+  private static final String DEFAULT_DETECTION_NAME = \"online_detection\";\n+\n+  /* -------- Metric config fields -------- */\n+  private static final String DATASET_YAML_FIELD = \"dataset\";\n+  private static final String DEFAULT_DATASET_NAME = \"online_dataset\";\n+  private static final String DATATYPE_YAML_FIELD = \"datatype\";\n+  private static final MetricType DEFAULT_DATA_TYPE = MetricType.DOUBLE;\n+\n+  /* -------- Dataset config fields -------- */\n+  private static final String METRIC_YAML_FIELD = \"metric\";\n+  private static final String DEFAULT_METRIC_NAME = \"online_metric\";\n+  private static final String DEFAULT_METRIC_COLUMN = \"metric\";\n+  private static final String TIME_COLUMN_YAML_FIELD = \"timeColumn\";\n+  private static final String DEFAULT_TIME_COLUMN = \"date\";\n+  private static final String TIME_UNIT_YAML_FIELD = \"timeUnit\";\n+  private static final TimeUnit DEFAULT_TIME_UNIT = TimeUnit.DAYS;\n+  private static final String TIME_DURATION_YAML_FIELD = \"timeDuration\";\n+  private static final String TIME_FORMAT_YAML_FIELD = \"timeFormat\";\n+  private static final String DEFAULT_TIME_FORMAT = \"SIMPLE_DATE_FORMAT:yyyyMMdd\";\n+  private static final String TIME_ZONE_YAML_FIELD = \"timezone\";\n+  private static final String DEFAULT_TIME_ZONE = \"US/Pacific\";\n+  private static final List<String> DEFAULT_DIMENSIONS =\n+      Collections.unmodifiableList(new ArrayList<>());\n+\n+  /* -------- Request/Response field -------- */\n+  private static final String DATA_FIELD = \"data\";\n+  private static final String COLUMNS_FIELD = \"columns\";\n+  private static final String ROWS_FIELD = \"rows\";\n+  private static final String DATASET_FIELD = \"datasetConfiguration\";\n+  private static final String METRIC_FIELD = \"metricConfiguration\";\n+  private static final String DETECTION_FIELD = \"detectionConfiguration\";\n+  private static final String ANOMALIES_FIELD = \"anomalies\";\n+\n+  /* -------- Others -------- */\n+  private static final String ONLINE_DATASOURCE = \"OnlineThirdEyeDataSource\";\n+  private static final String DETECTION_MYSQL_NAME_COLUMN = \"name\";\n+  private static final String TASK_MYSQL_NAME_COLUMN = \"name\";\n+  private static final String ANOMALY_ENDPOINT_URL = \"/userdashboard/anomalies\";\n+  private static final long POLLING_SLEEP_TIME = 5L;\n+  private static final int DEFAULT_TIME_DURATION = 1;\n+  private static final long MAX_ONLINE_PAYLOAD_SIZE = 10 * 1024 * 1024L;\n+\n+  private final UserDashboardResource userDashboardResource;\n+  private final DetectionConfigManager detectionConfigDAO;\n+  private final DataProvider provider;\n+  private final MetricConfigManager metricConfigDAO;\n+  private final DatasetConfigManager datasetConfigDAO;\n+  private final EventManager eventDAO;\n+  private final MergedAnomalyResultManager anomalyDAO;\n+  private final EvaluationManager evaluationDAO;\n+  private final TaskManager taskDAO;\n+  private final DetectionPipelineLoader loader;\n+  private final DetectionConfigValidator detectionValidator;\n+  private final DatasetConfigValidator datasetConfigValidator;\n+  private final MetricConfigValidator metricConfigValidator;\n+  private final ObjectMapper objectMapper = new ObjectMapper();\n+  private final Yaml yaml;\n+\n+  public AnomalyDetectionResource(UserDashboardResource userDashboardResource) {\n+    this.detectionConfigDAO = DAORegistry.getInstance().getDetectionConfigManager();\n+    this.metricConfigDAO = DAORegistry.getInstance().getMetricConfigDAO();\n+    this.datasetConfigDAO = DAORegistry.getInstance().getDatasetConfigDAO();\n+    this.eventDAO = DAORegistry.getInstance().getEventDAO();\n+    this.anomalyDAO = DAORegistry.getInstance().getMergedAnomalyResultDAO();\n+    this.taskDAO = DAORegistry.getInstance().getTaskDAO();\n+    this.evaluationDAO = DAORegistry.getInstance().getEvaluationManager();\n+    this.userDashboardResource = userDashboardResource;\n+\n+    TimeSeriesLoader timeseriesLoader =\n+        new DefaultTimeSeriesLoader(metricConfigDAO, datasetConfigDAO,\n+            ThirdEyeCacheRegistry.getInstance().getQueryCache(),\n+            ThirdEyeCacheRegistry.getInstance().getTimeSeriesCache());\n+\n+    AggregationLoader aggregationLoader =\n+        new DefaultAggregationLoader(metricConfigDAO, datasetConfigDAO,\n+            ThirdEyeCacheRegistry.getInstance().getQueryCache(),\n+            ThirdEyeCacheRegistry.getInstance().getDatasetMaxDataTimeCache());\n+\n+    this.loader = new DetectionPipelineLoader();\n+\n+    this.provider = new DefaultDataProvider(metricConfigDAO, datasetConfigDAO, eventDAO, anomalyDAO,\n+        evaluationDAO, timeseriesLoader, aggregationLoader, loader,\n+        TimeSeriesCacheBuilder.getInstance(), AnomaliesCacheBuilder.getInstance());\n+    this.detectionValidator = new DetectionConfigValidator(this.provider);\n+    this.metricConfigValidator = new MetricConfigValidator();\n+    this.datasetConfigValidator = new DatasetConfigValidator();\n+\n+    // Read template from disk\n+    this.yaml = new Yaml();\n+  }\n+\n+  /**\n+   * Run an online anomaly detection service synchronously. It will run anomaly detection using\n+   * default configs for detection, metric, dataset\n+   *\n+   * @param start     detection window start time\n+   * @param end       detection window end time\n+   * @param payload   payload in request including online data\n+   * @param principal user who sent this request. It's used to separate different config names\n+   * @return a message containing the detected anomalies and the detection config used\n+   */\n+  @POST\n+  @Path(\"/\")\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @Consumes(MediaType.APPLICATION_JSON)\n+  @ApiOperation(\"Request an anomaly detection online task\")\n+  public Response onlineApi(\n+          @QueryParam(\"start\") long start,\n+          @QueryParam(\"end\") long end,\n+          @ApiParam(\"jsonPayload\") String payload,\n+          @Auth ThirdEyePrincipal principal) {\n+    DatasetConfigDTO datasetConfigDTO = null;\n+    MetricConfigDTO metricConfigDTO = null;\n+    DetectionConfigDTO detectionConfigDTO = null;\n+    TaskDTO taskDTO = null;\n+    List<AnomalySummary> anomalies = null;\n+    Response.Status responseStatus;\n+    Map<String, String> responseMessage = new HashMap<>();\n+    ObjectMapper objectMapper = new ObjectMapper();\n+    // Use username to separate different requests. One user can only send one request at a time", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6d91338441effdb3e94eface7664035757ae2e4d"}, "originalPosition": 199}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzMxMjQzOQ==", "bodyText": "I'm worried about creating a temporary detection config and later cleans it up. These detection configs can get leaked into the UI where users can see and change them while the task is running.\nSince we're already persisting in the task DTO, the information needed to create a detection config can actually just be persisted within the task info. Then an OnlineDetectionTaskRunner can pick it up and create the detectionConfigDTO in run time. No need to persist the DetectionConfig.", "url": "https://github.com/apache/pinot/pull/5769#discussion_r463312439", "createdAt": "2020-07-30T22:44:42Z", "author": {"login": "jihaozh"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/api/detection/AnomalyDetectionResource.java", "diffHunk": "@@ -0,0 +1,756 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.pinot.thirdeye.api.detection;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ArrayNode;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.fasterxml.jackson.databind.node.TextNode;\n+import io.dropwizard.auth.Auth;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import io.swagger.annotations.ApiParam;\n+import org.apache.pinot.thirdeye.anomaly.task.TaskConstants;\n+import org.apache.pinot.thirdeye.api.Constants;\n+import org.apache.pinot.thirdeye.api.user.dashboard.UserDashboardResource;\n+import org.apache.pinot.thirdeye.auth.ThirdEyePrincipal;\n+import org.apache.pinot.thirdeye.common.metric.MetricType;\n+import org.apache.pinot.thirdeye.constant.MetricAggFunction;\n+import org.apache.pinot.thirdeye.dashboard.resources.v2.pojo.AnomalySummary;\n+import org.apache.pinot.thirdeye.datalayer.bao.*;\n+import org.apache.pinot.thirdeye.datalayer.dto.DatasetConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.DetectionConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.MetricConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.TaskDTO;\n+import org.apache.pinot.thirdeye.datalayer.util.Predicate;\n+import org.apache.pinot.thirdeye.datasource.DAORegistry;\n+import org.apache.pinot.thirdeye.datasource.ThirdEyeCacheRegistry;\n+import org.apache.pinot.thirdeye.datasource.loader.AggregationLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.DefaultAggregationLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.DefaultTimeSeriesLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.TimeSeriesLoader;\n+import org.apache.pinot.thirdeye.detection.*;\n+import org.apache.pinot.thirdeye.detection.cache.builder.AnomaliesCacheBuilder;\n+import org.apache.pinot.thirdeye.detection.cache.builder.TimeSeriesCacheBuilder;\n+import org.apache.pinot.thirdeye.detection.validators.DatasetConfigValidator;\n+import org.apache.pinot.thirdeye.detection.validators.DetectionConfigValidator;\n+import org.apache.pinot.thirdeye.detection.validators.MetricConfigValidator;\n+import org.apache.pinot.thirdeye.detection.yaml.DetectionConfigTuner;\n+import org.apache.pinot.thirdeye.detection.yaml.translator.DetectionConfigTranslator;\n+import org.apache.pinot.thirdeye.util.ThirdEyeUtils;\n+import org.jfree.util.Log;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.yaml.snakeyaml.Yaml;\n+import javax.ws.rs.*;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import javax.ws.rs.core.UriBuilder;\n+import java.util.*;\n+import java.util.concurrent.TimeUnit;\n+\n+@Path(\"/anomaly-detection\")\n+@Api(tags = { Constants.DETECTION_TAG })\n+public class AnomalyDetectionResource {\n+  protected static final Logger LOG = LoggerFactory.getLogger(AnomalyDetectionResource.class);\n+\n+  private static final String TEMPLATE_DETECTION_PATH = \"detection-config-template.yml\";\n+\n+  /* -------- Detection config fields -------- */\n+  private static final String DETECTION_YAML_FIELD = \"detectionName\";\n+  private static final String DEFAULT_DETECTION_NAME = \"online_detection\";\n+\n+  /* -------- Metric config fields -------- */\n+  private static final String DATASET_YAML_FIELD = \"dataset\";\n+  private static final String DEFAULT_DATASET_NAME = \"online_dataset\";\n+  private static final String DATATYPE_YAML_FIELD = \"datatype\";\n+  private static final MetricType DEFAULT_DATA_TYPE = MetricType.DOUBLE;\n+\n+  /* -------- Dataset config fields -------- */\n+  private static final String METRIC_YAML_FIELD = \"metric\";\n+  private static final String DEFAULT_METRIC_NAME = \"online_metric\";\n+  private static final String DEFAULT_METRIC_COLUMN = \"metric\";\n+  private static final String TIME_COLUMN_YAML_FIELD = \"timeColumn\";\n+  private static final String DEFAULT_TIME_COLUMN = \"date\";\n+  private static final String TIME_UNIT_YAML_FIELD = \"timeUnit\";\n+  private static final TimeUnit DEFAULT_TIME_UNIT = TimeUnit.DAYS;\n+  private static final String TIME_DURATION_YAML_FIELD = \"timeDuration\";\n+  private static final String TIME_FORMAT_YAML_FIELD = \"timeFormat\";\n+  private static final String DEFAULT_TIME_FORMAT = \"SIMPLE_DATE_FORMAT:yyyyMMdd\";\n+  private static final String TIME_ZONE_YAML_FIELD = \"timezone\";\n+  private static final String DEFAULT_TIME_ZONE = \"US/Pacific\";\n+  private static final List<String> DEFAULT_DIMENSIONS =\n+      Collections.unmodifiableList(new ArrayList<>());\n+\n+  /* -------- Request/Response field -------- */\n+  private static final String DATA_FIELD = \"data\";\n+  private static final String COLUMNS_FIELD = \"columns\";\n+  private static final String ROWS_FIELD = \"rows\";\n+  private static final String DATASET_FIELD = \"datasetConfiguration\";\n+  private static final String METRIC_FIELD = \"metricConfiguration\";\n+  private static final String DETECTION_FIELD = \"detectionConfiguration\";\n+  private static final String ANOMALIES_FIELD = \"anomalies\";\n+\n+  /* -------- Others -------- */\n+  private static final String ONLINE_DATASOURCE = \"OnlineThirdEyeDataSource\";\n+  private static final String DETECTION_MYSQL_NAME_COLUMN = \"name\";\n+  private static final String TASK_MYSQL_NAME_COLUMN = \"name\";\n+  private static final String ANOMALY_ENDPOINT_URL = \"/userdashboard/anomalies\";\n+  private static final long POLLING_SLEEP_TIME = 5L;\n+  private static final int DEFAULT_TIME_DURATION = 1;\n+  private static final long MAX_ONLINE_PAYLOAD_SIZE = 10 * 1024 * 1024L;\n+\n+  private final UserDashboardResource userDashboardResource;\n+  private final DetectionConfigManager detectionConfigDAO;\n+  private final DataProvider provider;\n+  private final MetricConfigManager metricConfigDAO;\n+  private final DatasetConfigManager datasetConfigDAO;\n+  private final EventManager eventDAO;\n+  private final MergedAnomalyResultManager anomalyDAO;\n+  private final EvaluationManager evaluationDAO;\n+  private final TaskManager taskDAO;\n+  private final DetectionPipelineLoader loader;\n+  private final DetectionConfigValidator detectionValidator;\n+  private final DatasetConfigValidator datasetConfigValidator;\n+  private final MetricConfigValidator metricConfigValidator;\n+  private final ObjectMapper objectMapper = new ObjectMapper();\n+  private final Yaml yaml;\n+\n+  public AnomalyDetectionResource(UserDashboardResource userDashboardResource) {\n+    this.detectionConfigDAO = DAORegistry.getInstance().getDetectionConfigManager();\n+    this.metricConfigDAO = DAORegistry.getInstance().getMetricConfigDAO();\n+    this.datasetConfigDAO = DAORegistry.getInstance().getDatasetConfigDAO();\n+    this.eventDAO = DAORegistry.getInstance().getEventDAO();\n+    this.anomalyDAO = DAORegistry.getInstance().getMergedAnomalyResultDAO();\n+    this.taskDAO = DAORegistry.getInstance().getTaskDAO();\n+    this.evaluationDAO = DAORegistry.getInstance().getEvaluationManager();\n+    this.userDashboardResource = userDashboardResource;\n+\n+    TimeSeriesLoader timeseriesLoader =\n+        new DefaultTimeSeriesLoader(metricConfigDAO, datasetConfigDAO,\n+            ThirdEyeCacheRegistry.getInstance().getQueryCache(),\n+            ThirdEyeCacheRegistry.getInstance().getTimeSeriesCache());\n+\n+    AggregationLoader aggregationLoader =\n+        new DefaultAggregationLoader(metricConfigDAO, datasetConfigDAO,\n+            ThirdEyeCacheRegistry.getInstance().getQueryCache(),\n+            ThirdEyeCacheRegistry.getInstance().getDatasetMaxDataTimeCache());\n+\n+    this.loader = new DetectionPipelineLoader();\n+\n+    this.provider = new DefaultDataProvider(metricConfigDAO, datasetConfigDAO, eventDAO, anomalyDAO,\n+        evaluationDAO, timeseriesLoader, aggregationLoader, loader,\n+        TimeSeriesCacheBuilder.getInstance(), AnomaliesCacheBuilder.getInstance());\n+    this.detectionValidator = new DetectionConfigValidator(this.provider);\n+    this.metricConfigValidator = new MetricConfigValidator();\n+    this.datasetConfigValidator = new DatasetConfigValidator();\n+\n+    // Read template from disk\n+    this.yaml = new Yaml();\n+  }\n+\n+  /**\n+   * Run an online anomaly detection service synchronously. It will run anomaly detection using\n+   * default configs for detection, metric, dataset\n+   *\n+   * @param start     detection window start time\n+   * @param end       detection window end time\n+   * @param payload   payload in request including online data\n+   * @param principal user who sent this request. It's used to separate different config names\n+   * @return a message containing the detected anomalies and the detection config used\n+   */\n+  @POST\n+  @Path(\"/\")\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @Consumes(MediaType.APPLICATION_JSON)\n+  @ApiOperation(\"Request an anomaly detection online task\")\n+  public Response onlineApi(\n+          @QueryParam(\"start\") long start,\n+          @QueryParam(\"end\") long end,\n+          @ApiParam(\"jsonPayload\") String payload,\n+          @Auth ThirdEyePrincipal principal) {\n+    DatasetConfigDTO datasetConfigDTO = null;\n+    MetricConfigDTO metricConfigDTO = null;\n+    DetectionConfigDTO detectionConfigDTO = null;\n+    TaskDTO taskDTO = null;\n+    List<AnomalySummary> anomalies = null;\n+    Response.Status responseStatus;\n+    Map<String, String> responseMessage = new HashMap<>();\n+    ObjectMapper objectMapper = new ObjectMapper();\n+    // Use username to separate different requests. One user can only send one request at a time\n+    String nameSuffix = \"_\" + principal.getName();\n+\n+    try {\n+      if (payload.getBytes().length > MAX_ONLINE_PAYLOAD_SIZE) {\n+        responseStatus = Response.Status.BAD_REQUEST;\n+        responseMessage.put(\"message\", \"Payload too large\");\n+        return Response.status(responseStatus).entity(responseMessage).build();\n+      }\n+\n+      JsonNode payloadNode = objectMapper.readTree(payload);\n+\n+      if (!validateOnlineRequestPayload(payloadNode)) {\n+        responseStatus = Response.Status.BAD_REQUEST;\n+        responseMessage.put(\"message\", \"Invalid request payload\");\n+        return Response.status(responseStatus).entity(responseMessage).build();\n+      }\n+\n+      // Preprocess: remove existing entities generated by the previous interrupted request\n+      cleanExistingOnlineTask(nameSuffix);\n+\n+      // Create & save dataset\n+      datasetConfigDTO = generateDatasetConfig(payloadNode, nameSuffix);\n+\n+      // Create & save metric along with online data\n+      metricConfigDTO = generateMetricConfig(payloadNode, nameSuffix);\n+\n+      // Create & save detection\n+      detectionConfigDTO =\n+          generateDetectionConfig(payloadNode, nameSuffix, datasetConfigDTO, metricConfigDTO, start,\n+              end);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6d91338441effdb3e94eface7664035757ae2e4d"}, "originalPosition": 229}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzMxNDcyNg==", "bodyText": "Any reason for creating the dataset and metric DTOs be created and later cleaned up?\nIMO a better approach will be to create separate CRUD endpoints for these online datasets/metrics. Doing that will allow the user to create a dataset one time and then run detection multiple times. They can also visualize them in ThirdEye UI if they want. If it's no longer needed, it can be removed. Compared to this way, users need post the data to Thirdeye every time when they run a detection.", "url": "https://github.com/apache/pinot/pull/5769#discussion_r463314726", "createdAt": "2020-07-30T22:51:48Z", "author": {"login": "jihaozh"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/api/detection/AnomalyDetectionResource.java", "diffHunk": "@@ -0,0 +1,756 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.pinot.thirdeye.api.detection;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ArrayNode;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.fasterxml.jackson.databind.node.TextNode;\n+import io.dropwizard.auth.Auth;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import io.swagger.annotations.ApiParam;\n+import org.apache.pinot.thirdeye.anomaly.task.TaskConstants;\n+import org.apache.pinot.thirdeye.api.Constants;\n+import org.apache.pinot.thirdeye.api.user.dashboard.UserDashboardResource;\n+import org.apache.pinot.thirdeye.auth.ThirdEyePrincipal;\n+import org.apache.pinot.thirdeye.common.metric.MetricType;\n+import org.apache.pinot.thirdeye.constant.MetricAggFunction;\n+import org.apache.pinot.thirdeye.dashboard.resources.v2.pojo.AnomalySummary;\n+import org.apache.pinot.thirdeye.datalayer.bao.*;\n+import org.apache.pinot.thirdeye.datalayer.dto.DatasetConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.DetectionConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.MetricConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.TaskDTO;\n+import org.apache.pinot.thirdeye.datalayer.util.Predicate;\n+import org.apache.pinot.thirdeye.datasource.DAORegistry;\n+import org.apache.pinot.thirdeye.datasource.ThirdEyeCacheRegistry;\n+import org.apache.pinot.thirdeye.datasource.loader.AggregationLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.DefaultAggregationLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.DefaultTimeSeriesLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.TimeSeriesLoader;\n+import org.apache.pinot.thirdeye.detection.*;\n+import org.apache.pinot.thirdeye.detection.cache.builder.AnomaliesCacheBuilder;\n+import org.apache.pinot.thirdeye.detection.cache.builder.TimeSeriesCacheBuilder;\n+import org.apache.pinot.thirdeye.detection.validators.DatasetConfigValidator;\n+import org.apache.pinot.thirdeye.detection.validators.DetectionConfigValidator;\n+import org.apache.pinot.thirdeye.detection.validators.MetricConfigValidator;\n+import org.apache.pinot.thirdeye.detection.yaml.DetectionConfigTuner;\n+import org.apache.pinot.thirdeye.detection.yaml.translator.DetectionConfigTranslator;\n+import org.apache.pinot.thirdeye.util.ThirdEyeUtils;\n+import org.jfree.util.Log;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.yaml.snakeyaml.Yaml;\n+import javax.ws.rs.*;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import javax.ws.rs.core.UriBuilder;\n+import java.util.*;\n+import java.util.concurrent.TimeUnit;\n+\n+@Path(\"/anomaly-detection\")\n+@Api(tags = { Constants.DETECTION_TAG })\n+public class AnomalyDetectionResource {\n+  protected static final Logger LOG = LoggerFactory.getLogger(AnomalyDetectionResource.class);\n+\n+  private static final String TEMPLATE_DETECTION_PATH = \"detection-config-template.yml\";\n+\n+  /* -------- Detection config fields -------- */\n+  private static final String DETECTION_YAML_FIELD = \"detectionName\";\n+  private static final String DEFAULT_DETECTION_NAME = \"online_detection\";\n+\n+  /* -------- Metric config fields -------- */\n+  private static final String DATASET_YAML_FIELD = \"dataset\";\n+  private static final String DEFAULT_DATASET_NAME = \"online_dataset\";\n+  private static final String DATATYPE_YAML_FIELD = \"datatype\";\n+  private static final MetricType DEFAULT_DATA_TYPE = MetricType.DOUBLE;\n+\n+  /* -------- Dataset config fields -------- */\n+  private static final String METRIC_YAML_FIELD = \"metric\";\n+  private static final String DEFAULT_METRIC_NAME = \"online_metric\";\n+  private static final String DEFAULT_METRIC_COLUMN = \"metric\";\n+  private static final String TIME_COLUMN_YAML_FIELD = \"timeColumn\";\n+  private static final String DEFAULT_TIME_COLUMN = \"date\";\n+  private static final String TIME_UNIT_YAML_FIELD = \"timeUnit\";\n+  private static final TimeUnit DEFAULT_TIME_UNIT = TimeUnit.DAYS;\n+  private static final String TIME_DURATION_YAML_FIELD = \"timeDuration\";\n+  private static final String TIME_FORMAT_YAML_FIELD = \"timeFormat\";\n+  private static final String DEFAULT_TIME_FORMAT = \"SIMPLE_DATE_FORMAT:yyyyMMdd\";\n+  private static final String TIME_ZONE_YAML_FIELD = \"timezone\";\n+  private static final String DEFAULT_TIME_ZONE = \"US/Pacific\";\n+  private static final List<String> DEFAULT_DIMENSIONS =\n+      Collections.unmodifiableList(new ArrayList<>());\n+\n+  /* -------- Request/Response field -------- */\n+  private static final String DATA_FIELD = \"data\";\n+  private static final String COLUMNS_FIELD = \"columns\";\n+  private static final String ROWS_FIELD = \"rows\";\n+  private static final String DATASET_FIELD = \"datasetConfiguration\";\n+  private static final String METRIC_FIELD = \"metricConfiguration\";\n+  private static final String DETECTION_FIELD = \"detectionConfiguration\";\n+  private static final String ANOMALIES_FIELD = \"anomalies\";\n+\n+  /* -------- Others -------- */\n+  private static final String ONLINE_DATASOURCE = \"OnlineThirdEyeDataSource\";\n+  private static final String DETECTION_MYSQL_NAME_COLUMN = \"name\";\n+  private static final String TASK_MYSQL_NAME_COLUMN = \"name\";\n+  private static final String ANOMALY_ENDPOINT_URL = \"/userdashboard/anomalies\";\n+  private static final long POLLING_SLEEP_TIME = 5L;\n+  private static final int DEFAULT_TIME_DURATION = 1;\n+  private static final long MAX_ONLINE_PAYLOAD_SIZE = 10 * 1024 * 1024L;\n+\n+  private final UserDashboardResource userDashboardResource;\n+  private final DetectionConfigManager detectionConfigDAO;\n+  private final DataProvider provider;\n+  private final MetricConfigManager metricConfigDAO;\n+  private final DatasetConfigManager datasetConfigDAO;\n+  private final EventManager eventDAO;\n+  private final MergedAnomalyResultManager anomalyDAO;\n+  private final EvaluationManager evaluationDAO;\n+  private final TaskManager taskDAO;\n+  private final DetectionPipelineLoader loader;\n+  private final DetectionConfigValidator detectionValidator;\n+  private final DatasetConfigValidator datasetConfigValidator;\n+  private final MetricConfigValidator metricConfigValidator;\n+  private final ObjectMapper objectMapper = new ObjectMapper();\n+  private final Yaml yaml;\n+\n+  public AnomalyDetectionResource(UserDashboardResource userDashboardResource) {\n+    this.detectionConfigDAO = DAORegistry.getInstance().getDetectionConfigManager();\n+    this.metricConfigDAO = DAORegistry.getInstance().getMetricConfigDAO();\n+    this.datasetConfigDAO = DAORegistry.getInstance().getDatasetConfigDAO();\n+    this.eventDAO = DAORegistry.getInstance().getEventDAO();\n+    this.anomalyDAO = DAORegistry.getInstance().getMergedAnomalyResultDAO();\n+    this.taskDAO = DAORegistry.getInstance().getTaskDAO();\n+    this.evaluationDAO = DAORegistry.getInstance().getEvaluationManager();\n+    this.userDashboardResource = userDashboardResource;\n+\n+    TimeSeriesLoader timeseriesLoader =\n+        new DefaultTimeSeriesLoader(metricConfigDAO, datasetConfigDAO,\n+            ThirdEyeCacheRegistry.getInstance().getQueryCache(),\n+            ThirdEyeCacheRegistry.getInstance().getTimeSeriesCache());\n+\n+    AggregationLoader aggregationLoader =\n+        new DefaultAggregationLoader(metricConfigDAO, datasetConfigDAO,\n+            ThirdEyeCacheRegistry.getInstance().getQueryCache(),\n+            ThirdEyeCacheRegistry.getInstance().getDatasetMaxDataTimeCache());\n+\n+    this.loader = new DetectionPipelineLoader();\n+\n+    this.provider = new DefaultDataProvider(metricConfigDAO, datasetConfigDAO, eventDAO, anomalyDAO,\n+        evaluationDAO, timeseriesLoader, aggregationLoader, loader,\n+        TimeSeriesCacheBuilder.getInstance(), AnomaliesCacheBuilder.getInstance());\n+    this.detectionValidator = new DetectionConfigValidator(this.provider);\n+    this.metricConfigValidator = new MetricConfigValidator();\n+    this.datasetConfigValidator = new DatasetConfigValidator();\n+\n+    // Read template from disk\n+    this.yaml = new Yaml();\n+  }\n+\n+  /**\n+   * Run an online anomaly detection service synchronously. It will run anomaly detection using\n+   * default configs for detection, metric, dataset\n+   *\n+   * @param start     detection window start time\n+   * @param end       detection window end time\n+   * @param payload   payload in request including online data\n+   * @param principal user who sent this request. It's used to separate different config names\n+   * @return a message containing the detected anomalies and the detection config used\n+   */\n+  @POST\n+  @Path(\"/\")\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @Consumes(MediaType.APPLICATION_JSON)\n+  @ApiOperation(\"Request an anomaly detection online task\")\n+  public Response onlineApi(\n+          @QueryParam(\"start\") long start,\n+          @QueryParam(\"end\") long end,\n+          @ApiParam(\"jsonPayload\") String payload,\n+          @Auth ThirdEyePrincipal principal) {\n+    DatasetConfigDTO datasetConfigDTO = null;\n+    MetricConfigDTO metricConfigDTO = null;\n+    DetectionConfigDTO detectionConfigDTO = null;\n+    TaskDTO taskDTO = null;\n+    List<AnomalySummary> anomalies = null;\n+    Response.Status responseStatus;\n+    Map<String, String> responseMessage = new HashMap<>();\n+    ObjectMapper objectMapper = new ObjectMapper();\n+    // Use username to separate different requests. One user can only send one request at a time\n+    String nameSuffix = \"_\" + principal.getName();\n+\n+    try {\n+      if (payload.getBytes().length > MAX_ONLINE_PAYLOAD_SIZE) {\n+        responseStatus = Response.Status.BAD_REQUEST;\n+        responseMessage.put(\"message\", \"Payload too large\");\n+        return Response.status(responseStatus).entity(responseMessage).build();\n+      }\n+\n+      JsonNode payloadNode = objectMapper.readTree(payload);\n+\n+      if (!validateOnlineRequestPayload(payloadNode)) {\n+        responseStatus = Response.Status.BAD_REQUEST;\n+        responseMessage.put(\"message\", \"Invalid request payload\");\n+        return Response.status(responseStatus).entity(responseMessage).build();\n+      }\n+\n+      // Preprocess: remove existing entities generated by the previous interrupted request\n+      cleanExistingOnlineTask(nameSuffix);\n+\n+      // Create & save dataset\n+      datasetConfigDTO = generateDatasetConfig(payloadNode, nameSuffix);\n+\n+      // Create & save metric along with online data\n+      metricConfigDTO = generateMetricConfig(payloadNode, nameSuffix);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6d91338441effdb3e94eface7664035757ae2e4d"}, "originalPosition": 224}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzMxNTM1NA==", "bodyText": "I'll still put a timeout mechanism here so that if anything external goes wrong, the thread can still timeout.", "url": "https://github.com/apache/pinot/pull/5769#discussion_r463315354", "createdAt": "2020-07-30T22:53:51Z", "author": {"login": "jihaozh"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/api/detection/AnomalyDetectionResource.java", "diffHunk": "@@ -0,0 +1,756 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.pinot.thirdeye.api.detection;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ArrayNode;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.fasterxml.jackson.databind.node.TextNode;\n+import io.dropwizard.auth.Auth;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import io.swagger.annotations.ApiParam;\n+import org.apache.pinot.thirdeye.anomaly.task.TaskConstants;\n+import org.apache.pinot.thirdeye.api.Constants;\n+import org.apache.pinot.thirdeye.api.user.dashboard.UserDashboardResource;\n+import org.apache.pinot.thirdeye.auth.ThirdEyePrincipal;\n+import org.apache.pinot.thirdeye.common.metric.MetricType;\n+import org.apache.pinot.thirdeye.constant.MetricAggFunction;\n+import org.apache.pinot.thirdeye.dashboard.resources.v2.pojo.AnomalySummary;\n+import org.apache.pinot.thirdeye.datalayer.bao.*;\n+import org.apache.pinot.thirdeye.datalayer.dto.DatasetConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.DetectionConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.MetricConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.TaskDTO;\n+import org.apache.pinot.thirdeye.datalayer.util.Predicate;\n+import org.apache.pinot.thirdeye.datasource.DAORegistry;\n+import org.apache.pinot.thirdeye.datasource.ThirdEyeCacheRegistry;\n+import org.apache.pinot.thirdeye.datasource.loader.AggregationLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.DefaultAggregationLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.DefaultTimeSeriesLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.TimeSeriesLoader;\n+import org.apache.pinot.thirdeye.detection.*;\n+import org.apache.pinot.thirdeye.detection.cache.builder.AnomaliesCacheBuilder;\n+import org.apache.pinot.thirdeye.detection.cache.builder.TimeSeriesCacheBuilder;\n+import org.apache.pinot.thirdeye.detection.validators.DatasetConfigValidator;\n+import org.apache.pinot.thirdeye.detection.validators.DetectionConfigValidator;\n+import org.apache.pinot.thirdeye.detection.validators.MetricConfigValidator;\n+import org.apache.pinot.thirdeye.detection.yaml.DetectionConfigTuner;\n+import org.apache.pinot.thirdeye.detection.yaml.translator.DetectionConfigTranslator;\n+import org.apache.pinot.thirdeye.util.ThirdEyeUtils;\n+import org.jfree.util.Log;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.yaml.snakeyaml.Yaml;\n+import javax.ws.rs.*;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import javax.ws.rs.core.UriBuilder;\n+import java.util.*;\n+import java.util.concurrent.TimeUnit;\n+\n+@Path(\"/anomaly-detection\")\n+@Api(tags = { Constants.DETECTION_TAG })\n+public class AnomalyDetectionResource {\n+  protected static final Logger LOG = LoggerFactory.getLogger(AnomalyDetectionResource.class);\n+\n+  private static final String TEMPLATE_DETECTION_PATH = \"detection-config-template.yml\";\n+\n+  /* -------- Detection config fields -------- */\n+  private static final String DETECTION_YAML_FIELD = \"detectionName\";\n+  private static final String DEFAULT_DETECTION_NAME = \"online_detection\";\n+\n+  /* -------- Metric config fields -------- */\n+  private static final String DATASET_YAML_FIELD = \"dataset\";\n+  private static final String DEFAULT_DATASET_NAME = \"online_dataset\";\n+  private static final String DATATYPE_YAML_FIELD = \"datatype\";\n+  private static final MetricType DEFAULT_DATA_TYPE = MetricType.DOUBLE;\n+\n+  /* -------- Dataset config fields -------- */\n+  private static final String METRIC_YAML_FIELD = \"metric\";\n+  private static final String DEFAULT_METRIC_NAME = \"online_metric\";\n+  private static final String DEFAULT_METRIC_COLUMN = \"metric\";\n+  private static final String TIME_COLUMN_YAML_FIELD = \"timeColumn\";\n+  private static final String DEFAULT_TIME_COLUMN = \"date\";\n+  private static final String TIME_UNIT_YAML_FIELD = \"timeUnit\";\n+  private static final TimeUnit DEFAULT_TIME_UNIT = TimeUnit.DAYS;\n+  private static final String TIME_DURATION_YAML_FIELD = \"timeDuration\";\n+  private static final String TIME_FORMAT_YAML_FIELD = \"timeFormat\";\n+  private static final String DEFAULT_TIME_FORMAT = \"SIMPLE_DATE_FORMAT:yyyyMMdd\";\n+  private static final String TIME_ZONE_YAML_FIELD = \"timezone\";\n+  private static final String DEFAULT_TIME_ZONE = \"US/Pacific\";\n+  private static final List<String> DEFAULT_DIMENSIONS =\n+      Collections.unmodifiableList(new ArrayList<>());\n+\n+  /* -------- Request/Response field -------- */\n+  private static final String DATA_FIELD = \"data\";\n+  private static final String COLUMNS_FIELD = \"columns\";\n+  private static final String ROWS_FIELD = \"rows\";\n+  private static final String DATASET_FIELD = \"datasetConfiguration\";\n+  private static final String METRIC_FIELD = \"metricConfiguration\";\n+  private static final String DETECTION_FIELD = \"detectionConfiguration\";\n+  private static final String ANOMALIES_FIELD = \"anomalies\";\n+\n+  /* -------- Others -------- */\n+  private static final String ONLINE_DATASOURCE = \"OnlineThirdEyeDataSource\";\n+  private static final String DETECTION_MYSQL_NAME_COLUMN = \"name\";\n+  private static final String TASK_MYSQL_NAME_COLUMN = \"name\";\n+  private static final String ANOMALY_ENDPOINT_URL = \"/userdashboard/anomalies\";\n+  private static final long POLLING_SLEEP_TIME = 5L;\n+  private static final int DEFAULT_TIME_DURATION = 1;\n+  private static final long MAX_ONLINE_PAYLOAD_SIZE = 10 * 1024 * 1024L;\n+\n+  private final UserDashboardResource userDashboardResource;\n+  private final DetectionConfigManager detectionConfigDAO;\n+  private final DataProvider provider;\n+  private final MetricConfigManager metricConfigDAO;\n+  private final DatasetConfigManager datasetConfigDAO;\n+  private final EventManager eventDAO;\n+  private final MergedAnomalyResultManager anomalyDAO;\n+  private final EvaluationManager evaluationDAO;\n+  private final TaskManager taskDAO;\n+  private final DetectionPipelineLoader loader;\n+  private final DetectionConfigValidator detectionValidator;\n+  private final DatasetConfigValidator datasetConfigValidator;\n+  private final MetricConfigValidator metricConfigValidator;\n+  private final ObjectMapper objectMapper = new ObjectMapper();\n+  private final Yaml yaml;\n+\n+  public AnomalyDetectionResource(UserDashboardResource userDashboardResource) {\n+    this.detectionConfigDAO = DAORegistry.getInstance().getDetectionConfigManager();\n+    this.metricConfigDAO = DAORegistry.getInstance().getMetricConfigDAO();\n+    this.datasetConfigDAO = DAORegistry.getInstance().getDatasetConfigDAO();\n+    this.eventDAO = DAORegistry.getInstance().getEventDAO();\n+    this.anomalyDAO = DAORegistry.getInstance().getMergedAnomalyResultDAO();\n+    this.taskDAO = DAORegistry.getInstance().getTaskDAO();\n+    this.evaluationDAO = DAORegistry.getInstance().getEvaluationManager();\n+    this.userDashboardResource = userDashboardResource;\n+\n+    TimeSeriesLoader timeseriesLoader =\n+        new DefaultTimeSeriesLoader(metricConfigDAO, datasetConfigDAO,\n+            ThirdEyeCacheRegistry.getInstance().getQueryCache(),\n+            ThirdEyeCacheRegistry.getInstance().getTimeSeriesCache());\n+\n+    AggregationLoader aggregationLoader =\n+        new DefaultAggregationLoader(metricConfigDAO, datasetConfigDAO,\n+            ThirdEyeCacheRegistry.getInstance().getQueryCache(),\n+            ThirdEyeCacheRegistry.getInstance().getDatasetMaxDataTimeCache());\n+\n+    this.loader = new DetectionPipelineLoader();\n+\n+    this.provider = new DefaultDataProvider(metricConfigDAO, datasetConfigDAO, eventDAO, anomalyDAO,\n+        evaluationDAO, timeseriesLoader, aggregationLoader, loader,\n+        TimeSeriesCacheBuilder.getInstance(), AnomaliesCacheBuilder.getInstance());\n+    this.detectionValidator = new DetectionConfigValidator(this.provider);\n+    this.metricConfigValidator = new MetricConfigValidator();\n+    this.datasetConfigValidator = new DatasetConfigValidator();\n+\n+    // Read template from disk\n+    this.yaml = new Yaml();\n+  }\n+\n+  /**\n+   * Run an online anomaly detection service synchronously. It will run anomaly detection using\n+   * default configs for detection, metric, dataset\n+   *\n+   * @param start     detection window start time\n+   * @param end       detection window end time\n+   * @param payload   payload in request including online data\n+   * @param principal user who sent this request. It's used to separate different config names\n+   * @return a message containing the detected anomalies and the detection config used\n+   */\n+  @POST\n+  @Path(\"/\")\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @Consumes(MediaType.APPLICATION_JSON)\n+  @ApiOperation(\"Request an anomaly detection online task\")\n+  public Response onlineApi(\n+          @QueryParam(\"start\") long start,\n+          @QueryParam(\"end\") long end,\n+          @ApiParam(\"jsonPayload\") String payload,\n+          @Auth ThirdEyePrincipal principal) {\n+    DatasetConfigDTO datasetConfigDTO = null;\n+    MetricConfigDTO metricConfigDTO = null;\n+    DetectionConfigDTO detectionConfigDTO = null;\n+    TaskDTO taskDTO = null;\n+    List<AnomalySummary> anomalies = null;\n+    Response.Status responseStatus;\n+    Map<String, String> responseMessage = new HashMap<>();\n+    ObjectMapper objectMapper = new ObjectMapper();\n+    // Use username to separate different requests. One user can only send one request at a time\n+    String nameSuffix = \"_\" + principal.getName();\n+\n+    try {\n+      if (payload.getBytes().length > MAX_ONLINE_PAYLOAD_SIZE) {\n+        responseStatus = Response.Status.BAD_REQUEST;\n+        responseMessage.put(\"message\", \"Payload too large\");\n+        return Response.status(responseStatus).entity(responseMessage).build();\n+      }\n+\n+      JsonNode payloadNode = objectMapper.readTree(payload);\n+\n+      if (!validateOnlineRequestPayload(payloadNode)) {\n+        responseStatus = Response.Status.BAD_REQUEST;\n+        responseMessage.put(\"message\", \"Invalid request payload\");\n+        return Response.status(responseStatus).entity(responseMessage).build();\n+      }\n+\n+      // Preprocess: remove existing entities generated by the previous interrupted request\n+      cleanExistingOnlineTask(nameSuffix);\n+\n+      // Create & save dataset\n+      datasetConfigDTO = generateDatasetConfig(payloadNode, nameSuffix);\n+\n+      // Create & save metric along with online data\n+      metricConfigDTO = generateMetricConfig(payloadNode, nameSuffix);\n+\n+      // Create & save detection\n+      detectionConfigDTO =\n+          generateDetectionConfig(payloadNode, nameSuffix, datasetConfigDTO, metricConfigDTO, start,\n+              end);\n+\n+      // Create & save task\n+      taskDTO = generateTaskConfig(detectionConfigDTO.getId(), start, end);\n+\n+      // Polling task status\n+      TaskDTO polledTaskDTO = pollingTask(taskDTO.getId());\n+\n+      // Task failure\n+      if (polledTaskDTO.getStatus() != TaskConstants.TaskStatus.COMPLETED) {\n+        LOG.warn(\"Task is not completed after polling: \" + polledTaskDTO);\n+\n+        responseStatus = Response.Status.INTERNAL_SERVER_ERROR;\n+\n+        switch (polledTaskDTO.getStatus()) {\n+        case FAILED:\n+          responseStatus = Response.Status.INTERNAL_SERVER_ERROR;\n+          responseMessage.put(\"message\", \"Failed to execute anomaly detection task.\");\n+          break;\n+        case TIMEOUT:\n+          responseStatus = Response.Status.REQUEST_TIMEOUT;\n+          responseMessage.put(\"message\", \"Anomaly detection task timeout.\");\n+        default:\n+          LOG.error(\"Error task status after polling: \" + polledTaskDTO.getStatus());\n+          responseMessage.put(\"message\", \"unknown task status.\");\n+          break;\n+        }\n+\n+        responseMessage.put(\"more-info\", \"Error = \" + polledTaskDTO.getMessage());\n+\n+        // Send response\n+        return Response.status(responseStatus).entity(responseMessage).build();\n+      }\n+\n+      // Task success\n+      // Retrieve task result\n+      anomalies = getAnomalies(start, end, metricConfigDTO.getName(), datasetConfigDTO.getName());\n+\n+      // Build success response\n+      JsonNode anomalyNode = objectMapper.convertValue(anomalies, JsonNode.class);\n+      JsonNode detectionConfigNode =\n+          objectMapper.convertValue(detectionConfigDTO.getYaml(), JsonNode.class);\n+      ObjectNode responseNode = objectMapper.createObjectNode();\n+      responseNode.set(ANOMALIES_FIELD, anomalyNode);\n+      responseNode.set(DETECTION_FIELD, detectionConfigNode);\n+\n+      responseStatus = Response.Status.OK;\n+      return Response.status(responseStatus).entity(objectMapper.writeValueAsString(responseNode))\n+          .build();\n+    } catch (JsonProcessingException e) {\n+      LOG.error(\"Error: {}\", e.getMessage());\n+      responseStatus = Response.Status.BAD_REQUEST;\n+      responseMessage.put(\"message\", \"Invalid request payload\");\n+      processException(e, responseMessage);\n+      return Response.status(responseStatus).entity(responseMessage).build();\n+    } catch (Exception e) {\n+      LOG.error(\"Error: {}\", e.getMessage());\n+      responseStatus = Response.Status.INTERNAL_SERVER_ERROR;\n+      responseMessage.put(\"message\", \"Failed executing anomaly detection service.\");\n+      processException(e, responseMessage);\n+      return Response.status(responseStatus).entity(responseMessage).build();\n+    } finally {\n+      // Online service is stateless\n+      cleanStates(anomalies, taskDTO, metricConfigDTO, datasetConfigDTO, detectionConfigDTO);\n+    }\n+  }\n+\n+  void cleanExistingOnlineTask(String nameSuffix) {\n+    String metricName = DEFAULT_METRIC_NAME + nameSuffix;\n+    List<MetricConfigDTO> metricConfigDTOS = metricConfigDAO.findByMetricName(metricName);\n+    for (MetricConfigDTO metricConfigDTO : metricConfigDTOS) {\n+      metricConfigDAO.deleteById(metricConfigDTO.getId());\n+      LOG.info(\"Deleted existing metric: {}\", metricConfigDTO);\n+    }\n+\n+    String datasetName = DEFAULT_DATASET_NAME + nameSuffix;\n+    DatasetConfigDTO datasetConfigDTO = datasetConfigDAO.findByDataset(datasetName);\n+    if (datasetConfigDTO != null) {\n+      datasetConfigDAO.delete(datasetConfigDTO);\n+      LOG.info(\"Deleted existing dataset: {}\", datasetConfigDTO);\n+    }\n+\n+    String detectionName = DEFAULT_DETECTION_NAME + nameSuffix;\n+    List<DetectionConfigDTO> detectionConfigDTOS = detectionConfigDAO\n+        .findByPredicate(Predicate.EQ(DETECTION_MYSQL_NAME_COLUMN, detectionName));\n+    for (DetectionConfigDTO detectionConfigDTO : detectionConfigDTOS) {\n+      detectionConfigDAO.delete(detectionConfigDTO);\n+      taskDAO.deleteByPredicate(Predicate.EQ(TASK_MYSQL_NAME_COLUMN,\n+          TaskConstants.TaskType.DETECTION.name() + \"_\" + detectionConfigDTO.getId()));\n+      LOG.info(\"Deleted existing task with detection: {}\", detectionConfigDTO);\n+    }\n+  }\n+\n+  boolean validateOnlineRequestPayload(JsonNode payloadNode) {\n+    if (!payloadNode.has(DATA_FIELD))\n+      return false;\n+\n+    JsonNode dataNode = payloadNode.get(DATA_FIELD);\n+    if (!dataNode.has(COLUMNS_FIELD) || !dataNode.has(ROWS_FIELD))\n+      return false;\n+\n+    JsonNode columnsNode = dataNode.get(COLUMNS_FIELD);\n+    if (!columnsNode.isArray())\n+      return false;\n+\n+    boolean hasTimeColumn = false, hasMetricColumn = false;\n+    for (JsonNode columnNode : columnsNode) {\n+      if (columnNode.textValue().equals(DEFAULT_TIME_COLUMN))\n+        hasTimeColumn = true;\n+      if (columnNode.textValue().equals(DEFAULT_METRIC_COLUMN))\n+        hasMetricColumn = true;\n+      if (hasTimeColumn && hasMetricColumn)\n+        break;\n+    }\n+    return hasTimeColumn && hasMetricColumn;\n+  }\n+\n+  DatasetConfigDTO generateDatasetConfig(JsonNode payloadNode, String suffix) {\n+    DatasetConfigDTO datasetConfigDTO = new DatasetConfigDTO();\n+\n+    // Default configuration\n+    datasetConfigDTO.setDataset(DEFAULT_DATASET_NAME + suffix);\n+    datasetConfigDTO.setDimensions(DEFAULT_DIMENSIONS);\n+    datasetConfigDTO.setTimeColumn(DEFAULT_TIME_COLUMN);\n+    datasetConfigDTO.setTimeDuration(DEFAULT_TIME_DURATION);\n+    datasetConfigDTO.setTimeUnit(DEFAULT_TIME_UNIT);\n+    datasetConfigDTO.setTimeFormat(DEFAULT_TIME_FORMAT);\n+    datasetConfigDTO.setTimezone(DEFAULT_TIME_ZONE);\n+    datasetConfigDTO.setDataSource(ONLINE_DATASOURCE);\n+\n+    // Customized configuration\n+    if (payloadNode.has(DATASET_FIELD)) {\n+\n+      Map<String, Object> datasetYaml =\n+          ConfigUtils.getMap(yaml.load(payloadNode.get(DATASET_FIELD).textValue()));\n+\n+      if (datasetYaml.containsKey(TIME_COLUMN_YAML_FIELD)) {\n+        datasetConfigDTO.setTimeColumn((String) datasetYaml.get(TIME_COLUMN_YAML_FIELD));\n+      }\n+      if (datasetYaml.containsKey(TIME_UNIT_YAML_FIELD)) {\n+        datasetConfigDTO\n+            .setTimeUnit(TimeUnit.valueOf((String) datasetYaml.get(TIME_UNIT_YAML_FIELD)));\n+      }\n+      if (datasetYaml.containsKey(TIME_DURATION_YAML_FIELD)) {\n+        datasetConfigDTO.setTimeDuration((Integer) datasetYaml.get(TIME_DURATION_YAML_FIELD));\n+      }\n+      if (datasetYaml.containsKey(TIME_FORMAT_YAML_FIELD)) {\n+        datasetConfigDTO.setTimeFormat((String) datasetYaml.get(TIME_FORMAT_YAML_FIELD));\n+      }\n+      if (datasetYaml.containsKey(TIME_ZONE_YAML_FIELD)) {\n+        datasetConfigDTO.setTimezone((String) datasetYaml.get(TIME_ZONE_YAML_FIELD));\n+      }\n+    }\n+\n+    this.datasetConfigValidator.validateConfig(datasetConfigDTO);\n+\n+    datasetConfigDAO.save(datasetConfigDTO);\n+    LOG.info(\"Created dataset with config {}\", datasetConfigDTO);\n+\n+    return datasetConfigDTO;\n+  }\n+\n+  MetricConfigDTO generateMetricConfig(JsonNode payloadNode, String suffix)\n+      throws JsonProcessingException {\n+    MetricConfigDTO metricConfigDTO = new MetricConfigDTO();\n+    JsonNode dataNode = payloadNode.get(DATA_FIELD);\n+\n+    // Default configuration\n+    metricConfigDTO.setName(DEFAULT_METRIC_NAME + suffix);\n+    metricConfigDTO.setDataset(DEFAULT_DATASET_NAME + suffix);\n+    metricConfigDTO.setAlias(ThirdEyeUtils\n+        .constructMetricAlias(DEFAULT_DATASET_NAME + suffix,\n+            DEFAULT_METRIC_NAME + suffix));\n+    metricConfigDTO.setDatatype(DEFAULT_DATA_TYPE);\n+    metricConfigDTO.setDefaultAggFunction(MetricAggFunction.SUM);\n+    metricConfigDTO.setActive(true);\n+\n+    // Customized configuration\n+    if (payloadNode.has(METRIC_FIELD)) {\n+      Map<String, Object> metricYaml =\n+          ConfigUtils.getMap(yaml.load(payloadNode.get(METRIC_FIELD).textValue()));\n+\n+      if (metricYaml.containsKey(DATATYPE_YAML_FIELD)) {\n+        metricConfigDTO\n+            .setDatatype(MetricType.valueOf((String) metricYaml.get(DATATYPE_YAML_FIELD)));\n+      }\n+    }\n+\n+    // Reformat Metric column name to keep consistency with metric config\n+    ArrayNode columnsNode = dataNode.withArray(COLUMNS_FIELD);\n+    if (columnsNode.isArray()) {\n+      int colIdx = 0;\n+      for (; colIdx < columnsNode.size(); colIdx++) {\n+        if (columnsNode.get(colIdx).textValue().equals(DEFAULT_METRIC_COLUMN)) {\n+          break;\n+        }\n+      }\n+      columnsNode.set(colIdx, new TextNode(DEFAULT_METRIC_NAME + suffix));\n+    }\n+    // TODO: should store online data into a new table\n+    metricConfigDTO.setOnlineData(this.objectMapper.writeValueAsString(dataNode));\n+\n+    this.metricConfigValidator.validateConfig(metricConfigDTO);\n+\n+    metricConfigDAO.save(metricConfigDTO);\n+    LOG.info(\"Created metric with config {}\", metricConfigDTO);\n+\n+    return metricConfigDTO;\n+  }\n+\n+  DetectionConfigDTO generateDetectionConfig(JsonNode payloadNode, String suffix,\n+      DatasetConfigDTO datasetConfigDTO, MetricConfigDTO metricConfigDTO, long start, long end) {\n+    DetectionConfigDTO detectionConfigDTO;\n+    Map<String, Object> detectionYaml;\n+    ClassLoader classLoader = Thread.currentThread().getContextClassLoader();\n+\n+    if (payloadNode.has(DETECTION_FIELD)) {\n+      // Customized configuration: retrieve config from user request\n+      detectionYaml = ConfigUtils.getMap(yaml.load(payloadNode.get(DETECTION_FIELD).textValue()));\n+    } else {\n+      // Default configuration: retrieve the template from disk\n+      detectionYaml =\n+          ConfigUtils.getMap(yaml.load(classLoader.getResourceAsStream(TEMPLATE_DETECTION_PATH)));\n+    }\n+\n+    // Do not support customized detection name as it is not a common use case\n+    detectionYaml.put(DETECTION_YAML_FIELD, DEFAULT_DETECTION_NAME + suffix);\n+    detectionYaml.put(DATASET_YAML_FIELD, datasetConfigDTO.getName());\n+    detectionYaml.put(METRIC_YAML_FIELD, metricConfigDTO.getName());\n+\n+    detectionConfigDTO =\n+        new DetectionConfigTranslator(this.yaml.dump(detectionYaml), this.provider).translate();\n+    detectionConfigDTO.setCron(\"0 0 0 1 1 ? 2200\"); // Never scheduled\n+\n+    // Tune the detection config - Passes the raw yaml params & injects tuned params\n+    DetectionConfigTuner detectionTuner = new DetectionConfigTuner(detectionConfigDTO, provider);\n+    detectionConfigDTO = detectionTuner.tune(start, end);\n+\n+    // Validate the detection config\n+    detectionValidator.validateConfig(detectionConfigDTO);\n+\n+    detectionConfigDAO.save(detectionConfigDTO);\n+    LOG.info(\"Created detection with config {}\", detectionConfigDTO);\n+\n+    return detectionConfigDTO;\n+  }\n+\n+  TaskDTO generateTaskConfig(long detectionConfigId, long start, long end)\n+      throws JsonProcessingException {\n+    TaskDTO taskDTO = new TaskDTO();\n+    taskDTO.setJobName(TaskConstants.TaskType.DETECTION.toString() + \"_\" + detectionConfigId);\n+    taskDTO.setStatus(TaskConstants.TaskStatus.WAITING);\n+    taskDTO.setTaskType(TaskConstants.TaskType.DETECTION_ONLINE);\n+    DetectionPipelineTaskInfo taskInfo =\n+        new DetectionPipelineTaskInfo(detectionConfigId, start, end);\n+    String taskInfoJson = objectMapper.writeValueAsString(taskInfo);\n+    taskDTO.setTaskInfo(taskInfoJson);\n+\n+    taskDAO.save(taskDTO);\n+    LOG.info(\"Created task: {}\", taskDTO);\n+\n+    return taskDTO;\n+  }\n+\n+  private TaskDTO pollingTask(long taskId) {\n+    long startTime = System.currentTimeMillis();\n+    TaskDTO taskDTO;\n+\n+    // Timeout mechanism will be handled by worker thread in the controller", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6d91338441effdb3e94eface7664035757ae2e4d"}, "originalPosition": 497}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzMxNTYxNg==", "bodyText": "no need to delete the taskDTO. it will be cleaned up periodically by the monitor task.", "url": "https://github.com/apache/pinot/pull/5769#discussion_r463315616", "createdAt": "2020-07-30T22:54:40Z", "author": {"login": "jihaozh"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/api/detection/AnomalyDetectionResource.java", "diffHunk": "@@ -0,0 +1,756 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.pinot.thirdeye.api.detection;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ArrayNode;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.fasterxml.jackson.databind.node.TextNode;\n+import io.dropwizard.auth.Auth;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import io.swagger.annotations.ApiParam;\n+import org.apache.pinot.thirdeye.anomaly.task.TaskConstants;\n+import org.apache.pinot.thirdeye.api.Constants;\n+import org.apache.pinot.thirdeye.api.user.dashboard.UserDashboardResource;\n+import org.apache.pinot.thirdeye.auth.ThirdEyePrincipal;\n+import org.apache.pinot.thirdeye.common.metric.MetricType;\n+import org.apache.pinot.thirdeye.constant.MetricAggFunction;\n+import org.apache.pinot.thirdeye.dashboard.resources.v2.pojo.AnomalySummary;\n+import org.apache.pinot.thirdeye.datalayer.bao.*;\n+import org.apache.pinot.thirdeye.datalayer.dto.DatasetConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.DetectionConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.MetricConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.TaskDTO;\n+import org.apache.pinot.thirdeye.datalayer.util.Predicate;\n+import org.apache.pinot.thirdeye.datasource.DAORegistry;\n+import org.apache.pinot.thirdeye.datasource.ThirdEyeCacheRegistry;\n+import org.apache.pinot.thirdeye.datasource.loader.AggregationLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.DefaultAggregationLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.DefaultTimeSeriesLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.TimeSeriesLoader;\n+import org.apache.pinot.thirdeye.detection.*;\n+import org.apache.pinot.thirdeye.detection.cache.builder.AnomaliesCacheBuilder;\n+import org.apache.pinot.thirdeye.detection.cache.builder.TimeSeriesCacheBuilder;\n+import org.apache.pinot.thirdeye.detection.validators.DatasetConfigValidator;\n+import org.apache.pinot.thirdeye.detection.validators.DetectionConfigValidator;\n+import org.apache.pinot.thirdeye.detection.validators.MetricConfigValidator;\n+import org.apache.pinot.thirdeye.detection.yaml.DetectionConfigTuner;\n+import org.apache.pinot.thirdeye.detection.yaml.translator.DetectionConfigTranslator;\n+import org.apache.pinot.thirdeye.util.ThirdEyeUtils;\n+import org.jfree.util.Log;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.yaml.snakeyaml.Yaml;\n+import javax.ws.rs.*;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import javax.ws.rs.core.UriBuilder;\n+import java.util.*;\n+import java.util.concurrent.TimeUnit;\n+\n+@Path(\"/anomaly-detection\")\n+@Api(tags = { Constants.DETECTION_TAG })\n+public class AnomalyDetectionResource {\n+  protected static final Logger LOG = LoggerFactory.getLogger(AnomalyDetectionResource.class);\n+\n+  private static final String TEMPLATE_DETECTION_PATH = \"detection-config-template.yml\";\n+\n+  /* -------- Detection config fields -------- */\n+  private static final String DETECTION_YAML_FIELD = \"detectionName\";\n+  private static final String DEFAULT_DETECTION_NAME = \"online_detection\";\n+\n+  /* -------- Metric config fields -------- */\n+  private static final String DATASET_YAML_FIELD = \"dataset\";\n+  private static final String DEFAULT_DATASET_NAME = \"online_dataset\";\n+  private static final String DATATYPE_YAML_FIELD = \"datatype\";\n+  private static final MetricType DEFAULT_DATA_TYPE = MetricType.DOUBLE;\n+\n+  /* -------- Dataset config fields -------- */\n+  private static final String METRIC_YAML_FIELD = \"metric\";\n+  private static final String DEFAULT_METRIC_NAME = \"online_metric\";\n+  private static final String DEFAULT_METRIC_COLUMN = \"metric\";\n+  private static final String TIME_COLUMN_YAML_FIELD = \"timeColumn\";\n+  private static final String DEFAULT_TIME_COLUMN = \"date\";\n+  private static final String TIME_UNIT_YAML_FIELD = \"timeUnit\";\n+  private static final TimeUnit DEFAULT_TIME_UNIT = TimeUnit.DAYS;\n+  private static final String TIME_DURATION_YAML_FIELD = \"timeDuration\";\n+  private static final String TIME_FORMAT_YAML_FIELD = \"timeFormat\";\n+  private static final String DEFAULT_TIME_FORMAT = \"SIMPLE_DATE_FORMAT:yyyyMMdd\";\n+  private static final String TIME_ZONE_YAML_FIELD = \"timezone\";\n+  private static final String DEFAULT_TIME_ZONE = \"US/Pacific\";\n+  private static final List<String> DEFAULT_DIMENSIONS =\n+      Collections.unmodifiableList(new ArrayList<>());\n+\n+  /* -------- Request/Response field -------- */\n+  private static final String DATA_FIELD = \"data\";\n+  private static final String COLUMNS_FIELD = \"columns\";\n+  private static final String ROWS_FIELD = \"rows\";\n+  private static final String DATASET_FIELD = \"datasetConfiguration\";\n+  private static final String METRIC_FIELD = \"metricConfiguration\";\n+  private static final String DETECTION_FIELD = \"detectionConfiguration\";\n+  private static final String ANOMALIES_FIELD = \"anomalies\";\n+\n+  /* -------- Others -------- */\n+  private static final String ONLINE_DATASOURCE = \"OnlineThirdEyeDataSource\";\n+  private static final String DETECTION_MYSQL_NAME_COLUMN = \"name\";\n+  private static final String TASK_MYSQL_NAME_COLUMN = \"name\";\n+  private static final String ANOMALY_ENDPOINT_URL = \"/userdashboard/anomalies\";\n+  private static final long POLLING_SLEEP_TIME = 5L;\n+  private static final int DEFAULT_TIME_DURATION = 1;\n+  private static final long MAX_ONLINE_PAYLOAD_SIZE = 10 * 1024 * 1024L;\n+\n+  private final UserDashboardResource userDashboardResource;\n+  private final DetectionConfigManager detectionConfigDAO;\n+  private final DataProvider provider;\n+  private final MetricConfigManager metricConfigDAO;\n+  private final DatasetConfigManager datasetConfigDAO;\n+  private final EventManager eventDAO;\n+  private final MergedAnomalyResultManager anomalyDAO;\n+  private final EvaluationManager evaluationDAO;\n+  private final TaskManager taskDAO;\n+  private final DetectionPipelineLoader loader;\n+  private final DetectionConfigValidator detectionValidator;\n+  private final DatasetConfigValidator datasetConfigValidator;\n+  private final MetricConfigValidator metricConfigValidator;\n+  private final ObjectMapper objectMapper = new ObjectMapper();\n+  private final Yaml yaml;\n+\n+  public AnomalyDetectionResource(UserDashboardResource userDashboardResource) {\n+    this.detectionConfigDAO = DAORegistry.getInstance().getDetectionConfigManager();\n+    this.metricConfigDAO = DAORegistry.getInstance().getMetricConfigDAO();\n+    this.datasetConfigDAO = DAORegistry.getInstance().getDatasetConfigDAO();\n+    this.eventDAO = DAORegistry.getInstance().getEventDAO();\n+    this.anomalyDAO = DAORegistry.getInstance().getMergedAnomalyResultDAO();\n+    this.taskDAO = DAORegistry.getInstance().getTaskDAO();\n+    this.evaluationDAO = DAORegistry.getInstance().getEvaluationManager();\n+    this.userDashboardResource = userDashboardResource;\n+\n+    TimeSeriesLoader timeseriesLoader =\n+        new DefaultTimeSeriesLoader(metricConfigDAO, datasetConfigDAO,\n+            ThirdEyeCacheRegistry.getInstance().getQueryCache(),\n+            ThirdEyeCacheRegistry.getInstance().getTimeSeriesCache());\n+\n+    AggregationLoader aggregationLoader =\n+        new DefaultAggregationLoader(metricConfigDAO, datasetConfigDAO,\n+            ThirdEyeCacheRegistry.getInstance().getQueryCache(),\n+            ThirdEyeCacheRegistry.getInstance().getDatasetMaxDataTimeCache());\n+\n+    this.loader = new DetectionPipelineLoader();\n+\n+    this.provider = new DefaultDataProvider(metricConfigDAO, datasetConfigDAO, eventDAO, anomalyDAO,\n+        evaluationDAO, timeseriesLoader, aggregationLoader, loader,\n+        TimeSeriesCacheBuilder.getInstance(), AnomaliesCacheBuilder.getInstance());\n+    this.detectionValidator = new DetectionConfigValidator(this.provider);\n+    this.metricConfigValidator = new MetricConfigValidator();\n+    this.datasetConfigValidator = new DatasetConfigValidator();\n+\n+    // Read template from disk\n+    this.yaml = new Yaml();\n+  }\n+\n+  /**\n+   * Run an online anomaly detection service synchronously. It will run anomaly detection using\n+   * default configs for detection, metric, dataset\n+   *\n+   * @param start     detection window start time\n+   * @param end       detection window end time\n+   * @param payload   payload in request including online data\n+   * @param principal user who sent this request. It's used to separate different config names\n+   * @return a message containing the detected anomalies and the detection config used\n+   */\n+  @POST\n+  @Path(\"/\")\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @Consumes(MediaType.APPLICATION_JSON)\n+  @ApiOperation(\"Request an anomaly detection online task\")\n+  public Response onlineApi(\n+          @QueryParam(\"start\") long start,\n+          @QueryParam(\"end\") long end,\n+          @ApiParam(\"jsonPayload\") String payload,\n+          @Auth ThirdEyePrincipal principal) {\n+    DatasetConfigDTO datasetConfigDTO = null;\n+    MetricConfigDTO metricConfigDTO = null;\n+    DetectionConfigDTO detectionConfigDTO = null;\n+    TaskDTO taskDTO = null;\n+    List<AnomalySummary> anomalies = null;\n+    Response.Status responseStatus;\n+    Map<String, String> responseMessage = new HashMap<>();\n+    ObjectMapper objectMapper = new ObjectMapper();\n+    // Use username to separate different requests. One user can only send one request at a time\n+    String nameSuffix = \"_\" + principal.getName();\n+\n+    try {\n+      if (payload.getBytes().length > MAX_ONLINE_PAYLOAD_SIZE) {\n+        responseStatus = Response.Status.BAD_REQUEST;\n+        responseMessage.put(\"message\", \"Payload too large\");\n+        return Response.status(responseStatus).entity(responseMessage).build();\n+      }\n+\n+      JsonNode payloadNode = objectMapper.readTree(payload);\n+\n+      if (!validateOnlineRequestPayload(payloadNode)) {\n+        responseStatus = Response.Status.BAD_REQUEST;\n+        responseMessage.put(\"message\", \"Invalid request payload\");\n+        return Response.status(responseStatus).entity(responseMessage).build();\n+      }\n+\n+      // Preprocess: remove existing entities generated by the previous interrupted request\n+      cleanExistingOnlineTask(nameSuffix);\n+\n+      // Create & save dataset\n+      datasetConfigDTO = generateDatasetConfig(payloadNode, nameSuffix);\n+\n+      // Create & save metric along with online data\n+      metricConfigDTO = generateMetricConfig(payloadNode, nameSuffix);\n+\n+      // Create & save detection\n+      detectionConfigDTO =\n+          generateDetectionConfig(payloadNode, nameSuffix, datasetConfigDTO, metricConfigDTO, start,\n+              end);\n+\n+      // Create & save task\n+      taskDTO = generateTaskConfig(detectionConfigDTO.getId(), start, end);\n+\n+      // Polling task status\n+      TaskDTO polledTaskDTO = pollingTask(taskDTO.getId());\n+\n+      // Task failure\n+      if (polledTaskDTO.getStatus() != TaskConstants.TaskStatus.COMPLETED) {\n+        LOG.warn(\"Task is not completed after polling: \" + polledTaskDTO);\n+\n+        responseStatus = Response.Status.INTERNAL_SERVER_ERROR;\n+\n+        switch (polledTaskDTO.getStatus()) {\n+        case FAILED:\n+          responseStatus = Response.Status.INTERNAL_SERVER_ERROR;\n+          responseMessage.put(\"message\", \"Failed to execute anomaly detection task.\");\n+          break;\n+        case TIMEOUT:\n+          responseStatus = Response.Status.REQUEST_TIMEOUT;\n+          responseMessage.put(\"message\", \"Anomaly detection task timeout.\");\n+        default:\n+          LOG.error(\"Error task status after polling: \" + polledTaskDTO.getStatus());\n+          responseMessage.put(\"message\", \"unknown task status.\");\n+          break;\n+        }\n+\n+        responseMessage.put(\"more-info\", \"Error = \" + polledTaskDTO.getMessage());\n+\n+        // Send response\n+        return Response.status(responseStatus).entity(responseMessage).build();\n+      }\n+\n+      // Task success\n+      // Retrieve task result\n+      anomalies = getAnomalies(start, end, metricConfigDTO.getName(), datasetConfigDTO.getName());\n+\n+      // Build success response\n+      JsonNode anomalyNode = objectMapper.convertValue(anomalies, JsonNode.class);\n+      JsonNode detectionConfigNode =\n+          objectMapper.convertValue(detectionConfigDTO.getYaml(), JsonNode.class);\n+      ObjectNode responseNode = objectMapper.createObjectNode();\n+      responseNode.set(ANOMALIES_FIELD, anomalyNode);\n+      responseNode.set(DETECTION_FIELD, detectionConfigNode);\n+\n+      responseStatus = Response.Status.OK;\n+      return Response.status(responseStatus).entity(objectMapper.writeValueAsString(responseNode))\n+          .build();\n+    } catch (JsonProcessingException e) {\n+      LOG.error(\"Error: {}\", e.getMessage());\n+      responseStatus = Response.Status.BAD_REQUEST;\n+      responseMessage.put(\"message\", \"Invalid request payload\");\n+      processException(e, responseMessage);\n+      return Response.status(responseStatus).entity(responseMessage).build();\n+    } catch (Exception e) {\n+      LOG.error(\"Error: {}\", e.getMessage());\n+      responseStatus = Response.Status.INTERNAL_SERVER_ERROR;\n+      responseMessage.put(\"message\", \"Failed executing anomaly detection service.\");\n+      processException(e, responseMessage);\n+      return Response.status(responseStatus).entity(responseMessage).build();\n+    } finally {\n+      // Online service is stateless\n+      cleanStates(anomalies, taskDTO, metricConfigDTO, datasetConfigDTO, detectionConfigDTO);\n+    }\n+  }\n+\n+  void cleanExistingOnlineTask(String nameSuffix) {\n+    String metricName = DEFAULT_METRIC_NAME + nameSuffix;\n+    List<MetricConfigDTO> metricConfigDTOS = metricConfigDAO.findByMetricName(metricName);\n+    for (MetricConfigDTO metricConfigDTO : metricConfigDTOS) {\n+      metricConfigDAO.deleteById(metricConfigDTO.getId());\n+      LOG.info(\"Deleted existing metric: {}\", metricConfigDTO);\n+    }\n+\n+    String datasetName = DEFAULT_DATASET_NAME + nameSuffix;\n+    DatasetConfigDTO datasetConfigDTO = datasetConfigDAO.findByDataset(datasetName);\n+    if (datasetConfigDTO != null) {\n+      datasetConfigDAO.delete(datasetConfigDTO);\n+      LOG.info(\"Deleted existing dataset: {}\", datasetConfigDTO);\n+    }\n+\n+    String detectionName = DEFAULT_DETECTION_NAME + nameSuffix;\n+    List<DetectionConfigDTO> detectionConfigDTOS = detectionConfigDAO\n+        .findByPredicate(Predicate.EQ(DETECTION_MYSQL_NAME_COLUMN, detectionName));\n+    for (DetectionConfigDTO detectionConfigDTO : detectionConfigDTOS) {\n+      detectionConfigDAO.delete(detectionConfigDTO);\n+      taskDAO.deleteByPredicate(Predicate.EQ(TASK_MYSQL_NAME_COLUMN,\n+          TaskConstants.TaskType.DETECTION.name() + \"_\" + detectionConfigDTO.getId()));\n+      LOG.info(\"Deleted existing task with detection: {}\", detectionConfigDTO);\n+    }\n+  }\n+\n+  boolean validateOnlineRequestPayload(JsonNode payloadNode) {\n+    if (!payloadNode.has(DATA_FIELD))\n+      return false;\n+\n+    JsonNode dataNode = payloadNode.get(DATA_FIELD);\n+    if (!dataNode.has(COLUMNS_FIELD) || !dataNode.has(ROWS_FIELD))\n+      return false;\n+\n+    JsonNode columnsNode = dataNode.get(COLUMNS_FIELD);\n+    if (!columnsNode.isArray())\n+      return false;\n+\n+    boolean hasTimeColumn = false, hasMetricColumn = false;\n+    for (JsonNode columnNode : columnsNode) {\n+      if (columnNode.textValue().equals(DEFAULT_TIME_COLUMN))\n+        hasTimeColumn = true;\n+      if (columnNode.textValue().equals(DEFAULT_METRIC_COLUMN))\n+        hasMetricColumn = true;\n+      if (hasTimeColumn && hasMetricColumn)\n+        break;\n+    }\n+    return hasTimeColumn && hasMetricColumn;\n+  }\n+\n+  DatasetConfigDTO generateDatasetConfig(JsonNode payloadNode, String suffix) {\n+    DatasetConfigDTO datasetConfigDTO = new DatasetConfigDTO();\n+\n+    // Default configuration\n+    datasetConfigDTO.setDataset(DEFAULT_DATASET_NAME + suffix);\n+    datasetConfigDTO.setDimensions(DEFAULT_DIMENSIONS);\n+    datasetConfigDTO.setTimeColumn(DEFAULT_TIME_COLUMN);\n+    datasetConfigDTO.setTimeDuration(DEFAULT_TIME_DURATION);\n+    datasetConfigDTO.setTimeUnit(DEFAULT_TIME_UNIT);\n+    datasetConfigDTO.setTimeFormat(DEFAULT_TIME_FORMAT);\n+    datasetConfigDTO.setTimezone(DEFAULT_TIME_ZONE);\n+    datasetConfigDTO.setDataSource(ONLINE_DATASOURCE);\n+\n+    // Customized configuration\n+    if (payloadNode.has(DATASET_FIELD)) {\n+\n+      Map<String, Object> datasetYaml =\n+          ConfigUtils.getMap(yaml.load(payloadNode.get(DATASET_FIELD).textValue()));\n+\n+      if (datasetYaml.containsKey(TIME_COLUMN_YAML_FIELD)) {\n+        datasetConfigDTO.setTimeColumn((String) datasetYaml.get(TIME_COLUMN_YAML_FIELD));\n+      }\n+      if (datasetYaml.containsKey(TIME_UNIT_YAML_FIELD)) {\n+        datasetConfigDTO\n+            .setTimeUnit(TimeUnit.valueOf((String) datasetYaml.get(TIME_UNIT_YAML_FIELD)));\n+      }\n+      if (datasetYaml.containsKey(TIME_DURATION_YAML_FIELD)) {\n+        datasetConfigDTO.setTimeDuration((Integer) datasetYaml.get(TIME_DURATION_YAML_FIELD));\n+      }\n+      if (datasetYaml.containsKey(TIME_FORMAT_YAML_FIELD)) {\n+        datasetConfigDTO.setTimeFormat((String) datasetYaml.get(TIME_FORMAT_YAML_FIELD));\n+      }\n+      if (datasetYaml.containsKey(TIME_ZONE_YAML_FIELD)) {\n+        datasetConfigDTO.setTimezone((String) datasetYaml.get(TIME_ZONE_YAML_FIELD));\n+      }\n+    }\n+\n+    this.datasetConfigValidator.validateConfig(datasetConfigDTO);\n+\n+    datasetConfigDAO.save(datasetConfigDTO);\n+    LOG.info(\"Created dataset with config {}\", datasetConfigDTO);\n+\n+    return datasetConfigDTO;\n+  }\n+\n+  MetricConfigDTO generateMetricConfig(JsonNode payloadNode, String suffix)\n+      throws JsonProcessingException {\n+    MetricConfigDTO metricConfigDTO = new MetricConfigDTO();\n+    JsonNode dataNode = payloadNode.get(DATA_FIELD);\n+\n+    // Default configuration\n+    metricConfigDTO.setName(DEFAULT_METRIC_NAME + suffix);\n+    metricConfigDTO.setDataset(DEFAULT_DATASET_NAME + suffix);\n+    metricConfigDTO.setAlias(ThirdEyeUtils\n+        .constructMetricAlias(DEFAULT_DATASET_NAME + suffix,\n+            DEFAULT_METRIC_NAME + suffix));\n+    metricConfigDTO.setDatatype(DEFAULT_DATA_TYPE);\n+    metricConfigDTO.setDefaultAggFunction(MetricAggFunction.SUM);\n+    metricConfigDTO.setActive(true);\n+\n+    // Customized configuration\n+    if (payloadNode.has(METRIC_FIELD)) {\n+      Map<String, Object> metricYaml =\n+          ConfigUtils.getMap(yaml.load(payloadNode.get(METRIC_FIELD).textValue()));\n+\n+      if (metricYaml.containsKey(DATATYPE_YAML_FIELD)) {\n+        metricConfigDTO\n+            .setDatatype(MetricType.valueOf((String) metricYaml.get(DATATYPE_YAML_FIELD)));\n+      }\n+    }\n+\n+    // Reformat Metric column name to keep consistency with metric config\n+    ArrayNode columnsNode = dataNode.withArray(COLUMNS_FIELD);\n+    if (columnsNode.isArray()) {\n+      int colIdx = 0;\n+      for (; colIdx < columnsNode.size(); colIdx++) {\n+        if (columnsNode.get(colIdx).textValue().equals(DEFAULT_METRIC_COLUMN)) {\n+          break;\n+        }\n+      }\n+      columnsNode.set(colIdx, new TextNode(DEFAULT_METRIC_NAME + suffix));\n+    }\n+    // TODO: should store online data into a new table\n+    metricConfigDTO.setOnlineData(this.objectMapper.writeValueAsString(dataNode));\n+\n+    this.metricConfigValidator.validateConfig(metricConfigDTO);\n+\n+    metricConfigDAO.save(metricConfigDTO);\n+    LOG.info(\"Created metric with config {}\", metricConfigDTO);\n+\n+    return metricConfigDTO;\n+  }\n+\n+  DetectionConfigDTO generateDetectionConfig(JsonNode payloadNode, String suffix,\n+      DatasetConfigDTO datasetConfigDTO, MetricConfigDTO metricConfigDTO, long start, long end) {\n+    DetectionConfigDTO detectionConfigDTO;\n+    Map<String, Object> detectionYaml;\n+    ClassLoader classLoader = Thread.currentThread().getContextClassLoader();\n+\n+    if (payloadNode.has(DETECTION_FIELD)) {\n+      // Customized configuration: retrieve config from user request\n+      detectionYaml = ConfigUtils.getMap(yaml.load(payloadNode.get(DETECTION_FIELD).textValue()));\n+    } else {\n+      // Default configuration: retrieve the template from disk\n+      detectionYaml =\n+          ConfigUtils.getMap(yaml.load(classLoader.getResourceAsStream(TEMPLATE_DETECTION_PATH)));\n+    }\n+\n+    // Do not support customized detection name as it is not a common use case\n+    detectionYaml.put(DETECTION_YAML_FIELD, DEFAULT_DETECTION_NAME + suffix);\n+    detectionYaml.put(DATASET_YAML_FIELD, datasetConfigDTO.getName());\n+    detectionYaml.put(METRIC_YAML_FIELD, metricConfigDTO.getName());\n+\n+    detectionConfigDTO =\n+        new DetectionConfigTranslator(this.yaml.dump(detectionYaml), this.provider).translate();\n+    detectionConfigDTO.setCron(\"0 0 0 1 1 ? 2200\"); // Never scheduled\n+\n+    // Tune the detection config - Passes the raw yaml params & injects tuned params\n+    DetectionConfigTuner detectionTuner = new DetectionConfigTuner(detectionConfigDTO, provider);\n+    detectionConfigDTO = detectionTuner.tune(start, end);\n+\n+    // Validate the detection config\n+    detectionValidator.validateConfig(detectionConfigDTO);\n+\n+    detectionConfigDAO.save(detectionConfigDTO);\n+    LOG.info(\"Created detection with config {}\", detectionConfigDTO);\n+\n+    return detectionConfigDTO;\n+  }\n+\n+  TaskDTO generateTaskConfig(long detectionConfigId, long start, long end)\n+      throws JsonProcessingException {\n+    TaskDTO taskDTO = new TaskDTO();\n+    taskDTO.setJobName(TaskConstants.TaskType.DETECTION.toString() + \"_\" + detectionConfigId);\n+    taskDTO.setStatus(TaskConstants.TaskStatus.WAITING);\n+    taskDTO.setTaskType(TaskConstants.TaskType.DETECTION_ONLINE);\n+    DetectionPipelineTaskInfo taskInfo =\n+        new DetectionPipelineTaskInfo(detectionConfigId, start, end);\n+    String taskInfoJson = objectMapper.writeValueAsString(taskInfo);\n+    taskDTO.setTaskInfo(taskInfoJson);\n+\n+    taskDAO.save(taskDTO);\n+    LOG.info(\"Created task: {}\", taskDTO);\n+\n+    return taskDTO;\n+  }\n+\n+  private TaskDTO pollingTask(long taskId) {\n+    long startTime = System.currentTimeMillis();\n+    TaskDTO taskDTO;\n+\n+    // Timeout mechanism will be handled by worker thread in the controller\n+    while (true) {\n+      taskDTO = taskDAO.findById(taskId);\n+\n+      LOG.info(\"Polling task : \" + taskDTO);\n+\n+      TaskConstants.TaskStatus taskStatus = taskDTO.getStatus();\n+      if (!taskStatus.equals(TaskConstants.TaskStatus.WAITING) && !taskStatus\n+          .equals(TaskConstants.TaskStatus.RUNNING)) {\n+        LOG.info(\"Polling finished ({}ms). Task status: {}\", System.currentTimeMillis() - startTime,\n+            taskStatus);\n+        break;\n+      }\n+\n+      try {\n+        TimeUnit.SECONDS.sleep(POLLING_SLEEP_TIME);\n+      } catch (InterruptedException e) {\n+        Log.warn(\"Interrupted during polling sleep\");\n+        break;\n+      }\n+    }\n+\n+    return taskDTO;\n+  }\n+\n+  private List<AnomalySummary> getAnomalies(long start, long end, String metric, String dataset) {\n+    List<AnomalySummary> anomalies =\n+        this.userDashboardResource.queryAnomalies(start, end, null, null, metric,\n+            dataset, null, false, null);\n+\n+    LOG.info(\"Successfully returned \" + anomalies.size() + \" anomalies.\");\n+    return anomalies;\n+  }\n+\n+  private void cleanStates(List<AnomalySummary> anomalies, TaskDTO taskDTO,\n+      MetricConfigDTO metricConfigDTO, DatasetConfigDTO datasetConfigDTO,\n+      DetectionConfigDTO detectionConfigDTO) {\n+    if (anomalies != null) {\n+      for (AnomalySummary anomaly : anomalies) {\n+        anomalyDAO.deleteById(anomaly.getId());\n+        LOG.info(\"Deleted anomaly with id: {}\", anomaly.getId());\n+      }\n+    }\n+\n+    if (datasetConfigDTO != null) {\n+      datasetConfigDAO.delete(datasetConfigDTO);\n+      LOG.info(\"Deleted dataset: {}\", datasetConfigDTO);\n+    }\n+\n+    if (metricConfigDTO != null) {\n+      metricConfigDAO.delete(metricConfigDTO);\n+      LOG.info(\"Deleted metric: {}\", metricConfigDTO);\n+    }\n+\n+    if (detectionConfigDTO != null) {\n+      detectionConfigDAO.delete(detectionConfigDTO);\n+      LOG.info(\"Deleted detection: {}\", detectionConfigDTO);\n+    }\n+\n+    if (taskDTO != null) {\n+      taskDAO.delete(taskDTO);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6d91338441effdb3e94eface7664035757ae2e4d"}, "originalPosition": 557}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDYxMTE3MDc5", "url": "https://github.com/apache/pinot/pull/5769#pullrequestreview-461117079", "createdAt": "2020-08-04T19:38:48Z", "commit": {"oid": "6d91338441effdb3e94eface7664035757ae2e4d"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQxOTozODo0OFrOG7u0Aw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQyMTo1MzowN1rOG8b8dw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTI4NjE0Nw==", "bodyText": "Could we use the constants in DetectionConfigValidator? It is even nicer if you can refactor these constants into a separate class.", "url": "https://github.com/apache/pinot/pull/5769#discussion_r465286147", "createdAt": "2020-08-04T19:38:48Z", "author": {"login": "vincentchenjl"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/api/detection/AnomalyDetectionResource.java", "diffHunk": "@@ -0,0 +1,756 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.pinot.thirdeye.api.detection;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ArrayNode;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.fasterxml.jackson.databind.node.TextNode;\n+import io.dropwizard.auth.Auth;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import io.swagger.annotations.ApiParam;\n+import org.apache.pinot.thirdeye.anomaly.task.TaskConstants;\n+import org.apache.pinot.thirdeye.api.Constants;\n+import org.apache.pinot.thirdeye.api.user.dashboard.UserDashboardResource;\n+import org.apache.pinot.thirdeye.auth.ThirdEyePrincipal;\n+import org.apache.pinot.thirdeye.common.metric.MetricType;\n+import org.apache.pinot.thirdeye.constant.MetricAggFunction;\n+import org.apache.pinot.thirdeye.dashboard.resources.v2.pojo.AnomalySummary;\n+import org.apache.pinot.thirdeye.datalayer.bao.*;\n+import org.apache.pinot.thirdeye.datalayer.dto.DatasetConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.DetectionConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.MetricConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.TaskDTO;\n+import org.apache.pinot.thirdeye.datalayer.util.Predicate;\n+import org.apache.pinot.thirdeye.datasource.DAORegistry;\n+import org.apache.pinot.thirdeye.datasource.ThirdEyeCacheRegistry;\n+import org.apache.pinot.thirdeye.datasource.loader.AggregationLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.DefaultAggregationLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.DefaultTimeSeriesLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.TimeSeriesLoader;\n+import org.apache.pinot.thirdeye.detection.*;\n+import org.apache.pinot.thirdeye.detection.cache.builder.AnomaliesCacheBuilder;\n+import org.apache.pinot.thirdeye.detection.cache.builder.TimeSeriesCacheBuilder;\n+import org.apache.pinot.thirdeye.detection.validators.DatasetConfigValidator;\n+import org.apache.pinot.thirdeye.detection.validators.DetectionConfigValidator;\n+import org.apache.pinot.thirdeye.detection.validators.MetricConfigValidator;\n+import org.apache.pinot.thirdeye.detection.yaml.DetectionConfigTuner;\n+import org.apache.pinot.thirdeye.detection.yaml.translator.DetectionConfigTranslator;\n+import org.apache.pinot.thirdeye.util.ThirdEyeUtils;\n+import org.jfree.util.Log;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.yaml.snakeyaml.Yaml;\n+import javax.ws.rs.*;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import javax.ws.rs.core.UriBuilder;\n+import java.util.*;\n+import java.util.concurrent.TimeUnit;\n+\n+@Path(\"/anomaly-detection\")\n+@Api(tags = { Constants.DETECTION_TAG })\n+public class AnomalyDetectionResource {\n+  protected static final Logger LOG = LoggerFactory.getLogger(AnomalyDetectionResource.class);\n+\n+  private static final String TEMPLATE_DETECTION_PATH = \"detection-config-template.yml\";\n+\n+  /* -------- Detection config fields -------- */\n+  private static final String DETECTION_YAML_FIELD = \"detectionName\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6d91338441effdb3e94eface7664035757ae2e4d"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTI4ODA4NA==", "bodyText": "If this constant is only used once, you probably don't need to define it on the class level.", "url": "https://github.com/apache/pinot/pull/5769#discussion_r465288084", "createdAt": "2020-08-04T19:42:41Z", "author": {"login": "vincentchenjl"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/api/detection/AnomalyDetectionResource.java", "diffHunk": "@@ -0,0 +1,756 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.pinot.thirdeye.api.detection;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ArrayNode;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.fasterxml.jackson.databind.node.TextNode;\n+import io.dropwizard.auth.Auth;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import io.swagger.annotations.ApiParam;\n+import org.apache.pinot.thirdeye.anomaly.task.TaskConstants;\n+import org.apache.pinot.thirdeye.api.Constants;\n+import org.apache.pinot.thirdeye.api.user.dashboard.UserDashboardResource;\n+import org.apache.pinot.thirdeye.auth.ThirdEyePrincipal;\n+import org.apache.pinot.thirdeye.common.metric.MetricType;\n+import org.apache.pinot.thirdeye.constant.MetricAggFunction;\n+import org.apache.pinot.thirdeye.dashboard.resources.v2.pojo.AnomalySummary;\n+import org.apache.pinot.thirdeye.datalayer.bao.*;\n+import org.apache.pinot.thirdeye.datalayer.dto.DatasetConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.DetectionConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.MetricConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.TaskDTO;\n+import org.apache.pinot.thirdeye.datalayer.util.Predicate;\n+import org.apache.pinot.thirdeye.datasource.DAORegistry;\n+import org.apache.pinot.thirdeye.datasource.ThirdEyeCacheRegistry;\n+import org.apache.pinot.thirdeye.datasource.loader.AggregationLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.DefaultAggregationLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.DefaultTimeSeriesLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.TimeSeriesLoader;\n+import org.apache.pinot.thirdeye.detection.*;\n+import org.apache.pinot.thirdeye.detection.cache.builder.AnomaliesCacheBuilder;\n+import org.apache.pinot.thirdeye.detection.cache.builder.TimeSeriesCacheBuilder;\n+import org.apache.pinot.thirdeye.detection.validators.DatasetConfigValidator;\n+import org.apache.pinot.thirdeye.detection.validators.DetectionConfigValidator;\n+import org.apache.pinot.thirdeye.detection.validators.MetricConfigValidator;\n+import org.apache.pinot.thirdeye.detection.yaml.DetectionConfigTuner;\n+import org.apache.pinot.thirdeye.detection.yaml.translator.DetectionConfigTranslator;\n+import org.apache.pinot.thirdeye.util.ThirdEyeUtils;\n+import org.jfree.util.Log;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.yaml.snakeyaml.Yaml;\n+import javax.ws.rs.*;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import javax.ws.rs.core.UriBuilder;\n+import java.util.*;\n+import java.util.concurrent.TimeUnit;\n+\n+@Path(\"/anomaly-detection\")\n+@Api(tags = { Constants.DETECTION_TAG })\n+public class AnomalyDetectionResource {\n+  protected static final Logger LOG = LoggerFactory.getLogger(AnomalyDetectionResource.class);\n+\n+  private static final String TEMPLATE_DETECTION_PATH = \"detection-config-template.yml\";\n+\n+  /* -------- Detection config fields -------- */\n+  private static final String DETECTION_YAML_FIELD = \"detectionName\";\n+  private static final String DEFAULT_DETECTION_NAME = \"online_detection\";\n+\n+  /* -------- Metric config fields -------- */\n+  private static final String DATASET_YAML_FIELD = \"dataset\";\n+  private static final String DEFAULT_DATASET_NAME = \"online_dataset\";\n+  private static final String DATATYPE_YAML_FIELD = \"datatype\";\n+  private static final MetricType DEFAULT_DATA_TYPE = MetricType.DOUBLE;\n+\n+  /* -------- Dataset config fields -------- */\n+  private static final String METRIC_YAML_FIELD = \"metric\";\n+  private static final String DEFAULT_METRIC_NAME = \"online_metric\";\n+  private static final String DEFAULT_METRIC_COLUMN = \"metric\";\n+  private static final String TIME_COLUMN_YAML_FIELD = \"timeColumn\";\n+  private static final String DEFAULT_TIME_COLUMN = \"date\";\n+  private static final String TIME_UNIT_YAML_FIELD = \"timeUnit\";\n+  private static final TimeUnit DEFAULT_TIME_UNIT = TimeUnit.DAYS;\n+  private static final String TIME_DURATION_YAML_FIELD = \"timeDuration\";\n+  private static final String TIME_FORMAT_YAML_FIELD = \"timeFormat\";\n+  private static final String DEFAULT_TIME_FORMAT = \"SIMPLE_DATE_FORMAT:yyyyMMdd\";\n+  private static final String TIME_ZONE_YAML_FIELD = \"timezone\";\n+  private static final String DEFAULT_TIME_ZONE = \"US/Pacific\";\n+  private static final List<String> DEFAULT_DIMENSIONS =\n+      Collections.unmodifiableList(new ArrayList<>());\n+\n+  /* -------- Request/Response field -------- */\n+  private static final String DATA_FIELD = \"data\";\n+  private static final String COLUMNS_FIELD = \"columns\";\n+  private static final String ROWS_FIELD = \"rows\";\n+  private static final String DATASET_FIELD = \"datasetConfiguration\";\n+  private static final String METRIC_FIELD = \"metricConfiguration\";\n+  private static final String DETECTION_FIELD = \"detectionConfiguration\";\n+  private static final String ANOMALIES_FIELD = \"anomalies\";\n+\n+  /* -------- Others -------- */\n+  private static final String ONLINE_DATASOURCE = \"OnlineThirdEyeDataSource\";\n+  private static final String DETECTION_MYSQL_NAME_COLUMN = \"name\";\n+  private static final String TASK_MYSQL_NAME_COLUMN = \"name\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6d91338441effdb3e94eface7664035757ae2e4d"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTQxMjI3NA==", "bodyText": "I think that we can put the failure stacktrace into the error message from taskDTO.", "url": "https://github.com/apache/pinot/pull/5769#discussion_r465412274", "createdAt": "2020-08-05T01:03:07Z", "author": {"login": "vincentchenjl"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/api/detection/AnomalyDetectionResource.java", "diffHunk": "@@ -0,0 +1,756 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.pinot.thirdeye.api.detection;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ArrayNode;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.fasterxml.jackson.databind.node.TextNode;\n+import io.dropwizard.auth.Auth;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import io.swagger.annotations.ApiParam;\n+import org.apache.pinot.thirdeye.anomaly.task.TaskConstants;\n+import org.apache.pinot.thirdeye.api.Constants;\n+import org.apache.pinot.thirdeye.api.user.dashboard.UserDashboardResource;\n+import org.apache.pinot.thirdeye.auth.ThirdEyePrincipal;\n+import org.apache.pinot.thirdeye.common.metric.MetricType;\n+import org.apache.pinot.thirdeye.constant.MetricAggFunction;\n+import org.apache.pinot.thirdeye.dashboard.resources.v2.pojo.AnomalySummary;\n+import org.apache.pinot.thirdeye.datalayer.bao.*;\n+import org.apache.pinot.thirdeye.datalayer.dto.DatasetConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.DetectionConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.MetricConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.TaskDTO;\n+import org.apache.pinot.thirdeye.datalayer.util.Predicate;\n+import org.apache.pinot.thirdeye.datasource.DAORegistry;\n+import org.apache.pinot.thirdeye.datasource.ThirdEyeCacheRegistry;\n+import org.apache.pinot.thirdeye.datasource.loader.AggregationLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.DefaultAggregationLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.DefaultTimeSeriesLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.TimeSeriesLoader;\n+import org.apache.pinot.thirdeye.detection.*;\n+import org.apache.pinot.thirdeye.detection.cache.builder.AnomaliesCacheBuilder;\n+import org.apache.pinot.thirdeye.detection.cache.builder.TimeSeriesCacheBuilder;\n+import org.apache.pinot.thirdeye.detection.validators.DatasetConfigValidator;\n+import org.apache.pinot.thirdeye.detection.validators.DetectionConfigValidator;\n+import org.apache.pinot.thirdeye.detection.validators.MetricConfigValidator;\n+import org.apache.pinot.thirdeye.detection.yaml.DetectionConfigTuner;\n+import org.apache.pinot.thirdeye.detection.yaml.translator.DetectionConfigTranslator;\n+import org.apache.pinot.thirdeye.util.ThirdEyeUtils;\n+import org.jfree.util.Log;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.yaml.snakeyaml.Yaml;\n+import javax.ws.rs.*;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import javax.ws.rs.core.UriBuilder;\n+import java.util.*;\n+import java.util.concurrent.TimeUnit;\n+\n+@Path(\"/anomaly-detection\")\n+@Api(tags = { Constants.DETECTION_TAG })\n+public class AnomalyDetectionResource {\n+  protected static final Logger LOG = LoggerFactory.getLogger(AnomalyDetectionResource.class);\n+\n+  private static final String TEMPLATE_DETECTION_PATH = \"detection-config-template.yml\";\n+\n+  /* -------- Detection config fields -------- */\n+  private static final String DETECTION_YAML_FIELD = \"detectionName\";\n+  private static final String DEFAULT_DETECTION_NAME = \"online_detection\";\n+\n+  /* -------- Metric config fields -------- */\n+  private static final String DATASET_YAML_FIELD = \"dataset\";\n+  private static final String DEFAULT_DATASET_NAME = \"online_dataset\";\n+  private static final String DATATYPE_YAML_FIELD = \"datatype\";\n+  private static final MetricType DEFAULT_DATA_TYPE = MetricType.DOUBLE;\n+\n+  /* -------- Dataset config fields -------- */\n+  private static final String METRIC_YAML_FIELD = \"metric\";\n+  private static final String DEFAULT_METRIC_NAME = \"online_metric\";\n+  private static final String DEFAULT_METRIC_COLUMN = \"metric\";\n+  private static final String TIME_COLUMN_YAML_FIELD = \"timeColumn\";\n+  private static final String DEFAULT_TIME_COLUMN = \"date\";\n+  private static final String TIME_UNIT_YAML_FIELD = \"timeUnit\";\n+  private static final TimeUnit DEFAULT_TIME_UNIT = TimeUnit.DAYS;\n+  private static final String TIME_DURATION_YAML_FIELD = \"timeDuration\";\n+  private static final String TIME_FORMAT_YAML_FIELD = \"timeFormat\";\n+  private static final String DEFAULT_TIME_FORMAT = \"SIMPLE_DATE_FORMAT:yyyyMMdd\";\n+  private static final String TIME_ZONE_YAML_FIELD = \"timezone\";\n+  private static final String DEFAULT_TIME_ZONE = \"US/Pacific\";\n+  private static final List<String> DEFAULT_DIMENSIONS =\n+      Collections.unmodifiableList(new ArrayList<>());\n+\n+  /* -------- Request/Response field -------- */\n+  private static final String DATA_FIELD = \"data\";\n+  private static final String COLUMNS_FIELD = \"columns\";\n+  private static final String ROWS_FIELD = \"rows\";\n+  private static final String DATASET_FIELD = \"datasetConfiguration\";\n+  private static final String METRIC_FIELD = \"metricConfiguration\";\n+  private static final String DETECTION_FIELD = \"detectionConfiguration\";\n+  private static final String ANOMALIES_FIELD = \"anomalies\";\n+\n+  /* -------- Others -------- */\n+  private static final String ONLINE_DATASOURCE = \"OnlineThirdEyeDataSource\";\n+  private static final String DETECTION_MYSQL_NAME_COLUMN = \"name\";\n+  private static final String TASK_MYSQL_NAME_COLUMN = \"name\";\n+  private static final String ANOMALY_ENDPOINT_URL = \"/userdashboard/anomalies\";\n+  private static final long POLLING_SLEEP_TIME = 5L;\n+  private static final int DEFAULT_TIME_DURATION = 1;\n+  private static final long MAX_ONLINE_PAYLOAD_SIZE = 10 * 1024 * 1024L;\n+\n+  private final UserDashboardResource userDashboardResource;\n+  private final DetectionConfigManager detectionConfigDAO;\n+  private final DataProvider provider;\n+  private final MetricConfigManager metricConfigDAO;\n+  private final DatasetConfigManager datasetConfigDAO;\n+  private final EventManager eventDAO;\n+  private final MergedAnomalyResultManager anomalyDAO;\n+  private final EvaluationManager evaluationDAO;\n+  private final TaskManager taskDAO;\n+  private final DetectionPipelineLoader loader;\n+  private final DetectionConfigValidator detectionValidator;\n+  private final DatasetConfigValidator datasetConfigValidator;\n+  private final MetricConfigValidator metricConfigValidator;\n+  private final ObjectMapper objectMapper = new ObjectMapper();\n+  private final Yaml yaml;\n+\n+  public AnomalyDetectionResource(UserDashboardResource userDashboardResource) {\n+    this.detectionConfigDAO = DAORegistry.getInstance().getDetectionConfigManager();\n+    this.metricConfigDAO = DAORegistry.getInstance().getMetricConfigDAO();\n+    this.datasetConfigDAO = DAORegistry.getInstance().getDatasetConfigDAO();\n+    this.eventDAO = DAORegistry.getInstance().getEventDAO();\n+    this.anomalyDAO = DAORegistry.getInstance().getMergedAnomalyResultDAO();\n+    this.taskDAO = DAORegistry.getInstance().getTaskDAO();\n+    this.evaluationDAO = DAORegistry.getInstance().getEvaluationManager();\n+    this.userDashboardResource = userDashboardResource;\n+\n+    TimeSeriesLoader timeseriesLoader =\n+        new DefaultTimeSeriesLoader(metricConfigDAO, datasetConfigDAO,\n+            ThirdEyeCacheRegistry.getInstance().getQueryCache(),\n+            ThirdEyeCacheRegistry.getInstance().getTimeSeriesCache());\n+\n+    AggregationLoader aggregationLoader =\n+        new DefaultAggregationLoader(metricConfigDAO, datasetConfigDAO,\n+            ThirdEyeCacheRegistry.getInstance().getQueryCache(),\n+            ThirdEyeCacheRegistry.getInstance().getDatasetMaxDataTimeCache());\n+\n+    this.loader = new DetectionPipelineLoader();\n+\n+    this.provider = new DefaultDataProvider(metricConfigDAO, datasetConfigDAO, eventDAO, anomalyDAO,\n+        evaluationDAO, timeseriesLoader, aggregationLoader, loader,\n+        TimeSeriesCacheBuilder.getInstance(), AnomaliesCacheBuilder.getInstance());\n+    this.detectionValidator = new DetectionConfigValidator(this.provider);\n+    this.metricConfigValidator = new MetricConfigValidator();\n+    this.datasetConfigValidator = new DatasetConfigValidator();\n+\n+    // Read template from disk\n+    this.yaml = new Yaml();\n+  }\n+\n+  /**\n+   * Run an online anomaly detection service synchronously. It will run anomaly detection using\n+   * default configs for detection, metric, dataset\n+   *\n+   * @param start     detection window start time\n+   * @param end       detection window end time\n+   * @param payload   payload in request including online data\n+   * @param principal user who sent this request. It's used to separate different config names\n+   * @return a message containing the detected anomalies and the detection config used\n+   */\n+  @POST\n+  @Path(\"/\")\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @Consumes(MediaType.APPLICATION_JSON)\n+  @ApiOperation(\"Request an anomaly detection online task\")\n+  public Response onlineApi(\n+          @QueryParam(\"start\") long start,\n+          @QueryParam(\"end\") long end,\n+          @ApiParam(\"jsonPayload\") String payload,\n+          @Auth ThirdEyePrincipal principal) {\n+    DatasetConfigDTO datasetConfigDTO = null;\n+    MetricConfigDTO metricConfigDTO = null;\n+    DetectionConfigDTO detectionConfigDTO = null;\n+    TaskDTO taskDTO = null;\n+    List<AnomalySummary> anomalies = null;\n+    Response.Status responseStatus;\n+    Map<String, String> responseMessage = new HashMap<>();\n+    ObjectMapper objectMapper = new ObjectMapper();\n+    // Use username to separate different requests. One user can only send one request at a time\n+    String nameSuffix = \"_\" + principal.getName();\n+\n+    try {\n+      if (payload.getBytes().length > MAX_ONLINE_PAYLOAD_SIZE) {\n+        responseStatus = Response.Status.BAD_REQUEST;\n+        responseMessage.put(\"message\", \"Payload too large\");\n+        return Response.status(responseStatus).entity(responseMessage).build();\n+      }\n+\n+      JsonNode payloadNode = objectMapper.readTree(payload);\n+\n+      if (!validateOnlineRequestPayload(payloadNode)) {\n+        responseStatus = Response.Status.BAD_REQUEST;\n+        responseMessage.put(\"message\", \"Invalid request payload\");\n+        return Response.status(responseStatus).entity(responseMessage).build();\n+      }\n+\n+      // Preprocess: remove existing entities generated by the previous interrupted request\n+      cleanExistingOnlineTask(nameSuffix);\n+\n+      // Create & save dataset\n+      datasetConfigDTO = generateDatasetConfig(payloadNode, nameSuffix);\n+\n+      // Create & save metric along with online data\n+      metricConfigDTO = generateMetricConfig(payloadNode, nameSuffix);\n+\n+      // Create & save detection\n+      detectionConfigDTO =\n+          generateDetectionConfig(payloadNode, nameSuffix, datasetConfigDTO, metricConfigDTO, start,\n+              end);\n+\n+      // Create & save task\n+      taskDTO = generateTaskConfig(detectionConfigDTO.getId(), start, end);\n+\n+      // Polling task status\n+      TaskDTO polledTaskDTO = pollingTask(taskDTO.getId());\n+\n+      // Task failure\n+      if (polledTaskDTO.getStatus() != TaskConstants.TaskStatus.COMPLETED) {\n+        LOG.warn(\"Task is not completed after polling: \" + polledTaskDTO);\n+\n+        responseStatus = Response.Status.INTERNAL_SERVER_ERROR;\n+\n+        switch (polledTaskDTO.getStatus()) {\n+        case FAILED:\n+          responseStatus = Response.Status.INTERNAL_SERVER_ERROR;\n+          responseMessage.put(\"message\", \"Failed to execute anomaly detection task.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6d91338441effdb3e94eface7664035757ae2e4d"}, "originalPosition": 246}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjAxMDkwMQ==", "bodyText": "Can we have more specific name for this class, something like OnlineMetricConfigValidator? Also, can we do more validation, such as checking the metric column specified actually exists in the dataset?", "url": "https://github.com/apache/pinot/pull/5769#discussion_r466010901", "createdAt": "2020-08-05T21:20:27Z", "author": {"login": "vincentchenjl"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/validators/MetricConfigValidator.java", "diffHunk": "@@ -0,0 +1,44 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.pinot.thirdeye.detection.validators;\n+\n+import java.util.Map;\n+\n+import com.google.common.base.Preconditions;\n+import org.apache.pinot.thirdeye.datalayer.dto.MetricConfigDTO;\n+\n+public class MetricConfigValidator implements ConfigValidator<MetricConfigDTO> {\n+  private static final String DEFAULT_METRIC_NAME = \"online_metric\";\n+\n+  @Override\n+  public void validateConfig(MetricConfigDTO config) throws IllegalArgumentException {\n+    Preconditions.checkArgument(config.getName().startsWith(DEFAULT_METRIC_NAME));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6d91338441effdb3e94eface7664035757ae2e4d"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjAxMTM1NA==", "bodyText": "Can we have more specific name for this class, something like OnlineDatasetConfigValidator?", "url": "https://github.com/apache/pinot/pull/5769#discussion_r466011354", "createdAt": "2020-08-05T21:21:26Z", "author": {"login": "vincentchenjl"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/validators/DatasetConfigValidator.java", "diffHunk": "@@ -0,0 +1,44 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.pinot.thirdeye.detection.validators;\n+\n+import java.util.Map;\n+\n+import com.google.common.base.Preconditions;\n+import org.apache.pinot.thirdeye.datalayer.dto.DatasetConfigDTO;\n+\n+public class DatasetConfigValidator implements ConfigValidator<DatasetConfigDTO> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6d91338441effdb3e94eface7664035757ae2e4d"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjAxMjgzNQ==", "bodyText": "Why do we want to check this prefix? It looks like that this prefix is added by our code and it is guaranteed to happen, right? If we just need to validate the prefix, we should remove this class.", "url": "https://github.com/apache/pinot/pull/5769#discussion_r466012835", "createdAt": "2020-08-05T21:24:37Z", "author": {"login": "vincentchenjl"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/detection/validators/DatasetConfigValidator.java", "diffHunk": "@@ -0,0 +1,44 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.pinot.thirdeye.detection.validators;\n+\n+import java.util.Map;\n+\n+import com.google.common.base.Preconditions;\n+import org.apache.pinot.thirdeye.datalayer.dto.DatasetConfigDTO;\n+\n+public class DatasetConfigValidator implements ConfigValidator<DatasetConfigDTO> {\n+  private static final String DEFAULT_DATASET_NAME = \"online_dataset\";\n+\n+  @Override\n+  public void validateConfig(DatasetConfigDTO config) throws IllegalArgumentException {\n+    Preconditions.checkArgument(config.getName().startsWith(DEFAULT_DATASET_NAME));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6d91338441effdb3e94eface7664035757ae2e4d"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjAxOTg1OA==", "bodyText": "I agree with Jihao. Having separate CRUD is much easier for users to use the ad-hoc detection. We can set up some cleanup mechanism that clean up any online dataset/metric that is not used for certain period, 14 days for instance.", "url": "https://github.com/apache/pinot/pull/5769#discussion_r466019858", "createdAt": "2020-08-05T21:39:54Z", "author": {"login": "vincentchenjl"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/api/detection/AnomalyDetectionResource.java", "diffHunk": "@@ -0,0 +1,756 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.pinot.thirdeye.api.detection;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ArrayNode;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.fasterxml.jackson.databind.node.TextNode;\n+import io.dropwizard.auth.Auth;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import io.swagger.annotations.ApiParam;\n+import org.apache.pinot.thirdeye.anomaly.task.TaskConstants;\n+import org.apache.pinot.thirdeye.api.Constants;\n+import org.apache.pinot.thirdeye.api.user.dashboard.UserDashboardResource;\n+import org.apache.pinot.thirdeye.auth.ThirdEyePrincipal;\n+import org.apache.pinot.thirdeye.common.metric.MetricType;\n+import org.apache.pinot.thirdeye.constant.MetricAggFunction;\n+import org.apache.pinot.thirdeye.dashboard.resources.v2.pojo.AnomalySummary;\n+import org.apache.pinot.thirdeye.datalayer.bao.*;\n+import org.apache.pinot.thirdeye.datalayer.dto.DatasetConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.DetectionConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.MetricConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.TaskDTO;\n+import org.apache.pinot.thirdeye.datalayer.util.Predicate;\n+import org.apache.pinot.thirdeye.datasource.DAORegistry;\n+import org.apache.pinot.thirdeye.datasource.ThirdEyeCacheRegistry;\n+import org.apache.pinot.thirdeye.datasource.loader.AggregationLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.DefaultAggregationLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.DefaultTimeSeriesLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.TimeSeriesLoader;\n+import org.apache.pinot.thirdeye.detection.*;\n+import org.apache.pinot.thirdeye.detection.cache.builder.AnomaliesCacheBuilder;\n+import org.apache.pinot.thirdeye.detection.cache.builder.TimeSeriesCacheBuilder;\n+import org.apache.pinot.thirdeye.detection.validators.DatasetConfigValidator;\n+import org.apache.pinot.thirdeye.detection.validators.DetectionConfigValidator;\n+import org.apache.pinot.thirdeye.detection.validators.MetricConfigValidator;\n+import org.apache.pinot.thirdeye.detection.yaml.DetectionConfigTuner;\n+import org.apache.pinot.thirdeye.detection.yaml.translator.DetectionConfigTranslator;\n+import org.apache.pinot.thirdeye.util.ThirdEyeUtils;\n+import org.jfree.util.Log;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.yaml.snakeyaml.Yaml;\n+import javax.ws.rs.*;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import javax.ws.rs.core.UriBuilder;\n+import java.util.*;\n+import java.util.concurrent.TimeUnit;\n+\n+@Path(\"/anomaly-detection\")\n+@Api(tags = { Constants.DETECTION_TAG })\n+public class AnomalyDetectionResource {\n+  protected static final Logger LOG = LoggerFactory.getLogger(AnomalyDetectionResource.class);\n+\n+  private static final String TEMPLATE_DETECTION_PATH = \"detection-config-template.yml\";\n+\n+  /* -------- Detection config fields -------- */\n+  private static final String DETECTION_YAML_FIELD = \"detectionName\";\n+  private static final String DEFAULT_DETECTION_NAME = \"online_detection\";\n+\n+  /* -------- Metric config fields -------- */\n+  private static final String DATASET_YAML_FIELD = \"dataset\";\n+  private static final String DEFAULT_DATASET_NAME = \"online_dataset\";\n+  private static final String DATATYPE_YAML_FIELD = \"datatype\";\n+  private static final MetricType DEFAULT_DATA_TYPE = MetricType.DOUBLE;\n+\n+  /* -------- Dataset config fields -------- */\n+  private static final String METRIC_YAML_FIELD = \"metric\";\n+  private static final String DEFAULT_METRIC_NAME = \"online_metric\";\n+  private static final String DEFAULT_METRIC_COLUMN = \"metric\";\n+  private static final String TIME_COLUMN_YAML_FIELD = \"timeColumn\";\n+  private static final String DEFAULT_TIME_COLUMN = \"date\";\n+  private static final String TIME_UNIT_YAML_FIELD = \"timeUnit\";\n+  private static final TimeUnit DEFAULT_TIME_UNIT = TimeUnit.DAYS;\n+  private static final String TIME_DURATION_YAML_FIELD = \"timeDuration\";\n+  private static final String TIME_FORMAT_YAML_FIELD = \"timeFormat\";\n+  private static final String DEFAULT_TIME_FORMAT = \"SIMPLE_DATE_FORMAT:yyyyMMdd\";\n+  private static final String TIME_ZONE_YAML_FIELD = \"timezone\";\n+  private static final String DEFAULT_TIME_ZONE = \"US/Pacific\";\n+  private static final List<String> DEFAULT_DIMENSIONS =\n+      Collections.unmodifiableList(new ArrayList<>());\n+\n+  /* -------- Request/Response field -------- */\n+  private static final String DATA_FIELD = \"data\";\n+  private static final String COLUMNS_FIELD = \"columns\";\n+  private static final String ROWS_FIELD = \"rows\";\n+  private static final String DATASET_FIELD = \"datasetConfiguration\";\n+  private static final String METRIC_FIELD = \"metricConfiguration\";\n+  private static final String DETECTION_FIELD = \"detectionConfiguration\";\n+  private static final String ANOMALIES_FIELD = \"anomalies\";\n+\n+  /* -------- Others -------- */\n+  private static final String ONLINE_DATASOURCE = \"OnlineThirdEyeDataSource\";\n+  private static final String DETECTION_MYSQL_NAME_COLUMN = \"name\";\n+  private static final String TASK_MYSQL_NAME_COLUMN = \"name\";\n+  private static final String ANOMALY_ENDPOINT_URL = \"/userdashboard/anomalies\";\n+  private static final long POLLING_SLEEP_TIME = 5L;\n+  private static final int DEFAULT_TIME_DURATION = 1;\n+  private static final long MAX_ONLINE_PAYLOAD_SIZE = 10 * 1024 * 1024L;\n+\n+  private final UserDashboardResource userDashboardResource;\n+  private final DetectionConfigManager detectionConfigDAO;\n+  private final DataProvider provider;\n+  private final MetricConfigManager metricConfigDAO;\n+  private final DatasetConfigManager datasetConfigDAO;\n+  private final EventManager eventDAO;\n+  private final MergedAnomalyResultManager anomalyDAO;\n+  private final EvaluationManager evaluationDAO;\n+  private final TaskManager taskDAO;\n+  private final DetectionPipelineLoader loader;\n+  private final DetectionConfigValidator detectionValidator;\n+  private final DatasetConfigValidator datasetConfigValidator;\n+  private final MetricConfigValidator metricConfigValidator;\n+  private final ObjectMapper objectMapper = new ObjectMapper();\n+  private final Yaml yaml;\n+\n+  public AnomalyDetectionResource(UserDashboardResource userDashboardResource) {\n+    this.detectionConfigDAO = DAORegistry.getInstance().getDetectionConfigManager();\n+    this.metricConfigDAO = DAORegistry.getInstance().getMetricConfigDAO();\n+    this.datasetConfigDAO = DAORegistry.getInstance().getDatasetConfigDAO();\n+    this.eventDAO = DAORegistry.getInstance().getEventDAO();\n+    this.anomalyDAO = DAORegistry.getInstance().getMergedAnomalyResultDAO();\n+    this.taskDAO = DAORegistry.getInstance().getTaskDAO();\n+    this.evaluationDAO = DAORegistry.getInstance().getEvaluationManager();\n+    this.userDashboardResource = userDashboardResource;\n+\n+    TimeSeriesLoader timeseriesLoader =\n+        new DefaultTimeSeriesLoader(metricConfigDAO, datasetConfigDAO,\n+            ThirdEyeCacheRegistry.getInstance().getQueryCache(),\n+            ThirdEyeCacheRegistry.getInstance().getTimeSeriesCache());\n+\n+    AggregationLoader aggregationLoader =\n+        new DefaultAggregationLoader(metricConfigDAO, datasetConfigDAO,\n+            ThirdEyeCacheRegistry.getInstance().getQueryCache(),\n+            ThirdEyeCacheRegistry.getInstance().getDatasetMaxDataTimeCache());\n+\n+    this.loader = new DetectionPipelineLoader();\n+\n+    this.provider = new DefaultDataProvider(metricConfigDAO, datasetConfigDAO, eventDAO, anomalyDAO,\n+        evaluationDAO, timeseriesLoader, aggregationLoader, loader,\n+        TimeSeriesCacheBuilder.getInstance(), AnomaliesCacheBuilder.getInstance());\n+    this.detectionValidator = new DetectionConfigValidator(this.provider);\n+    this.metricConfigValidator = new MetricConfigValidator();\n+    this.datasetConfigValidator = new DatasetConfigValidator();\n+\n+    // Read template from disk\n+    this.yaml = new Yaml();\n+  }\n+\n+  /**\n+   * Run an online anomaly detection service synchronously. It will run anomaly detection using\n+   * default configs for detection, metric, dataset\n+   *\n+   * @param start     detection window start time\n+   * @param end       detection window end time\n+   * @param payload   payload in request including online data\n+   * @param principal user who sent this request. It's used to separate different config names\n+   * @return a message containing the detected anomalies and the detection config used\n+   */\n+  @POST\n+  @Path(\"/\")\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @Consumes(MediaType.APPLICATION_JSON)\n+  @ApiOperation(\"Request an anomaly detection online task\")\n+  public Response onlineApi(\n+          @QueryParam(\"start\") long start,\n+          @QueryParam(\"end\") long end,\n+          @ApiParam(\"jsonPayload\") String payload,\n+          @Auth ThirdEyePrincipal principal) {\n+    DatasetConfigDTO datasetConfigDTO = null;\n+    MetricConfigDTO metricConfigDTO = null;\n+    DetectionConfigDTO detectionConfigDTO = null;\n+    TaskDTO taskDTO = null;\n+    List<AnomalySummary> anomalies = null;\n+    Response.Status responseStatus;\n+    Map<String, String> responseMessage = new HashMap<>();\n+    ObjectMapper objectMapper = new ObjectMapper();\n+    // Use username to separate different requests. One user can only send one request at a time\n+    String nameSuffix = \"_\" + principal.getName();\n+\n+    try {\n+      if (payload.getBytes().length > MAX_ONLINE_PAYLOAD_SIZE) {\n+        responseStatus = Response.Status.BAD_REQUEST;\n+        responseMessage.put(\"message\", \"Payload too large\");\n+        return Response.status(responseStatus).entity(responseMessage).build();\n+      }\n+\n+      JsonNode payloadNode = objectMapper.readTree(payload);\n+\n+      if (!validateOnlineRequestPayload(payloadNode)) {\n+        responseStatus = Response.Status.BAD_REQUEST;\n+        responseMessage.put(\"message\", \"Invalid request payload\");\n+        return Response.status(responseStatus).entity(responseMessage).build();\n+      }\n+\n+      // Preprocess: remove existing entities generated by the previous interrupted request\n+      cleanExistingOnlineTask(nameSuffix);\n+\n+      // Create & save dataset\n+      datasetConfigDTO = generateDatasetConfig(payloadNode, nameSuffix);\n+\n+      // Create & save metric along with online data\n+      metricConfigDTO = generateMetricConfig(payloadNode, nameSuffix);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzMxNDcyNg=="}, "originalCommit": {"oid": "6d91338441effdb3e94eface7664035757ae2e4d"}, "originalPosition": 224}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjAyNTU5MQ==", "bodyText": "What about attaching the failure stacktrace here rather than just a generic error message, since the error might help users to debug their configurations.", "url": "https://github.com/apache/pinot/pull/5769#discussion_r466025591", "createdAt": "2020-08-05T21:53:07Z", "author": {"login": "vincentchenjl"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/api/detection/AnomalyDetectionResource.java", "diffHunk": "@@ -0,0 +1,756 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.pinot.thirdeye.api.detection;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.node.ArrayNode;\n+import com.fasterxml.jackson.databind.node.ObjectNode;\n+import com.fasterxml.jackson.databind.node.TextNode;\n+import io.dropwizard.auth.Auth;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import io.swagger.annotations.ApiParam;\n+import org.apache.pinot.thirdeye.anomaly.task.TaskConstants;\n+import org.apache.pinot.thirdeye.api.Constants;\n+import org.apache.pinot.thirdeye.api.user.dashboard.UserDashboardResource;\n+import org.apache.pinot.thirdeye.auth.ThirdEyePrincipal;\n+import org.apache.pinot.thirdeye.common.metric.MetricType;\n+import org.apache.pinot.thirdeye.constant.MetricAggFunction;\n+import org.apache.pinot.thirdeye.dashboard.resources.v2.pojo.AnomalySummary;\n+import org.apache.pinot.thirdeye.datalayer.bao.*;\n+import org.apache.pinot.thirdeye.datalayer.dto.DatasetConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.DetectionConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.MetricConfigDTO;\n+import org.apache.pinot.thirdeye.datalayer.dto.TaskDTO;\n+import org.apache.pinot.thirdeye.datalayer.util.Predicate;\n+import org.apache.pinot.thirdeye.datasource.DAORegistry;\n+import org.apache.pinot.thirdeye.datasource.ThirdEyeCacheRegistry;\n+import org.apache.pinot.thirdeye.datasource.loader.AggregationLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.DefaultAggregationLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.DefaultTimeSeriesLoader;\n+import org.apache.pinot.thirdeye.datasource.loader.TimeSeriesLoader;\n+import org.apache.pinot.thirdeye.detection.*;\n+import org.apache.pinot.thirdeye.detection.cache.builder.AnomaliesCacheBuilder;\n+import org.apache.pinot.thirdeye.detection.cache.builder.TimeSeriesCacheBuilder;\n+import org.apache.pinot.thirdeye.detection.validators.DatasetConfigValidator;\n+import org.apache.pinot.thirdeye.detection.validators.DetectionConfigValidator;\n+import org.apache.pinot.thirdeye.detection.validators.MetricConfigValidator;\n+import org.apache.pinot.thirdeye.detection.yaml.DetectionConfigTuner;\n+import org.apache.pinot.thirdeye.detection.yaml.translator.DetectionConfigTranslator;\n+import org.apache.pinot.thirdeye.util.ThirdEyeUtils;\n+import org.jfree.util.Log;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.yaml.snakeyaml.Yaml;\n+import javax.ws.rs.*;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import javax.ws.rs.core.UriBuilder;\n+import java.util.*;\n+import java.util.concurrent.TimeUnit;\n+\n+@Path(\"/anomaly-detection\")\n+@Api(tags = { Constants.DETECTION_TAG })\n+public class AnomalyDetectionResource {\n+  protected static final Logger LOG = LoggerFactory.getLogger(AnomalyDetectionResource.class);\n+\n+  private static final String TEMPLATE_DETECTION_PATH = \"detection-config-template.yml\";\n+\n+  /* -------- Detection config fields -------- */\n+  private static final String DETECTION_YAML_FIELD = \"detectionName\";\n+  private static final String DEFAULT_DETECTION_NAME = \"online_detection\";\n+\n+  /* -------- Metric config fields -------- */\n+  private static final String DATASET_YAML_FIELD = \"dataset\";\n+  private static final String DEFAULT_DATASET_NAME = \"online_dataset\";\n+  private static final String DATATYPE_YAML_FIELD = \"datatype\";\n+  private static final MetricType DEFAULT_DATA_TYPE = MetricType.DOUBLE;\n+\n+  /* -------- Dataset config fields -------- */\n+  private static final String METRIC_YAML_FIELD = \"metric\";\n+  private static final String DEFAULT_METRIC_NAME = \"online_metric\";\n+  private static final String DEFAULT_METRIC_COLUMN = \"metric\";\n+  private static final String TIME_COLUMN_YAML_FIELD = \"timeColumn\";\n+  private static final String DEFAULT_TIME_COLUMN = \"date\";\n+  private static final String TIME_UNIT_YAML_FIELD = \"timeUnit\";\n+  private static final TimeUnit DEFAULT_TIME_UNIT = TimeUnit.DAYS;\n+  private static final String TIME_DURATION_YAML_FIELD = \"timeDuration\";\n+  private static final String TIME_FORMAT_YAML_FIELD = \"timeFormat\";\n+  private static final String DEFAULT_TIME_FORMAT = \"SIMPLE_DATE_FORMAT:yyyyMMdd\";\n+  private static final String TIME_ZONE_YAML_FIELD = \"timezone\";\n+  private static final String DEFAULT_TIME_ZONE = \"US/Pacific\";\n+  private static final List<String> DEFAULT_DIMENSIONS =\n+      Collections.unmodifiableList(new ArrayList<>());\n+\n+  /* -------- Request/Response field -------- */\n+  private static final String DATA_FIELD = \"data\";\n+  private static final String COLUMNS_FIELD = \"columns\";\n+  private static final String ROWS_FIELD = \"rows\";\n+  private static final String DATASET_FIELD = \"datasetConfiguration\";\n+  private static final String METRIC_FIELD = \"metricConfiguration\";\n+  private static final String DETECTION_FIELD = \"detectionConfiguration\";\n+  private static final String ANOMALIES_FIELD = \"anomalies\";\n+\n+  /* -------- Others -------- */\n+  private static final String ONLINE_DATASOURCE = \"OnlineThirdEyeDataSource\";\n+  private static final String DETECTION_MYSQL_NAME_COLUMN = \"name\";\n+  private static final String TASK_MYSQL_NAME_COLUMN = \"name\";\n+  private static final String ANOMALY_ENDPOINT_URL = \"/userdashboard/anomalies\";\n+  private static final long POLLING_SLEEP_TIME = 5L;\n+  private static final int DEFAULT_TIME_DURATION = 1;\n+  private static final long MAX_ONLINE_PAYLOAD_SIZE = 10 * 1024 * 1024L;\n+\n+  private final UserDashboardResource userDashboardResource;\n+  private final DetectionConfigManager detectionConfigDAO;\n+  private final DataProvider provider;\n+  private final MetricConfigManager metricConfigDAO;\n+  private final DatasetConfigManager datasetConfigDAO;\n+  private final EventManager eventDAO;\n+  private final MergedAnomalyResultManager anomalyDAO;\n+  private final EvaluationManager evaluationDAO;\n+  private final TaskManager taskDAO;\n+  private final DetectionPipelineLoader loader;\n+  private final DetectionConfigValidator detectionValidator;\n+  private final DatasetConfigValidator datasetConfigValidator;\n+  private final MetricConfigValidator metricConfigValidator;\n+  private final ObjectMapper objectMapper = new ObjectMapper();\n+  private final Yaml yaml;\n+\n+  public AnomalyDetectionResource(UserDashboardResource userDashboardResource) {\n+    this.detectionConfigDAO = DAORegistry.getInstance().getDetectionConfigManager();\n+    this.metricConfigDAO = DAORegistry.getInstance().getMetricConfigDAO();\n+    this.datasetConfigDAO = DAORegistry.getInstance().getDatasetConfigDAO();\n+    this.eventDAO = DAORegistry.getInstance().getEventDAO();\n+    this.anomalyDAO = DAORegistry.getInstance().getMergedAnomalyResultDAO();\n+    this.taskDAO = DAORegistry.getInstance().getTaskDAO();\n+    this.evaluationDAO = DAORegistry.getInstance().getEvaluationManager();\n+    this.userDashboardResource = userDashboardResource;\n+\n+    TimeSeriesLoader timeseriesLoader =\n+        new DefaultTimeSeriesLoader(metricConfigDAO, datasetConfigDAO,\n+            ThirdEyeCacheRegistry.getInstance().getQueryCache(),\n+            ThirdEyeCacheRegistry.getInstance().getTimeSeriesCache());\n+\n+    AggregationLoader aggregationLoader =\n+        new DefaultAggregationLoader(metricConfigDAO, datasetConfigDAO,\n+            ThirdEyeCacheRegistry.getInstance().getQueryCache(),\n+            ThirdEyeCacheRegistry.getInstance().getDatasetMaxDataTimeCache());\n+\n+    this.loader = new DetectionPipelineLoader();\n+\n+    this.provider = new DefaultDataProvider(metricConfigDAO, datasetConfigDAO, eventDAO, anomalyDAO,\n+        evaluationDAO, timeseriesLoader, aggregationLoader, loader,\n+        TimeSeriesCacheBuilder.getInstance(), AnomaliesCacheBuilder.getInstance());\n+    this.detectionValidator = new DetectionConfigValidator(this.provider);\n+    this.metricConfigValidator = new MetricConfigValidator();\n+    this.datasetConfigValidator = new DatasetConfigValidator();\n+\n+    // Read template from disk\n+    this.yaml = new Yaml();\n+  }\n+\n+  /**\n+   * Run an online anomaly detection service synchronously. It will run anomaly detection using\n+   * default configs for detection, metric, dataset\n+   *\n+   * @param start     detection window start time\n+   * @param end       detection window end time\n+   * @param payload   payload in request including online data\n+   * @param principal user who sent this request. It's used to separate different config names\n+   * @return a message containing the detected anomalies and the detection config used\n+   */\n+  @POST\n+  @Path(\"/\")\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @Consumes(MediaType.APPLICATION_JSON)\n+  @ApiOperation(\"Request an anomaly detection online task\")\n+  public Response onlineApi(\n+          @QueryParam(\"start\") long start,\n+          @QueryParam(\"end\") long end,\n+          @ApiParam(\"jsonPayload\") String payload,\n+          @Auth ThirdEyePrincipal principal) {\n+    DatasetConfigDTO datasetConfigDTO = null;\n+    MetricConfigDTO metricConfigDTO = null;\n+    DetectionConfigDTO detectionConfigDTO = null;\n+    TaskDTO taskDTO = null;\n+    List<AnomalySummary> anomalies = null;\n+    Response.Status responseStatus;\n+    Map<String, String> responseMessage = new HashMap<>();\n+    ObjectMapper objectMapper = new ObjectMapper();\n+    // Use username to separate different requests. One user can only send one request at a time\n+    String nameSuffix = \"_\" + principal.getName();\n+\n+    try {\n+      if (payload.getBytes().length > MAX_ONLINE_PAYLOAD_SIZE) {\n+        responseStatus = Response.Status.BAD_REQUEST;\n+        responseMessage.put(\"message\", \"Payload too large\");\n+        return Response.status(responseStatus).entity(responseMessage).build();\n+      }\n+\n+      JsonNode payloadNode = objectMapper.readTree(payload);\n+\n+      if (!validateOnlineRequestPayload(payloadNode)) {\n+        responseStatus = Response.Status.BAD_REQUEST;\n+        responseMessage.put(\"message\", \"Invalid request payload\");\n+        return Response.status(responseStatus).entity(responseMessage).build();\n+      }\n+\n+      // Preprocess: remove existing entities generated by the previous interrupted request\n+      cleanExistingOnlineTask(nameSuffix);\n+\n+      // Create & save dataset\n+      datasetConfigDTO = generateDatasetConfig(payloadNode, nameSuffix);\n+\n+      // Create & save metric along with online data\n+      metricConfigDTO = generateMetricConfig(payloadNode, nameSuffix);\n+\n+      // Create & save detection\n+      detectionConfigDTO =\n+          generateDetectionConfig(payloadNode, nameSuffix, datasetConfigDTO, metricConfigDTO, start,\n+              end);\n+\n+      // Create & save task\n+      taskDTO = generateTaskConfig(detectionConfigDTO.getId(), start, end);\n+\n+      // Polling task status\n+      TaskDTO polledTaskDTO = pollingTask(taskDTO.getId());\n+\n+      // Task failure\n+      if (polledTaskDTO.getStatus() != TaskConstants.TaskStatus.COMPLETED) {\n+        LOG.warn(\"Task is not completed after polling: \" + polledTaskDTO);\n+\n+        responseStatus = Response.Status.INTERNAL_SERVER_ERROR;\n+\n+        switch (polledTaskDTO.getStatus()) {\n+        case FAILED:\n+          responseStatus = Response.Status.INTERNAL_SERVER_ERROR;\n+          responseMessage.put(\"message\", \"Failed to execute anomaly detection task.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6d91338441effdb3e94eface7664035757ae2e4d"}, "originalPosition": 246}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8b0382938e4edcbe9daa6c881a4e5e3a91a1d262", "author": {"user": {"login": "jasonyanwenl", "name": "Yanwen(Jason) Lin"}}, "url": "https://github.com/apache/pinot/commit/8b0382938e4edcbe9daa6c881a4e5e3a91a1d262", "committedDate": "2020-08-06T20:32:41Z", "message": "[TE] add anomaly detection as a service - Phase 1"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0f6fc6aa84f4c12efb2532fa8e1024556800da40", "author": {"user": {"login": "jasonyanwenl", "name": "Yanwen(Jason) Lin"}}, "url": "https://github.com/apache/pinot/commit/0f6fc6aa84f4c12efb2532fa8e1024556800da40", "committedDate": "2020-08-06T20:32:41Z", "message": "do not delete taskDTO as it will be cleaned periodically"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1460ea1194a72145262e7c7c1411a783ac944ab1", "author": {"user": {"login": "jasonyanwenl", "name": "Yanwen(Jason) Lin"}}, "url": "https://github.com/apache/pinot/commit/1460ea1194a72145262e7c7c1411a783ac944ab1", "committedDate": "2020-08-06T20:32:41Z", "message": "add timeout for polling task status"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1cda1caedde33c4e9ed4df57a97d8f36b46efce3", "author": {"user": {"login": "jasonyanwenl", "name": "Yanwen(Jason) Lin"}}, "url": "https://github.com/apache/pinot/commit/1cda1caedde33c4e9ed4df57a97d8f36b46efce3", "committedDate": "2020-08-06T20:32:41Z", "message": "Guice injection for anomaly detection resource"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3c5f97d2326d5d77b3c13203c1816e6c49da23fa", "author": {"user": {"login": "jasonyanwenl", "name": "Yanwen(Jason) Lin"}}, "url": "https://github.com/apache/pinot/commit/3c5f97d2326d5d77b3c13203c1816e6c49da23fa", "committedDate": "2020-08-06T20:32:41Z", "message": "save detection config in task info instead of DB"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9a9a2129e08c996f72a4ff91374d21002c5d15ce", "author": {"user": {"login": "jasonyanwenl", "name": "Yanwen(Jason) Lin"}}, "url": "https://github.com/apache/pinot/commit/9a9a2129e08c996f72a4ff91374d21002c5d15ce", "committedDate": "2020-08-06T20:32:41Z", "message": "rename online task name to DETECTION_ONLINE_<>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bb66eab7f7013b72b28dce4bc8a35038700aca8d", "author": {"user": {"login": "jasonyanwenl", "name": "Yanwen(Jason) Lin"}}, "url": "https://github.com/apache/pinot/commit/bb66eab7f7013b72b28dce4bc8a35038700aca8d", "committedDate": "2020-08-06T20:32:41Z", "message": "delete existing metric/dataset by predicate"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0d2eb05d29b3925fc797e90fdbf12ab34ec16dd2", "author": {"user": {"login": "jasonyanwenl", "name": "Yanwen(Jason) Lin"}}, "url": "https://github.com/apache/pinot/commit/0d2eb05d29b3925fc797e90fdbf12ab34ec16dd2", "committedDate": "2020-08-06T20:32:41Z", "message": "add DETECTION_ONLINE task type in exception message"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7e717eda793b22794f58377414ee46d8845cb4d0", "author": {"user": {"login": "jasonyanwenl", "name": "Yanwen(Jason) Lin"}}, "url": "https://github.com/apache/pinot/commit/7e717eda793b22794f58377414ee46d8845cb4d0", "committedDate": "2020-08-06T20:32:41Z", "message": "delete existing anomalies"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d1e951e687aac8a2529e5b7cbe64d1fa6dce8134", "author": {"user": {"login": "jasonyanwenl", "name": "Yanwen(Jason) Lin"}}, "url": "https://github.com/apache/pinot/commit/d1e951e687aac8a2529e5b7cbe64d1fa6dce8134", "committedDate": "2020-08-06T20:32:41Z", "message": "batch delete generated anomalies by metric/dataset name"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d94eb714b20153c53955a2cd05c5f5edb7bc461b", "author": {"user": {"login": "jasonyanwenl", "name": "Yanwen(Jason) Lin"}}, "url": "https://github.com/apache/pinot/commit/d94eb714b20153c53955a2cd05c5f5edb7bc461b", "committedDate": "2020-08-06T20:32:41Z", "message": "add uuid in config name suffix"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6d91338441effdb3e94eface7664035757ae2e4d", "author": {"user": {"login": "jasonyanwenl", "name": "Yanwen(Jason) Lin"}}, "url": "https://github.com/apache/pinot/commit/6d91338441effdb3e94eface7664035757ae2e4d", "committedDate": "2020-07-29T22:40:52Z", "message": "[TE] add anomaly detection as a service - Phase 1"}, "afterCommit": {"oid": "d94eb714b20153c53955a2cd05c5f5edb7bc461b", "author": {"user": {"login": "jasonyanwenl", "name": "Yanwen(Jason) Lin"}}, "url": "https://github.com/apache/pinot/commit/d94eb714b20153c53955a2cd05c5f5edb7bc461b", "committedDate": "2020-08-06T20:32:41Z", "message": "add uuid in config name suffix"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1591f7c71306870ac868d4ad48de83fce8d28311", "author": {"user": {"login": "jasonyanwenl", "name": "Yanwen(Jason) Lin"}}, "url": "https://github.com/apache/pinot/commit/1591f7c71306870ac868d4ad48de83fce8d28311", "committedDate": "2020-08-06T23:55:27Z", "message": "reduce class-level constant strings"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4d37ce053af3ada1921cea53fdfe6bb1c32c850d", "author": {"user": {"login": "jasonyanwenl", "name": "Yanwen(Jason) Lin"}}, "url": "https://github.com/apache/pinot/commit/4d37ce053af3ada1921cea53fdfe6bb1c32c850d", "committedDate": "2020-08-07T16:50:30Z", "message": "support customized metric/time column names; add column name consistency validation; remove dataset/metric validator;"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY1MzI4Nzk0", "url": "https://github.com/apache/pinot/pull/5769#pullrequestreview-465328794", "createdAt": "2020-08-11T18:37:32Z", "commit": {"oid": "4d37ce053af3ada1921cea53fdfe6bb1c32c850d"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY1MzMyNTM4", "url": "https://github.com/apache/pinot/pull/5769#pullrequestreview-465332538", "createdAt": "2020-08-11T18:40:45Z", "commit": {"oid": "4d37ce053af3ada1921cea53fdfe6bb1c32c850d"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY2MzQxNjE1", "url": "https://github.com/apache/pinot/pull/5769#pullrequestreview-466341615", "createdAt": "2020-08-12T23:24:37Z", "commit": {"oid": "4d37ce053af3ada1921cea53fdfe6bb1c32c850d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQyMzoyNDozOFrOG_2L1A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQyMzoyNDozOFrOG_2L1A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTYwMTIzNg==", "bodyText": "@jasonyanwenl Sorry we missed this one earlier. Will this making it only picking up the Detection task here? This could be a serious issue because it won't be picking up other tasks, for example, sending out the notification, run detection onboarding, etc. Could you double-check?\n@vincentchenjl @akshayrai FYI, we may need to hold on deployment to prod.\n@suvodeep-pyne thanks for reporting this", "url": "https://github.com/apache/pinot/pull/5769#discussion_r469601236", "createdAt": "2020-08-12T23:24:38Z", "author": {"login": "jihaozh"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/task/TaskDriver.java", "diffHunk": "@@ -183,8 +192,11 @@ private TaskDTO acquireTask() {\n       try {\n         // randomize fetching head and tail to reduce synchronized patterns across threads (and hosts)\n         boolean orderAscending = System.currentTimeMillis() % 2 == 0;\n+\n+        // find by task type to separate online task from a normal task\n+        TaskType type = this.isOnline ? TaskType.DETECTION_ONLINE : TaskType.DETECTION;\n         anomalyTasks = taskDAO\n-            .findByStatusOrderByCreateTime(TaskStatus.WAITING, driverConfiguration.getTaskFetchSizeCap(),\n+            .findByStatusAndTypeOrderByCreateTime(TaskStatus.WAITING, type, driverConfiguration.getTaskFetchSizeCap(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4d37ce053af3ada1921cea53fdfe6bb1c32c850d"}, "originalPosition": 59}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 493, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}