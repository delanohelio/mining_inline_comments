{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDc4NDI2MDQ0", "number": 5967, "title": "Adding push job type of segment metadata only mode", "bodyText": "Description\n\nAdd new FileUploadType METADATA\nAdd /segments/metadata endpoint to upload segment with METADATA only mode.\nAdd new pinot push job types: SegmentMetadataPush and SegmentCreationAndMetadataPush\nThis job will upload pinot segment metadata along with download URI to bypass controller downloading segment code path.", "createdAt": "2020-09-03T07:37:16Z", "url": "https://github.com/apache/pinot/pull/5967", "merged": true, "mergeCommit": {"oid": "4f2e767f5ccd123e689ecab719a83f0c16f41b2c"}, "closed": true, "closedAt": "2020-09-30T04:47:27Z", "author": {"login": "xiangfu0"}, "timelineItems": {"totalCount": 16, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdFLmr2ABqjM3MjMzMzcwMzU=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdNva8SgBqjM4MjE4Mjk4ODI=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "26802e76b6df2aa593841083b331781b4d7c461e", "author": {"user": {"login": "xiangfu0", "name": "Xiang Fu"}}, "url": "https://github.com/apache/pinot/commit/26802e76b6df2aa593841083b331781b4d7c461e", "committedDate": "2020-09-03T07:33:22Z", "message": "Adding push job type of segment metadata only mode"}, "afterCommit": {"oid": "e3095b279bc19f938e4bb97470a3053159e48685", "author": {"user": {"login": "xiangfu0", "name": "Xiang Fu"}}, "url": "https://github.com/apache/pinot/commit/e3095b279bc19f938e4bb97470a3053159e48685", "committedDate": "2020-09-03T07:37:54Z", "message": "Adding push job type of segment metadata only mode"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e3095b279bc19f938e4bb97470a3053159e48685", "author": {"user": {"login": "xiangfu0", "name": "Xiang Fu"}}, "url": "https://github.com/apache/pinot/commit/e3095b279bc19f938e4bb97470a3053159e48685", "committedDate": "2020-09-03T07:37:54Z", "message": "Adding push job type of segment metadata only mode"}, "afterCommit": {"oid": "cb159a356f7ec13ae930f41b95fee0f2e0b00cc9", "author": {"user": {"login": "xiangfu0", "name": "Xiang Fu"}}, "url": "https://github.com/apache/pinot/commit/cb159a356f7ec13ae930f41b95fee0f2e0b00cc9", "committedDate": "2020-09-03T23:29:05Z", "message": "Adding push job type of segment metadata only mode"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "cb159a356f7ec13ae930f41b95fee0f2e0b00cc9", "author": {"user": {"login": "xiangfu0", "name": "Xiang Fu"}}, "url": "https://github.com/apache/pinot/commit/cb159a356f7ec13ae930f41b95fee0f2e0b00cc9", "committedDate": "2020-09-03T23:29:05Z", "message": "Adding push job type of segment metadata only mode"}, "afterCommit": {"oid": "bb4e5dab25d62ac7a3cc276d4dc89dd61afcc76d", "author": {"user": {"login": "xiangfu0", "name": "Xiang Fu"}}, "url": "https://github.com/apache/pinot/commit/bb4e5dab25d62ac7a3cc276d4dc89dd61afcc76d", "committedDate": "2020-09-23T20:41:49Z", "message": "Adding push job type of segment metadata only mode"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "bb4e5dab25d62ac7a3cc276d4dc89dd61afcc76d", "author": {"user": {"login": "xiangfu0", "name": "Xiang Fu"}}, "url": "https://github.com/apache/pinot/commit/bb4e5dab25d62ac7a3cc276d4dc89dd61afcc76d", "committedDate": "2020-09-23T20:41:49Z", "message": "Adding push job type of segment metadata only mode"}, "afterCommit": {"oid": "7d72d386c5c13b1b7d53dbe92fe95807d024e45e", "author": {"user": {"login": "xiangfu0", "name": "Xiang Fu"}}, "url": "https://github.com/apache/pinot/commit/7d72d386c5c13b1b7d53dbe92fe95807d024e45e", "committedDate": "2020-09-24T01:30:36Z", "message": "Adding push job type of segment metadata only mode"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "7d72d386c5c13b1b7d53dbe92fe95807d024e45e", "author": {"user": {"login": "xiangfu0", "name": "Xiang Fu"}}, "url": "https://github.com/apache/pinot/commit/7d72d386c5c13b1b7d53dbe92fe95807d024e45e", "committedDate": "2020-09-24T01:30:36Z", "message": "Adding push job type of segment metadata only mode"}, "afterCommit": {"oid": "a0aa8e698913711de1250e2069a95641aa1bd5ac", "author": {"user": {"login": "xiangfu0", "name": "Xiang Fu"}}, "url": "https://github.com/apache/pinot/commit/a0aa8e698913711de1250e2069a95641aa1bd5ac", "committedDate": "2020-09-24T01:38:02Z", "message": "Adding push job type of segment metadata only mode"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk4MDg1NTU4", "url": "https://github.com/apache/pinot/pull/5967#pullrequestreview-498085558", "createdAt": "2020-09-29T04:23:36Z", "commit": {"oid": "662b7b581942379896e01cbcd972bc815710d64b"}, "state": "COMMENTED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQwNDoyMzozN1rOHZYang==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQwNDozNzo1MlrOHZZBxw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjM3NjQ3OA==", "bodyText": "Should we add a new FileUploadType: METADATA instead of using this extra boolean flag?", "url": "https://github.com/apache/pinot/pull/5967#discussion_r496376478", "createdAt": "2020-09-29T04:23:37Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-controller/src/main/java/org/apache/pinot/controller/api/resources/PinotSegmentUploadDownloadRestletResource.java", "diffHunk": "@@ -182,7 +182,8 @@ public Response downloadSegment(\n   }\n \n   private SuccessResponse uploadSegment(@Nullable String tableName, FormDataMultiPart multiPart,\n-      boolean enableParallelPushProtection, HttpHeaders headers, Request request, boolean moveSegmentToFinalLocation) {\n+      boolean enableParallelPushProtection, HttpHeaders headers, Request request, boolean moveSegmentToFinalLocation,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "662b7b581942379896e01cbcd972bc815710d64b"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjM3ODU3Mg==", "bodyText": "Suggest reusing the existing APIs and use headers to differentiate segment/metadata upload.\nUsing POST /segmentmetadata to upload segments seems counter-intuitive to me.", "url": "https://github.com/apache/pinot/pull/5967#discussion_r496378572", "createdAt": "2020-09-29T04:26:33Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-controller/src/main/java/org/apache/pinot/controller/api/resources/PinotSegmentUploadDownloadRestletResource.java", "diffHunk": "@@ -454,7 +465,41 @@ public void uploadSegmentAsMultiPartV2(FormDataMultiPart multiPart,\n       @ApiParam(value = \"Whether to enable parallel push protection\") @DefaultValue(\"false\") @QueryParam(FileUploadDownloadClient.QueryParameters.ENABLE_PARALLEL_PUSH_PROTECTION) boolean enableParallelPushProtection,\n       @Context HttpHeaders headers, @Context Request request, @Suspended final AsyncResponse asyncResponse) {\n     try {\n-      asyncResponse.resume(uploadSegment(tableName, multiPart, enableParallelPushProtection, headers, request, true));\n+      asyncResponse.resume(uploadSegment(tableName, multiPart, enableParallelPushProtection, headers, request, true, false));\n+    } catch (Throwable t) {\n+      asyncResponse.resume(t);\n+    }\n+  }\n+\n+  @POST\n+  @ManagedAsync\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @Consumes(MediaType.APPLICATION_JSON)\n+  @Path(\"/segmentmetadata\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "662b7b581942379896e01cbcd972bc815710d64b"}, "originalPosition": 111}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjM3OTQ2Nw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                LOGGER.info(\"Start pushing segments: {}... to locations: {} for table {}\",\n          \n          \n            \n                LOGGER.info(\"Start pushing segment metadata: {} to locations: {} for table {}\",", "url": "https://github.com/apache/pinot/pull/5967#discussion_r496379467", "createdAt": "2020-09-29T04:27:45Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-plugins/pinot-batch-ingestion/pinot-batch-ingestion-common/src/main/java/org/apache/pinot/plugin/ingestion/batch/common/SegmentPushUtils.java", "diffHunk": "@@ -177,4 +187,125 @@ public static void sendSegmentUris(SegmentGenerationJobSpec spec, List<String> s\n       }\n     }\n   }\n+\n+  public static void sendSegmentUriToTarPathMap(SegmentGenerationJobSpec spec, PinotFS fileSystem, Map<String, String> segmentUriToTarPathMap)\n+      throws Exception {\n+    String tableName = spec.getTableSpec().getTableName();\n+    LOGGER.info(\"Start pushing segments: {}... to locations: {} for table {}\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "662b7b581942379896e01cbcd972bc815710d64b"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjM4MDc3NA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    Arrays.toString(segmentUriToTarPathMap.entrySet().toArray()),\n          \n          \n            \n                    segmentUriToTarPathMap,", "url": "https://github.com/apache/pinot/pull/5967#discussion_r496380774", "createdAt": "2020-09-29T04:29:42Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-plugins/pinot-batch-ingestion/pinot-batch-ingestion-common/src/main/java/org/apache/pinot/plugin/ingestion/batch/common/SegmentPushUtils.java", "diffHunk": "@@ -177,4 +187,125 @@ public static void sendSegmentUris(SegmentGenerationJobSpec spec, List<String> s\n       }\n     }\n   }\n+\n+  public static void sendSegmentUriToTarPathMap(SegmentGenerationJobSpec spec, PinotFS fileSystem, Map<String, String> segmentUriToTarPathMap)\n+      throws Exception {\n+    String tableName = spec.getTableSpec().getTableName();\n+    LOGGER.info(\"Start pushing segments: {}... to locations: {} for table {}\",\n+        Arrays.toString(segmentUriToTarPathMap.entrySet().toArray()),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "662b7b581942379896e01cbcd972bc815710d64b"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjM4MTUwNw==", "bodyText": "Suggest using UUID", "url": "https://github.com/apache/pinot/pull/5967#discussion_r496381507", "createdAt": "2020-09-29T04:30:50Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-plugins/pinot-batch-ingestion/pinot-batch-ingestion-common/src/main/java/org/apache/pinot/plugin/ingestion/batch/common/SegmentPushUtils.java", "diffHunk": "@@ -177,4 +187,125 @@ public static void sendSegmentUris(SegmentGenerationJobSpec spec, List<String> s\n       }\n     }\n   }\n+\n+  public static void sendSegmentUriToTarPathMap(SegmentGenerationJobSpec spec, PinotFS fileSystem, Map<String, String> segmentUriToTarPathMap)\n+      throws Exception {\n+    String tableName = spec.getTableSpec().getTableName();\n+    LOGGER.info(\"Start pushing segments: {}... to locations: {} for table {}\",\n+        Arrays.toString(segmentUriToTarPathMap.entrySet().toArray()),\n+        Arrays.toString(spec.getPinotClusterSpecs()), tableName);\n+    for (String segmentUriPath : segmentUriToTarPathMap.keySet()) {\n+      String tarFilePath = segmentUriToTarPathMap.get(segmentUriPath);\n+      String fileName = new File(tarFilePath).getName();\n+      Preconditions.checkArgument(fileName.endsWith(Constants.TAR_GZ_FILE_EXT));\n+      String segmentName = fileName.substring(0, fileName.length() - Constants.TAR_GZ_FILE_EXT.length());\n+      File segmentMetadataFile = new File(FileUtils.getTempDirectory(), \"segmentMetadataFile-\" + System.nanoTime() + TarGzCompressionUtils.TAR_GZ_FILE_EXTENSION);\n+      generateSegmentMetadataFile(fileSystem, URI.create(tarFilePath), segmentMetadataFile);\n+      try {\n+        for (PinotClusterSpec pinotClusterSpec : spec.getPinotClusterSpecs()) {\n+          URI controllerURI;\n+          try {\n+            controllerURI = new URI(pinotClusterSpec.getControllerURI());\n+          } catch (URISyntaxException e) {\n+            throw new RuntimeException(\"Got invalid controller uri - '\" + pinotClusterSpec.getControllerURI() + \"'\");\n+          }\n+          LOGGER.info(\"Pushing segment: {} to location: {} for table {}\", segmentName, controllerURI, tableName);\n+          int attempts = 1;\n+          if (spec.getPushJobSpec() != null && spec.getPushJobSpec().getPushAttempts() > 0) {\n+            attempts = spec.getPushJobSpec().getPushAttempts();\n+          }\n+          long retryWaitMs = 1000L;\n+          if (spec.getPushJobSpec() != null && spec.getPushJobSpec().getPushRetryIntervalMillis() > 0) {\n+            retryWaitMs = spec.getPushJobSpec().getPushRetryIntervalMillis();\n+          }\n+          RetryPolicies.exponentialBackoffRetryPolicy(attempts, retryWaitMs, 5).attempt(() -> {\n+            try {\n+              List<Header> headers = ImmutableList.of(new BasicHeader(FileUploadDownloadClient.CustomHeaders.DOWNLOAD_URI, segmentUriPath));\n+              // Add table name as a request parameter\n+              NameValuePair tableNameValuePair =\n+                  new BasicNameValuePair(FileUploadDownloadClient.QueryParameters.TABLE_NAME, tableName);\n+              List<NameValuePair> parameters = Arrays.asList(tableNameValuePair);\n+              SimpleHttpResponse response = FILE_UPLOAD_DOWNLOAD_CLIENT.uploadSegmentMetadata(FileUploadDownloadClient.getUploadSegmentMetadataURI(controllerURI),\n+                  segmentName, segmentMetadataFile, headers, parameters, FILE_UPLOAD_DOWNLOAD_CLIENT.DEFAULT_SOCKET_TIMEOUT_MS);\n+              LOGGER.info(\"Response for pushing table {} segment {} to location {} - {}: {}\", tableName, segmentName,\n+                  controllerURI, response.getStatusCode(), response.getResponse());\n+              return true;\n+            } catch (HttpErrorStatusException e) {\n+              int statusCode = e.getStatusCode();\n+              if (statusCode >= 500) {\n+                // Temporary exception\n+                LOGGER\n+                    .warn(\"Caught temporary exception while pushing table: {} segment: {} to {}, will retry\", tableName,\n+                        segmentName, controllerURI, e);\n+                return false;\n+              } else {\n+                // Permanent exception\n+                LOGGER.error(\"Caught permanent exception while pushing table: {} segment: {} to {}, won't retry\",\n+                    tableName, segmentName, controllerURI, e);\n+                throw e;\n+              }\n+            }\n+          });\n+        }\n+      } finally {\n+        FileUtils.deleteQuietly(segmentMetadataFile);\n+      }\n+    }\n+  }\n+\n+  public static Map<String, String> getSegmentUriToTarPathMap(URI outputDirURI, String uriPrefix, String uriSuffix, String[] files) {\n+    Map<String, String> segmentUriToTarPathMap = new HashMap<>();\n+    for (String file : files) {\n+      URI uri = URI.create(file);\n+      if (uri.getPath().endsWith(Constants.TAR_GZ_FILE_EXT)) {\n+        URI updatedURI = SegmentPushUtils.generateSegmentTarURI(outputDirURI, uri, uriPrefix,uriSuffix);\n+        segmentUriToTarPathMap.put(updatedURI.toString(), file);\n+      }\n+    }\n+    return segmentUriToTarPathMap;\n+  }\n+\n+  /**\n+   * Generate a segment metadata only tar file, which contains only metadata.properties and creation.meta file.\n+   * The purpose of this is to create a lean tar to push to Pinot controller for adding segments without downloading\n+   * the complete segment and untar the segment tarball.\n+   *\n+   * 1. Download segment tar file to temp dir;\n+   * 2. Extract only metadata.properties and creation.meta files from the segment tar file;\n+   * 3. Tar both files into a segment metadata file.\n+   *\n+   */\n+  private static boolean generateSegmentMetadataFile(PinotFS fileSystem, URI tarFileURI, File segmentMetadataTarFile)\n+      throws Exception {\n+    long currentTime = System.nanoTime();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "662b7b581942379896e01cbcd972bc815710d64b"}, "originalPosition": 122}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjM4MjE4Ng==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                File tarFile = new File(FileUtils.getTempDirectory(), \"segmentTar-\" + currentTime + TarGzCompressionUtils.TAR_GZ_FILE_EXTENSION).getAbsoluteFile();\n          \n          \n            \n                File segmentMetadataDir = new File(FileUtils.getTempDirectory(), \"segmentMetadataDir-\" + currentTime).getAbsoluteFile();\n          \n          \n            \n                File tarFile = new File(FileUtils.getTempDirectory(), \"segmentTar-\" + currentTime + TarGzCompressionUtils.TAR_GZ_FILE_EXTENSION);\n          \n          \n            \n                File segmentMetadataDir = new File(FileUtils.getTempDirectory(), \"segmentMetadataDir-\" + currentTime);", "url": "https://github.com/apache/pinot/pull/5967#discussion_r496382186", "createdAt": "2020-09-29T04:31:53Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-plugins/pinot-batch-ingestion/pinot-batch-ingestion-common/src/main/java/org/apache/pinot/plugin/ingestion/batch/common/SegmentPushUtils.java", "diffHunk": "@@ -177,4 +187,125 @@ public static void sendSegmentUris(SegmentGenerationJobSpec spec, List<String> s\n       }\n     }\n   }\n+\n+  public static void sendSegmentUriToTarPathMap(SegmentGenerationJobSpec spec, PinotFS fileSystem, Map<String, String> segmentUriToTarPathMap)\n+      throws Exception {\n+    String tableName = spec.getTableSpec().getTableName();\n+    LOGGER.info(\"Start pushing segments: {}... to locations: {} for table {}\",\n+        Arrays.toString(segmentUriToTarPathMap.entrySet().toArray()),\n+        Arrays.toString(spec.getPinotClusterSpecs()), tableName);\n+    for (String segmentUriPath : segmentUriToTarPathMap.keySet()) {\n+      String tarFilePath = segmentUriToTarPathMap.get(segmentUriPath);\n+      String fileName = new File(tarFilePath).getName();\n+      Preconditions.checkArgument(fileName.endsWith(Constants.TAR_GZ_FILE_EXT));\n+      String segmentName = fileName.substring(0, fileName.length() - Constants.TAR_GZ_FILE_EXT.length());\n+      File segmentMetadataFile = new File(FileUtils.getTempDirectory(), \"segmentMetadataFile-\" + System.nanoTime() + TarGzCompressionUtils.TAR_GZ_FILE_EXTENSION);\n+      generateSegmentMetadataFile(fileSystem, URI.create(tarFilePath), segmentMetadataFile);\n+      try {\n+        for (PinotClusterSpec pinotClusterSpec : spec.getPinotClusterSpecs()) {\n+          URI controllerURI;\n+          try {\n+            controllerURI = new URI(pinotClusterSpec.getControllerURI());\n+          } catch (URISyntaxException e) {\n+            throw new RuntimeException(\"Got invalid controller uri - '\" + pinotClusterSpec.getControllerURI() + \"'\");\n+          }\n+          LOGGER.info(\"Pushing segment: {} to location: {} for table {}\", segmentName, controllerURI, tableName);\n+          int attempts = 1;\n+          if (spec.getPushJobSpec() != null && spec.getPushJobSpec().getPushAttempts() > 0) {\n+            attempts = spec.getPushJobSpec().getPushAttempts();\n+          }\n+          long retryWaitMs = 1000L;\n+          if (spec.getPushJobSpec() != null && spec.getPushJobSpec().getPushRetryIntervalMillis() > 0) {\n+            retryWaitMs = spec.getPushJobSpec().getPushRetryIntervalMillis();\n+          }\n+          RetryPolicies.exponentialBackoffRetryPolicy(attempts, retryWaitMs, 5).attempt(() -> {\n+            try {\n+              List<Header> headers = ImmutableList.of(new BasicHeader(FileUploadDownloadClient.CustomHeaders.DOWNLOAD_URI, segmentUriPath));\n+              // Add table name as a request parameter\n+              NameValuePair tableNameValuePair =\n+                  new BasicNameValuePair(FileUploadDownloadClient.QueryParameters.TABLE_NAME, tableName);\n+              List<NameValuePair> parameters = Arrays.asList(tableNameValuePair);\n+              SimpleHttpResponse response = FILE_UPLOAD_DOWNLOAD_CLIENT.uploadSegmentMetadata(FileUploadDownloadClient.getUploadSegmentMetadataURI(controllerURI),\n+                  segmentName, segmentMetadataFile, headers, parameters, FILE_UPLOAD_DOWNLOAD_CLIENT.DEFAULT_SOCKET_TIMEOUT_MS);\n+              LOGGER.info(\"Response for pushing table {} segment {} to location {} - {}: {}\", tableName, segmentName,\n+                  controllerURI, response.getStatusCode(), response.getResponse());\n+              return true;\n+            } catch (HttpErrorStatusException e) {\n+              int statusCode = e.getStatusCode();\n+              if (statusCode >= 500) {\n+                // Temporary exception\n+                LOGGER\n+                    .warn(\"Caught temporary exception while pushing table: {} segment: {} to {}, will retry\", tableName,\n+                        segmentName, controllerURI, e);\n+                return false;\n+              } else {\n+                // Permanent exception\n+                LOGGER.error(\"Caught permanent exception while pushing table: {} segment: {} to {}, won't retry\",\n+                    tableName, segmentName, controllerURI, e);\n+                throw e;\n+              }\n+            }\n+          });\n+        }\n+      } finally {\n+        FileUtils.deleteQuietly(segmentMetadataFile);\n+      }\n+    }\n+  }\n+\n+  public static Map<String, String> getSegmentUriToTarPathMap(URI outputDirURI, String uriPrefix, String uriSuffix, String[] files) {\n+    Map<String, String> segmentUriToTarPathMap = new HashMap<>();\n+    for (String file : files) {\n+      URI uri = URI.create(file);\n+      if (uri.getPath().endsWith(Constants.TAR_GZ_FILE_EXT)) {\n+        URI updatedURI = SegmentPushUtils.generateSegmentTarURI(outputDirURI, uri, uriPrefix,uriSuffix);\n+        segmentUriToTarPathMap.put(updatedURI.toString(), file);\n+      }\n+    }\n+    return segmentUriToTarPathMap;\n+  }\n+\n+  /**\n+   * Generate a segment metadata only tar file, which contains only metadata.properties and creation.meta file.\n+   * The purpose of this is to create a lean tar to push to Pinot controller for adding segments without downloading\n+   * the complete segment and untar the segment tarball.\n+   *\n+   * 1. Download segment tar file to temp dir;\n+   * 2. Extract only metadata.properties and creation.meta files from the segment tar file;\n+   * 3. Tar both files into a segment metadata file.\n+   *\n+   */\n+  private static boolean generateSegmentMetadataFile(PinotFS fileSystem, URI tarFileURI, File segmentMetadataTarFile)\n+      throws Exception {\n+    long currentTime = System.nanoTime();\n+    File tarFile = new File(FileUtils.getTempDirectory(), \"segmentTar-\" + currentTime + TarGzCompressionUtils.TAR_GZ_FILE_EXTENSION).getAbsoluteFile();\n+    File segmentMetadataDir = new File(FileUtils.getTempDirectory(), \"segmentMetadataDir-\" + currentTime).getAbsoluteFile();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "662b7b581942379896e01cbcd972bc815710d64b"}, "originalPosition": 124}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjM4NTEyMA==", "bodyText": "Returns the generated file path instead of passing in the file path?", "url": "https://github.com/apache/pinot/pull/5967#discussion_r496385120", "createdAt": "2020-09-29T04:35:58Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-plugins/pinot-batch-ingestion/pinot-batch-ingestion-common/src/main/java/org/apache/pinot/plugin/ingestion/batch/common/SegmentPushUtils.java", "diffHunk": "@@ -177,4 +187,125 @@ public static void sendSegmentUris(SegmentGenerationJobSpec spec, List<String> s\n       }\n     }\n   }\n+\n+  public static void sendSegmentUriToTarPathMap(SegmentGenerationJobSpec spec, PinotFS fileSystem, Map<String, String> segmentUriToTarPathMap)\n+      throws Exception {\n+    String tableName = spec.getTableSpec().getTableName();\n+    LOGGER.info(\"Start pushing segments: {}... to locations: {} for table {}\",\n+        Arrays.toString(segmentUriToTarPathMap.entrySet().toArray()),\n+        Arrays.toString(spec.getPinotClusterSpecs()), tableName);\n+    for (String segmentUriPath : segmentUriToTarPathMap.keySet()) {\n+      String tarFilePath = segmentUriToTarPathMap.get(segmentUriPath);\n+      String fileName = new File(tarFilePath).getName();\n+      Preconditions.checkArgument(fileName.endsWith(Constants.TAR_GZ_FILE_EXT));\n+      String segmentName = fileName.substring(0, fileName.length() - Constants.TAR_GZ_FILE_EXT.length());\n+      File segmentMetadataFile = new File(FileUtils.getTempDirectory(), \"segmentMetadataFile-\" + System.nanoTime() + TarGzCompressionUtils.TAR_GZ_FILE_EXTENSION);\n+      generateSegmentMetadataFile(fileSystem, URI.create(tarFilePath), segmentMetadataFile);\n+      try {\n+        for (PinotClusterSpec pinotClusterSpec : spec.getPinotClusterSpecs()) {\n+          URI controllerURI;\n+          try {\n+            controllerURI = new URI(pinotClusterSpec.getControllerURI());\n+          } catch (URISyntaxException e) {\n+            throw new RuntimeException(\"Got invalid controller uri - '\" + pinotClusterSpec.getControllerURI() + \"'\");\n+          }\n+          LOGGER.info(\"Pushing segment: {} to location: {} for table {}\", segmentName, controllerURI, tableName);\n+          int attempts = 1;\n+          if (spec.getPushJobSpec() != null && spec.getPushJobSpec().getPushAttempts() > 0) {\n+            attempts = spec.getPushJobSpec().getPushAttempts();\n+          }\n+          long retryWaitMs = 1000L;\n+          if (spec.getPushJobSpec() != null && spec.getPushJobSpec().getPushRetryIntervalMillis() > 0) {\n+            retryWaitMs = spec.getPushJobSpec().getPushRetryIntervalMillis();\n+          }\n+          RetryPolicies.exponentialBackoffRetryPolicy(attempts, retryWaitMs, 5).attempt(() -> {\n+            try {\n+              List<Header> headers = ImmutableList.of(new BasicHeader(FileUploadDownloadClient.CustomHeaders.DOWNLOAD_URI, segmentUriPath));\n+              // Add table name as a request parameter\n+              NameValuePair tableNameValuePair =\n+                  new BasicNameValuePair(FileUploadDownloadClient.QueryParameters.TABLE_NAME, tableName);\n+              List<NameValuePair> parameters = Arrays.asList(tableNameValuePair);\n+              SimpleHttpResponse response = FILE_UPLOAD_DOWNLOAD_CLIENT.uploadSegmentMetadata(FileUploadDownloadClient.getUploadSegmentMetadataURI(controllerURI),\n+                  segmentName, segmentMetadataFile, headers, parameters, FILE_UPLOAD_DOWNLOAD_CLIENT.DEFAULT_SOCKET_TIMEOUT_MS);\n+              LOGGER.info(\"Response for pushing table {} segment {} to location {} - {}: {}\", tableName, segmentName,\n+                  controllerURI, response.getStatusCode(), response.getResponse());\n+              return true;\n+            } catch (HttpErrorStatusException e) {\n+              int statusCode = e.getStatusCode();\n+              if (statusCode >= 500) {\n+                // Temporary exception\n+                LOGGER\n+                    .warn(\"Caught temporary exception while pushing table: {} segment: {} to {}, will retry\", tableName,\n+                        segmentName, controllerURI, e);\n+                return false;\n+              } else {\n+                // Permanent exception\n+                LOGGER.error(\"Caught permanent exception while pushing table: {} segment: {} to {}, won't retry\",\n+                    tableName, segmentName, controllerURI, e);\n+                throw e;\n+              }\n+            }\n+          });\n+        }\n+      } finally {\n+        FileUtils.deleteQuietly(segmentMetadataFile);\n+      }\n+    }\n+  }\n+\n+  public static Map<String, String> getSegmentUriToTarPathMap(URI outputDirURI, String uriPrefix, String uriSuffix, String[] files) {\n+    Map<String, String> segmentUriToTarPathMap = new HashMap<>();\n+    for (String file : files) {\n+      URI uri = URI.create(file);\n+      if (uri.getPath().endsWith(Constants.TAR_GZ_FILE_EXT)) {\n+        URI updatedURI = SegmentPushUtils.generateSegmentTarURI(outputDirURI, uri, uriPrefix,uriSuffix);\n+        segmentUriToTarPathMap.put(updatedURI.toString(), file);\n+      }\n+    }\n+    return segmentUriToTarPathMap;\n+  }\n+\n+  /**\n+   * Generate a segment metadata only tar file, which contains only metadata.properties and creation.meta file.\n+   * The purpose of this is to create a lean tar to push to Pinot controller for adding segments without downloading\n+   * the complete segment and untar the segment tarball.\n+   *\n+   * 1. Download segment tar file to temp dir;\n+   * 2. Extract only metadata.properties and creation.meta files from the segment tar file;\n+   * 3. Tar both files into a segment metadata file.\n+   *\n+   */\n+  private static boolean generateSegmentMetadataFile(PinotFS fileSystem, URI tarFileURI, File segmentMetadataTarFile)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "662b7b581942379896e01cbcd972bc815710d64b"}, "originalPosition": 120}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjM4NjUwMw==", "bodyText": "Rename this to reflect it is sending the segment metadata instead of the segments?", "url": "https://github.com/apache/pinot/pull/5967#discussion_r496386503", "createdAt": "2020-09-29T04:37:52Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-plugins/pinot-batch-ingestion/pinot-batch-ingestion-common/src/main/java/org/apache/pinot/plugin/ingestion/batch/common/SegmentPushUtils.java", "diffHunk": "@@ -177,4 +187,125 @@ public static void sendSegmentUris(SegmentGenerationJobSpec spec, List<String> s\n       }\n     }\n   }\n+\n+  public static void sendSegmentUriToTarPathMap(SegmentGenerationJobSpec spec, PinotFS fileSystem, Map<String, String> segmentUriToTarPathMap)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "662b7b581942379896e01cbcd972bc815710d64b"}, "originalPosition": 33}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk4Nzg1MjAz", "url": "https://github.com/apache/pinot/pull/5967#pullrequestreview-498785203", "createdAt": "2020-09-29T18:55:31Z", "commit": {"oid": "02ad0df5401cb8ab24570d907a7a0acd8dce73db"}, "state": "APPROVED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxODo1NTozMlrOHZ8aBQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxOTowMDoyMVrOHZ8kvg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njk2NjE0OQ==", "bodyText": "I don't think we need to add these 2 new APIs, we can still use the existing segment upload API but with metadata upload in the header. I feel it is better to use the same path for segment upload.", "url": "https://github.com/apache/pinot/pull/5967#discussion_r496966149", "createdAt": "2020-09-29T18:55:32Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-controller/src/main/java/org/apache/pinot/controller/api/resources/PinotSegmentUploadDownloadRestletResource.java", "diffHunk": "@@ -460,6 +465,40 @@ public void uploadSegmentAsMultiPartV2(FormDataMultiPart multiPart,\n     }\n   }\n \n+  @POST\n+  @ManagedAsync\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @Consumes(MediaType.APPLICATION_JSON)\n+  @Path(\"/segments/metadata\")\n+  @ApiOperation(value = \"Upload a segment with metadata\", notes = \"Upload a segment using segment metadata\")\n+  public void uploadSegmentMetadataAsJson(String segmentJsonStr,\n+      @ApiParam(value = \"Name of the table\") @QueryParam(FileUploadDownloadClient.QueryParameters.TABLE_NAME) String tableName,\n+      @ApiParam(value = \"Whether to enable parallel push protection\") @DefaultValue(\"false\") @QueryParam(FileUploadDownloadClient.QueryParameters.ENABLE_PARALLEL_PUSH_PROTECTION) boolean enableParallelPushProtection,\n+      @Context HttpHeaders headers, @Context Request request, @Suspended final AsyncResponse asyncResponse) {\n+    try {\n+      asyncResponse.resume(uploadSegment(tableName, null, enableParallelPushProtection, headers, request, false));\n+    } catch (Throwable t) {\n+      asyncResponse.resume(t);\n+    }\n+  }\n+\n+  @POST\n+  @ManagedAsync\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @Consumes(MediaType.MULTIPART_FORM_DATA)\n+  @Path(\"/segments/metadata\")\n+  @ApiOperation(value = \"Upload a segment with metadata\", notes = \"Upload a segment using segment metadata\")\n+  public void uploadSegmentMetadataAsMultiPart(FormDataMultiPart multiPart,\n+      @ApiParam(value = \"Name of the table\") @QueryParam(FileUploadDownloadClient.QueryParameters.TABLE_NAME) String tableName,\n+      @ApiParam(value = \"Whether to enable parallel push protection\") @DefaultValue(\"false\") @QueryParam(FileUploadDownloadClient.QueryParameters.ENABLE_PARALLEL_PUSH_PROTECTION) boolean enableParallelPushProtection,\n+      @Context HttpHeaders headers, @Context Request request, @Suspended final AsyncResponse asyncResponse) {\n+    try {\n+      asyncResponse.resume(uploadSegment(tableName, multiPart, enableParallelPushProtection, headers, request, false));\n+    } catch (Throwable t) {\n+      asyncResponse.resume(t);\n+    }\n+  }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "02ad0df5401cb8ab24570d907a7a0acd8dce73db"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njk2NjQ0Nw==", "bodyText": "Add some javadoc?", "url": "https://github.com/apache/pinot/pull/5967#discussion_r496966447", "createdAt": "2020-09-29T18:56:05Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-plugins/pinot-batch-ingestion/pinot-batch-ingestion-common/src/main/java/org/apache/pinot/plugin/ingestion/batch/common/SegmentPushUtils.java", "diffHunk": "@@ -177,4 +188,127 @@ public static void sendSegmentUris(SegmentGenerationJobSpec spec, List<String> s\n       }\n     }\n   }\n+\n+  public static void sendSegmentUriAndMetadata(SegmentGenerationJobSpec spec, PinotFS fileSystem, Map<String, String> segmentUriToTarPathMap)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "02ad0df5401cb8ab24570d907a7a0acd8dce73db"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njk2NzIyMg==", "bodyText": "(nit) Why having the ... here? We are not omitting any segment here", "url": "https://github.com/apache/pinot/pull/5967#discussion_r496967222", "createdAt": "2020-09-29T18:57:28Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-plugins/pinot-batch-ingestion/pinot-batch-ingestion-common/src/main/java/org/apache/pinot/plugin/ingestion/batch/common/SegmentPushUtils.java", "diffHunk": "@@ -177,4 +188,127 @@ public static void sendSegmentUris(SegmentGenerationJobSpec spec, List<String> s\n       }\n     }\n   }\n+\n+  public static void sendSegmentUriAndMetadata(SegmentGenerationJobSpec spec, PinotFS fileSystem, Map<String, String> segmentUriToTarPathMap)\n+      throws Exception {\n+    String tableName = spec.getTableSpec().getTableName();\n+    LOGGER.info(\"Start pushing segment metadata: {}... to locations: {} for table {}\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "02ad0df5401cb8ab24570d907a7a0acd8dce73db"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Njk2ODg5NA==", "bodyText": "(Critical) Shouldn't this be METADATA?", "url": "https://github.com/apache/pinot/pull/5967#discussion_r496968894", "createdAt": "2020-09-29T19:00:21Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-plugins/pinot-batch-ingestion/pinot-batch-ingestion-common/src/main/java/org/apache/pinot/plugin/ingestion/batch/common/SegmentPushUtils.java", "diffHunk": "@@ -177,4 +188,127 @@ public static void sendSegmentUris(SegmentGenerationJobSpec spec, List<String> s\n       }\n     }\n   }\n+\n+  public static void sendSegmentUriAndMetadata(SegmentGenerationJobSpec spec, PinotFS fileSystem, Map<String, String> segmentUriToTarPathMap)\n+      throws Exception {\n+    String tableName = spec.getTableSpec().getTableName();\n+    LOGGER.info(\"Start pushing segment metadata: {}... to locations: {} for table {}\",\n+        segmentUriToTarPathMap,\n+        Arrays.toString(spec.getPinotClusterSpecs()), tableName);\n+    for (String segmentUriPath : segmentUriToTarPathMap.keySet()) {\n+      String tarFilePath = segmentUriToTarPathMap.get(segmentUriPath);\n+      String fileName = new File(tarFilePath).getName();\n+      Preconditions.checkArgument(fileName.endsWith(Constants.TAR_GZ_FILE_EXT));\n+      String segmentName = fileName.substring(0, fileName.length() - Constants.TAR_GZ_FILE_EXT.length());\n+      File segmentMetadataFile = generateSegmentMetadataFile(fileSystem, URI.create(tarFilePath));\n+      try {\n+        for (PinotClusterSpec pinotClusterSpec : spec.getPinotClusterSpecs()) {\n+          URI controllerURI;\n+          try {\n+            controllerURI = new URI(pinotClusterSpec.getControllerURI());\n+          } catch (URISyntaxException e) {\n+            throw new RuntimeException(\"Got invalid controller uri - '\" + pinotClusterSpec.getControllerURI() + \"'\");\n+          }\n+          LOGGER.info(\"Pushing segment: {} to location: {} for table {}\", segmentName, controllerURI, tableName);\n+          int attempts = 1;\n+          if (spec.getPushJobSpec() != null && spec.getPushJobSpec().getPushAttempts() > 0) {\n+            attempts = spec.getPushJobSpec().getPushAttempts();\n+          }\n+          long retryWaitMs = 1000L;\n+          if (spec.getPushJobSpec() != null && spec.getPushJobSpec().getPushRetryIntervalMillis() > 0) {\n+            retryWaitMs = spec.getPushJobSpec().getPushRetryIntervalMillis();\n+          }\n+          RetryPolicies.exponentialBackoffRetryPolicy(attempts, retryWaitMs, 5).attempt(() -> {\n+            try {\n+              List<Header> headers = ImmutableList.of(\n+                  new BasicHeader(FileUploadDownloadClient.CustomHeaders.DOWNLOAD_URI, segmentUriPath),\n+                  new BasicHeader(FileUploadDownloadClient.CustomHeaders.UPLOAD_TYPE, FileUploadDownloadClient.FileUploadType.URI.toString()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "02ad0df5401cb8ab24570d907a7a0acd8dce73db"}, "originalPosition": 67}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "02ad0df5401cb8ab24570d907a7a0acd8dce73db", "author": {"user": {"login": "xiangfu0", "name": "Xiang Fu"}}, "url": "https://github.com/apache/pinot/commit/02ad0df5401cb8ab24570d907a7a0acd8dce73db", "committedDate": "2020-09-29T17:15:09Z", "message": "Address comments"}, "afterCommit": {"oid": "4d315f48cfec3910e080a67d2c4f90e593ac7cf1", "author": {"user": {"login": "xiangfu0", "name": "Xiang Fu"}}, "url": "https://github.com/apache/pinot/commit/4d315f48cfec3910e080a67d2c4f90e593ac7cf1", "committedDate": "2020-09-29T19:10:50Z", "message": "Address comments"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "4d315f48cfec3910e080a67d2c4f90e593ac7cf1", "author": {"user": {"login": "xiangfu0", "name": "Xiang Fu"}}, "url": "https://github.com/apache/pinot/commit/4d315f48cfec3910e080a67d2c4f90e593ac7cf1", "committedDate": "2020-09-29T19:10:50Z", "message": "Address comments"}, "afterCommit": {"oid": "2d32aafe5dc23b9f5a0b03045ab6a69448c87558", "author": {"user": {"login": "xiangfu0", "name": "Xiang Fu"}}, "url": "https://github.com/apache/pinot/commit/2d32aafe5dc23b9f5a0b03045ab6a69448c87558", "committedDate": "2020-09-29T19:19:25Z", "message": "Address comments"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "2d32aafe5dc23b9f5a0b03045ab6a69448c87558", "author": {"user": {"login": "xiangfu0", "name": "Xiang Fu"}}, "url": "https://github.com/apache/pinot/commit/2d32aafe5dc23b9f5a0b03045ab6a69448c87558", "committedDate": "2020-09-29T19:19:25Z", "message": "Address comments"}, "afterCommit": {"oid": "dc894949951c273566b92e90f134035d0eacabf2", "author": {"user": {"login": "xiangfu0", "name": "Xiang Fu"}}, "url": "https://github.com/apache/pinot/commit/dc894949951c273566b92e90f134035d0eacabf2", "committedDate": "2020-09-29T21:32:36Z", "message": "Adding integration tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2dc06c7d54d03c7581cf2f61f9b0e5857bbde0d7", "author": {"user": {"login": "xiangfu0", "name": "Xiang Fu"}}, "url": "https://github.com/apache/pinot/commit/2dc06c7d54d03c7581cf2f61f9b0e5857bbde0d7", "committedDate": "2020-09-29T21:33:09Z", "message": "Adding push job type of segment metadata only mode"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "85f6b43e65ba9d0e40b12c73cede7bedeae4e2b7", "author": {"user": {"login": "xiangfu0", "name": "Xiang Fu"}}, "url": "https://github.com/apache/pinot/commit/85f6b43e65ba9d0e40b12c73cede7bedeae4e2b7", "committedDate": "2020-09-29T21:33:09Z", "message": "Adding clean up for temp files"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2635036ddec271d4881c08e46db77a615c6e8879", "author": {"user": {"login": "xiangfu0", "name": "Xiang Fu"}}, "url": "https://github.com/apache/pinot/commit/2635036ddec271d4881c08e46db77a615c6e8879", "committedDate": "2020-09-29T21:33:09Z", "message": "Address comments"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "dc894949951c273566b92e90f134035d0eacabf2", "author": {"user": {"login": "xiangfu0", "name": "Xiang Fu"}}, "url": "https://github.com/apache/pinot/commit/dc894949951c273566b92e90f134035d0eacabf2", "committedDate": "2020-09-29T21:32:36Z", "message": "Adding integration tests"}, "afterCommit": {"oid": "41ce8628eae2ebf57029c02b57897faddc2ea898", "author": {"user": {"login": "xiangfu0", "name": "Xiang Fu"}}, "url": "https://github.com/apache/pinot/commit/41ce8628eae2ebf57029c02b57897faddc2ea898", "committedDate": "2020-09-29T21:33:09Z", "message": "Adding integration tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d7ca99f5860dd6062d05a4119cf6b39ffd858752", "author": {"user": {"login": "xiangfu0", "name": "Xiang Fu"}}, "url": "https://github.com/apache/pinot/commit/d7ca99f5860dd6062d05a4119cf6b39ffd858752", "committedDate": "2020-09-29T21:53:04Z", "message": "Adding integration tests"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "41ce8628eae2ebf57029c02b57897faddc2ea898", "author": {"user": {"login": "xiangfu0", "name": "Xiang Fu"}}, "url": "https://github.com/apache/pinot/commit/41ce8628eae2ebf57029c02b57897faddc2ea898", "committedDate": "2020-09-29T21:33:09Z", "message": "Adding integration tests"}, "afterCommit": {"oid": "d7ca99f5860dd6062d05a4119cf6b39ffd858752", "author": {"user": {"login": "xiangfu0", "name": "Xiang Fu"}}, "url": "https://github.com/apache/pinot/commit/d7ca99f5860dd6062d05a4119cf6b39ffd858752", "committedDate": "2020-09-29T21:53:04Z", "message": "Adding integration tests"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1716, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}