{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDg2MDQwNDM2", "number": 6012, "title": "Configurable segment generation job parallelism for Hadoop and Spark", "bodyText": "Description\nAdding field 'segmentCreationJobParallelism' to allow users to set segment generation job parallelism, default to the number of input files.  This can avoid issues of hadoop/spark job submission timeout.\nSample error logs/stacktraces of Spark job submission:\n20/09/12 20:13:02 {} INFO org.apache.pinot.plugin.filesystem.S3PinotFS: Listed 40000 files from URI: s3://my-s3-bucket/, is recursive: true\n20/09/12 20:14:31 {} ERROR org.apache.spark.deploy.yarn.ApplicationMaster: Uncaught exception: \njava.util.concurrent.TimeoutException: Futures timed out after [100000 milliseconds]\n\tat scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259) ~[scala-library-2.12.10.jar:?]\n\tat scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263) ~[scala-library-2.12.10.jar:?]\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:220) ~[org_apache_spark_spark_shaded_distro_2_12.jar:?]\n\tat org.apache.spark.deploy.yarn.ApplicationMaster.runDriver(ApplicationMaster.scala:469) ~[org_apache_spark_spark_shaded_distro_2_12.jar:?]\n\tat org.apache.spark.deploy.yarn.ApplicationMaster.runImpl(ApplicationMaster.scala:305) ~[org_apache_spark_spark_shaded_distro_2_12.jar:?]\n\tat org.apache.spark.deploy.yarn.ApplicationMaster.$anonfun$run$1(ApplicationMaster.scala:245) ~[org_apache_spark_spark_shaded_distro_2_12.jar:?]\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) [scala-library-2.12.10.jar:?]\n\tat org.apache.spark.deploy.yarn.ApplicationMaster$$anon$3.run(ApplicationMaster.scala:779) [org_apache_spark_spark_shaded_distro_2_12.jar:?]\n\tat java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_265]\n\tat javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_265]\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.1.jar:?]\n\tat org.apache.spark.deploy.yarn.ApplicationMaster.doAsUser(ApplicationMaster.scala:778) [org_apache_spark_spark_shaded_distro_2_12.jar:?]\n\tat org.apache.spark.deploy.yarn.ApplicationMaster.run(ApplicationMaster.scala:245) [org_apache_spark_spark_shaded_distro_2_12.jar:?]\n\tat org.apache.spark.deploy.yarn.ApplicationMaster$.main(ApplicationMaster.scala:803) [org_apache_spark_spark_shaded_distro_2_12.jar:?]\n\tat org.apache.spark.deploy.yarn.ApplicationMaster.main(ApplicationMaster.scala) [org_apache_spark_spark_shaded_distro_2_12.jar:?]\n20/09/12 20:14:31 {} INFO org.apache.spark.deploy.yarn.ApplicationMaster: Final app status: FAILED, exitCode: 13, (reason: Uncaught exception: java.util.concurrent.TimeoutException: Futures timed out after [100000 milliseconds]\n\tat scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:259)\n\tat scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:263)\n\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:220)\n\tat org.apache.spark.deploy.yarn.ApplicationMaster.runDriver(ApplicationMaster.scala:469)\n\tat org.apache.spark.deploy.yarn.ApplicationMaster.runImpl(ApplicationMaster.scala:305)\n\tat org.apache.spark.deploy.yarn.ApplicationMaster.$anonfun$run$1(ApplicationMaster.scala:245)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.apache.spark.deploy.yarn.ApplicationMaster$$anon$3.run(ApplicationMaster.scala:779)\n\tat java.security.AccessController.doPrivileged(Native Method)\n\tat javax.security.auth.Subject.doAs(Subject.java:422)\n\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)\n\tat org.apache.spark.deploy.yarn.ApplicationMaster.doAsUser(ApplicationMaster.scala:778)\n\tat org.apache.spark.deploy.yarn.ApplicationMaster.run(ApplicationMaster.scala:245)\n\tat org.apache.spark.deploy.yarn.ApplicationMaster$.main(ApplicationMaster.scala:803)\n\tat org.apache.spark.deploy.yarn.ApplicationMaster.main(ApplicationMaster.scala)\n)\n20/09/12 20:14:31 {} INFO org.apache.spark.deploy.yarn.ApplicationMaster: Deleting staging directory hdfs://hadoop/user/user1/.sparkStaging/application_1596183113611_11111", "createdAt": "2020-09-12T22:14:57Z", "url": "https://github.com/apache/pinot/pull/6012", "merged": true, "mergeCommit": {"oid": "054faf76cdef5a625d042a4d435d428529c8d798"}, "closed": true, "closedAt": "2020-09-15T09:20:12Z", "author": {"login": "xiangfu0"}, "timelineItems": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdJA8a-gFqTQ4ODMzNDU0OA==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdJCY48gBqjM3NjY3NTczMjc=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg4MzM0NTQ4", "url": "https://github.com/apache/pinot/pull/6012#pullrequestreview-488334548", "createdAt": "2020-09-15T05:27:02Z", "commit": {"oid": "6e2cf599bb8623acef91836979a6cef4ef68bc02"}, "state": "APPROVED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQwNToyNzowMlrOHRxMtQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQwNToyODoxMVrOHRxN7A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM5MzkwOQ==", "bodyText": "Should we use min of configured parallelism and the numDataFiles?", "url": "https://github.com/apache/pinot/pull/6012#discussion_r488393909", "createdAt": "2020-09-15T05:27:02Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-plugins/pinot-batch-ingestion/pinot-batch-ingestion-hadoop/src/main/java/org/apache/pinot/plugin/ingestion/batch/hadoop/HadoopSegmentGenerationJobRunner.java", "diffHunk": "@@ -230,7 +230,10 @@ public void run()\n       if (hadoopTokenFileLocation != null) {\n         jobConf.set(\"mapreduce.job.credentials.binary\", hadoopTokenFileLocation);\n       }\n-      jobConf.setInt(JobContext.NUM_MAPS, numDataFiles);\n+\n+      int jobParallelism =\n+          (_spec.getSegmentCreationJobParallelism() > 0) ? _spec.getSegmentCreationJobParallelism() : numDataFiles;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6e2cf599bb8623acef91836979a6cef4ef68bc02"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM5NDIyMA==", "bodyText": "10000?", "url": "https://github.com/apache/pinot/pull/6012#discussion_r488394220", "createdAt": "2020-09-15T05:28:11Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-plugins/pinot-batch-ingestion/pinot-batch-ingestion-standalone/src/main/resources/segmentCreationAndTarPushJobSpec.yaml", "diffHunk": "@@ -28,6 +28,7 @@ includeFileNamePattern: 'glob:**/*.parquet'\n excludeFileNamePattern: 'glob:**/*.avro'\n outputDirURI: 'file:///path/to/output'\n overwriteOutput: true\n+parallelism: 10000", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6e2cf599bb8623acef91836979a6cef4ef68bc02"}, "originalPosition": 4}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "35b7ebc43c816c3cc7439880083e10832c6224e6", "author": {"user": {"login": "xiangfu0", "name": "Xiang Fu"}}, "url": "https://github.com/apache/pinot/commit/35b7ebc43c816c3cc7439880083e10832c6224e6", "committedDate": "2020-09-15T07:09:19Z", "message": "Adding field 'segmentCreationJobParallelism' to allow users to set segment generation job parallelism. Default to the number of input files."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6e2cf599bb8623acef91836979a6cef4ef68bc02", "author": {"user": {"login": "xiangfu0", "name": "Xiang Fu"}}, "url": "https://github.com/apache/pinot/commit/6e2cf599bb8623acef91836979a6cef4ef68bc02", "committedDate": "2020-09-12T22:08:55Z", "message": "Adding field 'segmentCreationJobParallelism' to allow users to set segment generation job parallelism. Default to the number of input files."}, "afterCommit": {"oid": "35b7ebc43c816c3cc7439880083e10832c6224e6", "author": {"user": {"login": "xiangfu0", "name": "Xiang Fu"}}, "url": "https://github.com/apache/pinot/commit/35b7ebc43c816c3cc7439880083e10832c6224e6", "committedDate": "2020-09-15T07:09:19Z", "message": "Adding field 'segmentCreationJobParallelism' to allow users to set segment generation job parallelism. Default to the number of input files."}}]}}}, "rateLimit": {"limit": 5000, "remaining": 34, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}