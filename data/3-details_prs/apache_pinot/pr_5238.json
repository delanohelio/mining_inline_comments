{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDAyMDU5Njk0", "number": 5238, "title": "Evaluate schema transform expressions during ingestion", "bodyText": "This PR adds the feature to execute transform functions written in the schema. This transformation will happen during ingestion. Detailed design doc listing all changes and design: Column Transformation during ingestion in Pinot.\n\nChanges mainly are:\n\ntransformFunction can be written in the schema for any fieldSpec using Groovy. The convention to follow is:\n\"transformFunction\": \"FunctionType({function}, argument1, argument2,...argumentN)\"\nFor example:\n\"transformFunction\" : \"Groovy({firstName + ' ' + lastName}, firstName, lastName)\"\nThe RecordReader will provide the Pinot schema to the SourceFieldNamesExtractor utility to get source field names.\nRecordExtractor interface is introduced, one per input format. The RecordReader will pass the source field names and the source record to the RecordExtractor, which will provide the destination GenericRow.\nThe ExpressionTransformer will create ExpressionEvaluator for each transform function and execute the functions.\nExpressionTransformer will go before all other RecordTransformers, so that every other transformer has the real values.\n\nI'll be happy to break this down into smaller PRs, if this is getting too big to review.\nI'm finding it hard to break this down, because the AvroRecordExtractor is already used in realtime decoders\nPending\n\nAdd transform functions in some integration test\nJMH benchmarks\n\nSome open questions\n\nWe no longer know the data type of the source fields. This is a problem in CSV and JSON.\nCSV\na) Everything is read as String, right until the DataTypeTransformer. The function will have to take care of handling the type conversion.\nb) Cannot distinguish between MV columns of single value vs single value column. Function will have to take care\nc) All empty values will be null values. Cannot distinguish between genuine \u201c\u201d and null in String\nJSON\na) Cannot distinguish between INT/LONG and DOUBLE/FLOAT, until DataTypeTransformer.\nWhat should we do if any of the inputs to the transform function is null? Currently, it is skipped. But should we make it the responsibility of the function to handle this?\nKafkaJSONDecoder needs to create JSONRecordExtractor by default. But we cannot access JSONRecordExtractor of input-format module in the stream-ingestion module. Did not face this problem in Avro, because everything is in input-format\nBefore ExpressionTransformer, the GenericRecord contains only source columns. After ExpressionTransformer, the GenericRecord contains source + destination columns, all the way up to the indexing. Should we introduce a Transformer which will create new GenericRecord with only the destination columns, to avoid the memory consumption by the extra columns?", "createdAt": "2020-04-10T20:32:51Z", "url": "https://github.com/apache/pinot/pull/5238", "merged": true, "mergeCommit": {"oid": "b20ace081fc8566490d5e8addc211537843c8a9a"}, "closed": true, "closedAt": "2020-04-15T21:13:15Z", "author": {"login": "npawar"}, "timelineItems": {"totalCount": 32, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcWZV7wAFqTM5MTY5MzY2Nw==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcX89d7gH2gAyNDAyMDU5Njk0OmRlMzAzMWQ1ZmIyOWIzYzVmMTkzODc5Y2UyNDkyN2Q0MzNkZmQyYzg=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkxNjkzNjY3", "url": "https://github.com/apache/pinot/pull/5238#pullrequestreview-391693667", "createdAt": "2020-04-10T22:37:48Z", "commit": {"oid": "865922d017e139b54ab245b84e33d1a495f6f978"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQyMjozNzo0OVrOGEHiJg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQyMjozNzo0OVrOGEHiJg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjk3MDkxOA==", "bodyText": "include column name in the log", "url": "https://github.com/apache/pinot/pull/5238#discussion_r406970918", "createdAt": "2020-04-10T22:37:49Z", "author": {"login": "mcvsubbu"}, "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/ExpressionEvaluatorFactory.java", "diffHunk": "@@ -0,0 +1,104 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.TimeFieldSpec;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Factory class to create an {@link ExpressionEvaluator} for the field spec based on the {@link FieldSpec#getTransformFunction()}\n+ */\n+public class ExpressionEvaluatorFactory {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(ExpressionEvaluatorFactory.class);\n+\n+  private ExpressionEvaluatorFactory() {\n+\n+  }\n+\n+  /**\n+   * Creates the {@link ExpressionEvaluator} for the given field spec\n+   *\n+   * 1. If transform expression is defined, use it to create {@link ExpressionEvaluator}\n+   * 2. For TIME column, {@link DefaultTimeSpecEvaluator} for backward compatible handling of time spec. This is needed until we migrate to {@link org.apache.pinot.spi.data.DateTimeFieldSpec}\n+   * 3. For columns ending with __KEYS or __VALUES (used for interpreting Map column in Avro), create default functions for handing the Map\n+   * 4. Return null, if none of the above\n+   */\n+  public static ExpressionEvaluator getExpressionEvaluator(FieldSpec fieldSpec) {\n+    ExpressionEvaluator expressionEvaluator = null;\n+\n+    if (!fieldSpec.isVirtualColumn()) {\n+\n+      String columnName = fieldSpec.getName();\n+      String transformExpression = fieldSpec.getTransformFunction();\n+      if (transformExpression != null) {\n+\n+        // if transform function expression present, use it to generate function evaluator\n+        try {\n+          expressionEvaluator = getExpressionEvaluator(transformExpression);\n+        } catch (Exception e) {\n+          LOGGER.error(\"Caught exception while constructing expression evaluator for: {}, skipping\", transformExpression, e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "865922d017e139b54ab245b84e33d1a495f6f978"}, "originalPosition": 59}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkxODgzODE0", "url": "https://github.com/apache/pinot/pull/5238#pullrequestreview-391883814", "createdAt": "2020-04-12T18:29:05Z", "commit": {"oid": "865922d017e139b54ab245b84e33d1a495f6f978"}, "state": "APPROVED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMlQxODoyOTowNlrOGEXsFQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMlQxODo0MzoyMlrOGEXx_g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzNTYwNQ==", "bodyText": "userId --> user_id we might make columns case insensitive at some point and this test case should still be valid.", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407235605", "createdAt": "2020-04-12T18:29:06Z", "author": {"login": "kishoreg"}, "path": "pinot-core/src/test/java/org/apache/pinot/core/data/recordtransformer/ExpressionTransformerTest.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.data.recordtransformer;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.net.URL;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.spi.data.readers.AbstractRecordExtractorTest;\n+import org.apache.pinot.spi.data.readers.GenericRow;\n+import org.testng.Assert;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.Test;\n+\n+\n+/**\n+ * Tests the evaluation of transform expressions by the ExpressionTransformer\n+ */\n+public class ExpressionTransformerTest {\n+\n+  private Schema _pinotSchema;\n+\n+  @BeforeClass\n+  public void setup()\n+      throws IOException {\n+    URL resource =\n+        AbstractRecordExtractorTest.class.getClassLoader().getResource(\"data/expression_transformer/groovy_expression_transformer.json\");\n+    File schemaFile = new File(resource.getFile());\n+    _pinotSchema = Schema.fromFile(schemaFile);\n+  }\n+\n+  @Test\n+  public void testGroovyExpressionTransformer() {\n+    ExpressionTransformer expressionTransformer = new ExpressionTransformer(_pinotSchema);\n+    DataTypeTransformer dataTypeTransformer = new DataTypeTransformer(_pinotSchema);\n+\n+    // test functions from schema\n+    GenericRow genericRow = new GenericRow();\n+    genericRow.putValue(\"userID\", 1L);\n+    genericRow.putValue(\"firstName\", \"John\");\n+    genericRow.putValue(\"lastName\", \"Denver\");\n+    genericRow.putValue(\"bids\", Arrays.asList(10, 20));\n+    HashMap<String, String> map1 = new HashMap<>(); // keys in Map from avro are always in STRING\n+    map1.put(\"30\", \"foo\");\n+    map1.put(\"200\", \"bar\");\n+    genericRow.putValue(\"map1\", map1);\n+    HashMap<String, Integer> map2 = new HashMap<>();\n+    map2.put(\"k1\", 10);\n+    map2.put(\"k2\", 20);\n+    genericRow.putValue(\"map2\", map2);\n+    genericRow.putValue(\"cost\", 1000.0);\n+    genericRow.putValue(\"timestamp\", 1574000000000L);\n+\n+    // expression transformer\n+    expressionTransformer.transform(genericRow);\n+\n+    // extract userId\n+    Assert.assertEquals(genericRow.getValue(\"userId\"), 1L);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "865922d017e139b54ab245b84e33d1a495f6f978"}, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzNTY0MQ==", "bodyText": "user_id", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407235641", "createdAt": "2020-04-12T18:29:21Z", "author": {"login": "kishoreg"}, "path": "pinot-core/src/test/resources/data/expression_transformer/groovy_expression_transformer.json", "diffHunk": "@@ -0,0 +1,62 @@\n+{\n+  \"schemaName\": \"events\",\n+  \"dimensionFieldSpecs\": [\n+    {\n+      \"name\": \"userId\",\n+      \"dataType\": \"LONG\",\n+      \"transformFunction\": \"Groovy({userID}, userID)\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "865922d017e139b54ab245b84e33d1a495f6f978"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzNjAyOQ==", "bodyText": "should this be part of SchemaUtils?", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407236029", "createdAt": "2020-04-12T18:33:00Z", "author": {"login": "kishoreg"}, "path": "pinot-plugins/pinot-input-format/pinot-avro-base/src/main/java/org/apache/pinot/plugin/inputformat/avro/AvroRecordReader.java", "diffHunk": "@@ -24,12 +24,11 @@\n import javax.annotation.Nullable;\n import org.apache.avro.file.DataFileStream;\n import org.apache.avro.generic.GenericRecord;\n-import org.apache.pinot.spi.data.FieldSpec;\n import org.apache.pinot.spi.data.Schema;\n import org.apache.pinot.spi.data.readers.GenericRow;\n import org.apache.pinot.spi.data.readers.RecordReader;\n import org.apache.pinot.spi.data.readers.RecordReaderConfig;\n-import org.apache.pinot.spi.data.readers.RecordReaderUtils;\n+import org.apache.pinot.spi.data.function.evaluators.SourceFieldNameExtractor;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "865922d017e139b54ab245b84e33d1a495f6f978"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzNjI1Mw==", "bodyText": "is this specific to Avro?", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407236253", "createdAt": "2020-04-12T18:34:44Z", "author": {"login": "kishoreg"}, "path": "pinot-plugins/pinot-input-format/pinot-avro-base/src/main/java/org/apache/pinot/plugin/inputformat/avro/AvroUtils.java", "diffHunk": "@@ -368,6 +341,21 @@ public static Object handleMultiValue(@Nullable Collection values) {\n     for (Object value : values) {\n       list.add(handleSingleValue(value));\n     }\n-    return list;\n+    return RecordReaderUtils.convertMultiValue(list);\n+  }\n+\n+  /**\n+   * Converts the values withing the map to single-valued values\n+   */\n+  public static Object handleMap(@Nullable Map map) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "865922d017e139b54ab245b84e33d1a495f6f978"}, "originalPosition": 111}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzNjg5Ng==", "bodyText": "will be nice to get perf on this and possibly optimize it by caching the compiled script. see this https://www.tothenew.com/blog/compile-groovyscript-at-runtime-allow-caching-of-compiled-source-to-avoid-recompilation-at-runtime-using-groovyclassloader/.\nWe can do this in another PR", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407236896", "createdAt": "2020-04-12T18:41:03Z", "author": {"login": "kishoreg"}, "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/GroovyExpressionEvaluator.java", "diffHunk": "@@ -0,0 +1,99 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import com.google.common.base.Splitter;\n+import groovy.lang.Binding;\n+import groovy.lang.GroovyShell;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.pinot.spi.data.readers.GenericRow;\n+\n+\n+/**\n+ * An {@link ExpressionEvaluator} for evaluating schema transform expressions written in Groovy.\n+ * GroovyShell is used to execute expressions.\n+ *\n+ * The transform expression must follow the convention Groovy({expression}, arguments1, argument2...)\n+ * For example:\n+ * \"dimensionFieldSpecs\": [\n+ *     {\n+ *       \"name\": \"fullName\",\n+ *       \"dataType\": \"STRING\",\n+ *       \"transformFunction\": \"Groovy({firstName+' '+lastName}, firstName, lastName)\"\n+ *     }\n+ *  ]\n+ */\n+public class GroovyExpressionEvaluator implements ExpressionEvaluator {\n+\n+  private static final String GROOVY_EXPRESSION_PREFIX = \"Groovy\";\n+  private static final String GROOVY_FUNCTION_REGEX = \"Groovy\\\\(\\\\{(?<script>.+)}(,(?<arguments>.+))?\\\\)\";\n+  private static final Pattern GROOVY_FUNCTION_PATTERN = Pattern.compile(GROOVY_FUNCTION_REGEX, Pattern.CASE_INSENSITIVE);\n+  private static final String ARGUMENTS_GROUP_NAME = \"arguments\";\n+  private static final String SCRIPT_GROUP_NAME = \"script\";\n+  private static final String ARGUMENTS_SEPARATOR = \",\";\n+\n+  private List<String> _arguments;\n+  private String _script;\n+\n+  public GroovyExpressionEvaluator(String transformExpression) {\n+    Matcher matcher = GROOVY_FUNCTION_PATTERN.matcher(transformExpression);\n+    if (matcher.matches()) {\n+      _script = matcher.group(SCRIPT_GROUP_NAME);\n+\n+      String arguments = matcher.group(ARGUMENTS_GROUP_NAME);\n+      if (arguments != null) {\n+        _arguments = Splitter.on(ARGUMENTS_SEPARATOR).trimResults().splitToList(arguments);\n+      } else {\n+        _arguments = Collections.emptyList();\n+      }\n+    }\n+  }\n+\n+  public static String getGroovyExpressionPrefix() {\n+    return GROOVY_EXPRESSION_PREFIX;\n+  }\n+\n+  @Override\n+  public List<String> getArguments() {\n+    return _arguments;\n+  }\n+\n+  @Override\n+  public Object evaluate(GenericRow genericRow) {\n+    Map<String, Object> params = new HashMap<>();\n+    for (String argument : _arguments) {\n+      params.put(argument, genericRow.getValue(argument));\n+    }\n+    if (params.containsValue(null)) { // TODO: disallow evaluation of any of the params is null? Or give complete control to function?\n+      return null;\n+    } else {\n+      Binding binding = new Binding();\n+      for (String argument : _arguments) {\n+        binding.setVariable(argument, params.get(argument));\n+      }\n+      GroovyShell shell = new GroovyShell(binding);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "865922d017e139b54ab245b84e33d1a495f6f978"}, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzNjkzNg==", "bodyText": "we can merge this into Schema utils?", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407236936", "createdAt": "2020-04-12T18:41:34Z", "author": {"login": "kishoreg"}, "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/SourceFieldNameExtractor.java", "diffHunk": "@@ -0,0 +1,56 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import com.google.common.collect.Lists;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.Schema;\n+\n+\n+/**\n+ * Extracts names of the source fields from the schema\n+ */\n+public class SourceFieldNameExtractor {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "865922d017e139b54ab245b84e33d1a495f6f978"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzNzAwMg==", "bodyText": "is there a better place for this constant?", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407237002", "createdAt": "2020-04-12T18:42:14Z", "author": {"login": "kishoreg"}, "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/SourceFieldNameExtractor.java", "diffHunk": "@@ -0,0 +1,56 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import com.google.common.collect.Lists;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.Schema;\n+\n+\n+/**\n+ * Extracts names of the source fields from the schema\n+ */\n+public class SourceFieldNameExtractor {\n+  public static final String MAP_KEY_COLUMN_SUFFIX = \"__KEYS\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "865922d017e139b54ab245b84e33d1a495f6f978"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzNzExOA==", "bodyText": "Nice to extractor interface decoupled from Schema", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407237118", "createdAt": "2020-04-12T18:43:22Z", "author": {"login": "kishoreg"}, "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/readers/RecordExtractor.java", "diffHunk": "@@ -18,16 +18,28 @@\n  */\n package org.apache.pinot.spi.data.readers;\n \n-import org.apache.pinot.spi.data.Schema;\n+import java.util.List;\n \n+\n+/**\n+ * Extracts fields from input records\n+ * @param <T> The format of the input record\n+ */\n public interface RecordExtractor<T> {\n+\n+  /**\n+   * Initialize the record extractor with its config\n+   */\n+  default void init(RecordExtractorConfig recordExtractorConfig) {\n+  }\n+\n   /**\n-   * TODO Add text to this javadoc\n+   * Extracts fields as listed in the sourceFieldNames from the given input record and sets them into the GenericRow\n    *\n-   * @param schema\n-   * @param from\n-   * @param to\n-   * @return\n+   * @param sourceFieldNames List of field names to extract from the provided input record\n+   * @param from The input record\n+   * @param to The output GenericRow\n+   * @return The output GenericRow\n    */\n-  GenericRow extract(Schema schema, T from, GenericRow to);\n+  GenericRow extract(List<String> sourceFieldNames, T from, GenericRow to);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "865922d017e139b54ab245b84e33d1a495f6f978"}, "originalPosition": 34}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkyMzYzMTY1", "url": "https://github.com/apache/pinot/pull/5238#pullrequestreview-392363165", "createdAt": "2020-04-13T19:06:10Z", "commit": {"oid": "865922d017e139b54ab245b84e33d1a495f6f978"}, "state": "COMMENTED", "comments": {"totalCount": 15, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xM1QxOTowNjoxMVrOGExeRg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xM1QyMDowMToxNlrOGEzPjQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY1ODA1NA==", "bodyText": "(nit) revert?", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407658054", "createdAt": "2020-04-13T19:06:11Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-common/src/test/java/org/apache/pinot/common/utils/time/TimeConverterTest.java", "diffHunk": "@@ -21,6 +21,7 @@\n import java.util.concurrent.TimeUnit;\n import org.apache.pinot.spi.data.FieldSpec;\n import org.apache.pinot.spi.data.TimeGranularitySpec;\n+import org.apache.pinot.spi.utils.TimeConverter;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "865922d017e139b54ab245b84e33d1a495f6f978"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY2MjY0Mw==", "bodyText": "Should be okay as we only extract the needed columns, then we can reuse the record", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407662643", "createdAt": "2020-04-13T19:14:56Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/data/recordtransformer/CompositeTransformer.java", "diffHunk": "@@ -48,9 +47,11 @@\n    * </ul>\n    */\n   public static CompositeTransformer getDefaultTransformer(Schema schema) {\n+    // TODO: ExpressionTransformer contains record with source columns, and after transformation, the record has source + destination columns.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "865922d017e139b54ab245b84e33d1a495f6f978"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY2NDc5Nw==", "bodyText": "Annotate as nullable for the return value", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407664797", "createdAt": "2020-04-13T19:18:59Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/ExpressionEvaluatorFactory.java", "diffHunk": "@@ -0,0 +1,104 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.TimeFieldSpec;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Factory class to create an {@link ExpressionEvaluator} for the field spec based on the {@link FieldSpec#getTransformFunction()}\n+ */\n+public class ExpressionEvaluatorFactory {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(ExpressionEvaluatorFactory.class);\n+\n+  private ExpressionEvaluatorFactory() {\n+\n+  }\n+\n+  /**\n+   * Creates the {@link ExpressionEvaluator} for the given field spec\n+   *\n+   * 1. If transform expression is defined, use it to create {@link ExpressionEvaluator}\n+   * 2. For TIME column, {@link DefaultTimeSpecEvaluator} for backward compatible handling of time spec. This is needed until we migrate to {@link org.apache.pinot.spi.data.DateTimeFieldSpec}\n+   * 3. For columns ending with __KEYS or __VALUES (used for interpreting Map column in Avro), create default functions for handing the Map\n+   * 4. Return null, if none of the above\n+   */\n+  public static ExpressionEvaluator getExpressionEvaluator(FieldSpec fieldSpec) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "276fba0688677fc04893d25d3fc237fd3cf6ea68"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY2NjMyNA==", "bodyText": "(nit) private?", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407666324", "createdAt": "2020-04-13T19:21:45Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-integration-tests/src/test/java/org/apache/pinot/integration/tests/ClusterTest.java", "diffHunk": "@@ -346,8 +347,8 @@ protected void dropOfflineTable(String tableName)\n     private static final Logger LOGGER = LoggerFactory.getLogger(AvroFileSchemaKafkaAvroMessageDecoder.class);\n     public static File avroFile;\n     private org.apache.avro.Schema _avroSchema;\n-    private Schema _pinotSchema;\n-    private RecordExtractor<GenericData.Record> _recordExtractor;\n+    List<String> _sourceFieldNames;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "276fba0688677fc04893d25d3fc237fd3cf6ea68"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY2OTcyMw==", "bodyText": "(nit) revert?", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407669723", "createdAt": "2020-04-13T19:28:15Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/readers/RecordReaderUtils.java", "diffHunk": "@@ -105,6 +136,8 @@ public static Object convert(FieldSpec fieldSpec, @Nullable Object value) {\n     }\n   }\n \n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "276fba0688677fc04893d25d3fc237fd3cf6ea68"}, "originalPosition": 110}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY3MDIyNA==", "bodyText": "Annotate both value and return as nullable, same for other methods", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407670224", "createdAt": "2020-04-13T19:29:15Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/readers/RecordReaderUtils.java", "diffHunk": "@@ -67,31 +63,66 @@ public static InputStream getInputStream(File dataFile)\n   }\n \n   /**\n-   * Extracts all field specs from the given schema.\n-   * <p>For time field spec:\n-   * <ul>\n-   *   <li>If incoming and outgoing time column name are the same, use incoming time field spec</li>\n-   *   <li>If incoming and outgoing time column name are different, put both of them as time field spec</li>\n-   *   <li>\n-   *     We keep both incoming and outgoing time column to handle cases where the input file contains time values that\n-   *     are already converted\n-   *   </li>\n-   * </ul>\n+   * Converts the value to a multi-values value or a single values value\n    */\n-  public static List<FieldSpec> extractFieldSpecs(Schema schema) {\n-    List<FieldSpec> fieldSpecs = new ArrayList<>();\n-    for (FieldSpec fieldSpec : schema.getAllFieldSpecs()) {\n-      if (fieldSpec.getFieldType() == FieldSpec.FieldType.TIME) {\n-        TimeFieldSpec timeFieldSpec = (TimeFieldSpec) fieldSpec;\n-        fieldSpecs.add(new TimeFieldSpec(timeFieldSpec.getIncomingGranularitySpec()));\n-        if (!timeFieldSpec.getOutgoingTimeColumnName().equals(timeFieldSpec.getIncomingTimeColumnName())) {\n-          fieldSpecs.add(new TimeFieldSpec(timeFieldSpec.getOutgoingGranularitySpec()));\n-        }\n-      } else {\n-        fieldSpecs.add(fieldSpec);\n+  public static Object convert(Object value) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "276fba0688677fc04893d25d3fc237fd3cf6ea68"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY3MjA3OQ==", "bodyText": "(nit) Several new files are lacking the empty line", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407672079", "createdAt": "2020-04-13T19:32:42Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-spi/src/test/java/org/apache/pinot/spi/data/function/evaluators/GroovyExpressionEvaluatorTest.java", "diffHunk": "@@ -0,0 +1,88 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.pinot.spi.data.readers.GenericRow;\n+import org.testng.Assert;\n+import org.testng.annotations.DataProvider;\n+import org.testng.annotations.Test;\n+import org.testng.collections.Lists;\n+\n+\n+/**\n+ * Tests Groovy functions for transforming schema columns\n+ */\n+public class GroovyExpressionEvaluatorTest {\n+\n+  @Test(dataProvider = \"groovyFunctionEvaluationDataProvider\")\n+  public void testGroovyFunctionEvaluation(String transformFunction, List<String> arguments, GenericRow genericRow, Object expectedResult) {\n+\n+    GroovyExpressionEvaluator groovyExpressionEvaluator = new GroovyExpressionEvaluator(transformFunction);\n+    Assert.assertEquals(groovyExpressionEvaluator.getArguments(), arguments);\n+\n+    Object result = groovyExpressionEvaluator.evaluate(genericRow);\n+    Assert.assertEquals(result, expectedResult);\n+  }\n+\n+  @DataProvider(name = \"groovyFunctionEvaluationDataProvider\")\n+  public Object[][] groovyFunctionEvaluationDataProvider() {\n+\n+    List<Object[]> entries = new ArrayList<>();\n+\n+    GenericRow genericRow1 = new GenericRow();\n+    genericRow1.putValue(\"userID\", 101);\n+    entries.add(new Object[]{\"Groovy({userID}, userID)\", Lists.newArrayList(\"userID\"), genericRow1, 101});\n+\n+    GenericRow genericRow2 = new GenericRow();\n+    Map<String, Integer> map1 = new HashMap<>();\n+    map1.put(\"def\", 10);\n+    map1.put(\"xyz\", 30);\n+    map1.put(\"abc\", 40);\n+    genericRow2.putValue(\"map1\", map1);\n+    entries.add(new Object[]{\"Groovy({map1.sort()*.value}, map1)\", Lists.newArrayList(\"map1\"), genericRow2, Lists.newArrayList(40, 10, 30)});\n+\n+    GenericRow genericRow3 = new GenericRow();\n+    genericRow3.putValue(\"campaigns\", new Object[]{3, 2});\n+    entries.add(new Object[]{\"Groovy({campaigns.max{ it.toBigDecimal() }}, campaigns)\", Lists.newArrayList(\"campaigns\"), genericRow3, 3});\n+\n+    GenericRow genericRow4 = new GenericRow();\n+    genericRow4.putValue(\"millis\", \"1584040201500\");\n+    entries.add(new Object[]{\"Groovy({(long)(Long.parseLong(millis)/(1000*60*60))}, millis)\", Lists.newArrayList(\"millis\"), genericRow4, 440011L});\n+\n+    GenericRow genericRow5 = new GenericRow();\n+    genericRow5.putValue(\"firstName\", \"John\");\n+    genericRow5.putValue(\"lastName\", \"Doe\");\n+    entries.add(new Object[]{\"Groovy({firstName + ' ' + lastName}, firstName, lastName)\", Lists.newArrayList(\"firstName\", \"lastName\"), genericRow5, \"John Doe\"});\n+\n+    GenericRow genericRow6 = new GenericRow();\n+    genericRow6.putValue(\"eventType\", \"IMPRESSION\");\n+    entries.add(new Object[]{\"Groovy({eventType == 'IMPRESSION' ? 1: 0}, eventType)\", Lists.newArrayList(\"eventType\"), genericRow6, 1});\n+\n+    GenericRow genericRow7 = new GenericRow();\n+    genericRow7.putValue(\"eventType\", \"CLICK\");\n+    entries.add(new Object[]{\"Groovy({eventType == 'IMPRESSION' ? 1: 0}, eventType)\", Lists.newArrayList(\"eventType\"), genericRow7, 0});\n+\n+    return entries.toArray(new Object[entries.size()][]);\n+  }\n+\n+}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "276fba0688677fc04893d25d3fc237fd3cf6ea68"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY3ODA5MA==", "bodyText": "I would recommend putting source fields into the init and rename it to fields for simplicity:\n  void init(List<String> fields, @Nullable RecordExtractorConfig recordExtractorConfig);", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407678090", "createdAt": "2020-04-13T19:44:36Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/readers/RecordExtractor.java", "diffHunk": "@@ -18,16 +18,28 @@\n  */\n package org.apache.pinot.spi.data.readers;\n \n-import org.apache.pinot.spi.data.Schema;\n+import java.util.List;\n \n+\n+/**\n+ * Extracts fields from input records\n+ * @param <T> The format of the input record\n+ */\n public interface RecordExtractor<T> {\n+\n+  /**\n+   * Initialize the record extractor with its config\n+   */\n+  default void init(RecordExtractorConfig recordExtractorConfig) {\n+  }\n+\n   /**\n-   * TODO Add text to this javadoc\n+   * Extracts fields as listed in the sourceFieldNames from the given input record and sets them into the GenericRow\n    *\n-   * @param schema\n-   * @param from\n-   * @param to\n-   * @return\n+   * @param sourceFieldNames List of field names to extract from the provided input record\n+   * @param from The input record\n+   * @param to The output GenericRow\n+   * @return The output GenericRow\n    */\n-  GenericRow extract(Schema schema, T from, GenericRow to);\n+  GenericRow extract(List<String> sourceFieldNames, T from, GenericRow to);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzNzExOA=="}, "originalCommit": {"oid": "865922d017e139b54ab245b84e33d1a495f6f978"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY3ODk5NA==", "bodyText": "I don't think this logic can be shared among all the record readers. For different input format, we might need different utils for them", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407678994", "createdAt": "2020-04-13T19:46:22Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/readers/RecordReaderUtils.java", "diffHunk": "@@ -67,31 +63,66 @@ public static InputStream getInputStream(File dataFile)\n   }\n \n   /**\n-   * Extracts all field specs from the given schema.\n-   * <p>For time field spec:\n-   * <ul>\n-   *   <li>If incoming and outgoing time column name are the same, use incoming time field spec</li>\n-   *   <li>If incoming and outgoing time column name are different, put both of them as time field spec</li>\n-   *   <li>\n-   *     We keep both incoming and outgoing time column to handle cases where the input file contains time values that\n-   *     are already converted\n-   *   </li>\n-   * </ul>\n+   * Converts the value to a multi-values value or a single values value\n    */\n-  public static List<FieldSpec> extractFieldSpecs(Schema schema) {\n-    List<FieldSpec> fieldSpecs = new ArrayList<>();\n-    for (FieldSpec fieldSpec : schema.getAllFieldSpecs()) {\n-      if (fieldSpec.getFieldType() == FieldSpec.FieldType.TIME) {\n-        TimeFieldSpec timeFieldSpec = (TimeFieldSpec) fieldSpec;\n-        fieldSpecs.add(new TimeFieldSpec(timeFieldSpec.getIncomingGranularitySpec()));\n-        if (!timeFieldSpec.getOutgoingTimeColumnName().equals(timeFieldSpec.getIncomingTimeColumnName())) {\n-          fieldSpecs.add(new TimeFieldSpec(timeFieldSpec.getOutgoingGranularitySpec()));\n-        }\n-      } else {\n-        fieldSpecs.add(fieldSpec);\n+  public static Object convert(Object value) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "276fba0688677fc04893d25d3fc237fd3cf6ea68"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY4MTI3Nw==", "bodyText": "(Critical) You should skip the virtual columns here instead of inside the ExpressionEvaluatorFactory. You don't want to put virtual column into the sourceFieldNames", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407681277", "createdAt": "2020-04-13T19:50:40Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/SourceFieldNameExtractor.java", "diffHunk": "@@ -0,0 +1,56 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import com.google.common.collect.Lists;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.Schema;\n+\n+\n+/**\n+ * Extracts names of the source fields from the schema\n+ */\n+public class SourceFieldNameExtractor {\n+  public static final String MAP_KEY_COLUMN_SUFFIX = \"__KEYS\";\n+  public static final String MAP_VALUE_COLUMN_SUFFIX = \"__VALUES\";\n+\n+  /**\n+   * Extracts the source fields from the schema\n+   * For field specs with a transform expression defined, use the arguments provided to the function\n+   * Otherwise, use the column name as is\n+   * TODO: for now, we assume that arguments to transform function are in the source i.e. there's no columns which are derived from transformed columns\n+   */\n+  public static List<String> extract(Schema schema) {\n+    Set<String> sourceFieldNames = new HashSet<>();\n+    for (FieldSpec fieldSpec : schema.getAllFieldSpecs()) {\n+      String columnName = fieldSpec.getName();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "276fba0688677fc04893d25d3fc237fd3cf6ea68"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY4MTU1OA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                return Lists.newArrayList(sourceFieldNames);\n          \n          \n            \n                return new ArrayList<>(sourceFieldNames);", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407681558", "createdAt": "2020-04-13T19:51:11Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/SourceFieldNameExtractor.java", "diffHunk": "@@ -0,0 +1,56 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import com.google.common.collect.Lists;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.Schema;\n+\n+\n+/**\n+ * Extracts names of the source fields from the schema\n+ */\n+public class SourceFieldNameExtractor {\n+  public static final String MAP_KEY_COLUMN_SUFFIX = \"__KEYS\";\n+  public static final String MAP_VALUE_COLUMN_SUFFIX = \"__VALUES\";\n+\n+  /**\n+   * Extracts the source fields from the schema\n+   * For field specs with a transform expression defined, use the arguments provided to the function\n+   * Otherwise, use the column name as is\n+   * TODO: for now, we assume that arguments to transform function are in the source i.e. there's no columns which are derived from transformed columns\n+   */\n+  public static List<String> extract(Schema schema) {\n+    Set<String> sourceFieldNames = new HashSet<>();\n+    for (FieldSpec fieldSpec : schema.getAllFieldSpecs()) {\n+      String columnName = fieldSpec.getName();\n+      ExpressionEvaluator expressionEvaluator = ExpressionEvaluatorFactory.getExpressionEvaluator(fieldSpec);\n+\n+      if (expressionEvaluator != null) {\n+        sourceFieldNames.addAll(expressionEvaluator.getArguments());\n+      } else {\n+        sourceFieldNames.add(columnName);\n+      }\n+    }\n+    return Lists.newArrayList(sourceFieldNames);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "276fba0688677fc04893d25d3fc237fd3cf6ea68"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY4MzI5Mw==", "bodyText": "Handling the virtual column before calling this method?\nAllow calling this for virtual column and handle it inside can cause confusion. You cannot differentiate virtual column or column without transform.", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407683293", "createdAt": "2020-04-13T19:54:26Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/ExpressionEvaluatorFactory.java", "diffHunk": "@@ -0,0 +1,104 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.TimeFieldSpec;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Factory class to create an {@link ExpressionEvaluator} for the field spec based on the {@link FieldSpec#getTransformFunction()}\n+ */\n+public class ExpressionEvaluatorFactory {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(ExpressionEvaluatorFactory.class);\n+\n+  private ExpressionEvaluatorFactory() {\n+\n+  }\n+\n+  /**\n+   * Creates the {@link ExpressionEvaluator} for the given field spec\n+   *\n+   * 1. If transform expression is defined, use it to create {@link ExpressionEvaluator}\n+   * 2. For TIME column, {@link DefaultTimeSpecEvaluator} for backward compatible handling of time spec. This is needed until we migrate to {@link org.apache.pinot.spi.data.DateTimeFieldSpec}\n+   * 3. For columns ending with __KEYS or __VALUES (used for interpreting Map column in Avro), create default functions for handing the Map\n+   * 4. Return null, if none of the above\n+   */\n+  public static ExpressionEvaluator getExpressionEvaluator(FieldSpec fieldSpec) {\n+    ExpressionEvaluator expressionEvaluator = null;\n+\n+    if (!fieldSpec.isVirtualColumn()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "276fba0688677fc04893d25d3fc237fd3cf6ea68"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY4NTI0Ng==", "bodyText": "For better performance, check it at line 86", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407685246", "createdAt": "2020-04-13T19:58:00Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/GroovyExpressionEvaluator.java", "diffHunk": "@@ -0,0 +1,99 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import com.google.common.base.Splitter;\n+import groovy.lang.Binding;\n+import groovy.lang.GroovyShell;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.pinot.spi.data.readers.GenericRow;\n+\n+\n+/**\n+ * An {@link ExpressionEvaluator} for evaluating schema transform expressions written in Groovy.\n+ * GroovyShell is used to execute expressions.\n+ *\n+ * The transform expression must follow the convention Groovy({expression}, arguments1, argument2...)\n+ * For example:\n+ * \"dimensionFieldSpecs\": [\n+ *     {\n+ *       \"name\": \"fullName\",\n+ *       \"dataType\": \"STRING\",\n+ *       \"transformFunction\": \"Groovy({firstName+' '+lastName}, firstName, lastName)\"\n+ *     }\n+ *  ]\n+ */\n+public class GroovyExpressionEvaluator implements ExpressionEvaluator {\n+\n+  private static final String GROOVY_EXPRESSION_PREFIX = \"Groovy\";\n+  private static final String GROOVY_FUNCTION_REGEX = \"Groovy\\\\(\\\\{(?<script>.+)}(,(?<arguments>.+))?\\\\)\";\n+  private static final Pattern GROOVY_FUNCTION_PATTERN = Pattern.compile(GROOVY_FUNCTION_REGEX, Pattern.CASE_INSENSITIVE);\n+  private static final String ARGUMENTS_GROUP_NAME = \"arguments\";\n+  private static final String SCRIPT_GROUP_NAME = \"script\";\n+  private static final String ARGUMENTS_SEPARATOR = \",\";\n+\n+  private List<String> _arguments;\n+  private String _script;\n+\n+  public GroovyExpressionEvaluator(String transformExpression) {\n+    Matcher matcher = GROOVY_FUNCTION_PATTERN.matcher(transformExpression);\n+    if (matcher.matches()) {\n+      _script = matcher.group(SCRIPT_GROUP_NAME);\n+\n+      String arguments = matcher.group(ARGUMENTS_GROUP_NAME);\n+      if (arguments != null) {\n+        _arguments = Splitter.on(ARGUMENTS_SEPARATOR).trimResults().splitToList(arguments);\n+      } else {\n+        _arguments = Collections.emptyList();\n+      }\n+    }\n+  }\n+\n+  public static String getGroovyExpressionPrefix() {\n+    return GROOVY_EXPRESSION_PREFIX;\n+  }\n+\n+  @Override\n+  public List<String> getArguments() {\n+    return _arguments;\n+  }\n+\n+  @Override\n+  public Object evaluate(GenericRow genericRow) {\n+    Map<String, Object> params = new HashMap<>();\n+    for (String argument : _arguments) {\n+      params.put(argument, genericRow.getValue(argument));\n+    }\n+    if (params.containsValue(null)) { // TODO: disallow evaluation of any of the params is null? Or give complete control to function?", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "276fba0688677fc04893d25d3fc237fd3cf6ea68"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY4NTcwMA==", "bodyText": "+1", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407685700", "createdAt": "2020-04-13T19:58:49Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/GroovyExpressionEvaluator.java", "diffHunk": "@@ -0,0 +1,99 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import com.google.common.base.Splitter;\n+import groovy.lang.Binding;\n+import groovy.lang.GroovyShell;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.pinot.spi.data.readers.GenericRow;\n+\n+\n+/**\n+ * An {@link ExpressionEvaluator} for evaluating schema transform expressions written in Groovy.\n+ * GroovyShell is used to execute expressions.\n+ *\n+ * The transform expression must follow the convention Groovy({expression}, arguments1, argument2...)\n+ * For example:\n+ * \"dimensionFieldSpecs\": [\n+ *     {\n+ *       \"name\": \"fullName\",\n+ *       \"dataType\": \"STRING\",\n+ *       \"transformFunction\": \"Groovy({firstName+' '+lastName}, firstName, lastName)\"\n+ *     }\n+ *  ]\n+ */\n+public class GroovyExpressionEvaluator implements ExpressionEvaluator {\n+\n+  private static final String GROOVY_EXPRESSION_PREFIX = \"Groovy\";\n+  private static final String GROOVY_FUNCTION_REGEX = \"Groovy\\\\(\\\\{(?<script>.+)}(,(?<arguments>.+))?\\\\)\";\n+  private static final Pattern GROOVY_FUNCTION_PATTERN = Pattern.compile(GROOVY_FUNCTION_REGEX, Pattern.CASE_INSENSITIVE);\n+  private static final String ARGUMENTS_GROUP_NAME = \"arguments\";\n+  private static final String SCRIPT_GROUP_NAME = \"script\";\n+  private static final String ARGUMENTS_SEPARATOR = \",\";\n+\n+  private List<String> _arguments;\n+  private String _script;\n+\n+  public GroovyExpressionEvaluator(String transformExpression) {\n+    Matcher matcher = GROOVY_FUNCTION_PATTERN.matcher(transformExpression);\n+    if (matcher.matches()) {\n+      _script = matcher.group(SCRIPT_GROUP_NAME);\n+\n+      String arguments = matcher.group(ARGUMENTS_GROUP_NAME);\n+      if (arguments != null) {\n+        _arguments = Splitter.on(ARGUMENTS_SEPARATOR).trimResults().splitToList(arguments);\n+      } else {\n+        _arguments = Collections.emptyList();\n+      }\n+    }\n+  }\n+\n+  public static String getGroovyExpressionPrefix() {\n+    return GROOVY_EXPRESSION_PREFIX;\n+  }\n+\n+  @Override\n+  public List<String> getArguments() {\n+    return _arguments;\n+  }\n+\n+  @Override\n+  public Object evaluate(GenericRow genericRow) {\n+    Map<String, Object> params = new HashMap<>();\n+    for (String argument : _arguments) {\n+      params.put(argument, genericRow.getValue(argument));\n+    }\n+    if (params.containsValue(null)) { // TODO: disallow evaluation of any of the params is null? Or give complete control to function?\n+      return null;\n+    } else {\n+      Binding binding = new Binding();\n+      for (String argument : _arguments) {\n+        binding.setVariable(argument, params.get(argument));\n+      }\n+      GroovyShell shell = new GroovyShell(binding);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzNjg5Ng=="}, "originalCommit": {"oid": "865922d017e139b54ab245b84e33d1a495f6f978"}, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY4NzA1Mw==", "bodyText": "We should standardize what data types are allowed in the GenericRow so that RecordReader and RecordExtractor can always extract the row into the supported data types, and ExpressionEvaluator can only evaluate values into these types", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407687053", "createdAt": "2020-04-13T20:01:16Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/ExpressionEvaluator.java", "diffHunk": "@@ -0,0 +1,43 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import java.util.List;\n+import org.apache.pinot.spi.data.readers.GenericRow;\n+\n+\n+/**\n+ * Interface for evaluators of transform function expressions of schema field specs\n+ * They transformFunction follows the convention:\n+ *  \"transformFunction\": \"FunctionType({function}, argument1, argument2,...argumentN)\"\n+ *  For example,\n+ *  \"transformFunction\" : \"Groovy({firstName + ' ' + lastName}, firstName, lastName)\"\n+ */\n+public interface ExpressionEvaluator {\n+\n+  /**\n+   * Get the arguments of the function\n+   */\n+  List<String> getArguments();\n+\n+  /**\n+   * Evaluate the function on the generic row and return the result\n+   */\n+  Object evaluate(GenericRow genericRow);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "276fba0688677fc04893d25d3fc237fd3cf6ea68"}, "originalPosition": 42}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkyNDQ5NTY1", "url": "https://github.com/apache/pinot/pull/5238#pullrequestreview-392449565", "createdAt": "2020-04-13T21:22:38Z", "commit": {"oid": "276fba0688677fc04893d25d3fc237fd3cf6ea68"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xM1QyMToyMjozOVrOGE11Ag==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xM1QyMToyMjozOVrOGE11Ag==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzcyOTQxMA==", "bodyText": "Shall we consider make this evaluators to be ordered? So we can derived a field based on another derived field?", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407729410", "createdAt": "2020-04-13T21:22:39Z", "author": {"login": "xiangfu0"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/data/recordtransformer/ExpressionTransformer.java", "diffHunk": "@@ -34,33 +33,31 @@\n  * regular column for other record transformers.\n  */\n public class ExpressionTransformer implements RecordTransformer {\n-  private static final Logger LOGGER = LoggerFactory.getLogger(ExpressionTransformer.class);\n \n-  private final Map<String, FunctionExpressionEvaluator> _expressionEvaluators = new HashMap<>();\n+  private final Map<String, ExpressionEvaluator> _expressionEvaluators = new HashMap<>();\n+\n+  private final String _timeColumn;\n \n   public ExpressionTransformer(Schema schema) {\n+    _timeColumn = schema.getTimeColumnName();\n     for (FieldSpec fieldSpec : schema.getAllFieldSpecs()) {\n-      if (!fieldSpec.isVirtualColumn()) {\n-        String expression = fieldSpec.getTransformFunction();\n-        if (expression != null) {\n-          try {\n-            _expressionEvaluators.put(fieldSpec.getName(), new FunctionExpressionEvaluator(expression));\n-          } catch (Exception e) {\n-            LOGGER.error(\"Caught exception while constructing expression evaluator for: {}, skipping\", expression, e);\n-          }\n-        }\n+      ExpressionEvaluator expressionEvaluator = ExpressionEvaluatorFactory.getExpressionEvaluator(fieldSpec);\n+      if (expressionEvaluator != null) {\n+        _expressionEvaluators.put(fieldSpec.getName(), expressionEvaluator);\n       }\n     }\n   }\n \n   @Override\n   public GenericRow transform(GenericRow record) {\n-    for (Map.Entry<String, FunctionExpressionEvaluator> entry : _expressionEvaluators.entrySet()) {\n+    for (Map.Entry<String, ExpressionEvaluator> entry : _expressionEvaluators.entrySet()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "276fba0688677fc04893d25d3fc237fd3cf6ea68"}, "originalPosition": 45}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkyNDYyNDg2", "url": "https://github.com/apache/pinot/pull/5238#pullrequestreview-392462486", "createdAt": "2020-04-13T21:46:03Z", "commit": {"oid": "aa9584c853cdb1294e7f54bc629189618b69ad96"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xM1QyMTo0NjowM1rOGE2fMw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xM1QyMTo0NjowM1rOGE2fMw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzc0MDIxMQ==", "bodyText": "nit: move the package below license", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407740211", "createdAt": "2020-04-13T21:46:03Z", "author": {"login": "xiangfu0"}, "path": "pinot-spi/src/test/java/org/apache/pinot/spi/utils/TimeConverterTest.java", "diffHunk": "@@ -1,3 +1,5 @@\n+package org.apache.pinot.spi.utils;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa9584c853cdb1294e7f54bc629189618b69ad96"}, "originalPosition": 1}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkyNDY2NzUz", "url": "https://github.com/apache/pinot/pull/5238#pullrequestreview-392466753", "createdAt": "2020-04-13T21:54:13Z", "commit": {"oid": "aa9584c853cdb1294e7f54bc629189618b69ad96"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xM1QyMTo1NDoxM1rOGE2tEQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xM1QyMTo1NDoxM1rOGE2tEQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzc0Mzc2MQ==", "bodyText": "Where we will do the conversion for dataType=bytes, and value is string.", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407743761", "createdAt": "2020-04-13T21:54:13Z", "author": {"login": "xiangfu0"}, "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/readers/RecordReaderUtils.java", "diffHunk": "@@ -67,167 +59,65 @@ public static InputStream getInputStream(File dataFile)\n   }\n \n   /**\n-   * Extracts all field specs from the given schema.\n-   * <p>For time field spec:\n-   * <ul>\n-   *   <li>If incoming and outgoing time column name are the same, use incoming time field spec</li>\n-   *   <li>If incoming and outgoing time column name are different, put both of them as time field spec</li>\n-   *   <li>\n-   *     We keep both incoming and outgoing time column to handle cases where the input file contains time values that\n-   *     are already converted\n-   *   </li>\n-   * </ul>\n+   * Converts the value to a multi-values value or a single values value\n    */\n-  public static List<FieldSpec> extractFieldSpecs(Schema schema) {\n-    List<FieldSpec> fieldSpecs = new ArrayList<>();\n-    for (FieldSpec fieldSpec : schema.getAllFieldSpecs()) {\n-      if (fieldSpec.getFieldType() == FieldSpec.FieldType.TIME) {\n-        TimeFieldSpec timeFieldSpec = (TimeFieldSpec) fieldSpec;\n-        fieldSpecs.add(new TimeFieldSpec(timeFieldSpec.getIncomingGranularitySpec()));\n-        if (!timeFieldSpec.getOutgoingTimeColumnName().equals(timeFieldSpec.getIncomingTimeColumnName())) {\n-          fieldSpecs.add(new TimeFieldSpec(timeFieldSpec.getOutgoingGranularitySpec()));\n-        }\n-      } else {\n-        fieldSpecs.add(fieldSpec);\n-      }\n-    }\n-    return fieldSpecs;\n-  }\n+  public static @Nullable Object convert(@Nullable Object value) {\n \n-  /**\n-   * Converts the value based on the given field spec.\n-   */\n-  public static Object convert(FieldSpec fieldSpec, @Nullable Object value) {\n-    if (fieldSpec.isSingleValueField()) {\n-      return convertSingleValue(fieldSpec, value);\n+    if (value == null) {\n+      return null;\n+    }\n+    if (value instanceof Collection) {\n+      return convertMultiValue((Collection) value);\n     } else {\n-      return convertMultiValue(fieldSpec, (Collection) value);\n+      return convertSingleValue(value);\n     }\n   }\n \n   /**\n-   * Converts the value to a single-valued value based on the given field spec.\n+   * Converts the value to a single-valued value\n    */\n-  public static Object convertSingleValue(FieldSpec fieldSpec, @Nullable Object value) {\n+  public static @Nullable Object convertSingleValue(@Nullable Object value) {\n     if (value == null) {\n       return null;\n     }\n-    DataType dataType = fieldSpec.getDataType();\n-    if (dataType == FieldSpec.DataType.BYTES) {\n-      // Avro ByteBuffer maps to byte[]\n-      if (value instanceof ByteBuffer) {\n-        ByteBuffer byteBufferValue = (ByteBuffer) value;\n \n-        // Use byteBufferValue.remaining() instead of byteBufferValue.capacity() so that it still works when buffer is\n-        // over-sized\n-        byte[] bytesValue = new byte[byteBufferValue.remaining()];\n-        byteBufferValue.get(bytesValue);\n-        return bytesValue;\n-      } else {\n-        Preconditions\n-            .checkState(value instanceof byte[], \"For BYTES data type, value must be either ByteBuffer or byte[]\");\n-        return value;\n-      }\n-    }\n-    if (value instanceof Number) {\n-      Number numberValue = (Number) value;\n-      switch (dataType) {\n-        case INT:\n-          return numberValue.intValue();\n-        case LONG:\n-          return numberValue.longValue();\n-        case FLOAT:\n-          return numberValue.floatValue();\n-        case DOUBLE:\n-          return numberValue.doubleValue();\n-        case STRING:\n-          return numberValue.toString();\n-        default:\n-          throw new IllegalStateException(\"Illegal data type: \" + dataType);\n-      }\n-    }\n-    return convertSingleValue(fieldSpec, value.toString());\n-  }\n+    if (value instanceof ByteBuffer) {\n+      ByteBuffer byteBufferValue = (ByteBuffer) value;\n \n-  /**\n-   * Converts the string value to a single-valued value based on the given field spec.\n-   */\n-  public static Object convertSingleValue(FieldSpec fieldSpec, @Nullable String stringValue) {\n-    if (stringValue == null) {\n-      return null;\n-    }\n-    DataType dataType = fieldSpec.getDataType();\n-    // Treat empty string as null for data types other than STRING\n-    if (stringValue.isEmpty() && dataType != DataType.STRING) {\n-      return null;\n+      // Use byteBufferValue.remaining() instead of byteBufferValue.capacity() so that it still works when buffer is\n+      // over-sized\n+      byte[] bytesValue = new byte[byteBufferValue.remaining()];\n+      byteBufferValue.get(bytesValue);\n+      return bytesValue;\n     }\n-    switch (dataType) {\n-      case INT:\n-        return Integer.parseInt(stringValue);\n-      case LONG:\n-        return Long.parseLong(stringValue);\n-      case FLOAT:\n-        return Float.parseFloat(stringValue);\n-      case DOUBLE:\n-        return Double.parseDouble(stringValue);\n-      case STRING:\n-        return stringValue;\n-      case BYTES:\n-        return BytesUtils.toBytes(stringValue);\n-      default:\n-        throw new IllegalStateException(\"Illegal data type: \" + dataType);\n+    if (value instanceof Number) {\n+      return value;\n     }\n+    return value.toString();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aa9584c853cdb1294e7f54bc629189618b69ad96"}, "originalPosition": 159}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkyNTI3OTY2", "url": "https://github.com/apache/pinot/pull/5238#pullrequestreview-392527966", "createdAt": "2020-04-14T00:35:36Z", "commit": {"oid": "3ad57c497e4ff89fd1130df08bcae46e9cc4f70a"}, "state": "COMMENTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwMDozNTozN1rOGE5_nA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwMTowNTo1NVrOGE6gVg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzc5NzY2MA==", "bodyText": "Skip virtual columns here", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407797660", "createdAt": "2020-04-14T00:35:37Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/data/recordtransformer/ExpressionTransformer.java", "diffHunk": "@@ -34,33 +33,31 @@\n  * regular column for other record transformers.\n  */\n public class ExpressionTransformer implements RecordTransformer {\n-  private static final Logger LOGGER = LoggerFactory.getLogger(ExpressionTransformer.class);\n \n-  private final Map<String, FunctionExpressionEvaluator> _expressionEvaluators = new HashMap<>();\n+  private final Map<String, ExpressionEvaluator> _expressionEvaluators = new HashMap<>();\n+\n+  private final String _timeColumn;\n \n   public ExpressionTransformer(Schema schema) {\n+    _timeColumn = schema.getTimeColumnName();\n     for (FieldSpec fieldSpec : schema.getAllFieldSpecs()) {\n-      if (!fieldSpec.isVirtualColumn()) {\n-        String expression = fieldSpec.getTransformFunction();\n-        if (expression != null) {\n-          try {\n-            _expressionEvaluators.put(fieldSpec.getName(), new FunctionExpressionEvaluator(expression));\n-          } catch (Exception e) {\n-            LOGGER.error(\"Caught exception while constructing expression evaluator for: {}, skipping\", expression, e);\n-          }\n-        }\n+      ExpressionEvaluator expressionEvaluator = ExpressionEvaluatorFactory.getExpressionEvaluator(fieldSpec);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ad57c497e4ff89fd1130df08bcae46e9cc4f70a"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzc5Nzk2Ng==", "bodyText": "(convention) Put nullable in front of public static as a separate line", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407797966", "createdAt": "2020-04-14T00:36:49Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/ExpressionEvaluatorFactory.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import javax.annotation.Nullable;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.TimeFieldSpec;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Factory class to create an {@link ExpressionEvaluator} for the field spec based on the {@link FieldSpec#getTransformFunction()}\n+ */\n+public class ExpressionEvaluatorFactory {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(ExpressionEvaluatorFactory.class);\n+\n+  private ExpressionEvaluatorFactory() {\n+\n+  }\n+\n+  /**\n+   * Creates the {@link ExpressionEvaluator} for the given field spec\n+   *\n+   * 1. If transform expression is defined, use it to create {@link ExpressionEvaluator}\n+   * 2. For TIME column, {@link DefaultTimeSpecEvaluator} for backward compatible handling of time spec. This is needed until we migrate to {@link org.apache.pinot.spi.data.DateTimeFieldSpec}\n+   * 3. For columns ending with __KEYS or __VALUES (used for interpreting Map column in Avro), create default functions for handing the Map\n+   * 4. Return null, if none of the above\n+   */\n+  public static @Nullable", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ad57c497e4ff89fd1130df08bcae46e9cc4f70a"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzc5OTI2Nw==", "bodyText": "Don't specialize time column here. When the dest column already exists, we should not evaluate the expression again.\nThe reason for this is that: for hybrid table, both realtime and offline side share the same schema, and usually the batch ingestion already pre-processed the data and finished all the expression evaluation.\nHere comes a limitation of maintaining this behavior: the source column name must be different from the dest column name, but I think this should be fine. We can also add a validation for that in the SourceFieldNameExtractor", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407799267", "createdAt": "2020-04-14T00:41:23Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/data/recordtransformer/ExpressionTransformer.java", "diffHunk": "@@ -34,33 +33,31 @@\n  * regular column for other record transformers.\n  */\n public class ExpressionTransformer implements RecordTransformer {\n-  private static final Logger LOGGER = LoggerFactory.getLogger(ExpressionTransformer.class);\n \n-  private final Map<String, FunctionExpressionEvaluator> _expressionEvaluators = new HashMap<>();\n+  private final Map<String, ExpressionEvaluator> _expressionEvaluators = new HashMap<>();\n+\n+  private final String _timeColumn;\n \n   public ExpressionTransformer(Schema schema) {\n+    _timeColumn = schema.getTimeColumnName();\n     for (FieldSpec fieldSpec : schema.getAllFieldSpecs()) {\n-      if (!fieldSpec.isVirtualColumn()) {\n-        String expression = fieldSpec.getTransformFunction();\n-        if (expression != null) {\n-          try {\n-            _expressionEvaluators.put(fieldSpec.getName(), new FunctionExpressionEvaluator(expression));\n-          } catch (Exception e) {\n-            LOGGER.error(\"Caught exception while constructing expression evaluator for: {}, skipping\", expression, e);\n-          }\n-        }\n+      ExpressionEvaluator expressionEvaluator = ExpressionEvaluatorFactory.getExpressionEvaluator(fieldSpec);\n+      if (expressionEvaluator != null) {\n+        _expressionEvaluators.put(fieldSpec.getName(), expressionEvaluator);\n       }\n     }\n   }\n \n   @Override\n   public GenericRow transform(GenericRow record) {\n-    for (Map.Entry<String, FunctionExpressionEvaluator> entry : _expressionEvaluators.entrySet()) {\n+    for (Map.Entry<String, ExpressionEvaluator> entry : _expressionEvaluators.entrySet()) {\n       String column = entry.getKey();\n-      // Skip transformation if column value already exist\n+      ExpressionEvaluator transformExpressionEvaluator = entry.getValue();\n+      // Skip transformation if column value already exist. Value can exist for time transformation (incoming name = outgoing name)\n       // NOTE: column value might already exist for OFFLINE data\n-      if (record.getValue(column) == null) {\n-        record.putValue(column, entry.getValue().evaluate(record));\n+      if (record.getValue(column) == null || column.equals(_timeColumn)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ad57c497e4ff89fd1130df08bcae46e9cc4f70a"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzgwMDAzOQ==", "bodyText": "You may have another SchemaUtils in pinot-spi. I don't have preference for the exact name, but recommend making it ***Utils as it is a util class.", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407800039", "createdAt": "2020-04-14T00:44:09Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-plugins/pinot-input-format/pinot-avro-base/src/main/java/org/apache/pinot/plugin/inputformat/avro/AvroRecordReader.java", "diffHunk": "@@ -24,12 +24,11 @@\n import javax.annotation.Nullable;\n import org.apache.avro.file.DataFileStream;\n import org.apache.avro.generic.GenericRecord;\n-import org.apache.pinot.spi.data.FieldSpec;\n import org.apache.pinot.spi.data.Schema;\n import org.apache.pinot.spi.data.readers.GenericRow;\n import org.apache.pinot.spi.data.readers.RecordReader;\n import org.apache.pinot.spi.data.readers.RecordReaderConfig;\n-import org.apache.pinot.spi.data.readers.RecordReaderUtils;\n+import org.apache.pinot.spi.data.function.evaluators.SourceFieldNameExtractor;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzNjAyOQ=="}, "originalCommit": {"oid": "865922d017e139b54ab245b84e33d1a495f6f978"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzgwMTA0Nw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    requireNonNull(indexingSchema, \"indexingSchema is null\");\n          \n          \n            \n                    Preconditions.checkState(indexingSchema != null, \"Schema must be provided\");\n          \n      \n    \n    \n  \n\nAlso remove the static import", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407801047", "createdAt": "2020-04-14T00:47:43Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-plugins/pinot-input-format/pinot-confluent-avro/src/main/java/org/apache/pinot/plugin/inputformat/avro/confluent/KafkaConfluentSchemaRegistryAvroMessageDecoder.java", "diffHunk": "@@ -44,13 +46,14 @@\n     private KafkaAvroDeserializer deserializer;\n     private RecordExtractor<Record> avroRecordConverter;\n     private String topicName;\n-    private Schema pinotSchema;\n+    private List<String> _sourceFieldNames;\n \n     @Override\n     public void init(Map<String, String> props, Schema indexingSchema, String topicName) throws Exception {\n         checkState(props.containsKey(SCHEMA_REGISTRY_REST_URL), \"Missing required property '%s'\", SCHEMA_REGISTRY_REST_URL);\n         String schemaRegistryUrl = props.get(SCHEMA_REGISTRY_REST_URL);\n-        pinotSchema = requireNonNull(indexingSchema, \"indexingSchema is null\");\n+        requireNonNull(indexingSchema, \"indexingSchema is null\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ad57c497e4ff89fd1130df08bcae46e9cc4f70a"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzgwMjg4NA==", "bodyText": "(Critical) ORC might not work with the extractor model because it is not read row-by-row but batch-by-batch.\nI would recommend reverting the change on ORCRecordReader and leave it as is. I'm working on re-do this record reader.", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407802884", "createdAt": "2020-04-14T00:54:22Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-plugins/pinot-input-format/pinot-orc/src/main/java/org/apache/pinot/plugin/inputformat/orc/ORCRecordExtractor.java", "diffHunk": "@@ -0,0 +1,144 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.plugin.inputformat.orc;\n+\n+import com.google.common.collect.ImmutableList;\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.hadoop.hive.ql.exec.vector.ColumnVector;\n+import org.apache.hadoop.hive.ql.exec.vector.VectorizedRowBatch;\n+import org.apache.hadoop.io.BooleanWritable;\n+import org.apache.hadoop.io.ByteWritable;\n+import org.apache.hadoop.io.BytesWritable;\n+import org.apache.hadoop.io.DoubleWritable;\n+import org.apache.hadoop.io.FloatWritable;\n+import org.apache.hadoop.io.IntWritable;\n+import org.apache.hadoop.io.LongWritable;\n+import org.apache.hadoop.io.NullWritable;\n+import org.apache.hadoop.io.ShortWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.io.WritableComparable;\n+import org.apache.orc.TypeDescription;\n+import org.apache.orc.mapred.OrcList;\n+import org.apache.orc.mapred.OrcMapredRecordReader;\n+import org.apache.pinot.spi.data.readers.GenericRow;\n+import org.apache.pinot.spi.data.readers.RecordExtractor;\n+import org.apache.pinot.spi.data.readers.RecordExtractorConfig;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Extractor for ORC records\n+ */\n+public class ORCRecordExtractor implements RecordExtractor<VectorizedRowBatch> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ad57c497e4ff89fd1130df08bcae46e9cc4f70a"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzgwMzI1MA==", "bodyText": "I think this test will fail if you create a file with more than 1 records.", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407803250", "createdAt": "2020-04-14T00:55:40Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-plugins/pinot-input-format/pinot-orc/src/test/java/org/apache/pinot/plugin/inputformat/orc/ORCRecordExtractorTest.java", "diffHunk": "@@ -0,0 +1,101 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.plugin.inputformat.orc;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.DoubleWritable;\n+import org.apache.hadoop.io.IntWritable;\n+import org.apache.hadoop.io.LongWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.orc.OrcFile;\n+import org.apache.orc.TypeDescription;\n+import org.apache.orc.Writer;\n+import org.apache.orc.mapred.OrcList;\n+import org.apache.orc.mapred.OrcMapredRecordWriter;\n+import org.apache.orc.mapred.OrcStruct;\n+import org.apache.pinot.spi.data.readers.AbstractRecordExtractorTest;\n+import org.apache.pinot.spi.data.readers.RecordReader;\n+\n+\n+/**\n+ * Tests the {@link ORCRecordExtractor} using a schema containing groovy transform functions\n+ */\n+public class ORCRecordExtractorTest extends AbstractRecordExtractorTest {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ad57c497e4ff89fd1130df08bcae46e9cc4f70a"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzgwNDIxMw==", "bodyText": "Just checked the code (DataTypeTransformer). Based on the current behavior, we support the following data types:\nSV: Boolean, Byte, Character, Short, Integer, Long, Float, Double, String, byte[]\nMV: Object[] or List of Byte, Character, Short, Integer, Long, Float, Double, String\nI vote for not using Boolean, Byte, Character and Short to keep it simple, but it is not done inside each RecordExtractor. We might want to track this issue somewhere.", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407804213", "createdAt": "2020-04-14T00:59:04Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/ExpressionEvaluator.java", "diffHunk": "@@ -0,0 +1,43 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import java.util.List;\n+import org.apache.pinot.spi.data.readers.GenericRow;\n+\n+\n+/**\n+ * Interface for evaluators of transform function expressions of schema field specs\n+ * They transformFunction follows the convention:\n+ *  \"transformFunction\": \"FunctionType({function}, argument1, argument2,...argumentN)\"\n+ *  For example,\n+ *  \"transformFunction\" : \"Groovy({firstName + ' ' + lastName}, firstName, lastName)\"\n+ */\n+public interface ExpressionEvaluator {\n+\n+  /**\n+   * Get the arguments of the function\n+   */\n+  List<String> getArguments();\n+\n+  /**\n+   * Evaluate the function on the generic row and return the result\n+   */\n+  Object evaluate(GenericRow genericRow);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzY4NzA1Mw=="}, "originalCommit": {"oid": "276fba0688677fc04893d25d3fc237fd3cf6ea68"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzgwNjAzOA==", "bodyText": "This comment is not addressed", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407806038", "createdAt": "2020-04-14T01:05:55Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/readers/RecordExtractor.java", "diffHunk": "@@ -18,16 +18,28 @@\n  */\n package org.apache.pinot.spi.data.readers;\n \n-import org.apache.pinot.spi.data.Schema;\n+import java.util.List;\n \n+\n+/**\n+ * Extracts fields from input records\n+ * @param <T> The format of the input record\n+ */\n public interface RecordExtractor<T> {\n+\n+  /**\n+   * Initialize the record extractor with its config\n+   */\n+  default void init(RecordExtractorConfig recordExtractorConfig) {\n+  }\n+\n   /**\n-   * TODO Add text to this javadoc\n+   * Extracts fields as listed in the sourceFieldNames from the given input record and sets them into the GenericRow\n    *\n-   * @param schema\n-   * @param from\n-   * @param to\n-   * @return\n+   * @param sourceFieldNames List of field names to extract from the provided input record\n+   * @param from The input record\n+   * @param to The output GenericRow\n+   * @return The output GenericRow\n    */\n-  GenericRow extract(Schema schema, T from, GenericRow to);\n+  GenericRow extract(List<String> sourceFieldNames, T from, GenericRow to);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzIzNzExOA=="}, "originalCommit": {"oid": "865922d017e139b54ab245b84e33d1a495f6f978"}, "originalPosition": 34}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkyNTQwODUz", "url": "https://github.com/apache/pinot/pull/5238#pullrequestreview-392540853", "createdAt": "2020-04-14T01:19:00Z", "commit": {"oid": "3ad57c497e4ff89fd1130df08bcae46e9cc4f70a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwMToxOTowMVrOGE6uLQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwMToxOTowMVrOGE6uLQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzgwOTU4MQ==", "bodyText": "Wrong format", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407809581", "createdAt": "2020-04-14T01:19:01Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-plugins/pinot-input-format/pinot-orc/src/test/java/org/apache/pinot/plugin/inputformat/orc/ORCRecordExtractorTest.java", "diffHunk": "@@ -0,0 +1,101 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.plugin.inputformat.orc;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.hadoop.io.DoubleWritable;\n+import org.apache.hadoop.io.IntWritable;\n+import org.apache.hadoop.io.LongWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.orc.OrcFile;\n+import org.apache.orc.TypeDescription;\n+import org.apache.orc.Writer;\n+import org.apache.orc.mapred.OrcList;\n+import org.apache.orc.mapred.OrcMapredRecordWriter;\n+import org.apache.orc.mapred.OrcStruct;\n+import org.apache.pinot.spi.data.readers.AbstractRecordExtractorTest;\n+import org.apache.pinot.spi.data.readers.RecordReader;\n+\n+\n+/**\n+ * Tests the {@link ORCRecordExtractor} using a schema containing groovy transform functions\n+ */\n+public class ORCRecordExtractorTest extends AbstractRecordExtractorTest {\n+\n+  private final File _dataFile = new File(_tempDir, \"events.orc\");\n+\n+  /**\n+   * Create an ORCRecordReader\n+   */\n+  @Override\n+  protected RecordReader createRecordReader()\n+      throws IOException {\n+    ORCRecordReader orcRecordReader = new ORCRecordReader();\n+    orcRecordReader.init(_dataFile, _pinotSchema, null);\n+    return orcRecordReader;\n+  }\n+\n+  /**\n+   * Create an ORC input file using the input records\n+   */\n+  @Override\n+  protected void createInputFile()\n+      throws IOException {\n+    TypeDescription schema = TypeDescription.createStruct();\n+    schema.addField(\"userID\", TypeDescription.createInt());\n+    schema.addField(\"firstName\", TypeDescription.createString());\n+    schema.addField(\"lastName\", TypeDescription.createString());\n+    TypeDescription typeBids = TypeDescription.createList(TypeDescription.createInt());\n+    schema.addField(\"bids\", typeBids);\n+    schema.addField(\"campaignInfo\", TypeDescription.createString());\n+    schema.addField(\"cost\", TypeDescription.createDouble());\n+    schema.addField(\"timestamp\", TypeDescription.createLong());\n+\n+    Writer writer = OrcFile.createWriter(new Path(_dataFile.getAbsolutePath()),\n+        OrcFile.writerOptions(new Configuration()).setSchema(schema));\n+    OrcMapredRecordWriter mrRecordWriter = new OrcMapredRecordWriter(writer);\n+    for (Map<String, Object> inputRecord : _inputRecords) {\n+      OrcStruct struct = new OrcStruct(schema);\n+      Integer userID = (Integer) inputRecord.get(\"userID\");\n+      struct.setFieldValue(\"userID\", userID == null ? null : new IntWritable(userID));\n+      String firstName = (String) inputRecord.get(\"firstName\");\n+      struct.setFieldValue(\"firstName\", firstName == null ? null : new Text(firstName));\n+      struct.setFieldValue(\"lastName\", new Text((String) inputRecord.get(\"lastName\")));\n+      List<Integer> bids = (List<Integer>) inputRecord.get(\"bids\");\n+      if (bids != null) {\n+        OrcList<IntWritable> bidsList = new OrcList<>(typeBids);\n+        for (Integer bid : bids) {\n+          bidsList.add(new IntWritable(bid));\n+        }\n+        struct.setFieldValue(\"bids\", bidsList);\n+      } else {\n+        struct.setFieldValue(\"bids\", null);\n+      }\n+      struct.setFieldValue(\"campaignInfo\", new Text((String) inputRecord.get(\"campaignInfo\")));\n+      struct.setFieldValue(\"cost\", new DoubleWritable((Double) inputRecord.get(\"cost\")));\n+      struct.setFieldValue(\"timestamp\", new LongWritable((Long) inputRecord.get(\"timestamp\")));\n+      mrRecordWriter.write(null, struct);\n+    } mrRecordWriter.close(null);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ad57c497e4ff89fd1130df08bcae46e9cc4f70a"}, "originalPosition": 99}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkyNTQ1NDM0", "url": "https://github.com/apache/pinot/pull/5238#pullrequestreview-392545434", "createdAt": "2020-04-14T01:34:13Z", "commit": {"oid": "3ad57c497e4ff89fd1130df08bcae46e9cc4f70a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwMTozNDoxM1rOGE6-sA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwMTozNDoxM1rOGE6-sA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzgxMzgwOA==", "bodyText": "Please remove this log message, it will show up in every input message.  We don't seem to be logging this in other extractors either", "url": "https://github.com/apache/pinot/pull/5238#discussion_r407813808", "createdAt": "2020-04-14T01:34:13Z", "author": {"login": "mcvsubbu"}, "path": "pinot-plugins/pinot-input-format/pinot-orc/src/main/java/org/apache/pinot/plugin/inputformat/orc/ORCRecordExtractor.java", "diffHunk": "@@ -0,0 +1,144 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.plugin.inputformat.orc;\n+\n+import com.google.common.collect.ImmutableList;\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.hadoop.hive.ql.exec.vector.ColumnVector;\n+import org.apache.hadoop.hive.ql.exec.vector.VectorizedRowBatch;\n+import org.apache.hadoop.io.BooleanWritable;\n+import org.apache.hadoop.io.ByteWritable;\n+import org.apache.hadoop.io.BytesWritable;\n+import org.apache.hadoop.io.DoubleWritable;\n+import org.apache.hadoop.io.FloatWritable;\n+import org.apache.hadoop.io.IntWritable;\n+import org.apache.hadoop.io.LongWritable;\n+import org.apache.hadoop.io.NullWritable;\n+import org.apache.hadoop.io.ShortWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.hadoop.io.WritableComparable;\n+import org.apache.orc.TypeDescription;\n+import org.apache.orc.mapred.OrcList;\n+import org.apache.orc.mapred.OrcMapredRecordReader;\n+import org.apache.pinot.spi.data.readers.GenericRow;\n+import org.apache.pinot.spi.data.readers.RecordExtractor;\n+import org.apache.pinot.spi.data.readers.RecordExtractorConfig;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Extractor for ORC records\n+ */\n+public class ORCRecordExtractor implements RecordExtractor<VectorizedRowBatch> {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(ORCRecordExtractor.class);\n+\n+  private TypeDescription _orcSchema;\n+\n+  @Override\n+  public void init(RecordExtractorConfig recordExtractorConfig) {\n+    _orcSchema = ((ORCRecordExtractorConfig) recordExtractorConfig).getOrcSchema();\n+  }\n+\n+  @Override\n+  public GenericRow extract(List<String> sourceFieldNames, VectorizedRowBatch from, GenericRow to) {\n+    // TODO: use Pinot schema to fill the values to handle missing column and default values properly\n+\n+    // ORC's TypeDescription is the equivalent of a schema. The way we will support ORC in Pinot\n+    // will be to get the top level struct that contains all our fields and look through its\n+    // children to determine the fields in our schemas.\n+    if (_orcSchema.getCategory().equals(TypeDescription.Category.STRUCT)) {\n+      List<TypeDescription> orcSchemaChildren = _orcSchema.getChildren();\n+      for (int i = 0; i < orcSchemaChildren.size(); i++) {\n+        // Get current column in schema\n+        String currColumnName = _orcSchema.getFieldNames().get(i);\n+        if (!sourceFieldNames.contains(currColumnName)) {\n+          LOGGER.warn(\"Skipping column {} because it is not in source columns\", currColumnName);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ad57c497e4ff89fd1130df08bcae46e9cc4f70a"}, "originalPosition": 74}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkyNTc0MzYx", "url": "https://github.com/apache/pinot/pull/5238#pullrequestreview-392574361", "createdAt": "2020-04-14T03:09:30Z", "commit": {"oid": "e12c035a961305656393a4802bffc2c809155525"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7740e915ae6f773b6be7468ffda9b5065aadfb5d", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/7740e915ae6f773b6be7468ffda9b5065aadfb5d", "committedDate": "2020-04-14T03:22:05Z", "message": "First pass of transform functions using Groovy"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6ac6ff18edc3d7934f0bc350526527dac04e72c5", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/6ac6ff18edc3d7934f0bc350526527dac04e72c5", "committedDate": "2020-04-14T03:22:05Z", "message": "Tests for RecordExtractors, Evaluators, SourceFieldName utility, ExpressionTransformer, Map type, TimeSpec conversion and more"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2926598fefb24f28c685af92a196c0ed68b80d1d", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/2926598fefb24f28c685af92a196c0ed68b80d1d", "committedDate": "2020-04-14T03:22:05Z", "message": "More Groovy test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "93a80d575d31ef78489dbcf74d70357a471c1dc6", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/93a80d575d31ef78489dbcf74d70357a471c1dc6", "committedDate": "2020-04-14T03:22:05Z", "message": "Javadocs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c6b3718e0223c15f53ca06064896f8d3d0d31a51", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/c6b3718e0223c15f53ca06064896f8d3d0d31a51", "committedDate": "2020-04-14T03:22:05Z", "message": "Corner cases in Time"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "398af9b4d30433e614a7439da658391a6bfdae99", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/398af9b4d30433e614a7439da658391a6bfdae99", "committedDate": "2020-04-14T03:22:05Z", "message": "Review comments - Nullable, newline, blank lines, some refactoring"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e0b3619d9d644e73aacac676c0063eea393dc0c3", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/e0b3619d9d644e73aacac676c0063eea393dc0c3", "committedDate": "2020-04-14T03:22:05Z", "message": "Remove unused code form RecordReaderUtils"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f8474d4f05455712f490732b3065d169a93b79d6", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/f8474d4f05455712f490732b3065d169a93b79d6", "committedDate": "2020-04-14T03:22:05Z", "message": "Addressing some review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9fec7577082fcf10f6f3bdc1d2cf8a0ab4b9f1c4", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/9fec7577082fcf10f6f3bdc1d2cf8a0ab4b9f1c4", "committedDate": "2020-04-14T03:22:05Z", "message": "Make JsonRecordExtractor not use the generic RecordReaderUtils for conversion"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ec6f299710c1e1e9a45e3965986fb34eb23f3ea7", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/ec6f299710c1e1e9a45e3965986fb34eb23f3ea7", "committedDate": "2020-04-14T03:22:05Z", "message": "Fix AvroRecordToPinotRowGeneratortest"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "55c789aad03deedc729a097cc86f4b353b7c4a58", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/55c789aad03deedc729a097cc86f4b353b7c4a58", "committedDate": "2020-04-14T03:22:05Z", "message": "Addressed review comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkzMDE5NzAy", "url": "https://github.com/apache/pinot/pull/5238#pullrequestreview-393019702", "createdAt": "2020-04-14T15:04:23Z", "commit": {"oid": "e12c035a961305656393a4802bffc2c809155525"}, "state": "COMMENTED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQxNTowNDoyM1rOGFTKNQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQxNTo1MzoxM1rOGFVbOg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODIwOTk3Mw==", "bodyText": "Can value be an instance of primitive array?", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408209973", "createdAt": "2020-04-14T15:04:23Z", "author": {"login": "mayankshriv"}, "path": "pinot-plugins/pinot-input-format/pinot-avro-base/src/main/java/org/apache/pinot/plugin/inputformat/avro/AvroUtils.java", "diffHunk": "@@ -305,46 +301,23 @@ public static boolean isSingleValueField(Field field) {\n     }\n   }\n \n-  @SuppressWarnings(\"unchecked\")\n-  public static void extractField(FieldSpec fieldSpec, GenericRecord from, GenericRow to) {\n-    String fieldName = fieldSpec.getName();\n-\n-    // Handle the Map type\n-    if (fieldName.endsWith(MAP_KEY_COLUMN_SUFFIX)) {\n-      String avroFieldName = fieldName.substring(0, fieldName.length() - MAP_KEY_COLUMN_SUFFIX.length());\n-      Map map = (Map) from.get(avroFieldName);\n-      if (map != null) {\n-        // Sort the keys so that the order is deterministic\n-        TreeSet sortedKeys = new TreeSet(map.keySet());\n-        to.putField(fieldName, RecordReaderUtils.convert(fieldSpec, sortedKeys));\n-        return;\n-      }\n-    } else if (fieldName.endsWith(MAP_VALUE_COLUMN_SUFFIX)) {\n-      String avroFieldName = fieldName.substring(0, fieldName.length() - MAP_VALUE_COLUMN_SUFFIX.length());\n-      Map map = (Map) from.get(avroFieldName);\n-      if (map != null) {\n-        // Sort the keys so that the order is deterministic\n-        TreeMap sortedMap = new TreeMap<>(map);\n-        to.putField(fieldName, RecordReaderUtils.convert(fieldSpec, sortedMap.values()));\n-        return;\n-      }\n-    }\n-    to.putField(fieldName, RecordReaderUtils.convert(fieldSpec, convert(fieldSpec, from.get(fieldName))));\n-  }\n-\n   /**\n-   * Converts the value based on the given field spec.\n+   * Converts the value to a single-valued value or a multi-valued value\n    */\n-  public static Object convert(FieldSpec fieldSpec, @Nullable Object value) {\n-    if (fieldSpec.isSingleValueField()) {\n-      return handleSingleValue(value);\n+  public static Object convert(Object value) {\n+    Object convertedValue;\n+    if (value instanceof Collection) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e12c035a961305656393a4802bffc2c809155525"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODIxMDc0OA==", "bodyText": "So we no longer need source schema?", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408210748", "createdAt": "2020-04-14T15:05:24Z", "author": {"login": "mayankshriv"}, "path": "pinot-plugins/pinot-input-format/pinot-avro-base/src/main/java/org/apache/pinot/plugin/inputformat/avro/AvroRecordExtractor.java", "diffHunk": "@@ -18,18 +18,31 @@\n  */\n package org.apache.pinot.plugin.inputformat.avro;\n \n-import org.apache.avro.generic.GenericData;\n-import org.apache.pinot.spi.data.FieldSpec;\n-import org.apache.pinot.spi.data.Schema;\n-import org.apache.pinot.spi.data.readers.AbstractBaseRecordExtractor;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import org.apache.avro.generic.GenericRecord;\n import org.apache.pinot.spi.data.readers.GenericRow;\n+import org.apache.pinot.spi.data.readers.RecordExtractor;\n+import org.apache.pinot.spi.data.readers.RecordExtractorConfig;\n+\n+\n+/**\n+ * Extractor for Avro Records\n+ */\n+public class AvroRecordExtractor implements RecordExtractor<GenericRecord> {\n+  private List<String> _fields;\n+\n+  @Override\n+  public void init(List<String> fields, @Nullable RecordExtractorConfig recordExtractorConfig) {\n+    _fields = fields;\n+  }\n \n-public class AvroRecordExtractor extends AbstractBaseRecordExtractor<GenericData.Record> {\n   @Override\n-  public GenericRow extract(Schema schema, GenericData.Record from, GenericRow to) {\n-    for (FieldSpec fieldSpec : schema.getAllFieldSpecs()) {\n-      FieldSpec incomingFieldSpec = getFieldSpecToUse(schema, fieldSpec);\n-      AvroUtils.extractField(incomingFieldSpec, from, to);\n+  public GenericRow extract(GenericRecord from, GenericRow to) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e12c035a961305656393a4802bffc2c809155525"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODIxMzA4OQ==", "bodyText": "Probably a bit more description would help.", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408213089", "createdAt": "2020-04-14T15:08:20Z", "author": {"login": "mayankshriv"}, "path": "pinot-plugins/pinot-input-format/pinot-avro-base/src/main/java/org/apache/pinot/plugin/inputformat/avro/AvroUtils.java", "diffHunk": "@@ -305,46 +301,23 @@ public static boolean isSingleValueField(Field field) {\n     }\n   }\n \n-  @SuppressWarnings(\"unchecked\")\n-  public static void extractField(FieldSpec fieldSpec, GenericRecord from, GenericRow to) {\n-    String fieldName = fieldSpec.getName();\n-\n-    // Handle the Map type\n-    if (fieldName.endsWith(MAP_KEY_COLUMN_SUFFIX)) {\n-      String avroFieldName = fieldName.substring(0, fieldName.length() - MAP_KEY_COLUMN_SUFFIX.length());\n-      Map map = (Map) from.get(avroFieldName);\n-      if (map != null) {\n-        // Sort the keys so that the order is deterministic\n-        TreeSet sortedKeys = new TreeSet(map.keySet());\n-        to.putField(fieldName, RecordReaderUtils.convert(fieldSpec, sortedKeys));\n-        return;\n-      }\n-    } else if (fieldName.endsWith(MAP_VALUE_COLUMN_SUFFIX)) {\n-      String avroFieldName = fieldName.substring(0, fieldName.length() - MAP_VALUE_COLUMN_SUFFIX.length());\n-      Map map = (Map) from.get(avroFieldName);\n-      if (map != null) {\n-        // Sort the keys so that the order is deterministic\n-        TreeMap sortedMap = new TreeMap<>(map);\n-        to.putField(fieldName, RecordReaderUtils.convert(fieldSpec, sortedMap.values()));\n-        return;\n-      }\n-    }\n-    to.putField(fieldName, RecordReaderUtils.convert(fieldSpec, convert(fieldSpec, from.get(fieldName))));\n-  }\n-\n   /**\n-   * Converts the value based on the given field spec.\n+   * Converts the value to a single-valued value or a multi-valued value\n    */\n-  public static Object convert(FieldSpec fieldSpec, @Nullable Object value) {\n-    if (fieldSpec.isSingleValueField()) {\n-      return handleSingleValue(value);\n+  public static Object convert(Object value) {\n+    Object convertedValue;\n+    if (value instanceof Collection) {\n+      convertedValue = handleMultiValue((Collection) value);\n+    } else if (value instanceof Map) {\n+      convertedValue = handleMap((Map) value);\n     } else {\n-      return handleMultiValue((Collection) value);\n+      convertedValue = handleSingleValue(value);\n     }\n+    return convertedValue;\n   }\n \n   /**\n-   * Converts the value based on the given field spec.\n+   * Converts the value to a single-valued value", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e12c035a961305656393a4802bffc2c809155525"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODIxMzQ2MA==", "bodyText": "s/withing/within", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408213460", "createdAt": "2020-04-14T15:08:47Z", "author": {"login": "mayankshriv"}, "path": "pinot-plugins/pinot-input-format/pinot-avro-base/src/main/java/org/apache/pinot/plugin/inputformat/avro/AvroUtils.java", "diffHunk": "@@ -368,6 +341,21 @@ public static Object handleMultiValue(@Nullable Collection values) {\n     for (Object value : values) {\n       list.add(handleSingleValue(value));\n     }\n-    return list;\n+    return RecordReaderUtils.convertMultiValue(list);\n+  }\n+\n+  /**\n+   * Converts the values withing the map to single-valued values", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e12c035a961305656393a4802bffc2c809155525"}, "originalPosition": 109}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODI0MTA1MA==", "bodyText": "Is genericRecord the right argument for this api, to make it more general purpose evaluator?", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408241050", "createdAt": "2020-04-14T15:45:12Z", "author": {"login": "mayankshriv"}, "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/ExpressionEvaluator.java", "diffHunk": "@@ -0,0 +1,43 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import java.util.List;\n+import org.apache.pinot.spi.data.readers.GenericRow;\n+\n+\n+/**\n+ * Interface for evaluators of transform function expressions of schema field specs\n+ * They transformFunction follows the convention:\n+ *  \"transformFunction\": \"FunctionType({function}, argument1, argument2,...argumentN)\"\n+ *  For example,\n+ *  \"transformFunction\" : \"Groovy({firstName + ' ' + lastName}, firstName, lastName)\"\n+ */\n+public interface ExpressionEvaluator {\n+\n+  /**\n+   * Get the arguments of the function\n+   */\n+  List<String> getArguments();\n+\n+  /**\n+   * Evaluate the function on the generic row and return the result\n+   */\n+  Object evaluate(GenericRow genericRow);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e12c035a961305656393a4802bffc2c809155525"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODI0NDI0Mg==", "bodyText": "Is this really expression evaluator, or more of a function evaluator? For example, the function could be a complex groovy script?  Also, how about nested functions?", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408244242", "createdAt": "2020-04-14T15:49:19Z", "author": {"login": "mayankshriv"}, "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/ExpressionEvaluator.java", "diffHunk": "@@ -0,0 +1,43 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import java.util.List;\n+import org.apache.pinot.spi.data.readers.GenericRow;\n+\n+\n+/**\n+ * Interface for evaluators of transform function expressions of schema field specs\n+ * They transformFunction follows the convention:\n+ *  \"transformFunction\": \"FunctionType({function}, argument1, argument2,...argumentN)\"\n+ *  For example,\n+ *  \"transformFunction\" : \"Groovy({firstName + ' ' + lastName}, firstName, lastName)\"\n+ */\n+public interface ExpressionEvaluator {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e12c035a961305656393a4802bffc2c809155525"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODI0NjA1MA==", "bodyText": "Is this the only syntax available for a groovy script?", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408246050", "createdAt": "2020-04-14T15:51:45Z", "author": {"login": "mayankshriv"}, "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/GroovyExpressionEvaluator.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import com.google.common.base.Splitter;\n+import groovy.lang.Binding;\n+import groovy.lang.GroovyShell;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.pinot.spi.data.readers.GenericRow;\n+\n+\n+/**\n+ * An {@link ExpressionEvaluator} for evaluating schema transform expressions written in Groovy.\n+ * GroovyShell is used to execute expressions.\n+ *\n+ * The transform expression must follow the convention Groovy({expression}, arguments1, argument2...)\n+ * For example:\n+ * \"dimensionFieldSpecs\": [\n+ *     {\n+ *       \"name\": \"fullName\",\n+ *       \"dataType\": \"STRING\",\n+ *       \"transformFunction\": \"Groovy({firstName+' '+lastName}, firstName, lastName)\"\n+ *     }\n+ *  ]\n+ */\n+public class GroovyExpressionEvaluator implements ExpressionEvaluator {\n+\n+  private static final String GROOVY_EXPRESSION_PREFIX = \"Groovy\";\n+  private static final String GROOVY_FUNCTION_REGEX = \"Groovy\\\\(\\\\{(?<script>.+)}(,(?<arguments>.+))?\\\\)\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e12c035a961305656393a4802bffc2c809155525"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODI0NzA5OA==", "bodyText": "Checkout Groovy Binding for argument biniding.", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408247098", "createdAt": "2020-04-14T15:53:13Z", "author": {"login": "mayankshriv"}, "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/GroovyExpressionEvaluator.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import com.google.common.base.Splitter;\n+import groovy.lang.Binding;\n+import groovy.lang.GroovyShell;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.pinot.spi.data.readers.GenericRow;\n+\n+\n+/**\n+ * An {@link ExpressionEvaluator} for evaluating schema transform expressions written in Groovy.\n+ * GroovyShell is used to execute expressions.\n+ *\n+ * The transform expression must follow the convention Groovy({expression}, arguments1, argument2...)\n+ * For example:\n+ * \"dimensionFieldSpecs\": [\n+ *     {\n+ *       \"name\": \"fullName\",\n+ *       \"dataType\": \"STRING\",\n+ *       \"transformFunction\": \"Groovy({firstName+' '+lastName}, firstName, lastName)\"\n+ *     }\n+ *  ]\n+ */\n+public class GroovyExpressionEvaluator implements ExpressionEvaluator {\n+\n+  private static final String GROOVY_EXPRESSION_PREFIX = \"Groovy\";\n+  private static final String GROOVY_FUNCTION_REGEX = \"Groovy\\\\(\\\\{(?<script>.+)}(,(?<arguments>.+))?\\\\)\";\n+  private static final Pattern GROOVY_FUNCTION_PATTERN =\n+      Pattern.compile(GROOVY_FUNCTION_REGEX, Pattern.CASE_INSENSITIVE);\n+  private static final String ARGUMENTS_GROUP_NAME = \"arguments\";\n+  private static final String SCRIPT_GROUP_NAME = \"script\";\n+  private static final String ARGUMENTS_SEPARATOR = \",\";\n+\n+  private List<String> _arguments;\n+  private String _script;\n+\n+  public GroovyExpressionEvaluator(String transformExpression) {\n+    Matcher matcher = GROOVY_FUNCTION_PATTERN.matcher(transformExpression);\n+    if (matcher.matches()) {\n+      _script = matcher.group(SCRIPT_GROUP_NAME);\n+\n+      String arguments = matcher.group(ARGUMENTS_GROUP_NAME);\n+      if (arguments != null) {\n+        _arguments = Splitter.on(ARGUMENTS_SEPARATOR).trimResults().splitToList(arguments);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e12c035a961305656393a4802bffc2c809155525"}, "originalPosition": 67}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2570bf792aa94dca41909cdd3c9a09b223285b74", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/2570bf792aa94dca41909cdd3c9a09b223285b74", "committedDate": "2020-04-14T22:14:13Z", "message": "Simplify time conversion logic"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e12c035a961305656393a4802bffc2c809155525", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/e12c035a961305656393a4802bffc2c809155525", "committedDate": "2020-04-14T02:49:43Z", "message": "Addressed review comments"}, "afterCommit": {"oid": "2570bf792aa94dca41909cdd3c9a09b223285b74", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/2570bf792aa94dca41909cdd3c9a09b223285b74", "committedDate": "2020-04-14T22:14:13Z", "message": "Simplify time conversion logic"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkzMzM5NzQ2", "url": "https://github.com/apache/pinot/pull/5238#pullrequestreview-393339746", "createdAt": "2020-04-14T22:29:07Z", "commit": {"oid": "2570bf792aa94dca41909cdd3c9a09b223285b74"}, "state": "COMMENTED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQyMjoyOTowN1rOGFjPWw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQyMjo0MDoyNlrOGFjfhQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ3MzQzNQ==", "bodyText": "Argument should only contain _incomingTimeColumn?", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408473435", "createdAt": "2020-04-14T22:29:07Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/DefaultTimeSpecEvaluator.java", "diffHunk": "@@ -0,0 +1,72 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import java.util.List;\n+import org.apache.pinot.spi.data.TimeFieldSpec;\n+import org.apache.pinot.spi.data.TimeGranularitySpec;\n+import org.apache.pinot.spi.data.readers.GenericRow;\n+import org.apache.pinot.spi.utils.TimeConverter;\n+import org.apache.pinot.spi.utils.TimeUtils;\n+\n+\n+/**\n+ * The {@code DefaultTimeSpecEvaluator} class will convert the time value based on the {@link TimeFieldSpec}.\n+ */\n+public class DefaultTimeSpecEvaluator implements ExpressionEvaluator {\n+  private String _incomingTimeColumn;\n+  private String _outgoingTimeColumn;\n+  private TimeConverter _incomingTimeConverter;\n+  private TimeConverter _outgoingTimeConverter;\n+  private boolean _isValidated = false;\n+\n+  public DefaultTimeSpecEvaluator(TimeGranularitySpec incomingGranularitySpec,\n+      TimeGranularitySpec outgoingGranularitySpec) {\n+    Preconditions.checkState(!incomingGranularitySpec.equals(outgoingGranularitySpec));\n+    _incomingTimeColumn = incomingGranularitySpec.getName();\n+    _outgoingTimeColumn = outgoingGranularitySpec.getName();\n+    Preconditions.checkState(!_incomingTimeColumn.equals(_outgoingTimeColumn));\n+    _incomingTimeConverter = new TimeConverter(incomingGranularitySpec);\n+    _outgoingTimeConverter = new TimeConverter(outgoingGranularitySpec);\n+  }\n+\n+  @Override\n+  public List<String> getArguments() {\n+    return Lists.newArrayList(_incomingTimeColumn, _outgoingTimeColumn);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2570bf792aa94dca41909cdd3c9a09b223285b74"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ3NDExNQ==", "bodyText": "The first 4 variables can be final", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408474115", "createdAt": "2020-04-14T22:31:01Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/DefaultTimeSpecEvaluator.java", "diffHunk": "@@ -0,0 +1,72 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import java.util.List;\n+import org.apache.pinot.spi.data.TimeFieldSpec;\n+import org.apache.pinot.spi.data.TimeGranularitySpec;\n+import org.apache.pinot.spi.data.readers.GenericRow;\n+import org.apache.pinot.spi.utils.TimeConverter;\n+import org.apache.pinot.spi.utils.TimeUtils;\n+\n+\n+/**\n+ * The {@code DefaultTimeSpecEvaluator} class will convert the time value based on the {@link TimeFieldSpec}.\n+ */\n+public class DefaultTimeSpecEvaluator implements ExpressionEvaluator {\n+  private String _incomingTimeColumn;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2570bf792aa94dca41909cdd3c9a09b223285b74"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ3NTAxNg==", "bodyText": "Directly throw the exception out to prevent unexpected data ingested", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408475016", "createdAt": "2020-04-14T22:33:30Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/ExpressionEvaluatorFactory.java", "diffHunk": "@@ -0,0 +1,111 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import javax.annotation.Nullable;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.TimeFieldSpec;\n+import org.apache.pinot.spi.data.TimeGranularitySpec;\n+import org.apache.pinot.spi.utils.SchemaFieldExtractorUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Factory class to create an {@link ExpressionEvaluator} for the field spec based on the {@link FieldSpec#getTransformFunction()}\n+ */\n+public class ExpressionEvaluatorFactory {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(ExpressionEvaluatorFactory.class);\n+\n+  private ExpressionEvaluatorFactory() {\n+\n+  }\n+\n+  /**\n+   * Creates the {@link ExpressionEvaluator} for the given field spec\n+   *\n+   * 1. If transform expression is defined, use it to create {@link ExpressionEvaluator}\n+   * 2. For TIME column, if conversion is needed, {@link DefaultTimeSpecEvaluator} for backward compatible handling of time spec. This is needed until we migrate to {@link org.apache.pinot.spi.data.DateTimeFieldSpec}\n+   * 3. For columns ending with __KEYS or __VALUES (used for interpreting Map column in Avro), create default functions for handing the Map\n+   * 4. Return null, if none of the above\n+   */\n+  @Nullable\n+  public static ExpressionEvaluator getExpressionEvaluator(FieldSpec fieldSpec) {\n+    ExpressionEvaluator expressionEvaluator = null;\n+\n+    String columnName = fieldSpec.getName();\n+    String transformExpression = fieldSpec.getTransformFunction();\n+    if (transformExpression != null) {\n+\n+      // if transform function expression present, use it to generate function evaluator\n+      try {\n+        expressionEvaluator = getExpressionEvaluator(transformExpression);\n+      } catch (Exception e) {\n+        LOGGER.error(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2570bf792aa94dca41909cdd3c9a09b223285b74"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ3NTIwOQ==", "bodyText": "Better to throw IllegalStateException when incoming and outgoing name are the same", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408475209", "createdAt": "2020-04-14T22:34:01Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/ExpressionEvaluatorFactory.java", "diffHunk": "@@ -0,0 +1,111 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import javax.annotation.Nullable;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.TimeFieldSpec;\n+import org.apache.pinot.spi.data.TimeGranularitySpec;\n+import org.apache.pinot.spi.utils.SchemaFieldExtractorUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Factory class to create an {@link ExpressionEvaluator} for the field spec based on the {@link FieldSpec#getTransformFunction()}\n+ */\n+public class ExpressionEvaluatorFactory {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(ExpressionEvaluatorFactory.class);\n+\n+  private ExpressionEvaluatorFactory() {\n+\n+  }\n+\n+  /**\n+   * Creates the {@link ExpressionEvaluator} for the given field spec\n+   *\n+   * 1. If transform expression is defined, use it to create {@link ExpressionEvaluator}\n+   * 2. For TIME column, if conversion is needed, {@link DefaultTimeSpecEvaluator} for backward compatible handling of time spec. This is needed until we migrate to {@link org.apache.pinot.spi.data.DateTimeFieldSpec}\n+   * 3. For columns ending with __KEYS or __VALUES (used for interpreting Map column in Avro), create default functions for handing the Map\n+   * 4. Return null, if none of the above\n+   */\n+  @Nullable\n+  public static ExpressionEvaluator getExpressionEvaluator(FieldSpec fieldSpec) {\n+    ExpressionEvaluator expressionEvaluator = null;\n+\n+    String columnName = fieldSpec.getName();\n+    String transformExpression = fieldSpec.getTransformFunction();\n+    if (transformExpression != null) {\n+\n+      // if transform function expression present, use it to generate function evaluator\n+      try {\n+        expressionEvaluator = getExpressionEvaluator(transformExpression);\n+      } catch (Exception e) {\n+        LOGGER.error(\n+            \"Caught exception while constructing expression evaluator for transform expression: {}, of column: {}, skipping\",\n+            transformExpression, columnName, e);\n+      }\n+    } else if (fieldSpec.getFieldType().equals(FieldSpec.FieldType.TIME)) {\n+\n+      // for backward compatible handling of TIME field conversion\n+      TimeFieldSpec timeFieldSpec = (TimeFieldSpec) fieldSpec;\n+      TimeGranularitySpec incomingGranularitySpec = timeFieldSpec.getIncomingGranularitySpec();\n+      TimeGranularitySpec outgoingGranularitySpec = timeFieldSpec.getOutgoingGranularitySpec();\n+      if (outgoingGranularitySpec != null && !incomingGranularitySpec.equals(outgoingGranularitySpec)\n+          && !incomingGranularitySpec.getName().equals(outgoingGranularitySpec.getName())) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2570bf792aa94dca41909cdd3c9a09b223285b74"}, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ3NTY0Mw==", "bodyText": "(nit) transformExpression can never be null. Suggest moving this check to the caller", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408475643", "createdAt": "2020-04-14T22:35:13Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/ExpressionEvaluatorFactory.java", "diffHunk": "@@ -0,0 +1,111 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import javax.annotation.Nullable;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.TimeFieldSpec;\n+import org.apache.pinot.spi.data.TimeGranularitySpec;\n+import org.apache.pinot.spi.utils.SchemaFieldExtractorUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Factory class to create an {@link ExpressionEvaluator} for the field spec based on the {@link FieldSpec#getTransformFunction()}\n+ */\n+public class ExpressionEvaluatorFactory {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(ExpressionEvaluatorFactory.class);\n+\n+  private ExpressionEvaluatorFactory() {\n+\n+  }\n+\n+  /**\n+   * Creates the {@link ExpressionEvaluator} for the given field spec\n+   *\n+   * 1. If transform expression is defined, use it to create {@link ExpressionEvaluator}\n+   * 2. For TIME column, if conversion is needed, {@link DefaultTimeSpecEvaluator} for backward compatible handling of time spec. This is needed until we migrate to {@link org.apache.pinot.spi.data.DateTimeFieldSpec}\n+   * 3. For columns ending with __KEYS or __VALUES (used for interpreting Map column in Avro), create default functions for handing the Map\n+   * 4. Return null, if none of the above\n+   */\n+  @Nullable\n+  public static ExpressionEvaluator getExpressionEvaluator(FieldSpec fieldSpec) {\n+    ExpressionEvaluator expressionEvaluator = null;\n+\n+    String columnName = fieldSpec.getName();\n+    String transformExpression = fieldSpec.getTransformFunction();\n+    if (transformExpression != null) {\n+\n+      // if transform function expression present, use it to generate function evaluator\n+      try {\n+        expressionEvaluator = getExpressionEvaluator(transformExpression);\n+      } catch (Exception e) {\n+        LOGGER.error(\n+            \"Caught exception while constructing expression evaluator for transform expression: {}, of column: {}, skipping\",\n+            transformExpression, columnName, e);\n+      }\n+    } else if (fieldSpec.getFieldType().equals(FieldSpec.FieldType.TIME)) {\n+\n+      // for backward compatible handling of TIME field conversion\n+      TimeFieldSpec timeFieldSpec = (TimeFieldSpec) fieldSpec;\n+      TimeGranularitySpec incomingGranularitySpec = timeFieldSpec.getIncomingGranularitySpec();\n+      TimeGranularitySpec outgoingGranularitySpec = timeFieldSpec.getOutgoingGranularitySpec();\n+      if (outgoingGranularitySpec != null && !incomingGranularitySpec.equals(outgoingGranularitySpec)\n+          && !incomingGranularitySpec.getName().equals(outgoingGranularitySpec.getName())) {\n+        expressionEvaluator = new DefaultTimeSpecEvaluator(incomingGranularitySpec, outgoingGranularitySpec);\n+      }\n+    } else if (columnName.endsWith(SchemaFieldExtractorUtils.MAP_KEY_COLUMN_SUFFIX)) {\n+\n+      // for backward compatible handling of Map type (currently only in Avro)\n+      String sourceMapName =\n+          columnName.substring(0, columnName.length() - SchemaFieldExtractorUtils.MAP_KEY_COLUMN_SUFFIX.length());\n+      String defaultMapKeysTransformExpression = getDefaultMapKeysTransformExpression(sourceMapName);\n+      expressionEvaluator = getExpressionEvaluator(defaultMapKeysTransformExpression);\n+    } else if (columnName.endsWith(SchemaFieldExtractorUtils.MAP_VALUE_COLUMN_SUFFIX)) {\n+\n+      // for backward compatible handling of Map type in avro (currently only in Avro)\n+      String sourceMapName =\n+          columnName.substring(0, columnName.length() - SchemaFieldExtractorUtils.MAP_VALUE_COLUMN_SUFFIX.length());\n+      String defaultMapValuesTransformExpression = getDefaultMapValuesTransformExpression(sourceMapName);\n+      expressionEvaluator = getExpressionEvaluator(defaultMapValuesTransformExpression);\n+    }\n+\n+    return expressionEvaluator;\n+  }\n+\n+  private static ExpressionEvaluator getExpressionEvaluator(String transformExpression) {\n+    ExpressionEvaluator expressionEvaluator = null;\n+    if (transformExpression != null && !transformExpression.isEmpty()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2570bf792aa94dca41909cdd3c9a09b223285b74"}, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ3NjE1OQ==", "bodyText": "Is this possible? Should we throw exception here?", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408476159", "createdAt": "2020-04-14T22:36:41Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/GroovyExpressionEvaluator.java", "diffHunk": "@@ -0,0 +1,102 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import com.google.common.base.Splitter;\n+import groovy.lang.Binding;\n+import groovy.lang.GroovyShell;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.pinot.spi.data.readers.GenericRow;\n+\n+\n+/**\n+ * An {@link ExpressionEvaluator} for evaluating schema transform expressions written in Groovy.\n+ * GroovyShell is used to execute expressions.\n+ *\n+ * The transform expression must follow the convention Groovy({expression}, arguments1, argument2...)\n+ * For example:\n+ * \"dimensionFieldSpecs\": [\n+ *     {\n+ *       \"name\": \"fullName\",\n+ *       \"dataType\": \"STRING\",\n+ *       \"transformFunction\": \"Groovy({firstName+' '+lastName}, firstName, lastName)\"\n+ *     }\n+ *  ]\n+ */\n+public class GroovyExpressionEvaluator implements ExpressionEvaluator {\n+\n+  private static final String GROOVY_EXPRESSION_PREFIX = \"Groovy\";\n+  private static final String GROOVY_FUNCTION_REGEX = \"Groovy\\\\(\\\\{(?<script>.+)}(,(?<arguments>.+))?\\\\)\";\n+  private static final Pattern GROOVY_FUNCTION_PATTERN =\n+      Pattern.compile(GROOVY_FUNCTION_REGEX, Pattern.CASE_INSENSITIVE);\n+  private static final String ARGUMENTS_GROUP_NAME = \"arguments\";\n+  private static final String SCRIPT_GROUP_NAME = \"script\";\n+  private static final String ARGUMENTS_SEPARATOR = \",\";\n+\n+  private List<String> _arguments;\n+  private String _script;\n+\n+  public GroovyExpressionEvaluator(String transformExpression) {\n+    Matcher matcher = GROOVY_FUNCTION_PATTERN.matcher(transformExpression);\n+    if (matcher.matches()) {\n+      _script = matcher.group(SCRIPT_GROUP_NAME);\n+\n+      String arguments = matcher.group(ARGUMENTS_GROUP_NAME);\n+      if (arguments != null) {\n+        _arguments = Splitter.on(ARGUMENTS_SEPARATOR).trimResults().splitToList(arguments);\n+      } else {\n+        _arguments = Collections.emptyList();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2570bf792aa94dca41909cdd3c9a09b223285b74"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ3NzI4OQ==", "bodyText": "(nit) outgoingGranularitySpec will never be null because it will return incoming spec if outgoing is not set", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408477289", "createdAt": "2020-04-14T22:39:40Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-spi/src/main/java/org/apache/pinot/spi/utils/SchemaFieldExtractorUtils.java", "diffHunk": "@@ -0,0 +1,105 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.utils;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.spi.data.TimeFieldSpec;\n+import org.apache.pinot.spi.data.TimeGranularitySpec;\n+import org.apache.pinot.spi.data.function.evaluators.ExpressionEvaluator;\n+import org.apache.pinot.spi.data.function.evaluators.ExpressionEvaluatorFactory;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Extracts names of the source fields from the schema\n+ */\n+public class SchemaFieldExtractorUtils {\n+  public static final String MAP_KEY_COLUMN_SUFFIX = \"__KEYS\";\n+  public static final String MAP_VALUE_COLUMN_SUFFIX = \"__VALUES\";\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(SchemaFieldExtractorUtils.class);\n+\n+  /**\n+   * Extracts the source fields from the schema\n+   * For field specs with a transform expression defined, use the arguments provided to the function\n+   * Otherwise, use the column name as is\n+   * TODO: for now, we assume that arguments to transform function are in the source i.e. there's no columns which are derived from transformed columns\n+   */\n+  public static List<String> extract(Schema schema) {\n+    Set<String> sourceFieldNames = new HashSet<>();\n+    for (FieldSpec fieldSpec : schema.getAllFieldSpecs()) {\n+      if (!fieldSpec.isVirtualColumn()) {\n+        ExpressionEvaluator expressionEvaluator = ExpressionEvaluatorFactory.getExpressionEvaluator(fieldSpec);\n+\n+        if (expressionEvaluator != null) {\n+          sourceFieldNames.addAll(expressionEvaluator.getArguments());\n+        } else {\n+          sourceFieldNames.add(fieldSpec.getName());\n+        }\n+      }\n+    }\n+    return new ArrayList<>(sourceFieldNames);\n+  }\n+\n+  /**\n+   * Validates that for a field spec with transform function, the source column name and destination column name are exclusive\n+   * i.e. do not allow using source column name for destination column\n+   * 1. Transform function of a field spec should not use the destination column\n+   * 2. TimeFieldSpec - cannot have same name for incoming and outgoing field spec, if the specs are different\n+   */\n+  public static boolean validate(Schema schema) {\n+    for (FieldSpec fieldSpec : schema.getAllFieldSpecs()) {\n+      if (!fieldSpec.isVirtualColumn()) {\n+        String column = fieldSpec.getName();\n+        String transformFunction = fieldSpec.getTransformFunction();\n+        if (transformFunction != null) {\n+          ExpressionEvaluator expressionEvaluator = ExpressionEvaluatorFactory.getExpressionEvaluator(fieldSpec);\n+          if (expressionEvaluator != null) {\n+            List<String> arguments = expressionEvaluator.getArguments();\n+            // output column used as input\n+            if (arguments.contains(column)) {\n+              LOGGER.error(\"The arguments of transform function: {}, should not contain the destination column: {}\",\n+                  transformFunction, column);\n+              return false;\n+            }\n+          }\n+        } else if (fieldSpec.getFieldType().equals(FieldSpec.FieldType.TIME)) {\n+          TimeFieldSpec timeFieldSpec = (TimeFieldSpec) fieldSpec;\n+          TimeGranularitySpec incomingGranularitySpec = timeFieldSpec.getIncomingGranularitySpec();\n+          TimeGranularitySpec outgoingGranularitySpec = timeFieldSpec.getOutgoingGranularitySpec();\n+          // different incoming and outgoing spec, but same name\n+          if (outgoingGranularitySpec != null && !incomingGranularitySpec.equals(outgoingGranularitySpec)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2570bf792aa94dca41909cdd3c9a09b223285b74"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODQ3NzU3Mw==", "bodyText": "(nit) outgoingGranularitySpec will never be null because it will return incoming spec if outgoing is not set", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408477573", "createdAt": "2020-04-14T22:40:26Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/function/evaluators/ExpressionEvaluatorFactory.java", "diffHunk": "@@ -0,0 +1,111 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.data.function.evaluators;\n+\n+import javax.annotation.Nullable;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.TimeFieldSpec;\n+import org.apache.pinot.spi.data.TimeGranularitySpec;\n+import org.apache.pinot.spi.utils.SchemaFieldExtractorUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Factory class to create an {@link ExpressionEvaluator} for the field spec based on the {@link FieldSpec#getTransformFunction()}\n+ */\n+public class ExpressionEvaluatorFactory {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(ExpressionEvaluatorFactory.class);\n+\n+  private ExpressionEvaluatorFactory() {\n+\n+  }\n+\n+  /**\n+   * Creates the {@link ExpressionEvaluator} for the given field spec\n+   *\n+   * 1. If transform expression is defined, use it to create {@link ExpressionEvaluator}\n+   * 2. For TIME column, if conversion is needed, {@link DefaultTimeSpecEvaluator} for backward compatible handling of time spec. This is needed until we migrate to {@link org.apache.pinot.spi.data.DateTimeFieldSpec}\n+   * 3. For columns ending with __KEYS or __VALUES (used for interpreting Map column in Avro), create default functions for handing the Map\n+   * 4. Return null, if none of the above\n+   */\n+  @Nullable\n+  public static ExpressionEvaluator getExpressionEvaluator(FieldSpec fieldSpec) {\n+    ExpressionEvaluator expressionEvaluator = null;\n+\n+    String columnName = fieldSpec.getName();\n+    String transformExpression = fieldSpec.getTransformFunction();\n+    if (transformExpression != null) {\n+\n+      // if transform function expression present, use it to generate function evaluator\n+      try {\n+        expressionEvaluator = getExpressionEvaluator(transformExpression);\n+      } catch (Exception e) {\n+        LOGGER.error(\n+            \"Caught exception while constructing expression evaluator for transform expression: {}, of column: {}, skipping\",\n+            transformExpression, columnName, e);\n+      }\n+    } else if (fieldSpec.getFieldType().equals(FieldSpec.FieldType.TIME)) {\n+\n+      // for backward compatible handling of TIME field conversion\n+      TimeFieldSpec timeFieldSpec = (TimeFieldSpec) fieldSpec;\n+      TimeGranularitySpec incomingGranularitySpec = timeFieldSpec.getIncomingGranularitySpec();\n+      TimeGranularitySpec outgoingGranularitySpec = timeFieldSpec.getOutgoingGranularitySpec();\n+      if (outgoingGranularitySpec != null && !incomingGranularitySpec.equals(outgoingGranularitySpec)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2570bf792aa94dca41909cdd3c9a09b223285b74"}, "originalPosition": 71}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "aa723c8b4ef6113594a06b4c94bce7ddb91c43e4", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/aa723c8b4ef6113594a06b4c94bce7ddb91c43e4", "committedDate": "2020-04-15T00:40:28Z", "message": "Handle case where transformed destination value already exists in the record"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8cb07c0fd9baab32ee4977c34ee8a319d4b3a925", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/8cb07c0fd9baab32ee4977c34ee8a319d4b3a925", "committedDate": "2020-04-15T01:37:25Z", "message": "Make extract return Set. Exceptions from ExpressionEvaluatorFactory"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e3b81b7e5fc49833f5175bb07d2746589917737d", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/e3b81b7e5fc49833f5175bb07d2746589917737d", "committedDate": "2020-04-15T01:42:19Z", "message": "Fix brokern test"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkzNDA1Mjc1", "url": "https://github.com/apache/pinot/pull/5238#pullrequestreview-393405275", "createdAt": "2020-04-15T01:48:24Z", "commit": {"oid": "e3b81b7e5fc49833f5175bb07d2746589917737d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwMTo0ODoyNFrOGFm6AA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwMTo0ODoyNFrOGFm6AA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODUzMzUwNA==", "bodyText": "This should also take a set", "url": "https://github.com/apache/pinot/pull/5238#discussion_r408533504", "createdAt": "2020-04-15T01:48:24Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/readers/RecordExtractor.java", "diffHunk": "@@ -18,16 +18,29 @@\n  */\n package org.apache.pinot.spi.data.readers;\n \n-import org.apache.pinot.spi.data.Schema;\n+import java.util.List;\n \n+\n+/**\n+ * Extracts fields from input records\n+ * @param <T> The format of the input record\n+ */\n public interface RecordExtractor<T> {\n+\n+  /**\n+   * Initialize the record extractor with its config\n+   *\n+   * @param fields List of field names to extract from the provided input record\n+   * @param recordExtractorConfig The record extractor config\n+   */\n+  void init(List<String> fields, RecordExtractorConfig recordExtractorConfig);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e3b81b7e5fc49833f5175bb07d2746589917737d"}, "originalPosition": 20}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "55a1cf9ea867a47fc086367aa4b5909fd04ce4f6", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/55a1cf9ea867a47fc086367aa4b5909fd04ce4f6", "committedDate": "2020-04-15T17:50:57Z", "message": "Make fields a set in the interface, fix tests, fix quickstart"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk0MDA1MjMz", "url": "https://github.com/apache/pinot/pull/5238#pullrequestreview-394005233", "createdAt": "2020-04-15T17:55:45Z", "commit": {"oid": "55a1cf9ea867a47fc086367aa4b5909fd04ce4f6"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "de3031d5fb29b3c5f193879ce24927d433dfd2c8", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/de3031d5fb29b3c5f193879ce24927d433dfd2c8", "committedDate": "2020-04-15T19:07:47Z", "message": "Comment about supported datatypes in GenericRow"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1216, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}