{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTMyODQ0OTAx", "number": 6322, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwMzoxMjo0NFrOFBD0Fw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwMzoxNjowNFrOFBD1wQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM2NjU1MzgzOnYy", "diffSide": "RIGHT", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/helix/core/PinotHelixResourceManager.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwMzoxMjo0NFrOH_o5ow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwMzoxMjo0NFrOH_o5ow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ5MjQ1MQ==", "bodyText": "consumingSegments must be a set or it will containing duplicates", "url": "https://github.com/apache/pinot/pull/6322#discussion_r536492451", "createdAt": "2020-12-05T03:12:44Z", "author": {"login": "kishoreg"}, "path": "pinot-controller/src/main/java/org/apache/pinot/controller/helix/core/PinotHelixResourceManager.java", "diffHunk": "@@ -1895,6 +1895,24 @@ public void toggleQueryQuotaStateForBroker(String brokerInstanceName, String sta\n     return serverToSegmentsMap;\n   }\n \n+  /**\n+   * Returns a list of CONSUMING segments for the given realtime table.\n+   */\n+  public List<String> getConsumingSegments(String tableNameWithType) {\n+    IdealState idealState = _helixAdmin.getResourceIdealState(_helixClusterName, tableNameWithType);\n+    if (idealState == null) {\n+      throw new IllegalStateException(\"Ideal state does not exist for table: \" + tableNameWithType);\n+    }\n+    List<String> consumingSegments = new ArrayList<>();\n+    for (String segment : idealState.getPartitionSet()) {\n+      Map<String, String> instanceStateMap = idealState.getInstanceStateMap(segment);\n+      if (instanceStateMap.containsValue(SegmentStateModel.CONSUMING)) {\n+        consumingSegments.add(segment);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e70617e163bbb1eb2639b9a097abe72006e2666d"}, "originalPosition": 16}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM2NjU1NDI5OnYy", "diffSide": "RIGHT", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/helix/core/PinotHelixResourceManager.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwMzoxMzowOFrOH_o50g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQyMDo1OTo1OFrOIABRng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ5MjQ5OA==", "bodyText": "might also need null check?", "url": "https://github.com/apache/pinot/pull/6322#discussion_r536492498", "createdAt": "2020-12-05T03:13:08Z", "author": {"login": "kishoreg"}, "path": "pinot-controller/src/main/java/org/apache/pinot/controller/helix/core/PinotHelixResourceManager.java", "diffHunk": "@@ -1895,6 +1895,24 @@ public void toggleQueryQuotaStateForBroker(String brokerInstanceName, String sta\n     return serverToSegmentsMap;\n   }\n \n+  /**\n+   * Returns a list of CONSUMING segments for the given realtime table.\n+   */\n+  public List<String> getConsumingSegments(String tableNameWithType) {\n+    IdealState idealState = _helixAdmin.getResourceIdealState(_helixClusterName, tableNameWithType);\n+    if (idealState == null) {\n+      throw new IllegalStateException(\"Ideal state does not exist for table: \" + tableNameWithType);\n+    }\n+    List<String> consumingSegments = new ArrayList<>();\n+    for (String segment : idealState.getPartitionSet()) {\n+      Map<String, String> instanceStateMap = idealState.getInstanceStateMap(segment);\n+      if (instanceStateMap.containsValue(SegmentStateModel.CONSUMING)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e70617e163bbb1eb2639b9a097abe72006e2666d"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjg5MTgwNg==", "bodyText": "shouldn't need null check (or even Set) because we're iterating over the segments fetched from the ideal state. Changed it to Set anyway.", "url": "https://github.com/apache/pinot/pull/6322#discussion_r536891806", "createdAt": "2020-12-05T20:59:58Z", "author": {"login": "npawar"}, "path": "pinot-controller/src/main/java/org/apache/pinot/controller/helix/core/PinotHelixResourceManager.java", "diffHunk": "@@ -1895,6 +1895,24 @@ public void toggleQueryQuotaStateForBroker(String brokerInstanceName, String sta\n     return serverToSegmentsMap;\n   }\n \n+  /**\n+   * Returns a list of CONSUMING segments for the given realtime table.\n+   */\n+  public List<String> getConsumingSegments(String tableNameWithType) {\n+    IdealState idealState = _helixAdmin.getResourceIdealState(_helixClusterName, tableNameWithType);\n+    if (idealState == null) {\n+      throw new IllegalStateException(\"Ideal state does not exist for table: \" + tableNameWithType);\n+    }\n+    List<String> consumingSegments = new ArrayList<>();\n+    for (String segment : idealState.getPartitionSet()) {\n+      Map<String, String> instanceStateMap = idealState.getInstanceStateMap(segment);\n+      if (instanceStateMap.containsValue(SegmentStateModel.CONSUMING)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ5MjQ5OA=="}, "originalCommit": {"oid": "e70617e163bbb1eb2639b9a097abe72006e2666d"}, "originalPosition": 15}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM2NjU1Njc0OnYy", "diffSide": "RIGHT", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/util/ConsumingSegmentInfoReader.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwMzoxNTowM1rOH_o64w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwMzoxNTowM1rOH_o64w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ5Mjc3MQ==", "bodyText": "_partitionToOffsetMap ?", "url": "https://github.com/apache/pinot/pull/6322#discussion_r536492771", "createdAt": "2020-12-05T03:15:03Z", "author": {"login": "kishoreg"}, "path": "pinot-controller/src/main/java/org/apache/pinot/controller/util/ConsumingSegmentInfoReader.java", "diffHunk": "@@ -0,0 +1,162 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.util;\n+\n+import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.core.type.TypeReference;\n+import com.google.common.collect.BiMap;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.TreeMap;\n+import java.util.concurrent.Executor;\n+import org.apache.commons.httpclient.HttpConnectionManager;\n+import org.apache.pinot.common.exception.InvalidConfigException;\n+import org.apache.pinot.common.restlet.resources.SegmentConsumerInfo;\n+import org.apache.pinot.controller.helix.core.PinotHelixResourceManager;\n+import org.apache.pinot.spi.utils.JsonUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * This is a helper class that calls the server API endpoints to fetch consuming segments info\n+ * Only the servers returning success are returned by the method. For servers returning errors (http error or otherwise),\n+ * no entry is created in the return list\n+ */\n+public class ConsumingSegmentInfoReader {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(ConsumingSegmentInfoReader.class);\n+\n+  private final Executor _executor;\n+  private final HttpConnectionManager _connectionManager;\n+  private final PinotHelixResourceManager _pinotHelixResourceManager;\n+\n+  public ConsumingSegmentInfoReader(Executor executor, HttpConnectionManager connectionManager,\n+      PinotHelixResourceManager helixResourceManager) {\n+    _executor = executor;\n+    _connectionManager = connectionManager;\n+    _pinotHelixResourceManager = helixResourceManager;\n+  }\n+\n+  /**\n+   * This method retrieves the consuming segments info for a given realtime table.\n+   * @return a map of segmentName to the information about its consumer\n+   */\n+  public ConsumingSegmentsInfoMap getConsumingSegmentsInfo(String tableNameWithType, int timeoutMs)\n+      throws InvalidConfigException {\n+    final Map<String, List<String>> serverToSegments =\n+        _pinotHelixResourceManager.getServerToSegmentsMap(tableNameWithType);\n+    BiMap<String, String> serverToEndpoints =\n+        _pinotHelixResourceManager.getDataInstanceAdminEndpoints(serverToSegments.keySet());\n+\n+    // Gets info for segments with LLRealtimeSegmentDataManager found in the table data manager\n+    Map<String, List<SegmentConsumerInfo>> serverToSegmentConsumerInfoMap =\n+        getConsumingSegmentsInfoFromServers(tableNameWithType, serverToEndpoints, timeoutMs);\n+    TreeMap<String, List<ConsumingSegmentInfo>> consumingSegmentInfoMap = new TreeMap<>();\n+    for (Map.Entry<String, List<SegmentConsumerInfo>> entry : serverToSegmentConsumerInfoMap.entrySet()) {\n+      String serverName = entry.getKey();\n+      for (SegmentConsumerInfo info : entry.getValue()) {\n+        consumingSegmentInfoMap.computeIfAbsent(info.getSegmentName(), k -> new ArrayList<>())\n+            .add(new ConsumingSegmentInfo(serverName, info.getConsumerState(), info.getPartitionToOffset()));\n+      }\n+    }\n+    // Segments which are in CONSUMING state but found no consumer on the server\n+    List<String> consumingSegments = _pinotHelixResourceManager.getConsumingSegments(tableNameWithType);\n+    consumingSegments.forEach(c -> consumingSegmentInfoMap.putIfAbsent(c, Collections.emptyList()));\n+    return new ConsumingSegmentsInfoMap(consumingSegmentInfoMap);\n+  }\n+\n+  /**\n+   * This method makes a MultiGet call to all servers to get the consuming segments info.\n+   * @return servers queried and a list of consumer status information for consuming segments on that server\n+   */\n+  private Map<String, List<SegmentConsumerInfo>> getConsumingSegmentsInfoFromServers(String tableNameWithType,\n+      BiMap<String, String> serverToEndpoints, int timeoutMs) {\n+    LOGGER.info(\"Reading consuming segment info from servers: {} for table: {}\", serverToEndpoints.keySet(),\n+        tableNameWithType);\n+\n+    List<String> serverUrls = new ArrayList<>(serverToEndpoints.size());\n+    BiMap<String, String> endpointsToServers = serverToEndpoints.inverse();\n+    for (String endpoint : endpointsToServers.keySet()) {\n+      String consumingSegmentInfoURI = generateServerURL(tableNameWithType, endpoint);\n+      serverUrls.add(consumingSegmentInfoURI);\n+    }\n+\n+    CompletionServiceHelper completionServiceHelper =\n+        new CompletionServiceHelper(_executor, _connectionManager, endpointsToServers);\n+    CompletionServiceHelper.CompletionServiceResponse serviceResponse =\n+        completionServiceHelper.doMultiGetRequest(serverUrls, tableNameWithType, timeoutMs);\n+    Map<String, List<SegmentConsumerInfo>> serverToConsumingSegmentInfoList = new HashMap<>();\n+    int failedParses = 0;\n+    for (Map.Entry<String, String> streamResponse : serviceResponse._httpResponses.entrySet()) {\n+      try {\n+        List<SegmentConsumerInfo> segmentConsumerInfos =\n+            JsonUtils.stringToObject(streamResponse.getValue(), new TypeReference<List<SegmentConsumerInfo>>() {\n+            });\n+        serverToConsumingSegmentInfoList.put(streamResponse.getKey(), segmentConsumerInfos);\n+      } catch (IOException e) {\n+        failedParses++;\n+        LOGGER.error(\"Unable to parse server {} response due to an error: \", streamResponse.getKey(), e);\n+      }\n+    }\n+    if (failedParses != 0) {\n+      LOGGER.warn(\"Failed to parse {} / {} segment size info responses from servers.\", failedParses, serverUrls.size());\n+    }\n+    return serverToConsumingSegmentInfoList;\n+  }\n+\n+  private String generateServerURL(String tableNameWithType, String endpoint) {\n+    return String.format(\"http://%s/tables/%s/consumingSegmentsInfo\", endpoint, tableNameWithType);\n+  }\n+\n+  /**\n+   * Map containing all consuming segments and their status information\n+   */\n+  @JsonIgnoreProperties(ignoreUnknown = true)\n+  static public class ConsumingSegmentsInfoMap {\n+    public TreeMap<String, List<ConsumingSegmentInfo>> _segmentToConsumingInfoMap;\n+\n+    public ConsumingSegmentsInfoMap(\n+        @JsonProperty(\"segmentToConsumingInfoMap\") TreeMap<String, List<ConsumingSegmentInfo>> segmentToConsumingInfoMap) {\n+      this._segmentToConsumingInfoMap = segmentToConsumingInfoMap;\n+    }\n+  }\n+\n+  /**\n+   * Contains all the information about a consuming segment\n+   */\n+  @JsonIgnoreProperties(ignoreUnknown = true)\n+  static public class ConsumingSegmentInfo {\n+    public String _serverName;\n+    public String _consumerState;\n+    public Map<String, String> _partitionToOffset;\n+\n+    public ConsumingSegmentInfo(@JsonProperty(\"serverName\") String serverName,\n+        @JsonProperty(\"consumerState\") String consumerState,\n+        @JsonProperty(\"partitionToOffset\") Map<String, String> partitionToOffset) {\n+      _serverName = serverName;\n+      _consumerState = consumerState;\n+      _partitionToOffset = partitionToOffset;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e70617e163bbb1eb2639b9a097abe72006e2666d"}, "originalPosition": 159}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM2NjU1ODA5OnYy", "diffSide": "RIGHT", "path": "pinot-controller/src/main/java/org/apache/pinot/controller/util/ConsumingSegmentInfoReader.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwMzoxNjowNFrOH_o7fA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQyMTowNDozNFrOIABUJg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ5MjkyNA==", "bodyText": "can we add a lastConsumedTimestamp?", "url": "https://github.com/apache/pinot/pull/6322#discussion_r536492924", "createdAt": "2020-12-05T03:16:04Z", "author": {"login": "kishoreg"}, "path": "pinot-controller/src/main/java/org/apache/pinot/controller/util/ConsumingSegmentInfoReader.java", "diffHunk": "@@ -0,0 +1,162 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.util;\n+\n+import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.core.type.TypeReference;\n+import com.google.common.collect.BiMap;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.TreeMap;\n+import java.util.concurrent.Executor;\n+import org.apache.commons.httpclient.HttpConnectionManager;\n+import org.apache.pinot.common.exception.InvalidConfigException;\n+import org.apache.pinot.common.restlet.resources.SegmentConsumerInfo;\n+import org.apache.pinot.controller.helix.core.PinotHelixResourceManager;\n+import org.apache.pinot.spi.utils.JsonUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * This is a helper class that calls the server API endpoints to fetch consuming segments info\n+ * Only the servers returning success are returned by the method. For servers returning errors (http error or otherwise),\n+ * no entry is created in the return list\n+ */\n+public class ConsumingSegmentInfoReader {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(ConsumingSegmentInfoReader.class);\n+\n+  private final Executor _executor;\n+  private final HttpConnectionManager _connectionManager;\n+  private final PinotHelixResourceManager _pinotHelixResourceManager;\n+\n+  public ConsumingSegmentInfoReader(Executor executor, HttpConnectionManager connectionManager,\n+      PinotHelixResourceManager helixResourceManager) {\n+    _executor = executor;\n+    _connectionManager = connectionManager;\n+    _pinotHelixResourceManager = helixResourceManager;\n+  }\n+\n+  /**\n+   * This method retrieves the consuming segments info for a given realtime table.\n+   * @return a map of segmentName to the information about its consumer\n+   */\n+  public ConsumingSegmentsInfoMap getConsumingSegmentsInfo(String tableNameWithType, int timeoutMs)\n+      throws InvalidConfigException {\n+    final Map<String, List<String>> serverToSegments =\n+        _pinotHelixResourceManager.getServerToSegmentsMap(tableNameWithType);\n+    BiMap<String, String> serverToEndpoints =\n+        _pinotHelixResourceManager.getDataInstanceAdminEndpoints(serverToSegments.keySet());\n+\n+    // Gets info for segments with LLRealtimeSegmentDataManager found in the table data manager\n+    Map<String, List<SegmentConsumerInfo>> serverToSegmentConsumerInfoMap =\n+        getConsumingSegmentsInfoFromServers(tableNameWithType, serverToEndpoints, timeoutMs);\n+    TreeMap<String, List<ConsumingSegmentInfo>> consumingSegmentInfoMap = new TreeMap<>();\n+    for (Map.Entry<String, List<SegmentConsumerInfo>> entry : serverToSegmentConsumerInfoMap.entrySet()) {\n+      String serverName = entry.getKey();\n+      for (SegmentConsumerInfo info : entry.getValue()) {\n+        consumingSegmentInfoMap.computeIfAbsent(info.getSegmentName(), k -> new ArrayList<>())\n+            .add(new ConsumingSegmentInfo(serverName, info.getConsumerState(), info.getPartitionToOffset()));\n+      }\n+    }\n+    // Segments which are in CONSUMING state but found no consumer on the server\n+    List<String> consumingSegments = _pinotHelixResourceManager.getConsumingSegments(tableNameWithType);\n+    consumingSegments.forEach(c -> consumingSegmentInfoMap.putIfAbsent(c, Collections.emptyList()));\n+    return new ConsumingSegmentsInfoMap(consumingSegmentInfoMap);\n+  }\n+\n+  /**\n+   * This method makes a MultiGet call to all servers to get the consuming segments info.\n+   * @return servers queried and a list of consumer status information for consuming segments on that server\n+   */\n+  private Map<String, List<SegmentConsumerInfo>> getConsumingSegmentsInfoFromServers(String tableNameWithType,\n+      BiMap<String, String> serverToEndpoints, int timeoutMs) {\n+    LOGGER.info(\"Reading consuming segment info from servers: {} for table: {}\", serverToEndpoints.keySet(),\n+        tableNameWithType);\n+\n+    List<String> serverUrls = new ArrayList<>(serverToEndpoints.size());\n+    BiMap<String, String> endpointsToServers = serverToEndpoints.inverse();\n+    for (String endpoint : endpointsToServers.keySet()) {\n+      String consumingSegmentInfoURI = generateServerURL(tableNameWithType, endpoint);\n+      serverUrls.add(consumingSegmentInfoURI);\n+    }\n+\n+    CompletionServiceHelper completionServiceHelper =\n+        new CompletionServiceHelper(_executor, _connectionManager, endpointsToServers);\n+    CompletionServiceHelper.CompletionServiceResponse serviceResponse =\n+        completionServiceHelper.doMultiGetRequest(serverUrls, tableNameWithType, timeoutMs);\n+    Map<String, List<SegmentConsumerInfo>> serverToConsumingSegmentInfoList = new HashMap<>();\n+    int failedParses = 0;\n+    for (Map.Entry<String, String> streamResponse : serviceResponse._httpResponses.entrySet()) {\n+      try {\n+        List<SegmentConsumerInfo> segmentConsumerInfos =\n+            JsonUtils.stringToObject(streamResponse.getValue(), new TypeReference<List<SegmentConsumerInfo>>() {\n+            });\n+        serverToConsumingSegmentInfoList.put(streamResponse.getKey(), segmentConsumerInfos);\n+      } catch (IOException e) {\n+        failedParses++;\n+        LOGGER.error(\"Unable to parse server {} response due to an error: \", streamResponse.getKey(), e);\n+      }\n+    }\n+    if (failedParses != 0) {\n+      LOGGER.warn(\"Failed to parse {} / {} segment size info responses from servers.\", failedParses, serverUrls.size());\n+    }\n+    return serverToConsumingSegmentInfoList;\n+  }\n+\n+  private String generateServerURL(String tableNameWithType, String endpoint) {\n+    return String.format(\"http://%s/tables/%s/consumingSegmentsInfo\", endpoint, tableNameWithType);\n+  }\n+\n+  /**\n+   * Map containing all consuming segments and their status information\n+   */\n+  @JsonIgnoreProperties(ignoreUnknown = true)\n+  static public class ConsumingSegmentsInfoMap {\n+    public TreeMap<String, List<ConsumingSegmentInfo>> _segmentToConsumingInfoMap;\n+\n+    public ConsumingSegmentsInfoMap(\n+        @JsonProperty(\"segmentToConsumingInfoMap\") TreeMap<String, List<ConsumingSegmentInfo>> segmentToConsumingInfoMap) {\n+      this._segmentToConsumingInfoMap = segmentToConsumingInfoMap;\n+    }\n+  }\n+\n+  /**\n+   * Contains all the information about a consuming segment\n+   */\n+  @JsonIgnoreProperties(ignoreUnknown = true)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e70617e163bbb1eb2639b9a097abe72006e2666d"}, "originalPosition": 148}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjg5MjQ1NA==", "bodyText": "yes should be doable. Let me add that.", "url": "https://github.com/apache/pinot/pull/6322#discussion_r536892454", "createdAt": "2020-12-05T21:04:34Z", "author": {"login": "npawar"}, "path": "pinot-controller/src/main/java/org/apache/pinot/controller/util/ConsumingSegmentInfoReader.java", "diffHunk": "@@ -0,0 +1,162 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.util;\n+\n+import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.core.type.TypeReference;\n+import com.google.common.collect.BiMap;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.TreeMap;\n+import java.util.concurrent.Executor;\n+import org.apache.commons.httpclient.HttpConnectionManager;\n+import org.apache.pinot.common.exception.InvalidConfigException;\n+import org.apache.pinot.common.restlet.resources.SegmentConsumerInfo;\n+import org.apache.pinot.controller.helix.core.PinotHelixResourceManager;\n+import org.apache.pinot.spi.utils.JsonUtils;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * This is a helper class that calls the server API endpoints to fetch consuming segments info\n+ * Only the servers returning success are returned by the method. For servers returning errors (http error or otherwise),\n+ * no entry is created in the return list\n+ */\n+public class ConsumingSegmentInfoReader {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(ConsumingSegmentInfoReader.class);\n+\n+  private final Executor _executor;\n+  private final HttpConnectionManager _connectionManager;\n+  private final PinotHelixResourceManager _pinotHelixResourceManager;\n+\n+  public ConsumingSegmentInfoReader(Executor executor, HttpConnectionManager connectionManager,\n+      PinotHelixResourceManager helixResourceManager) {\n+    _executor = executor;\n+    _connectionManager = connectionManager;\n+    _pinotHelixResourceManager = helixResourceManager;\n+  }\n+\n+  /**\n+   * This method retrieves the consuming segments info for a given realtime table.\n+   * @return a map of segmentName to the information about its consumer\n+   */\n+  public ConsumingSegmentsInfoMap getConsumingSegmentsInfo(String tableNameWithType, int timeoutMs)\n+      throws InvalidConfigException {\n+    final Map<String, List<String>> serverToSegments =\n+        _pinotHelixResourceManager.getServerToSegmentsMap(tableNameWithType);\n+    BiMap<String, String> serverToEndpoints =\n+        _pinotHelixResourceManager.getDataInstanceAdminEndpoints(serverToSegments.keySet());\n+\n+    // Gets info for segments with LLRealtimeSegmentDataManager found in the table data manager\n+    Map<String, List<SegmentConsumerInfo>> serverToSegmentConsumerInfoMap =\n+        getConsumingSegmentsInfoFromServers(tableNameWithType, serverToEndpoints, timeoutMs);\n+    TreeMap<String, List<ConsumingSegmentInfo>> consumingSegmentInfoMap = new TreeMap<>();\n+    for (Map.Entry<String, List<SegmentConsumerInfo>> entry : serverToSegmentConsumerInfoMap.entrySet()) {\n+      String serverName = entry.getKey();\n+      for (SegmentConsumerInfo info : entry.getValue()) {\n+        consumingSegmentInfoMap.computeIfAbsent(info.getSegmentName(), k -> new ArrayList<>())\n+            .add(new ConsumingSegmentInfo(serverName, info.getConsumerState(), info.getPartitionToOffset()));\n+      }\n+    }\n+    // Segments which are in CONSUMING state but found no consumer on the server\n+    List<String> consumingSegments = _pinotHelixResourceManager.getConsumingSegments(tableNameWithType);\n+    consumingSegments.forEach(c -> consumingSegmentInfoMap.putIfAbsent(c, Collections.emptyList()));\n+    return new ConsumingSegmentsInfoMap(consumingSegmentInfoMap);\n+  }\n+\n+  /**\n+   * This method makes a MultiGet call to all servers to get the consuming segments info.\n+   * @return servers queried and a list of consumer status information for consuming segments on that server\n+   */\n+  private Map<String, List<SegmentConsumerInfo>> getConsumingSegmentsInfoFromServers(String tableNameWithType,\n+      BiMap<String, String> serverToEndpoints, int timeoutMs) {\n+    LOGGER.info(\"Reading consuming segment info from servers: {} for table: {}\", serverToEndpoints.keySet(),\n+        tableNameWithType);\n+\n+    List<String> serverUrls = new ArrayList<>(serverToEndpoints.size());\n+    BiMap<String, String> endpointsToServers = serverToEndpoints.inverse();\n+    for (String endpoint : endpointsToServers.keySet()) {\n+      String consumingSegmentInfoURI = generateServerURL(tableNameWithType, endpoint);\n+      serverUrls.add(consumingSegmentInfoURI);\n+    }\n+\n+    CompletionServiceHelper completionServiceHelper =\n+        new CompletionServiceHelper(_executor, _connectionManager, endpointsToServers);\n+    CompletionServiceHelper.CompletionServiceResponse serviceResponse =\n+        completionServiceHelper.doMultiGetRequest(serverUrls, tableNameWithType, timeoutMs);\n+    Map<String, List<SegmentConsumerInfo>> serverToConsumingSegmentInfoList = new HashMap<>();\n+    int failedParses = 0;\n+    for (Map.Entry<String, String> streamResponse : serviceResponse._httpResponses.entrySet()) {\n+      try {\n+        List<SegmentConsumerInfo> segmentConsumerInfos =\n+            JsonUtils.stringToObject(streamResponse.getValue(), new TypeReference<List<SegmentConsumerInfo>>() {\n+            });\n+        serverToConsumingSegmentInfoList.put(streamResponse.getKey(), segmentConsumerInfos);\n+      } catch (IOException e) {\n+        failedParses++;\n+        LOGGER.error(\"Unable to parse server {} response due to an error: \", streamResponse.getKey(), e);\n+      }\n+    }\n+    if (failedParses != 0) {\n+      LOGGER.warn(\"Failed to parse {} / {} segment size info responses from servers.\", failedParses, serverUrls.size());\n+    }\n+    return serverToConsumingSegmentInfoList;\n+  }\n+\n+  private String generateServerURL(String tableNameWithType, String endpoint) {\n+    return String.format(\"http://%s/tables/%s/consumingSegmentsInfo\", endpoint, tableNameWithType);\n+  }\n+\n+  /**\n+   * Map containing all consuming segments and their status information\n+   */\n+  @JsonIgnoreProperties(ignoreUnknown = true)\n+  static public class ConsumingSegmentsInfoMap {\n+    public TreeMap<String, List<ConsumingSegmentInfo>> _segmentToConsumingInfoMap;\n+\n+    public ConsumingSegmentsInfoMap(\n+        @JsonProperty(\"segmentToConsumingInfoMap\") TreeMap<String, List<ConsumingSegmentInfo>> segmentToConsumingInfoMap) {\n+      this._segmentToConsumingInfoMap = segmentToConsumingInfoMap;\n+    }\n+  }\n+\n+  /**\n+   * Contains all the information about a consuming segment\n+   */\n+  @JsonIgnoreProperties(ignoreUnknown = true)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ5MjkyNA=="}, "originalCommit": {"oid": "e70617e163bbb1eb2639b9a097abe72006e2666d"}, "originalPosition": 148}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2994, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}