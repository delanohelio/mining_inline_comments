{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTE5NTY4NjY0", "number": 6259, "reviewThreads": {"totalCount": 66, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQwNjozMzozMlrOE4BAiA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQwMDowNzoyOVrOFQL0uA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3MTcyMjMyOnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/PartitionSegmentPruner.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQwNjozMzozMlrOHxsTIw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQwNjozMzozMlrOHxsTIw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTg2ODA2Nw==", "bodyText": "Let's see if the pruner code can deal with set v/s list as opposed to changing the APIs across all pruner users.", "url": "https://github.com/apache/pinot/pull/6259#discussion_r521868067", "createdAt": "2020-11-12T06:33:32Z", "author": {"login": "siddharthteotia"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/PartitionSegmentPruner.java", "diffHunk": "@@ -148,12 +149,12 @@ public synchronized void refreshSegment(String segment) {\n   }\n \n   @Override\n-  public List<String> prune(BrokerRequest brokerRequest, List<String> segments) {\n+  public Set<String> prune(BrokerRequest brokerRequest, Set<String> segments) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3MTcyNDk1OnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/SegmentPrunerFactory.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQwNjozNDo0M1rOHxsUqQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QwMDoyMTowN1rOHyUVOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTg2ODQ1Nw==", "bodyText": "This check is not needed again right?", "url": "https://github.com/apache/pinot/pull/6259#discussion_r521868457", "createdAt": "2020-11-12T06:34:43Z", "author": {"login": "siddharthteotia"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/SegmentPrunerFactory.java", "diffHunk": "@@ -97,4 +105,44 @@ private static PartitionSegmentPruner getPartitionSegmentPruner(TableConfig tabl\n       return new PartitionSegmentPruner(tableNameWithType, partitionColumn, propertyStore);\n     }\n   }\n+\n+  @Nullable\n+  private static TimeRangeSegmentPruner getTimeRangeSegmentPruner(TableConfig tableConfig,\n+      ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    String tableNameWithType = tableConfig.getTableName();\n+    SegmentsValidationAndRetentionConfig validationConfig = tableConfig.getValidationConfig();\n+    if (validationConfig == null) {\n+      LOGGER.warn(\"Cannot enable time range pruning without validation config for table: {}\",\n+          tableNameWithType);\n+      return null;\n+    }\n+    String timeColumn = validationConfig.getTimeColumnName();\n+    if (timeColumn == null) {\n+      LOGGER.warn(\"Cannot enable time range pruning without time column for table: {}\",\n+          tableNameWithType);\n+      return null;\n+    }\n+\n+    LOGGER.info(\"Using TimeRangePruner on time column: {} for table: {}\", timeColumn,\n+        tableNameWithType);\n+    return new TimeRangeSegmentPruner(tableConfig, propertyStore);\n+  }\n+\n+  private static List<SegmentPruner> sortSegmentPruners(List<SegmentPruner> pruners) {\n+    // If there's multiple pruners, move time range pruners to the front\u3002\n+    // Partition pruner run time is proportional to input # of segments while time range pruner is not,\n+    // Prune based on time range first will have a smaller input size for partition pruners, so have better performance.\n+    List<SegmentPruner> sortedPruners = new ArrayList<>();\n+    for (SegmentPruner pruner : pruners) {\n+      if (pruner instanceof TimeRangeSegmentPruner) {\n+        sortedPruners.add(pruner);\n+      }\n+    }\n+    for (SegmentPruner pruner: pruners) {\n+      if (!(pruner instanceof TimeRangeSegmentPruner)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjUyMzk2MQ==", "bodyText": "The first for loop will add TimeRangeSegmentPruner to the sorted result, this loop are adding non-timeRange pruners. To avoid duplicated pruners, I think this is still needed.", "url": "https://github.com/apache/pinot/pull/6259#discussion_r522523961", "createdAt": "2020-11-13T00:21:07Z", "author": {"login": "jtao15"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/SegmentPrunerFactory.java", "diffHunk": "@@ -97,4 +105,44 @@ private static PartitionSegmentPruner getPartitionSegmentPruner(TableConfig tabl\n       return new PartitionSegmentPruner(tableNameWithType, partitionColumn, propertyStore);\n     }\n   }\n+\n+  @Nullable\n+  private static TimeRangeSegmentPruner getTimeRangeSegmentPruner(TableConfig tableConfig,\n+      ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    String tableNameWithType = tableConfig.getTableName();\n+    SegmentsValidationAndRetentionConfig validationConfig = tableConfig.getValidationConfig();\n+    if (validationConfig == null) {\n+      LOGGER.warn(\"Cannot enable time range pruning without validation config for table: {}\",\n+          tableNameWithType);\n+      return null;\n+    }\n+    String timeColumn = validationConfig.getTimeColumnName();\n+    if (timeColumn == null) {\n+      LOGGER.warn(\"Cannot enable time range pruning without time column for table: {}\",\n+          tableNameWithType);\n+      return null;\n+    }\n+\n+    LOGGER.info(\"Using TimeRangePruner on time column: {} for table: {}\", timeColumn,\n+        tableNameWithType);\n+    return new TimeRangeSegmentPruner(tableConfig, propertyStore);\n+  }\n+\n+  private static List<SegmentPruner> sortSegmentPruners(List<SegmentPruner> pruners) {\n+    // If there's multiple pruners, move time range pruners to the front\u3002\n+    // Partition pruner run time is proportional to input # of segments while time range pruner is not,\n+    // Prune based on time range first will have a smaller input size for partition pruners, so have better performance.\n+    List<SegmentPruner> sortedPruners = new ArrayList<>();\n+    for (SegmentPruner pruner : pruners) {\n+      if (pruner instanceof TimeRangeSegmentPruner) {\n+        sortedPruners.add(pruner);\n+      }\n+    }\n+    for (SegmentPruner pruner: pruners) {\n+      if (!(pruner instanceof TimeRangeSegmentPruner)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTg2ODQ1Nw=="}, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 63}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3MTcyNjAxOnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeRangeSegmentPruner.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQwNjozNTowM1rOHxsVQw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QxOTowMjowMFrOHy7ahQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTg2ODYxMQ==", "bodyText": "I am not quite sure why list of list is needed here?\nEach child operator under AND root will give you a list containing one or more intervals.\nThis is List childRanges.\nYou can still maintain the result list as List resultRanges and do the following inside for loop\nfor (FilterQueryTree child : filterQueryTree.getChildren()) {\n          List<Interval> childRanges = getFilterTimeRange(child);\n          if (childRanges != null) {\n            resultRanges.addAll(childRanges);\n          }\n        }\n        // do sorted merge of these intervals\n        return getIntersectionSortedRanges(resultIntervals);", "url": "https://github.com/apache/pinot/pull/6259#discussion_r521868611", "createdAt": "2020-11-12T06:35:03Z", "author": {"login": "siddharthteotia"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeRangeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeRangeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeRangeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeRangeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final TimeUnit _timeUnit;\n+\n+  private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n+\n+  public TimeRangeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    DateTimeFormatSpec formatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    _timeUnit = formatSpec.getColumnUnit();\n+    Preconditions\n+        .checkNotNull(_timeUnit, \"Time unit must be configured in the field spec for time column: %s of table: %s\",\n+            _timeColumn, _tableNameWithType);\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    onExternalViewChange(externalView, idealState, onlineSegments);\n+  }\n+\n+  @Override\n+  public void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    updateTimeRangeMSToSegmentSearchTree(onlineSegments);\n+  }\n+\n+  private void updateTimeRangeMSToSegmentSearchTree(Set<String> onlineSegments) {\n+    List<String> segments = new ArrayList<>(onlineSegments);\n+    // atomic swap _timeRangeToSegmentMap for input online segments\n+    List<String> segmentZKMetadataPaths = new ArrayList<>();\n+    for (String segment: segments) {\n+      segmentZKMetadataPaths.add(_segmentZKMetadataPathPrefix + segment);\n+    }\n+\n+    List<ZNRecord> znRecords = _propertyStore.get(segmentZKMetadataPaths, null, AccessOption.PERSISTENT, true);\n+\n+    List<Long> startTimes = new ArrayList<>();\n+    List<Long> endTimes = new ArrayList<>();\n+\n+    for (int i = 0; i < segments.size(); i++) {\n+      String segment = segments.get(i);\n+\n+      long[] range = extractStartEndTimeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(i));\n+      startTimes.add(range[0]);\n+      endTimes.add(range[1]);\n+    }\n+\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(startTimes, endTimes, segments);\n+  }\n+\n+\n+  private long[] extractStartEndTimeMSFromSegmentZKMetaZNRecord(String segment, @Nullable ZNRecord znRecord) {\n+    long[] range = {MIN_START_TIME, MAX_END_TIME};\n+    // Segments without metadata or with invalid time range will be set with [min_start, max_end] and will not be pruned\n+    if (znRecord == null) {\n+      LOGGER.warn(\"Failed to find segment ZK metadata for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return range;\n+    }\n+\n+    long startTime = znRecord.getLongField(CommonConstants.Segment.START_TIME, -1);\n+    long endTime = znRecord.getLongField(CommonConstants.Segment.END_TIME, -1);\n+    if (startTime < 0 || endTime < 0 || startTime > endTime) {\n+      LOGGER.warn(\"Failed to find valid end time for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return range;\n+    }\n+\n+    TimeUnit timeUnit = znRecord.getEnumField(CommonConstants.Segment.TIME_UNIT, TimeUnit.class, TimeUnit.DAYS);\n+    range[0] = timeUnit.toMillis(startTime);\n+    range[1] = timeUnit.toMillis(endTime);\n+    return range;\n+  }\n+\n+  @Override\n+  public void refreshSegment(String segment) {\n+    Set<String> segments;\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      segments = new HashSet<>();\n+    } else {\n+      segments = _timeRangeMSToSegmentSearchTree.getAllValues();\n+    }\n+    if (!segment.contains(segment)) {\n+      segments.add(segment);\n+    }\n+\n+    updateTimeRangeMSToSegmentSearchTree(segments);\n+  }\n+\n+  /**\n+   * NOTE: Pruning is done by searching _timeRangeToSegmentSearchTree based on request time range and check if the results\n+   *       are in the input segments. By doing so we will have run time O(M * logN) (N is the # of all online segments,\n+   *       M is the # of qualified intersected segments).\n+   */\n+  @Override\n+  public Set<String> prune(BrokerRequest brokerRequest, Set<String> segments) {\n+    // The pruned order may be different from the input order\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      return segments;\n+    }\n+    FilterQueryTree filterQueryTree = RequestUtils.generateFilterQueryTree(brokerRequest);\n+    if (filterQueryTree == null) {\n+      return segments;\n+    }\n+    List<Interval> ranges = getFilterTimeRange(filterQueryTree);\n+    if (ranges == null) { // cannot prune based on time for input request\n+      return segments;\n+    }\n+    if (ranges.size() == 0) { // invalid query time range\n+      return Collections.emptySet();\n+    }\n+\n+    Set<String> prunedSegments = new HashSet<>();\n+    for (Interval range : ranges) {\n+      Interval rangeMS = convertRangeToMS(range);\n+      for (Object segment : _timeRangeMSToSegmentSearchTree.searchAll(rangeMS)) {\n+        if (segments.contains(segment)) {\n+          prunedSegments.add((String) segment);\n+        }\n+      }\n+    }\n+    return new HashSet<String>(prunedSegments);\n+  }\n+\n+  private List<Interval> getFilterTimeRange(FilterQueryTree filterQueryTree) {\n+    // return NUll if no time range info or cannot filter base on the info (e.g. 'SELECT * from myTable where time < 50 OR firstName = Jason')\n+    // return an empty list if filtering range is specified but invalid (e.g. 'SELECT * from myTable where time < 50 AND time > 100')\n+    switch (filterQueryTree.getOperator()) {\n+      case AND:\n+        List<List<Interval>> andRanges = new ArrayList<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 197}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjUyNzExNg==", "bodyText": "Say I have one child ranges as { [1, 4], [8, 10]} (from OR operator), another as {[3, 5], [7, 9]}. The merged result should be {[3, 4], [8, 9]}. If I put all child ranges into one list as { [1, 4], [8, 10], [3, 5], [7, 9]}, some helper informations are needed to track which ranges are from the same child to avoid calculate the intersections between them. In this case I should not calculate the intersection between [1, 4] and [8, 10].", "url": "https://github.com/apache/pinot/pull/6259#discussion_r522527116", "createdAt": "2020-11-13T00:30:54Z", "author": {"login": "jtao15"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeRangeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeRangeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeRangeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeRangeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final TimeUnit _timeUnit;\n+\n+  private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n+\n+  public TimeRangeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    DateTimeFormatSpec formatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    _timeUnit = formatSpec.getColumnUnit();\n+    Preconditions\n+        .checkNotNull(_timeUnit, \"Time unit must be configured in the field spec for time column: %s of table: %s\",\n+            _timeColumn, _tableNameWithType);\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    onExternalViewChange(externalView, idealState, onlineSegments);\n+  }\n+\n+  @Override\n+  public void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    updateTimeRangeMSToSegmentSearchTree(onlineSegments);\n+  }\n+\n+  private void updateTimeRangeMSToSegmentSearchTree(Set<String> onlineSegments) {\n+    List<String> segments = new ArrayList<>(onlineSegments);\n+    // atomic swap _timeRangeToSegmentMap for input online segments\n+    List<String> segmentZKMetadataPaths = new ArrayList<>();\n+    for (String segment: segments) {\n+      segmentZKMetadataPaths.add(_segmentZKMetadataPathPrefix + segment);\n+    }\n+\n+    List<ZNRecord> znRecords = _propertyStore.get(segmentZKMetadataPaths, null, AccessOption.PERSISTENT, true);\n+\n+    List<Long> startTimes = new ArrayList<>();\n+    List<Long> endTimes = new ArrayList<>();\n+\n+    for (int i = 0; i < segments.size(); i++) {\n+      String segment = segments.get(i);\n+\n+      long[] range = extractStartEndTimeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(i));\n+      startTimes.add(range[0]);\n+      endTimes.add(range[1]);\n+    }\n+\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(startTimes, endTimes, segments);\n+  }\n+\n+\n+  private long[] extractStartEndTimeMSFromSegmentZKMetaZNRecord(String segment, @Nullable ZNRecord znRecord) {\n+    long[] range = {MIN_START_TIME, MAX_END_TIME};\n+    // Segments without metadata or with invalid time range will be set with [min_start, max_end] and will not be pruned\n+    if (znRecord == null) {\n+      LOGGER.warn(\"Failed to find segment ZK metadata for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return range;\n+    }\n+\n+    long startTime = znRecord.getLongField(CommonConstants.Segment.START_TIME, -1);\n+    long endTime = znRecord.getLongField(CommonConstants.Segment.END_TIME, -1);\n+    if (startTime < 0 || endTime < 0 || startTime > endTime) {\n+      LOGGER.warn(\"Failed to find valid end time for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return range;\n+    }\n+\n+    TimeUnit timeUnit = znRecord.getEnumField(CommonConstants.Segment.TIME_UNIT, TimeUnit.class, TimeUnit.DAYS);\n+    range[0] = timeUnit.toMillis(startTime);\n+    range[1] = timeUnit.toMillis(endTime);\n+    return range;\n+  }\n+\n+  @Override\n+  public void refreshSegment(String segment) {\n+    Set<String> segments;\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      segments = new HashSet<>();\n+    } else {\n+      segments = _timeRangeMSToSegmentSearchTree.getAllValues();\n+    }\n+    if (!segment.contains(segment)) {\n+      segments.add(segment);\n+    }\n+\n+    updateTimeRangeMSToSegmentSearchTree(segments);\n+  }\n+\n+  /**\n+   * NOTE: Pruning is done by searching _timeRangeToSegmentSearchTree based on request time range and check if the results\n+   *       are in the input segments. By doing so we will have run time O(M * logN) (N is the # of all online segments,\n+   *       M is the # of qualified intersected segments).\n+   */\n+  @Override\n+  public Set<String> prune(BrokerRequest brokerRequest, Set<String> segments) {\n+    // The pruned order may be different from the input order\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      return segments;\n+    }\n+    FilterQueryTree filterQueryTree = RequestUtils.generateFilterQueryTree(brokerRequest);\n+    if (filterQueryTree == null) {\n+      return segments;\n+    }\n+    List<Interval> ranges = getFilterTimeRange(filterQueryTree);\n+    if (ranges == null) { // cannot prune based on time for input request\n+      return segments;\n+    }\n+    if (ranges.size() == 0) { // invalid query time range\n+      return Collections.emptySet();\n+    }\n+\n+    Set<String> prunedSegments = new HashSet<>();\n+    for (Interval range : ranges) {\n+      Interval rangeMS = convertRangeToMS(range);\n+      for (Object segment : _timeRangeMSToSegmentSearchTree.searchAll(rangeMS)) {\n+        if (segments.contains(segment)) {\n+          prunedSegments.add((String) segment);\n+        }\n+      }\n+    }\n+    return new HashSet<String>(prunedSegments);\n+  }\n+\n+  private List<Interval> getFilterTimeRange(FilterQueryTree filterQueryTree) {\n+    // return NUll if no time range info or cannot filter base on the info (e.g. 'SELECT * from myTable where time < 50 OR firstName = Jason')\n+    // return an empty list if filtering range is specified but invalid (e.g. 'SELECT * from myTable where time < 50 AND time > 100')\n+    switch (filterQueryTree.getOperator()) {\n+      case AND:\n+        List<List<Interval>> andRanges = new ArrayList<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTg2ODYxMQ=="}, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 197}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjU4NjY2Nw==", "bodyText": "Sorted merge is an O(N) operation. So the algorithm will first sort { [1, 4], [8, 10], [3, 5], [7, 9]} on startTime to\n{ [1, 4], [3, 5], [7, 9], [8, 10]} and then do a single pass through them to merge into disjoint intervals resulting in {[3, 4], [8, 9]}.\nI don't think keeping track of which range came from which child is worth the code complexity. Time complexity is still O(N). Also, the time filters are usually not that deeply rooted in a complex filter tree. While, there could be multiple occurrences of time filter in a query (haven't seen many example so far though), they may not be part of every subtree filter expression.", "url": "https://github.com/apache/pinot/pull/6259#discussion_r522586667", "createdAt": "2020-11-13T03:11:33Z", "author": {"login": "siddharthteotia"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeRangeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeRangeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeRangeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeRangeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final TimeUnit _timeUnit;\n+\n+  private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n+\n+  public TimeRangeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    DateTimeFormatSpec formatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    _timeUnit = formatSpec.getColumnUnit();\n+    Preconditions\n+        .checkNotNull(_timeUnit, \"Time unit must be configured in the field spec for time column: %s of table: %s\",\n+            _timeColumn, _tableNameWithType);\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    onExternalViewChange(externalView, idealState, onlineSegments);\n+  }\n+\n+  @Override\n+  public void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    updateTimeRangeMSToSegmentSearchTree(onlineSegments);\n+  }\n+\n+  private void updateTimeRangeMSToSegmentSearchTree(Set<String> onlineSegments) {\n+    List<String> segments = new ArrayList<>(onlineSegments);\n+    // atomic swap _timeRangeToSegmentMap for input online segments\n+    List<String> segmentZKMetadataPaths = new ArrayList<>();\n+    for (String segment: segments) {\n+      segmentZKMetadataPaths.add(_segmentZKMetadataPathPrefix + segment);\n+    }\n+\n+    List<ZNRecord> znRecords = _propertyStore.get(segmentZKMetadataPaths, null, AccessOption.PERSISTENT, true);\n+\n+    List<Long> startTimes = new ArrayList<>();\n+    List<Long> endTimes = new ArrayList<>();\n+\n+    for (int i = 0; i < segments.size(); i++) {\n+      String segment = segments.get(i);\n+\n+      long[] range = extractStartEndTimeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(i));\n+      startTimes.add(range[0]);\n+      endTimes.add(range[1]);\n+    }\n+\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(startTimes, endTimes, segments);\n+  }\n+\n+\n+  private long[] extractStartEndTimeMSFromSegmentZKMetaZNRecord(String segment, @Nullable ZNRecord znRecord) {\n+    long[] range = {MIN_START_TIME, MAX_END_TIME};\n+    // Segments without metadata or with invalid time range will be set with [min_start, max_end] and will not be pruned\n+    if (znRecord == null) {\n+      LOGGER.warn(\"Failed to find segment ZK metadata for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return range;\n+    }\n+\n+    long startTime = znRecord.getLongField(CommonConstants.Segment.START_TIME, -1);\n+    long endTime = znRecord.getLongField(CommonConstants.Segment.END_TIME, -1);\n+    if (startTime < 0 || endTime < 0 || startTime > endTime) {\n+      LOGGER.warn(\"Failed to find valid end time for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return range;\n+    }\n+\n+    TimeUnit timeUnit = znRecord.getEnumField(CommonConstants.Segment.TIME_UNIT, TimeUnit.class, TimeUnit.DAYS);\n+    range[0] = timeUnit.toMillis(startTime);\n+    range[1] = timeUnit.toMillis(endTime);\n+    return range;\n+  }\n+\n+  @Override\n+  public void refreshSegment(String segment) {\n+    Set<String> segments;\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      segments = new HashSet<>();\n+    } else {\n+      segments = _timeRangeMSToSegmentSearchTree.getAllValues();\n+    }\n+    if (!segment.contains(segment)) {\n+      segments.add(segment);\n+    }\n+\n+    updateTimeRangeMSToSegmentSearchTree(segments);\n+  }\n+\n+  /**\n+   * NOTE: Pruning is done by searching _timeRangeToSegmentSearchTree based on request time range and check if the results\n+   *       are in the input segments. By doing so we will have run time O(M * logN) (N is the # of all online segments,\n+   *       M is the # of qualified intersected segments).\n+   */\n+  @Override\n+  public Set<String> prune(BrokerRequest brokerRequest, Set<String> segments) {\n+    // The pruned order may be different from the input order\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      return segments;\n+    }\n+    FilterQueryTree filterQueryTree = RequestUtils.generateFilterQueryTree(brokerRequest);\n+    if (filterQueryTree == null) {\n+      return segments;\n+    }\n+    List<Interval> ranges = getFilterTimeRange(filterQueryTree);\n+    if (ranges == null) { // cannot prune based on time for input request\n+      return segments;\n+    }\n+    if (ranges.size() == 0) { // invalid query time range\n+      return Collections.emptySet();\n+    }\n+\n+    Set<String> prunedSegments = new HashSet<>();\n+    for (Interval range : ranges) {\n+      Interval rangeMS = convertRangeToMS(range);\n+      for (Object segment : _timeRangeMSToSegmentSearchTree.searchAll(rangeMS)) {\n+        if (segments.contains(segment)) {\n+          prunedSegments.add((String) segment);\n+        }\n+      }\n+    }\n+    return new HashSet<String>(prunedSegments);\n+  }\n+\n+  private List<Interval> getFilterTimeRange(FilterQueryTree filterQueryTree) {\n+    // return NUll if no time range info or cannot filter base on the info (e.g. 'SELECT * from myTable where time < 50 OR firstName = Jason')\n+    // return an empty list if filtering range is specified but invalid (e.g. 'SELECT * from myTable where time < 50 AND time > 100')\n+    switch (filterQueryTree.getOperator()) {\n+      case AND:\n+        List<List<Interval>> andRanges = new ArrayList<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTg2ODYxMQ=="}, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 197}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzE2NDI5Mw==", "bodyText": "I see your points now, yes, this can be simplified to list by sorting in the function. The time complexity may not be big a concern since the FilterQuery tree should not be too complex. I'll refactor this.", "url": "https://github.com/apache/pinot/pull/6259#discussion_r523164293", "createdAt": "2020-11-13T19:02:00Z", "author": {"login": "jtao15"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeRangeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeRangeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeRangeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeRangeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final TimeUnit _timeUnit;\n+\n+  private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n+\n+  public TimeRangeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    DateTimeFormatSpec formatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    _timeUnit = formatSpec.getColumnUnit();\n+    Preconditions\n+        .checkNotNull(_timeUnit, \"Time unit must be configured in the field spec for time column: %s of table: %s\",\n+            _timeColumn, _tableNameWithType);\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    onExternalViewChange(externalView, idealState, onlineSegments);\n+  }\n+\n+  @Override\n+  public void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    updateTimeRangeMSToSegmentSearchTree(onlineSegments);\n+  }\n+\n+  private void updateTimeRangeMSToSegmentSearchTree(Set<String> onlineSegments) {\n+    List<String> segments = new ArrayList<>(onlineSegments);\n+    // atomic swap _timeRangeToSegmentMap for input online segments\n+    List<String> segmentZKMetadataPaths = new ArrayList<>();\n+    for (String segment: segments) {\n+      segmentZKMetadataPaths.add(_segmentZKMetadataPathPrefix + segment);\n+    }\n+\n+    List<ZNRecord> znRecords = _propertyStore.get(segmentZKMetadataPaths, null, AccessOption.PERSISTENT, true);\n+\n+    List<Long> startTimes = new ArrayList<>();\n+    List<Long> endTimes = new ArrayList<>();\n+\n+    for (int i = 0; i < segments.size(); i++) {\n+      String segment = segments.get(i);\n+\n+      long[] range = extractStartEndTimeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(i));\n+      startTimes.add(range[0]);\n+      endTimes.add(range[1]);\n+    }\n+\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(startTimes, endTimes, segments);\n+  }\n+\n+\n+  private long[] extractStartEndTimeMSFromSegmentZKMetaZNRecord(String segment, @Nullable ZNRecord znRecord) {\n+    long[] range = {MIN_START_TIME, MAX_END_TIME};\n+    // Segments without metadata or with invalid time range will be set with [min_start, max_end] and will not be pruned\n+    if (znRecord == null) {\n+      LOGGER.warn(\"Failed to find segment ZK metadata for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return range;\n+    }\n+\n+    long startTime = znRecord.getLongField(CommonConstants.Segment.START_TIME, -1);\n+    long endTime = znRecord.getLongField(CommonConstants.Segment.END_TIME, -1);\n+    if (startTime < 0 || endTime < 0 || startTime > endTime) {\n+      LOGGER.warn(\"Failed to find valid end time for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return range;\n+    }\n+\n+    TimeUnit timeUnit = znRecord.getEnumField(CommonConstants.Segment.TIME_UNIT, TimeUnit.class, TimeUnit.DAYS);\n+    range[0] = timeUnit.toMillis(startTime);\n+    range[1] = timeUnit.toMillis(endTime);\n+    return range;\n+  }\n+\n+  @Override\n+  public void refreshSegment(String segment) {\n+    Set<String> segments;\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      segments = new HashSet<>();\n+    } else {\n+      segments = _timeRangeMSToSegmentSearchTree.getAllValues();\n+    }\n+    if (!segment.contains(segment)) {\n+      segments.add(segment);\n+    }\n+\n+    updateTimeRangeMSToSegmentSearchTree(segments);\n+  }\n+\n+  /**\n+   * NOTE: Pruning is done by searching _timeRangeToSegmentSearchTree based on request time range and check if the results\n+   *       are in the input segments. By doing so we will have run time O(M * logN) (N is the # of all online segments,\n+   *       M is the # of qualified intersected segments).\n+   */\n+  @Override\n+  public Set<String> prune(BrokerRequest brokerRequest, Set<String> segments) {\n+    // The pruned order may be different from the input order\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      return segments;\n+    }\n+    FilterQueryTree filterQueryTree = RequestUtils.generateFilterQueryTree(brokerRequest);\n+    if (filterQueryTree == null) {\n+      return segments;\n+    }\n+    List<Interval> ranges = getFilterTimeRange(filterQueryTree);\n+    if (ranges == null) { // cannot prune based on time for input request\n+      return segments;\n+    }\n+    if (ranges.size() == 0) { // invalid query time range\n+      return Collections.emptySet();\n+    }\n+\n+    Set<String> prunedSegments = new HashSet<>();\n+    for (Interval range : ranges) {\n+      Interval rangeMS = convertRangeToMS(range);\n+      for (Object segment : _timeRangeMSToSegmentSearchTree.searchAll(rangeMS)) {\n+        if (segments.contains(segment)) {\n+          prunedSegments.add((String) segment);\n+        }\n+      }\n+    }\n+    return new HashSet<String>(prunedSegments);\n+  }\n+\n+  private List<Interval> getFilterTimeRange(FilterQueryTree filterQueryTree) {\n+    // return NUll if no time range info or cannot filter base on the info (e.g. 'SELECT * from myTable where time < 50 OR firstName = Jason')\n+    // return an empty list if filtering range is specified but invalid (e.g. 'SELECT * from myTable where time < 50 AND time > 100')\n+    switch (filterQueryTree.getOperator()) {\n+      case AND:\n+        List<List<Interval>> andRanges = new ArrayList<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTg2ODYxMQ=="}, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 197}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3MTcyNjE5OnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeRangeSegmentPruner.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQwNjozNTowNlrOHxsVXA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQwNjozNTowNlrOHxsVXA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTg2ODYzNg==", "bodyText": "The list of list comment above for AND is applicable here as well", "url": "https://github.com/apache/pinot/pull/6259#discussion_r521868636", "createdAt": "2020-11-12T06:35:06Z", "author": {"login": "siddharthteotia"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeRangeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeRangeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeRangeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeRangeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final TimeUnit _timeUnit;\n+\n+  private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n+\n+  public TimeRangeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    DateTimeFormatSpec formatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    _timeUnit = formatSpec.getColumnUnit();\n+    Preconditions\n+        .checkNotNull(_timeUnit, \"Time unit must be configured in the field spec for time column: %s of table: %s\",\n+            _timeColumn, _tableNameWithType);\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    onExternalViewChange(externalView, idealState, onlineSegments);\n+  }\n+\n+  @Override\n+  public void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    updateTimeRangeMSToSegmentSearchTree(onlineSegments);\n+  }\n+\n+  private void updateTimeRangeMSToSegmentSearchTree(Set<String> onlineSegments) {\n+    List<String> segments = new ArrayList<>(onlineSegments);\n+    // atomic swap _timeRangeToSegmentMap for input online segments\n+    List<String> segmentZKMetadataPaths = new ArrayList<>();\n+    for (String segment: segments) {\n+      segmentZKMetadataPaths.add(_segmentZKMetadataPathPrefix + segment);\n+    }\n+\n+    List<ZNRecord> znRecords = _propertyStore.get(segmentZKMetadataPaths, null, AccessOption.PERSISTENT, true);\n+\n+    List<Long> startTimes = new ArrayList<>();\n+    List<Long> endTimes = new ArrayList<>();\n+\n+    for (int i = 0; i < segments.size(); i++) {\n+      String segment = segments.get(i);\n+\n+      long[] range = extractStartEndTimeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(i));\n+      startTimes.add(range[0]);\n+      endTimes.add(range[1]);\n+    }\n+\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(startTimes, endTimes, segments);\n+  }\n+\n+\n+  private long[] extractStartEndTimeMSFromSegmentZKMetaZNRecord(String segment, @Nullable ZNRecord znRecord) {\n+    long[] range = {MIN_START_TIME, MAX_END_TIME};\n+    // Segments without metadata or with invalid time range will be set with [min_start, max_end] and will not be pruned\n+    if (znRecord == null) {\n+      LOGGER.warn(\"Failed to find segment ZK metadata for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return range;\n+    }\n+\n+    long startTime = znRecord.getLongField(CommonConstants.Segment.START_TIME, -1);\n+    long endTime = znRecord.getLongField(CommonConstants.Segment.END_TIME, -1);\n+    if (startTime < 0 || endTime < 0 || startTime > endTime) {\n+      LOGGER.warn(\"Failed to find valid end time for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return range;\n+    }\n+\n+    TimeUnit timeUnit = znRecord.getEnumField(CommonConstants.Segment.TIME_UNIT, TimeUnit.class, TimeUnit.DAYS);\n+    range[0] = timeUnit.toMillis(startTime);\n+    range[1] = timeUnit.toMillis(endTime);\n+    return range;\n+  }\n+\n+  @Override\n+  public void refreshSegment(String segment) {\n+    Set<String> segments;\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      segments = new HashSet<>();\n+    } else {\n+      segments = _timeRangeMSToSegmentSearchTree.getAllValues();\n+    }\n+    if (!segment.contains(segment)) {\n+      segments.add(segment);\n+    }\n+\n+    updateTimeRangeMSToSegmentSearchTree(segments);\n+  }\n+\n+  /**\n+   * NOTE: Pruning is done by searching _timeRangeToSegmentSearchTree based on request time range and check if the results\n+   *       are in the input segments. By doing so we will have run time O(M * logN) (N is the # of all online segments,\n+   *       M is the # of qualified intersected segments).\n+   */\n+  @Override\n+  public Set<String> prune(BrokerRequest brokerRequest, Set<String> segments) {\n+    // The pruned order may be different from the input order\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      return segments;\n+    }\n+    FilterQueryTree filterQueryTree = RequestUtils.generateFilterQueryTree(brokerRequest);\n+    if (filterQueryTree == null) {\n+      return segments;\n+    }\n+    List<Interval> ranges = getFilterTimeRange(filterQueryTree);\n+    if (ranges == null) { // cannot prune based on time for input request\n+      return segments;\n+    }\n+    if (ranges.size() == 0) { // invalid query time range\n+      return Collections.emptySet();\n+    }\n+\n+    Set<String> prunedSegments = new HashSet<>();\n+    for (Interval range : ranges) {\n+      Interval rangeMS = convertRangeToMS(range);\n+      for (Object segment : _timeRangeMSToSegmentSearchTree.searchAll(rangeMS)) {\n+        if (segments.contains(segment)) {\n+          prunedSegments.add((String) segment);\n+        }\n+      }\n+    }\n+    return new HashSet<String>(prunedSegments);\n+  }\n+\n+  private List<Interval> getFilterTimeRange(FilterQueryTree filterQueryTree) {\n+    // return NUll if no time range info or cannot filter base on the info (e.g. 'SELECT * from myTable where time < 50 OR firstName = Jason')\n+    // return an empty list if filtering range is specified but invalid (e.g. 'SELECT * from myTable where time < 50 AND time > 100')\n+    switch (filterQueryTree.getOperator()) {\n+      case AND:\n+        List<List<Interval>> andRanges = new ArrayList<>();\n+        for (FilterQueryTree child : filterQueryTree.getChildren()) {\n+          List<Interval> childRanges = getFilterTimeRange(child);\n+          if (childRanges != null) {\n+            andRanges.add(childRanges);\n+          }\n+        }\n+        return getIntersectionSortedRanges(andRanges);\n+      case OR:\n+        List<List<Interval>> orRanges = new ArrayList<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 206}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3MTcyNjQ5OnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeRangeSegmentPruner.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQwNjozNToxM1rOHxsVhQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QxOTowMTo0OFrOHy7aEQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTg2ODY3Nw==", "bodyText": "IIUC, this is sorted merge of intervals. Given a list of intervals, it returns a sorted (and disjoint) list of intervals. The algorithm can internally first sort on startTime and then merge as opposed to asking the caller to pass sorted intervals?\nSecondly, I don't see where the input is sorted by the caller.", "url": "https://github.com/apache/pinot/pull/6259#discussion_r521868677", "createdAt": "2020-11-12T06:35:13Z", "author": {"login": "siddharthteotia"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeRangeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeRangeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeRangeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeRangeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final TimeUnit _timeUnit;\n+\n+  private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n+\n+  public TimeRangeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    DateTimeFormatSpec formatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    _timeUnit = formatSpec.getColumnUnit();\n+    Preconditions\n+        .checkNotNull(_timeUnit, \"Time unit must be configured in the field spec for time column: %s of table: %s\",\n+            _timeColumn, _tableNameWithType);\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    onExternalViewChange(externalView, idealState, onlineSegments);\n+  }\n+\n+  @Override\n+  public void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    updateTimeRangeMSToSegmentSearchTree(onlineSegments);\n+  }\n+\n+  private void updateTimeRangeMSToSegmentSearchTree(Set<String> onlineSegments) {\n+    List<String> segments = new ArrayList<>(onlineSegments);\n+    // atomic swap _timeRangeToSegmentMap for input online segments\n+    List<String> segmentZKMetadataPaths = new ArrayList<>();\n+    for (String segment: segments) {\n+      segmentZKMetadataPaths.add(_segmentZKMetadataPathPrefix + segment);\n+    }\n+\n+    List<ZNRecord> znRecords = _propertyStore.get(segmentZKMetadataPaths, null, AccessOption.PERSISTENT, true);\n+\n+    List<Long> startTimes = new ArrayList<>();\n+    List<Long> endTimes = new ArrayList<>();\n+\n+    for (int i = 0; i < segments.size(); i++) {\n+      String segment = segments.get(i);\n+\n+      long[] range = extractStartEndTimeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(i));\n+      startTimes.add(range[0]);\n+      endTimes.add(range[1]);\n+    }\n+\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(startTimes, endTimes, segments);\n+  }\n+\n+\n+  private long[] extractStartEndTimeMSFromSegmentZKMetaZNRecord(String segment, @Nullable ZNRecord znRecord) {\n+    long[] range = {MIN_START_TIME, MAX_END_TIME};\n+    // Segments without metadata or with invalid time range will be set with [min_start, max_end] and will not be pruned\n+    if (znRecord == null) {\n+      LOGGER.warn(\"Failed to find segment ZK metadata for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return range;\n+    }\n+\n+    long startTime = znRecord.getLongField(CommonConstants.Segment.START_TIME, -1);\n+    long endTime = znRecord.getLongField(CommonConstants.Segment.END_TIME, -1);\n+    if (startTime < 0 || endTime < 0 || startTime > endTime) {\n+      LOGGER.warn(\"Failed to find valid end time for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return range;\n+    }\n+\n+    TimeUnit timeUnit = znRecord.getEnumField(CommonConstants.Segment.TIME_UNIT, TimeUnit.class, TimeUnit.DAYS);\n+    range[0] = timeUnit.toMillis(startTime);\n+    range[1] = timeUnit.toMillis(endTime);\n+    return range;\n+  }\n+\n+  @Override\n+  public void refreshSegment(String segment) {\n+    Set<String> segments;\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      segments = new HashSet<>();\n+    } else {\n+      segments = _timeRangeMSToSegmentSearchTree.getAllValues();\n+    }\n+    if (!segment.contains(segment)) {\n+      segments.add(segment);\n+    }\n+\n+    updateTimeRangeMSToSegmentSearchTree(segments);\n+  }\n+\n+  /**\n+   * NOTE: Pruning is done by searching _timeRangeToSegmentSearchTree based on request time range and check if the results\n+   *       are in the input segments. By doing so we will have run time O(M * logN) (N is the # of all online segments,\n+   *       M is the # of qualified intersected segments).\n+   */\n+  @Override\n+  public Set<String> prune(BrokerRequest brokerRequest, Set<String> segments) {\n+    // The pruned order may be different from the input order\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      return segments;\n+    }\n+    FilterQueryTree filterQueryTree = RequestUtils.generateFilterQueryTree(brokerRequest);\n+    if (filterQueryTree == null) {\n+      return segments;\n+    }\n+    List<Interval> ranges = getFilterTimeRange(filterQueryTree);\n+    if (ranges == null) { // cannot prune based on time for input request\n+      return segments;\n+    }\n+    if (ranges.size() == 0) { // invalid query time range\n+      return Collections.emptySet();\n+    }\n+\n+    Set<String> prunedSegments = new HashSet<>();\n+    for (Interval range : ranges) {\n+      Interval rangeMS = convertRangeToMS(range);\n+      for (Object segment : _timeRangeMSToSegmentSearchTree.searchAll(rangeMS)) {\n+        if (segments.contains(segment)) {\n+          prunedSegments.add((String) segment);\n+        }\n+      }\n+    }\n+    return new HashSet<String>(prunedSegments);\n+  }\n+\n+  private List<Interval> getFilterTimeRange(FilterQueryTree filterQueryTree) {\n+    // return NUll if no time range info or cannot filter base on the info (e.g. 'SELECT * from myTable where time < 50 OR firstName = Jason')\n+    // return an empty list if filtering range is specified but invalid (e.g. 'SELECT * from myTable where time < 50 AND time > 100')\n+    switch (filterQueryTree.getOperator()) {\n+      case AND:\n+        List<List<Interval>> andRanges = new ArrayList<>();\n+        for (FilterQueryTree child : filterQueryTree.getChildren()) {\n+          List<Interval> childRanges = getFilterTimeRange(child);\n+          if (childRanges != null) {\n+            andRanges.add(childRanges);\n+          }\n+        }\n+        return getIntersectionSortedRanges(andRanges);\n+      case OR:\n+        List<List<Interval>> orRanges = new ArrayList<>();\n+        for (FilterQueryTree child : filterQueryTree.getChildren()) {\n+          List<Interval> childRanges = getFilterTimeRange(child);\n+          if (childRanges == null) {\n+            return null;\n+          } else {\n+            orRanges.add(childRanges);\n+          }\n+        }\n+        return getUnionSortedRanges(orRanges);\n+      case EQUALITY:\n+        if (filterQueryTree.getColumn().equals(_timeColumn)) {\n+          long timeStamp = Long.parseLong(filterQueryTree.getValue().get(0));\n+          return Collections.singletonList(new Interval(timeStamp, timeStamp));\n+        }\n+        return null;\n+      case RANGE:\n+        if (filterQueryTree.getColumn().equals(_timeColumn)) {\n+          return parseRange(filterQueryTree.getValue());\n+        }\n+        return null;\n+      default:\n+        return null;\n+    }\n+  }\n+\n+  private Interval convertRangeToMS(Interval range) {\n+    long min = range.min == MIN_START_TIME ? MIN_START_TIME : _timeUnit.toMillis(range.min);\n+    long max = range.max == MAX_END_TIME ? MAX_END_TIME : _timeUnit.toMillis(range.max);\n+    return new Interval(min, max);\n+  }\n+\n+  private List<Interval> getIntersectionSortedRanges(List<List<Interval>> ranges) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 238}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjUzMzg5NQ==", "bodyText": "Yes, I was assuming the input ranges are sorted. I think in this case the leaf of the queryFilterTree will always contains only one range, and getting the intersection/union ranges from leaves will return a sorted result. So the input for this function and getUnionSortedRange() should always be sorted.", "url": "https://github.com/apache/pinot/pull/6259#discussion_r522533895", "createdAt": "2020-11-13T00:48:17Z", "author": {"login": "jtao15"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeRangeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeRangeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeRangeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeRangeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final TimeUnit _timeUnit;\n+\n+  private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n+\n+  public TimeRangeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    DateTimeFormatSpec formatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    _timeUnit = formatSpec.getColumnUnit();\n+    Preconditions\n+        .checkNotNull(_timeUnit, \"Time unit must be configured in the field spec for time column: %s of table: %s\",\n+            _timeColumn, _tableNameWithType);\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    onExternalViewChange(externalView, idealState, onlineSegments);\n+  }\n+\n+  @Override\n+  public void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    updateTimeRangeMSToSegmentSearchTree(onlineSegments);\n+  }\n+\n+  private void updateTimeRangeMSToSegmentSearchTree(Set<String> onlineSegments) {\n+    List<String> segments = new ArrayList<>(onlineSegments);\n+    // atomic swap _timeRangeToSegmentMap for input online segments\n+    List<String> segmentZKMetadataPaths = new ArrayList<>();\n+    for (String segment: segments) {\n+      segmentZKMetadataPaths.add(_segmentZKMetadataPathPrefix + segment);\n+    }\n+\n+    List<ZNRecord> znRecords = _propertyStore.get(segmentZKMetadataPaths, null, AccessOption.PERSISTENT, true);\n+\n+    List<Long> startTimes = new ArrayList<>();\n+    List<Long> endTimes = new ArrayList<>();\n+\n+    for (int i = 0; i < segments.size(); i++) {\n+      String segment = segments.get(i);\n+\n+      long[] range = extractStartEndTimeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(i));\n+      startTimes.add(range[0]);\n+      endTimes.add(range[1]);\n+    }\n+\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(startTimes, endTimes, segments);\n+  }\n+\n+\n+  private long[] extractStartEndTimeMSFromSegmentZKMetaZNRecord(String segment, @Nullable ZNRecord znRecord) {\n+    long[] range = {MIN_START_TIME, MAX_END_TIME};\n+    // Segments without metadata or with invalid time range will be set with [min_start, max_end] and will not be pruned\n+    if (znRecord == null) {\n+      LOGGER.warn(\"Failed to find segment ZK metadata for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return range;\n+    }\n+\n+    long startTime = znRecord.getLongField(CommonConstants.Segment.START_TIME, -1);\n+    long endTime = znRecord.getLongField(CommonConstants.Segment.END_TIME, -1);\n+    if (startTime < 0 || endTime < 0 || startTime > endTime) {\n+      LOGGER.warn(\"Failed to find valid end time for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return range;\n+    }\n+\n+    TimeUnit timeUnit = znRecord.getEnumField(CommonConstants.Segment.TIME_UNIT, TimeUnit.class, TimeUnit.DAYS);\n+    range[0] = timeUnit.toMillis(startTime);\n+    range[1] = timeUnit.toMillis(endTime);\n+    return range;\n+  }\n+\n+  @Override\n+  public void refreshSegment(String segment) {\n+    Set<String> segments;\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      segments = new HashSet<>();\n+    } else {\n+      segments = _timeRangeMSToSegmentSearchTree.getAllValues();\n+    }\n+    if (!segment.contains(segment)) {\n+      segments.add(segment);\n+    }\n+\n+    updateTimeRangeMSToSegmentSearchTree(segments);\n+  }\n+\n+  /**\n+   * NOTE: Pruning is done by searching _timeRangeToSegmentSearchTree based on request time range and check if the results\n+   *       are in the input segments. By doing so we will have run time O(M * logN) (N is the # of all online segments,\n+   *       M is the # of qualified intersected segments).\n+   */\n+  @Override\n+  public Set<String> prune(BrokerRequest brokerRequest, Set<String> segments) {\n+    // The pruned order may be different from the input order\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      return segments;\n+    }\n+    FilterQueryTree filterQueryTree = RequestUtils.generateFilterQueryTree(brokerRequest);\n+    if (filterQueryTree == null) {\n+      return segments;\n+    }\n+    List<Interval> ranges = getFilterTimeRange(filterQueryTree);\n+    if (ranges == null) { // cannot prune based on time for input request\n+      return segments;\n+    }\n+    if (ranges.size() == 0) { // invalid query time range\n+      return Collections.emptySet();\n+    }\n+\n+    Set<String> prunedSegments = new HashSet<>();\n+    for (Interval range : ranges) {\n+      Interval rangeMS = convertRangeToMS(range);\n+      for (Object segment : _timeRangeMSToSegmentSearchTree.searchAll(rangeMS)) {\n+        if (segments.contains(segment)) {\n+          prunedSegments.add((String) segment);\n+        }\n+      }\n+    }\n+    return new HashSet<String>(prunedSegments);\n+  }\n+\n+  private List<Interval> getFilterTimeRange(FilterQueryTree filterQueryTree) {\n+    // return NUll if no time range info or cannot filter base on the info (e.g. 'SELECT * from myTable where time < 50 OR firstName = Jason')\n+    // return an empty list if filtering range is specified but invalid (e.g. 'SELECT * from myTable where time < 50 AND time > 100')\n+    switch (filterQueryTree.getOperator()) {\n+      case AND:\n+        List<List<Interval>> andRanges = new ArrayList<>();\n+        for (FilterQueryTree child : filterQueryTree.getChildren()) {\n+          List<Interval> childRanges = getFilterTimeRange(child);\n+          if (childRanges != null) {\n+            andRanges.add(childRanges);\n+          }\n+        }\n+        return getIntersectionSortedRanges(andRanges);\n+      case OR:\n+        List<List<Interval>> orRanges = new ArrayList<>();\n+        for (FilterQueryTree child : filterQueryTree.getChildren()) {\n+          List<Interval> childRanges = getFilterTimeRange(child);\n+          if (childRanges == null) {\n+            return null;\n+          } else {\n+            orRanges.add(childRanges);\n+          }\n+        }\n+        return getUnionSortedRanges(orRanges);\n+      case EQUALITY:\n+        if (filterQueryTree.getColumn().equals(_timeColumn)) {\n+          long timeStamp = Long.parseLong(filterQueryTree.getValue().get(0));\n+          return Collections.singletonList(new Interval(timeStamp, timeStamp));\n+        }\n+        return null;\n+      case RANGE:\n+        if (filterQueryTree.getColumn().equals(_timeColumn)) {\n+          return parseRange(filterQueryTree.getValue());\n+        }\n+        return null;\n+      default:\n+        return null;\n+    }\n+  }\n+\n+  private Interval convertRangeToMS(Interval range) {\n+    long min = range.min == MIN_START_TIME ? MIN_START_TIME : _timeUnit.toMillis(range.min);\n+    long max = range.max == MAX_END_TIME ? MAX_END_TIME : _timeUnit.toMillis(range.max);\n+    return new Interval(min, max);\n+  }\n+\n+  private List<Interval> getIntersectionSortedRanges(List<List<Interval>> ranges) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTg2ODY3Nw=="}, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 238}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjU4NzkxMA==", "bodyText": "Consider the simple case of an AND tree with 2 immediate leaves\nWhen the recursion returns to AND (end of for loop), it will have a list with 2 intervals (one from each child). How do we guarantee that they are already sorted?", "url": "https://github.com/apache/pinot/pull/6259#discussion_r522587910", "createdAt": "2020-11-13T03:16:22Z", "author": {"login": "siddharthteotia"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeRangeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeRangeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeRangeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeRangeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final TimeUnit _timeUnit;\n+\n+  private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n+\n+  public TimeRangeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    DateTimeFormatSpec formatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    _timeUnit = formatSpec.getColumnUnit();\n+    Preconditions\n+        .checkNotNull(_timeUnit, \"Time unit must be configured in the field spec for time column: %s of table: %s\",\n+            _timeColumn, _tableNameWithType);\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    onExternalViewChange(externalView, idealState, onlineSegments);\n+  }\n+\n+  @Override\n+  public void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    updateTimeRangeMSToSegmentSearchTree(onlineSegments);\n+  }\n+\n+  private void updateTimeRangeMSToSegmentSearchTree(Set<String> onlineSegments) {\n+    List<String> segments = new ArrayList<>(onlineSegments);\n+    // atomic swap _timeRangeToSegmentMap for input online segments\n+    List<String> segmentZKMetadataPaths = new ArrayList<>();\n+    for (String segment: segments) {\n+      segmentZKMetadataPaths.add(_segmentZKMetadataPathPrefix + segment);\n+    }\n+\n+    List<ZNRecord> znRecords = _propertyStore.get(segmentZKMetadataPaths, null, AccessOption.PERSISTENT, true);\n+\n+    List<Long> startTimes = new ArrayList<>();\n+    List<Long> endTimes = new ArrayList<>();\n+\n+    for (int i = 0; i < segments.size(); i++) {\n+      String segment = segments.get(i);\n+\n+      long[] range = extractStartEndTimeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(i));\n+      startTimes.add(range[0]);\n+      endTimes.add(range[1]);\n+    }\n+\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(startTimes, endTimes, segments);\n+  }\n+\n+\n+  private long[] extractStartEndTimeMSFromSegmentZKMetaZNRecord(String segment, @Nullable ZNRecord znRecord) {\n+    long[] range = {MIN_START_TIME, MAX_END_TIME};\n+    // Segments without metadata or with invalid time range will be set with [min_start, max_end] and will not be pruned\n+    if (znRecord == null) {\n+      LOGGER.warn(\"Failed to find segment ZK metadata for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return range;\n+    }\n+\n+    long startTime = znRecord.getLongField(CommonConstants.Segment.START_TIME, -1);\n+    long endTime = znRecord.getLongField(CommonConstants.Segment.END_TIME, -1);\n+    if (startTime < 0 || endTime < 0 || startTime > endTime) {\n+      LOGGER.warn(\"Failed to find valid end time for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return range;\n+    }\n+\n+    TimeUnit timeUnit = znRecord.getEnumField(CommonConstants.Segment.TIME_UNIT, TimeUnit.class, TimeUnit.DAYS);\n+    range[0] = timeUnit.toMillis(startTime);\n+    range[1] = timeUnit.toMillis(endTime);\n+    return range;\n+  }\n+\n+  @Override\n+  public void refreshSegment(String segment) {\n+    Set<String> segments;\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      segments = new HashSet<>();\n+    } else {\n+      segments = _timeRangeMSToSegmentSearchTree.getAllValues();\n+    }\n+    if (!segment.contains(segment)) {\n+      segments.add(segment);\n+    }\n+\n+    updateTimeRangeMSToSegmentSearchTree(segments);\n+  }\n+\n+  /**\n+   * NOTE: Pruning is done by searching _timeRangeToSegmentSearchTree based on request time range and check if the results\n+   *       are in the input segments. By doing so we will have run time O(M * logN) (N is the # of all online segments,\n+   *       M is the # of qualified intersected segments).\n+   */\n+  @Override\n+  public Set<String> prune(BrokerRequest brokerRequest, Set<String> segments) {\n+    // The pruned order may be different from the input order\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      return segments;\n+    }\n+    FilterQueryTree filterQueryTree = RequestUtils.generateFilterQueryTree(brokerRequest);\n+    if (filterQueryTree == null) {\n+      return segments;\n+    }\n+    List<Interval> ranges = getFilterTimeRange(filterQueryTree);\n+    if (ranges == null) { // cannot prune based on time for input request\n+      return segments;\n+    }\n+    if (ranges.size() == 0) { // invalid query time range\n+      return Collections.emptySet();\n+    }\n+\n+    Set<String> prunedSegments = new HashSet<>();\n+    for (Interval range : ranges) {\n+      Interval rangeMS = convertRangeToMS(range);\n+      for (Object segment : _timeRangeMSToSegmentSearchTree.searchAll(rangeMS)) {\n+        if (segments.contains(segment)) {\n+          prunedSegments.add((String) segment);\n+        }\n+      }\n+    }\n+    return new HashSet<String>(prunedSegments);\n+  }\n+\n+  private List<Interval> getFilterTimeRange(FilterQueryTree filterQueryTree) {\n+    // return NUll if no time range info or cannot filter base on the info (e.g. 'SELECT * from myTable where time < 50 OR firstName = Jason')\n+    // return an empty list if filtering range is specified but invalid (e.g. 'SELECT * from myTable where time < 50 AND time > 100')\n+    switch (filterQueryTree.getOperator()) {\n+      case AND:\n+        List<List<Interval>> andRanges = new ArrayList<>();\n+        for (FilterQueryTree child : filterQueryTree.getChildren()) {\n+          List<Interval> childRanges = getFilterTimeRange(child);\n+          if (childRanges != null) {\n+            andRanges.add(childRanges);\n+          }\n+        }\n+        return getIntersectionSortedRanges(andRanges);\n+      case OR:\n+        List<List<Interval>> orRanges = new ArrayList<>();\n+        for (FilterQueryTree child : filterQueryTree.getChildren()) {\n+          List<Interval> childRanges = getFilterTimeRange(child);\n+          if (childRanges == null) {\n+            return null;\n+          } else {\n+            orRanges.add(childRanges);\n+          }\n+        }\n+        return getUnionSortedRanges(orRanges);\n+      case EQUALITY:\n+        if (filterQueryTree.getColumn().equals(_timeColumn)) {\n+          long timeStamp = Long.parseLong(filterQueryTree.getValue().get(0));\n+          return Collections.singletonList(new Interval(timeStamp, timeStamp));\n+        }\n+        return null;\n+      case RANGE:\n+        if (filterQueryTree.getColumn().equals(_timeColumn)) {\n+          return parseRange(filterQueryTree.getValue());\n+        }\n+        return null;\n+      default:\n+        return null;\n+    }\n+  }\n+\n+  private Interval convertRangeToMS(Interval range) {\n+    long min = range.min == MIN_START_TIME ? MIN_START_TIME : _timeUnit.toMillis(range.min);\n+    long max = range.max == MAX_END_TIME ? MAX_END_TIME : _timeUnit.toMillis(range.max);\n+    return new Interval(min, max);\n+  }\n+\n+  private List<Interval> getIntersectionSortedRanges(List<List<Interval>> ranges) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTg2ODY3Nw=="}, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 238}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzE2NDE3Nw==", "bodyText": "I was basically doing a merge sort, the input for getIntersectionOfTwoSortedRanges()(where merge happens) will be two sorted lists(both contains one single element) the merging process guarantees that the output will be sorted. And so will the returned list for getIntersectionSortedRanges be sorted.", "url": "https://github.com/apache/pinot/pull/6259#discussion_r523164177", "createdAt": "2020-11-13T19:01:48Z", "author": {"login": "jtao15"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeRangeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeRangeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeRangeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeRangeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final TimeUnit _timeUnit;\n+\n+  private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n+\n+  public TimeRangeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    DateTimeFormatSpec formatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    _timeUnit = formatSpec.getColumnUnit();\n+    Preconditions\n+        .checkNotNull(_timeUnit, \"Time unit must be configured in the field spec for time column: %s of table: %s\",\n+            _timeColumn, _tableNameWithType);\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    onExternalViewChange(externalView, idealState, onlineSegments);\n+  }\n+\n+  @Override\n+  public void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    updateTimeRangeMSToSegmentSearchTree(onlineSegments);\n+  }\n+\n+  private void updateTimeRangeMSToSegmentSearchTree(Set<String> onlineSegments) {\n+    List<String> segments = new ArrayList<>(onlineSegments);\n+    // atomic swap _timeRangeToSegmentMap for input online segments\n+    List<String> segmentZKMetadataPaths = new ArrayList<>();\n+    for (String segment: segments) {\n+      segmentZKMetadataPaths.add(_segmentZKMetadataPathPrefix + segment);\n+    }\n+\n+    List<ZNRecord> znRecords = _propertyStore.get(segmentZKMetadataPaths, null, AccessOption.PERSISTENT, true);\n+\n+    List<Long> startTimes = new ArrayList<>();\n+    List<Long> endTimes = new ArrayList<>();\n+\n+    for (int i = 0; i < segments.size(); i++) {\n+      String segment = segments.get(i);\n+\n+      long[] range = extractStartEndTimeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(i));\n+      startTimes.add(range[0]);\n+      endTimes.add(range[1]);\n+    }\n+\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(startTimes, endTimes, segments);\n+  }\n+\n+\n+  private long[] extractStartEndTimeMSFromSegmentZKMetaZNRecord(String segment, @Nullable ZNRecord znRecord) {\n+    long[] range = {MIN_START_TIME, MAX_END_TIME};\n+    // Segments without metadata or with invalid time range will be set with [min_start, max_end] and will not be pruned\n+    if (znRecord == null) {\n+      LOGGER.warn(\"Failed to find segment ZK metadata for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return range;\n+    }\n+\n+    long startTime = znRecord.getLongField(CommonConstants.Segment.START_TIME, -1);\n+    long endTime = znRecord.getLongField(CommonConstants.Segment.END_TIME, -1);\n+    if (startTime < 0 || endTime < 0 || startTime > endTime) {\n+      LOGGER.warn(\"Failed to find valid end time for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return range;\n+    }\n+\n+    TimeUnit timeUnit = znRecord.getEnumField(CommonConstants.Segment.TIME_UNIT, TimeUnit.class, TimeUnit.DAYS);\n+    range[0] = timeUnit.toMillis(startTime);\n+    range[1] = timeUnit.toMillis(endTime);\n+    return range;\n+  }\n+\n+  @Override\n+  public void refreshSegment(String segment) {\n+    Set<String> segments;\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      segments = new HashSet<>();\n+    } else {\n+      segments = _timeRangeMSToSegmentSearchTree.getAllValues();\n+    }\n+    if (!segment.contains(segment)) {\n+      segments.add(segment);\n+    }\n+\n+    updateTimeRangeMSToSegmentSearchTree(segments);\n+  }\n+\n+  /**\n+   * NOTE: Pruning is done by searching _timeRangeToSegmentSearchTree based on request time range and check if the results\n+   *       are in the input segments. By doing so we will have run time O(M * logN) (N is the # of all online segments,\n+   *       M is the # of qualified intersected segments).\n+   */\n+  @Override\n+  public Set<String> prune(BrokerRequest brokerRequest, Set<String> segments) {\n+    // The pruned order may be different from the input order\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      return segments;\n+    }\n+    FilterQueryTree filterQueryTree = RequestUtils.generateFilterQueryTree(brokerRequest);\n+    if (filterQueryTree == null) {\n+      return segments;\n+    }\n+    List<Interval> ranges = getFilterTimeRange(filterQueryTree);\n+    if (ranges == null) { // cannot prune based on time for input request\n+      return segments;\n+    }\n+    if (ranges.size() == 0) { // invalid query time range\n+      return Collections.emptySet();\n+    }\n+\n+    Set<String> prunedSegments = new HashSet<>();\n+    for (Interval range : ranges) {\n+      Interval rangeMS = convertRangeToMS(range);\n+      for (Object segment : _timeRangeMSToSegmentSearchTree.searchAll(rangeMS)) {\n+        if (segments.contains(segment)) {\n+          prunedSegments.add((String) segment);\n+        }\n+      }\n+    }\n+    return new HashSet<String>(prunedSegments);\n+  }\n+\n+  private List<Interval> getFilterTimeRange(FilterQueryTree filterQueryTree) {\n+    // return NUll if no time range info or cannot filter base on the info (e.g. 'SELECT * from myTable where time < 50 OR firstName = Jason')\n+    // return an empty list if filtering range is specified but invalid (e.g. 'SELECT * from myTable where time < 50 AND time > 100')\n+    switch (filterQueryTree.getOperator()) {\n+      case AND:\n+        List<List<Interval>> andRanges = new ArrayList<>();\n+        for (FilterQueryTree child : filterQueryTree.getChildren()) {\n+          List<Interval> childRanges = getFilterTimeRange(child);\n+          if (childRanges != null) {\n+            andRanges.add(childRanges);\n+          }\n+        }\n+        return getIntersectionSortedRanges(andRanges);\n+      case OR:\n+        List<List<Interval>> orRanges = new ArrayList<>();\n+        for (FilterQueryTree child : filterQueryTree.getChildren()) {\n+          List<Interval> childRanges = getFilterTimeRange(child);\n+          if (childRanges == null) {\n+            return null;\n+          } else {\n+            orRanges.add(childRanges);\n+          }\n+        }\n+        return getUnionSortedRanges(orRanges);\n+      case EQUALITY:\n+        if (filterQueryTree.getColumn().equals(_timeColumn)) {\n+          long timeStamp = Long.parseLong(filterQueryTree.getValue().get(0));\n+          return Collections.singletonList(new Interval(timeStamp, timeStamp));\n+        }\n+        return null;\n+      case RANGE:\n+        if (filterQueryTree.getColumn().equals(_timeColumn)) {\n+          return parseRange(filterQueryTree.getValue());\n+        }\n+        return null;\n+      default:\n+        return null;\n+    }\n+  }\n+\n+  private Interval convertRangeToMS(Interval range) {\n+    long min = range.min == MIN_START_TIME ? MIN_START_TIME : _timeUnit.toMillis(range.min);\n+    long max = range.max == MAX_END_TIME ? MAX_END_TIME : _timeUnit.toMillis(range.max);\n+    return new Interval(min, max);\n+  }\n+\n+  private List<Interval> getIntersectionSortedRanges(List<List<Interval>> ranges) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTg2ODY3Nw=="}, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 238}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3MTcyNjgyOnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeRangeSegmentPruner.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQwNjozNToyMlrOHxsVtw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQwNjozNToyMlrOHxsVtw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTg2ODcyNw==", "bodyText": "I think this and the next method can be simplified into one method that works on List<Interval> ranges and not List<List<Interval>> ranges", "url": "https://github.com/apache/pinot/pull/6259#discussion_r521868727", "createdAt": "2020-11-12T06:35:22Z", "author": {"login": "siddharthteotia"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeRangeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeRangeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeRangeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeRangeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final TimeUnit _timeUnit;\n+\n+  private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n+\n+  public TimeRangeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    DateTimeFormatSpec formatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    _timeUnit = formatSpec.getColumnUnit();\n+    Preconditions\n+        .checkNotNull(_timeUnit, \"Time unit must be configured in the field spec for time column: %s of table: %s\",\n+            _timeColumn, _tableNameWithType);\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    onExternalViewChange(externalView, idealState, onlineSegments);\n+  }\n+\n+  @Override\n+  public void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    updateTimeRangeMSToSegmentSearchTree(onlineSegments);\n+  }\n+\n+  private void updateTimeRangeMSToSegmentSearchTree(Set<String> onlineSegments) {\n+    List<String> segments = new ArrayList<>(onlineSegments);\n+    // atomic swap _timeRangeToSegmentMap for input online segments\n+    List<String> segmentZKMetadataPaths = new ArrayList<>();\n+    for (String segment: segments) {\n+      segmentZKMetadataPaths.add(_segmentZKMetadataPathPrefix + segment);\n+    }\n+\n+    List<ZNRecord> znRecords = _propertyStore.get(segmentZKMetadataPaths, null, AccessOption.PERSISTENT, true);\n+\n+    List<Long> startTimes = new ArrayList<>();\n+    List<Long> endTimes = new ArrayList<>();\n+\n+    for (int i = 0; i < segments.size(); i++) {\n+      String segment = segments.get(i);\n+\n+      long[] range = extractStartEndTimeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(i));\n+      startTimes.add(range[0]);\n+      endTimes.add(range[1]);\n+    }\n+\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(startTimes, endTimes, segments);\n+  }\n+\n+\n+  private long[] extractStartEndTimeMSFromSegmentZKMetaZNRecord(String segment, @Nullable ZNRecord znRecord) {\n+    long[] range = {MIN_START_TIME, MAX_END_TIME};\n+    // Segments without metadata or with invalid time range will be set with [min_start, max_end] and will not be pruned\n+    if (znRecord == null) {\n+      LOGGER.warn(\"Failed to find segment ZK metadata for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return range;\n+    }\n+\n+    long startTime = znRecord.getLongField(CommonConstants.Segment.START_TIME, -1);\n+    long endTime = znRecord.getLongField(CommonConstants.Segment.END_TIME, -1);\n+    if (startTime < 0 || endTime < 0 || startTime > endTime) {\n+      LOGGER.warn(\"Failed to find valid end time for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return range;\n+    }\n+\n+    TimeUnit timeUnit = znRecord.getEnumField(CommonConstants.Segment.TIME_UNIT, TimeUnit.class, TimeUnit.DAYS);\n+    range[0] = timeUnit.toMillis(startTime);\n+    range[1] = timeUnit.toMillis(endTime);\n+    return range;\n+  }\n+\n+  @Override\n+  public void refreshSegment(String segment) {\n+    Set<String> segments;\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      segments = new HashSet<>();\n+    } else {\n+      segments = _timeRangeMSToSegmentSearchTree.getAllValues();\n+    }\n+    if (!segment.contains(segment)) {\n+      segments.add(segment);\n+    }\n+\n+    updateTimeRangeMSToSegmentSearchTree(segments);\n+  }\n+\n+  /**\n+   * NOTE: Pruning is done by searching _timeRangeToSegmentSearchTree based on request time range and check if the results\n+   *       are in the input segments. By doing so we will have run time O(M * logN) (N is the # of all online segments,\n+   *       M is the # of qualified intersected segments).\n+   */\n+  @Override\n+  public Set<String> prune(BrokerRequest brokerRequest, Set<String> segments) {\n+    // The pruned order may be different from the input order\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      return segments;\n+    }\n+    FilterQueryTree filterQueryTree = RequestUtils.generateFilterQueryTree(brokerRequest);\n+    if (filterQueryTree == null) {\n+      return segments;\n+    }\n+    List<Interval> ranges = getFilterTimeRange(filterQueryTree);\n+    if (ranges == null) { // cannot prune based on time for input request\n+      return segments;\n+    }\n+    if (ranges.size() == 0) { // invalid query time range\n+      return Collections.emptySet();\n+    }\n+\n+    Set<String> prunedSegments = new HashSet<>();\n+    for (Interval range : ranges) {\n+      Interval rangeMS = convertRangeToMS(range);\n+      for (Object segment : _timeRangeMSToSegmentSearchTree.searchAll(rangeMS)) {\n+        if (segments.contains(segment)) {\n+          prunedSegments.add((String) segment);\n+        }\n+      }\n+    }\n+    return new HashSet<String>(prunedSegments);\n+  }\n+\n+  private List<Interval> getFilterTimeRange(FilterQueryTree filterQueryTree) {\n+    // return NUll if no time range info or cannot filter base on the info (e.g. 'SELECT * from myTable where time < 50 OR firstName = Jason')\n+    // return an empty list if filtering range is specified but invalid (e.g. 'SELECT * from myTable where time < 50 AND time > 100')\n+    switch (filterQueryTree.getOperator()) {\n+      case AND:\n+        List<List<Interval>> andRanges = new ArrayList<>();\n+        for (FilterQueryTree child : filterQueryTree.getChildren()) {\n+          List<Interval> childRanges = getFilterTimeRange(child);\n+          if (childRanges != null) {\n+            andRanges.add(childRanges);\n+          }\n+        }\n+        return getIntersectionSortedRanges(andRanges);\n+      case OR:\n+        List<List<Interval>> orRanges = new ArrayList<>();\n+        for (FilterQueryTree child : filterQueryTree.getChildren()) {\n+          List<Interval> childRanges = getFilterTimeRange(child);\n+          if (childRanges == null) {\n+            return null;\n+          } else {\n+            orRanges.add(childRanges);\n+          }\n+        }\n+        return getUnionSortedRanges(orRanges);\n+      case EQUALITY:\n+        if (filterQueryTree.getColumn().equals(_timeColumn)) {\n+          long timeStamp = Long.parseLong(filterQueryTree.getValue().get(0));\n+          return Collections.singletonList(new Interval(timeStamp, timeStamp));\n+        }\n+        return null;\n+      case RANGE:\n+        if (filterQueryTree.getColumn().equals(_timeColumn)) {\n+          return parseRange(filterQueryTree.getValue());\n+        }\n+        return null;\n+      default:\n+        return null;\n+    }\n+  }\n+\n+  private Interval convertRangeToMS(Interval range) {\n+    long min = range.min == MIN_START_TIME ? MIN_START_TIME : _timeUnit.toMillis(range.min);\n+    long max = range.max == MAX_END_TIME ? MAX_END_TIME : _timeUnit.toMillis(range.max);\n+    return new Interval(min, max);\n+  }\n+\n+  private List<Interval> getIntersectionSortedRanges(List<List<Interval>> ranges) {\n+    // Requires input ranges are sorted, the return ranges will be sorted\n+    return getIntersectionSortedRanges(ranges, 0, ranges.size());\n+  }\n+\n+  private List<Interval> getIntersectionSortedRanges(List<List<Interval>> ranges, int start, int end) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 243}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3MTczMTU2OnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeRangeSegmentPruner.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQwNjozNzozOFrOHxsYlw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQwNjozNzozOFrOHxsYlw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTg2OTQ2Mw==", "bodyText": "I think List of list is complicating the algorithm slightly. We can combine these two methods into one method that does sorted merge of two List<Interval> range1, List<Interval> range2", "url": "https://github.com/apache/pinot/pull/6259#discussion_r521869463", "createdAt": "2020-11-12T06:37:38Z", "author": {"login": "siddharthteotia"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeRangeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeRangeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeRangeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeRangeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final TimeUnit _timeUnit;\n+\n+  private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n+\n+  public TimeRangeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    DateTimeFormatSpec formatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    _timeUnit = formatSpec.getColumnUnit();\n+    Preconditions\n+        .checkNotNull(_timeUnit, \"Time unit must be configured in the field spec for time column: %s of table: %s\",\n+            _timeColumn, _tableNameWithType);\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    onExternalViewChange(externalView, idealState, onlineSegments);\n+  }\n+\n+  @Override\n+  public void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    updateTimeRangeMSToSegmentSearchTree(onlineSegments);\n+  }\n+\n+  private void updateTimeRangeMSToSegmentSearchTree(Set<String> onlineSegments) {\n+    List<String> segments = new ArrayList<>(onlineSegments);\n+    // atomic swap _timeRangeToSegmentMap for input online segments\n+    List<String> segmentZKMetadataPaths = new ArrayList<>();\n+    for (String segment: segments) {\n+      segmentZKMetadataPaths.add(_segmentZKMetadataPathPrefix + segment);\n+    }\n+\n+    List<ZNRecord> znRecords = _propertyStore.get(segmentZKMetadataPaths, null, AccessOption.PERSISTENT, true);\n+\n+    List<Long> startTimes = new ArrayList<>();\n+    List<Long> endTimes = new ArrayList<>();\n+\n+    for (int i = 0; i < segments.size(); i++) {\n+      String segment = segments.get(i);\n+\n+      long[] range = extractStartEndTimeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(i));\n+      startTimes.add(range[0]);\n+      endTimes.add(range[1]);\n+    }\n+\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(startTimes, endTimes, segments);\n+  }\n+\n+\n+  private long[] extractStartEndTimeMSFromSegmentZKMetaZNRecord(String segment, @Nullable ZNRecord znRecord) {\n+    long[] range = {MIN_START_TIME, MAX_END_TIME};\n+    // Segments without metadata or with invalid time range will be set with [min_start, max_end] and will not be pruned\n+    if (znRecord == null) {\n+      LOGGER.warn(\"Failed to find segment ZK metadata for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return range;\n+    }\n+\n+    long startTime = znRecord.getLongField(CommonConstants.Segment.START_TIME, -1);\n+    long endTime = znRecord.getLongField(CommonConstants.Segment.END_TIME, -1);\n+    if (startTime < 0 || endTime < 0 || startTime > endTime) {\n+      LOGGER.warn(\"Failed to find valid end time for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return range;\n+    }\n+\n+    TimeUnit timeUnit = znRecord.getEnumField(CommonConstants.Segment.TIME_UNIT, TimeUnit.class, TimeUnit.DAYS);\n+    range[0] = timeUnit.toMillis(startTime);\n+    range[1] = timeUnit.toMillis(endTime);\n+    return range;\n+  }\n+\n+  @Override\n+  public void refreshSegment(String segment) {\n+    Set<String> segments;\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      segments = new HashSet<>();\n+    } else {\n+      segments = _timeRangeMSToSegmentSearchTree.getAllValues();\n+    }\n+    if (!segment.contains(segment)) {\n+      segments.add(segment);\n+    }\n+\n+    updateTimeRangeMSToSegmentSearchTree(segments);\n+  }\n+\n+  /**\n+   * NOTE: Pruning is done by searching _timeRangeToSegmentSearchTree based on request time range and check if the results\n+   *       are in the input segments. By doing so we will have run time O(M * logN) (N is the # of all online segments,\n+   *       M is the # of qualified intersected segments).\n+   */\n+  @Override\n+  public Set<String> prune(BrokerRequest brokerRequest, Set<String> segments) {\n+    // The pruned order may be different from the input order\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      return segments;\n+    }\n+    FilterQueryTree filterQueryTree = RequestUtils.generateFilterQueryTree(brokerRequest);\n+    if (filterQueryTree == null) {\n+      return segments;\n+    }\n+    List<Interval> ranges = getFilterTimeRange(filterQueryTree);\n+    if (ranges == null) { // cannot prune based on time for input request\n+      return segments;\n+    }\n+    if (ranges.size() == 0) { // invalid query time range\n+      return Collections.emptySet();\n+    }\n+\n+    Set<String> prunedSegments = new HashSet<>();\n+    for (Interval range : ranges) {\n+      Interval rangeMS = convertRangeToMS(range);\n+      for (Object segment : _timeRangeMSToSegmentSearchTree.searchAll(rangeMS)) {\n+        if (segments.contains(segment)) {\n+          prunedSegments.add((String) segment);\n+        }\n+      }\n+    }\n+    return new HashSet<String>(prunedSegments);\n+  }\n+\n+  private List<Interval> getFilterTimeRange(FilterQueryTree filterQueryTree) {\n+    // return NUll if no time range info or cannot filter base on the info (e.g. 'SELECT * from myTable where time < 50 OR firstName = Jason')\n+    // return an empty list if filtering range is specified but invalid (e.g. 'SELECT * from myTable where time < 50 AND time > 100')\n+    switch (filterQueryTree.getOperator()) {\n+      case AND:\n+        List<List<Interval>> andRanges = new ArrayList<>();\n+        for (FilterQueryTree child : filterQueryTree.getChildren()) {\n+          List<Interval> childRanges = getFilterTimeRange(child);\n+          if (childRanges != null) {\n+            andRanges.add(childRanges);\n+          }\n+        }\n+        return getIntersectionSortedRanges(andRanges);\n+      case OR:\n+        List<List<Interval>> orRanges = new ArrayList<>();\n+        for (FilterQueryTree child : filterQueryTree.getChildren()) {\n+          List<Interval> childRanges = getFilterTimeRange(child);\n+          if (childRanges == null) {\n+            return null;\n+          } else {\n+            orRanges.add(childRanges);\n+          }\n+        }\n+        return getUnionSortedRanges(orRanges);\n+      case EQUALITY:\n+        if (filterQueryTree.getColumn().equals(_timeColumn)) {\n+          long timeStamp = Long.parseLong(filterQueryTree.getValue().get(0));\n+          return Collections.singletonList(new Interval(timeStamp, timeStamp));\n+        }\n+        return null;\n+      case RANGE:\n+        if (filterQueryTree.getColumn().equals(_timeColumn)) {\n+          return parseRange(filterQueryTree.getValue());\n+        }\n+        return null;\n+      default:\n+        return null;\n+    }\n+  }\n+\n+  private Interval convertRangeToMS(Interval range) {\n+    long min = range.min == MIN_START_TIME ? MIN_START_TIME : _timeUnit.toMillis(range.min);\n+    long max = range.max == MAX_END_TIME ? MAX_END_TIME : _timeUnit.toMillis(range.max);\n+    return new Interval(min, max);\n+  }\n+\n+  private List<Interval> getIntersectionSortedRanges(List<List<Interval>> ranges) {\n+    // Requires input ranges are sorted, the return ranges will be sorted\n+    return getIntersectionSortedRanges(ranges, 0, ranges.size());\n+  }\n+\n+  private List<Interval> getIntersectionSortedRanges(List<List<Interval>> ranges, int start, int end) {\n+    if (start == end) {\n+      return null;\n+    }\n+\n+    if (start + 1 == end) {\n+      return ranges.get(start);\n+    }\n+\n+    int mid = start + (end - start) / 2;\n+    List<Interval> ranges1 = getIntersectionSortedRanges(ranges, start, mid);\n+    List<Interval> ranges2 = getIntersectionSortedRanges(ranges, mid, end);\n+    return getIntersectionOfTwoSortedRanges(ranges1, ranges2);\n+  }\n+\n+  private List<Interval> getIntersectionOfTwoSortedRanges(List<Interval> ranges1, List<Interval> ranges2) { // sorted non-overlapping ranges\n+    List<Interval> res = new ArrayList<>();\n+    int i = 0, j = 0;\n+    while (i < ranges1.size() && j < ranges2.size()) {\n+      Interval range1 = ranges1.get(i);\n+      Interval range2 = ranges2.get(j);\n+      if (range1.intersects(range2)) {\n+        res.add(Interval.getIntersection(range1, range2));\n+      }\n+      if (range1.max < range2.max) {\n+        i++;\n+      } else {\n+        j++;\n+      }\n+    }\n+    return res;\n+  }\n+\n+  private List<Interval> getUnionSortedRanges(List<List<Interval>> ranges) {\n+    return getUnionSortedRanges(ranges, 0, ranges.size());\n+  }\n+\n+  private List<Interval> getUnionSortedRanges(List<List<Interval>> ranges, int start, int end) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 280}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3MTczMTkzOnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/Interval.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQwNjozNzo1MlrOHxsY1Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQwNjozNzo1MlrOHxsY1Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTg2OTUyNQ==", "bodyText": "Please add brief javadoc on the usage/purpose of this class", "url": "https://github.com/apache/pinot/pull/6259#discussion_r521869525", "createdAt": "2020-11-12T06:37:52Z", "author": {"login": "siddharthteotia"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/Interval.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner.intervalST;\n+\n+import com.google.common.base.Preconditions;\n+\n+\n+public class Interval implements Comparable<Interval> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3MTczMjExOnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/Interval.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQwNjozNzo1N1rOHxsY8A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQwNjozNzo1N1rOHxsY8A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTg2OTU1Mg==", "bodyText": "I think checkNotNull is not needed.", "url": "https://github.com/apache/pinot/pull/6259#discussion_r521869552", "createdAt": "2020-11-12T06:37:57Z", "author": {"login": "siddharthteotia"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/Interval.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner.intervalST;\n+\n+import com.google.common.base.Preconditions;\n+\n+\n+public class Interval implements Comparable<Interval> {\n+  // interval with both ends inclusive [min, max]\n+  public final long min;\n+  public final long max;\n+\n+  public Interval(long min, long max) {\n+    Preconditions.checkState(min <= max, \"invalid interval [{}, {}]\", min, max);\n+    this.min = min;\n+    this.max = max;\n+  }\n+\n+  public boolean intersects(Interval that) {\n+    Preconditions.checkNotNull(that, \"Invalid interval: null\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 36}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3MTczMjE4OnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/Interval.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQwNjozODowMlrOHxsY_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQwNjozODowMlrOHxsY_g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTg2OTU2Ng==", "bodyText": "Can be simplified to one if condition", "url": "https://github.com/apache/pinot/pull/6259#discussion_r521869566", "createdAt": "2020-11-12T06:38:02Z", "author": {"login": "siddharthteotia"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/Interval.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner.intervalST;\n+\n+import com.google.common.base.Preconditions;\n+\n+\n+public class Interval implements Comparable<Interval> {\n+  // interval with both ends inclusive [min, max]\n+  public final long min;\n+  public final long max;\n+\n+  public Interval(long min, long max) {\n+    Preconditions.checkState(min <= max, \"invalid interval [{}, {}]\", min, max);\n+    this.min = min;\n+    this.max = max;\n+  }\n+\n+  public boolean intersects(Interval that) {\n+    Preconditions.checkNotNull(that, \"Invalid interval: null\");\n+    if (that.max < this.min) {\n+      return false;\n+    }\n+    if (this.max < that.min) {\n+      return false;\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 42}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3MTczMjI4OnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/Interval.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQwNjozODowNVrOHxsZDg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QyMjoyMDowOFrOHzBduA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTg2OTU4Mg==", "bodyText": "I don't think checkNotNull is needed. May be consider using @NotNull annotation", "url": "https://github.com/apache/pinot/pull/6259#discussion_r521869582", "createdAt": "2020-11-12T06:38:05Z", "author": {"login": "siddharthteotia"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/Interval.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner.intervalST;\n+\n+import com.google.common.base.Preconditions;\n+\n+\n+public class Interval implements Comparable<Interval> {\n+  // interval with both ends inclusive [min, max]\n+  public final long min;\n+  public final long max;\n+\n+  public Interval(long min, long max) {\n+    Preconditions.checkState(min <= max, \"invalid interval [{}, {}]\", min, max);\n+    this.min = min;\n+    this.max = max;\n+  }\n+\n+  public boolean intersects(Interval that) {\n+    Preconditions.checkNotNull(that, \"Invalid interval: null\");\n+    if (that.max < this.min) {\n+      return false;\n+    }\n+    if (this.max < that.min) {\n+      return false;\n+    }\n+    return true;\n+  }\n+\n+  @Override\n+  public int compareTo(Interval that) {\n+    Preconditions.checkNotNull(that, \"Compare to invalid interval: null\");\n+    if (this.min < that.min) {\n+      return -1;\n+    } else if (this.min > that.min) {\n+      return 1;\n+    } else if (this.max < that.max) {\n+      return -1;\n+    } else if (this.max > that.max) {\n+      return 1;\n+    }\n+    else return 0;\n+  }\n+\n+  @Override\n+  public int hashCode() {\n+    return (int)(min * 17 + max);\n+  }\n+\n+  @Override\n+  public boolean equals(Object that) {\n+    if (that instanceof Interval && that != null\n+        && this.min == ((Interval)that).min && this.max == ((Interval)that).max) {\n+      return true;\n+    }\n+    return false;\n+  }\n+\n+  public static Interval getIntersection(Interval a, Interval b) {\n+    Preconditions.checkNotNull(a, \"Invalid interval: null\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 76}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzI2MzQxNg==", "bodyText": "We don't usually use Nonnull annotation but only use Nullable because they look very similar. Arguments without an annotation should be non-null.", "url": "https://github.com/apache/pinot/pull/6259#discussion_r523263416", "createdAt": "2020-11-13T22:20:08Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/Interval.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner.intervalST;\n+\n+import com.google.common.base.Preconditions;\n+\n+\n+public class Interval implements Comparable<Interval> {\n+  // interval with both ends inclusive [min, max]\n+  public final long min;\n+  public final long max;\n+\n+  public Interval(long min, long max) {\n+    Preconditions.checkState(min <= max, \"invalid interval [{}, {}]\", min, max);\n+    this.min = min;\n+    this.max = max;\n+  }\n+\n+  public boolean intersects(Interval that) {\n+    Preconditions.checkNotNull(that, \"Invalid interval: null\");\n+    if (that.max < this.min) {\n+      return false;\n+    }\n+    if (this.max < that.min) {\n+      return false;\n+    }\n+    return true;\n+  }\n+\n+  @Override\n+  public int compareTo(Interval that) {\n+    Preconditions.checkNotNull(that, \"Compare to invalid interval: null\");\n+    if (this.min < that.min) {\n+      return -1;\n+    } else if (this.min > that.min) {\n+      return 1;\n+    } else if (this.max < that.max) {\n+      return -1;\n+    } else if (this.max > that.max) {\n+      return 1;\n+    }\n+    else return 0;\n+  }\n+\n+  @Override\n+  public int hashCode() {\n+    return (int)(min * 17 + max);\n+  }\n+\n+  @Override\n+  public boolean equals(Object that) {\n+    if (that instanceof Interval && that != null\n+        && this.min == ((Interval)that).min && this.max == ((Interval)that).max) {\n+      return true;\n+    }\n+    return false;\n+  }\n+\n+  public static Interval getIntersection(Interval a, Interval b) {\n+    Preconditions.checkNotNull(a, \"Invalid interval: null\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTg2OTU4Mg=="}, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 76}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3MTczMjQ2OnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/IntervalST.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQwNjozODoxMFrOHxsZKA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzo1OToxN1rOH22zag==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTg2OTYwOA==", "bodyText": "Doesn't java util or guava/fastutil library provide an implementation of balanced BST that can be used for intervals? Might just save effort of writing all the rotations correctly", "url": "https://github.com/apache/pinot/pull/6259#discussion_r521869608", "createdAt": "2020-11-12T06:38:10Z", "author": {"login": "siddharthteotia"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/IntervalST.java", "diffHunk": "@@ -0,0 +1,187 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner.intervalST;\n+\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+\n+\n+// A read-only interval search tree based on AVL Tree\n+public class IntervalST<Value> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjU0Nzg2Mw==", "bodyText": "For the Interval search tree, auxiliary info - max (max end point for subtree) are kept for each node. And searching decisions are made based on this info. Correct me if I'm wrong, but I couldn't find any bst implementation supports customized searching.", "url": "https://github.com/apache/pinot/pull/6259#discussion_r522547863", "createdAt": "2020-11-13T01:17:19Z", "author": {"login": "jtao15"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/IntervalST.java", "diffHunk": "@@ -0,0 +1,187 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner.intervalST;\n+\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+\n+\n+// A read-only interval search tree based on AVL Tree\n+public class IntervalST<Value> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTg2OTYwOA=="}, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzI4MzA1MA==", "bodyText": "Suggest renaming it to IntervalTree (seems this is the official name of this data structure)", "url": "https://github.com/apache/pinot/pull/6259#discussion_r527283050", "createdAt": "2020-11-19T23:59:17Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/IntervalST.java", "diffHunk": "@@ -0,0 +1,187 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner.intervalST;\n+\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+\n+\n+// A read-only interval search tree based on AVL Tree\n+public class IntervalST<Value> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTg2OTYwOA=="}, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3MTczMjgxOnYy", "diffSide": "LEFT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentselector/RealtimeSegmentSelector.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQwNjozODoxOFrOHxsZXA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QwMTozMzo0N1rOHyWGcg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTg2OTY2MA==", "bodyText": "Is it possible to not have this interface change of List to Set by handling the logic inside the pruner. I believe the change of List to Set comes because otherwise you need a memcpy in the prune() method?", "url": "https://github.com/apache/pinot/pull/6259#discussion_r521869660", "createdAt": "2020-11-12T06:38:18Z", "author": {"login": "siddharthteotia"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentselector/RealtimeSegmentSelector.java", "diffHunk": "@@ -52,8 +53,8 @@\n   public static final String FORCE_HLC = \"FORCE_HLC\";\n \n   private final AtomicLong _requestId = new AtomicLong();\n-  private volatile List<List<String>> _hlcSegments;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjU1Mjk0Ng==", "bodyText": "Yes, I made this change to avoid making a HashSet of input segments in prune(). Is there any considerations to keep this as list? The time range pruner keeps a search treemap from time ranges to segments. Pruning is done by search intersected segments based on query and check if they are in input segments of prune(). Ideally the input segments are in a HashSet, so the checking process would be efficient.", "url": "https://github.com/apache/pinot/pull/6259#discussion_r522552946", "createdAt": "2020-11-13T01:33:47Z", "author": {"login": "jtao15"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentselector/RealtimeSegmentSelector.java", "diffHunk": "@@ -52,8 +53,8 @@\n   public static final String FORCE_HLC = \"FORCE_HLC\";\n \n   private final AtomicLong _requestId = new AtomicLong();\n-  private volatile List<List<String>> _hlcSegments;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTg2OTY2MA=="}, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3MTczNTM1OnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeRangeSegmentPruner.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQwNjozOToxNlrOHxsa3A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QwMTozOTowOVrOHyWM7A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTg3MDA0NA==", "bodyText": "The number of time ranges should also be part of Big O time complexity right?", "url": "https://github.com/apache/pinot/pull/6259#discussion_r521870044", "createdAt": "2020-11-12T06:39:16Z", "author": {"login": "siddharthteotia"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeRangeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeRangeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeRangeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeRangeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final TimeUnit _timeUnit;\n+\n+  private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n+\n+  public TimeRangeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    DateTimeFormatSpec formatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    _timeUnit = formatSpec.getColumnUnit();\n+    Preconditions\n+        .checkNotNull(_timeUnit, \"Time unit must be configured in the field spec for time column: %s of table: %s\",\n+            _timeColumn, _tableNameWithType);\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    onExternalViewChange(externalView, idealState, onlineSegments);\n+  }\n+\n+  @Override\n+  public void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    updateTimeRangeMSToSegmentSearchTree(onlineSegments);\n+  }\n+\n+  private void updateTimeRangeMSToSegmentSearchTree(Set<String> onlineSegments) {\n+    List<String> segments = new ArrayList<>(onlineSegments);\n+    // atomic swap _timeRangeToSegmentMap for input online segments\n+    List<String> segmentZKMetadataPaths = new ArrayList<>();\n+    for (String segment: segments) {\n+      segmentZKMetadataPaths.add(_segmentZKMetadataPathPrefix + segment);\n+    }\n+\n+    List<ZNRecord> znRecords = _propertyStore.get(segmentZKMetadataPaths, null, AccessOption.PERSISTENT, true);\n+\n+    List<Long> startTimes = new ArrayList<>();\n+    List<Long> endTimes = new ArrayList<>();\n+\n+    for (int i = 0; i < segments.size(); i++) {\n+      String segment = segments.get(i);\n+\n+      long[] range = extractStartEndTimeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(i));\n+      startTimes.add(range[0]);\n+      endTimes.add(range[1]);\n+    }\n+\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(startTimes, endTimes, segments);\n+  }\n+\n+\n+  private long[] extractStartEndTimeMSFromSegmentZKMetaZNRecord(String segment, @Nullable ZNRecord znRecord) {\n+    long[] range = {MIN_START_TIME, MAX_END_TIME};\n+    // Segments without metadata or with invalid time range will be set with [min_start, max_end] and will not be pruned\n+    if (znRecord == null) {\n+      LOGGER.warn(\"Failed to find segment ZK metadata for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return range;\n+    }\n+\n+    long startTime = znRecord.getLongField(CommonConstants.Segment.START_TIME, -1);\n+    long endTime = znRecord.getLongField(CommonConstants.Segment.END_TIME, -1);\n+    if (startTime < 0 || endTime < 0 || startTime > endTime) {\n+      LOGGER.warn(\"Failed to find valid end time for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return range;\n+    }\n+\n+    TimeUnit timeUnit = znRecord.getEnumField(CommonConstants.Segment.TIME_UNIT, TimeUnit.class, TimeUnit.DAYS);\n+    range[0] = timeUnit.toMillis(startTime);\n+    range[1] = timeUnit.toMillis(endTime);\n+    return range;\n+  }\n+\n+  @Override\n+  public void refreshSegment(String segment) {\n+    Set<String> segments;\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      segments = new HashSet<>();\n+    } else {\n+      segments = _timeRangeMSToSegmentSearchTree.getAllValues();\n+    }\n+    if (!segment.contains(segment)) {\n+      segments.add(segment);\n+    }\n+\n+    updateTimeRangeMSToSegmentSearchTree(segments);\n+  }\n+\n+  /**\n+   * NOTE: Pruning is done by searching _timeRangeToSegmentSearchTree based on request time range and check if the results\n+   *       are in the input segments. By doing so we will have run time O(M * logN) (N is the # of all online segments,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 159}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjU1NDYwNA==", "bodyText": "The worst case would be no segments share the same time range, so # time ranges would be the same as N in this case. Searching 1 intersected range will take O(logN) time, and get all results will take O(M*logN)", "url": "https://github.com/apache/pinot/pull/6259#discussion_r522554604", "createdAt": "2020-11-13T01:39:09Z", "author": {"login": "jtao15"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeRangeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeRangeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeRangeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeRangeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final TimeUnit _timeUnit;\n+\n+  private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n+\n+  public TimeRangeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    DateTimeFormatSpec formatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    _timeUnit = formatSpec.getColumnUnit();\n+    Preconditions\n+        .checkNotNull(_timeUnit, \"Time unit must be configured in the field spec for time column: %s of table: %s\",\n+            _timeColumn, _tableNameWithType);\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    onExternalViewChange(externalView, idealState, onlineSegments);\n+  }\n+\n+  @Override\n+  public void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    updateTimeRangeMSToSegmentSearchTree(onlineSegments);\n+  }\n+\n+  private void updateTimeRangeMSToSegmentSearchTree(Set<String> onlineSegments) {\n+    List<String> segments = new ArrayList<>(onlineSegments);\n+    // atomic swap _timeRangeToSegmentMap for input online segments\n+    List<String> segmentZKMetadataPaths = new ArrayList<>();\n+    for (String segment: segments) {\n+      segmentZKMetadataPaths.add(_segmentZKMetadataPathPrefix + segment);\n+    }\n+\n+    List<ZNRecord> znRecords = _propertyStore.get(segmentZKMetadataPaths, null, AccessOption.PERSISTENT, true);\n+\n+    List<Long> startTimes = new ArrayList<>();\n+    List<Long> endTimes = new ArrayList<>();\n+\n+    for (int i = 0; i < segments.size(); i++) {\n+      String segment = segments.get(i);\n+\n+      long[] range = extractStartEndTimeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(i));\n+      startTimes.add(range[0]);\n+      endTimes.add(range[1]);\n+    }\n+\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(startTimes, endTimes, segments);\n+  }\n+\n+\n+  private long[] extractStartEndTimeMSFromSegmentZKMetaZNRecord(String segment, @Nullable ZNRecord znRecord) {\n+    long[] range = {MIN_START_TIME, MAX_END_TIME};\n+    // Segments without metadata or with invalid time range will be set with [min_start, max_end] and will not be pruned\n+    if (znRecord == null) {\n+      LOGGER.warn(\"Failed to find segment ZK metadata for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return range;\n+    }\n+\n+    long startTime = znRecord.getLongField(CommonConstants.Segment.START_TIME, -1);\n+    long endTime = znRecord.getLongField(CommonConstants.Segment.END_TIME, -1);\n+    if (startTime < 0 || endTime < 0 || startTime > endTime) {\n+      LOGGER.warn(\"Failed to find valid end time for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return range;\n+    }\n+\n+    TimeUnit timeUnit = znRecord.getEnumField(CommonConstants.Segment.TIME_UNIT, TimeUnit.class, TimeUnit.DAYS);\n+    range[0] = timeUnit.toMillis(startTime);\n+    range[1] = timeUnit.toMillis(endTime);\n+    return range;\n+  }\n+\n+  @Override\n+  public void refreshSegment(String segment) {\n+    Set<String> segments;\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      segments = new HashSet<>();\n+    } else {\n+      segments = _timeRangeMSToSegmentSearchTree.getAllValues();\n+    }\n+    if (!segment.contains(segment)) {\n+      segments.add(segment);\n+    }\n+\n+    updateTimeRangeMSToSegmentSearchTree(segments);\n+  }\n+\n+  /**\n+   * NOTE: Pruning is done by searching _timeRangeToSegmentSearchTree based on request time range and check if the results\n+   *       are in the input segments. By doing so we will have run time O(M * logN) (N is the # of all online segments,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTg3MDA0NA=="}, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 159}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3MTc1NTI5OnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/IntervalST.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQwNjo0NzozNVrOHxsmGQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQwNjo0NzozNVrOHxsmGQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTg3MjkyMQ==", "bodyText": "This API is a bit non-intuitive. Essentially what it is doing is given an interval, it looks for all overlapping intervals in the BST and for all those overlapping intervals, returns the corresponding list of segments? At least a javadoc with details on semantics is definitely needed", "url": "https://github.com/apache/pinot/pull/6259#discussion_r521872921", "createdAt": "2020-11-12T06:47:35Z", "author": {"login": "siddharthteotia"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/IntervalST.java", "diffHunk": "@@ -0,0 +1,187 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner.intervalST;\n+\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+\n+\n+// A read-only interval search tree based on AVL Tree\n+public class IntervalST<Value> {\n+\n+  private Node<Value> root;\n+\n+  public IntervalST(List<Long> mins, List<Long> maxs, List<Value> values) {\n+    // read only once constructed\n+    for (int i = 0; i < mins.size(); i++) {\n+      insert(mins.get(i), maxs.get(i), values.get(i));\n+    }\n+  }\n+\n+  private void insert(long min, long max, Value value) {\n+    root = insert(root, new Interval(min, max), value);\n+  }\n+\n+  private Node insert(Node node, Interval interval, Value value) {\n+    if (node == null) {\n+      return new Node(interval, value);\n+    }\n+\n+    int cmp = interval.compareTo(node.interval);\n+    if (cmp == 0) {\n+      node.valueList.add(value);\n+      return node;\n+    } else if (cmp < 0) {\n+      node.left = insert(node.left, interval, value);\n+    } else {\n+      node.right = insert(node.right, interval, value);\n+    }\n+\n+    fixAuxiliaryInfo(node);\n+    int balance = getBalance(node);\n+    // Balance current subtree\n+    if (balance < -1) {\n+      if (getBalance(node.right) > 0) {\n+        node.right = rotateRight(node.right); // Right-left case\n+      }\n+      node = rotateLeft(node);\n+    } else if (balance > 1) {\n+      if (getBalance(node.left) < 0) {\n+        node.left = rotateLeft(node.left); // Left-right case\n+      }\n+      node = rotateRight(node);\n+    }\n+    return node;\n+  }\n+\n+  // Get all intervals which intersect with input range [min, max]\n+  public List<Value> searchAll(long min, long max) {\n+    return searchAll(new Interval(min, max));\n+  }\n+\n+  public List<Value> searchAll(Interval interval) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 80}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3MTc2MDQ0OnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeRangeSegmentPruner.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQwNjo0OTo0NlrOHxspCA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QwMTo0MDo0NVrOHyWO4A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTg3MzY3Mg==", "bodyText": "Is this the reason for List to Set change in API across all the users? Let's see if we can handle it internally within this class (will require a copy?)", "url": "https://github.com/apache/pinot/pull/6259#discussion_r521873672", "createdAt": "2020-11-12T06:49:46Z", "author": {"login": "siddharthteotia"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeRangeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeRangeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeRangeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeRangeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final TimeUnit _timeUnit;\n+\n+  private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n+\n+  public TimeRangeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    DateTimeFormatSpec formatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    _timeUnit = formatSpec.getColumnUnit();\n+    Preconditions\n+        .checkNotNull(_timeUnit, \"Time unit must be configured in the field spec for time column: %s of table: %s\",\n+            _timeColumn, _tableNameWithType);\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    onExternalViewChange(externalView, idealState, onlineSegments);\n+  }\n+\n+  @Override\n+  public void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    updateTimeRangeMSToSegmentSearchTree(onlineSegments);\n+  }\n+\n+  private void updateTimeRangeMSToSegmentSearchTree(Set<String> onlineSegments) {\n+    List<String> segments = new ArrayList<>(onlineSegments);\n+    // atomic swap _timeRangeToSegmentMap for input online segments\n+    List<String> segmentZKMetadataPaths = new ArrayList<>();\n+    for (String segment: segments) {\n+      segmentZKMetadataPaths.add(_segmentZKMetadataPathPrefix + segment);\n+    }\n+\n+    List<ZNRecord> znRecords = _propertyStore.get(segmentZKMetadataPaths, null, AccessOption.PERSISTENT, true);\n+\n+    List<Long> startTimes = new ArrayList<>();\n+    List<Long> endTimes = new ArrayList<>();\n+\n+    for (int i = 0; i < segments.size(); i++) {\n+      String segment = segments.get(i);\n+\n+      long[] range = extractStartEndTimeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(i));\n+      startTimes.add(range[0]);\n+      endTimes.add(range[1]);\n+    }\n+\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(startTimes, endTimes, segments);\n+  }\n+\n+\n+  private long[] extractStartEndTimeMSFromSegmentZKMetaZNRecord(String segment, @Nullable ZNRecord znRecord) {\n+    long[] range = {MIN_START_TIME, MAX_END_TIME};\n+    // Segments without metadata or with invalid time range will be set with [min_start, max_end] and will not be pruned\n+    if (znRecord == null) {\n+      LOGGER.warn(\"Failed to find segment ZK metadata for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return range;\n+    }\n+\n+    long startTime = znRecord.getLongField(CommonConstants.Segment.START_TIME, -1);\n+    long endTime = znRecord.getLongField(CommonConstants.Segment.END_TIME, -1);\n+    if (startTime < 0 || endTime < 0 || startTime > endTime) {\n+      LOGGER.warn(\"Failed to find valid end time for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return range;\n+    }\n+\n+    TimeUnit timeUnit = znRecord.getEnumField(CommonConstants.Segment.TIME_UNIT, TimeUnit.class, TimeUnit.DAYS);\n+    range[0] = timeUnit.toMillis(startTime);\n+    range[1] = timeUnit.toMillis(endTime);\n+    return range;\n+  }\n+\n+  @Override\n+  public void refreshSegment(String segment) {\n+    Set<String> segments;\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      segments = new HashSet<>();\n+    } else {\n+      segments = _timeRangeMSToSegmentSearchTree.getAllValues();\n+    }\n+    if (!segment.contains(segment)) {\n+      segments.add(segment);\n+    }\n+\n+    updateTimeRangeMSToSegmentSearchTree(segments);\n+  }\n+\n+  /**\n+   * NOTE: Pruning is done by searching _timeRangeToSegmentSearchTree based on request time range and check if the results\n+   *       are in the input segments. By doing so we will have run time O(M * logN) (N is the # of all online segments,\n+   *       M is the # of qualified intersected segments).\n+   */\n+  @Override\n+  public Set<String> prune(BrokerRequest brokerRequest, Set<String> segments) {\n+    // The pruned order may be different from the input order\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      return segments;\n+    }\n+    FilterQueryTree filterQueryTree = RequestUtils.generateFilterQueryTree(brokerRequest);\n+    if (filterQueryTree == null) {\n+      return segments;\n+    }\n+    List<Interval> ranges = getFilterTimeRange(filterQueryTree);\n+    if (ranges == null) { // cannot prune based on time for input request\n+      return segments;\n+    }\n+    if (ranges.size() == 0) { // invalid query time range\n+      return Collections.emptySet();\n+    }\n+\n+    Set<String> prunedSegments = new HashSet<>();\n+    for (Interval range : ranges) {\n+      Interval rangeMS = convertRangeToMS(range);\n+      for (Object segment : _timeRangeMSToSegmentSearchTree.searchAll(rangeMS)) {\n+        if (segments.contains(segment)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 184}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjU1NTEwNA==", "bodyText": "Yes", "url": "https://github.com/apache/pinot/pull/6259#discussion_r522555104", "createdAt": "2020-11-13T01:40:45Z", "author": {"login": "jtao15"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeRangeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeRangeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeRangeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeRangeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final TimeUnit _timeUnit;\n+\n+  private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n+\n+  public TimeRangeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    DateTimeFormatSpec formatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    _timeUnit = formatSpec.getColumnUnit();\n+    Preconditions\n+        .checkNotNull(_timeUnit, \"Time unit must be configured in the field spec for time column: %s of table: %s\",\n+            _timeColumn, _tableNameWithType);\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    onExternalViewChange(externalView, idealState, onlineSegments);\n+  }\n+\n+  @Override\n+  public void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    updateTimeRangeMSToSegmentSearchTree(onlineSegments);\n+  }\n+\n+  private void updateTimeRangeMSToSegmentSearchTree(Set<String> onlineSegments) {\n+    List<String> segments = new ArrayList<>(onlineSegments);\n+    // atomic swap _timeRangeToSegmentMap for input online segments\n+    List<String> segmentZKMetadataPaths = new ArrayList<>();\n+    for (String segment: segments) {\n+      segmentZKMetadataPaths.add(_segmentZKMetadataPathPrefix + segment);\n+    }\n+\n+    List<ZNRecord> znRecords = _propertyStore.get(segmentZKMetadataPaths, null, AccessOption.PERSISTENT, true);\n+\n+    List<Long> startTimes = new ArrayList<>();\n+    List<Long> endTimes = new ArrayList<>();\n+\n+    for (int i = 0; i < segments.size(); i++) {\n+      String segment = segments.get(i);\n+\n+      long[] range = extractStartEndTimeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(i));\n+      startTimes.add(range[0]);\n+      endTimes.add(range[1]);\n+    }\n+\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(startTimes, endTimes, segments);\n+  }\n+\n+\n+  private long[] extractStartEndTimeMSFromSegmentZKMetaZNRecord(String segment, @Nullable ZNRecord znRecord) {\n+    long[] range = {MIN_START_TIME, MAX_END_TIME};\n+    // Segments without metadata or with invalid time range will be set with [min_start, max_end] and will not be pruned\n+    if (znRecord == null) {\n+      LOGGER.warn(\"Failed to find segment ZK metadata for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return range;\n+    }\n+\n+    long startTime = znRecord.getLongField(CommonConstants.Segment.START_TIME, -1);\n+    long endTime = znRecord.getLongField(CommonConstants.Segment.END_TIME, -1);\n+    if (startTime < 0 || endTime < 0 || startTime > endTime) {\n+      LOGGER.warn(\"Failed to find valid end time for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return range;\n+    }\n+\n+    TimeUnit timeUnit = znRecord.getEnumField(CommonConstants.Segment.TIME_UNIT, TimeUnit.class, TimeUnit.DAYS);\n+    range[0] = timeUnit.toMillis(startTime);\n+    range[1] = timeUnit.toMillis(endTime);\n+    return range;\n+  }\n+\n+  @Override\n+  public void refreshSegment(String segment) {\n+    Set<String> segments;\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      segments = new HashSet<>();\n+    } else {\n+      segments = _timeRangeMSToSegmentSearchTree.getAllValues();\n+    }\n+    if (!segment.contains(segment)) {\n+      segments.add(segment);\n+    }\n+\n+    updateTimeRangeMSToSegmentSearchTree(segments);\n+  }\n+\n+  /**\n+   * NOTE: Pruning is done by searching _timeRangeToSegmentSearchTree based on request time range and check if the results\n+   *       are in the input segments. By doing so we will have run time O(M * logN) (N is the # of all online segments,\n+   *       M is the # of qualified intersected segments).\n+   */\n+  @Override\n+  public Set<String> prune(BrokerRequest brokerRequest, Set<String> segments) {\n+    // The pruned order may be different from the input order\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      return segments;\n+    }\n+    FilterQueryTree filterQueryTree = RequestUtils.generateFilterQueryTree(brokerRequest);\n+    if (filterQueryTree == null) {\n+      return segments;\n+    }\n+    List<Interval> ranges = getFilterTimeRange(filterQueryTree);\n+    if (ranges == null) { // cannot prune based on time for input request\n+      return segments;\n+    }\n+    if (ranges.size() == 0) { // invalid query time range\n+      return Collections.emptySet();\n+    }\n+\n+    Set<String> prunedSegments = new HashSet<>();\n+    for (Interval range : ranges) {\n+      Interval rangeMS = convertRangeToMS(range);\n+      for (Object segment : _timeRangeMSToSegmentSearchTree.searchAll(rangeMS)) {\n+        if (segments.contains(segment)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTg3MzY3Mg=="}, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 184}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3MTc2MjM3OnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeRangeSegmentPruner.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQwNjo1MDozN1rOHxsqGg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QwMTo0Mjo1NVrOHyWRWg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTg3Mzk0Ng==", "bodyText": "Actually the reverse is true right? The segment list retrieved from BST is the one that will be used. Consider changing the name to selectedSegments or something else", "url": "https://github.com/apache/pinot/pull/6259#discussion_r521873946", "createdAt": "2020-11-12T06:50:37Z", "author": {"login": "siddharthteotia"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeRangeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeRangeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeRangeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeRangeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final TimeUnit _timeUnit;\n+\n+  private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n+\n+  public TimeRangeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    DateTimeFormatSpec formatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    _timeUnit = formatSpec.getColumnUnit();\n+    Preconditions\n+        .checkNotNull(_timeUnit, \"Time unit must be configured in the field spec for time column: %s of table: %s\",\n+            _timeColumn, _tableNameWithType);\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    onExternalViewChange(externalView, idealState, onlineSegments);\n+  }\n+\n+  @Override\n+  public void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    updateTimeRangeMSToSegmentSearchTree(onlineSegments);\n+  }\n+\n+  private void updateTimeRangeMSToSegmentSearchTree(Set<String> onlineSegments) {\n+    List<String> segments = new ArrayList<>(onlineSegments);\n+    // atomic swap _timeRangeToSegmentMap for input online segments\n+    List<String> segmentZKMetadataPaths = new ArrayList<>();\n+    for (String segment: segments) {\n+      segmentZKMetadataPaths.add(_segmentZKMetadataPathPrefix + segment);\n+    }\n+\n+    List<ZNRecord> znRecords = _propertyStore.get(segmentZKMetadataPaths, null, AccessOption.PERSISTENT, true);\n+\n+    List<Long> startTimes = new ArrayList<>();\n+    List<Long> endTimes = new ArrayList<>();\n+\n+    for (int i = 0; i < segments.size(); i++) {\n+      String segment = segments.get(i);\n+\n+      long[] range = extractStartEndTimeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(i));\n+      startTimes.add(range[0]);\n+      endTimes.add(range[1]);\n+    }\n+\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(startTimes, endTimes, segments);\n+  }\n+\n+\n+  private long[] extractStartEndTimeMSFromSegmentZKMetaZNRecord(String segment, @Nullable ZNRecord znRecord) {\n+    long[] range = {MIN_START_TIME, MAX_END_TIME};\n+    // Segments without metadata or with invalid time range will be set with [min_start, max_end] and will not be pruned\n+    if (znRecord == null) {\n+      LOGGER.warn(\"Failed to find segment ZK metadata for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return range;\n+    }\n+\n+    long startTime = znRecord.getLongField(CommonConstants.Segment.START_TIME, -1);\n+    long endTime = znRecord.getLongField(CommonConstants.Segment.END_TIME, -1);\n+    if (startTime < 0 || endTime < 0 || startTime > endTime) {\n+      LOGGER.warn(\"Failed to find valid end time for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return range;\n+    }\n+\n+    TimeUnit timeUnit = znRecord.getEnumField(CommonConstants.Segment.TIME_UNIT, TimeUnit.class, TimeUnit.DAYS);\n+    range[0] = timeUnit.toMillis(startTime);\n+    range[1] = timeUnit.toMillis(endTime);\n+    return range;\n+  }\n+\n+  @Override\n+  public void refreshSegment(String segment) {\n+    Set<String> segments;\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      segments = new HashSet<>();\n+    } else {\n+      segments = _timeRangeMSToSegmentSearchTree.getAllValues();\n+    }\n+    if (!segment.contains(segment)) {\n+      segments.add(segment);\n+    }\n+\n+    updateTimeRangeMSToSegmentSearchTree(segments);\n+  }\n+\n+  /**\n+   * NOTE: Pruning is done by searching _timeRangeToSegmentSearchTree based on request time range and check if the results\n+   *       are in the input segments. By doing so we will have run time O(M * logN) (N is the # of all online segments,\n+   *       M is the # of qualified intersected segments).\n+   */\n+  @Override\n+  public Set<String> prune(BrokerRequest brokerRequest, Set<String> segments) {\n+    // The pruned order may be different from the input order\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      return segments;\n+    }\n+    FilterQueryTree filterQueryTree = RequestUtils.generateFilterQueryTree(brokerRequest);\n+    if (filterQueryTree == null) {\n+      return segments;\n+    }\n+    List<Interval> ranges = getFilterTimeRange(filterQueryTree);\n+    if (ranges == null) { // cannot prune based on time for input request\n+      return segments;\n+    }\n+    if (ranges.size() == 0) { // invalid query time range\n+      return Collections.emptySet();\n+    }\n+\n+    Set<String> prunedSegments = new HashSet<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 180}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjU1NTczOA==", "bodyText": "I'll rename this.", "url": "https://github.com/apache/pinot/pull/6259#discussion_r522555738", "createdAt": "2020-11-13T01:42:55Z", "author": {"login": "jtao15"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeRangeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeRangeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeRangeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeRangeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final TimeUnit _timeUnit;\n+\n+  private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n+\n+  public TimeRangeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    DateTimeFormatSpec formatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    _timeUnit = formatSpec.getColumnUnit();\n+    Preconditions\n+        .checkNotNull(_timeUnit, \"Time unit must be configured in the field spec for time column: %s of table: %s\",\n+            _timeColumn, _tableNameWithType);\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    onExternalViewChange(externalView, idealState, onlineSegments);\n+  }\n+\n+  @Override\n+  public void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    updateTimeRangeMSToSegmentSearchTree(onlineSegments);\n+  }\n+\n+  private void updateTimeRangeMSToSegmentSearchTree(Set<String> onlineSegments) {\n+    List<String> segments = new ArrayList<>(onlineSegments);\n+    // atomic swap _timeRangeToSegmentMap for input online segments\n+    List<String> segmentZKMetadataPaths = new ArrayList<>();\n+    for (String segment: segments) {\n+      segmentZKMetadataPaths.add(_segmentZKMetadataPathPrefix + segment);\n+    }\n+\n+    List<ZNRecord> znRecords = _propertyStore.get(segmentZKMetadataPaths, null, AccessOption.PERSISTENT, true);\n+\n+    List<Long> startTimes = new ArrayList<>();\n+    List<Long> endTimes = new ArrayList<>();\n+\n+    for (int i = 0; i < segments.size(); i++) {\n+      String segment = segments.get(i);\n+\n+      long[] range = extractStartEndTimeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(i));\n+      startTimes.add(range[0]);\n+      endTimes.add(range[1]);\n+    }\n+\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(startTimes, endTimes, segments);\n+  }\n+\n+\n+  private long[] extractStartEndTimeMSFromSegmentZKMetaZNRecord(String segment, @Nullable ZNRecord znRecord) {\n+    long[] range = {MIN_START_TIME, MAX_END_TIME};\n+    // Segments without metadata or with invalid time range will be set with [min_start, max_end] and will not be pruned\n+    if (znRecord == null) {\n+      LOGGER.warn(\"Failed to find segment ZK metadata for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return range;\n+    }\n+\n+    long startTime = znRecord.getLongField(CommonConstants.Segment.START_TIME, -1);\n+    long endTime = znRecord.getLongField(CommonConstants.Segment.END_TIME, -1);\n+    if (startTime < 0 || endTime < 0 || startTime > endTime) {\n+      LOGGER.warn(\"Failed to find valid end time for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return range;\n+    }\n+\n+    TimeUnit timeUnit = znRecord.getEnumField(CommonConstants.Segment.TIME_UNIT, TimeUnit.class, TimeUnit.DAYS);\n+    range[0] = timeUnit.toMillis(startTime);\n+    range[1] = timeUnit.toMillis(endTime);\n+    return range;\n+  }\n+\n+  @Override\n+  public void refreshSegment(String segment) {\n+    Set<String> segments;\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      segments = new HashSet<>();\n+    } else {\n+      segments = _timeRangeMSToSegmentSearchTree.getAllValues();\n+    }\n+    if (!segment.contains(segment)) {\n+      segments.add(segment);\n+    }\n+\n+    updateTimeRangeMSToSegmentSearchTree(segments);\n+  }\n+\n+  /**\n+   * NOTE: Pruning is done by searching _timeRangeToSegmentSearchTree based on request time range and check if the results\n+   *       are in the input segments. By doing so we will have run time O(M * logN) (N is the # of all online segments,\n+   *       M is the # of qualified intersected segments).\n+   */\n+  @Override\n+  public Set<String> prune(BrokerRequest brokerRequest, Set<String> segments) {\n+    // The pruned order may be different from the input order\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      return segments;\n+    }\n+    FilterQueryTree filterQueryTree = RequestUtils.generateFilterQueryTree(brokerRequest);\n+    if (filterQueryTree == null) {\n+      return segments;\n+    }\n+    List<Interval> ranges = getFilterTimeRange(filterQueryTree);\n+    if (ranges == null) { // cannot prune based on time for input request\n+      return segments;\n+    }\n+    if (ranges.size() == 0) { // invalid query time range\n+      return Collections.emptySet();\n+    }\n+\n+    Set<String> prunedSegments = new HashSet<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTg3Mzk0Ng=="}, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 180}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI4MDUxODc5OnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/Interval.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QyMjoxODoyM1rOHzBbVQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QyMjoxODoyM1rOHzBbVQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzI2MjgwNQ==", "bodyText": "Prefix the member variables with _ and avoid using this.", "url": "https://github.com/apache/pinot/pull/6259#discussion_r523262805", "createdAt": "2020-11-13T22:18:23Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/Interval.java", "diffHunk": "@@ -0,0 +1,98 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner.intervalST;\n+\n+import com.google.common.base.Preconditions;\n+\n+\n+public class Interval implements Comparable<Interval> {\n+  // interval with both ends inclusive [min, max]\n+  public final long min;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI4MDUyNjE4OnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/IntervalST.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QyMjoyMToyNlrOHzBffQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QyMjoyMToyNlrOHzBffQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzI2Mzg2OQ==", "bodyText": "Prefix them with _", "url": "https://github.com/apache/pinot/pull/6259#discussion_r523263869", "createdAt": "2020-11-13T22:21:26Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/IntervalST.java", "diffHunk": "@@ -0,0 +1,187 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner.intervalST;\n+\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+\n+\n+// A read-only interval search tree based on AVL Tree\n+public class IntervalST<Value> {\n+\n+  private Node<Value> root;\n+\n+  public IntervalST(List<Long> mins, List<Long> maxs, List<Value> values) {\n+    // read only once constructed\n+    for (int i = 0; i < mins.size(); i++) {\n+      insert(mins.get(i), maxs.get(i), values.get(i));\n+    }\n+  }\n+\n+  private void insert(long min, long max, Value value) {\n+    root = insert(root, new Interval(min, max), value);\n+  }\n+\n+  private Node insert(Node node, Interval interval, Value value) {\n+    if (node == null) {\n+      return new Node(interval, value);\n+    }\n+\n+    int cmp = interval.compareTo(node.interval);\n+    if (cmp == 0) {\n+      node.valueList.add(value);\n+      return node;\n+    } else if (cmp < 0) {\n+      node.left = insert(node.left, interval, value);\n+    } else {\n+      node.right = insert(node.right, interval, value);\n+    }\n+\n+    fixAuxiliaryInfo(node);\n+    int balance = getBalance(node);\n+    // Balance current subtree\n+    if (balance < -1) {\n+      if (getBalance(node.right) > 0) {\n+        node.right = rotateRight(node.right); // Right-left case\n+      }\n+      node = rotateLeft(node);\n+    } else if (balance > 1) {\n+      if (getBalance(node.left) < 0) {\n+        node.left = rotateLeft(node.left); // Left-right case\n+      }\n+      node = rotateRight(node);\n+    }\n+    return node;\n+  }\n+\n+  // Get all intervals which intersect with input range [min, max]\n+  public List<Value> searchAll(long min, long max) {\n+    return searchAll(new Interval(min, max));\n+  }\n+\n+  public List<Value> searchAll(Interval interval) {\n+    List<Value> list = new ArrayList<Value>();\n+    searchAll(root, interval, list);\n+    return list;\n+  }\n+\n+  private boolean searchAll(Node<Value> node, Interval interval, List<Value> list) {\n+    boolean foundRoot = false;\n+    boolean foundLeft = false;\n+    boolean foundRight = false;\n+    if (node == null)\n+      return false;\n+    if (interval.intersects(node.interval)) {\n+      list.addAll(node.valueList);\n+      foundRoot = true;\n+    }\n+    if (node.left != null && node.left.max >= interval.min) {\n+      foundLeft = searchAll(node.left, interval, list);\n+    }\n+\n+    if (foundLeft || node.left == null || node.left.max < interval.min) {\n+      // If node.left.max > interval.min but cannot find intersections on left subtree,\n+      // then there won't be any intersections in right subtree, since the right most interval x\n+      // in left subtree must have x.min > interval.max. All intervals in right subtree\n+      // will have mins >= x.min, so there won't be any intersections.\n+      foundRight = searchAll(node.right, interval, list);\n+    }\n+    return foundRoot || foundLeft || foundRight;\n+  }\n+\n+  public Set<Value> getAllValues() {\n+    Set<Value> values = new HashSet<>();\n+    getAllValues(root, values);\n+    return values;\n+  }\n+\n+  private void getAllValues(Node<Value> node, Set<Value> values) {\n+    if (node == null) {\n+      return;\n+    }\n+    getAllValues(node.left, values);\n+    values.addAll(node.valueList);\n+    getAllValues(node.right, values);\n+  }\n+\n+  private Node rotateRight(Node x) {\n+    Node y = x.left;\n+    x.left = y.right;\n+    y.right = x;\n+    fixAuxiliaryInfo(x);\n+    fixAuxiliaryInfo(y);\n+    return y;\n+  }\n+\n+  private Node rotateLeft(Node x) {\n+    Node y = x.right;\n+    x.right = y.left;\n+    y.left = x;\n+    fixAuxiliaryInfo(x);\n+    fixAuxiliaryInfo(y);\n+    return y;\n+  }\n+\n+  private int getBalance(Node node) {\n+    if (node == null) {\n+      return 0;\n+    }\n+    return height(node.left) - height(node.right);\n+  }\n+\n+  private int height(Node node) {\n+    if (node == null) {\n+      return 0;\n+    }\n+    return node.height;\n+  }\n+\n+  private long max(Node node) {\n+    if (node == null) {\n+      return Long.MIN_VALUE;\n+    }\n+    return node.max;\n+  }\n+\n+  // fix auxiliary information\n+  private void fixAuxiliaryInfo(Node node) {\n+    if (node == null) return;\n+    node.height = 1 + Math.max(height(node.left), height(node.right));\n+    node.max = Math.max(max(node.left), max(node.right));\n+    node.max = Math.max(node.max, node.interval.max);\n+  }\n+\n+  private static class Node<Value> {\n+    final Interval interval; // key", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 173}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI4MDUyNzAzOnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/IntervalST.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QyMjoyMTo0OVrOHzBf_A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QyMjoyMTo0OVrOHzBf_A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzI2Mzk5Ng==", "bodyText": "Make this declaration into 2 lines", "url": "https://github.com/apache/pinot/pull/6259#discussion_r523263996", "createdAt": "2020-11-13T22:21:49Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/IntervalST.java", "diffHunk": "@@ -0,0 +1,187 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner.intervalST;\n+\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+\n+\n+// A read-only interval search tree based on AVL Tree\n+public class IntervalST<Value> {\n+\n+  private Node<Value> root;\n+\n+  public IntervalST(List<Long> mins, List<Long> maxs, List<Value> values) {\n+    // read only once constructed\n+    for (int i = 0; i < mins.size(); i++) {\n+      insert(mins.get(i), maxs.get(i), values.get(i));\n+    }\n+  }\n+\n+  private void insert(long min, long max, Value value) {\n+    root = insert(root, new Interval(min, max), value);\n+  }\n+\n+  private Node insert(Node node, Interval interval, Value value) {\n+    if (node == null) {\n+      return new Node(interval, value);\n+    }\n+\n+    int cmp = interval.compareTo(node.interval);\n+    if (cmp == 0) {\n+      node.valueList.add(value);\n+      return node;\n+    } else if (cmp < 0) {\n+      node.left = insert(node.left, interval, value);\n+    } else {\n+      node.right = insert(node.right, interval, value);\n+    }\n+\n+    fixAuxiliaryInfo(node);\n+    int balance = getBalance(node);\n+    // Balance current subtree\n+    if (balance < -1) {\n+      if (getBalance(node.right) > 0) {\n+        node.right = rotateRight(node.right); // Right-left case\n+      }\n+      node = rotateLeft(node);\n+    } else if (balance > 1) {\n+      if (getBalance(node.left) < 0) {\n+        node.left = rotateLeft(node.left); // Left-right case\n+      }\n+      node = rotateRight(node);\n+    }\n+    return node;\n+  }\n+\n+  // Get all intervals which intersect with input range [min, max]\n+  public List<Value> searchAll(long min, long max) {\n+    return searchAll(new Interval(min, max));\n+  }\n+\n+  public List<Value> searchAll(Interval interval) {\n+    List<Value> list = new ArrayList<Value>();\n+    searchAll(root, interval, list);\n+    return list;\n+  }\n+\n+  private boolean searchAll(Node<Value> node, Interval interval, List<Value> list) {\n+    boolean foundRoot = false;\n+    boolean foundLeft = false;\n+    boolean foundRight = false;\n+    if (node == null)\n+      return false;\n+    if (interval.intersects(node.interval)) {\n+      list.addAll(node.valueList);\n+      foundRoot = true;\n+    }\n+    if (node.left != null && node.left.max >= interval.min) {\n+      foundLeft = searchAll(node.left, interval, list);\n+    }\n+\n+    if (foundLeft || node.left == null || node.left.max < interval.min) {\n+      // If node.left.max > interval.min but cannot find intersections on left subtree,\n+      // then there won't be any intersections in right subtree, since the right most interval x\n+      // in left subtree must have x.min > interval.max. All intervals in right subtree\n+      // will have mins >= x.min, so there won't be any intersections.\n+      foundRight = searchAll(node.right, interval, list);\n+    }\n+    return foundRoot || foundLeft || foundRight;\n+  }\n+\n+  public Set<Value> getAllValues() {\n+    Set<Value> values = new HashSet<>();\n+    getAllValues(root, values);\n+    return values;\n+  }\n+\n+  private void getAllValues(Node<Value> node, Set<Value> values) {\n+    if (node == null) {\n+      return;\n+    }\n+    getAllValues(node.left, values);\n+    values.addAll(node.valueList);\n+    getAllValues(node.right, values);\n+  }\n+\n+  private Node rotateRight(Node x) {\n+    Node y = x.left;\n+    x.left = y.right;\n+    y.right = x;\n+    fixAuxiliaryInfo(x);\n+    fixAuxiliaryInfo(y);\n+    return y;\n+  }\n+\n+  private Node rotateLeft(Node x) {\n+    Node y = x.right;\n+    x.right = y.left;\n+    y.left = x;\n+    fixAuxiliaryInfo(x);\n+    fixAuxiliaryInfo(y);\n+    return y;\n+  }\n+\n+  private int getBalance(Node node) {\n+    if (node == null) {\n+      return 0;\n+    }\n+    return height(node.left) - height(node.right);\n+  }\n+\n+  private int height(Node node) {\n+    if (node == null) {\n+      return 0;\n+    }\n+    return node.height;\n+  }\n+\n+  private long max(Node node) {\n+    if (node == null) {\n+      return Long.MIN_VALUE;\n+    }\n+    return node.max;\n+  }\n+\n+  // fix auxiliary information\n+  private void fixAuxiliaryInfo(Node node) {\n+    if (node == null) return;\n+    node.height = 1 + Math.max(height(node.left), height(node.right));\n+    node.max = Math.max(max(node.left), max(node.right));\n+    node.max = Math.max(node.max, node.interval.max);\n+  }\n+\n+  private static class Node<Value> {\n+    final Interval interval; // key\n+    List<Value> valueList;\n+    Node<Value> left, right;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 175}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI4MDU5NjI4OnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/IntervalST.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xM1QyMjo1NTo0N1rOHzCJaQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNFQwMDo1NDoxM1rOHzD9Nw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzI3NDYwMQ==", "bodyText": "(Critical) I don't think this will work.\nE.g.\nroot [10, 20]\n     /\n[0, 5]\n     \\ \n  [1, 10]\n\nInterval: [6, 10]\n\nThis algorithm will miss the interval of [1, 10]", "url": "https://github.com/apache/pinot/pull/6259#discussion_r523274601", "createdAt": "2020-11-13T22:55:47Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/IntervalST.java", "diffHunk": "@@ -0,0 +1,187 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner.intervalST;\n+\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+\n+\n+// A read-only interval search tree based on AVL Tree\n+public class IntervalST<Value> {\n+\n+  private Node<Value> root;\n+\n+  public IntervalST(List<Long> mins, List<Long> maxs, List<Value> values) {\n+    // read only once constructed\n+    for (int i = 0; i < mins.size(); i++) {\n+      insert(mins.get(i), maxs.get(i), values.get(i));\n+    }\n+  }\n+\n+  private void insert(long min, long max, Value value) {\n+    root = insert(root, new Interval(min, max), value);\n+  }\n+\n+  private Node insert(Node node, Interval interval, Value value) {\n+    if (node == null) {\n+      return new Node(interval, value);\n+    }\n+\n+    int cmp = interval.compareTo(node.interval);\n+    if (cmp == 0) {\n+      node.valueList.add(value);\n+      return node;\n+    } else if (cmp < 0) {\n+      node.left = insert(node.left, interval, value);\n+    } else {\n+      node.right = insert(node.right, interval, value);\n+    }\n+\n+    fixAuxiliaryInfo(node);\n+    int balance = getBalance(node);\n+    // Balance current subtree\n+    if (balance < -1) {\n+      if (getBalance(node.right) > 0) {\n+        node.right = rotateRight(node.right); // Right-left case\n+      }\n+      node = rotateLeft(node);\n+    } else if (balance > 1) {\n+      if (getBalance(node.left) < 0) {\n+        node.left = rotateLeft(node.left); // Left-right case\n+      }\n+      node = rotateRight(node);\n+    }\n+    return node;\n+  }\n+\n+  // Get all intervals which intersect with input range [min, max]\n+  public List<Value> searchAll(long min, long max) {\n+    return searchAll(new Interval(min, max));\n+  }\n+\n+  public List<Value> searchAll(Interval interval) {\n+    List<Value> list = new ArrayList<Value>();\n+    searchAll(root, interval, list);\n+    return list;\n+  }\n+\n+  private boolean searchAll(Node<Value> node, Interval interval, List<Value> list) {\n+    boolean foundRoot = false;\n+    boolean foundLeft = false;\n+    boolean foundRight = false;\n+    if (node == null)\n+      return false;\n+    if (interval.intersects(node.interval)) {\n+      list.addAll(node.valueList);\n+      foundRoot = true;\n+    }\n+    if (node.left != null && node.left.max >= interval.min) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzMwNDI0Nw==", "bodyText": "With some offline discussion, the algorithm used here is the Augmented tree solution under this wiki: https://en.wikipedia.org/wiki/Interval_tree, where the max is the max of all the nodes under the current node", "url": "https://github.com/apache/pinot/pull/6259#discussion_r523304247", "createdAt": "2020-11-14T00:54:13Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/IntervalST.java", "diffHunk": "@@ -0,0 +1,187 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner.intervalST;\n+\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+\n+\n+// A read-only interval search tree based on AVL Tree\n+public class IntervalST<Value> {\n+\n+  private Node<Value> root;\n+\n+  public IntervalST(List<Long> mins, List<Long> maxs, List<Value> values) {\n+    // read only once constructed\n+    for (int i = 0; i < mins.size(); i++) {\n+      insert(mins.get(i), maxs.get(i), values.get(i));\n+    }\n+  }\n+\n+  private void insert(long min, long max, Value value) {\n+    root = insert(root, new Interval(min, max), value);\n+  }\n+\n+  private Node insert(Node node, Interval interval, Value value) {\n+    if (node == null) {\n+      return new Node(interval, value);\n+    }\n+\n+    int cmp = interval.compareTo(node.interval);\n+    if (cmp == 0) {\n+      node.valueList.add(value);\n+      return node;\n+    } else if (cmp < 0) {\n+      node.left = insert(node.left, interval, value);\n+    } else {\n+      node.right = insert(node.right, interval, value);\n+    }\n+\n+    fixAuxiliaryInfo(node);\n+    int balance = getBalance(node);\n+    // Balance current subtree\n+    if (balance < -1) {\n+      if (getBalance(node.right) > 0) {\n+        node.right = rotateRight(node.right); // Right-left case\n+      }\n+      node = rotateLeft(node);\n+    } else if (balance > 1) {\n+      if (getBalance(node.left) < 0) {\n+        node.left = rotateLeft(node.left); // Left-right case\n+      }\n+      node = rotateRight(node);\n+    }\n+    return node;\n+  }\n+\n+  // Get all intervals which intersect with input range [min, max]\n+  public List<Value> searchAll(long min, long max) {\n+    return searchAll(new Interval(min, max));\n+  }\n+\n+  public List<Value> searchAll(Interval interval) {\n+    List<Value> list = new ArrayList<Value>();\n+    searchAll(root, interval, list);\n+    return list;\n+  }\n+\n+  private boolean searchAll(Node<Value> node, Interval interval, List<Value> list) {\n+    boolean foundRoot = false;\n+    boolean foundLeft = false;\n+    boolean foundRight = false;\n+    if (node == null)\n+      return false;\n+    if (interval.intersects(node.interval)) {\n+      list.addAll(node.valueList);\n+      foundRoot = true;\n+    }\n+    if (node.left != null && node.left.max >= interval.min) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzI3NDYwMQ=="}, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 96}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI4MDgyMzA4OnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/IntervalST.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNFQwMTowMToxOVrOHzEL6Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNFQwMTowMToxOVrOHzEL6Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzMwODAwOQ==", "bodyText": "(nit) Braces over the if block", "url": "https://github.com/apache/pinot/pull/6259#discussion_r523308009", "createdAt": "2020-11-14T01:01:19Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/IntervalST.java", "diffHunk": "@@ -0,0 +1,187 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner.intervalST;\n+\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+\n+\n+// A read-only interval search tree based on AVL Tree\n+public class IntervalST<Value> {\n+\n+  private Node<Value> root;\n+\n+  public IntervalST(List<Long> mins, List<Long> maxs, List<Value> values) {\n+    // read only once constructed\n+    for (int i = 0; i < mins.size(); i++) {\n+      insert(mins.get(i), maxs.get(i), values.get(i));\n+    }\n+  }\n+\n+  private void insert(long min, long max, Value value) {\n+    root = insert(root, new Interval(min, max), value);\n+  }\n+\n+  private Node insert(Node node, Interval interval, Value value) {\n+    if (node == null) {\n+      return new Node(interval, value);\n+    }\n+\n+    int cmp = interval.compareTo(node.interval);\n+    if (cmp == 0) {\n+      node.valueList.add(value);\n+      return node;\n+    } else if (cmp < 0) {\n+      node.left = insert(node.left, interval, value);\n+    } else {\n+      node.right = insert(node.right, interval, value);\n+    }\n+\n+    fixAuxiliaryInfo(node);\n+    int balance = getBalance(node);\n+    // Balance current subtree\n+    if (balance < -1) {\n+      if (getBalance(node.right) > 0) {\n+        node.right = rotateRight(node.right); // Right-left case\n+      }\n+      node = rotateLeft(node);\n+    } else if (balance > 1) {\n+      if (getBalance(node.left) < 0) {\n+        node.left = rotateLeft(node.left); // Left-right case\n+      }\n+      node = rotateRight(node);\n+    }\n+    return node;\n+  }\n+\n+  // Get all intervals which intersect with input range [min, max]\n+  public List<Value> searchAll(long min, long max) {\n+    return searchAll(new Interval(min, max));\n+  }\n+\n+  public List<Value> searchAll(Interval interval) {\n+    List<Value> list = new ArrayList<Value>();\n+    searchAll(root, interval, list);\n+    return list;\n+  }\n+\n+  private boolean searchAll(Node<Value> node, Interval interval, List<Value> list) {\n+    boolean foundRoot = false;\n+    boolean foundLeft = false;\n+    boolean foundRight = false;\n+    if (node == null)\n+      return false;\n+    if (interval.intersects(node.interval)) {\n+      list.addAll(node.valueList);\n+      foundRoot = true;\n+    }\n+    if (node.left != null && node.left.max >= interval.min) {\n+      foundLeft = searchAll(node.left, interval, list);\n+    }\n+\n+    if (foundLeft || node.left == null || node.left.max < interval.min) {\n+      // If node.left.max > interval.min but cannot find intersections on left subtree,\n+      // then there won't be any intersections in right subtree, since the right most interval x\n+      // in left subtree must have x.min > interval.max. All intervals in right subtree\n+      // will have mins >= x.min, so there won't be any intersections.\n+      foundRight = searchAll(node.right, interval, list);\n+    }\n+    return foundRoot || foundLeft || foundRight;\n+  }\n+\n+  public Set<Value> getAllValues() {\n+    Set<Value> values = new HashSet<>();\n+    getAllValues(root, values);\n+    return values;\n+  }\n+\n+  private void getAllValues(Node<Value> node, Set<Value> values) {\n+    if (node == null) {\n+      return;\n+    }\n+    getAllValues(node.left, values);\n+    values.addAll(node.valueList);\n+    getAllValues(node.right, values);\n+  }\n+\n+  private Node rotateRight(Node x) {\n+    Node y = x.left;\n+    x.left = y.right;\n+    y.right = x;\n+    fixAuxiliaryInfo(x);\n+    fixAuxiliaryInfo(y);\n+    return y;\n+  }\n+\n+  private Node rotateLeft(Node x) {\n+    Node y = x.right;\n+    x.right = y.left;\n+    y.left = x;\n+    fixAuxiliaryInfo(x);\n+    fixAuxiliaryInfo(y);\n+    return y;\n+  }\n+\n+  private int getBalance(Node node) {\n+    if (node == null) {\n+      return 0;\n+    }\n+    return height(node.left) - height(node.right);\n+  }\n+\n+  private int height(Node node) {\n+    if (node == null) {\n+      return 0;\n+    }\n+    return node.height;\n+  }\n+\n+  private long max(Node node) {\n+    if (node == null) {\n+      return Long.MIN_VALUE;\n+    }\n+    return node.max;\n+  }\n+\n+  // fix auxiliary information\n+  private void fixAuxiliaryInfo(Node node) {\n+    if (node == null) return;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 166}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI4MDk0ODQ0OnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/IntervalST.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNFQwMToyNzo1MlrOHzFkBg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNlQyMDoyMDo0NlrOH0P3Tw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzMzMDU2Ng==", "bodyText": "Since this is a read-only interval search tree, we can simplify the tree construction with the following steps:\n\nSort the intervals\nConstruct a full BST from the sorted intervals\nUse DFS to generate the auxiliary info\n\nOne step further, you can skip the step 2 and directly use the sorted intervals as the tree structure and use index to access the full BST (calculate the index is a little bit tricky though)", "url": "https://github.com/apache/pinot/pull/6259#discussion_r523330566", "createdAt": "2020-11-14T01:27:52Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/IntervalST.java", "diffHunk": "@@ -0,0 +1,187 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner.intervalST;\n+\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+\n+\n+// A read-only interval search tree based on AVL Tree\n+public class IntervalST<Value> {\n+\n+  private Node<Value> root;\n+\n+  public IntervalST(List<Long> mins, List<Long> maxs, List<Value> values) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDU0NzkxOQ==", "bodyText": "Cool idea! I think we can have a list representation of the bst (like array representation of heap). The root will be indexed as 0, left child 1, right child 2 and so on. The root of each subtree will be the one has median interval for that subtree.\nA typical balanced tree\n                              [10, 20]\n                              /       \\\n                       [8, 15]        [12, 20]  \n                          /            / \n                   [5, 10]       [10, 30]\n\nwill be represented as { [10, 20], [8, 15], [12, 20], [5, 10], null, [10, 30] }", "url": "https://github.com/apache/pinot/pull/6259#discussion_r524547919", "createdAt": "2020-11-16T20:20:46Z", "author": {"login": "jtao15"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/IntervalST.java", "diffHunk": "@@ -0,0 +1,187 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner.intervalST;\n+\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+\n+\n+// A read-only interval search tree based on AVL Tree\n+public class IntervalST<Value> {\n+\n+  private Node<Value> root;\n+\n+  public IntervalST(List<Long> mins, List<Long> maxs, List<Value> values) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzMzMDU2Ng=="}, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI4MDk2OTYzOnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeRangeSegmentPruner.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNFQwMTozMjo1NVrOHzFzEA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNFQwMTozMjo1NVrOHzFzEA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzMzNDQxNg==", "bodyText": "We don't want to read the ZK metadata for all segments for each callback. This is slow and could cause very heavy load on ZK, especially when the number of segments are high. We should cache the intervals and only read the ZK metadata for new segments. refreshSegment() is used for refreshing the cached interval for existing segments.", "url": "https://github.com/apache/pinot/pull/6259#discussion_r523334416", "createdAt": "2020-11-14T01:32:55Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeRangeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeRangeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeRangeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeRangeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final TimeUnit _timeUnit;\n+\n+  private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n+\n+  public TimeRangeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    DateTimeFormatSpec formatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    _timeUnit = formatSpec.getColumnUnit();\n+    Preconditions\n+        .checkNotNull(_timeUnit, \"Time unit must be configured in the field spec for time column: %s of table: %s\",\n+            _timeColumn, _tableNameWithType);\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    onExternalViewChange(externalView, idealState, onlineSegments);\n+  }\n+\n+  @Override\n+  public void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    updateTimeRangeMSToSegmentSearchTree(onlineSegments);\n+  }\n+\n+  private void updateTimeRangeMSToSegmentSearchTree(Set<String> onlineSegments) {\n+    List<String> segments = new ArrayList<>(onlineSegments);\n+    // atomic swap _timeRangeToSegmentMap for input online segments\n+    List<String> segmentZKMetadataPaths = new ArrayList<>();\n+    for (String segment: segments) {\n+      segmentZKMetadataPaths.add(_segmentZKMetadataPathPrefix + segment);\n+    }\n+\n+    List<ZNRecord> znRecords = _propertyStore.get(segmentZKMetadataPaths, null, AccessOption.PERSISTENT, true);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 104}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI4MDk5MzExOnYy", "diffSide": "RIGHT", "path": "pinot-spi/src/main/java/org/apache/pinot/spi/config/table/RoutingConfig.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNFQwMTo1Mzo0N1rOHzF-qw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNFQwMTo1Mzo0N1rOHzF-qw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMzMzNzM4Nw==", "bodyText": "Let's name it time to be consistent with partition. Also it works not only on time range, but also point time lookup\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              public static final String TIME_RANGE_SEGMENT_PRUNER_TYPE = \"timeRange\";\n          \n          \n            \n              public static final String TIME_SEGMENT_PRUNER_TYPE = \"time\";", "url": "https://github.com/apache/pinot/pull/6259#discussion_r523337387", "createdAt": "2020-11-14T01:53:47Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-spi/src/main/java/org/apache/pinot/spi/config/table/RoutingConfig.java", "diffHunk": "@@ -27,6 +27,7 @@\n \n public class RoutingConfig extends BaseJsonConfig {\n   public static final String PARTITION_SEGMENT_PRUNER_TYPE = \"partition\";\n+  public static final String TIME_RANGE_SEGMENT_PRUNER_TYPE = \"timeRange\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4148ef75949f6003ad0362781ed87e1b13fed60"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwMjAwODI2OnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/RoutingManager.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwNzoxMDoyNFrOH2Pa0g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzo1ODo0NlrOH22yww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjYzNzc3OA==", "bodyText": "Why did you change the interface to return Set for SegmentSelector if you will anyway convert it back to the array list?", "url": "https://github.com/apache/pinot/pull/6259#discussion_r526637778", "createdAt": "2020-11-19T07:10:24Z", "author": {"login": "snleee"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/RoutingManager.java", "diffHunk": "@@ -570,14 +570,14 @@ void refreshSegment(String segment) {\n     }\n \n     InstanceSelector.SelectionResult calculateRouting(BrokerRequest brokerRequest) {\n-      List<String> selectedSegments = _segmentSelector.select(brokerRequest);\n+      Set<String> selectedSegments = _segmentSelector.select(brokerRequest);\n       if (!selectedSegments.isEmpty()) {\n         for (SegmentPruner segmentPruner : _segmentPruners) {\n           selectedSegments = segmentPruner.prune(brokerRequest, selectedSegments);\n         }\n       }\n       if (!selectedSegments.isEmpty()) {\n-        return _instanceSelector.select(brokerRequest, selectedSegments);\n+        return _instanceSelector.select(brokerRequest, new ArrayList<>(selectedSegments));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1adcfac676a45b45421f5ba6eab4ee6b1853555"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzI4Mjg4Mw==", "bodyText": "Current BalancedInstanceSelector logic relies on the order of the selected segments, maybe we can change that logic and change this api to be Set.", "url": "https://github.com/apache/pinot/pull/6259#discussion_r527282883", "createdAt": "2020-11-19T23:58:46Z", "author": {"login": "jtao15"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/RoutingManager.java", "diffHunk": "@@ -570,14 +570,14 @@ void refreshSegment(String segment) {\n     }\n \n     InstanceSelector.SelectionResult calculateRouting(BrokerRequest brokerRequest) {\n-      List<String> selectedSegments = _segmentSelector.select(brokerRequest);\n+      Set<String> selectedSegments = _segmentSelector.select(brokerRequest);\n       if (!selectedSegments.isEmpty()) {\n         for (SegmentPruner segmentPruner : _segmentPruners) {\n           selectedSegments = segmentPruner.prune(brokerRequest, selectedSegments);\n         }\n       }\n       if (!selectedSegments.isEmpty()) {\n-        return _instanceSelector.select(brokerRequest, selectedSegments);\n+        return _instanceSelector.select(brokerRequest, new ArrayList<>(selectedSegments));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjYzNzc3OA=="}, "originalCommit": {"oid": "f1adcfac676a45b45421f5ba6eab4ee6b1853555"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwMjAxMTk3OnYy", "diffSide": "LEFT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/instanceselector/BaseInstanceSelector.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwNzoxMTo1NFrOH2PdAQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwNzoxMTo1NFrOH2PdAQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjYzODMzNw==", "bodyText": "+1 good catch :)", "url": "https://github.com/apache/pinot/pull/6259#discussion_r526638337", "createdAt": "2020-11-19T07:11:54Z", "author": {"login": "snleee"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/instanceselector/BaseInstanceSelector.java", "diffHunk": "@@ -25,8 +25,6 @@\n import java.util.List;\n import java.util.Map;\n import java.util.Set;\n-import java.util.TreeMap;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1adcfac676a45b45421f5ba6eab4ee6b1853555"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwMjA2NzU4OnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwNzozMjowNFrOH2P9ig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzowNjo1MlrOH21qJA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjY0NjY2Ng==", "bodyText": "Are we covering the following case?\n1.segment_0 gets uploaded with start_time=10, end_time=12\n2. There was an issue with the offline pipeline, we refresh the segment_0 with start_time=10, end_time=11.\nIn this case, _segmentToTimeRangeMSCache needs to be updated properly with the new interval. Otherwise, our pruner result will be wrong. I think that the partition pruner also does not currently handle this issue. We should at least add the TODO comment to handle this in the future.\nOne possible approach is to add TTL expiration to the cache to make sure the interval eventually gets updated to the correct value.", "url": "https://github.com/apache/pinot/pull/6259#discussion_r526646666", "createdAt": "2020-11-19T07:32:04Z", "author": {"login": "snleee"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.math.BigDecimal;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final TimeUnit _timeUnit;\n+\n+  private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n+  private final Map _segmentToTimeRangeMSCache;\n+\n+  public TimeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    DateTimeFormatSpec formatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    _timeUnit = formatSpec.getColumnUnit();\n+    Preconditions\n+        .checkNotNull(_timeUnit, \"Time unit must be configured in the field spec for time column: %s of table: %s\",\n+            _timeColumn, _tableNameWithType);\n+    _segmentToTimeRangeMSCache = new HashMap<String, Interval>();\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    onExternalViewChange(externalView, idealState, onlineSegments);\n+  }\n+\n+  @Override\n+  synchronized public void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    List<String> newSegments = new ArrayList<>();\n+    for (String onlineSegment : onlineSegments) {\n+      if (!_segmentToTimeRangeMSCache.containsKey(onlineSegment)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1adcfac676a45b45421f5ba6eab4ee6b1853555"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzI2NDE4MA==", "bodyText": "Will the refresh call refreshSegment() on pruners? If yes, the cache will be updated.", "url": "https://github.com/apache/pinot/pull/6259#discussion_r527264180", "createdAt": "2020-11-19T23:06:35Z", "author": {"login": "jtao15"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.math.BigDecimal;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final TimeUnit _timeUnit;\n+\n+  private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n+  private final Map _segmentToTimeRangeMSCache;\n+\n+  public TimeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    DateTimeFormatSpec formatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    _timeUnit = formatSpec.getColumnUnit();\n+    Preconditions\n+        .checkNotNull(_timeUnit, \"Time unit must be configured in the field spec for time column: %s of table: %s\",\n+            _timeColumn, _tableNameWithType);\n+    _segmentToTimeRangeMSCache = new HashMap<String, Interval>();\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    onExternalViewChange(externalView, idealState, onlineSegments);\n+  }\n+\n+  @Override\n+  synchronized public void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    List<String> newSegments = new ArrayList<>();\n+    for (String onlineSegment : onlineSegments) {\n+      if (!_segmentToTimeRangeMSCache.containsKey(onlineSegment)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjY0NjY2Ng=="}, "originalCommit": {"oid": "f1adcfac676a45b45421f5ba6eab4ee6b1853555"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzI2NDI5Mg==", "bodyText": "@snleee This is handled with the API refreshSegment()", "url": "https://github.com/apache/pinot/pull/6259#discussion_r527264292", "createdAt": "2020-11-19T23:06:52Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.math.BigDecimal;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final TimeUnit _timeUnit;\n+\n+  private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n+  private final Map _segmentToTimeRangeMSCache;\n+\n+  public TimeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    DateTimeFormatSpec formatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    _timeUnit = formatSpec.getColumnUnit();\n+    Preconditions\n+        .checkNotNull(_timeUnit, \"Time unit must be configured in the field spec for time column: %s of table: %s\",\n+            _timeColumn, _tableNameWithType);\n+    _segmentToTimeRangeMSCache = new HashMap<String, Interval>();\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    onExternalViewChange(externalView, idealState, onlineSegments);\n+  }\n+\n+  @Override\n+  synchronized public void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    List<String> newSegments = new ArrayList<>();\n+    for (String onlineSegment : onlineSegments) {\n+      if (!_segmentToTimeRangeMSCache.containsKey(onlineSegment)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjY0NjY2Ng=="}, "originalCommit": {"oid": "f1adcfac676a45b45421f5ba6eab4ee6b1853555"}, "originalPosition": 100}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwMjA3OTI3OnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/test/java/org/apache/pinot/broker/routing/segmentpruner/SegmentPrunerTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwNzozNjoxM1rOH2QElg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwNzozNjoxM1rOH2QElg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjY0ODQ3MA==", "bodyText": "Can we also add the test with parsing query with SQL?", "url": "https://github.com/apache/pinot/pull/6259#discussion_r526648470", "createdAt": "2020-11-19T07:36:13Z", "author": {"login": "snleee"}, "path": "pinot-broker/src/test/java/org/apache/pinot/broker/routing/segmentpruner/SegmentPrunerTest.java", "diffHunk": "@@ -170,56 +220,213 @@ public void testPartitionAwareSegmentPruner() {\n     ZKMetadataProvider\n         .setOfflineSegmentZKMetadata(_propertyStore, OFFLINE_TABLE_NAME, segmentZKMetadataWithoutPartitionMetadata);\n     segmentPruner.onExternalViewChange(externalView, idealState, onlineSegments);\n-    assertEquals(segmentPruner.prune(brokerRequest1, Collections.singletonList(segmentWithoutPartitionMetadata)),\n+    assertEquals(segmentPruner.prune(brokerRequest1, new HashSet<>(Collections.singletonList(segmentWithoutPartitionMetadata))),\n         Collections.singletonList(segmentWithoutPartitionMetadata));\n-    assertEquals(segmentPruner.prune(brokerRequest2, Collections.singletonList(segmentWithoutPartitionMetadata)),\n+    assertEquals(segmentPruner.prune(brokerRequest2, new HashSet<>(Collections.singletonList(segmentWithoutPartitionMetadata))),\n         Collections.singletonList(segmentWithoutPartitionMetadata));\n-    assertEquals(segmentPruner.prune(brokerRequest3, Collections.singletonList(segmentWithoutPartitionMetadata)),\n+    assertEquals(segmentPruner.prune(brokerRequest3, new HashSet<>(Collections.singletonList(segmentWithoutPartitionMetadata))),\n         Collections.singletonList(segmentWithoutPartitionMetadata));\n \n     // Test different partition functions and number of partitions\n     // 0 % 5 = 0; 1 % 5 = 1; 2 % 5 = 2\n     String segment0 = \"segment0\";\n     onlineSegments.add(segment0);\n-    setSegmentZKMetadata(segment0, \"Modulo\", 5, 0);\n+    setSegmentZKPartitionMetadata(segment0, \"Modulo\", 5, 0);\n     // Murmur(0) % 4 = 0; Murmur(1) % 4 = 3; Murmur(2) % 4 = 0\n     String segment1 = \"segment1\";\n     onlineSegments.add(segment1);\n-    setSegmentZKMetadata(segment1, \"Murmur\", 4, 0);\n+    setSegmentZKPartitionMetadata(segment1, \"Murmur\", 4, 0);\n     segmentPruner.onExternalViewChange(externalView, idealState, onlineSegments);\n-    assertEquals(segmentPruner.prune(brokerRequest1, Arrays.asList(segment0, segment1)),\n-        Arrays.asList(segment0, segment1));\n-    assertEquals(segmentPruner.prune(brokerRequest2, Arrays.asList(segment0, segment1)),\n-        Arrays.asList(segment0, segment1));\n-    assertEquals(segmentPruner.prune(brokerRequest3, Arrays.asList(segment0, segment1)),\n-        Collections.singletonList(segment1));\n+    assertEquals(segmentPruner.prune(brokerRequest1, new HashSet<>(Arrays.asList(segment0, segment1))),\n+        new HashSet<>(Arrays.asList(segment0, segment1)));\n+    assertEquals(segmentPruner.prune(brokerRequest2, new HashSet<>(Arrays.asList(segment0, segment1))),\n+        new HashSet<>(Arrays.asList(segment0, segment1)));\n+    assertEquals(segmentPruner.prune(brokerRequest3, new HashSet<>(Arrays.asList(segment0, segment1))),\n+        new HashSet<>(Collections.singletonList(segment1)));\n \n     // Update partition metadata without refreshing should have no effect\n-    setSegmentZKMetadata(segment0, \"Modulo\", 4, 1);\n+    setSegmentZKPartitionMetadata(segment0, \"Modulo\", 4, 1);\n     segmentPruner.onExternalViewChange(externalView, idealState, onlineSegments);\n-    assertEquals(segmentPruner.prune(brokerRequest1, Arrays.asList(segment0, segment1)),\n-        Arrays.asList(segment0, segment1));\n-    assertEquals(segmentPruner.prune(brokerRequest2, Arrays.asList(segment0, segment1)),\n-        Arrays.asList(segment0, segment1));\n-    assertEquals(segmentPruner.prune(brokerRequest3, Arrays.asList(segment0, segment1)),\n-        Collections.singletonList(segment1));\n+    assertEquals(segmentPruner.prune(brokerRequest1, new HashSet<>(Arrays.asList(segment0, segment1))),\n+        new HashSet<>(Arrays.asList(segment0, segment1)));\n+    assertEquals(segmentPruner.prune(brokerRequest2, new HashSet<>(Arrays.asList(segment0, segment1))),\n+        new HashSet<>(Arrays.asList(segment0, segment1)));\n+    assertEquals(segmentPruner.prune(brokerRequest3, new HashSet<>(Arrays.asList(segment0, segment1))),\n+        new HashSet<>(Collections.singletonList(segment1)));\n \n     // Refresh the changed segment should update the segment pruner\n     segmentPruner.refreshSegment(segment0);\n-    assertEquals(segmentPruner.prune(brokerRequest1, Arrays.asList(segment0, segment1)),\n-        Arrays.asList(segment0, segment1));\n-    assertEquals(segmentPruner.prune(brokerRequest2, Arrays.asList(segment0, segment1)),\n-        Collections.singletonList(segment1));\n-    assertEquals(segmentPruner.prune(brokerRequest3, Arrays.asList(segment0, segment1)),\n-        Arrays.asList(segment0, segment1));\n+    assertEquals(segmentPruner.prune(brokerRequest1, new HashSet<>(Arrays.asList(segment0, segment1))),\n+        new HashSet<>(Arrays.asList(segment0, segment1)));\n+    assertEquals(segmentPruner.prune(brokerRequest2, new HashSet<>(Arrays.asList(segment0, segment1))),\n+        new HashSet<>(Collections.singletonList(segment1)));\n+    assertEquals(segmentPruner.prune(brokerRequest3, new HashSet<>(Arrays.asList(segment0, segment1))),\n+        new HashSet<>(Arrays.asList(segment0, segment1)));\n+  }\n+\n+  @Test\n+  public void testTimeRangeSegmentPruner() {\n+    Pql2Compiler compiler = new Pql2Compiler();\n+    BrokerRequest brokerRequest1 = compiler.compileToBrokerRequest(QUERY_1);\n+    BrokerRequest brokerRequest2 = compiler.compileToBrokerRequest(QUERY_5);\n+    BrokerRequest brokerRequest3 = compiler.compileToBrokerRequest(QUERY_6);\n+    BrokerRequest brokerRequest4 = compiler.compileToBrokerRequest(QUERY_7);\n+    BrokerRequest brokerRequest5 = compiler.compileToBrokerRequest(QUERY_8);\n+    BrokerRequest brokerRequest6 = compiler.compileToBrokerRequest(QUERY_9);\n+    BrokerRequest brokerRequest7 = compiler.compileToBrokerRequest(QUERY_10);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1adcfac676a45b45421f5ba6eab4ee6b1853555"}, "originalPosition": 248}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwMjA4MjUyOnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/Interval.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwNzozNzoxOFrOH2QGkg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzowNzoxMVrOH21qqw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjY0ODk3OA==", "bodyText": "Is this intellij auto generated equals()? If not, let's use the one generated by intellij.", "url": "https://github.com/apache/pinot/pull/6259#discussion_r526648978", "createdAt": "2020-11-19T07:37:18Z", "author": {"login": "snleee"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/Interval.java", "diffHunk": "@@ -0,0 +1,90 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner.intervalST;\n+\n+import com.google.common.base.Preconditions;\n+import javax.validation.constraints.NotNull;\n+\n+\n+/**\n+ * The {@code Interval} class represents an one-dimensional closed interval which contains both ends.\n+ */\n+public class Interval implements Comparable<Interval> {\n+  public final long _min;\n+  public final long _max;\n+\n+  public Interval(long min, long max) {\n+    Preconditions.checkState(min <= max, \"invalid interval [{}, {}]\", min, max);\n+    _min = min;\n+    _max = max;\n+  }\n+\n+  public boolean intersects(@NotNull Interval that) {\n+    return _max >= that._min && that._max >= _min;\n+  }\n+\n+  @Override\n+  public int compareTo(Interval that) {\n+    Preconditions.checkNotNull(that, \"Compare to invalid interval: null\");\n+    if (_min < that._min) {\n+      return -1;\n+    } else if (_min > that._min) {\n+      return 1;\n+    } else if (_max < that._max) {\n+      return -1;\n+    } else if (_max > that._max) {\n+      return 1;\n+    }\n+    else return 0;\n+  }\n+\n+  @Override\n+  public int hashCode() {\n+    return (int)(_min * 17 + _max);\n+  }\n+\n+  @Override\n+  public boolean equals(Object that) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1adcfac676a45b45421f5ba6eab4ee6b1853555"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzI2NDQyNw==", "bodyText": "No, I'll use the auto generated one instead.", "url": "https://github.com/apache/pinot/pull/6259#discussion_r527264427", "createdAt": "2020-11-19T23:07:11Z", "author": {"login": "jtao15"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/Interval.java", "diffHunk": "@@ -0,0 +1,90 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner.intervalST;\n+\n+import com.google.common.base.Preconditions;\n+import javax.validation.constraints.NotNull;\n+\n+\n+/**\n+ * The {@code Interval} class represents an one-dimensional closed interval which contains both ends.\n+ */\n+public class Interval implements Comparable<Interval> {\n+  public final long _min;\n+  public final long _max;\n+\n+  public Interval(long min, long max) {\n+    Preconditions.checkState(min <= max, \"invalid interval [{}, {}]\", min, max);\n+    _min = min;\n+    _max = max;\n+  }\n+\n+  public boolean intersects(@NotNull Interval that) {\n+    return _max >= that._min && that._max >= _min;\n+  }\n+\n+  @Override\n+  public int compareTo(Interval that) {\n+    Preconditions.checkNotNull(that, \"Compare to invalid interval: null\");\n+    if (_min < that._min) {\n+      return -1;\n+    } else if (_min > that._min) {\n+      return 1;\n+    } else if (_max < that._max) {\n+      return -1;\n+    } else if (_max > that._max) {\n+      return 1;\n+    }\n+    else return 0;\n+  }\n+\n+  @Override\n+  public int hashCode() {\n+    return (int)(_min * 17 + _max);\n+  }\n+\n+  @Override\n+  public boolean equals(Object that) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjY0ODk3OA=="}, "originalCommit": {"oid": "f1adcfac676a45b45421f5ba6eab4ee6b1853555"}, "originalPosition": 63}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwMjA4MzMwOnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/Interval.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwNzozNzozNFrOH2QHCg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzo1Njo0OVrOH22wRA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjY0OTA5OA==", "bodyText": "Is this autogenerated by intelij?", "url": "https://github.com/apache/pinot/pull/6259#discussion_r526649098", "createdAt": "2020-11-19T07:37:34Z", "author": {"login": "snleee"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/Interval.java", "diffHunk": "@@ -0,0 +1,90 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner.intervalST;\n+\n+import com.google.common.base.Preconditions;\n+import javax.validation.constraints.NotNull;\n+\n+\n+/**\n+ * The {@code Interval} class represents an one-dimensional closed interval which contains both ends.\n+ */\n+public class Interval implements Comparable<Interval> {\n+  public final long _min;\n+  public final long _max;\n+\n+  public Interval(long min, long max) {\n+    Preconditions.checkState(min <= max, \"invalid interval [{}, {}]\", min, max);\n+    _min = min;\n+    _max = max;\n+  }\n+\n+  public boolean intersects(@NotNull Interval that) {\n+    return _max >= that._min && that._max >= _min;\n+  }\n+\n+  @Override\n+  public int compareTo(Interval that) {\n+    Preconditions.checkNotNull(that, \"Compare to invalid interval: null\");\n+    if (_min < that._min) {\n+      return -1;\n+    } else if (_min > that._min) {\n+      return 1;\n+    } else if (_max < that._max) {\n+      return -1;\n+    } else if (_max > that._max) {\n+      return 1;\n+    }\n+    else return 0;\n+  }\n+\n+  @Override\n+  public int hashCode() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1adcfac676a45b45421f5ba6eab4ee6b1853555"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzI4MjI0NA==", "bodyText": "Yeah, please use the one auto-generated", "url": "https://github.com/apache/pinot/pull/6259#discussion_r527282244", "createdAt": "2020-11-19T23:56:49Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/Interval.java", "diffHunk": "@@ -0,0 +1,90 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner.intervalST;\n+\n+import com.google.common.base.Preconditions;\n+import javax.validation.constraints.NotNull;\n+\n+\n+/**\n+ * The {@code Interval} class represents an one-dimensional closed interval which contains both ends.\n+ */\n+public class Interval implements Comparable<Interval> {\n+  public final long _min;\n+  public final long _max;\n+\n+  public Interval(long min, long max) {\n+    Preconditions.checkState(min <= max, \"invalid interval [{}, {}]\", min, max);\n+    _min = min;\n+    _max = max;\n+  }\n+\n+  public boolean intersects(@NotNull Interval that) {\n+    return _max >= that._min && that._max >= _min;\n+  }\n+\n+  @Override\n+  public int compareTo(Interval that) {\n+    Preconditions.checkNotNull(that, \"Compare to invalid interval: null\");\n+    if (_min < that._min) {\n+      return -1;\n+    } else if (_min > that._min) {\n+      return 1;\n+    } else if (_max < that._max) {\n+      return -1;\n+    } else if (_max > that._max) {\n+      return 1;\n+    }\n+    else return 0;\n+  }\n+\n+  @Override\n+  public int hashCode() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjY0OTA5OA=="}, "originalCommit": {"oid": "f1adcfac676a45b45421f5ba6eab4ee6b1853555"}, "originalPosition": 58}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNTk5NTcyOnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzoxNDowOFrOH2103A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzoxNDowOFrOH2103A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzI2NzAzNg==", "bodyText": "Put synchronized after public (actually synchronized is not needed here as it is already synchronized by the caller, but okay to have for readability), same for other signatures.", "url": "https://github.com/apache/pinot/pull/6259#discussion_r527267036", "createdAt": "2020-11-19T23:14:08Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.math.BigDecimal;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final TimeUnit _timeUnit;\n+\n+  private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n+  private final Map _segmentToTimeRangeMSCache;\n+\n+  public TimeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    DateTimeFormatSpec formatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    _timeUnit = formatSpec.getColumnUnit();\n+    Preconditions\n+        .checkNotNull(_timeUnit, \"Time unit must be configured in the field spec for time column: %s of table: %s\",\n+            _timeColumn, _tableNameWithType);\n+    _segmentToTimeRangeMSCache = new HashMap<String, Interval>();\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    onExternalViewChange(externalView, idealState, onlineSegments);\n+  }\n+\n+  @Override\n+  synchronized public void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1adcfac676a45b45421f5ba6eab4ee6b1853555"}, "originalPosition": 97}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNjAwMjAyOnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzoxNjo0MVrOH214kg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzoxNjo0MVrOH214kg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzI2Nzk4Ng==", "bodyText": "You may refer to PartitionSegmentPruner where we do batch read for init() and single read for onExternalViewChange() because usually external view change only involves change for one segment.", "url": "https://github.com/apache/pinot/pull/6259#discussion_r527267986", "createdAt": "2020-11-19T23:16:41Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.math.BigDecimal;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final TimeUnit _timeUnit;\n+\n+  private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n+  private final Map _segmentToTimeRangeMSCache;\n+\n+  public TimeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    DateTimeFormatSpec formatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    _timeUnit = formatSpec.getColumnUnit();\n+    Preconditions\n+        .checkNotNull(_timeUnit, \"Time unit must be configured in the field spec for time column: %s of table: %s\",\n+            _timeColumn, _tableNameWithType);\n+    _segmentToTimeRangeMSCache = new HashMap<String, Interval>();\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1adcfac676a45b45421f5ba6eab4ee6b1853555"}, "originalPosition": 92}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNjAwNDczOnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzoxNzo1MFrOH216Kw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzoxNzo1MFrOH216Kw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzI2ODM5NQ==", "bodyText": "Put defaultRange as a constant", "url": "https://github.com/apache/pinot/pull/6259#discussion_r527268395", "createdAt": "2020-11-19T23:17:50Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.math.BigDecimal;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final TimeUnit _timeUnit;\n+\n+  private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n+  private final Map _segmentToTimeRangeMSCache;\n+\n+  public TimeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    DateTimeFormatSpec formatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    _timeUnit = formatSpec.getColumnUnit();\n+    Preconditions\n+        .checkNotNull(_timeUnit, \"Time unit must be configured in the field spec for time column: %s of table: %s\",\n+            _timeColumn, _tableNameWithType);\n+    _segmentToTimeRangeMSCache = new HashMap<String, Interval>();\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    onExternalViewChange(externalView, idealState, onlineSegments);\n+  }\n+\n+  @Override\n+  synchronized public void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    List<String> newSegments = new ArrayList<>();\n+    for (String onlineSegment : onlineSegments) {\n+      if (!_segmentToTimeRangeMSCache.containsKey(onlineSegment)) {\n+        newSegments.add(onlineSegment);\n+      }\n+    }\n+\n+    List<String> newSegmentZKMetadataPaths = new ArrayList<>();\n+    for (String segment: newSegments) {\n+      newSegmentZKMetadataPaths.add(_segmentZKMetadataPathPrefix + segment);\n+    }\n+\n+    List<ZNRecord> znRecords = _propertyStore.get(newSegmentZKMetadataPaths, null, AccessOption.PERSISTENT, true);\n+\n+    for (int i = 0; i < newSegments.size(); i++) {\n+      String segment = newSegments.get(i);\n+      Interval range = extractTimeRangeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(i));\n+      _segmentToTimeRangeMSCache.put(segment, range);\n+    }\n+    _segmentToTimeRangeMSCache.keySet().retainAll(onlineSegments);\n+    // atomic swap _timeRangeToSegmentMap for input online segments\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(_segmentToTimeRangeMSCache);\n+  }\n+\n+  private Interval extractTimeRangeMSFromSegmentZKMetaZNRecord(String segment, @Nullable ZNRecord znRecord) {\n+    Interval defaultRange = new Interval(MIN_START_TIME, MAX_END_TIME);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1adcfac676a45b45421f5ba6eab4ee6b1853555"}, "originalPosition": 123}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNjAwOTA5OnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzoxOTozNlrOH218tg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzoxOTozNlrOH218tg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzI2OTA0Ng==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n          \n          \n            \n              private final Map _segmentToTimeRangeMSCache;\n          \n          \n            \n              private volatile IntervalST<String> _intervalTree;\n          \n          \n            \n              private final Map<String, Interval> _intervalMap;", "url": "https://github.com/apache/pinot/pull/6259#discussion_r527269046", "createdAt": "2020-11-19T23:19:36Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.math.BigDecimal;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final TimeUnit _timeUnit;\n+\n+  private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n+  private final Map _segmentToTimeRangeMSCache;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1adcfac676a45b45421f5ba6eab4ee6b1853555"}, "originalPosition": 68}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNjAxNDE5OnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzoyMTozNFrOH21_lA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzoyMzoxNVrOH22CDw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzI2OTc4MA==", "bodyText": "Cache _timeRangeMSToSegmentSearchTree into a local variable in case it is swapped during this method", "url": "https://github.com/apache/pinot/pull/6259#discussion_r527269780", "createdAt": "2020-11-19T23:21:34Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.math.BigDecimal;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final TimeUnit _timeUnit;\n+\n+  private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n+  private final Map _segmentToTimeRangeMSCache;\n+\n+  public TimeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    DateTimeFormatSpec formatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    _timeUnit = formatSpec.getColumnUnit();\n+    Preconditions\n+        .checkNotNull(_timeUnit, \"Time unit must be configured in the field spec for time column: %s of table: %s\",\n+            _timeColumn, _tableNameWithType);\n+    _segmentToTimeRangeMSCache = new HashMap<String, Interval>();\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    onExternalViewChange(externalView, idealState, onlineSegments);\n+  }\n+\n+  @Override\n+  synchronized public void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    List<String> newSegments = new ArrayList<>();\n+    for (String onlineSegment : onlineSegments) {\n+      if (!_segmentToTimeRangeMSCache.containsKey(onlineSegment)) {\n+        newSegments.add(onlineSegment);\n+      }\n+    }\n+\n+    List<String> newSegmentZKMetadataPaths = new ArrayList<>();\n+    for (String segment: newSegments) {\n+      newSegmentZKMetadataPaths.add(_segmentZKMetadataPathPrefix + segment);\n+    }\n+\n+    List<ZNRecord> znRecords = _propertyStore.get(newSegmentZKMetadataPaths, null, AccessOption.PERSISTENT, true);\n+\n+    for (int i = 0; i < newSegments.size(); i++) {\n+      String segment = newSegments.get(i);\n+      Interval range = extractTimeRangeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(i));\n+      _segmentToTimeRangeMSCache.put(segment, range);\n+    }\n+    _segmentToTimeRangeMSCache.keySet().retainAll(onlineSegments);\n+    // atomic swap _timeRangeToSegmentMap for input online segments\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(_segmentToTimeRangeMSCache);\n+  }\n+\n+  private Interval extractTimeRangeMSFromSegmentZKMetaZNRecord(String segment, @Nullable ZNRecord znRecord) {\n+    Interval defaultRange = new Interval(MIN_START_TIME, MAX_END_TIME);\n+    // Segments without metadata or with invalid time range will be set with [min_start, max_end] and will not be pruned\n+    if (znRecord == null) {\n+      LOGGER.warn(\"Failed to find segment ZK metadata for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return defaultRange;\n+    }\n+\n+    long startTime = znRecord.getLongField(CommonConstants.Segment.START_TIME, -1);\n+    long endTime = znRecord.getLongField(CommonConstants.Segment.END_TIME, -1);\n+    if (startTime < 0 || endTime < 0 || startTime > endTime) {\n+      LOGGER.warn(\"Failed to find valid end time for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return defaultRange;\n+    }\n+\n+    TimeUnit timeUnit = znRecord.getEnumField(CommonConstants.Segment.TIME_UNIT, TimeUnit.class, TimeUnit.DAYS);\n+    return new Interval(timeUnit.toMillis(startTime), timeUnit.toMillis(endTime));\n+  }\n+\n+  @Override\n+  synchronized public void refreshSegment(String segment) {\n+    List<ZNRecord> znRecords = _propertyStore.get(Collections.singletonList(_segmentZKMetadataPathPrefix + segment), null, AccessOption.PERSISTENT, true);\n+    Interval range = extractTimeRangeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(0));\n+    _segmentToTimeRangeMSCache.put(segment, range);\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(_segmentToTimeRangeMSCache);\n+  }\n+\n+  /**\n+   * NOTE: Pruning is done by searching _timeRangeToSegmentSearchTree based on request time range and check if the results\n+   *       are in the input segments. By doing so we will have run time O(M * logN) (N is the # of all online segments,\n+   *       M is the # of qualified intersected segments).\n+   */\n+  @Override\n+  public Set<String> prune(BrokerRequest brokerRequest, Set<String> segments) {\n+    // The pruned order may be different from the input order\n+    if (_timeRangeMSToSegmentSearchTree == null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1adcfac676a45b45421f5ba6eab4ee6b1853555"}, "originalPosition": 157}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzI3MDQxNQ==", "bodyText": "Also I think it can never be null here", "url": "https://github.com/apache/pinot/pull/6259#discussion_r527270415", "createdAt": "2020-11-19T23:23:15Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.math.BigDecimal;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final TimeUnit _timeUnit;\n+\n+  private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n+  private final Map _segmentToTimeRangeMSCache;\n+\n+  public TimeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    DateTimeFormatSpec formatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    _timeUnit = formatSpec.getColumnUnit();\n+    Preconditions\n+        .checkNotNull(_timeUnit, \"Time unit must be configured in the field spec for time column: %s of table: %s\",\n+            _timeColumn, _tableNameWithType);\n+    _segmentToTimeRangeMSCache = new HashMap<String, Interval>();\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    onExternalViewChange(externalView, idealState, onlineSegments);\n+  }\n+\n+  @Override\n+  synchronized public void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    List<String> newSegments = new ArrayList<>();\n+    for (String onlineSegment : onlineSegments) {\n+      if (!_segmentToTimeRangeMSCache.containsKey(onlineSegment)) {\n+        newSegments.add(onlineSegment);\n+      }\n+    }\n+\n+    List<String> newSegmentZKMetadataPaths = new ArrayList<>();\n+    for (String segment: newSegments) {\n+      newSegmentZKMetadataPaths.add(_segmentZKMetadataPathPrefix + segment);\n+    }\n+\n+    List<ZNRecord> znRecords = _propertyStore.get(newSegmentZKMetadataPaths, null, AccessOption.PERSISTENT, true);\n+\n+    for (int i = 0; i < newSegments.size(); i++) {\n+      String segment = newSegments.get(i);\n+      Interval range = extractTimeRangeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(i));\n+      _segmentToTimeRangeMSCache.put(segment, range);\n+    }\n+    _segmentToTimeRangeMSCache.keySet().retainAll(onlineSegments);\n+    // atomic swap _timeRangeToSegmentMap for input online segments\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(_segmentToTimeRangeMSCache);\n+  }\n+\n+  private Interval extractTimeRangeMSFromSegmentZKMetaZNRecord(String segment, @Nullable ZNRecord znRecord) {\n+    Interval defaultRange = new Interval(MIN_START_TIME, MAX_END_TIME);\n+    // Segments without metadata or with invalid time range will be set with [min_start, max_end] and will not be pruned\n+    if (znRecord == null) {\n+      LOGGER.warn(\"Failed to find segment ZK metadata for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return defaultRange;\n+    }\n+\n+    long startTime = znRecord.getLongField(CommonConstants.Segment.START_TIME, -1);\n+    long endTime = znRecord.getLongField(CommonConstants.Segment.END_TIME, -1);\n+    if (startTime < 0 || endTime < 0 || startTime > endTime) {\n+      LOGGER.warn(\"Failed to find valid end time for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return defaultRange;\n+    }\n+\n+    TimeUnit timeUnit = znRecord.getEnumField(CommonConstants.Segment.TIME_UNIT, TimeUnit.class, TimeUnit.DAYS);\n+    return new Interval(timeUnit.toMillis(startTime), timeUnit.toMillis(endTime));\n+  }\n+\n+  @Override\n+  synchronized public void refreshSegment(String segment) {\n+    List<ZNRecord> znRecords = _propertyStore.get(Collections.singletonList(_segmentZKMetadataPathPrefix + segment), null, AccessOption.PERSISTENT, true);\n+    Interval range = extractTimeRangeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(0));\n+    _segmentToTimeRangeMSCache.put(segment, range);\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(_segmentToTimeRangeMSCache);\n+  }\n+\n+  /**\n+   * NOTE: Pruning is done by searching _timeRangeToSegmentSearchTree based on request time range and check if the results\n+   *       are in the input segments. By doing so we will have run time O(M * logN) (N is the # of all online segments,\n+   *       M is the # of qualified intersected segments).\n+   */\n+  @Override\n+  public Set<String> prune(BrokerRequest brokerRequest, Set<String> segments) {\n+    // The pruned order may be different from the input order\n+    if (_timeRangeMSToSegmentSearchTree == null) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzI2OTc4MA=="}, "originalCommit": {"oid": "f1adcfac676a45b45421f5ba6eab4ee6b1853555"}, "originalPosition": 157}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNjAyMzk5OnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzoyNToyN1rOH22Fbg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzoyNToyN1rOH22Fbg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzI3MTI3OA==", "bodyText": "Put these comments as the javadoc for this method", "url": "https://github.com/apache/pinot/pull/6259#discussion_r527271278", "createdAt": "2020-11-19T23:25:27Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.math.BigDecimal;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final TimeUnit _timeUnit;\n+\n+  private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n+  private final Map _segmentToTimeRangeMSCache;\n+\n+  public TimeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    DateTimeFormatSpec formatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    _timeUnit = formatSpec.getColumnUnit();\n+    Preconditions\n+        .checkNotNull(_timeUnit, \"Time unit must be configured in the field spec for time column: %s of table: %s\",\n+            _timeColumn, _tableNameWithType);\n+    _segmentToTimeRangeMSCache = new HashMap<String, Interval>();\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    onExternalViewChange(externalView, idealState, onlineSegments);\n+  }\n+\n+  @Override\n+  synchronized public void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    List<String> newSegments = new ArrayList<>();\n+    for (String onlineSegment : onlineSegments) {\n+      if (!_segmentToTimeRangeMSCache.containsKey(onlineSegment)) {\n+        newSegments.add(onlineSegment);\n+      }\n+    }\n+\n+    List<String> newSegmentZKMetadataPaths = new ArrayList<>();\n+    for (String segment: newSegments) {\n+      newSegmentZKMetadataPaths.add(_segmentZKMetadataPathPrefix + segment);\n+    }\n+\n+    List<ZNRecord> znRecords = _propertyStore.get(newSegmentZKMetadataPaths, null, AccessOption.PERSISTENT, true);\n+\n+    for (int i = 0; i < newSegments.size(); i++) {\n+      String segment = newSegments.get(i);\n+      Interval range = extractTimeRangeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(i));\n+      _segmentToTimeRangeMSCache.put(segment, range);\n+    }\n+    _segmentToTimeRangeMSCache.keySet().retainAll(onlineSegments);\n+    // atomic swap _timeRangeToSegmentMap for input online segments\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(_segmentToTimeRangeMSCache);\n+  }\n+\n+  private Interval extractTimeRangeMSFromSegmentZKMetaZNRecord(String segment, @Nullable ZNRecord znRecord) {\n+    Interval defaultRange = new Interval(MIN_START_TIME, MAX_END_TIME);\n+    // Segments without metadata or with invalid time range will be set with [min_start, max_end] and will not be pruned\n+    if (znRecord == null) {\n+      LOGGER.warn(\"Failed to find segment ZK metadata for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return defaultRange;\n+    }\n+\n+    long startTime = znRecord.getLongField(CommonConstants.Segment.START_TIME, -1);\n+    long endTime = znRecord.getLongField(CommonConstants.Segment.END_TIME, -1);\n+    if (startTime < 0 || endTime < 0 || startTime > endTime) {\n+      LOGGER.warn(\"Failed to find valid end time for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return defaultRange;\n+    }\n+\n+    TimeUnit timeUnit = znRecord.getEnumField(CommonConstants.Segment.TIME_UNIT, TimeUnit.class, TimeUnit.DAYS);\n+    return new Interval(timeUnit.toMillis(startTime), timeUnit.toMillis(endTime));\n+  }\n+\n+  @Override\n+  synchronized public void refreshSegment(String segment) {\n+    List<ZNRecord> znRecords = _propertyStore.get(Collections.singletonList(_segmentZKMetadataPathPrefix + segment), null, AccessOption.PERSISTENT, true);\n+    Interval range = extractTimeRangeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(0));\n+    _segmentToTimeRangeMSCache.put(segment, range);\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(_segmentToTimeRangeMSCache);\n+  }\n+\n+  /**\n+   * NOTE: Pruning is done by searching _timeRangeToSegmentSearchTree based on request time range and check if the results\n+   *       are in the input segments. By doing so we will have run time O(M * logN) (N is the # of all online segments,\n+   *       M is the # of qualified intersected segments).\n+   */\n+  @Override\n+  public Set<String> prune(BrokerRequest brokerRequest, Set<String> segments) {\n+    // The pruned order may be different from the input order\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      return segments;\n+    }\n+    FilterQueryTree filterQueryTree = RequestUtils.generateFilterQueryTree(brokerRequest);\n+    if (filterQueryTree == null) {\n+      return segments;\n+    }\n+    List<Interval> ranges = getFilterTimeRange(filterQueryTree);\n+    if (ranges == null) { // cannot prune based on time for input request\n+      return segments;\n+    }\n+    if (ranges.size() == 0) { // invalid query time range\n+      return Collections.emptySet();\n+    }\n+\n+    Set<String> selectedSegments = new HashSet<>();\n+    for (Interval range : ranges) {\n+      Interval rangeMS = convertRangeToMS(range);\n+      for (Object segment : _timeRangeMSToSegmentSearchTree.searchAll(rangeMS)) {\n+        if (segments.contains(segment)) {\n+          selectedSegments.add((String) segment);\n+        }\n+      }\n+    }\n+    return selectedSegments;\n+  }\n+\n+  private List<Interval> getFilterTimeRange(FilterQueryTree filterQueryTree) {\n+    // return NUll if no time range info or cannot filter base on the info (e.g. 'SELECT * from myTable where time < 50 OR firstName = Jason')", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1adcfac676a45b45421f5ba6eab4ee6b1853555"}, "originalPosition": 185}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNjAyNDUyOnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzoyNTozOFrOH22FuA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzoyNTozOFrOH22FuA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzI3MTM1Mg==", "bodyText": "Annotate the return as nullable", "url": "https://github.com/apache/pinot/pull/6259#discussion_r527271352", "createdAt": "2020-11-19T23:25:38Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.math.BigDecimal;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final TimeUnit _timeUnit;\n+\n+  private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n+  private final Map _segmentToTimeRangeMSCache;\n+\n+  public TimeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    DateTimeFormatSpec formatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    _timeUnit = formatSpec.getColumnUnit();\n+    Preconditions\n+        .checkNotNull(_timeUnit, \"Time unit must be configured in the field spec for time column: %s of table: %s\",\n+            _timeColumn, _tableNameWithType);\n+    _segmentToTimeRangeMSCache = new HashMap<String, Interval>();\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    onExternalViewChange(externalView, idealState, onlineSegments);\n+  }\n+\n+  @Override\n+  synchronized public void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    List<String> newSegments = new ArrayList<>();\n+    for (String onlineSegment : onlineSegments) {\n+      if (!_segmentToTimeRangeMSCache.containsKey(onlineSegment)) {\n+        newSegments.add(onlineSegment);\n+      }\n+    }\n+\n+    List<String> newSegmentZKMetadataPaths = new ArrayList<>();\n+    for (String segment: newSegments) {\n+      newSegmentZKMetadataPaths.add(_segmentZKMetadataPathPrefix + segment);\n+    }\n+\n+    List<ZNRecord> znRecords = _propertyStore.get(newSegmentZKMetadataPaths, null, AccessOption.PERSISTENT, true);\n+\n+    for (int i = 0; i < newSegments.size(); i++) {\n+      String segment = newSegments.get(i);\n+      Interval range = extractTimeRangeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(i));\n+      _segmentToTimeRangeMSCache.put(segment, range);\n+    }\n+    _segmentToTimeRangeMSCache.keySet().retainAll(onlineSegments);\n+    // atomic swap _timeRangeToSegmentMap for input online segments\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(_segmentToTimeRangeMSCache);\n+  }\n+\n+  private Interval extractTimeRangeMSFromSegmentZKMetaZNRecord(String segment, @Nullable ZNRecord znRecord) {\n+    Interval defaultRange = new Interval(MIN_START_TIME, MAX_END_TIME);\n+    // Segments without metadata or with invalid time range will be set with [min_start, max_end] and will not be pruned\n+    if (znRecord == null) {\n+      LOGGER.warn(\"Failed to find segment ZK metadata for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return defaultRange;\n+    }\n+\n+    long startTime = znRecord.getLongField(CommonConstants.Segment.START_TIME, -1);\n+    long endTime = znRecord.getLongField(CommonConstants.Segment.END_TIME, -1);\n+    if (startTime < 0 || endTime < 0 || startTime > endTime) {\n+      LOGGER.warn(\"Failed to find valid end time for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return defaultRange;\n+    }\n+\n+    TimeUnit timeUnit = znRecord.getEnumField(CommonConstants.Segment.TIME_UNIT, TimeUnit.class, TimeUnit.DAYS);\n+    return new Interval(timeUnit.toMillis(startTime), timeUnit.toMillis(endTime));\n+  }\n+\n+  @Override\n+  synchronized public void refreshSegment(String segment) {\n+    List<ZNRecord> znRecords = _propertyStore.get(Collections.singletonList(_segmentZKMetadataPathPrefix + segment), null, AccessOption.PERSISTENT, true);\n+    Interval range = extractTimeRangeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(0));\n+    _segmentToTimeRangeMSCache.put(segment, range);\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(_segmentToTimeRangeMSCache);\n+  }\n+\n+  /**\n+   * NOTE: Pruning is done by searching _timeRangeToSegmentSearchTree based on request time range and check if the results\n+   *       are in the input segments. By doing so we will have run time O(M * logN) (N is the # of all online segments,\n+   *       M is the # of qualified intersected segments).\n+   */\n+  @Override\n+  public Set<String> prune(BrokerRequest brokerRequest, Set<String> segments) {\n+    // The pruned order may be different from the input order\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      return segments;\n+    }\n+    FilterQueryTree filterQueryTree = RequestUtils.generateFilterQueryTree(brokerRequest);\n+    if (filterQueryTree == null) {\n+      return segments;\n+    }\n+    List<Interval> ranges = getFilterTimeRange(filterQueryTree);\n+    if (ranges == null) { // cannot prune based on time for input request\n+      return segments;\n+    }\n+    if (ranges.size() == 0) { // invalid query time range\n+      return Collections.emptySet();\n+    }\n+\n+    Set<String> selectedSegments = new HashSet<>();\n+    for (Interval range : ranges) {\n+      Interval rangeMS = convertRangeToMS(range);\n+      for (Object segment : _timeRangeMSToSegmentSearchTree.searchAll(rangeMS)) {\n+        if (segments.contains(segment)) {\n+          selectedSegments.add((String) segment);\n+        }\n+      }\n+    }\n+    return selectedSegments;\n+  }\n+\n+  private List<Interval> getFilterTimeRange(FilterQueryTree filterQueryTree) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1adcfac676a45b45421f5ba6eab4ee6b1853555"}, "originalPosition": 184}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNjAyNTU0OnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzoyNjowNVrOH22GVw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzoyNjowNVrOH22GVw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzI3MTUxMQ==", "bodyText": "(nit)\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                if (ranges.size() == 0) { // invalid query time range\n          \n          \n            \n                if (ranges.isEmpty()) { // invalid query time range", "url": "https://github.com/apache/pinot/pull/6259#discussion_r527271511", "createdAt": "2020-11-19T23:26:05Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.math.BigDecimal;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final TimeUnit _timeUnit;\n+\n+  private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n+  private final Map _segmentToTimeRangeMSCache;\n+\n+  public TimeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    DateTimeFormatSpec formatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    _timeUnit = formatSpec.getColumnUnit();\n+    Preconditions\n+        .checkNotNull(_timeUnit, \"Time unit must be configured in the field spec for time column: %s of table: %s\",\n+            _timeColumn, _tableNameWithType);\n+    _segmentToTimeRangeMSCache = new HashMap<String, Interval>();\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    onExternalViewChange(externalView, idealState, onlineSegments);\n+  }\n+\n+  @Override\n+  synchronized public void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    List<String> newSegments = new ArrayList<>();\n+    for (String onlineSegment : onlineSegments) {\n+      if (!_segmentToTimeRangeMSCache.containsKey(onlineSegment)) {\n+        newSegments.add(onlineSegment);\n+      }\n+    }\n+\n+    List<String> newSegmentZKMetadataPaths = new ArrayList<>();\n+    for (String segment: newSegments) {\n+      newSegmentZKMetadataPaths.add(_segmentZKMetadataPathPrefix + segment);\n+    }\n+\n+    List<ZNRecord> znRecords = _propertyStore.get(newSegmentZKMetadataPaths, null, AccessOption.PERSISTENT, true);\n+\n+    for (int i = 0; i < newSegments.size(); i++) {\n+      String segment = newSegments.get(i);\n+      Interval range = extractTimeRangeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(i));\n+      _segmentToTimeRangeMSCache.put(segment, range);\n+    }\n+    _segmentToTimeRangeMSCache.keySet().retainAll(onlineSegments);\n+    // atomic swap _timeRangeToSegmentMap for input online segments\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(_segmentToTimeRangeMSCache);\n+  }\n+\n+  private Interval extractTimeRangeMSFromSegmentZKMetaZNRecord(String segment, @Nullable ZNRecord znRecord) {\n+    Interval defaultRange = new Interval(MIN_START_TIME, MAX_END_TIME);\n+    // Segments without metadata or with invalid time range will be set with [min_start, max_end] and will not be pruned\n+    if (znRecord == null) {\n+      LOGGER.warn(\"Failed to find segment ZK metadata for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return defaultRange;\n+    }\n+\n+    long startTime = znRecord.getLongField(CommonConstants.Segment.START_TIME, -1);\n+    long endTime = znRecord.getLongField(CommonConstants.Segment.END_TIME, -1);\n+    if (startTime < 0 || endTime < 0 || startTime > endTime) {\n+      LOGGER.warn(\"Failed to find valid end time for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return defaultRange;\n+    }\n+\n+    TimeUnit timeUnit = znRecord.getEnumField(CommonConstants.Segment.TIME_UNIT, TimeUnit.class, TimeUnit.DAYS);\n+    return new Interval(timeUnit.toMillis(startTime), timeUnit.toMillis(endTime));\n+  }\n+\n+  @Override\n+  synchronized public void refreshSegment(String segment) {\n+    List<ZNRecord> znRecords = _propertyStore.get(Collections.singletonList(_segmentZKMetadataPathPrefix + segment), null, AccessOption.PERSISTENT, true);\n+    Interval range = extractTimeRangeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(0));\n+    _segmentToTimeRangeMSCache.put(segment, range);\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(_segmentToTimeRangeMSCache);\n+  }\n+\n+  /**\n+   * NOTE: Pruning is done by searching _timeRangeToSegmentSearchTree based on request time range and check if the results\n+   *       are in the input segments. By doing so we will have run time O(M * logN) (N is the # of all online segments,\n+   *       M is the # of qualified intersected segments).\n+   */\n+  @Override\n+  public Set<String> prune(BrokerRequest brokerRequest, Set<String> segments) {\n+    // The pruned order may be different from the input order\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      return segments;\n+    }\n+    FilterQueryTree filterQueryTree = RequestUtils.generateFilterQueryTree(brokerRequest);\n+    if (filterQueryTree == null) {\n+      return segments;\n+    }\n+    List<Interval> ranges = getFilterTimeRange(filterQueryTree);\n+    if (ranges == null) { // cannot prune based on time for input request\n+      return segments;\n+    }\n+    if (ranges.size() == 0) { // invalid query time range", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1adcfac676a45b45421f5ba6eab4ee6b1853555"}, "originalPosition": 168}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNjAzMjEwOnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzoyODo1M1rOH22KUA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzoyODo1M1rOH22KUA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzI3MjUyOA==", "bodyText": "We usually use Ms instead of MS. Also, suggest simplifying the name as extractIntervalFromSegmentZKMetadataZNRecord", "url": "https://github.com/apache/pinot/pull/6259#discussion_r527272528", "createdAt": "2020-11-19T23:28:53Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.math.BigDecimal;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final TimeUnit _timeUnit;\n+\n+  private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n+  private final Map _segmentToTimeRangeMSCache;\n+\n+  public TimeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    DateTimeFormatSpec formatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    _timeUnit = formatSpec.getColumnUnit();\n+    Preconditions\n+        .checkNotNull(_timeUnit, \"Time unit must be configured in the field spec for time column: %s of table: %s\",\n+            _timeColumn, _tableNameWithType);\n+    _segmentToTimeRangeMSCache = new HashMap<String, Interval>();\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    onExternalViewChange(externalView, idealState, onlineSegments);\n+  }\n+\n+  @Override\n+  synchronized public void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    List<String> newSegments = new ArrayList<>();\n+    for (String onlineSegment : onlineSegments) {\n+      if (!_segmentToTimeRangeMSCache.containsKey(onlineSegment)) {\n+        newSegments.add(onlineSegment);\n+      }\n+    }\n+\n+    List<String> newSegmentZKMetadataPaths = new ArrayList<>();\n+    for (String segment: newSegments) {\n+      newSegmentZKMetadataPaths.add(_segmentZKMetadataPathPrefix + segment);\n+    }\n+\n+    List<ZNRecord> znRecords = _propertyStore.get(newSegmentZKMetadataPaths, null, AccessOption.PERSISTENT, true);\n+\n+    for (int i = 0; i < newSegments.size(); i++) {\n+      String segment = newSegments.get(i);\n+      Interval range = extractTimeRangeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(i));\n+      _segmentToTimeRangeMSCache.put(segment, range);\n+    }\n+    _segmentToTimeRangeMSCache.keySet().retainAll(onlineSegments);\n+    // atomic swap _timeRangeToSegmentMap for input online segments\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(_segmentToTimeRangeMSCache);\n+  }\n+\n+  private Interval extractTimeRangeMSFromSegmentZKMetaZNRecord(String segment, @Nullable ZNRecord znRecord) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1adcfac676a45b45421f5ba6eab4ee6b1853555"}, "originalPosition": 122}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNjAzNTkxOnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzozMDoyMFrOH22MkQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzozMDoyMFrOH22MkQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzI3MzEwNQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              private final ZkHelixPropertyStore _propertyStore;\n          \n          \n            \n              private final ZkHelixPropertyStore<ZNRecord> _propertyStore;", "url": "https://github.com/apache/pinot/pull/6259#discussion_r527273105", "createdAt": "2020-11-19T23:30:20Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.math.BigDecimal;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1adcfac676a45b45421f5ba6eab4ee6b1853555"}, "originalPosition": 62}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNjA0MzE2OnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzozMzo0MFrOH22Q9A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzozMzo0MFrOH22Q9A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzI3NDIyOA==", "bodyText": "Keeping _timeUnit is not enough, you need to keep the formatSpec in order to handle the simple data format (e.g. \"2020-11-19\")", "url": "https://github.com/apache/pinot/pull/6259#discussion_r527274228", "createdAt": "2020-11-19T23:33:40Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.math.BigDecimal;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final TimeUnit _timeUnit;\n+\n+  private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n+  private final Map _segmentToTimeRangeMSCache;\n+\n+  public TimeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    DateTimeFormatSpec formatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    _timeUnit = formatSpec.getColumnUnit();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1adcfac676a45b45421f5ba6eab4ee6b1853555"}, "originalPosition": 84}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNjA1MzEyOnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzozNzo1M1rOH22Wwg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzozNzo1M1rOH22Wwg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzI3NTcxNA==", "bodyText": "the time value in the query might not be numeric for simple date format", "url": "https://github.com/apache/pinot/pull/6259#discussion_r527275714", "createdAt": "2020-11-19T23:37:53Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.math.BigDecimal;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final TimeUnit _timeUnit;\n+\n+  private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n+  private final Map _segmentToTimeRangeMSCache;\n+\n+  public TimeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    DateTimeFormatSpec formatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    _timeUnit = formatSpec.getColumnUnit();\n+    Preconditions\n+        .checkNotNull(_timeUnit, \"Time unit must be configured in the field spec for time column: %s of table: %s\",\n+            _timeColumn, _tableNameWithType);\n+    _segmentToTimeRangeMSCache = new HashMap<String, Interval>();\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    onExternalViewChange(externalView, idealState, onlineSegments);\n+  }\n+\n+  @Override\n+  synchronized public void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    List<String> newSegments = new ArrayList<>();\n+    for (String onlineSegment : onlineSegments) {\n+      if (!_segmentToTimeRangeMSCache.containsKey(onlineSegment)) {\n+        newSegments.add(onlineSegment);\n+      }\n+    }\n+\n+    List<String> newSegmentZKMetadataPaths = new ArrayList<>();\n+    for (String segment: newSegments) {\n+      newSegmentZKMetadataPaths.add(_segmentZKMetadataPathPrefix + segment);\n+    }\n+\n+    List<ZNRecord> znRecords = _propertyStore.get(newSegmentZKMetadataPaths, null, AccessOption.PERSISTENT, true);\n+\n+    for (int i = 0; i < newSegments.size(); i++) {\n+      String segment = newSegments.get(i);\n+      Interval range = extractTimeRangeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(i));\n+      _segmentToTimeRangeMSCache.put(segment, range);\n+    }\n+    _segmentToTimeRangeMSCache.keySet().retainAll(onlineSegments);\n+    // atomic swap _timeRangeToSegmentMap for input online segments\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(_segmentToTimeRangeMSCache);\n+  }\n+\n+  private Interval extractTimeRangeMSFromSegmentZKMetaZNRecord(String segment, @Nullable ZNRecord znRecord) {\n+    Interval defaultRange = new Interval(MIN_START_TIME, MAX_END_TIME);\n+    // Segments without metadata or with invalid time range will be set with [min_start, max_end] and will not be pruned\n+    if (znRecord == null) {\n+      LOGGER.warn(\"Failed to find segment ZK metadata for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return defaultRange;\n+    }\n+\n+    long startTime = znRecord.getLongField(CommonConstants.Segment.START_TIME, -1);\n+    long endTime = znRecord.getLongField(CommonConstants.Segment.END_TIME, -1);\n+    if (startTime < 0 || endTime < 0 || startTime > endTime) {\n+      LOGGER.warn(\"Failed to find valid end time for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return defaultRange;\n+    }\n+\n+    TimeUnit timeUnit = znRecord.getEnumField(CommonConstants.Segment.TIME_UNIT, TimeUnit.class, TimeUnit.DAYS);\n+    return new Interval(timeUnit.toMillis(startTime), timeUnit.toMillis(endTime));\n+  }\n+\n+  @Override\n+  synchronized public void refreshSegment(String segment) {\n+    List<ZNRecord> znRecords = _propertyStore.get(Collections.singletonList(_segmentZKMetadataPathPrefix + segment), null, AccessOption.PERSISTENT, true);\n+    Interval range = extractTimeRangeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(0));\n+    _segmentToTimeRangeMSCache.put(segment, range);\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(_segmentToTimeRangeMSCache);\n+  }\n+\n+  /**\n+   * NOTE: Pruning is done by searching _timeRangeToSegmentSearchTree based on request time range and check if the results\n+   *       are in the input segments. By doing so we will have run time O(M * logN) (N is the # of all online segments,\n+   *       M is the # of qualified intersected segments).\n+   */\n+  @Override\n+  public Set<String> prune(BrokerRequest brokerRequest, Set<String> segments) {\n+    // The pruned order may be different from the input order\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      return segments;\n+    }\n+    FilterQueryTree filterQueryTree = RequestUtils.generateFilterQueryTree(brokerRequest);\n+    if (filterQueryTree == null) {\n+      return segments;\n+    }\n+    List<Interval> ranges = getFilterTimeRange(filterQueryTree);\n+    if (ranges == null) { // cannot prune based on time for input request\n+      return segments;\n+    }\n+    if (ranges.size() == 0) { // invalid query time range\n+      return Collections.emptySet();\n+    }\n+\n+    Set<String> selectedSegments = new HashSet<>();\n+    for (Interval range : ranges) {\n+      Interval rangeMS = convertRangeToMS(range);\n+      for (Object segment : _timeRangeMSToSegmentSearchTree.searchAll(rangeMS)) {\n+        if (segments.contains(segment)) {\n+          selectedSegments.add((String) segment);\n+        }\n+      }\n+    }\n+    return selectedSegments;\n+  }\n+\n+  private List<Interval> getFilterTimeRange(FilterQueryTree filterQueryTree) {\n+    // return NUll if no time range info or cannot filter base on the info (e.g. 'SELECT * from myTable where time < 50 OR firstName = Jason')\n+    // return an empty list if filtering range is specified but invalid (e.g. 'SELECT * from myTable where time < 50 AND time > 100')\n+    switch (filterQueryTree.getOperator()) {\n+      case AND:\n+        List<List<Interval>> andRanges = new ArrayList<>();\n+        for (FilterQueryTree child : filterQueryTree.getChildren()) {\n+          List<Interval> childRanges = getFilterTimeRange(child);\n+          if (childRanges != null) {\n+            andRanges.add(childRanges);\n+          }\n+        }\n+        return getIntersectionSortedRanges(andRanges);\n+      case OR:\n+        List<List<Interval>> orRanges = new ArrayList<>();\n+        for (FilterQueryTree child : filterQueryTree.getChildren()) {\n+          List<Interval> childRanges = getFilterTimeRange(child);\n+          if (childRanges == null) {\n+            return null;\n+          } else {\n+            orRanges.add(childRanges);\n+          }\n+        }\n+        return getUnionSortedRanges(orRanges);\n+      case EQUALITY:\n+        if (filterQueryTree.getColumn().equals(_timeColumn)) {\n+          long timeStamp = Long.parseLong(filterQueryTree.getValue().get(0));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1adcfac676a45b45421f5ba6eab4ee6b1853555"}, "originalPosition": 210}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNjA1NTAwOnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzozODo0OFrOH22X7Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzozODo0OFrOH22X7Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzI3NjAxMw==", "bodyText": "Always use timestamp (in millis) for interval for both SDF handling and clarity", "url": "https://github.com/apache/pinot/pull/6259#discussion_r527276013", "createdAt": "2020-11-19T23:38:48Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.math.BigDecimal;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final TimeUnit _timeUnit;\n+\n+  private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n+  private final Map _segmentToTimeRangeMSCache;\n+\n+  public TimeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    DateTimeFormatSpec formatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    _timeUnit = formatSpec.getColumnUnit();\n+    Preconditions\n+        .checkNotNull(_timeUnit, \"Time unit must be configured in the field spec for time column: %s of table: %s\",\n+            _timeColumn, _tableNameWithType);\n+    _segmentToTimeRangeMSCache = new HashMap<String, Interval>();\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    onExternalViewChange(externalView, idealState, onlineSegments);\n+  }\n+\n+  @Override\n+  synchronized public void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    List<String> newSegments = new ArrayList<>();\n+    for (String onlineSegment : onlineSegments) {\n+      if (!_segmentToTimeRangeMSCache.containsKey(onlineSegment)) {\n+        newSegments.add(onlineSegment);\n+      }\n+    }\n+\n+    List<String> newSegmentZKMetadataPaths = new ArrayList<>();\n+    for (String segment: newSegments) {\n+      newSegmentZKMetadataPaths.add(_segmentZKMetadataPathPrefix + segment);\n+    }\n+\n+    List<ZNRecord> znRecords = _propertyStore.get(newSegmentZKMetadataPaths, null, AccessOption.PERSISTENT, true);\n+\n+    for (int i = 0; i < newSegments.size(); i++) {\n+      String segment = newSegments.get(i);\n+      Interval range = extractTimeRangeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(i));\n+      _segmentToTimeRangeMSCache.put(segment, range);\n+    }\n+    _segmentToTimeRangeMSCache.keySet().retainAll(onlineSegments);\n+    // atomic swap _timeRangeToSegmentMap for input online segments\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(_segmentToTimeRangeMSCache);\n+  }\n+\n+  private Interval extractTimeRangeMSFromSegmentZKMetaZNRecord(String segment, @Nullable ZNRecord znRecord) {\n+    Interval defaultRange = new Interval(MIN_START_TIME, MAX_END_TIME);\n+    // Segments without metadata or with invalid time range will be set with [min_start, max_end] and will not be pruned\n+    if (znRecord == null) {\n+      LOGGER.warn(\"Failed to find segment ZK metadata for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return defaultRange;\n+    }\n+\n+    long startTime = znRecord.getLongField(CommonConstants.Segment.START_TIME, -1);\n+    long endTime = znRecord.getLongField(CommonConstants.Segment.END_TIME, -1);\n+    if (startTime < 0 || endTime < 0 || startTime > endTime) {\n+      LOGGER.warn(\"Failed to find valid end time for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return defaultRange;\n+    }\n+\n+    TimeUnit timeUnit = znRecord.getEnumField(CommonConstants.Segment.TIME_UNIT, TimeUnit.class, TimeUnit.DAYS);\n+    return new Interval(timeUnit.toMillis(startTime), timeUnit.toMillis(endTime));\n+  }\n+\n+  @Override\n+  synchronized public void refreshSegment(String segment) {\n+    List<ZNRecord> znRecords = _propertyStore.get(Collections.singletonList(_segmentZKMetadataPathPrefix + segment), null, AccessOption.PERSISTENT, true);\n+    Interval range = extractTimeRangeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(0));\n+    _segmentToTimeRangeMSCache.put(segment, range);\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(_segmentToTimeRangeMSCache);\n+  }\n+\n+  /**\n+   * NOTE: Pruning is done by searching _timeRangeToSegmentSearchTree based on request time range and check if the results\n+   *       are in the input segments. By doing so we will have run time O(M * logN) (N is the # of all online segments,\n+   *       M is the # of qualified intersected segments).\n+   */\n+  @Override\n+  public Set<String> prune(BrokerRequest brokerRequest, Set<String> segments) {\n+    // The pruned order may be different from the input order\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      return segments;\n+    }\n+    FilterQueryTree filterQueryTree = RequestUtils.generateFilterQueryTree(brokerRequest);\n+    if (filterQueryTree == null) {\n+      return segments;\n+    }\n+    List<Interval> ranges = getFilterTimeRange(filterQueryTree);\n+    if (ranges == null) { // cannot prune based on time for input request\n+      return segments;\n+    }\n+    if (ranges.size() == 0) { // invalid query time range\n+      return Collections.emptySet();\n+    }\n+\n+    Set<String> selectedSegments = new HashSet<>();\n+    for (Interval range : ranges) {\n+      Interval rangeMS = convertRangeToMS(range);\n+      for (Object segment : _timeRangeMSToSegmentSearchTree.searchAll(rangeMS)) {\n+        if (segments.contains(segment)) {\n+          selectedSegments.add((String) segment);\n+        }\n+      }\n+    }\n+    return selectedSegments;\n+  }\n+\n+  private List<Interval> getFilterTimeRange(FilterQueryTree filterQueryTree) {\n+    // return NUll if no time range info or cannot filter base on the info (e.g. 'SELECT * from myTable where time < 50 OR firstName = Jason')\n+    // return an empty list if filtering range is specified but invalid (e.g. 'SELECT * from myTable where time < 50 AND time > 100')\n+    switch (filterQueryTree.getOperator()) {\n+      case AND:\n+        List<List<Interval>> andRanges = new ArrayList<>();\n+        for (FilterQueryTree child : filterQueryTree.getChildren()) {\n+          List<Interval> childRanges = getFilterTimeRange(child);\n+          if (childRanges != null) {\n+            andRanges.add(childRanges);\n+          }\n+        }\n+        return getIntersectionSortedRanges(andRanges);\n+      case OR:\n+        List<List<Interval>> orRanges = new ArrayList<>();\n+        for (FilterQueryTree child : filterQueryTree.getChildren()) {\n+          List<Interval> childRanges = getFilterTimeRange(child);\n+          if (childRanges == null) {\n+            return null;\n+          } else {\n+            orRanges.add(childRanges);\n+          }\n+        }\n+        return getUnionSortedRanges(orRanges);\n+      case EQUALITY:\n+        if (filterQueryTree.getColumn().equals(_timeColumn)) {\n+          long timeStamp = Long.parseLong(filterQueryTree.getValue().get(0));\n+          return Collections.singletonList(new Interval(timeStamp, timeStamp));\n+        }\n+        return null;\n+      case RANGE:\n+        if (filterQueryTree.getColumn().equals(_timeColumn)) {\n+          return parseRange(filterQueryTree.getValue());\n+        }\n+        return null;\n+      default:\n+        return null;\n+    }\n+  }\n+\n+  private Interval convertRangeToMS(Interval range) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1adcfac676a45b45421f5ba6eab4ee6b1853555"}, "originalPosition": 224}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNjA2OTIzOnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzo0NDo0NFrOH22gPg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzo0NDo0NFrOH22gPg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzI3ODE0Mg==", "bodyText": "Should never reach here (or getIntersectionOfTwoSortedRanges() will throw NPE). Same for union", "url": "https://github.com/apache/pinot/pull/6259#discussion_r527278142", "createdAt": "2020-11-19T23:44:44Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.math.BigDecimal;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final TimeUnit _timeUnit;\n+\n+  private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n+  private final Map _segmentToTimeRangeMSCache;\n+\n+  public TimeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    DateTimeFormatSpec formatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    _timeUnit = formatSpec.getColumnUnit();\n+    Preconditions\n+        .checkNotNull(_timeUnit, \"Time unit must be configured in the field spec for time column: %s of table: %s\",\n+            _timeColumn, _tableNameWithType);\n+    _segmentToTimeRangeMSCache = new HashMap<String, Interval>();\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    onExternalViewChange(externalView, idealState, onlineSegments);\n+  }\n+\n+  @Override\n+  synchronized public void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    List<String> newSegments = new ArrayList<>();\n+    for (String onlineSegment : onlineSegments) {\n+      if (!_segmentToTimeRangeMSCache.containsKey(onlineSegment)) {\n+        newSegments.add(onlineSegment);\n+      }\n+    }\n+\n+    List<String> newSegmentZKMetadataPaths = new ArrayList<>();\n+    for (String segment: newSegments) {\n+      newSegmentZKMetadataPaths.add(_segmentZKMetadataPathPrefix + segment);\n+    }\n+\n+    List<ZNRecord> znRecords = _propertyStore.get(newSegmentZKMetadataPaths, null, AccessOption.PERSISTENT, true);\n+\n+    for (int i = 0; i < newSegments.size(); i++) {\n+      String segment = newSegments.get(i);\n+      Interval range = extractTimeRangeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(i));\n+      _segmentToTimeRangeMSCache.put(segment, range);\n+    }\n+    _segmentToTimeRangeMSCache.keySet().retainAll(onlineSegments);\n+    // atomic swap _timeRangeToSegmentMap for input online segments\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(_segmentToTimeRangeMSCache);\n+  }\n+\n+  private Interval extractTimeRangeMSFromSegmentZKMetaZNRecord(String segment, @Nullable ZNRecord znRecord) {\n+    Interval defaultRange = new Interval(MIN_START_TIME, MAX_END_TIME);\n+    // Segments without metadata or with invalid time range will be set with [min_start, max_end] and will not be pruned\n+    if (znRecord == null) {\n+      LOGGER.warn(\"Failed to find segment ZK metadata for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return defaultRange;\n+    }\n+\n+    long startTime = znRecord.getLongField(CommonConstants.Segment.START_TIME, -1);\n+    long endTime = znRecord.getLongField(CommonConstants.Segment.END_TIME, -1);\n+    if (startTime < 0 || endTime < 0 || startTime > endTime) {\n+      LOGGER.warn(\"Failed to find valid end time for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return defaultRange;\n+    }\n+\n+    TimeUnit timeUnit = znRecord.getEnumField(CommonConstants.Segment.TIME_UNIT, TimeUnit.class, TimeUnit.DAYS);\n+    return new Interval(timeUnit.toMillis(startTime), timeUnit.toMillis(endTime));\n+  }\n+\n+  @Override\n+  synchronized public void refreshSegment(String segment) {\n+    List<ZNRecord> znRecords = _propertyStore.get(Collections.singletonList(_segmentZKMetadataPathPrefix + segment), null, AccessOption.PERSISTENT, true);\n+    Interval range = extractTimeRangeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(0));\n+    _segmentToTimeRangeMSCache.put(segment, range);\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(_segmentToTimeRangeMSCache);\n+  }\n+\n+  /**\n+   * NOTE: Pruning is done by searching _timeRangeToSegmentSearchTree based on request time range and check if the results\n+   *       are in the input segments. By doing so we will have run time O(M * logN) (N is the # of all online segments,\n+   *       M is the # of qualified intersected segments).\n+   */\n+  @Override\n+  public Set<String> prune(BrokerRequest brokerRequest, Set<String> segments) {\n+    // The pruned order may be different from the input order\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      return segments;\n+    }\n+    FilterQueryTree filterQueryTree = RequestUtils.generateFilterQueryTree(brokerRequest);\n+    if (filterQueryTree == null) {\n+      return segments;\n+    }\n+    List<Interval> ranges = getFilterTimeRange(filterQueryTree);\n+    if (ranges == null) { // cannot prune based on time for input request\n+      return segments;\n+    }\n+    if (ranges.size() == 0) { // invalid query time range\n+      return Collections.emptySet();\n+    }\n+\n+    Set<String> selectedSegments = new HashSet<>();\n+    for (Interval range : ranges) {\n+      Interval rangeMS = convertRangeToMS(range);\n+      for (Object segment : _timeRangeMSToSegmentSearchTree.searchAll(rangeMS)) {\n+        if (segments.contains(segment)) {\n+          selectedSegments.add((String) segment);\n+        }\n+      }\n+    }\n+    return selectedSegments;\n+  }\n+\n+  private List<Interval> getFilterTimeRange(FilterQueryTree filterQueryTree) {\n+    // return NUll if no time range info or cannot filter base on the info (e.g. 'SELECT * from myTable where time < 50 OR firstName = Jason')\n+    // return an empty list if filtering range is specified but invalid (e.g. 'SELECT * from myTable where time < 50 AND time > 100')\n+    switch (filterQueryTree.getOperator()) {\n+      case AND:\n+        List<List<Interval>> andRanges = new ArrayList<>();\n+        for (FilterQueryTree child : filterQueryTree.getChildren()) {\n+          List<Interval> childRanges = getFilterTimeRange(child);\n+          if (childRanges != null) {\n+            andRanges.add(childRanges);\n+          }\n+        }\n+        return getIntersectionSortedRanges(andRanges);\n+      case OR:\n+        List<List<Interval>> orRanges = new ArrayList<>();\n+        for (FilterQueryTree child : filterQueryTree.getChildren()) {\n+          List<Interval> childRanges = getFilterTimeRange(child);\n+          if (childRanges == null) {\n+            return null;\n+          } else {\n+            orRanges.add(childRanges);\n+          }\n+        }\n+        return getUnionSortedRanges(orRanges);\n+      case EQUALITY:\n+        if (filterQueryTree.getColumn().equals(_timeColumn)) {\n+          long timeStamp = Long.parseLong(filterQueryTree.getValue().get(0));\n+          return Collections.singletonList(new Interval(timeStamp, timeStamp));\n+        }\n+        return null;\n+      case RANGE:\n+        if (filterQueryTree.getColumn().equals(_timeColumn)) {\n+          return parseRange(filterQueryTree.getValue());\n+        }\n+        return null;\n+      default:\n+        return null;\n+    }\n+  }\n+\n+  private Interval convertRangeToMS(Interval range) {\n+    long min = range._min == MIN_START_TIME ? MIN_START_TIME : _timeUnit.toMillis(range._min);\n+    long max = range._max == MAX_END_TIME ? MAX_END_TIME : _timeUnit.toMillis(range._max);\n+    return new Interval(min, max);\n+  }\n+\n+  private List<Interval> getIntersectionSortedRanges(List<List<Interval>> ranges) {\n+    // Requires input ranges are sorted, the return ranges will be sorted\n+    return getIntersectionSortedRanges(ranges, 0, ranges.size());\n+  }\n+\n+  private List<Interval> getIntersectionSortedRanges(List<List<Interval>> ranges, int start, int end) {\n+    if (start == end) {\n+      return null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1adcfac676a45b45421f5ba6eab4ee6b1853555"}, "originalPosition": 237}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNjA3MDY1OnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzo0NToyMVrOH22hCA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzo0NToyMVrOH22hCA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzI3ODM0NA==", "bodyText": "Cache these 2 sizes in local variables", "url": "https://github.com/apache/pinot/pull/6259#discussion_r527278344", "createdAt": "2020-11-19T23:45:21Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.math.BigDecimal;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final TimeUnit _timeUnit;\n+\n+  private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n+  private final Map _segmentToTimeRangeMSCache;\n+\n+  public TimeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    DateTimeFormatSpec formatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    _timeUnit = formatSpec.getColumnUnit();\n+    Preconditions\n+        .checkNotNull(_timeUnit, \"Time unit must be configured in the field spec for time column: %s of table: %s\",\n+            _timeColumn, _tableNameWithType);\n+    _segmentToTimeRangeMSCache = new HashMap<String, Interval>();\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    onExternalViewChange(externalView, idealState, onlineSegments);\n+  }\n+\n+  @Override\n+  synchronized public void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    List<String> newSegments = new ArrayList<>();\n+    for (String onlineSegment : onlineSegments) {\n+      if (!_segmentToTimeRangeMSCache.containsKey(onlineSegment)) {\n+        newSegments.add(onlineSegment);\n+      }\n+    }\n+\n+    List<String> newSegmentZKMetadataPaths = new ArrayList<>();\n+    for (String segment: newSegments) {\n+      newSegmentZKMetadataPaths.add(_segmentZKMetadataPathPrefix + segment);\n+    }\n+\n+    List<ZNRecord> znRecords = _propertyStore.get(newSegmentZKMetadataPaths, null, AccessOption.PERSISTENT, true);\n+\n+    for (int i = 0; i < newSegments.size(); i++) {\n+      String segment = newSegments.get(i);\n+      Interval range = extractTimeRangeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(i));\n+      _segmentToTimeRangeMSCache.put(segment, range);\n+    }\n+    _segmentToTimeRangeMSCache.keySet().retainAll(onlineSegments);\n+    // atomic swap _timeRangeToSegmentMap for input online segments\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(_segmentToTimeRangeMSCache);\n+  }\n+\n+  private Interval extractTimeRangeMSFromSegmentZKMetaZNRecord(String segment, @Nullable ZNRecord znRecord) {\n+    Interval defaultRange = new Interval(MIN_START_TIME, MAX_END_TIME);\n+    // Segments without metadata or with invalid time range will be set with [min_start, max_end] and will not be pruned\n+    if (znRecord == null) {\n+      LOGGER.warn(\"Failed to find segment ZK metadata for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return defaultRange;\n+    }\n+\n+    long startTime = znRecord.getLongField(CommonConstants.Segment.START_TIME, -1);\n+    long endTime = znRecord.getLongField(CommonConstants.Segment.END_TIME, -1);\n+    if (startTime < 0 || endTime < 0 || startTime > endTime) {\n+      LOGGER.warn(\"Failed to find valid end time for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return defaultRange;\n+    }\n+\n+    TimeUnit timeUnit = znRecord.getEnumField(CommonConstants.Segment.TIME_UNIT, TimeUnit.class, TimeUnit.DAYS);\n+    return new Interval(timeUnit.toMillis(startTime), timeUnit.toMillis(endTime));\n+  }\n+\n+  @Override\n+  synchronized public void refreshSegment(String segment) {\n+    List<ZNRecord> znRecords = _propertyStore.get(Collections.singletonList(_segmentZKMetadataPathPrefix + segment), null, AccessOption.PERSISTENT, true);\n+    Interval range = extractTimeRangeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(0));\n+    _segmentToTimeRangeMSCache.put(segment, range);\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(_segmentToTimeRangeMSCache);\n+  }\n+\n+  /**\n+   * NOTE: Pruning is done by searching _timeRangeToSegmentSearchTree based on request time range and check if the results\n+   *       are in the input segments. By doing so we will have run time O(M * logN) (N is the # of all online segments,\n+   *       M is the # of qualified intersected segments).\n+   */\n+  @Override\n+  public Set<String> prune(BrokerRequest brokerRequest, Set<String> segments) {\n+    // The pruned order may be different from the input order\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      return segments;\n+    }\n+    FilterQueryTree filterQueryTree = RequestUtils.generateFilterQueryTree(brokerRequest);\n+    if (filterQueryTree == null) {\n+      return segments;\n+    }\n+    List<Interval> ranges = getFilterTimeRange(filterQueryTree);\n+    if (ranges == null) { // cannot prune based on time for input request\n+      return segments;\n+    }\n+    if (ranges.size() == 0) { // invalid query time range\n+      return Collections.emptySet();\n+    }\n+\n+    Set<String> selectedSegments = new HashSet<>();\n+    for (Interval range : ranges) {\n+      Interval rangeMS = convertRangeToMS(range);\n+      for (Object segment : _timeRangeMSToSegmentSearchTree.searchAll(rangeMS)) {\n+        if (segments.contains(segment)) {\n+          selectedSegments.add((String) segment);\n+        }\n+      }\n+    }\n+    return selectedSegments;\n+  }\n+\n+  private List<Interval> getFilterTimeRange(FilterQueryTree filterQueryTree) {\n+    // return NUll if no time range info or cannot filter base on the info (e.g. 'SELECT * from myTable where time < 50 OR firstName = Jason')\n+    // return an empty list if filtering range is specified but invalid (e.g. 'SELECT * from myTable where time < 50 AND time > 100')\n+    switch (filterQueryTree.getOperator()) {\n+      case AND:\n+        List<List<Interval>> andRanges = new ArrayList<>();\n+        for (FilterQueryTree child : filterQueryTree.getChildren()) {\n+          List<Interval> childRanges = getFilterTimeRange(child);\n+          if (childRanges != null) {\n+            andRanges.add(childRanges);\n+          }\n+        }\n+        return getIntersectionSortedRanges(andRanges);\n+      case OR:\n+        List<List<Interval>> orRanges = new ArrayList<>();\n+        for (FilterQueryTree child : filterQueryTree.getChildren()) {\n+          List<Interval> childRanges = getFilterTimeRange(child);\n+          if (childRanges == null) {\n+            return null;\n+          } else {\n+            orRanges.add(childRanges);\n+          }\n+        }\n+        return getUnionSortedRanges(orRanges);\n+      case EQUALITY:\n+        if (filterQueryTree.getColumn().equals(_timeColumn)) {\n+          long timeStamp = Long.parseLong(filterQueryTree.getValue().get(0));\n+          return Collections.singletonList(new Interval(timeStamp, timeStamp));\n+        }\n+        return null;\n+      case RANGE:\n+        if (filterQueryTree.getColumn().equals(_timeColumn)) {\n+          return parseRange(filterQueryTree.getValue());\n+        }\n+        return null;\n+      default:\n+        return null;\n+    }\n+  }\n+\n+  private Interval convertRangeToMS(Interval range) {\n+    long min = range._min == MIN_START_TIME ? MIN_START_TIME : _timeUnit.toMillis(range._min);\n+    long max = range._max == MAX_END_TIME ? MAX_END_TIME : _timeUnit.toMillis(range._max);\n+    return new Interval(min, max);\n+  }\n+\n+  private List<Interval> getIntersectionSortedRanges(List<List<Interval>> ranges) {\n+    // Requires input ranges are sorted, the return ranges will be sorted\n+    return getIntersectionSortedRanges(ranges, 0, ranges.size());\n+  }\n+\n+  private List<Interval> getIntersectionSortedRanges(List<List<Interval>> ranges, int start, int end) {\n+    if (start == end) {\n+      return null;\n+    }\n+\n+    if (start + 1 == end) {\n+      return ranges.get(start);\n+    }\n+\n+    int mid = start + (end - start) / 2;\n+    List<Interval> ranges1 = getIntersectionSortedRanges(ranges, start, mid);\n+    List<Interval> ranges2 = getIntersectionSortedRanges(ranges, mid, end);\n+    return getIntersectionOfTwoSortedRanges(ranges1, ranges2);\n+  }\n+\n+  private List<Interval> getIntersectionOfTwoSortedRanges(List<Interval> ranges1, List<Interval> ranges2) { // sorted non-overlapping ranges\n+    List<Interval> res = new ArrayList<>();\n+    int i = 0, j = 0;\n+    while (i < ranges1.size() && j < ranges2.size()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1adcfac676a45b45421f5ba6eab4ee6b1853555"}, "originalPosition": 253}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNjA3MTI3OnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzo0NTozM1rOH22hVw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzo0NTozM1rOH22hVw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzI3ODQyMw==", "bodyText": "Split into 2 lines", "url": "https://github.com/apache/pinot/pull/6259#discussion_r527278423", "createdAt": "2020-11-19T23:45:33Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.math.BigDecimal;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final TimeUnit _timeUnit;\n+\n+  private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n+  private final Map _segmentToTimeRangeMSCache;\n+\n+  public TimeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    DateTimeFormatSpec formatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    _timeUnit = formatSpec.getColumnUnit();\n+    Preconditions\n+        .checkNotNull(_timeUnit, \"Time unit must be configured in the field spec for time column: %s of table: %s\",\n+            _timeColumn, _tableNameWithType);\n+    _segmentToTimeRangeMSCache = new HashMap<String, Interval>();\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    onExternalViewChange(externalView, idealState, onlineSegments);\n+  }\n+\n+  @Override\n+  synchronized public void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    List<String> newSegments = new ArrayList<>();\n+    for (String onlineSegment : onlineSegments) {\n+      if (!_segmentToTimeRangeMSCache.containsKey(onlineSegment)) {\n+        newSegments.add(onlineSegment);\n+      }\n+    }\n+\n+    List<String> newSegmentZKMetadataPaths = new ArrayList<>();\n+    for (String segment: newSegments) {\n+      newSegmentZKMetadataPaths.add(_segmentZKMetadataPathPrefix + segment);\n+    }\n+\n+    List<ZNRecord> znRecords = _propertyStore.get(newSegmentZKMetadataPaths, null, AccessOption.PERSISTENT, true);\n+\n+    for (int i = 0; i < newSegments.size(); i++) {\n+      String segment = newSegments.get(i);\n+      Interval range = extractTimeRangeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(i));\n+      _segmentToTimeRangeMSCache.put(segment, range);\n+    }\n+    _segmentToTimeRangeMSCache.keySet().retainAll(onlineSegments);\n+    // atomic swap _timeRangeToSegmentMap for input online segments\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(_segmentToTimeRangeMSCache);\n+  }\n+\n+  private Interval extractTimeRangeMSFromSegmentZKMetaZNRecord(String segment, @Nullable ZNRecord znRecord) {\n+    Interval defaultRange = new Interval(MIN_START_TIME, MAX_END_TIME);\n+    // Segments without metadata or with invalid time range will be set with [min_start, max_end] and will not be pruned\n+    if (znRecord == null) {\n+      LOGGER.warn(\"Failed to find segment ZK metadata for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return defaultRange;\n+    }\n+\n+    long startTime = znRecord.getLongField(CommonConstants.Segment.START_TIME, -1);\n+    long endTime = znRecord.getLongField(CommonConstants.Segment.END_TIME, -1);\n+    if (startTime < 0 || endTime < 0 || startTime > endTime) {\n+      LOGGER.warn(\"Failed to find valid end time for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return defaultRange;\n+    }\n+\n+    TimeUnit timeUnit = znRecord.getEnumField(CommonConstants.Segment.TIME_UNIT, TimeUnit.class, TimeUnit.DAYS);\n+    return new Interval(timeUnit.toMillis(startTime), timeUnit.toMillis(endTime));\n+  }\n+\n+  @Override\n+  synchronized public void refreshSegment(String segment) {\n+    List<ZNRecord> znRecords = _propertyStore.get(Collections.singletonList(_segmentZKMetadataPathPrefix + segment), null, AccessOption.PERSISTENT, true);\n+    Interval range = extractTimeRangeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(0));\n+    _segmentToTimeRangeMSCache.put(segment, range);\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(_segmentToTimeRangeMSCache);\n+  }\n+\n+  /**\n+   * NOTE: Pruning is done by searching _timeRangeToSegmentSearchTree based on request time range and check if the results\n+   *       are in the input segments. By doing so we will have run time O(M * logN) (N is the # of all online segments,\n+   *       M is the # of qualified intersected segments).\n+   */\n+  @Override\n+  public Set<String> prune(BrokerRequest brokerRequest, Set<String> segments) {\n+    // The pruned order may be different from the input order\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      return segments;\n+    }\n+    FilterQueryTree filterQueryTree = RequestUtils.generateFilterQueryTree(brokerRequest);\n+    if (filterQueryTree == null) {\n+      return segments;\n+    }\n+    List<Interval> ranges = getFilterTimeRange(filterQueryTree);\n+    if (ranges == null) { // cannot prune based on time for input request\n+      return segments;\n+    }\n+    if (ranges.size() == 0) { // invalid query time range\n+      return Collections.emptySet();\n+    }\n+\n+    Set<String> selectedSegments = new HashSet<>();\n+    for (Interval range : ranges) {\n+      Interval rangeMS = convertRangeToMS(range);\n+      for (Object segment : _timeRangeMSToSegmentSearchTree.searchAll(rangeMS)) {\n+        if (segments.contains(segment)) {\n+          selectedSegments.add((String) segment);\n+        }\n+      }\n+    }\n+    return selectedSegments;\n+  }\n+\n+  private List<Interval> getFilterTimeRange(FilterQueryTree filterQueryTree) {\n+    // return NUll if no time range info or cannot filter base on the info (e.g. 'SELECT * from myTable where time < 50 OR firstName = Jason')\n+    // return an empty list if filtering range is specified but invalid (e.g. 'SELECT * from myTable where time < 50 AND time > 100')\n+    switch (filterQueryTree.getOperator()) {\n+      case AND:\n+        List<List<Interval>> andRanges = new ArrayList<>();\n+        for (FilterQueryTree child : filterQueryTree.getChildren()) {\n+          List<Interval> childRanges = getFilterTimeRange(child);\n+          if (childRanges != null) {\n+            andRanges.add(childRanges);\n+          }\n+        }\n+        return getIntersectionSortedRanges(andRanges);\n+      case OR:\n+        List<List<Interval>> orRanges = new ArrayList<>();\n+        for (FilterQueryTree child : filterQueryTree.getChildren()) {\n+          List<Interval> childRanges = getFilterTimeRange(child);\n+          if (childRanges == null) {\n+            return null;\n+          } else {\n+            orRanges.add(childRanges);\n+          }\n+        }\n+        return getUnionSortedRanges(orRanges);\n+      case EQUALITY:\n+        if (filterQueryTree.getColumn().equals(_timeColumn)) {\n+          long timeStamp = Long.parseLong(filterQueryTree.getValue().get(0));\n+          return Collections.singletonList(new Interval(timeStamp, timeStamp));\n+        }\n+        return null;\n+      case RANGE:\n+        if (filterQueryTree.getColumn().equals(_timeColumn)) {\n+          return parseRange(filterQueryTree.getValue());\n+        }\n+        return null;\n+      default:\n+        return null;\n+    }\n+  }\n+\n+  private Interval convertRangeToMS(Interval range) {\n+    long min = range._min == MIN_START_TIME ? MIN_START_TIME : _timeUnit.toMillis(range._min);\n+    long max = range._max == MAX_END_TIME ? MAX_END_TIME : _timeUnit.toMillis(range._max);\n+    return new Interval(min, max);\n+  }\n+\n+  private List<Interval> getIntersectionSortedRanges(List<List<Interval>> ranges) {\n+    // Requires input ranges are sorted, the return ranges will be sorted\n+    return getIntersectionSortedRanges(ranges, 0, ranges.size());\n+  }\n+\n+  private List<Interval> getIntersectionSortedRanges(List<List<Interval>> ranges, int start, int end) {\n+    if (start == end) {\n+      return null;\n+    }\n+\n+    if (start + 1 == end) {\n+      return ranges.get(start);\n+    }\n+\n+    int mid = start + (end - start) / 2;\n+    List<Interval> ranges1 = getIntersectionSortedRanges(ranges, start, mid);\n+    List<Interval> ranges2 = getIntersectionSortedRanges(ranges, mid, end);\n+    return getIntersectionOfTwoSortedRanges(ranges1, ranges2);\n+  }\n+\n+  private List<Interval> getIntersectionOfTwoSortedRanges(List<Interval> ranges1, List<Interval> ranges2) { // sorted non-overlapping ranges\n+    List<Interval> res = new ArrayList<>();\n+    int i = 0, j = 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1adcfac676a45b45421f5ba6eab4ee6b1853555"}, "originalPosition": 252}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNjA4MTA4OnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzo0OTo1MlrOH22m-g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzo0OTo1MlrOH22m-g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzI3OTg2Ng==", "bodyText": "Reformat this part", "url": "https://github.com/apache/pinot/pull/6259#discussion_r527279866", "createdAt": "2020-11-19T23:49:52Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.math.BigDecimal;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final TimeUnit _timeUnit;\n+\n+  private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n+  private final Map _segmentToTimeRangeMSCache;\n+\n+  public TimeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    DateTimeFormatSpec formatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    _timeUnit = formatSpec.getColumnUnit();\n+    Preconditions\n+        .checkNotNull(_timeUnit, \"Time unit must be configured in the field spec for time column: %s of table: %s\",\n+            _timeColumn, _tableNameWithType);\n+    _segmentToTimeRangeMSCache = new HashMap<String, Interval>();\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    onExternalViewChange(externalView, idealState, onlineSegments);\n+  }\n+\n+  @Override\n+  synchronized public void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    List<String> newSegments = new ArrayList<>();\n+    for (String onlineSegment : onlineSegments) {\n+      if (!_segmentToTimeRangeMSCache.containsKey(onlineSegment)) {\n+        newSegments.add(onlineSegment);\n+      }\n+    }\n+\n+    List<String> newSegmentZKMetadataPaths = new ArrayList<>();\n+    for (String segment: newSegments) {\n+      newSegmentZKMetadataPaths.add(_segmentZKMetadataPathPrefix + segment);\n+    }\n+\n+    List<ZNRecord> znRecords = _propertyStore.get(newSegmentZKMetadataPaths, null, AccessOption.PERSISTENT, true);\n+\n+    for (int i = 0; i < newSegments.size(); i++) {\n+      String segment = newSegments.get(i);\n+      Interval range = extractTimeRangeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(i));\n+      _segmentToTimeRangeMSCache.put(segment, range);\n+    }\n+    _segmentToTimeRangeMSCache.keySet().retainAll(onlineSegments);\n+    // atomic swap _timeRangeToSegmentMap for input online segments\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(_segmentToTimeRangeMSCache);\n+  }\n+\n+  private Interval extractTimeRangeMSFromSegmentZKMetaZNRecord(String segment, @Nullable ZNRecord znRecord) {\n+    Interval defaultRange = new Interval(MIN_START_TIME, MAX_END_TIME);\n+    // Segments without metadata or with invalid time range will be set with [min_start, max_end] and will not be pruned\n+    if (znRecord == null) {\n+      LOGGER.warn(\"Failed to find segment ZK metadata for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return defaultRange;\n+    }\n+\n+    long startTime = znRecord.getLongField(CommonConstants.Segment.START_TIME, -1);\n+    long endTime = znRecord.getLongField(CommonConstants.Segment.END_TIME, -1);\n+    if (startTime < 0 || endTime < 0 || startTime > endTime) {\n+      LOGGER.warn(\"Failed to find valid end time for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return defaultRange;\n+    }\n+\n+    TimeUnit timeUnit = znRecord.getEnumField(CommonConstants.Segment.TIME_UNIT, TimeUnit.class, TimeUnit.DAYS);\n+    return new Interval(timeUnit.toMillis(startTime), timeUnit.toMillis(endTime));\n+  }\n+\n+  @Override\n+  synchronized public void refreshSegment(String segment) {\n+    List<ZNRecord> znRecords = _propertyStore.get(Collections.singletonList(_segmentZKMetadataPathPrefix + segment), null, AccessOption.PERSISTENT, true);\n+    Interval range = extractTimeRangeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(0));\n+    _segmentToTimeRangeMSCache.put(segment, range);\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(_segmentToTimeRangeMSCache);\n+  }\n+\n+  /**\n+   * NOTE: Pruning is done by searching _timeRangeToSegmentSearchTree based on request time range and check if the results\n+   *       are in the input segments. By doing so we will have run time O(M * logN) (N is the # of all online segments,\n+   *       M is the # of qualified intersected segments).\n+   */\n+  @Override\n+  public Set<String> prune(BrokerRequest brokerRequest, Set<String> segments) {\n+    // The pruned order may be different from the input order\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      return segments;\n+    }\n+    FilterQueryTree filterQueryTree = RequestUtils.generateFilterQueryTree(brokerRequest);\n+    if (filterQueryTree == null) {\n+      return segments;\n+    }\n+    List<Interval> ranges = getFilterTimeRange(filterQueryTree);\n+    if (ranges == null) { // cannot prune based on time for input request\n+      return segments;\n+    }\n+    if (ranges.size() == 0) { // invalid query time range\n+      return Collections.emptySet();\n+    }\n+\n+    Set<String> selectedSegments = new HashSet<>();\n+    for (Interval range : ranges) {\n+      Interval rangeMS = convertRangeToMS(range);\n+      for (Object segment : _timeRangeMSToSegmentSearchTree.searchAll(rangeMS)) {\n+        if (segments.contains(segment)) {\n+          selectedSegments.add((String) segment);\n+        }\n+      }\n+    }\n+    return selectedSegments;\n+  }\n+\n+  private List<Interval> getFilterTimeRange(FilterQueryTree filterQueryTree) {\n+    // return NUll if no time range info or cannot filter base on the info (e.g. 'SELECT * from myTable where time < 50 OR firstName = Jason')\n+    // return an empty list if filtering range is specified but invalid (e.g. 'SELECT * from myTable where time < 50 AND time > 100')\n+    switch (filterQueryTree.getOperator()) {\n+      case AND:\n+        List<List<Interval>> andRanges = new ArrayList<>();\n+        for (FilterQueryTree child : filterQueryTree.getChildren()) {\n+          List<Interval> childRanges = getFilterTimeRange(child);\n+          if (childRanges != null) {\n+            andRanges.add(childRanges);\n+          }\n+        }\n+        return getIntersectionSortedRanges(andRanges);\n+      case OR:\n+        List<List<Interval>> orRanges = new ArrayList<>();\n+        for (FilterQueryTree child : filterQueryTree.getChildren()) {\n+          List<Interval> childRanges = getFilterTimeRange(child);\n+          if (childRanges == null) {\n+            return null;\n+          } else {\n+            orRanges.add(childRanges);\n+          }\n+        }\n+        return getUnionSortedRanges(orRanges);\n+      case EQUALITY:\n+        if (filterQueryTree.getColumn().equals(_timeColumn)) {\n+          long timeStamp = Long.parseLong(filterQueryTree.getValue().get(0));\n+          return Collections.singletonList(new Interval(timeStamp, timeStamp));\n+        }\n+        return null;\n+      case RANGE:\n+        if (filterQueryTree.getColumn().equals(_timeColumn)) {\n+          return parseRange(filterQueryTree.getValue());\n+        }\n+        return null;\n+      default:\n+        return null;\n+    }\n+  }\n+\n+  private Interval convertRangeToMS(Interval range) {\n+    long min = range._min == MIN_START_TIME ? MIN_START_TIME : _timeUnit.toMillis(range._min);\n+    long max = range._max == MAX_END_TIME ? MAX_END_TIME : _timeUnit.toMillis(range._max);\n+    return new Interval(min, max);\n+  }\n+\n+  private List<Interval> getIntersectionSortedRanges(List<List<Interval>> ranges) {\n+    // Requires input ranges are sorted, the return ranges will be sorted\n+    return getIntersectionSortedRanges(ranges, 0, ranges.size());\n+  }\n+\n+  private List<Interval> getIntersectionSortedRanges(List<List<Interval>> ranges, int start, int end) {\n+    if (start == end) {\n+      return null;\n+    }\n+\n+    if (start + 1 == end) {\n+      return ranges.get(start);\n+    }\n+\n+    int mid = start + (end - start) / 2;\n+    List<Interval> ranges1 = getIntersectionSortedRanges(ranges, start, mid);\n+    List<Interval> ranges2 = getIntersectionSortedRanges(ranges, mid, end);\n+    return getIntersectionOfTwoSortedRanges(ranges1, ranges2);\n+  }\n+\n+  private List<Interval> getIntersectionOfTwoSortedRanges(List<Interval> ranges1, List<Interval> ranges2) { // sorted non-overlapping ranges\n+    List<Interval> res = new ArrayList<>();\n+    int i = 0, j = 0;\n+    while (i < ranges1.size() && j < ranges2.size()) {\n+      Interval range1 = ranges1.get(i);\n+      Interval range2 = ranges2.get(j);\n+      if (range1.intersects(range2)) {\n+        res.add(Interval.getIntersection(range1, range2));\n+      }\n+      if (range1._max < range2._max) {\n+        i++;\n+      } else {\n+        j++;\n+      }\n+    }\n+    return res;\n+  }\n+\n+  private List<Interval> getUnionSortedRanges(List<List<Interval>> ranges) {\n+    return getUnionSortedRanges(ranges, 0, ranges.size());\n+  }\n+\n+  private List<Interval> getUnionSortedRanges(List<List<Interval>> ranges, int start, int end) {\n+    if (start == end) {\n+      return null;\n+    }\n+\n+    if (start + 1 == end) {\n+      return ranges.get(start);\n+    }\n+\n+    int mid = start + (end - start) / 2;\n+    List<Interval> ranges1 = getUnionSortedRanges(ranges, start, mid);\n+    List<Interval> ranges2 = getUnionSortedRanges(ranges, mid, end);\n+    return getUnionOfTwoSortedRanges(ranges1, ranges2);\n+  }\n+\n+  private List<Interval> getUnionOfTwoSortedRanges(List<Interval> ranges1, List<Interval> ranges2) { // sorted non-overlapping ranges\n+    List<Interval> res = new ArrayList<>();\n+    int i = 0, j = 0;\n+\n+    while (i < ranges1.size() || j < ranges2.size()) {\n+      if (j == ranges2.size() || i < ranges1.size() && ranges1.get(i).compareTo(ranges2.get(j)) <= 0) {\n+        if (res.size() == 0 || !ranges1.get(i).intersects(res.get(res.size()-1))) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1adcfac676a45b45421f5ba6eab4ee6b1853555"}, "originalPosition": 293}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNjA4NzM1OnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzo1MjoyOVrOH22qhA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzo1MjoyOVrOH22qhA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzI4MDc3Mg==", "bodyText": "Put some comments explaining the algorithm", "url": "https://github.com/apache/pinot/pull/6259#discussion_r527280772", "createdAt": "2020-11-19T23:52:29Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.math.BigDecimal;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final TimeUnit _timeUnit;\n+\n+  private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n+  private final Map _segmentToTimeRangeMSCache;\n+\n+  public TimeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    DateTimeFormatSpec formatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    _timeUnit = formatSpec.getColumnUnit();\n+    Preconditions\n+        .checkNotNull(_timeUnit, \"Time unit must be configured in the field spec for time column: %s of table: %s\",\n+            _timeColumn, _tableNameWithType);\n+    _segmentToTimeRangeMSCache = new HashMap<String, Interval>();\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    onExternalViewChange(externalView, idealState, onlineSegments);\n+  }\n+\n+  @Override\n+  synchronized public void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    List<String> newSegments = new ArrayList<>();\n+    for (String onlineSegment : onlineSegments) {\n+      if (!_segmentToTimeRangeMSCache.containsKey(onlineSegment)) {\n+        newSegments.add(onlineSegment);\n+      }\n+    }\n+\n+    List<String> newSegmentZKMetadataPaths = new ArrayList<>();\n+    for (String segment: newSegments) {\n+      newSegmentZKMetadataPaths.add(_segmentZKMetadataPathPrefix + segment);\n+    }\n+\n+    List<ZNRecord> znRecords = _propertyStore.get(newSegmentZKMetadataPaths, null, AccessOption.PERSISTENT, true);\n+\n+    for (int i = 0; i < newSegments.size(); i++) {\n+      String segment = newSegments.get(i);\n+      Interval range = extractTimeRangeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(i));\n+      _segmentToTimeRangeMSCache.put(segment, range);\n+    }\n+    _segmentToTimeRangeMSCache.keySet().retainAll(onlineSegments);\n+    // atomic swap _timeRangeToSegmentMap for input online segments\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(_segmentToTimeRangeMSCache);\n+  }\n+\n+  private Interval extractTimeRangeMSFromSegmentZKMetaZNRecord(String segment, @Nullable ZNRecord znRecord) {\n+    Interval defaultRange = new Interval(MIN_START_TIME, MAX_END_TIME);\n+    // Segments without metadata or with invalid time range will be set with [min_start, max_end] and will not be pruned\n+    if (znRecord == null) {\n+      LOGGER.warn(\"Failed to find segment ZK metadata for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return defaultRange;\n+    }\n+\n+    long startTime = znRecord.getLongField(CommonConstants.Segment.START_TIME, -1);\n+    long endTime = znRecord.getLongField(CommonConstants.Segment.END_TIME, -1);\n+    if (startTime < 0 || endTime < 0 || startTime > endTime) {\n+      LOGGER.warn(\"Failed to find valid end time for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return defaultRange;\n+    }\n+\n+    TimeUnit timeUnit = znRecord.getEnumField(CommonConstants.Segment.TIME_UNIT, TimeUnit.class, TimeUnit.DAYS);\n+    return new Interval(timeUnit.toMillis(startTime), timeUnit.toMillis(endTime));\n+  }\n+\n+  @Override\n+  synchronized public void refreshSegment(String segment) {\n+    List<ZNRecord> znRecords = _propertyStore.get(Collections.singletonList(_segmentZKMetadataPathPrefix + segment), null, AccessOption.PERSISTENT, true);\n+    Interval range = extractTimeRangeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(0));\n+    _segmentToTimeRangeMSCache.put(segment, range);\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(_segmentToTimeRangeMSCache);\n+  }\n+\n+  /**\n+   * NOTE: Pruning is done by searching _timeRangeToSegmentSearchTree based on request time range and check if the results\n+   *       are in the input segments. By doing so we will have run time O(M * logN) (N is the # of all online segments,\n+   *       M is the # of qualified intersected segments).\n+   */\n+  @Override\n+  public Set<String> prune(BrokerRequest brokerRequest, Set<String> segments) {\n+    // The pruned order may be different from the input order\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      return segments;\n+    }\n+    FilterQueryTree filterQueryTree = RequestUtils.generateFilterQueryTree(brokerRequest);\n+    if (filterQueryTree == null) {\n+      return segments;\n+    }\n+    List<Interval> ranges = getFilterTimeRange(filterQueryTree);\n+    if (ranges == null) { // cannot prune based on time for input request\n+      return segments;\n+    }\n+    if (ranges.size() == 0) { // invalid query time range\n+      return Collections.emptySet();\n+    }\n+\n+    Set<String> selectedSegments = new HashSet<>();\n+    for (Interval range : ranges) {\n+      Interval rangeMS = convertRangeToMS(range);\n+      for (Object segment : _timeRangeMSToSegmentSearchTree.searchAll(rangeMS)) {\n+        if (segments.contains(segment)) {\n+          selectedSegments.add((String) segment);\n+        }\n+      }\n+    }\n+    return selectedSegments;\n+  }\n+\n+  private List<Interval> getFilterTimeRange(FilterQueryTree filterQueryTree) {\n+    // return NUll if no time range info or cannot filter base on the info (e.g. 'SELECT * from myTable where time < 50 OR firstName = Jason')\n+    // return an empty list if filtering range is specified but invalid (e.g. 'SELECT * from myTable where time < 50 AND time > 100')\n+    switch (filterQueryTree.getOperator()) {\n+      case AND:\n+        List<List<Interval>> andRanges = new ArrayList<>();\n+        for (FilterQueryTree child : filterQueryTree.getChildren()) {\n+          List<Interval> childRanges = getFilterTimeRange(child);\n+          if (childRanges != null) {\n+            andRanges.add(childRanges);\n+          }\n+        }\n+        return getIntersectionSortedRanges(andRanges);\n+      case OR:\n+        List<List<Interval>> orRanges = new ArrayList<>();\n+        for (FilterQueryTree child : filterQueryTree.getChildren()) {\n+          List<Interval> childRanges = getFilterTimeRange(child);\n+          if (childRanges == null) {\n+            return null;\n+          } else {\n+            orRanges.add(childRanges);\n+          }\n+        }\n+        return getUnionSortedRanges(orRanges);\n+      case EQUALITY:\n+        if (filterQueryTree.getColumn().equals(_timeColumn)) {\n+          long timeStamp = Long.parseLong(filterQueryTree.getValue().get(0));\n+          return Collections.singletonList(new Interval(timeStamp, timeStamp));\n+        }\n+        return null;\n+      case RANGE:\n+        if (filterQueryTree.getColumn().equals(_timeColumn)) {\n+          return parseRange(filterQueryTree.getValue());\n+        }\n+        return null;\n+      default:\n+        return null;\n+    }\n+  }\n+\n+  private Interval convertRangeToMS(Interval range) {\n+    long min = range._min == MIN_START_TIME ? MIN_START_TIME : _timeUnit.toMillis(range._min);\n+    long max = range._max == MAX_END_TIME ? MAX_END_TIME : _timeUnit.toMillis(range._max);\n+    return new Interval(min, max);\n+  }\n+\n+  private List<Interval> getIntersectionSortedRanges(List<List<Interval>> ranges) {\n+    // Requires input ranges are sorted, the return ranges will be sorted\n+    return getIntersectionSortedRanges(ranges, 0, ranges.size());\n+  }\n+\n+  private List<Interval> getIntersectionSortedRanges(List<List<Interval>> ranges, int start, int end) {\n+    if (start == end) {\n+      return null;\n+    }\n+\n+    if (start + 1 == end) {\n+      return ranges.get(start);\n+    }\n+\n+    int mid = start + (end - start) / 2;\n+    List<Interval> ranges1 = getIntersectionSortedRanges(ranges, start, mid);\n+    List<Interval> ranges2 = getIntersectionSortedRanges(ranges, mid, end);\n+    return getIntersectionOfTwoSortedRanges(ranges1, ranges2);\n+  }\n+\n+  private List<Interval> getIntersectionOfTwoSortedRanges(List<Interval> ranges1, List<Interval> ranges2) { // sorted non-overlapping ranges\n+    List<Interval> res = new ArrayList<>();\n+    int i = 0, j = 0;\n+    while (i < ranges1.size() && j < ranges2.size()) {\n+      Interval range1 = ranges1.get(i);\n+      Interval range2 = ranges2.get(j);\n+      if (range1.intersects(range2)) {\n+        res.add(Interval.getIntersection(range1, range2));\n+      }\n+      if (range1._max < range2._max) {\n+        i++;\n+      } else {\n+        j++;\n+      }\n+    }\n+    return res;\n+  }\n+\n+  private List<Interval> getUnionSortedRanges(List<List<Interval>> ranges) {\n+    return getUnionSortedRanges(ranges, 0, ranges.size());\n+  }\n+\n+  private List<Interval> getUnionSortedRanges(List<List<Interval>> ranges, int start, int end) {\n+    if (start == end) {\n+      return null;\n+    }\n+\n+    if (start + 1 == end) {\n+      return ranges.get(start);\n+    }\n+\n+    int mid = start + (end - start) / 2;\n+    List<Interval> ranges1 = getUnionSortedRanges(ranges, start, mid);\n+    List<Interval> ranges2 = getUnionSortedRanges(ranges, mid, end);\n+    return getUnionOfTwoSortedRanges(ranges1, ranges2);\n+  }\n+\n+  private List<Interval> getUnionOfTwoSortedRanges(List<Interval> ranges1, List<Interval> ranges2) { // sorted non-overlapping ranges\n+    List<Interval> res = new ArrayList<>();\n+    int i = 0, j = 0;\n+\n+    while (i < ranges1.size() || j < ranges2.size()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1adcfac676a45b45421f5ba6eab4ee6b1853555"}, "originalPosition": 291}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNjA5MTgxOnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzo1NDozMVrOH22tAQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzo1NDozMVrOH22tAQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzI4MTQwOQ==", "bodyText": "Here you can handle SDF and directly parse the range into interval in millis", "url": "https://github.com/apache/pinot/pull/6259#discussion_r527281409", "createdAt": "2020-11-19T23:54:31Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.math.BigDecimal;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.intervalST.IntervalST;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeSegmentPruner.class);\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final long MIN_START_TIME = 0;\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final TimeUnit _timeUnit;\n+\n+  private volatile IntervalST _timeRangeMSToSegmentSearchTree;\n+  private final Map _segmentToTimeRangeMSCache;\n+\n+  public TimeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    DateTimeFormatSpec formatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    _timeUnit = formatSpec.getColumnUnit();\n+    Preconditions\n+        .checkNotNull(_timeUnit, \"Time unit must be configured in the field spec for time column: %s of table: %s\",\n+            _timeColumn, _tableNameWithType);\n+    _segmentToTimeRangeMSCache = new HashMap<String, Interval>();\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    onExternalViewChange(externalView, idealState, onlineSegments);\n+  }\n+\n+  @Override\n+  synchronized public void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    List<String> newSegments = new ArrayList<>();\n+    for (String onlineSegment : onlineSegments) {\n+      if (!_segmentToTimeRangeMSCache.containsKey(onlineSegment)) {\n+        newSegments.add(onlineSegment);\n+      }\n+    }\n+\n+    List<String> newSegmentZKMetadataPaths = new ArrayList<>();\n+    for (String segment: newSegments) {\n+      newSegmentZKMetadataPaths.add(_segmentZKMetadataPathPrefix + segment);\n+    }\n+\n+    List<ZNRecord> znRecords = _propertyStore.get(newSegmentZKMetadataPaths, null, AccessOption.PERSISTENT, true);\n+\n+    for (int i = 0; i < newSegments.size(); i++) {\n+      String segment = newSegments.get(i);\n+      Interval range = extractTimeRangeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(i));\n+      _segmentToTimeRangeMSCache.put(segment, range);\n+    }\n+    _segmentToTimeRangeMSCache.keySet().retainAll(onlineSegments);\n+    // atomic swap _timeRangeToSegmentMap for input online segments\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(_segmentToTimeRangeMSCache);\n+  }\n+\n+  private Interval extractTimeRangeMSFromSegmentZKMetaZNRecord(String segment, @Nullable ZNRecord znRecord) {\n+    Interval defaultRange = new Interval(MIN_START_TIME, MAX_END_TIME);\n+    // Segments without metadata or with invalid time range will be set with [min_start, max_end] and will not be pruned\n+    if (znRecord == null) {\n+      LOGGER.warn(\"Failed to find segment ZK metadata for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return defaultRange;\n+    }\n+\n+    long startTime = znRecord.getLongField(CommonConstants.Segment.START_TIME, -1);\n+    long endTime = znRecord.getLongField(CommonConstants.Segment.END_TIME, -1);\n+    if (startTime < 0 || endTime < 0 || startTime > endTime) {\n+      LOGGER.warn(\"Failed to find valid end time for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return defaultRange;\n+    }\n+\n+    TimeUnit timeUnit = znRecord.getEnumField(CommonConstants.Segment.TIME_UNIT, TimeUnit.class, TimeUnit.DAYS);\n+    return new Interval(timeUnit.toMillis(startTime), timeUnit.toMillis(endTime));\n+  }\n+\n+  @Override\n+  synchronized public void refreshSegment(String segment) {\n+    List<ZNRecord> znRecords = _propertyStore.get(Collections.singletonList(_segmentZKMetadataPathPrefix + segment), null, AccessOption.PERSISTENT, true);\n+    Interval range = extractTimeRangeMSFromSegmentZKMetaZNRecord(segment, znRecords.get(0));\n+    _segmentToTimeRangeMSCache.put(segment, range);\n+    _timeRangeMSToSegmentSearchTree = new IntervalST<String>(_segmentToTimeRangeMSCache);\n+  }\n+\n+  /**\n+   * NOTE: Pruning is done by searching _timeRangeToSegmentSearchTree based on request time range and check if the results\n+   *       are in the input segments. By doing so we will have run time O(M * logN) (N is the # of all online segments,\n+   *       M is the # of qualified intersected segments).\n+   */\n+  @Override\n+  public Set<String> prune(BrokerRequest brokerRequest, Set<String> segments) {\n+    // The pruned order may be different from the input order\n+    if (_timeRangeMSToSegmentSearchTree == null) {\n+      return segments;\n+    }\n+    FilterQueryTree filterQueryTree = RequestUtils.generateFilterQueryTree(brokerRequest);\n+    if (filterQueryTree == null) {\n+      return segments;\n+    }\n+    List<Interval> ranges = getFilterTimeRange(filterQueryTree);\n+    if (ranges == null) { // cannot prune based on time for input request\n+      return segments;\n+    }\n+    if (ranges.size() == 0) { // invalid query time range\n+      return Collections.emptySet();\n+    }\n+\n+    Set<String> selectedSegments = new HashSet<>();\n+    for (Interval range : ranges) {\n+      Interval rangeMS = convertRangeToMS(range);\n+      for (Object segment : _timeRangeMSToSegmentSearchTree.searchAll(rangeMS)) {\n+        if (segments.contains(segment)) {\n+          selectedSegments.add((String) segment);\n+        }\n+      }\n+    }\n+    return selectedSegments;\n+  }\n+\n+  private List<Interval> getFilterTimeRange(FilterQueryTree filterQueryTree) {\n+    // return NUll if no time range info or cannot filter base on the info (e.g. 'SELECT * from myTable where time < 50 OR firstName = Jason')\n+    // return an empty list if filtering range is specified but invalid (e.g. 'SELECT * from myTable where time < 50 AND time > 100')\n+    switch (filterQueryTree.getOperator()) {\n+      case AND:\n+        List<List<Interval>> andRanges = new ArrayList<>();\n+        for (FilterQueryTree child : filterQueryTree.getChildren()) {\n+          List<Interval> childRanges = getFilterTimeRange(child);\n+          if (childRanges != null) {\n+            andRanges.add(childRanges);\n+          }\n+        }\n+        return getIntersectionSortedRanges(andRanges);\n+      case OR:\n+        List<List<Interval>> orRanges = new ArrayList<>();\n+        for (FilterQueryTree child : filterQueryTree.getChildren()) {\n+          List<Interval> childRanges = getFilterTimeRange(child);\n+          if (childRanges == null) {\n+            return null;\n+          } else {\n+            orRanges.add(childRanges);\n+          }\n+        }\n+        return getUnionSortedRanges(orRanges);\n+      case EQUALITY:\n+        if (filterQueryTree.getColumn().equals(_timeColumn)) {\n+          long timeStamp = Long.parseLong(filterQueryTree.getValue().get(0));\n+          return Collections.singletonList(new Interval(timeStamp, timeStamp));\n+        }\n+        return null;\n+      case RANGE:\n+        if (filterQueryTree.getColumn().equals(_timeColumn)) {\n+          return parseRange(filterQueryTree.getValue());\n+        }\n+        return null;\n+      default:\n+        return null;\n+    }\n+  }\n+\n+  private Interval convertRangeToMS(Interval range) {\n+    long min = range._min == MIN_START_TIME ? MIN_START_TIME : _timeUnit.toMillis(range._min);\n+    long max = range._max == MAX_END_TIME ? MAX_END_TIME : _timeUnit.toMillis(range._max);\n+    return new Interval(min, max);\n+  }\n+\n+  private List<Interval> getIntersectionSortedRanges(List<List<Interval>> ranges) {\n+    // Requires input ranges are sorted, the return ranges will be sorted\n+    return getIntersectionSortedRanges(ranges, 0, ranges.size());\n+  }\n+\n+  private List<Interval> getIntersectionSortedRanges(List<List<Interval>> ranges, int start, int end) {\n+    if (start == end) {\n+      return null;\n+    }\n+\n+    if (start + 1 == end) {\n+      return ranges.get(start);\n+    }\n+\n+    int mid = start + (end - start) / 2;\n+    List<Interval> ranges1 = getIntersectionSortedRanges(ranges, start, mid);\n+    List<Interval> ranges2 = getIntersectionSortedRanges(ranges, mid, end);\n+    return getIntersectionOfTwoSortedRanges(ranges1, ranges2);\n+  }\n+\n+  private List<Interval> getIntersectionOfTwoSortedRanges(List<Interval> ranges1, List<Interval> ranges2) { // sorted non-overlapping ranges\n+    List<Interval> res = new ArrayList<>();\n+    int i = 0, j = 0;\n+    while (i < ranges1.size() && j < ranges2.size()) {\n+      Interval range1 = ranges1.get(i);\n+      Interval range2 = ranges2.get(j);\n+      if (range1.intersects(range2)) {\n+        res.add(Interval.getIntersection(range1, range2));\n+      }\n+      if (range1._max < range2._max) {\n+        i++;\n+      } else {\n+        j++;\n+      }\n+    }\n+    return res;\n+  }\n+\n+  private List<Interval> getUnionSortedRanges(List<List<Interval>> ranges) {\n+    return getUnionSortedRanges(ranges, 0, ranges.size());\n+  }\n+\n+  private List<Interval> getUnionSortedRanges(List<List<Interval>> ranges, int start, int end) {\n+    if (start == end) {\n+      return null;\n+    }\n+\n+    if (start + 1 == end) {\n+      return ranges.get(start);\n+    }\n+\n+    int mid = start + (end - start) / 2;\n+    List<Interval> ranges1 = getUnionSortedRanges(ranges, start, mid);\n+    List<Interval> ranges2 = getUnionSortedRanges(ranges, mid, end);\n+    return getUnionOfTwoSortedRanges(ranges1, ranges2);\n+  }\n+\n+  private List<Interval> getUnionOfTwoSortedRanges(List<Interval> ranges1, List<Interval> ranges2) { // sorted non-overlapping ranges\n+    List<Interval> res = new ArrayList<>();\n+    int i = 0, j = 0;\n+\n+    while (i < ranges1.size() || j < ranges2.size()) {\n+      if (j == ranges2.size() || i < ranges1.size() && ranges1.get(i).compareTo(ranges2.get(j)) <= 0) {\n+        if (res.size() == 0 || !ranges1.get(i).intersects(res.get(res.size()-1))) {\n+          res.add(ranges1.get(i));\n+        } else {\n+          res.set(res.size()-1, Interval.getUnion(res.get(res.size()-1), (ranges1.get(i))));\n+        }\n+        i++;\n+      } else {\n+        if (res.size() == 0 || !ranges2.get(j).intersects(res.get(res.size()-1))) {\n+          res.add(ranges2.get(j));\n+        } else {\n+          res.set(res.size()-1, Interval.getUnion(res.get(res.size()-1), (ranges2.get(j))));\n+        }\n+        j++;\n+      }\n+    }\n+    return res;\n+  }\n+\n+  private List<Interval> parseRange(List<String> rangeExpressions) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1adcfac676a45b45421f5ba6eab4ee6b1853555"}, "originalPosition": 311}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNjA5Mzk3OnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/Interval.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzo1NToxNFrOH22uKg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzo1NToxNFrOH22uKg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzI4MTcwNg==", "bodyText": "Change the directory name to interval (no capital in directories)", "url": "https://github.com/apache/pinot/pull/6259#discussion_r527281706", "createdAt": "2020-11-19T23:55:14Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/Interval.java", "diffHunk": "@@ -0,0 +1,90 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner.intervalST;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1adcfac676a45b45421f5ba6eab4ee6b1853555"}, "originalPosition": 19}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNjA5NjMzOnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/Interval.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzo1NjoxNFrOH22vkA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzo1NjoxNFrOH22vkA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzI4MjA2NA==", "bodyText": "Don't use NotNull annotation. We only use Nullable, variables without annotation are treated as non-null", "url": "https://github.com/apache/pinot/pull/6259#discussion_r527282064", "createdAt": "2020-11-19T23:56:14Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/Interval.java", "diffHunk": "@@ -0,0 +1,90 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner.intervalST;\n+\n+import com.google.common.base.Preconditions;\n+import javax.validation.constraints.NotNull;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1adcfac676a45b45421f5ba6eab4ee6b1853555"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNjEwMTU0OnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/Interval.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzo1ODozMlrOH22yfw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzo1ODozMlrOH22yfw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzI4MjgxNQ==", "bodyText": "Preconditions might be better? We don't want it to be null as the caller cannot handle the null values", "url": "https://github.com/apache/pinot/pull/6259#discussion_r527282815", "createdAt": "2020-11-19T23:58:32Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/Interval.java", "diffHunk": "@@ -0,0 +1,90 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner.intervalST;\n+\n+import com.google.common.base.Preconditions;\n+import javax.validation.constraints.NotNull;\n+\n+\n+/**\n+ * The {@code Interval} class represents an one-dimensional closed interval which contains both ends.\n+ */\n+public class Interval implements Comparable<Interval> {\n+  public final long _min;\n+  public final long _max;\n+\n+  public Interval(long min, long max) {\n+    Preconditions.checkState(min <= max, \"invalid interval [{}, {}]\", min, max);\n+    _min = min;\n+    _max = max;\n+  }\n+\n+  public boolean intersects(@NotNull Interval that) {\n+    return _max >= that._min && that._max >= _min;\n+  }\n+\n+  @Override\n+  public int compareTo(Interval that) {\n+    Preconditions.checkNotNull(that, \"Compare to invalid interval: null\");\n+    if (_min < that._min) {\n+      return -1;\n+    } else if (_min > that._min) {\n+      return 1;\n+    } else if (_max < that._max) {\n+      return -1;\n+    } else if (_max > that._max) {\n+      return 1;\n+    }\n+    else return 0;\n+  }\n+\n+  @Override\n+  public int hashCode() {\n+    return (int)(_min * 17 + _max);\n+  }\n+\n+  @Override\n+  public boolean equals(Object that) {\n+    if (that instanceof Interval && that != null\n+        && _min == ((Interval)that)._min && _max == ((Interval)that)._max) {\n+      return true;\n+    }\n+    return false;\n+  }\n+\n+  public static Interval getIntersection(@NotNull Interval a, @NotNull Interval b) {\n+    if (!a.intersects(b)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1adcfac676a45b45421f5ba6eab4ee6b1853555"}, "originalPosition": 72}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNjEwNTEyOnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/IntervalST.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzo1OTo1OVrOH220gg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQyMzo1OTo1OVrOH220gg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzI4MzMzMA==", "bodyText": "Have a separate class for these info and keep one list", "url": "https://github.com/apache/pinot/pull/6259#discussion_r527283330", "createdAt": "2020-11-19T23:59:59Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/IntervalST.java", "diffHunk": "@@ -0,0 +1,197 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner.intervalST;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * The {@code IntervalST} class represents read-only balanced binary interval search tree map (from intervals to values)\n+ */\n+public class IntervalST<Value> {\n+\n+  // List representation of bst with root at index 0. For node with index x, it's left child index is (2x+1), right child index is (2x+2)\n+  //\n+  // A node with index x is represented as following structure\n+  //   {\n+  //        Interval _interval = _intervals[x];\n+  //        List<Value> _values = _values[x];\n+  //        long _max = _max[x];                   // max interval right end of subtree rooted at this node\n+  //    }\n+  private final List<Interval> _intervals;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1adcfac676a45b45421f5ba6eab4ee6b1853555"}, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNjExMzE4OnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/IntervalST.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQwMDowMzozOVrOH225fQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQwMDowMzozOVrOH225fQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzI4NDYwNQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                if (sortedIntervals.size() == 0) {\n          \n          \n            \n                if (sortedIntervals.size() <= 1) {", "url": "https://github.com/apache/pinot/pull/6259#discussion_r527284605", "createdAt": "2020-11-20T00:03:39Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/IntervalST.java", "diffHunk": "@@ -0,0 +1,197 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner.intervalST;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * The {@code IntervalST} class represents read-only balanced binary interval search tree map (from intervals to values)\n+ */\n+public class IntervalST<Value> {\n+\n+  // List representation of bst with root at index 0. For node with index x, it's left child index is (2x+1), right child index is (2x+2)\n+  //\n+  // A node with index x is represented as following structure\n+  //   {\n+  //        Interval _interval = _intervals[x];\n+  //        List<Value> _values = _values[x];\n+  //        long _max = _max[x];                   // max interval right end of subtree rooted at this node\n+  //    }\n+  private final List<Interval> _intervals;\n+  private final List<List<Value>> _values;\n+  private final List<Long> _maxs;\n+\n+  public IntervalST(Map<Value, Interval> valueToIntervalMap) {\n+    HashMap<Interval, List<Value>> intervalToValuesMap = new HashMap<>();\n+    for (Map.Entry<Value, Interval> entry : valueToIntervalMap.entrySet()) {\n+      List<Value> vals = intervalToValuesMap.putIfAbsent(entry.getValue(), new ArrayList<>());\n+      intervalToValuesMap.get(entry.getValue()).add(entry.getKey());\n+    }\n+\n+    List<Interval> sortedIntervals = new ArrayList<>(intervalToValuesMap.keySet());\n+    Collections.sort(sortedIntervals);\n+\n+    _intervals = new ArrayList<>(sortedIntervals.size());\n+    buildIntervalTree(sortedIntervals, _intervals);\n+\n+    _values = new ArrayList<>(_intervals.size());\n+    for (Interval interval: _intervals) {\n+      if (interval == null) {\n+        _values.add(null);\n+      } else {\n+        _values.add(intervalToValuesMap.get(interval));\n+      }\n+    }\n+\n+    _maxs = new ArrayList<>(_intervals.size());\n+    buildAuxiliaryInfo();\n+  }\n+\n+  private void buildIntervalTree(List<Interval> sortedIntervals, List<Interval> res) {\n+    // Build interval bst by bfs, the root for each subtree will be the median interval.\n+    // A typical balanced tree\n+    //                              [10, 20]\n+    //                              /       \\\n+    //                       [8, 15]        [12, 20]\n+    //                          /            /\n+    //                   [5, 10]       [10, 30]\n+    //\n+    // will be represented as { [10, 20], [8, 15], [12, 20], [5, 10], null, [10, 30] }\n+    if (sortedIntervals.size() == 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1adcfac676a45b45421f5ba6eab4ee6b1853555"}, "originalPosition": 81}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNjEyOTUxOnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/IntervalST.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQwMDoxMDo0NFrOH23CyQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQwMDoxMDo0NFrOH23CyQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzI4Njk4NQ==", "bodyText": "Keep one list of IntPair", "url": "https://github.com/apache/pinot/pull/6259#discussion_r527286985", "createdAt": "2020-11-20T00:10:44Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/IntervalST.java", "diffHunk": "@@ -0,0 +1,197 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner.intervalST;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * The {@code IntervalST} class represents read-only balanced binary interval search tree map (from intervals to values)\n+ */\n+public class IntervalST<Value> {\n+\n+  // List representation of bst with root at index 0. For node with index x, it's left child index is (2x+1), right child index is (2x+2)\n+  //\n+  // A node with index x is represented as following structure\n+  //   {\n+  //        Interval _interval = _intervals[x];\n+  //        List<Value> _values = _values[x];\n+  //        long _max = _max[x];                   // max interval right end of subtree rooted at this node\n+  //    }\n+  private final List<Interval> _intervals;\n+  private final List<List<Value>> _values;\n+  private final List<Long> _maxs;\n+\n+  public IntervalST(Map<Value, Interval> valueToIntervalMap) {\n+    HashMap<Interval, List<Value>> intervalToValuesMap = new HashMap<>();\n+    for (Map.Entry<Value, Interval> entry : valueToIntervalMap.entrySet()) {\n+      List<Value> vals = intervalToValuesMap.putIfAbsent(entry.getValue(), new ArrayList<>());\n+      intervalToValuesMap.get(entry.getValue()).add(entry.getKey());\n+    }\n+\n+    List<Interval> sortedIntervals = new ArrayList<>(intervalToValuesMap.keySet());\n+    Collections.sort(sortedIntervals);\n+\n+    _intervals = new ArrayList<>(sortedIntervals.size());\n+    buildIntervalTree(sortedIntervals, _intervals);\n+\n+    _values = new ArrayList<>(_intervals.size());\n+    for (Interval interval: _intervals) {\n+      if (interval == null) {\n+        _values.add(null);\n+      } else {\n+        _values.add(intervalToValuesMap.get(interval));\n+      }\n+    }\n+\n+    _maxs = new ArrayList<>(_intervals.size());\n+    buildAuxiliaryInfo();\n+  }\n+\n+  private void buildIntervalTree(List<Interval> sortedIntervals, List<Interval> res) {\n+    // Build interval bst by bfs, the root for each subtree will be the median interval.\n+    // A typical balanced tree\n+    //                              [10, 20]\n+    //                              /       \\\n+    //                       [8, 15]        [12, 20]\n+    //                          /            /\n+    //                   [5, 10]       [10, 30]\n+    //\n+    // will be represented as { [10, 20], [8, 15], [12, 20], [5, 10], null, [10, 30] }\n+    if (sortedIntervals.size() == 0) {\n+      return;\n+    }\n+\n+    LinkedList<Integer> startIndexQueue = new LinkedList<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1adcfac676a45b45421f5ba6eab4ee6b1853555"}, "originalPosition": 85}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNjE0NjY4OnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/IntervalST.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQwMDoxNTowOVrOH23OMQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQwMDoxNTowOVrOH23OMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzI4OTkwNQ==", "bodyText": "!startIndexQueue.isEmpty() is redundant", "url": "https://github.com/apache/pinot/pull/6259#discussion_r527289905", "createdAt": "2020-11-20T00:15:09Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/IntervalST.java", "diffHunk": "@@ -0,0 +1,197 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner.intervalST;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * The {@code IntervalST} class represents read-only balanced binary interval search tree map (from intervals to values)\n+ */\n+public class IntervalST<Value> {\n+\n+  // List representation of bst with root at index 0. For node with index x, it's left child index is (2x+1), right child index is (2x+2)\n+  //\n+  // A node with index x is represented as following structure\n+  //   {\n+  //        Interval _interval = _intervals[x];\n+  //        List<Value> _values = _values[x];\n+  //        long _max = _max[x];                   // max interval right end of subtree rooted at this node\n+  //    }\n+  private final List<Interval> _intervals;\n+  private final List<List<Value>> _values;\n+  private final List<Long> _maxs;\n+\n+  public IntervalST(Map<Value, Interval> valueToIntervalMap) {\n+    HashMap<Interval, List<Value>> intervalToValuesMap = new HashMap<>();\n+    for (Map.Entry<Value, Interval> entry : valueToIntervalMap.entrySet()) {\n+      List<Value> vals = intervalToValuesMap.putIfAbsent(entry.getValue(), new ArrayList<>());\n+      intervalToValuesMap.get(entry.getValue()).add(entry.getKey());\n+    }\n+\n+    List<Interval> sortedIntervals = new ArrayList<>(intervalToValuesMap.keySet());\n+    Collections.sort(sortedIntervals);\n+\n+    _intervals = new ArrayList<>(sortedIntervals.size());\n+    buildIntervalTree(sortedIntervals, _intervals);\n+\n+    _values = new ArrayList<>(_intervals.size());\n+    for (Interval interval: _intervals) {\n+      if (interval == null) {\n+        _values.add(null);\n+      } else {\n+        _values.add(intervalToValuesMap.get(interval));\n+      }\n+    }\n+\n+    _maxs = new ArrayList<>(_intervals.size());\n+    buildAuxiliaryInfo();\n+  }\n+\n+  private void buildIntervalTree(List<Interval> sortedIntervals, List<Interval> res) {\n+    // Build interval bst by bfs, the root for each subtree will be the median interval.\n+    // A typical balanced tree\n+    //                              [10, 20]\n+    //                              /       \\\n+    //                       [8, 15]        [12, 20]\n+    //                          /            /\n+    //                   [5, 10]       [10, 30]\n+    //\n+    // will be represented as { [10, 20], [8, 15], [12, 20], [5, 10], null, [10, 30] }\n+    if (sortedIntervals.size() == 0) {\n+      return;\n+    }\n+\n+    LinkedList<Integer> startIndexQueue = new LinkedList<>();\n+    LinkedList<Integer> endIndexQueue = new LinkedList<>();\n+    startIndexQueue.addLast(0);\n+    endIndexQueue.addLast(sortedIntervals.size());\n+    int count = 0;\n+    while (!startIndexQueue.isEmpty() && count < sortedIntervals.size()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1adcfac676a45b45421f5ba6eab4ee6b1853555"}, "originalPosition": 90}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwNjIzNTI5OnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/IntervalST.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQwMDozMjo1NlrOH24KNw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQxNzozODoyN1rOH5N8Hg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzMwNTI3MQ==", "bodyText": "I think we can simplify the algorithm as followings:\n- Check root\n- If (left.max >= interval.min) search left\n- If (root.min <= interval.max) search right\n\nThen we don't need to maintain these extra flags, and it is actually more efficient because if left.max >= interval.min and you cannot find intersections on left subtree, then root.min is always larger than interval.max", "url": "https://github.com/apache/pinot/pull/6259#discussion_r527305271", "createdAt": "2020-11-20T00:32:56Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/IntervalST.java", "diffHunk": "@@ -0,0 +1,197 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner.intervalST;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * The {@code IntervalST} class represents read-only balanced binary interval search tree map (from intervals to values)\n+ */\n+public class IntervalST<Value> {\n+\n+  // List representation of bst with root at index 0. For node with index x, it's left child index is (2x+1), right child index is (2x+2)\n+  //\n+  // A node with index x is represented as following structure\n+  //   {\n+  //        Interval _interval = _intervals[x];\n+  //        List<Value> _values = _values[x];\n+  //        long _max = _max[x];                   // max interval right end of subtree rooted at this node\n+  //    }\n+  private final List<Interval> _intervals;\n+  private final List<List<Value>> _values;\n+  private final List<Long> _maxs;\n+\n+  public IntervalST(Map<Value, Interval> valueToIntervalMap) {\n+    HashMap<Interval, List<Value>> intervalToValuesMap = new HashMap<>();\n+    for (Map.Entry<Value, Interval> entry : valueToIntervalMap.entrySet()) {\n+      List<Value> vals = intervalToValuesMap.putIfAbsent(entry.getValue(), new ArrayList<>());\n+      intervalToValuesMap.get(entry.getValue()).add(entry.getKey());\n+    }\n+\n+    List<Interval> sortedIntervals = new ArrayList<>(intervalToValuesMap.keySet());\n+    Collections.sort(sortedIntervals);\n+\n+    _intervals = new ArrayList<>(sortedIntervals.size());\n+    buildIntervalTree(sortedIntervals, _intervals);\n+\n+    _values = new ArrayList<>(_intervals.size());\n+    for (Interval interval: _intervals) {\n+      if (interval == null) {\n+        _values.add(null);\n+      } else {\n+        _values.add(intervalToValuesMap.get(interval));\n+      }\n+    }\n+\n+    _maxs = new ArrayList<>(_intervals.size());\n+    buildAuxiliaryInfo();\n+  }\n+\n+  private void buildIntervalTree(List<Interval> sortedIntervals, List<Interval> res) {\n+    // Build interval bst by bfs, the root for each subtree will be the median interval.\n+    // A typical balanced tree\n+    //                              [10, 20]\n+    //                              /       \\\n+    //                       [8, 15]        [12, 20]\n+    //                          /            /\n+    //                   [5, 10]       [10, 30]\n+    //\n+    // will be represented as { [10, 20], [8, 15], [12, 20], [5, 10], null, [10, 30] }\n+    if (sortedIntervals.size() == 0) {\n+      return;\n+    }\n+\n+    LinkedList<Integer> startIndexQueue = new LinkedList<>();\n+    LinkedList<Integer> endIndexQueue = new LinkedList<>();\n+    startIndexQueue.addLast(0);\n+    endIndexQueue.addLast(sortedIntervals.size());\n+    int count = 0;\n+    while (!startIndexQueue.isEmpty() && count < sortedIntervals.size()) {\n+      int start = startIndexQueue.pollFirst();\n+      int end = endIndexQueue.pollFirst();\n+      if (start < end) {\n+        int mid = start + (end - start) / 2;\n+        res.add(sortedIntervals.get(mid));\n+        count++;\n+        startIndexQueue.addLast(start);\n+        endIndexQueue.addLast(mid);\n+        startIndexQueue.addLast(mid + 1);\n+        endIndexQueue.addLast(end);\n+      } else {\n+        res.add(null);\n+      }\n+    }\n+  }\n+\n+  private void buildAuxiliaryInfo() {\n+    // Initialize and build max info for the interval tree by dfs\n+    for (int i = 0; i < _intervals.size(); i++) {\n+      _maxs.add(Long.MIN_VALUE);\n+    }\n+    buildAuxiliaryInfo(0);\n+  }\n+\n+  private void buildAuxiliaryInfo(int nodeIndex) {\n+    if (!hasNode(nodeIndex)) {\n+      return;\n+    }\n+\n+    int leftChildIndex = getLeftChildIndex(nodeIndex);\n+    int rightChildIndex = getRightChildIndex(nodeIndex);\n+\n+    buildAuxiliaryInfo(leftChildIndex);\n+    buildAuxiliaryInfo(rightChildIndex);\n+\n+    long max = _intervals.get(nodeIndex)._max;\n+    max = Math.max(getMax(rightChildIndex), Math.max(max, getMax(leftChildIndex)));\n+    _maxs.set(nodeIndex, max);\n+  }\n+\n+  private int getLeftChildIndex(int nodeIndex) {\n+    return nodeIndex * 2 + 1;\n+  }\n+\n+  private int getRightChildIndex(int nodeIndex) {\n+    return  nodeIndex * 2 + 2;\n+  }\n+\n+  private long getMax(int index) {\n+    if (!hasNode(index)) {\n+      return Long.MIN_VALUE;\n+    }\n+    return _maxs.get(index);\n+  }\n+\n+  /**\n+   * Find all values whose intervals intersect with the input interval.\n+   *\n+   * @param searchInterval search interval\n+   * @return list of all qualified values.\n+   */\n+  public List<Value> searchAll(Interval searchInterval) {\n+    List<Value> list = new ArrayList<>();\n+    if (searchInterval == null) {\n+      return list;\n+    }\n+    searchAll(0, searchInterval, list);\n+    return list;\n+  }\n+\n+  private boolean searchAll(int nodeIndex, Interval searchInterval, List<Value> list) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1adcfac676a45b45421f5ba6eab4ee6b1853555"}, "originalPosition": 161}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTc1OTI2Mg==", "bodyText": "Yes, I agree. root.min <= interval.max should be a tighter condition.", "url": "https://github.com/apache/pinot/pull/6259#discussion_r529759262", "createdAt": "2020-11-24T17:38:27Z", "author": {"login": "jtao15"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/intervalST/IntervalST.java", "diffHunk": "@@ -0,0 +1,197 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner.intervalST;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Map;\n+\n+/**\n+ * The {@code IntervalST} class represents read-only balanced binary interval search tree map (from intervals to values)\n+ */\n+public class IntervalST<Value> {\n+\n+  // List representation of bst with root at index 0. For node with index x, it's left child index is (2x+1), right child index is (2x+2)\n+  //\n+  // A node with index x is represented as following structure\n+  //   {\n+  //        Interval _interval = _intervals[x];\n+  //        List<Value> _values = _values[x];\n+  //        long _max = _max[x];                   // max interval right end of subtree rooted at this node\n+  //    }\n+  private final List<Interval> _intervals;\n+  private final List<List<Value>> _values;\n+  private final List<Long> _maxs;\n+\n+  public IntervalST(Map<Value, Interval> valueToIntervalMap) {\n+    HashMap<Interval, List<Value>> intervalToValuesMap = new HashMap<>();\n+    for (Map.Entry<Value, Interval> entry : valueToIntervalMap.entrySet()) {\n+      List<Value> vals = intervalToValuesMap.putIfAbsent(entry.getValue(), new ArrayList<>());\n+      intervalToValuesMap.get(entry.getValue()).add(entry.getKey());\n+    }\n+\n+    List<Interval> sortedIntervals = new ArrayList<>(intervalToValuesMap.keySet());\n+    Collections.sort(sortedIntervals);\n+\n+    _intervals = new ArrayList<>(sortedIntervals.size());\n+    buildIntervalTree(sortedIntervals, _intervals);\n+\n+    _values = new ArrayList<>(_intervals.size());\n+    for (Interval interval: _intervals) {\n+      if (interval == null) {\n+        _values.add(null);\n+      } else {\n+        _values.add(intervalToValuesMap.get(interval));\n+      }\n+    }\n+\n+    _maxs = new ArrayList<>(_intervals.size());\n+    buildAuxiliaryInfo();\n+  }\n+\n+  private void buildIntervalTree(List<Interval> sortedIntervals, List<Interval> res) {\n+    // Build interval bst by bfs, the root for each subtree will be the median interval.\n+    // A typical balanced tree\n+    //                              [10, 20]\n+    //                              /       \\\n+    //                       [8, 15]        [12, 20]\n+    //                          /            /\n+    //                   [5, 10]       [10, 30]\n+    //\n+    // will be represented as { [10, 20], [8, 15], [12, 20], [5, 10], null, [10, 30] }\n+    if (sortedIntervals.size() == 0) {\n+      return;\n+    }\n+\n+    LinkedList<Integer> startIndexQueue = new LinkedList<>();\n+    LinkedList<Integer> endIndexQueue = new LinkedList<>();\n+    startIndexQueue.addLast(0);\n+    endIndexQueue.addLast(sortedIntervals.size());\n+    int count = 0;\n+    while (!startIndexQueue.isEmpty() && count < sortedIntervals.size()) {\n+      int start = startIndexQueue.pollFirst();\n+      int end = endIndexQueue.pollFirst();\n+      if (start < end) {\n+        int mid = start + (end - start) / 2;\n+        res.add(sortedIntervals.get(mid));\n+        count++;\n+        startIndexQueue.addLast(start);\n+        endIndexQueue.addLast(mid);\n+        startIndexQueue.addLast(mid + 1);\n+        endIndexQueue.addLast(end);\n+      } else {\n+        res.add(null);\n+      }\n+    }\n+  }\n+\n+  private void buildAuxiliaryInfo() {\n+    // Initialize and build max info for the interval tree by dfs\n+    for (int i = 0; i < _intervals.size(); i++) {\n+      _maxs.add(Long.MIN_VALUE);\n+    }\n+    buildAuxiliaryInfo(0);\n+  }\n+\n+  private void buildAuxiliaryInfo(int nodeIndex) {\n+    if (!hasNode(nodeIndex)) {\n+      return;\n+    }\n+\n+    int leftChildIndex = getLeftChildIndex(nodeIndex);\n+    int rightChildIndex = getRightChildIndex(nodeIndex);\n+\n+    buildAuxiliaryInfo(leftChildIndex);\n+    buildAuxiliaryInfo(rightChildIndex);\n+\n+    long max = _intervals.get(nodeIndex)._max;\n+    max = Math.max(getMax(rightChildIndex), Math.max(max, getMax(leftChildIndex)));\n+    _maxs.set(nodeIndex, max);\n+  }\n+\n+  private int getLeftChildIndex(int nodeIndex) {\n+    return nodeIndex * 2 + 1;\n+  }\n+\n+  private int getRightChildIndex(int nodeIndex) {\n+    return  nodeIndex * 2 + 2;\n+  }\n+\n+  private long getMax(int index) {\n+    if (!hasNode(index)) {\n+      return Long.MIN_VALUE;\n+    }\n+    return _maxs.get(index);\n+  }\n+\n+  /**\n+   * Find all values whose intervals intersect with the input interval.\n+   *\n+   * @param searchInterval search interval\n+   * @return list of all qualified values.\n+   */\n+  public List<Value> searchAll(Interval searchInterval) {\n+    List<Value> list = new ArrayList<>();\n+    if (searchInterval == null) {\n+      return list;\n+    }\n+    searchAll(0, searchInterval, list);\n+    return list;\n+  }\n+\n+  private boolean searchAll(int nodeIndex, Interval searchInterval, List<Value> list) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzMwNTI3MQ=="}, "originalCommit": {"oid": "f1adcfac676a45b45421f5ba6eab4ee6b1853555"}, "originalPosition": 161}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0MzkzNjcyOnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMDo0ODowM1rOH8TtMQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMDo0ODowM1rOH8TtMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjk5OTQ3Mw==", "bodyText": "Why do we need this check? We should not need the time unit information", "url": "https://github.com/apache/pinot/pull/6259#discussion_r532999473", "createdAt": "2020-12-01T00:48:03Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,344 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.interval.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.interval.IntervalTree;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeSegmentPruner.class);\n+  private static final long MIN_START_TIME = 0;\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final Interval DEFAULT_INTERVAL = new Interval(MIN_START_TIME, MAX_END_TIME);\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore<ZNRecord> _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final DateTimeFormatSpec _timeFormatSpec;\n+\n+  private volatile IntervalTree _intervalTree;\n+  private final Map<String, Interval> _intervalMap = new HashMap<>();\n+\n+  public TimeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    _timeFormatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    Preconditions.checkNotNull(_timeFormatSpec.getColumnUnit(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "787ee45ccc48dc0c099e6e3da74b7a95b14a527c"}, "originalPosition": 84}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0Mzk1MzEyOnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMDo1NDo1NlrOH8T2ew==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMDo1NDo1NlrOH8T2ew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAwMTg1MQ==", "bodyText": "We can check for empty intervals and directly return empty list", "url": "https://github.com/apache/pinot/pull/6259#discussion_r533001851", "createdAt": "2020-12-01T00:54:56Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,344 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.interval.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.interval.IntervalTree;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeSegmentPruner.class);\n+  private static final long MIN_START_TIME = 0;\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final Interval DEFAULT_INTERVAL = new Interval(MIN_START_TIME, MAX_END_TIME);\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore<ZNRecord> _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final DateTimeFormatSpec _timeFormatSpec;\n+\n+  private volatile IntervalTree _intervalTree;\n+  private final Map<String, Interval> _intervalMap = new HashMap<>();\n+\n+  public TimeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    _timeFormatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    Preconditions.checkNotNull(_timeFormatSpec.getColumnUnit(),\n+        \"Time unit must be configured in the field spec for time column: %s of table: %s\", _timeColumn,\n+        _tableNameWithType);\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    // Bulk load time info for all online segments\n+    int numSegments = onlineSegments.size();\n+    List<String> segments = new ArrayList<>(numSegments);\n+    List<String> segmentZKMetadataPaths = new ArrayList<>(numSegments);\n+    for (String segment : segments) {\n+      segments.add(segment);\n+      segmentZKMetadataPaths.add(_segmentZKMetadataPathPrefix + segment);\n+    }\n+    List<ZNRecord> znRecords = _propertyStore.get(segmentZKMetadataPaths, null, AccessOption.PERSISTENT, false);\n+    for (int i = 0; i < numSegments; i++) {\n+      String segment = segments.get(i);\n+      Interval interval = extractIntervalFromSegmentZKMetaZNRecord(segment, znRecords.get(i));\n+      _intervalMap.put(segment, interval);\n+    }\n+    _intervalTree = new IntervalTree<>(_intervalMap);\n+  }\n+\n+  private Interval extractIntervalFromSegmentZKMetaZNRecord(String segment, @Nullable ZNRecord znRecord) {\n+    // Segments without metadata or with invalid time interval will be set with [min_start, max_end] and will not be pruned\n+    if (znRecord == null) {\n+      LOGGER.warn(\"Failed to find segment ZK metadata for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return DEFAULT_INTERVAL;\n+    }\n+\n+    long startTime = znRecord.getLongField(CommonConstants.Segment.START_TIME, -1);\n+    long endTime = znRecord.getLongField(CommonConstants.Segment.END_TIME, -1);\n+    if (startTime < 0 || endTime < 0 || startTime > endTime) {\n+      LOGGER.warn(\"Failed to find valid time interval for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return DEFAULT_INTERVAL;\n+    }\n+\n+    TimeUnit timeUnit = znRecord.getEnumField(CommonConstants.Segment.TIME_UNIT, TimeUnit.class, TimeUnit.DAYS);\n+    return new Interval(timeUnit.toMillis(startTime), timeUnit.toMillis(endTime));\n+  }\n+\n+  @Override\n+  public synchronized void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    // NOTE: We don't update all the segment ZK metadata for every external view change, but only the new added/removed\n+    //       ones. The refreshed segment ZK metadata change won't be picked up.\n+    for (String segment : onlineSegments) {\n+      _intervalMap.computeIfAbsent(segment, k -> extractIntervalFromSegmentZKMetaZNRecord(k,\n+          _propertyStore.get(_segmentZKMetadataPathPrefix + k, null, AccessOption.PERSISTENT)));\n+    }\n+    _intervalMap.keySet().retainAll(onlineSegments);\n+    _intervalTree = new IntervalTree<>(_intervalMap);\n+  }\n+\n+\n+  @Override\n+  public synchronized void refreshSegment(String segment) {\n+    Interval interval = extractIntervalFromSegmentZKMetaZNRecord(segment, _propertyStore.get(_segmentZKMetadataPathPrefix + segment, null, AccessOption.PERSISTENT));\n+    _intervalMap.put(segment, interval);\n+    _intervalTree = new IntervalTree<>(_intervalMap);\n+  }\n+\n+  /**\n+   * NOTE: Pruning is done by searching _intervalTree based on request time interval and check if the results\n+   *       are in the input segments. By doing so we will have run time O(M * logN) (N: # of all online segments,\n+   *       M: # of qualified intersected segments).\n+   */\n+  @Override\n+  public Set<String> prune(BrokerRequest brokerRequest, Set<String> segments) {\n+    IntervalTree<String> intervalTree = _intervalTree;\n+    FilterQueryTree filterQueryTree = RequestUtils.generateFilterQueryTree(brokerRequest);\n+    if (filterQueryTree == null) {\n+      return segments;\n+    }\n+    List<Interval> intervals = getFilterTimeIntervals(filterQueryTree);\n+    if (intervals == null) { // cannot prune based on time for input request\n+      return segments;\n+    }\n+    if (intervals.isEmpty()) { // invalid query time interval\n+      return Collections.emptySet();\n+    }\n+\n+    Set<String> selectedSegments = new HashSet<>();\n+    for (Interval interval : intervals) {\n+      for (String segment : intervalTree.searchAll(interval)) {\n+        if (segments.contains(segment)) {\n+          selectedSegments.add(segment);\n+        }\n+      }\n+    }\n+    return selectedSegments;\n+  }\n+\n+  /**\n+   * @return Null if no time condition or cannot filter base on the condition (e.g. 'SELECT * from myTable where time < 50 OR firstName = Jason')\n+   * @return Empty list if time condition is specified but invalid (e.g. 'SELECT * from myTable where time < 50 AND time > 100')\n+   */\n+  @Nullable\n+  private List<Interval> getFilterTimeIntervals(FilterQueryTree filterQueryTree) {\n+    switch (filterQueryTree.getOperator()) {\n+      case AND:\n+        List<List<Interval>> andIntervals = new ArrayList<>();\n+        for (FilterQueryTree child : filterQueryTree.getChildren()) {\n+          List<Interval> childIntervals = getFilterTimeIntervals(child);\n+          if (childIntervals != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "787ee45ccc48dc0c099e6e3da74b7a95b14a527c"}, "originalPosition": 188}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0Mzk2MjQ1OnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMDo1OTowOVrOH8T7tw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQwODoyMTowOVrOH9PNDQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAwMzE5MQ==", "bodyText": "Please add some comments here on why it should return null for empty intervals list. IMO handle it in the case AND: is more clear, up to you", "url": "https://github.com/apache/pinot/pull/6259#discussion_r533003191", "createdAt": "2020-12-01T00:59:09Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,344 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.interval.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.interval.IntervalTree;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeSegmentPruner.class);\n+  private static final long MIN_START_TIME = 0;\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final Interval DEFAULT_INTERVAL = new Interval(MIN_START_TIME, MAX_END_TIME);\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore<ZNRecord> _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final DateTimeFormatSpec _timeFormatSpec;\n+\n+  private volatile IntervalTree _intervalTree;\n+  private final Map<String, Interval> _intervalMap = new HashMap<>();\n+\n+  public TimeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    _timeFormatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    Preconditions.checkNotNull(_timeFormatSpec.getColumnUnit(),\n+        \"Time unit must be configured in the field spec for time column: %s of table: %s\", _timeColumn,\n+        _tableNameWithType);\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    // Bulk load time info for all online segments\n+    int numSegments = onlineSegments.size();\n+    List<String> segments = new ArrayList<>(numSegments);\n+    List<String> segmentZKMetadataPaths = new ArrayList<>(numSegments);\n+    for (String segment : segments) {\n+      segments.add(segment);\n+      segmentZKMetadataPaths.add(_segmentZKMetadataPathPrefix + segment);\n+    }\n+    List<ZNRecord> znRecords = _propertyStore.get(segmentZKMetadataPaths, null, AccessOption.PERSISTENT, false);\n+    for (int i = 0; i < numSegments; i++) {\n+      String segment = segments.get(i);\n+      Interval interval = extractIntervalFromSegmentZKMetaZNRecord(segment, znRecords.get(i));\n+      _intervalMap.put(segment, interval);\n+    }\n+    _intervalTree = new IntervalTree<>(_intervalMap);\n+  }\n+\n+  private Interval extractIntervalFromSegmentZKMetaZNRecord(String segment, @Nullable ZNRecord znRecord) {\n+    // Segments without metadata or with invalid time interval will be set with [min_start, max_end] and will not be pruned\n+    if (znRecord == null) {\n+      LOGGER.warn(\"Failed to find segment ZK metadata for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return DEFAULT_INTERVAL;\n+    }\n+\n+    long startTime = znRecord.getLongField(CommonConstants.Segment.START_TIME, -1);\n+    long endTime = znRecord.getLongField(CommonConstants.Segment.END_TIME, -1);\n+    if (startTime < 0 || endTime < 0 || startTime > endTime) {\n+      LOGGER.warn(\"Failed to find valid time interval for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return DEFAULT_INTERVAL;\n+    }\n+\n+    TimeUnit timeUnit = znRecord.getEnumField(CommonConstants.Segment.TIME_UNIT, TimeUnit.class, TimeUnit.DAYS);\n+    return new Interval(timeUnit.toMillis(startTime), timeUnit.toMillis(endTime));\n+  }\n+\n+  @Override\n+  public synchronized void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    // NOTE: We don't update all the segment ZK metadata for every external view change, but only the new added/removed\n+    //       ones. The refreshed segment ZK metadata change won't be picked up.\n+    for (String segment : onlineSegments) {\n+      _intervalMap.computeIfAbsent(segment, k -> extractIntervalFromSegmentZKMetaZNRecord(k,\n+          _propertyStore.get(_segmentZKMetadataPathPrefix + k, null, AccessOption.PERSISTENT)));\n+    }\n+    _intervalMap.keySet().retainAll(onlineSegments);\n+    _intervalTree = new IntervalTree<>(_intervalMap);\n+  }\n+\n+\n+  @Override\n+  public synchronized void refreshSegment(String segment) {\n+    Interval interval = extractIntervalFromSegmentZKMetaZNRecord(segment, _propertyStore.get(_segmentZKMetadataPathPrefix + segment, null, AccessOption.PERSISTENT));\n+    _intervalMap.put(segment, interval);\n+    _intervalTree = new IntervalTree<>(_intervalMap);\n+  }\n+\n+  /**\n+   * NOTE: Pruning is done by searching _intervalTree based on request time interval and check if the results\n+   *       are in the input segments. By doing so we will have run time O(M * logN) (N: # of all online segments,\n+   *       M: # of qualified intersected segments).\n+   */\n+  @Override\n+  public Set<String> prune(BrokerRequest brokerRequest, Set<String> segments) {\n+    IntervalTree<String> intervalTree = _intervalTree;\n+    FilterQueryTree filterQueryTree = RequestUtils.generateFilterQueryTree(brokerRequest);\n+    if (filterQueryTree == null) {\n+      return segments;\n+    }\n+    List<Interval> intervals = getFilterTimeIntervals(filterQueryTree);\n+    if (intervals == null) { // cannot prune based on time for input request\n+      return segments;\n+    }\n+    if (intervals.isEmpty()) { // invalid query time interval\n+      return Collections.emptySet();\n+    }\n+\n+    Set<String> selectedSegments = new HashSet<>();\n+    for (Interval interval : intervals) {\n+      for (String segment : intervalTree.searchAll(interval)) {\n+        if (segments.contains(segment)) {\n+          selectedSegments.add(segment);\n+        }\n+      }\n+    }\n+    return selectedSegments;\n+  }\n+\n+  /**\n+   * @return Null if no time condition or cannot filter base on the condition (e.g. 'SELECT * from myTable where time < 50 OR firstName = Jason')\n+   * @return Empty list if time condition is specified but invalid (e.g. 'SELECT * from myTable where time < 50 AND time > 100')\n+   */\n+  @Nullable\n+  private List<Interval> getFilterTimeIntervals(FilterQueryTree filterQueryTree) {\n+    switch (filterQueryTree.getOperator()) {\n+      case AND:\n+        List<List<Interval>> andIntervals = new ArrayList<>();\n+        for (FilterQueryTree child : filterQueryTree.getChildren()) {\n+          List<Interval> childIntervals = getFilterTimeIntervals(child);\n+          if (childIntervals != null) {\n+            andIntervals.add(childIntervals);\n+          }\n+        }\n+        return getIntersectionSortedIntervals(andIntervals);\n+      case OR:\n+        List<List<Interval>> orIntervals = new ArrayList<>();\n+        for (FilterQueryTree child : filterQueryTree.getChildren()) {\n+          List<Interval> childIntervals = getFilterTimeIntervals(child);\n+          if (childIntervals == null) {\n+            return null;\n+          } else {\n+            orIntervals.add(childIntervals);\n+          }\n+        }\n+        return getUnionSortedIntervals(orIntervals);\n+      case EQUALITY:\n+        if (filterQueryTree.getColumn().equals(_timeColumn)) {\n+          long timeStamp = _timeFormatSpec.fromFormatToMillis(filterQueryTree.getValue().get(0));\n+          return Collections.singletonList(new Interval(timeStamp, timeStamp));\n+        }\n+        return null;\n+      case RANGE:\n+        if (filterQueryTree.getColumn().equals(_timeColumn)) {\n+          return parseInterval(filterQueryTree.getValue());\n+        }\n+        return null;\n+      default:\n+        return null;\n+    }\n+  }\n+\n+  private List<Interval> getIntersectionSortedIntervals(List<List<Interval>> intervals) {\n+    // Requires input intervals are sorted, the return intervals will be sorted\n+    if (intervals.isEmpty()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "787ee45ccc48dc0c099e6e3da74b7a95b14a527c"}, "originalPosition": 222}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzk3NDI4NQ==", "bodyText": "Moved the condition to caller.", "url": "https://github.com/apache/pinot/pull/6259#discussion_r533974285", "createdAt": "2020-12-02T08:21:09Z", "author": {"login": "jtao15"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,344 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.interval.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.interval.IntervalTree;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeSegmentPruner.class);\n+  private static final long MIN_START_TIME = 0;\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final Interval DEFAULT_INTERVAL = new Interval(MIN_START_TIME, MAX_END_TIME);\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore<ZNRecord> _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final DateTimeFormatSpec _timeFormatSpec;\n+\n+  private volatile IntervalTree _intervalTree;\n+  private final Map<String, Interval> _intervalMap = new HashMap<>();\n+\n+  public TimeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    _timeFormatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    Preconditions.checkNotNull(_timeFormatSpec.getColumnUnit(),\n+        \"Time unit must be configured in the field spec for time column: %s of table: %s\", _timeColumn,\n+        _tableNameWithType);\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    // Bulk load time info for all online segments\n+    int numSegments = onlineSegments.size();\n+    List<String> segments = new ArrayList<>(numSegments);\n+    List<String> segmentZKMetadataPaths = new ArrayList<>(numSegments);\n+    for (String segment : segments) {\n+      segments.add(segment);\n+      segmentZKMetadataPaths.add(_segmentZKMetadataPathPrefix + segment);\n+    }\n+    List<ZNRecord> znRecords = _propertyStore.get(segmentZKMetadataPaths, null, AccessOption.PERSISTENT, false);\n+    for (int i = 0; i < numSegments; i++) {\n+      String segment = segments.get(i);\n+      Interval interval = extractIntervalFromSegmentZKMetaZNRecord(segment, znRecords.get(i));\n+      _intervalMap.put(segment, interval);\n+    }\n+    _intervalTree = new IntervalTree<>(_intervalMap);\n+  }\n+\n+  private Interval extractIntervalFromSegmentZKMetaZNRecord(String segment, @Nullable ZNRecord znRecord) {\n+    // Segments without metadata or with invalid time interval will be set with [min_start, max_end] and will not be pruned\n+    if (znRecord == null) {\n+      LOGGER.warn(\"Failed to find segment ZK metadata for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return DEFAULT_INTERVAL;\n+    }\n+\n+    long startTime = znRecord.getLongField(CommonConstants.Segment.START_TIME, -1);\n+    long endTime = znRecord.getLongField(CommonConstants.Segment.END_TIME, -1);\n+    if (startTime < 0 || endTime < 0 || startTime > endTime) {\n+      LOGGER.warn(\"Failed to find valid time interval for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return DEFAULT_INTERVAL;\n+    }\n+\n+    TimeUnit timeUnit = znRecord.getEnumField(CommonConstants.Segment.TIME_UNIT, TimeUnit.class, TimeUnit.DAYS);\n+    return new Interval(timeUnit.toMillis(startTime), timeUnit.toMillis(endTime));\n+  }\n+\n+  @Override\n+  public synchronized void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    // NOTE: We don't update all the segment ZK metadata for every external view change, but only the new added/removed\n+    //       ones. The refreshed segment ZK metadata change won't be picked up.\n+    for (String segment : onlineSegments) {\n+      _intervalMap.computeIfAbsent(segment, k -> extractIntervalFromSegmentZKMetaZNRecord(k,\n+          _propertyStore.get(_segmentZKMetadataPathPrefix + k, null, AccessOption.PERSISTENT)));\n+    }\n+    _intervalMap.keySet().retainAll(onlineSegments);\n+    _intervalTree = new IntervalTree<>(_intervalMap);\n+  }\n+\n+\n+  @Override\n+  public synchronized void refreshSegment(String segment) {\n+    Interval interval = extractIntervalFromSegmentZKMetaZNRecord(segment, _propertyStore.get(_segmentZKMetadataPathPrefix + segment, null, AccessOption.PERSISTENT));\n+    _intervalMap.put(segment, interval);\n+    _intervalTree = new IntervalTree<>(_intervalMap);\n+  }\n+\n+  /**\n+   * NOTE: Pruning is done by searching _intervalTree based on request time interval and check if the results\n+   *       are in the input segments. By doing so we will have run time O(M * logN) (N: # of all online segments,\n+   *       M: # of qualified intersected segments).\n+   */\n+  @Override\n+  public Set<String> prune(BrokerRequest brokerRequest, Set<String> segments) {\n+    IntervalTree<String> intervalTree = _intervalTree;\n+    FilterQueryTree filterQueryTree = RequestUtils.generateFilterQueryTree(brokerRequest);\n+    if (filterQueryTree == null) {\n+      return segments;\n+    }\n+    List<Interval> intervals = getFilterTimeIntervals(filterQueryTree);\n+    if (intervals == null) { // cannot prune based on time for input request\n+      return segments;\n+    }\n+    if (intervals.isEmpty()) { // invalid query time interval\n+      return Collections.emptySet();\n+    }\n+\n+    Set<String> selectedSegments = new HashSet<>();\n+    for (Interval interval : intervals) {\n+      for (String segment : intervalTree.searchAll(interval)) {\n+        if (segments.contains(segment)) {\n+          selectedSegments.add(segment);\n+        }\n+      }\n+    }\n+    return selectedSegments;\n+  }\n+\n+  /**\n+   * @return Null if no time condition or cannot filter base on the condition (e.g. 'SELECT * from myTable where time < 50 OR firstName = Jason')\n+   * @return Empty list if time condition is specified but invalid (e.g. 'SELECT * from myTable where time < 50 AND time > 100')\n+   */\n+  @Nullable\n+  private List<Interval> getFilterTimeIntervals(FilterQueryTree filterQueryTree) {\n+    switch (filterQueryTree.getOperator()) {\n+      case AND:\n+        List<List<Interval>> andIntervals = new ArrayList<>();\n+        for (FilterQueryTree child : filterQueryTree.getChildren()) {\n+          List<Interval> childIntervals = getFilterTimeIntervals(child);\n+          if (childIntervals != null) {\n+            andIntervals.add(childIntervals);\n+          }\n+        }\n+        return getIntersectionSortedIntervals(andIntervals);\n+      case OR:\n+        List<List<Interval>> orIntervals = new ArrayList<>();\n+        for (FilterQueryTree child : filterQueryTree.getChildren()) {\n+          List<Interval> childIntervals = getFilterTimeIntervals(child);\n+          if (childIntervals == null) {\n+            return null;\n+          } else {\n+            orIntervals.add(childIntervals);\n+          }\n+        }\n+        return getUnionSortedIntervals(orIntervals);\n+      case EQUALITY:\n+        if (filterQueryTree.getColumn().equals(_timeColumn)) {\n+          long timeStamp = _timeFormatSpec.fromFormatToMillis(filterQueryTree.getValue().get(0));\n+          return Collections.singletonList(new Interval(timeStamp, timeStamp));\n+        }\n+        return null;\n+      case RANGE:\n+        if (filterQueryTree.getColumn().equals(_timeColumn)) {\n+          return parseInterval(filterQueryTree.getValue());\n+        }\n+        return null;\n+      default:\n+        return null;\n+    }\n+  }\n+\n+  private List<Interval> getIntersectionSortedIntervals(List<List<Interval>> intervals) {\n+    // Requires input intervals are sorted, the return intervals will be sorted\n+    if (intervals.isEmpty()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAwMzE5MQ=="}, "originalCommit": {"oid": "787ee45ccc48dc0c099e6e3da74b7a95b14a527c"}, "originalPosition": 222}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0Mzk2NzMzOnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMTowMDo1NFrOH8T-Yw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMTowMDo1NFrOH8T-Yw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAwMzg3NQ==", "bodyText": "Not really possible, or it should already return null under the OR case", "url": "https://github.com/apache/pinot/pull/6259#discussion_r533003875", "createdAt": "2020-12-01T01:00:54Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,344 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.interval.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.interval.IntervalTree;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeSegmentPruner.class);\n+  private static final long MIN_START_TIME = 0;\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final Interval DEFAULT_INTERVAL = new Interval(MIN_START_TIME, MAX_END_TIME);\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore<ZNRecord> _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final DateTimeFormatSpec _timeFormatSpec;\n+\n+  private volatile IntervalTree _intervalTree;\n+  private final Map<String, Interval> _intervalMap = new HashMap<>();\n+\n+  public TimeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    _timeFormatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    Preconditions.checkNotNull(_timeFormatSpec.getColumnUnit(),\n+        \"Time unit must be configured in the field spec for time column: %s of table: %s\", _timeColumn,\n+        _tableNameWithType);\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    // Bulk load time info for all online segments\n+    int numSegments = onlineSegments.size();\n+    List<String> segments = new ArrayList<>(numSegments);\n+    List<String> segmentZKMetadataPaths = new ArrayList<>(numSegments);\n+    for (String segment : segments) {\n+      segments.add(segment);\n+      segmentZKMetadataPaths.add(_segmentZKMetadataPathPrefix + segment);\n+    }\n+    List<ZNRecord> znRecords = _propertyStore.get(segmentZKMetadataPaths, null, AccessOption.PERSISTENT, false);\n+    for (int i = 0; i < numSegments; i++) {\n+      String segment = segments.get(i);\n+      Interval interval = extractIntervalFromSegmentZKMetaZNRecord(segment, znRecords.get(i));\n+      _intervalMap.put(segment, interval);\n+    }\n+    _intervalTree = new IntervalTree<>(_intervalMap);\n+  }\n+\n+  private Interval extractIntervalFromSegmentZKMetaZNRecord(String segment, @Nullable ZNRecord znRecord) {\n+    // Segments without metadata or with invalid time interval will be set with [min_start, max_end] and will not be pruned\n+    if (znRecord == null) {\n+      LOGGER.warn(\"Failed to find segment ZK metadata for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return DEFAULT_INTERVAL;\n+    }\n+\n+    long startTime = znRecord.getLongField(CommonConstants.Segment.START_TIME, -1);\n+    long endTime = znRecord.getLongField(CommonConstants.Segment.END_TIME, -1);\n+    if (startTime < 0 || endTime < 0 || startTime > endTime) {\n+      LOGGER.warn(\"Failed to find valid time interval for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return DEFAULT_INTERVAL;\n+    }\n+\n+    TimeUnit timeUnit = znRecord.getEnumField(CommonConstants.Segment.TIME_UNIT, TimeUnit.class, TimeUnit.DAYS);\n+    return new Interval(timeUnit.toMillis(startTime), timeUnit.toMillis(endTime));\n+  }\n+\n+  @Override\n+  public synchronized void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    // NOTE: We don't update all the segment ZK metadata for every external view change, but only the new added/removed\n+    //       ones. The refreshed segment ZK metadata change won't be picked up.\n+    for (String segment : onlineSegments) {\n+      _intervalMap.computeIfAbsent(segment, k -> extractIntervalFromSegmentZKMetaZNRecord(k,\n+          _propertyStore.get(_segmentZKMetadataPathPrefix + k, null, AccessOption.PERSISTENT)));\n+    }\n+    _intervalMap.keySet().retainAll(onlineSegments);\n+    _intervalTree = new IntervalTree<>(_intervalMap);\n+  }\n+\n+\n+  @Override\n+  public synchronized void refreshSegment(String segment) {\n+    Interval interval = extractIntervalFromSegmentZKMetaZNRecord(segment, _propertyStore.get(_segmentZKMetadataPathPrefix + segment, null, AccessOption.PERSISTENT));\n+    _intervalMap.put(segment, interval);\n+    _intervalTree = new IntervalTree<>(_intervalMap);\n+  }\n+\n+  /**\n+   * NOTE: Pruning is done by searching _intervalTree based on request time interval and check if the results\n+   *       are in the input segments. By doing so we will have run time O(M * logN) (N: # of all online segments,\n+   *       M: # of qualified intersected segments).\n+   */\n+  @Override\n+  public Set<String> prune(BrokerRequest brokerRequest, Set<String> segments) {\n+    IntervalTree<String> intervalTree = _intervalTree;\n+    FilterQueryTree filterQueryTree = RequestUtils.generateFilterQueryTree(brokerRequest);\n+    if (filterQueryTree == null) {\n+      return segments;\n+    }\n+    List<Interval> intervals = getFilterTimeIntervals(filterQueryTree);\n+    if (intervals == null) { // cannot prune based on time for input request\n+      return segments;\n+    }\n+    if (intervals.isEmpty()) { // invalid query time interval\n+      return Collections.emptySet();\n+    }\n+\n+    Set<String> selectedSegments = new HashSet<>();\n+    for (Interval interval : intervals) {\n+      for (String segment : intervalTree.searchAll(interval)) {\n+        if (segments.contains(segment)) {\n+          selectedSegments.add(segment);\n+        }\n+      }\n+    }\n+    return selectedSegments;\n+  }\n+\n+  /**\n+   * @return Null if no time condition or cannot filter base on the condition (e.g. 'SELECT * from myTable where time < 50 OR firstName = Jason')\n+   * @return Empty list if time condition is specified but invalid (e.g. 'SELECT * from myTable where time < 50 AND time > 100')\n+   */\n+  @Nullable\n+  private List<Interval> getFilterTimeIntervals(FilterQueryTree filterQueryTree) {\n+    switch (filterQueryTree.getOperator()) {\n+      case AND:\n+        List<List<Interval>> andIntervals = new ArrayList<>();\n+        for (FilterQueryTree child : filterQueryTree.getChildren()) {\n+          List<Interval> childIntervals = getFilterTimeIntervals(child);\n+          if (childIntervals != null) {\n+            andIntervals.add(childIntervals);\n+          }\n+        }\n+        return getIntersectionSortedIntervals(andIntervals);\n+      case OR:\n+        List<List<Interval>> orIntervals = new ArrayList<>();\n+        for (FilterQueryTree child : filterQueryTree.getChildren()) {\n+          List<Interval> childIntervals = getFilterTimeIntervals(child);\n+          if (childIntervals == null) {\n+            return null;\n+          } else {\n+            orIntervals.add(childIntervals);\n+          }\n+        }\n+        return getUnionSortedIntervals(orIntervals);\n+      case EQUALITY:\n+        if (filterQueryTree.getColumn().equals(_timeColumn)) {\n+          long timeStamp = _timeFormatSpec.fromFormatToMillis(filterQueryTree.getValue().get(0));\n+          return Collections.singletonList(new Interval(timeStamp, timeStamp));\n+        }\n+        return null;\n+      case RANGE:\n+        if (filterQueryTree.getColumn().equals(_timeColumn)) {\n+          return parseInterval(filterQueryTree.getValue());\n+        }\n+        return null;\n+      default:\n+        return null;\n+    }\n+  }\n+\n+  private List<Interval> getIntersectionSortedIntervals(List<List<Interval>> intervals) {\n+    // Requires input intervals are sorted, the return intervals will be sorted\n+    if (intervals.isEmpty()) {\n+      return null;\n+    }\n+    return getIntersectionSortedIntervals(intervals, 0, intervals.size());\n+  }\n+\n+  private List<Interval> getIntersectionSortedIntervals(List<List<Interval>> intervals, int start, int end) {\n+    if (start + 1 == end) {\n+      return intervals.get(start);\n+    }\n+\n+    int mid = start + (end - start) / 2;\n+    List<Interval> interval1 = getIntersectionSortedIntervals(intervals, start, mid);\n+    List<Interval> interval2 = getIntersectionSortedIntervals(intervals, mid, end);\n+    return getIntersectionTwoSortedIntervals(interval1, interval2);\n+  }\n+\n+  /**\n+   * Intersect two list of non-overlapping sorted intervals.\n+   * E.g. {[1, 3], [4, 6], [7, 8], [10, 10]} and {[2, 5], [7, 9]} are merged as {[2, 3], [4, 5], [7, 8]}\n+   */\n+  private List<Interval> getIntersectionTwoSortedIntervals(List<Interval> intervals1, List<Interval> intervals2) {\n+    List<Interval> res = new ArrayList<>();\n+    int size1 = intervals1.size();\n+    int size2 = intervals2.size();\n+    int i = 0;\n+    int j = 0;\n+    while (i < size1 && j < size2) {\n+      Interval interval1 = intervals1.get(i);\n+      Interval interval2 = intervals2.get(j);\n+      if (interval1.intersects(interval2)) {\n+        res.add(Interval.getIntersection(interval1, interval2));\n+      }\n+      if (interval1._max <= interval2._max) {\n+        i++;\n+      } else {\n+        j++;\n+      }\n+    }\n+    return res;\n+  }\n+\n+  private List<Interval> getUnionSortedIntervals(List<List<Interval>> intervals) {\n+    // Requires input intervals are sorted, the return intervals will be sorted\n+    if (intervals.isEmpty()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "787ee45ccc48dc0c099e6e3da74b7a95b14a527c"}, "originalPosition": 266}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0Mzk4OTQxOnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMToxMDozM1rOH8UK_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQwODoxOTo1NVrOH9PKUA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAwNzEwMg==", "bodyText": "(Critical) Don't use arbitrary whitespace as the delimiter (they might be valid as the value, also I don't think '\\0is a whitespace). You may refer toRangePredicate.java` on how to parse the range string", "url": "https://github.com/apache/pinot/pull/6259#discussion_r533007102", "createdAt": "2020-12-01T01:10:33Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,344 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.interval.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.interval.IntervalTree;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeSegmentPruner.class);\n+  private static final long MIN_START_TIME = 0;\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final Interval DEFAULT_INTERVAL = new Interval(MIN_START_TIME, MAX_END_TIME);\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore<ZNRecord> _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final DateTimeFormatSpec _timeFormatSpec;\n+\n+  private volatile IntervalTree _intervalTree;\n+  private final Map<String, Interval> _intervalMap = new HashMap<>();\n+\n+  public TimeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    _timeFormatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    Preconditions.checkNotNull(_timeFormatSpec.getColumnUnit(),\n+        \"Time unit must be configured in the field spec for time column: %s of table: %s\", _timeColumn,\n+        _tableNameWithType);\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    // Bulk load time info for all online segments\n+    int numSegments = onlineSegments.size();\n+    List<String> segments = new ArrayList<>(numSegments);\n+    List<String> segmentZKMetadataPaths = new ArrayList<>(numSegments);\n+    for (String segment : segments) {\n+      segments.add(segment);\n+      segmentZKMetadataPaths.add(_segmentZKMetadataPathPrefix + segment);\n+    }\n+    List<ZNRecord> znRecords = _propertyStore.get(segmentZKMetadataPaths, null, AccessOption.PERSISTENT, false);\n+    for (int i = 0; i < numSegments; i++) {\n+      String segment = segments.get(i);\n+      Interval interval = extractIntervalFromSegmentZKMetaZNRecord(segment, znRecords.get(i));\n+      _intervalMap.put(segment, interval);\n+    }\n+    _intervalTree = new IntervalTree<>(_intervalMap);\n+  }\n+\n+  private Interval extractIntervalFromSegmentZKMetaZNRecord(String segment, @Nullable ZNRecord znRecord) {\n+    // Segments without metadata or with invalid time interval will be set with [min_start, max_end] and will not be pruned\n+    if (znRecord == null) {\n+      LOGGER.warn(\"Failed to find segment ZK metadata for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return DEFAULT_INTERVAL;\n+    }\n+\n+    long startTime = znRecord.getLongField(CommonConstants.Segment.START_TIME, -1);\n+    long endTime = znRecord.getLongField(CommonConstants.Segment.END_TIME, -1);\n+    if (startTime < 0 || endTime < 0 || startTime > endTime) {\n+      LOGGER.warn(\"Failed to find valid time interval for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return DEFAULT_INTERVAL;\n+    }\n+\n+    TimeUnit timeUnit = znRecord.getEnumField(CommonConstants.Segment.TIME_UNIT, TimeUnit.class, TimeUnit.DAYS);\n+    return new Interval(timeUnit.toMillis(startTime), timeUnit.toMillis(endTime));\n+  }\n+\n+  @Override\n+  public synchronized void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    // NOTE: We don't update all the segment ZK metadata for every external view change, but only the new added/removed\n+    //       ones. The refreshed segment ZK metadata change won't be picked up.\n+    for (String segment : onlineSegments) {\n+      _intervalMap.computeIfAbsent(segment, k -> extractIntervalFromSegmentZKMetaZNRecord(k,\n+          _propertyStore.get(_segmentZKMetadataPathPrefix + k, null, AccessOption.PERSISTENT)));\n+    }\n+    _intervalMap.keySet().retainAll(onlineSegments);\n+    _intervalTree = new IntervalTree<>(_intervalMap);\n+  }\n+\n+\n+  @Override\n+  public synchronized void refreshSegment(String segment) {\n+    Interval interval = extractIntervalFromSegmentZKMetaZNRecord(segment, _propertyStore.get(_segmentZKMetadataPathPrefix + segment, null, AccessOption.PERSISTENT));\n+    _intervalMap.put(segment, interval);\n+    _intervalTree = new IntervalTree<>(_intervalMap);\n+  }\n+\n+  /**\n+   * NOTE: Pruning is done by searching _intervalTree based on request time interval and check if the results\n+   *       are in the input segments. By doing so we will have run time O(M * logN) (N: # of all online segments,\n+   *       M: # of qualified intersected segments).\n+   */\n+  @Override\n+  public Set<String> prune(BrokerRequest brokerRequest, Set<String> segments) {\n+    IntervalTree<String> intervalTree = _intervalTree;\n+    FilterQueryTree filterQueryTree = RequestUtils.generateFilterQueryTree(brokerRequest);\n+    if (filterQueryTree == null) {\n+      return segments;\n+    }\n+    List<Interval> intervals = getFilterTimeIntervals(filterQueryTree);\n+    if (intervals == null) { // cannot prune based on time for input request\n+      return segments;\n+    }\n+    if (intervals.isEmpty()) { // invalid query time interval\n+      return Collections.emptySet();\n+    }\n+\n+    Set<String> selectedSegments = new HashSet<>();\n+    for (Interval interval : intervals) {\n+      for (String segment : intervalTree.searchAll(interval)) {\n+        if (segments.contains(segment)) {\n+          selectedSegments.add(segment);\n+        }\n+      }\n+    }\n+    return selectedSegments;\n+  }\n+\n+  /**\n+   * @return Null if no time condition or cannot filter base on the condition (e.g. 'SELECT * from myTable where time < 50 OR firstName = Jason')\n+   * @return Empty list if time condition is specified but invalid (e.g. 'SELECT * from myTable where time < 50 AND time > 100')\n+   */\n+  @Nullable\n+  private List<Interval> getFilterTimeIntervals(FilterQueryTree filterQueryTree) {\n+    switch (filterQueryTree.getOperator()) {\n+      case AND:\n+        List<List<Interval>> andIntervals = new ArrayList<>();\n+        for (FilterQueryTree child : filterQueryTree.getChildren()) {\n+          List<Interval> childIntervals = getFilterTimeIntervals(child);\n+          if (childIntervals != null) {\n+            andIntervals.add(childIntervals);\n+          }\n+        }\n+        return getIntersectionSortedIntervals(andIntervals);\n+      case OR:\n+        List<List<Interval>> orIntervals = new ArrayList<>();\n+        for (FilterQueryTree child : filterQueryTree.getChildren()) {\n+          List<Interval> childIntervals = getFilterTimeIntervals(child);\n+          if (childIntervals == null) {\n+            return null;\n+          } else {\n+            orIntervals.add(childIntervals);\n+          }\n+        }\n+        return getUnionSortedIntervals(orIntervals);\n+      case EQUALITY:\n+        if (filterQueryTree.getColumn().equals(_timeColumn)) {\n+          long timeStamp = _timeFormatSpec.fromFormatToMillis(filterQueryTree.getValue().get(0));\n+          return Collections.singletonList(new Interval(timeStamp, timeStamp));\n+        }\n+        return null;\n+      case RANGE:\n+        if (filterQueryTree.getColumn().equals(_timeColumn)) {\n+          return parseInterval(filterQueryTree.getValue());\n+        }\n+        return null;\n+      default:\n+        return null;\n+    }\n+  }\n+\n+  private List<Interval> getIntersectionSortedIntervals(List<List<Interval>> intervals) {\n+    // Requires input intervals are sorted, the return intervals will be sorted\n+    if (intervals.isEmpty()) {\n+      return null;\n+    }\n+    return getIntersectionSortedIntervals(intervals, 0, intervals.size());\n+  }\n+\n+  private List<Interval> getIntersectionSortedIntervals(List<List<Interval>> intervals, int start, int end) {\n+    if (start + 1 == end) {\n+      return intervals.get(start);\n+    }\n+\n+    int mid = start + (end - start) / 2;\n+    List<Interval> interval1 = getIntersectionSortedIntervals(intervals, start, mid);\n+    List<Interval> interval2 = getIntersectionSortedIntervals(intervals, mid, end);\n+    return getIntersectionTwoSortedIntervals(interval1, interval2);\n+  }\n+\n+  /**\n+   * Intersect two list of non-overlapping sorted intervals.\n+   * E.g. {[1, 3], [4, 6], [7, 8], [10, 10]} and {[2, 5], [7, 9]} are merged as {[2, 3], [4, 5], [7, 8]}\n+   */\n+  private List<Interval> getIntersectionTwoSortedIntervals(List<Interval> intervals1, List<Interval> intervals2) {\n+    List<Interval> res = new ArrayList<>();\n+    int size1 = intervals1.size();\n+    int size2 = intervals2.size();\n+    int i = 0;\n+    int j = 0;\n+    while (i < size1 && j < size2) {\n+      Interval interval1 = intervals1.get(i);\n+      Interval interval2 = intervals2.get(j);\n+      if (interval1.intersects(interval2)) {\n+        res.add(Interval.getIntersection(interval1, interval2));\n+      }\n+      if (interval1._max <= interval2._max) {\n+        i++;\n+      } else {\n+        j++;\n+      }\n+    }\n+    return res;\n+  }\n+\n+  private List<Interval> getUnionSortedIntervals(List<List<Interval>> intervals) {\n+    // Requires input intervals are sorted, the return intervals will be sorted\n+    if (intervals.isEmpty()) {\n+      return null;\n+    }\n+    return getUnionSortedIntervals(intervals, 0, intervals.size());\n+  }\n+\n+  private List<Interval> getUnionSortedIntervals(List<List<Interval>> intervals, int start, int end) {\n+    if (start + 1 == end) {\n+      return intervals.get(start);\n+    }\n+\n+    int mid = start + (end - start) / 2;\n+    List<Interval> intervals1 = getUnionSortedIntervals(intervals, start, mid);\n+    List<Interval> intervals2 = getUnionSortedIntervals(intervals, mid, end);\n+    return getUnionTwoSortedIntervals(intervals1, intervals2);\n+  }\n+\n+  /**\n+   * Union two list of non-overlapping sorted intervals.\n+   * E.g. {[1, 2], [5, 7], [9, 10]} and {[2, 3], [4, 8]} are merged as {[1, 3], [4, 8], [9, 10]}\n+   */\n+  private List<Interval> getUnionTwoSortedIntervals(List<Interval> intervals1, List<Interval> intervals2) {\n+    List<Interval> res = new ArrayList<>();\n+    int size1 = intervals1.size();\n+    int size2 = intervals2.size();\n+    int i = 0;\n+    int j = 0;\n+    while (i < size1 || j < size2) {\n+      // Get the `smaller` interval\n+      Interval interval = null;\n+      if (j == size2 || i < size1 && intervals1.get(i).compareTo(intervals2.get(j)) <= 0) {\n+        interval = intervals1.get(i++);\n+      } else {\n+        interval = intervals2.get(j++);\n+      }\n+      // If not overlapping with current result, add as a new interval\n+      int resSize = res.size();\n+      if (res.isEmpty() || !interval.intersects(res.get(resSize - 1))) {\n+        res.add(interval);\n+      } else {\n+        // If overlaps with the result, union with current result\n+        res.set(resSize - 1, Interval.getUnion(interval, res.get(resSize - 1)));\n+      }\n+    }\n+    return res;\n+  }\n+\n+  /**\n+   * Parse interval to millisecond as [min, max] with both sides included.\n+   * E.g. '(* 16311]' is parsed as [0, 16311], '(1455 16311)' is parsed as [1456, 16310]\n+   */\n+  private List<Interval> parseInterval(List<String> intervalExpressions) {\n+    Preconditions.checkState(intervalExpressions != null && intervalExpressions.size() == 1,\n+        \"Cannot parse range expressions from query: %s\", intervalExpressions);\n+    long startTime = MIN_START_TIME;\n+    long endTime = MAX_END_TIME;\n+    String intervalExpression = intervalExpressions.get(0);\n+    String[] s = intervalExpression.substring(1, intervalExpression.length() - 1).split(\"\\\\s+\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "787ee45ccc48dc0c099e6e3da74b7a95b14a527c"}, "originalPosition": 323}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzk3MzU4NA==", "bodyText": "Fixed. Thank you for helping to review and improve the code, appreciate it!", "url": "https://github.com/apache/pinot/pull/6259#discussion_r533973584", "createdAt": "2020-12-02T08:19:55Z", "author": {"login": "jtao15"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,344 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.interval.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.interval.IntervalTree;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeSegmentPruner.class);\n+  private static final long MIN_START_TIME = 0;\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final Interval DEFAULT_INTERVAL = new Interval(MIN_START_TIME, MAX_END_TIME);\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore<ZNRecord> _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final DateTimeFormatSpec _timeFormatSpec;\n+\n+  private volatile IntervalTree _intervalTree;\n+  private final Map<String, Interval> _intervalMap = new HashMap<>();\n+\n+  public TimeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    _timeFormatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+    Preconditions.checkNotNull(_timeFormatSpec.getColumnUnit(),\n+        \"Time unit must be configured in the field spec for time column: %s of table: %s\", _timeColumn,\n+        _tableNameWithType);\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    // Bulk load time info for all online segments\n+    int numSegments = onlineSegments.size();\n+    List<String> segments = new ArrayList<>(numSegments);\n+    List<String> segmentZKMetadataPaths = new ArrayList<>(numSegments);\n+    for (String segment : segments) {\n+      segments.add(segment);\n+      segmentZKMetadataPaths.add(_segmentZKMetadataPathPrefix + segment);\n+    }\n+    List<ZNRecord> znRecords = _propertyStore.get(segmentZKMetadataPaths, null, AccessOption.PERSISTENT, false);\n+    for (int i = 0; i < numSegments; i++) {\n+      String segment = segments.get(i);\n+      Interval interval = extractIntervalFromSegmentZKMetaZNRecord(segment, znRecords.get(i));\n+      _intervalMap.put(segment, interval);\n+    }\n+    _intervalTree = new IntervalTree<>(_intervalMap);\n+  }\n+\n+  private Interval extractIntervalFromSegmentZKMetaZNRecord(String segment, @Nullable ZNRecord znRecord) {\n+    // Segments without metadata or with invalid time interval will be set with [min_start, max_end] and will not be pruned\n+    if (znRecord == null) {\n+      LOGGER.warn(\"Failed to find segment ZK metadata for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return DEFAULT_INTERVAL;\n+    }\n+\n+    long startTime = znRecord.getLongField(CommonConstants.Segment.START_TIME, -1);\n+    long endTime = znRecord.getLongField(CommonConstants.Segment.END_TIME, -1);\n+    if (startTime < 0 || endTime < 0 || startTime > endTime) {\n+      LOGGER.warn(\"Failed to find valid time interval for segment: {}, table: {}\", segment, _tableNameWithType);\n+      return DEFAULT_INTERVAL;\n+    }\n+\n+    TimeUnit timeUnit = znRecord.getEnumField(CommonConstants.Segment.TIME_UNIT, TimeUnit.class, TimeUnit.DAYS);\n+    return new Interval(timeUnit.toMillis(startTime), timeUnit.toMillis(endTime));\n+  }\n+\n+  @Override\n+  public synchronized void onExternalViewChange(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    // NOTE: We don't update all the segment ZK metadata for every external view change, but only the new added/removed\n+    //       ones. The refreshed segment ZK metadata change won't be picked up.\n+    for (String segment : onlineSegments) {\n+      _intervalMap.computeIfAbsent(segment, k -> extractIntervalFromSegmentZKMetaZNRecord(k,\n+          _propertyStore.get(_segmentZKMetadataPathPrefix + k, null, AccessOption.PERSISTENT)));\n+    }\n+    _intervalMap.keySet().retainAll(onlineSegments);\n+    _intervalTree = new IntervalTree<>(_intervalMap);\n+  }\n+\n+\n+  @Override\n+  public synchronized void refreshSegment(String segment) {\n+    Interval interval = extractIntervalFromSegmentZKMetaZNRecord(segment, _propertyStore.get(_segmentZKMetadataPathPrefix + segment, null, AccessOption.PERSISTENT));\n+    _intervalMap.put(segment, interval);\n+    _intervalTree = new IntervalTree<>(_intervalMap);\n+  }\n+\n+  /**\n+   * NOTE: Pruning is done by searching _intervalTree based on request time interval and check if the results\n+   *       are in the input segments. By doing so we will have run time O(M * logN) (N: # of all online segments,\n+   *       M: # of qualified intersected segments).\n+   */\n+  @Override\n+  public Set<String> prune(BrokerRequest brokerRequest, Set<String> segments) {\n+    IntervalTree<String> intervalTree = _intervalTree;\n+    FilterQueryTree filterQueryTree = RequestUtils.generateFilterQueryTree(brokerRequest);\n+    if (filterQueryTree == null) {\n+      return segments;\n+    }\n+    List<Interval> intervals = getFilterTimeIntervals(filterQueryTree);\n+    if (intervals == null) { // cannot prune based on time for input request\n+      return segments;\n+    }\n+    if (intervals.isEmpty()) { // invalid query time interval\n+      return Collections.emptySet();\n+    }\n+\n+    Set<String> selectedSegments = new HashSet<>();\n+    for (Interval interval : intervals) {\n+      for (String segment : intervalTree.searchAll(interval)) {\n+        if (segments.contains(segment)) {\n+          selectedSegments.add(segment);\n+        }\n+      }\n+    }\n+    return selectedSegments;\n+  }\n+\n+  /**\n+   * @return Null if no time condition or cannot filter base on the condition (e.g. 'SELECT * from myTable where time < 50 OR firstName = Jason')\n+   * @return Empty list if time condition is specified but invalid (e.g. 'SELECT * from myTable where time < 50 AND time > 100')\n+   */\n+  @Nullable\n+  private List<Interval> getFilterTimeIntervals(FilterQueryTree filterQueryTree) {\n+    switch (filterQueryTree.getOperator()) {\n+      case AND:\n+        List<List<Interval>> andIntervals = new ArrayList<>();\n+        for (FilterQueryTree child : filterQueryTree.getChildren()) {\n+          List<Interval> childIntervals = getFilterTimeIntervals(child);\n+          if (childIntervals != null) {\n+            andIntervals.add(childIntervals);\n+          }\n+        }\n+        return getIntersectionSortedIntervals(andIntervals);\n+      case OR:\n+        List<List<Interval>> orIntervals = new ArrayList<>();\n+        for (FilterQueryTree child : filterQueryTree.getChildren()) {\n+          List<Interval> childIntervals = getFilterTimeIntervals(child);\n+          if (childIntervals == null) {\n+            return null;\n+          } else {\n+            orIntervals.add(childIntervals);\n+          }\n+        }\n+        return getUnionSortedIntervals(orIntervals);\n+      case EQUALITY:\n+        if (filterQueryTree.getColumn().equals(_timeColumn)) {\n+          long timeStamp = _timeFormatSpec.fromFormatToMillis(filterQueryTree.getValue().get(0));\n+          return Collections.singletonList(new Interval(timeStamp, timeStamp));\n+        }\n+        return null;\n+      case RANGE:\n+        if (filterQueryTree.getColumn().equals(_timeColumn)) {\n+          return parseInterval(filterQueryTree.getValue());\n+        }\n+        return null;\n+      default:\n+        return null;\n+    }\n+  }\n+\n+  private List<Interval> getIntersectionSortedIntervals(List<List<Interval>> intervals) {\n+    // Requires input intervals are sorted, the return intervals will be sorted\n+    if (intervals.isEmpty()) {\n+      return null;\n+    }\n+    return getIntersectionSortedIntervals(intervals, 0, intervals.size());\n+  }\n+\n+  private List<Interval> getIntersectionSortedIntervals(List<List<Interval>> intervals, int start, int end) {\n+    if (start + 1 == end) {\n+      return intervals.get(start);\n+    }\n+\n+    int mid = start + (end - start) / 2;\n+    List<Interval> interval1 = getIntersectionSortedIntervals(intervals, start, mid);\n+    List<Interval> interval2 = getIntersectionSortedIntervals(intervals, mid, end);\n+    return getIntersectionTwoSortedIntervals(interval1, interval2);\n+  }\n+\n+  /**\n+   * Intersect two list of non-overlapping sorted intervals.\n+   * E.g. {[1, 3], [4, 6], [7, 8], [10, 10]} and {[2, 5], [7, 9]} are merged as {[2, 3], [4, 5], [7, 8]}\n+   */\n+  private List<Interval> getIntersectionTwoSortedIntervals(List<Interval> intervals1, List<Interval> intervals2) {\n+    List<Interval> res = new ArrayList<>();\n+    int size1 = intervals1.size();\n+    int size2 = intervals2.size();\n+    int i = 0;\n+    int j = 0;\n+    while (i < size1 && j < size2) {\n+      Interval interval1 = intervals1.get(i);\n+      Interval interval2 = intervals2.get(j);\n+      if (interval1.intersects(interval2)) {\n+        res.add(Interval.getIntersection(interval1, interval2));\n+      }\n+      if (interval1._max <= interval2._max) {\n+        i++;\n+      } else {\n+        j++;\n+      }\n+    }\n+    return res;\n+  }\n+\n+  private List<Interval> getUnionSortedIntervals(List<List<Interval>> intervals) {\n+    // Requires input intervals are sorted, the return intervals will be sorted\n+    if (intervals.isEmpty()) {\n+      return null;\n+    }\n+    return getUnionSortedIntervals(intervals, 0, intervals.size());\n+  }\n+\n+  private List<Interval> getUnionSortedIntervals(List<List<Interval>> intervals, int start, int end) {\n+    if (start + 1 == end) {\n+      return intervals.get(start);\n+    }\n+\n+    int mid = start + (end - start) / 2;\n+    List<Interval> intervals1 = getUnionSortedIntervals(intervals, start, mid);\n+    List<Interval> intervals2 = getUnionSortedIntervals(intervals, mid, end);\n+    return getUnionTwoSortedIntervals(intervals1, intervals2);\n+  }\n+\n+  /**\n+   * Union two list of non-overlapping sorted intervals.\n+   * E.g. {[1, 2], [5, 7], [9, 10]} and {[2, 3], [4, 8]} are merged as {[1, 3], [4, 8], [9, 10]}\n+   */\n+  private List<Interval> getUnionTwoSortedIntervals(List<Interval> intervals1, List<Interval> intervals2) {\n+    List<Interval> res = new ArrayList<>();\n+    int size1 = intervals1.size();\n+    int size2 = intervals2.size();\n+    int i = 0;\n+    int j = 0;\n+    while (i < size1 || j < size2) {\n+      // Get the `smaller` interval\n+      Interval interval = null;\n+      if (j == size2 || i < size1 && intervals1.get(i).compareTo(intervals2.get(j)) <= 0) {\n+        interval = intervals1.get(i++);\n+      } else {\n+        interval = intervals2.get(j++);\n+      }\n+      // If not overlapping with current result, add as a new interval\n+      int resSize = res.size();\n+      if (res.isEmpty() || !interval.intersects(res.get(resSize - 1))) {\n+        res.add(interval);\n+      } else {\n+        // If overlaps with the result, union with current result\n+        res.set(resSize - 1, Interval.getUnion(interval, res.get(resSize - 1)));\n+      }\n+    }\n+    return res;\n+  }\n+\n+  /**\n+   * Parse interval to millisecond as [min, max] with both sides included.\n+   * E.g. '(* 16311]' is parsed as [0, 16311], '(1455 16311)' is parsed as [1456, 16310]\n+   */\n+  private List<Interval> parseInterval(List<String> intervalExpressions) {\n+    Preconditions.checkState(intervalExpressions != null && intervalExpressions.size() == 1,\n+        \"Cannot parse range expressions from query: %s\", intervalExpressions);\n+    long startTime = MIN_START_TIME;\n+    long endTime = MAX_END_TIME;\n+    String intervalExpression = intervalExpressions.get(0);\n+    String[] s = intervalExpression.substring(1, intervalExpression.length() - 1).split(\"\\\\s+\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAwNzEwMg=="}, "originalCommit": {"oid": "787ee45ccc48dc0c099e6e3da74b7a95b14a527c"}, "originalPosition": 323}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NDAwMDY5OnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMToxNTo0NlrOH8URfQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMToxNTo0NlrOH8URfQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAwODc2NQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              private volatile IntervalTree _intervalTree;\n          \n          \n            \n              private volatile IntervalTree<String> _intervalTree;", "url": "https://github.com/apache/pinot/pull/6259#discussion_r533008765", "createdAt": "2020-12-01T01:15:46Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,344 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.interval.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.interval.IntervalTree;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeSegmentPruner.class);\n+  private static final long MIN_START_TIME = 0;\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final Interval DEFAULT_INTERVAL = new Interval(MIN_START_TIME, MAX_END_TIME);\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore<ZNRecord> _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final DateTimeFormatSpec _timeFormatSpec;\n+\n+  private volatile IntervalTree _intervalTree;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "787ee45ccc48dc0c099e6e3da74b7a95b14a527c"}, "originalPosition": 67}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQyMjE4ODM1OnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxOTo0MTo1MlrOIHWHHQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQxOTo0MTo1MlrOIHWHHQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDU3MzIxMw==", "bodyText": "Preconditions.checkNotNull()", "url": "https://github.com/apache/pinot/pull/6259#discussion_r544573213", "createdAt": "2020-12-16T19:41:52Z", "author": {"login": "snleee"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,346 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.interval.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.interval.IntervalTree;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeSegmentPruner.class);\n+  private static final long MIN_START_TIME = 0;\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final Interval DEFAULT_INTERVAL = new Interval(MIN_START_TIME, MAX_END_TIME);\n+  private static final char DELIMITER = '\\0';\n+  private static final String LEGACY_DELIMITER = \"\\t\\t\";\n+  private static final char START_INCLUSIVE = '(';\n+  private static final char END_INCLUSIVE = ')';\n+  private static final String UNBOUNDED = \"*\";\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore<ZNRecord> _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final DateTimeFormatSpec _timeFormatSpec;\n+\n+  private volatile IntervalTree<String> _intervalTree;\n+  private final Map<String, Interval> _intervalMap = new HashMap<>();\n+\n+  public TimeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkState(schema != null, \"Failed to find schema for table: %s\", _tableNameWithType);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ff8f2fdb8f63b101e4f2287f285fb50520fec305"}, "originalPosition": 85}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUyNTE1MjU2OnYy", "diffSide": "RIGHT", "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQwMDowNzoyOVrOIV6GaA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOVQwMDozOTo0OVrOIV6f7A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTg0MjkyMA==", "bodyText": "segments is always going to be empty here. Shouldn't this be onlineSegments ?\nThe call on line 104 will always result in index out of bounds.\nAm I missing something here? Shouldn't the tests have caught this?", "url": "https://github.com/apache/pinot/pull/6259#discussion_r559842920", "createdAt": "2021-01-19T00:07:29Z", "author": {"login": "npawar"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,346 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.interval.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.interval.IntervalTree;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeSegmentPruner.class);\n+  private static final long MIN_START_TIME = 0;\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final Interval DEFAULT_INTERVAL = new Interval(MIN_START_TIME, MAX_END_TIME);\n+  private static final char DELIMITER = '\\0';\n+  private static final String LEGACY_DELIMITER = \"\\t\\t\";\n+  private static final char START_INCLUSIVE = '(';\n+  private static final char END_INCLUSIVE = ')';\n+  private static final String UNBOUNDED = \"*\";\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore<ZNRecord> _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final DateTimeFormatSpec _timeFormatSpec;\n+\n+  private volatile IntervalTree<String> _intervalTree;\n+  private final Map<String, Interval> _intervalMap = new HashMap<>();\n+\n+  public TimeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkNotNull(schema, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    _timeFormatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    // Bulk load time info for all online segments\n+    int numSegments = onlineSegments.size();\n+    List<String> segments = new ArrayList<>(numSegments);\n+    List<String> segmentZKMetadataPaths = new ArrayList<>(numSegments);\n+    for (String segment : segments) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9102f3287fa300fb2cb3ca8e5fb566bec7e66885"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTg0OTQ1Mg==", "bodyText": "Yes, this should be onlineSegments. The tests only covered cases that onlineSegments are empty. Let me send a pr to fix this and cover cases when onlineSegments are not empty.", "url": "https://github.com/apache/pinot/pull/6259#discussion_r559849452", "createdAt": "2021-01-19T00:39:49Z", "author": {"login": "jtao15"}, "path": "pinot-broker/src/main/java/org/apache/pinot/broker/routing/segmentpruner/TimeSegmentPruner.java", "diffHunk": "@@ -0,0 +1,346 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.broker.routing.segmentpruner;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.helix.AccessOption;\n+import org.apache.helix.ZNRecord;\n+import org.apache.helix.model.ExternalView;\n+import org.apache.helix.model.IdealState;\n+import org.apache.helix.store.zk.ZkHelixPropertyStore;\n+import org.apache.pinot.broker.routing.segmentpruner.interval.Interval;\n+import org.apache.pinot.broker.routing.segmentpruner.interval.IntervalTree;\n+import org.apache.pinot.common.metadata.ZKMetadataProvider;\n+import org.apache.pinot.common.request.BrokerRequest;\n+import org.apache.pinot.common.utils.CommonConstants;\n+import org.apache.pinot.common.utils.request.FilterQueryTree;\n+import org.apache.pinot.common.utils.request.RequestUtils;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.DateTimeFieldSpec;\n+import org.apache.pinot.spi.data.DateTimeFormatSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * The {@code TimeSegmentPruner} prunes segments based on their time column start & end time metadata stored in ZK. The pruner\n+ * supports queries with filter (or nested filter) of EQUALITY and RANGE predicates.\n+ */\n+public class TimeSegmentPruner implements SegmentPruner {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(TimeSegmentPruner.class);\n+  private static final long MIN_START_TIME = 0;\n+  private static final long MAX_END_TIME = Long.MAX_VALUE;\n+  private static final Interval DEFAULT_INTERVAL = new Interval(MIN_START_TIME, MAX_END_TIME);\n+  private static final char DELIMITER = '\\0';\n+  private static final String LEGACY_DELIMITER = \"\\t\\t\";\n+  private static final char START_INCLUSIVE = '(';\n+  private static final char END_INCLUSIVE = ')';\n+  private static final String UNBOUNDED = \"*\";\n+\n+  private final String _tableNameWithType;\n+  private final ZkHelixPropertyStore<ZNRecord> _propertyStore;\n+  private final String _segmentZKMetadataPathPrefix;\n+  private final String _timeColumn;\n+  private final DateTimeFormatSpec _timeFormatSpec;\n+\n+  private volatile IntervalTree<String> _intervalTree;\n+  private final Map<String, Interval> _intervalMap = new HashMap<>();\n+\n+  public TimeSegmentPruner(TableConfig tableConfig, ZkHelixPropertyStore<ZNRecord> propertyStore) {\n+    _tableNameWithType = tableConfig.getTableName();\n+    _propertyStore = propertyStore;\n+    _segmentZKMetadataPathPrefix = ZKMetadataProvider.constructPropertyStorePathForResource(_tableNameWithType) + \"/\";\n+    _timeColumn = tableConfig.getValidationConfig().getTimeColumnName();\n+    Preconditions\n+        .checkNotNull(_timeColumn, \"Time column must be configured in table config for table: %s\", _tableNameWithType);\n+\n+    Schema schema = ZKMetadataProvider.getTableSchema(_propertyStore, _tableNameWithType);\n+    Preconditions.checkNotNull(schema, \"Failed to find schema for table: %s\", _tableNameWithType);\n+    DateTimeFieldSpec dateTimeSpec = schema.getSpecForTimeColumn(_timeColumn);\n+    Preconditions.checkNotNull(dateTimeSpec, \"Field spec must be specified in schema for time column: %s of table: %s\",\n+        _timeColumn, _tableNameWithType);\n+    _timeFormatSpec = new DateTimeFormatSpec(dateTimeSpec.getFormat());\n+  }\n+\n+  @Override\n+  public void init(ExternalView externalView, IdealState idealState, Set<String> onlineSegments) {\n+    // Bulk load time info for all online segments\n+    int numSegments = onlineSegments.size();\n+    List<String> segments = new ArrayList<>(numSegments);\n+    List<String> segmentZKMetadataPaths = new ArrayList<>(numSegments);\n+    for (String segment : segments) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTg0MjkyMA=="}, "originalCommit": {"oid": "9102f3287fa300fb2cb3ca8e5fb566bec7e66885"}, "originalPosition": 98}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3120, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}