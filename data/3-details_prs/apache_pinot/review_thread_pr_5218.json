{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDAwMTk1NzUx", "number": 5218, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQxODo0MTo1OFrODyoRBw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQyMTowMjowN1rODyrG8Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0NDE1MTExOnYy", "diffSide": "RIGHT", "path": "pinot-plugins/pinot-file-system/pinot-hdfs/src/main/java/org/apache/pinot/plugin/filesystem/HadoopPinotFS.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQxODo0MTo1OFrOGGyfRA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQxOTowNDoxNlrOGGzPtA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTc3MTg0NA==", "bodyText": "Why do we need to set it to false?", "url": "https://github.com/apache/pinot/pull/5218#discussion_r409771844", "createdAt": "2020-04-16T18:41:58Z", "author": {"login": "jackjlli"}, "path": "pinot-plugins/pinot-file-system/pinot-hdfs/src/main/java/org/apache/pinot/plugin/filesystem/HadoopPinotFS.java", "diffHunk": "@@ -60,6 +62,7 @@ public void init(Configuration config) {\n       _hadoopConf = getConf(config.getString(HADOOP_CONF_PATH));\n       authenticate(_hadoopConf, config);\n       _hadoopFS = org.apache.hadoop.fs.FileSystem.get(_hadoopConf);\n+      _hadoopFS.setWriteChecksum((config.getBoolean(WRITE_CHECKSUM, false)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c82e14b085ffb65d4eac4794361157c54ef8e8b0"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTc4NDI0NA==", "bodyText": "This will still do checksum but not write the .crc file to directory.", "url": "https://github.com/apache/pinot/pull/5218#discussion_r409784244", "createdAt": "2020-04-16T19:04:16Z", "author": {"login": "xiangfu0"}, "path": "pinot-plugins/pinot-file-system/pinot-hdfs/src/main/java/org/apache/pinot/plugin/filesystem/HadoopPinotFS.java", "diffHunk": "@@ -60,6 +62,7 @@ public void init(Configuration config) {\n       _hadoopConf = getConf(config.getString(HADOOP_CONF_PATH));\n       authenticate(_hadoopConf, config);\n       _hadoopFS = org.apache.hadoop.fs.FileSystem.get(_hadoopConf);\n+      _hadoopFS.setWriteChecksum((config.getBoolean(WRITE_CHECKSUM, false)));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTc3MTg0NA=="}, "originalCommit": {"oid": "c82e14b085ffb65d4eac4794361157c54ef8e8b0"}, "originalPosition": 47}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0NDYxNjgxOnYy", "diffSide": "RIGHT", "path": "pinot-plugins/pinot-file-system/pinot-hdfs/src/main/java/org/apache/pinot/plugin/filesystem/HadoopPinotFS.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQyMTowMjowN1rOGG3BXg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xN1QwMDowODoxNFrOGG7bqA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTg0NjExMA==", "bodyText": "Here the distURI is constructed by target + sourceFilePath. Can you make sure sourceFilePath is relative path instead of absolute path?\nAnd if possible, it'd be good to add some tests for this method. Thanks!", "url": "https://github.com/apache/pinot/pull/5218#discussion_r409846110", "createdAt": "2020-04-16T21:02:07Z", "author": {"login": "jackjlli"}, "path": "pinot-plugins/pinot-file-system/pinot-hdfs/src/main/java/org/apache/pinot/plugin/filesystem/HadoopPinotFS.java", "diffHunk": "@@ -97,13 +100,24 @@ public boolean copy(URI srcUri, URI dstUri)\n       throws IOException {\n     Path source = new Path(srcUri);\n     Path target = new Path(dstUri);\n-    RemoteIterator<LocatedFileStatus> sourceFiles = _hadoopFS.listFiles(source, true);\n+    RemoteIterator<FileStatus> sourceFiles = _hadoopFS.listStatusIterator(source);\n     if (sourceFiles != null) {\n       while (sourceFiles.hasNext()) {\n-        boolean succeeded =\n-            FileUtil.copy(_hadoopFS, sourceFiles.next().getPath(), _hadoopFS, target, true, _hadoopConf);\n-        if (!succeeded) {\n-          return false;\n+        FileStatus sourceFile = sourceFiles.next();\n+        Path sourceFilePath = sourceFile.getPath();\n+        if (sourceFile.isFile()) {\n+          try {\n+            FileUtil.copy(_hadoopFS, sourceFilePath, _hadoopFS, new Path(target, sourceFilePath.getName()), false,\n+                _hadoopConf);\n+          } catch (FileNotFoundException e) {\n+            LOGGER.warn(\"Not found file {}, skipping copying it...\", sourceFilePath, e);\n+          }\n+        } else if (sourceFile.isDirectory()) {\n+          try {\n+            copy(sourceFilePath.toUri(), new Path(target, sourceFilePath.getName()).toUri());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c82e14b085ffb65d4eac4794361157c54ef8e8b0"}, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTkxODM3Ng==", "bodyText": "added a test .", "url": "https://github.com/apache/pinot/pull/5218#discussion_r409918376", "createdAt": "2020-04-17T00:08:14Z", "author": {"login": "xiangfu0"}, "path": "pinot-plugins/pinot-file-system/pinot-hdfs/src/main/java/org/apache/pinot/plugin/filesystem/HadoopPinotFS.java", "diffHunk": "@@ -97,13 +100,24 @@ public boolean copy(URI srcUri, URI dstUri)\n       throws IOException {\n     Path source = new Path(srcUri);\n     Path target = new Path(dstUri);\n-    RemoteIterator<LocatedFileStatus> sourceFiles = _hadoopFS.listFiles(source, true);\n+    RemoteIterator<FileStatus> sourceFiles = _hadoopFS.listStatusIterator(source);\n     if (sourceFiles != null) {\n       while (sourceFiles.hasNext()) {\n-        boolean succeeded =\n-            FileUtil.copy(_hadoopFS, sourceFiles.next().getPath(), _hadoopFS, target, true, _hadoopConf);\n-        if (!succeeded) {\n-          return false;\n+        FileStatus sourceFile = sourceFiles.next();\n+        Path sourceFilePath = sourceFile.getPath();\n+        if (sourceFile.isFile()) {\n+          try {\n+            FileUtil.copy(_hadoopFS, sourceFilePath, _hadoopFS, new Path(target, sourceFilePath.getName()), false,\n+                _hadoopConf);\n+          } catch (FileNotFoundException e) {\n+            LOGGER.warn(\"Not found file {}, skipping copying it...\", sourceFilePath, e);\n+          }\n+        } else if (sourceFile.isDirectory()) {\n+          try {\n+            copy(sourceFilePath.toUri(), new Path(target, sourceFilePath.getName()).toUri());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTg0NjExMA=="}, "originalCommit": {"oid": "c82e14b085ffb65d4eac4794361157c54ef8e8b0"}, "originalPosition": 74}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3358, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}