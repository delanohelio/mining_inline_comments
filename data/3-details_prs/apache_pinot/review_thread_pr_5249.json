{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDAzODQ0OTg0", "number": 5249, "reviewThreads": {"totalCount": 23, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQyMDozMTozMFrODyO5SA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQxOTo1NDoxMVrOD0aLwA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzOTk5NDMyOnYy", "diffSide": "RIGHT", "path": "pinot-plugins/pinot-file-system/pinot-s3/src/main/java/org/apache/pinot/plugin/filesystem/S3PinotFS.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQyMDozMTozMFrOGGKb7A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQyMDozMTozMFrOGGKb7A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTExNTYyOA==", "bodyText": "Add docs on what are the properties needed for this and how to configure S3PinotFS", "url": "https://github.com/apache/pinot/pull/5249#discussion_r409115628", "createdAt": "2020-04-15T20:31:30Z", "author": {"login": "kishoreg"}, "path": "pinot-plugins/pinot-file-system/pinot-s3/src/main/java/org/apache/pinot/plugin/filesystem/S3PinotFS.java", "diffHunk": "@@ -0,0 +1,485 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.plugin.filesystem;\n+\n+import com.google.common.collect.ImmutableList;\n+import org.apache.commons.configuration.Configuration;\n+import org.apache.pinot.spi.filesystem.PinotFS;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import software.amazon.awssdk.auth.credentials.AwsBasicCredentials;\n+import software.amazon.awssdk.auth.credentials.EnvironmentVariableCredentialsProvider;\n+import software.amazon.awssdk.auth.credentials.StaticCredentialsProvider;\n+import software.amazon.awssdk.core.ResponseBytes;\n+import software.amazon.awssdk.core.exception.SdkClientException;\n+import software.amazon.awssdk.core.exception.SdkServiceException;\n+import software.amazon.awssdk.core.sync.RequestBody;\n+import software.amazon.awssdk.core.sync.ResponseTransformer;\n+import software.amazon.awssdk.regions.Region;\n+import software.amazon.awssdk.services.s3.S3Client;\n+import software.amazon.awssdk.services.s3.internal.resource.S3BucketResource;\n+import software.amazon.awssdk.services.s3.model.*;\n+\n+import java.io.*;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.net.URLEncoder;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.Date;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkState;\n+import static java.util.Objects.requireNonNull;\n+import static joptsimple.internal.Strings.isNullOrEmpty;\n+import static org.glassfish.jersey.internal.guava.Preconditions.checkArgument;\n+\n+public class S3PinotFS extends PinotFS {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a55cc4ceef627cf87d4ce344435ded19f249b49"}, "originalPosition": 58}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzOTk5NTc3OnYy", "diffSide": "RIGHT", "path": "pinot-plugins/pinot-file-system/pinot-s3/src/main/java/org/apache/pinot/plugin/filesystem/S3PinotFS.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQyMDozMTo1OFrOGGKc3Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQyMDozMTo1OFrOGGKc3Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTExNTg2OQ==", "bodyText": "should this be passed in as part of config", "url": "https://github.com/apache/pinot/pull/5249#discussion_r409115869", "createdAt": "2020-04-15T20:31:58Z", "author": {"login": "kishoreg"}, "path": "pinot-plugins/pinot-file-system/pinot-s3/src/main/java/org/apache/pinot/plugin/filesystem/S3PinotFS.java", "diffHunk": "@@ -0,0 +1,485 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.plugin.filesystem;\n+\n+import com.google.common.collect.ImmutableList;\n+import org.apache.commons.configuration.Configuration;\n+import org.apache.pinot.spi.filesystem.PinotFS;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import software.amazon.awssdk.auth.credentials.AwsBasicCredentials;\n+import software.amazon.awssdk.auth.credentials.EnvironmentVariableCredentialsProvider;\n+import software.amazon.awssdk.auth.credentials.StaticCredentialsProvider;\n+import software.amazon.awssdk.core.ResponseBytes;\n+import software.amazon.awssdk.core.exception.SdkClientException;\n+import software.amazon.awssdk.core.exception.SdkServiceException;\n+import software.amazon.awssdk.core.sync.RequestBody;\n+import software.amazon.awssdk.core.sync.ResponseTransformer;\n+import software.amazon.awssdk.regions.Region;\n+import software.amazon.awssdk.services.s3.S3Client;\n+import software.amazon.awssdk.services.s3.internal.resource.S3BucketResource;\n+import software.amazon.awssdk.services.s3.model.*;\n+\n+import java.io.*;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.net.URLEncoder;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.Date;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkState;\n+import static java.util.Objects.requireNonNull;\n+import static joptsimple.internal.Strings.isNullOrEmpty;\n+import static org.glassfish.jersey.internal.guava.Preconditions.checkArgument;\n+\n+public class S3PinotFS extends PinotFS {\n+    public static final String ACCESS_KEY = \"accessKey\";\n+    public static final String SECRET_KEY = \"secretKey\";\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(S3PinotFS.class);\n+    private static final String DELIMITER = \"/\";\n+    private S3Client s3Client;\n+\n+    @Override\n+    public void init(Configuration config) {\n+        checkArgument(!isNullOrEmpty(config.getString(ACCESS_KEY)));\n+        checkArgument(!isNullOrEmpty(config.getString(SECRET_KEY)));\n+        String accessKey = config.getString(ACCESS_KEY);\n+        String secretKey = config.getString(SECRET_KEY);\n+        try {\n+            AwsBasicCredentials awsBasicCredentials = AwsBasicCredentials.create(accessKey, secretKey);\n+            s3Client = S3Client.builder()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a55cc4ceef627cf87d4ce344435ded19f249b49"}, "originalPosition": 74}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0MTAxMTQ4OnYy", "diffSide": "RIGHT", "path": "pinot-plugins/pinot-file-system/pinot-s3/pom.xml", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwNDowOTo0MFrOGGT11A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQyMTowOTo0OVrOGG3RCQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI2OTcxNg==", "bodyText": "Add new line at the end of the file", "url": "https://github.com/apache/pinot/pull/5249#discussion_r409269716", "createdAt": "2020-04-16T04:09:40Z", "author": {"login": "haibow"}, "path": "pinot-plugins/pinot-file-system/pinot-s3/pom.xml", "diffHunk": "@@ -0,0 +1,154 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+\n+-->\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n+         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n+         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+    <modelVersion>4.0.0</modelVersion>\n+    <parent>\n+        <artifactId>pinot-file-system</artifactId>\n+        <groupId>org.apache.pinot</groupId>\n+        <version>${revision}${sha1}</version>\n+        <relativePath>..</relativePath>\n+    </parent>\n+\n+    <artifactId>pinot-s3</artifactId>\n+    <name>Pinot Amazon S3</name>\n+    <url>https://pinot.apache.org</url>\n+    <properties>\n+        <pinot.root>${basedir}/../../..</pinot.root>\n+    </properties>\n+\n+    <dependencyManagement>\n+        <dependencies>\n+            <dependency>\n+                <groupId>software.amazon.awssdk</groupId>\n+                <artifactId>bom</artifactId>\n+                <version>2.11.12</version>\n+                <type>pom</type>\n+                <scope>import</scope>\n+            </dependency>\n+        </dependencies>\n+    </dependencyManagement>\n+\n+    <dependencies>\n+        <dependency>\n+            <groupId>commons-configuration</groupId>\n+            <artifactId>commons-configuration</artifactId>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.apache.pinot</groupId>\n+            <artifactId>pinot-spi</artifactId>\n+            <version>0.4.0-SNAPSHOT</version>\n+        </dependency>\n+        <!-- amazon s3 -->\n+        <dependency>\n+            <groupId>software.amazon.awssdk</groupId>\n+            <artifactId>s3</artifactId>\n+            <version>2.11.12</version>\n+            <exclusions>\n+                <exclusion>\n+                    <groupId>org.reactivestreams</groupId>\n+                    <artifactId>reactive-streams</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>io.netty</groupId>\n+                    <artifactId>netty-codec</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>io.netty</groupId>\n+                    <artifactId>netty-buffer</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>io.netty</groupId>\n+                    <artifactId>netty-transport</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>io.netty</groupId>\n+                    <artifactId>netty-common</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>org.apache.httpcomponents</groupId>\n+                    <artifactId>httpcore</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>org.apache.httpcomponents</groupId>\n+                    <artifactId>httpclient</artifactId>\n+                </exclusion>\n+            </exclusions>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.apache.httpcomponents</groupId>\n+            <artifactId>httpclient</artifactId>\n+            <version>4.5.5</version>\n+            <exclusions>\n+                <exclusion>\n+                    <groupId>org.apache.httpcomponents</groupId>\n+                    <artifactId>httpcore</artifactId>\n+                </exclusion>\n+            </exclusions>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.apache.httpcomponents</groupId>\n+            <artifactId>httpcore</artifactId>\n+            <version>4.4.9</version>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.reactivestreams</groupId>\n+            <artifactId>reactive-streams</artifactId>\n+            <version>1.0.3</version>\n+        </dependency>\n+        <dependency>\n+            <groupId>io.netty</groupId>\n+            <artifactId>netty-codec</artifactId>\n+            <version>4.1.42.Final</version>\n+        </dependency>\n+        <dependency>\n+            <groupId>io.netty</groupId>\n+            <artifactId>netty-buffer</artifactId>\n+            <version>4.1.42.Final</version>\n+        </dependency>\n+        <dependency>\n+            <groupId>io.netty</groupId>\n+            <artifactId>netty-transport</artifactId>\n+            <version>4.1.42.Final</version>\n+        </dependency>\n+        <dependency>\n+            <groupId>io.netty</groupId>\n+            <artifactId>netty-common</artifactId>\n+            <version>4.1.42.Final</version>\n+        </dependency>\n+        <dependency>\n+            <groupId>net.sf.jopt-simple</groupId>\n+            <artifactId>jopt-simple</artifactId>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.glassfish.jersey.core</groupId>\n+            <artifactId>jersey-server</artifactId>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.jetbrains</groupId>\n+            <artifactId>annotations</artifactId>\n+            <version>18.0.0</version>\n+            <scope>compile</scope>\n+        </dependency>\n+    </dependencies>\n+</project>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a55cc4ceef627cf87d4ce344435ded19f249b49"}, "originalPosition": 154}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTg1MDEyMQ==", "bodyText": "+1", "url": "https://github.com/apache/pinot/pull/5249#discussion_r409850121", "createdAt": "2020-04-16T21:09:49Z", "author": {"login": "xiangfu0"}, "path": "pinot-plugins/pinot-file-system/pinot-s3/pom.xml", "diffHunk": "@@ -0,0 +1,154 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+\n+-->\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n+         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n+         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+    <modelVersion>4.0.0</modelVersion>\n+    <parent>\n+        <artifactId>pinot-file-system</artifactId>\n+        <groupId>org.apache.pinot</groupId>\n+        <version>${revision}${sha1}</version>\n+        <relativePath>..</relativePath>\n+    </parent>\n+\n+    <artifactId>pinot-s3</artifactId>\n+    <name>Pinot Amazon S3</name>\n+    <url>https://pinot.apache.org</url>\n+    <properties>\n+        <pinot.root>${basedir}/../../..</pinot.root>\n+    </properties>\n+\n+    <dependencyManagement>\n+        <dependencies>\n+            <dependency>\n+                <groupId>software.amazon.awssdk</groupId>\n+                <artifactId>bom</artifactId>\n+                <version>2.11.12</version>\n+                <type>pom</type>\n+                <scope>import</scope>\n+            </dependency>\n+        </dependencies>\n+    </dependencyManagement>\n+\n+    <dependencies>\n+        <dependency>\n+            <groupId>commons-configuration</groupId>\n+            <artifactId>commons-configuration</artifactId>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.apache.pinot</groupId>\n+            <artifactId>pinot-spi</artifactId>\n+            <version>0.4.0-SNAPSHOT</version>\n+        </dependency>\n+        <!-- amazon s3 -->\n+        <dependency>\n+            <groupId>software.amazon.awssdk</groupId>\n+            <artifactId>s3</artifactId>\n+            <version>2.11.12</version>\n+            <exclusions>\n+                <exclusion>\n+                    <groupId>org.reactivestreams</groupId>\n+                    <artifactId>reactive-streams</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>io.netty</groupId>\n+                    <artifactId>netty-codec</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>io.netty</groupId>\n+                    <artifactId>netty-buffer</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>io.netty</groupId>\n+                    <artifactId>netty-transport</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>io.netty</groupId>\n+                    <artifactId>netty-common</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>org.apache.httpcomponents</groupId>\n+                    <artifactId>httpcore</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>org.apache.httpcomponents</groupId>\n+                    <artifactId>httpclient</artifactId>\n+                </exclusion>\n+            </exclusions>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.apache.httpcomponents</groupId>\n+            <artifactId>httpclient</artifactId>\n+            <version>4.5.5</version>\n+            <exclusions>\n+                <exclusion>\n+                    <groupId>org.apache.httpcomponents</groupId>\n+                    <artifactId>httpcore</artifactId>\n+                </exclusion>\n+            </exclusions>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.apache.httpcomponents</groupId>\n+            <artifactId>httpcore</artifactId>\n+            <version>4.4.9</version>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.reactivestreams</groupId>\n+            <artifactId>reactive-streams</artifactId>\n+            <version>1.0.3</version>\n+        </dependency>\n+        <dependency>\n+            <groupId>io.netty</groupId>\n+            <artifactId>netty-codec</artifactId>\n+            <version>4.1.42.Final</version>\n+        </dependency>\n+        <dependency>\n+            <groupId>io.netty</groupId>\n+            <artifactId>netty-buffer</artifactId>\n+            <version>4.1.42.Final</version>\n+        </dependency>\n+        <dependency>\n+            <groupId>io.netty</groupId>\n+            <artifactId>netty-transport</artifactId>\n+            <version>4.1.42.Final</version>\n+        </dependency>\n+        <dependency>\n+            <groupId>io.netty</groupId>\n+            <artifactId>netty-common</artifactId>\n+            <version>4.1.42.Final</version>\n+        </dependency>\n+        <dependency>\n+            <groupId>net.sf.jopt-simple</groupId>\n+            <artifactId>jopt-simple</artifactId>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.glassfish.jersey.core</groupId>\n+            <artifactId>jersey-server</artifactId>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.jetbrains</groupId>\n+            <artifactId>annotations</artifactId>\n+            <version>18.0.0</version>\n+            <scope>compile</scope>\n+        </dependency>\n+    </dependencies>\n+</project>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI2OTcxNg=="}, "originalCommit": {"oid": "4a55cc4ceef627cf87d4ce344435ded19f249b49"}, "originalPosition": 154}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0MTAxMjc2OnYy", "diffSide": "RIGHT", "path": "pinot-plugins/pinot-file-system/pinot-s3/src/main/java/org/apache/pinot/plugin/filesystem/S3PinotFS.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwNDoxMDoyOVrOGGT2jA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwNDoxMDoyOVrOGGT2jA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI2OTkwMA==", "bodyText": "Missing space between } and catch. Please format the files with codestyle config in https://github.com/apache/incubator-pinot/tree/master/config", "url": "https://github.com/apache/pinot/pull/5249#discussion_r409269900", "createdAt": "2020-04-16T04:10:29Z", "author": {"login": "haibow"}, "path": "pinot-plugins/pinot-file-system/pinot-s3/src/main/java/org/apache/pinot/plugin/filesystem/S3PinotFS.java", "diffHunk": "@@ -0,0 +1,485 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.plugin.filesystem;\n+\n+import com.google.common.collect.ImmutableList;\n+import org.apache.commons.configuration.Configuration;\n+import org.apache.pinot.spi.filesystem.PinotFS;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import software.amazon.awssdk.auth.credentials.AwsBasicCredentials;\n+import software.amazon.awssdk.auth.credentials.EnvironmentVariableCredentialsProvider;\n+import software.amazon.awssdk.auth.credentials.StaticCredentialsProvider;\n+import software.amazon.awssdk.core.ResponseBytes;\n+import software.amazon.awssdk.core.exception.SdkClientException;\n+import software.amazon.awssdk.core.exception.SdkServiceException;\n+import software.amazon.awssdk.core.sync.RequestBody;\n+import software.amazon.awssdk.core.sync.ResponseTransformer;\n+import software.amazon.awssdk.regions.Region;\n+import software.amazon.awssdk.services.s3.S3Client;\n+import software.amazon.awssdk.services.s3.internal.resource.S3BucketResource;\n+import software.amazon.awssdk.services.s3.model.*;\n+\n+import java.io.*;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.net.URLEncoder;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.Date;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkState;\n+import static java.util.Objects.requireNonNull;\n+import static joptsimple.internal.Strings.isNullOrEmpty;\n+import static org.glassfish.jersey.internal.guava.Preconditions.checkArgument;\n+\n+public class S3PinotFS extends PinotFS {\n+    public static final String ACCESS_KEY = \"accessKey\";\n+    public static final String SECRET_KEY = \"secretKey\";\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(S3PinotFS.class);\n+    private static final String DELIMITER = \"/\";\n+    private S3Client s3Client;\n+\n+    @Override\n+    public void init(Configuration config) {\n+        checkArgument(!isNullOrEmpty(config.getString(ACCESS_KEY)));\n+        checkArgument(!isNullOrEmpty(config.getString(SECRET_KEY)));\n+        String accessKey = config.getString(ACCESS_KEY);\n+        String secretKey = config.getString(SECRET_KEY);\n+        try {\n+            AwsBasicCredentials awsBasicCredentials = AwsBasicCredentials.create(accessKey, secretKey);\n+            s3Client = S3Client.builder()\n+                    .region(Region.AP_SOUTHEAST_1)\n+                    .credentialsProvider(StaticCredentialsProvider.create(awsBasicCredentials))\n+                    .build();\n+\n+        } catch (S3Exception e) {\n+            throw new RuntimeException(\"Could not initialize S3PinotFS\", e);\n+        }\n+    }\n+\n+    private HeadObjectResponse getS3ObjectMetadata(URI uri) throws IOException {\n+            URI base = getBase(uri);\n+            String path = sanitizePath(base.relativize(uri).getPath());\n+            HeadObjectRequest headObjectRequest = HeadObjectRequest.builder()\n+                    .bucket(uri.getHost())\n+                    .key(path)\n+                    .build();\n+\n+            return s3Client.headObject(headObjectRequest);\n+    }\n+\n+    private boolean isPathTerminatedByDelimiter(URI uri) {\n+        return uri.getPath().endsWith(DELIMITER);\n+    }\n+\n+    private String normalizeToDirectoryPrefix(URI uri) throws IOException {\n+        requireNonNull(uri, \"uri is null\");\n+        URI strippedUri = getBase(uri).relativize(uri);\n+        if (isPathTerminatedByDelimiter(strippedUri)) {\n+            return sanitizePath(strippedUri.getPath());\n+        }\n+        return sanitizePath(strippedUri.getPath() + DELIMITER);\n+    }\n+\n+    private URI normalizeToDirectoryUri(URI uri) throws IOException {\n+        if (isPathTerminatedByDelimiter(uri)) {\n+            return uri;\n+        }\n+        try {\n+            return new URI(uri.getScheme(), uri.getHost(), sanitizePath(uri.getPath() + DELIMITER), null);\n+        } catch (URISyntaxException e) {\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    private String sanitizePath(String path) {\n+        path = path.replaceAll(DELIMITER + \"+\", DELIMITER);\n+        if (path.startsWith(DELIMITER) && !path.equals(DELIMITER)) {\n+            path = path.substring(1);\n+        }\n+        return path;\n+    }\n+\n+    private URI getBase(URI uri) throws IOException {\n+        try {\n+            return new URI(uri.getScheme(), uri.getHost(), null, null);\n+        } catch (URISyntaxException e) {\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    private boolean existsFile(URI uri) throws IOException {\n+        try {\n+            URI base = getBase(uri);\n+            String path = sanitizePath(base.relativize(uri).getPath());\n+            HeadObjectRequest headObjectRequest = HeadObjectRequest.builder()\n+                    .bucket(uri.getHost())\n+                    .key(path)\n+                    .build();\n+\n+            s3Client.headObject(headObjectRequest);\n+            return true;\n+        }catch(NoSuchKeyException e){", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a55cc4ceef627cf87d4ce344435ded19f249b49"}, "originalPosition": 146}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0MTAyMTY5OnYy", "diffSide": "RIGHT", "path": "pinot-plugins/pinot-file-system/pinot-s3/src/main/java/org/apache/pinot/plugin/filesystem/S3PinotFS.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwNDoxNToyMFrOGGT7ag==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwNDoxNToyMFrOGGT7ag==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI3MTE0Ng==", "bodyText": "Why log.info and continue, instead of directly throwing exception?", "url": "https://github.com/apache/pinot/pull/5249#discussion_r409271146", "createdAt": "2020-04-16T04:15:20Z", "author": {"login": "haibow"}, "path": "pinot-plugins/pinot-file-system/pinot-s3/src/main/java/org/apache/pinot/plugin/filesystem/S3PinotFS.java", "diffHunk": "@@ -0,0 +1,485 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.plugin.filesystem;\n+\n+import com.google.common.collect.ImmutableList;\n+import org.apache.commons.configuration.Configuration;\n+import org.apache.pinot.spi.filesystem.PinotFS;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import software.amazon.awssdk.auth.credentials.AwsBasicCredentials;\n+import software.amazon.awssdk.auth.credentials.EnvironmentVariableCredentialsProvider;\n+import software.amazon.awssdk.auth.credentials.StaticCredentialsProvider;\n+import software.amazon.awssdk.core.ResponseBytes;\n+import software.amazon.awssdk.core.exception.SdkClientException;\n+import software.amazon.awssdk.core.exception.SdkServiceException;\n+import software.amazon.awssdk.core.sync.RequestBody;\n+import software.amazon.awssdk.core.sync.ResponseTransformer;\n+import software.amazon.awssdk.regions.Region;\n+import software.amazon.awssdk.services.s3.S3Client;\n+import software.amazon.awssdk.services.s3.internal.resource.S3BucketResource;\n+import software.amazon.awssdk.services.s3.model.*;\n+\n+import java.io.*;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.net.URLEncoder;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.Date;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkState;\n+import static java.util.Objects.requireNonNull;\n+import static joptsimple.internal.Strings.isNullOrEmpty;\n+import static org.glassfish.jersey.internal.guava.Preconditions.checkArgument;\n+\n+public class S3PinotFS extends PinotFS {\n+    public static final String ACCESS_KEY = \"accessKey\";\n+    public static final String SECRET_KEY = \"secretKey\";\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(S3PinotFS.class);\n+    private static final String DELIMITER = \"/\";\n+    private S3Client s3Client;\n+\n+    @Override\n+    public void init(Configuration config) {\n+        checkArgument(!isNullOrEmpty(config.getString(ACCESS_KEY)));\n+        checkArgument(!isNullOrEmpty(config.getString(SECRET_KEY)));\n+        String accessKey = config.getString(ACCESS_KEY);\n+        String secretKey = config.getString(SECRET_KEY);\n+        try {\n+            AwsBasicCredentials awsBasicCredentials = AwsBasicCredentials.create(accessKey, secretKey);\n+            s3Client = S3Client.builder()\n+                    .region(Region.AP_SOUTHEAST_1)\n+                    .credentialsProvider(StaticCredentialsProvider.create(awsBasicCredentials))\n+                    .build();\n+\n+        } catch (S3Exception e) {\n+            throw new RuntimeException(\"Could not initialize S3PinotFS\", e);\n+        }\n+    }\n+\n+    private HeadObjectResponse getS3ObjectMetadata(URI uri) throws IOException {\n+            URI base = getBase(uri);\n+            String path = sanitizePath(base.relativize(uri).getPath());\n+            HeadObjectRequest headObjectRequest = HeadObjectRequest.builder()\n+                    .bucket(uri.getHost())\n+                    .key(path)\n+                    .build();\n+\n+            return s3Client.headObject(headObjectRequest);\n+    }\n+\n+    private boolean isPathTerminatedByDelimiter(URI uri) {\n+        return uri.getPath().endsWith(DELIMITER);\n+    }\n+\n+    private String normalizeToDirectoryPrefix(URI uri) throws IOException {\n+        requireNonNull(uri, \"uri is null\");\n+        URI strippedUri = getBase(uri).relativize(uri);\n+        if (isPathTerminatedByDelimiter(strippedUri)) {\n+            return sanitizePath(strippedUri.getPath());\n+        }\n+        return sanitizePath(strippedUri.getPath() + DELIMITER);\n+    }\n+\n+    private URI normalizeToDirectoryUri(URI uri) throws IOException {\n+        if (isPathTerminatedByDelimiter(uri)) {\n+            return uri;\n+        }\n+        try {\n+            return new URI(uri.getScheme(), uri.getHost(), sanitizePath(uri.getPath() + DELIMITER), null);\n+        } catch (URISyntaxException e) {\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    private String sanitizePath(String path) {\n+        path = path.replaceAll(DELIMITER + \"+\", DELIMITER);\n+        if (path.startsWith(DELIMITER) && !path.equals(DELIMITER)) {\n+            path = path.substring(1);\n+        }\n+        return path;\n+    }\n+\n+    private URI getBase(URI uri) throws IOException {\n+        try {\n+            return new URI(uri.getScheme(), uri.getHost(), null, null);\n+        } catch (URISyntaxException e) {\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    private boolean existsFile(URI uri) throws IOException {\n+        try {\n+            URI base = getBase(uri);\n+            String path = sanitizePath(base.relativize(uri).getPath());\n+            HeadObjectRequest headObjectRequest = HeadObjectRequest.builder()\n+                    .bucket(uri.getHost())\n+                    .key(path)\n+                    .build();\n+\n+            s3Client.headObject(headObjectRequest);\n+            return true;\n+        }catch(NoSuchKeyException e){\n+            return false;\n+        }catch(S3Exception e){\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    private boolean isEmptyDirectory(URI uri) throws IOException {\n+        if (!isDirectory(uri)) {\n+            return false;\n+        }\n+        String prefix = normalizeToDirectoryPrefix(uri);\n+        boolean isEmpty = true;\n+        ListObjectsV2Response listObjectsV2Response;\n+        ListObjectsV2Request.Builder listObjectsV2RequestBuilder = ListObjectsV2Request.builder()\n+                .bucket(uri.getHost());\n+\n+        if (prefix.equals(DELIMITER)) {\n+            ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.build();\n+            listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);\n+        } else {\n+            ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.prefix(prefix).build();\n+            listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);\n+        }\n+        for (S3Object s3Object : listObjectsV2Response.contents()) {\n+            if (s3Object.key().equals(prefix)) {\n+                continue;\n+            } else {\n+                isEmpty = false;\n+                break;\n+            }\n+        }\n+        return isEmpty;\n+    }\n+\n+    private boolean copyFile(URI srcUri, URI dstUri) throws IOException {\n+        try {\n+            String encodedUrl = null;\n+            try {\n+                encodedUrl = URLEncoder.encode(srcUri.getHost() + srcUri.getPath(), StandardCharsets.UTF_8.toString());\n+            } catch (UnsupportedEncodingException e) {\n+                LOGGER.info(\"URL could not be encoded: {}\", e.getMessage());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a55cc4ceef627cf87d4ce344435ded19f249b49"}, "originalPosition": 187}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0MTAyNDA0OnYy", "diffSide": "RIGHT", "path": "pinot-plugins/pinot-file-system/pinot-s3/src/main/java/org/apache/pinot/plugin/filesystem/S3PinotFS.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwNDoxNzowMVrOGGT82Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQxOTo0NToyN1rOGJVfvA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI3MTUxMw==", "bodyText": "nit: listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request); seems repetitive in both blocks. Move it below if-else.", "url": "https://github.com/apache/pinot/pull/5249#discussion_r409271513", "createdAt": "2020-04-16T04:17:01Z", "author": {"login": "haibow"}, "path": "pinot-plugins/pinot-file-system/pinot-s3/src/main/java/org/apache/pinot/plugin/filesystem/S3PinotFS.java", "diffHunk": "@@ -0,0 +1,485 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.plugin.filesystem;\n+\n+import com.google.common.collect.ImmutableList;\n+import org.apache.commons.configuration.Configuration;\n+import org.apache.pinot.spi.filesystem.PinotFS;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import software.amazon.awssdk.auth.credentials.AwsBasicCredentials;\n+import software.amazon.awssdk.auth.credentials.EnvironmentVariableCredentialsProvider;\n+import software.amazon.awssdk.auth.credentials.StaticCredentialsProvider;\n+import software.amazon.awssdk.core.ResponseBytes;\n+import software.amazon.awssdk.core.exception.SdkClientException;\n+import software.amazon.awssdk.core.exception.SdkServiceException;\n+import software.amazon.awssdk.core.sync.RequestBody;\n+import software.amazon.awssdk.core.sync.ResponseTransformer;\n+import software.amazon.awssdk.regions.Region;\n+import software.amazon.awssdk.services.s3.S3Client;\n+import software.amazon.awssdk.services.s3.internal.resource.S3BucketResource;\n+import software.amazon.awssdk.services.s3.model.*;\n+\n+import java.io.*;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.net.URLEncoder;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.Date;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkState;\n+import static java.util.Objects.requireNonNull;\n+import static joptsimple.internal.Strings.isNullOrEmpty;\n+import static org.glassfish.jersey.internal.guava.Preconditions.checkArgument;\n+\n+public class S3PinotFS extends PinotFS {\n+    public static final String ACCESS_KEY = \"accessKey\";\n+    public static final String SECRET_KEY = \"secretKey\";\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(S3PinotFS.class);\n+    private static final String DELIMITER = \"/\";\n+    private S3Client s3Client;\n+\n+    @Override\n+    public void init(Configuration config) {\n+        checkArgument(!isNullOrEmpty(config.getString(ACCESS_KEY)));\n+        checkArgument(!isNullOrEmpty(config.getString(SECRET_KEY)));\n+        String accessKey = config.getString(ACCESS_KEY);\n+        String secretKey = config.getString(SECRET_KEY);\n+        try {\n+            AwsBasicCredentials awsBasicCredentials = AwsBasicCredentials.create(accessKey, secretKey);\n+            s3Client = S3Client.builder()\n+                    .region(Region.AP_SOUTHEAST_1)\n+                    .credentialsProvider(StaticCredentialsProvider.create(awsBasicCredentials))\n+                    .build();\n+\n+        } catch (S3Exception e) {\n+            throw new RuntimeException(\"Could not initialize S3PinotFS\", e);\n+        }\n+    }\n+\n+    private HeadObjectResponse getS3ObjectMetadata(URI uri) throws IOException {\n+            URI base = getBase(uri);\n+            String path = sanitizePath(base.relativize(uri).getPath());\n+            HeadObjectRequest headObjectRequest = HeadObjectRequest.builder()\n+                    .bucket(uri.getHost())\n+                    .key(path)\n+                    .build();\n+\n+            return s3Client.headObject(headObjectRequest);\n+    }\n+\n+    private boolean isPathTerminatedByDelimiter(URI uri) {\n+        return uri.getPath().endsWith(DELIMITER);\n+    }\n+\n+    private String normalizeToDirectoryPrefix(URI uri) throws IOException {\n+        requireNonNull(uri, \"uri is null\");\n+        URI strippedUri = getBase(uri).relativize(uri);\n+        if (isPathTerminatedByDelimiter(strippedUri)) {\n+            return sanitizePath(strippedUri.getPath());\n+        }\n+        return sanitizePath(strippedUri.getPath() + DELIMITER);\n+    }\n+\n+    private URI normalizeToDirectoryUri(URI uri) throws IOException {\n+        if (isPathTerminatedByDelimiter(uri)) {\n+            return uri;\n+        }\n+        try {\n+            return new URI(uri.getScheme(), uri.getHost(), sanitizePath(uri.getPath() + DELIMITER), null);\n+        } catch (URISyntaxException e) {\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    private String sanitizePath(String path) {\n+        path = path.replaceAll(DELIMITER + \"+\", DELIMITER);\n+        if (path.startsWith(DELIMITER) && !path.equals(DELIMITER)) {\n+            path = path.substring(1);\n+        }\n+        return path;\n+    }\n+\n+    private URI getBase(URI uri) throws IOException {\n+        try {\n+            return new URI(uri.getScheme(), uri.getHost(), null, null);\n+        } catch (URISyntaxException e) {\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    private boolean existsFile(URI uri) throws IOException {\n+        try {\n+            URI base = getBase(uri);\n+            String path = sanitizePath(base.relativize(uri).getPath());\n+            HeadObjectRequest headObjectRequest = HeadObjectRequest.builder()\n+                    .bucket(uri.getHost())\n+                    .key(path)\n+                    .build();\n+\n+            s3Client.headObject(headObjectRequest);\n+            return true;\n+        }catch(NoSuchKeyException e){\n+            return false;\n+        }catch(S3Exception e){\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    private boolean isEmptyDirectory(URI uri) throws IOException {\n+        if (!isDirectory(uri)) {\n+            return false;\n+        }\n+        String prefix = normalizeToDirectoryPrefix(uri);\n+        boolean isEmpty = true;\n+        ListObjectsV2Response listObjectsV2Response;\n+        ListObjectsV2Request.Builder listObjectsV2RequestBuilder = ListObjectsV2Request.builder()\n+                .bucket(uri.getHost());\n+\n+        if (prefix.equals(DELIMITER)) {\n+            ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.build();\n+            listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);\n+        } else {\n+            ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.prefix(prefix).build();\n+            listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);\n+        }\n+        for (S3Object s3Object : listObjectsV2Response.contents()) {\n+            if (s3Object.key().equals(prefix)) {\n+                continue;\n+            } else {\n+                isEmpty = false;\n+                break;\n+            }\n+        }\n+        return isEmpty;\n+    }\n+\n+    private boolean copyFile(URI srcUri, URI dstUri) throws IOException {\n+        try {\n+            String encodedUrl = null;\n+            try {\n+                encodedUrl = URLEncoder.encode(srcUri.getHost() + srcUri.getPath(), StandardCharsets.UTF_8.toString());\n+            } catch (UnsupportedEncodingException e) {\n+                LOGGER.info(\"URL could not be encoded: {}\", e.getMessage());\n+            }\n+\n+            String dstPath = sanitizePath(dstUri.getPath());\n+            CopyObjectRequest copyReq = CopyObjectRequest.builder()\n+                    .copySource(encodedUrl)\n+                    .destinationBucket(dstUri.getHost())\n+                    .destinationKey(dstPath)\n+                    .build();\n+\n+            CopyObjectResponse copyObjectResponse = s3Client.copyObject(copyReq);\n+            return copyObjectResponse.sdkHttpResponse().isSuccessful();\n+        }catch(S3Exception e){\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    @Override\n+    public boolean mkdir(URI uri) throws IOException {\n+        LOGGER.info(\"mkdir {}\", uri);\n+        try {\n+            requireNonNull(uri, \"uri is null\");\n+            String path = normalizeToDirectoryPrefix(uri);\n+            // Bucket root directory already exists and cannot be created\n+            if (path.equals(DELIMITER)) {\n+                return true;\n+            }\n+\n+            PutObjectRequest putObjectRequest = PutObjectRequest.builder()\n+                    .bucket(uri.getHost())\n+                    .key(path)\n+                    .build();\n+\n+            PutObjectResponse putObjectResponse = s3Client.putObject(putObjectRequest, RequestBody.fromBytes(new byte[0]));\n+\n+            return putObjectResponse.sdkHttpResponse().isSuccessful();\n+        } catch (Throwable t) {\n+            throw new IOException(t);\n+        }\n+    }\n+\n+    @Override\n+    public boolean delete(URI segmentUri, boolean forceDelete) throws IOException {\n+        LOGGER.info(\"Deleting uri {} force {}\", segmentUri, forceDelete);\n+        try {\n+            if (isDirectory(segmentUri)) {\n+                if (!forceDelete) {\n+                    checkState(isEmptyDirectory(segmentUri), \"ForceDelete flag is not set and directory '%s' is not empty\", segmentUri);\n+                }\n+                String prefix = normalizeToDirectoryPrefix(segmentUri);\n+                ListObjectsV2Response listObjectsV2Response;\n+                ListObjectsV2Request.Builder listObjectsV2RequestBuilder = ListObjectsV2Request.builder()\n+                        .bucket(segmentUri.getHost());\n+\n+                if (prefix.equals(DELIMITER)) {\n+                    ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.build();\n+                    listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);\n+                } else {\n+                    ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.prefix(prefix).build();\n+                    listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a55cc4ceef627cf87d4ce344435ded19f249b49"}, "originalPosition": 246}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjQ0MjU1Ng==", "bodyText": "done", "url": "https://github.com/apache/pinot/pull/5249#discussion_r412442556", "createdAt": "2020-04-21T19:45:27Z", "author": {"login": "KKcorps"}, "path": "pinot-plugins/pinot-file-system/pinot-s3/src/main/java/org/apache/pinot/plugin/filesystem/S3PinotFS.java", "diffHunk": "@@ -0,0 +1,485 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.plugin.filesystem;\n+\n+import com.google.common.collect.ImmutableList;\n+import org.apache.commons.configuration.Configuration;\n+import org.apache.pinot.spi.filesystem.PinotFS;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import software.amazon.awssdk.auth.credentials.AwsBasicCredentials;\n+import software.amazon.awssdk.auth.credentials.EnvironmentVariableCredentialsProvider;\n+import software.amazon.awssdk.auth.credentials.StaticCredentialsProvider;\n+import software.amazon.awssdk.core.ResponseBytes;\n+import software.amazon.awssdk.core.exception.SdkClientException;\n+import software.amazon.awssdk.core.exception.SdkServiceException;\n+import software.amazon.awssdk.core.sync.RequestBody;\n+import software.amazon.awssdk.core.sync.ResponseTransformer;\n+import software.amazon.awssdk.regions.Region;\n+import software.amazon.awssdk.services.s3.S3Client;\n+import software.amazon.awssdk.services.s3.internal.resource.S3BucketResource;\n+import software.amazon.awssdk.services.s3.model.*;\n+\n+import java.io.*;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.net.URLEncoder;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.Date;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkState;\n+import static java.util.Objects.requireNonNull;\n+import static joptsimple.internal.Strings.isNullOrEmpty;\n+import static org.glassfish.jersey.internal.guava.Preconditions.checkArgument;\n+\n+public class S3PinotFS extends PinotFS {\n+    public static final String ACCESS_KEY = \"accessKey\";\n+    public static final String SECRET_KEY = \"secretKey\";\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(S3PinotFS.class);\n+    private static final String DELIMITER = \"/\";\n+    private S3Client s3Client;\n+\n+    @Override\n+    public void init(Configuration config) {\n+        checkArgument(!isNullOrEmpty(config.getString(ACCESS_KEY)));\n+        checkArgument(!isNullOrEmpty(config.getString(SECRET_KEY)));\n+        String accessKey = config.getString(ACCESS_KEY);\n+        String secretKey = config.getString(SECRET_KEY);\n+        try {\n+            AwsBasicCredentials awsBasicCredentials = AwsBasicCredentials.create(accessKey, secretKey);\n+            s3Client = S3Client.builder()\n+                    .region(Region.AP_SOUTHEAST_1)\n+                    .credentialsProvider(StaticCredentialsProvider.create(awsBasicCredentials))\n+                    .build();\n+\n+        } catch (S3Exception e) {\n+            throw new RuntimeException(\"Could not initialize S3PinotFS\", e);\n+        }\n+    }\n+\n+    private HeadObjectResponse getS3ObjectMetadata(URI uri) throws IOException {\n+            URI base = getBase(uri);\n+            String path = sanitizePath(base.relativize(uri).getPath());\n+            HeadObjectRequest headObjectRequest = HeadObjectRequest.builder()\n+                    .bucket(uri.getHost())\n+                    .key(path)\n+                    .build();\n+\n+            return s3Client.headObject(headObjectRequest);\n+    }\n+\n+    private boolean isPathTerminatedByDelimiter(URI uri) {\n+        return uri.getPath().endsWith(DELIMITER);\n+    }\n+\n+    private String normalizeToDirectoryPrefix(URI uri) throws IOException {\n+        requireNonNull(uri, \"uri is null\");\n+        URI strippedUri = getBase(uri).relativize(uri);\n+        if (isPathTerminatedByDelimiter(strippedUri)) {\n+            return sanitizePath(strippedUri.getPath());\n+        }\n+        return sanitizePath(strippedUri.getPath() + DELIMITER);\n+    }\n+\n+    private URI normalizeToDirectoryUri(URI uri) throws IOException {\n+        if (isPathTerminatedByDelimiter(uri)) {\n+            return uri;\n+        }\n+        try {\n+            return new URI(uri.getScheme(), uri.getHost(), sanitizePath(uri.getPath() + DELIMITER), null);\n+        } catch (URISyntaxException e) {\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    private String sanitizePath(String path) {\n+        path = path.replaceAll(DELIMITER + \"+\", DELIMITER);\n+        if (path.startsWith(DELIMITER) && !path.equals(DELIMITER)) {\n+            path = path.substring(1);\n+        }\n+        return path;\n+    }\n+\n+    private URI getBase(URI uri) throws IOException {\n+        try {\n+            return new URI(uri.getScheme(), uri.getHost(), null, null);\n+        } catch (URISyntaxException e) {\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    private boolean existsFile(URI uri) throws IOException {\n+        try {\n+            URI base = getBase(uri);\n+            String path = sanitizePath(base.relativize(uri).getPath());\n+            HeadObjectRequest headObjectRequest = HeadObjectRequest.builder()\n+                    .bucket(uri.getHost())\n+                    .key(path)\n+                    .build();\n+\n+            s3Client.headObject(headObjectRequest);\n+            return true;\n+        }catch(NoSuchKeyException e){\n+            return false;\n+        }catch(S3Exception e){\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    private boolean isEmptyDirectory(URI uri) throws IOException {\n+        if (!isDirectory(uri)) {\n+            return false;\n+        }\n+        String prefix = normalizeToDirectoryPrefix(uri);\n+        boolean isEmpty = true;\n+        ListObjectsV2Response listObjectsV2Response;\n+        ListObjectsV2Request.Builder listObjectsV2RequestBuilder = ListObjectsV2Request.builder()\n+                .bucket(uri.getHost());\n+\n+        if (prefix.equals(DELIMITER)) {\n+            ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.build();\n+            listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);\n+        } else {\n+            ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.prefix(prefix).build();\n+            listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);\n+        }\n+        for (S3Object s3Object : listObjectsV2Response.contents()) {\n+            if (s3Object.key().equals(prefix)) {\n+                continue;\n+            } else {\n+                isEmpty = false;\n+                break;\n+            }\n+        }\n+        return isEmpty;\n+    }\n+\n+    private boolean copyFile(URI srcUri, URI dstUri) throws IOException {\n+        try {\n+            String encodedUrl = null;\n+            try {\n+                encodedUrl = URLEncoder.encode(srcUri.getHost() + srcUri.getPath(), StandardCharsets.UTF_8.toString());\n+            } catch (UnsupportedEncodingException e) {\n+                LOGGER.info(\"URL could not be encoded: {}\", e.getMessage());\n+            }\n+\n+            String dstPath = sanitizePath(dstUri.getPath());\n+            CopyObjectRequest copyReq = CopyObjectRequest.builder()\n+                    .copySource(encodedUrl)\n+                    .destinationBucket(dstUri.getHost())\n+                    .destinationKey(dstPath)\n+                    .build();\n+\n+            CopyObjectResponse copyObjectResponse = s3Client.copyObject(copyReq);\n+            return copyObjectResponse.sdkHttpResponse().isSuccessful();\n+        }catch(S3Exception e){\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    @Override\n+    public boolean mkdir(URI uri) throws IOException {\n+        LOGGER.info(\"mkdir {}\", uri);\n+        try {\n+            requireNonNull(uri, \"uri is null\");\n+            String path = normalizeToDirectoryPrefix(uri);\n+            // Bucket root directory already exists and cannot be created\n+            if (path.equals(DELIMITER)) {\n+                return true;\n+            }\n+\n+            PutObjectRequest putObjectRequest = PutObjectRequest.builder()\n+                    .bucket(uri.getHost())\n+                    .key(path)\n+                    .build();\n+\n+            PutObjectResponse putObjectResponse = s3Client.putObject(putObjectRequest, RequestBody.fromBytes(new byte[0]));\n+\n+            return putObjectResponse.sdkHttpResponse().isSuccessful();\n+        } catch (Throwable t) {\n+            throw new IOException(t);\n+        }\n+    }\n+\n+    @Override\n+    public boolean delete(URI segmentUri, boolean forceDelete) throws IOException {\n+        LOGGER.info(\"Deleting uri {} force {}\", segmentUri, forceDelete);\n+        try {\n+            if (isDirectory(segmentUri)) {\n+                if (!forceDelete) {\n+                    checkState(isEmptyDirectory(segmentUri), \"ForceDelete flag is not set and directory '%s' is not empty\", segmentUri);\n+                }\n+                String prefix = normalizeToDirectoryPrefix(segmentUri);\n+                ListObjectsV2Response listObjectsV2Response;\n+                ListObjectsV2Request.Builder listObjectsV2RequestBuilder = ListObjectsV2Request.builder()\n+                        .bucket(segmentUri.getHost());\n+\n+                if (prefix.equals(DELIMITER)) {\n+                    ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.build();\n+                    listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);\n+                } else {\n+                    ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.prefix(prefix).build();\n+                    listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI3MTUxMw=="}, "originalCommit": {"oid": "4a55cc4ceef627cf87d4ce344435ded19f249b49"}, "originalPosition": 246}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0MTAyNTQ5OnYy", "diffSide": "RIGHT", "path": "pinot-plugins/pinot-file-system/pinot-s3/src/main/java/org/apache/pinot/plugin/filesystem/S3PinotFS.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwNDoxNzo1OVrOGGT9rg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQxOTo0NToyMVrOGJVfeQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI3MTcyNg==", "bodyText": "nit: move this repetitive line outside if-else blocks.", "url": "https://github.com/apache/pinot/pull/5249#discussion_r409271726", "createdAt": "2020-04-16T04:17:59Z", "author": {"login": "haibow"}, "path": "pinot-plugins/pinot-file-system/pinot-s3/src/main/java/org/apache/pinot/plugin/filesystem/S3PinotFS.java", "diffHunk": "@@ -0,0 +1,485 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.plugin.filesystem;\n+\n+import com.google.common.collect.ImmutableList;\n+import org.apache.commons.configuration.Configuration;\n+import org.apache.pinot.spi.filesystem.PinotFS;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import software.amazon.awssdk.auth.credentials.AwsBasicCredentials;\n+import software.amazon.awssdk.auth.credentials.EnvironmentVariableCredentialsProvider;\n+import software.amazon.awssdk.auth.credentials.StaticCredentialsProvider;\n+import software.amazon.awssdk.core.ResponseBytes;\n+import software.amazon.awssdk.core.exception.SdkClientException;\n+import software.amazon.awssdk.core.exception.SdkServiceException;\n+import software.amazon.awssdk.core.sync.RequestBody;\n+import software.amazon.awssdk.core.sync.ResponseTransformer;\n+import software.amazon.awssdk.regions.Region;\n+import software.amazon.awssdk.services.s3.S3Client;\n+import software.amazon.awssdk.services.s3.internal.resource.S3BucketResource;\n+import software.amazon.awssdk.services.s3.model.*;\n+\n+import java.io.*;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.net.URLEncoder;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.Date;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkState;\n+import static java.util.Objects.requireNonNull;\n+import static joptsimple.internal.Strings.isNullOrEmpty;\n+import static org.glassfish.jersey.internal.guava.Preconditions.checkArgument;\n+\n+public class S3PinotFS extends PinotFS {\n+    public static final String ACCESS_KEY = \"accessKey\";\n+    public static final String SECRET_KEY = \"secretKey\";\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(S3PinotFS.class);\n+    private static final String DELIMITER = \"/\";\n+    private S3Client s3Client;\n+\n+    @Override\n+    public void init(Configuration config) {\n+        checkArgument(!isNullOrEmpty(config.getString(ACCESS_KEY)));\n+        checkArgument(!isNullOrEmpty(config.getString(SECRET_KEY)));\n+        String accessKey = config.getString(ACCESS_KEY);\n+        String secretKey = config.getString(SECRET_KEY);\n+        try {\n+            AwsBasicCredentials awsBasicCredentials = AwsBasicCredentials.create(accessKey, secretKey);\n+            s3Client = S3Client.builder()\n+                    .region(Region.AP_SOUTHEAST_1)\n+                    .credentialsProvider(StaticCredentialsProvider.create(awsBasicCredentials))\n+                    .build();\n+\n+        } catch (S3Exception e) {\n+            throw new RuntimeException(\"Could not initialize S3PinotFS\", e);\n+        }\n+    }\n+\n+    private HeadObjectResponse getS3ObjectMetadata(URI uri) throws IOException {\n+            URI base = getBase(uri);\n+            String path = sanitizePath(base.relativize(uri).getPath());\n+            HeadObjectRequest headObjectRequest = HeadObjectRequest.builder()\n+                    .bucket(uri.getHost())\n+                    .key(path)\n+                    .build();\n+\n+            return s3Client.headObject(headObjectRequest);\n+    }\n+\n+    private boolean isPathTerminatedByDelimiter(URI uri) {\n+        return uri.getPath().endsWith(DELIMITER);\n+    }\n+\n+    private String normalizeToDirectoryPrefix(URI uri) throws IOException {\n+        requireNonNull(uri, \"uri is null\");\n+        URI strippedUri = getBase(uri).relativize(uri);\n+        if (isPathTerminatedByDelimiter(strippedUri)) {\n+            return sanitizePath(strippedUri.getPath());\n+        }\n+        return sanitizePath(strippedUri.getPath() + DELIMITER);\n+    }\n+\n+    private URI normalizeToDirectoryUri(URI uri) throws IOException {\n+        if (isPathTerminatedByDelimiter(uri)) {\n+            return uri;\n+        }\n+        try {\n+            return new URI(uri.getScheme(), uri.getHost(), sanitizePath(uri.getPath() + DELIMITER), null);\n+        } catch (URISyntaxException e) {\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    private String sanitizePath(String path) {\n+        path = path.replaceAll(DELIMITER + \"+\", DELIMITER);\n+        if (path.startsWith(DELIMITER) && !path.equals(DELIMITER)) {\n+            path = path.substring(1);\n+        }\n+        return path;\n+    }\n+\n+    private URI getBase(URI uri) throws IOException {\n+        try {\n+            return new URI(uri.getScheme(), uri.getHost(), null, null);\n+        } catch (URISyntaxException e) {\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    private boolean existsFile(URI uri) throws IOException {\n+        try {\n+            URI base = getBase(uri);\n+            String path = sanitizePath(base.relativize(uri).getPath());\n+            HeadObjectRequest headObjectRequest = HeadObjectRequest.builder()\n+                    .bucket(uri.getHost())\n+                    .key(path)\n+                    .build();\n+\n+            s3Client.headObject(headObjectRequest);\n+            return true;\n+        }catch(NoSuchKeyException e){\n+            return false;\n+        }catch(S3Exception e){\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    private boolean isEmptyDirectory(URI uri) throws IOException {\n+        if (!isDirectory(uri)) {\n+            return false;\n+        }\n+        String prefix = normalizeToDirectoryPrefix(uri);\n+        boolean isEmpty = true;\n+        ListObjectsV2Response listObjectsV2Response;\n+        ListObjectsV2Request.Builder listObjectsV2RequestBuilder = ListObjectsV2Request.builder()\n+                .bucket(uri.getHost());\n+\n+        if (prefix.equals(DELIMITER)) {\n+            ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.build();\n+            listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);\n+        } else {\n+            ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.prefix(prefix).build();\n+            listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);\n+        }\n+        for (S3Object s3Object : listObjectsV2Response.contents()) {\n+            if (s3Object.key().equals(prefix)) {\n+                continue;\n+            } else {\n+                isEmpty = false;\n+                break;\n+            }\n+        }\n+        return isEmpty;\n+    }\n+\n+    private boolean copyFile(URI srcUri, URI dstUri) throws IOException {\n+        try {\n+            String encodedUrl = null;\n+            try {\n+                encodedUrl = URLEncoder.encode(srcUri.getHost() + srcUri.getPath(), StandardCharsets.UTF_8.toString());\n+            } catch (UnsupportedEncodingException e) {\n+                LOGGER.info(\"URL could not be encoded: {}\", e.getMessage());\n+            }\n+\n+            String dstPath = sanitizePath(dstUri.getPath());\n+            CopyObjectRequest copyReq = CopyObjectRequest.builder()\n+                    .copySource(encodedUrl)\n+                    .destinationBucket(dstUri.getHost())\n+                    .destinationKey(dstPath)\n+                    .build();\n+\n+            CopyObjectResponse copyObjectResponse = s3Client.copyObject(copyReq);\n+            return copyObjectResponse.sdkHttpResponse().isSuccessful();\n+        }catch(S3Exception e){\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    @Override\n+    public boolean mkdir(URI uri) throws IOException {\n+        LOGGER.info(\"mkdir {}\", uri);\n+        try {\n+            requireNonNull(uri, \"uri is null\");\n+            String path = normalizeToDirectoryPrefix(uri);\n+            // Bucket root directory already exists and cannot be created\n+            if (path.equals(DELIMITER)) {\n+                return true;\n+            }\n+\n+            PutObjectRequest putObjectRequest = PutObjectRequest.builder()\n+                    .bucket(uri.getHost())\n+                    .key(path)\n+                    .build();\n+\n+            PutObjectResponse putObjectResponse = s3Client.putObject(putObjectRequest, RequestBody.fromBytes(new byte[0]));\n+\n+            return putObjectResponse.sdkHttpResponse().isSuccessful();\n+        } catch (Throwable t) {\n+            throw new IOException(t);\n+        }\n+    }\n+\n+    @Override\n+    public boolean delete(URI segmentUri, boolean forceDelete) throws IOException {\n+        LOGGER.info(\"Deleting uri {} force {}\", segmentUri, forceDelete);\n+        try {\n+            if (isDirectory(segmentUri)) {\n+                if (!forceDelete) {\n+                    checkState(isEmptyDirectory(segmentUri), \"ForceDelete flag is not set and directory '%s' is not empty\", segmentUri);\n+                }\n+                String prefix = normalizeToDirectoryPrefix(segmentUri);\n+                ListObjectsV2Response listObjectsV2Response;\n+                ListObjectsV2Request.Builder listObjectsV2RequestBuilder = ListObjectsV2Request.builder()\n+                        .bucket(segmentUri.getHost());\n+\n+                if (prefix.equals(DELIMITER)) {\n+                    ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.build();\n+                    listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);\n+                } else {\n+                    ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.prefix(prefix).build();\n+                    listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);\n+                }\n+                boolean deleteSucceeded = true;\n+                for (S3Object s3Object : listObjectsV2Response.contents()) {\n+                    DeleteObjectRequest deleteObjectRequest = DeleteObjectRequest.builder()\n+                            .bucket(segmentUri.getHost())\n+                            .key(s3Object.key())\n+                            .build();\n+\n+                    DeleteObjectResponse deleteObjectResponse = s3Client.deleteObject(deleteObjectRequest);\n+\n+                    deleteSucceeded &= deleteObjectResponse.sdkHttpResponse().isSuccessful();\n+                }\n+                return deleteSucceeded;\n+            } else {\n+                String prefix = sanitizePath(segmentUri.getPath());\n+                DeleteObjectRequest deleteObjectRequest = DeleteObjectRequest.builder()\n+                        .bucket(segmentUri.getHost())\n+                        .key(prefix)\n+                        .build();\n+\n+                DeleteObjectResponse deleteObjectResponse = s3Client.deleteObject(deleteObjectRequest);\n+\n+                return deleteObjectResponse.sdkHttpResponse().isSuccessful();\n+            }\n+        }catch(NoSuchKeyException e){\n+            return false;\n+        } catch (S3Exception e) {\n+            throw e;\n+        } catch(Throwable t) {\n+            throw new IOException(t);\n+        }\n+    }\n+\n+    @Override\n+    public boolean doMove(URI srcUri, URI dstUri) throws IOException {\n+        if (copy(srcUri, dstUri)) {\n+            return  delete(srcUri, true);\n+        }\n+        return false;\n+    }\n+\n+    @Override\n+    public boolean copy(URI srcUri, URI dstUri) throws IOException {\n+        LOGGER.info(\"Copying uri {} to uri {}\", srcUri, dstUri);\n+        checkState(exists(srcUri), \"Source URI '%s' does not exist\", srcUri);\n+        if (srcUri.equals(dstUri)) {\n+            return true;\n+        }\n+        if (!isDirectory(srcUri)) {\n+            delete(dstUri, true);\n+            return copyFile(srcUri, dstUri);\n+        }\n+        dstUri = normalizeToDirectoryUri(dstUri);\n+        ImmutableList.Builder<URI> builder = ImmutableList.builder();\n+        Path srcPath = Paths.get(srcUri.getPath());\n+        try {\n+            boolean copySucceeded = true;\n+            for (String directoryEntry : listFiles(srcUri, true)) {\n+                URI src = new URI(srcUri.getScheme(), srcUri.getHost(), directoryEntry, null);\n+                String relativeSrcPath = srcPath.relativize(Paths.get(directoryEntry)).toString();\n+                String dstPath = dstUri.resolve(relativeSrcPath).getPath();\n+                URI dst = new URI(dstUri.getScheme(), dstUri.getHost(), dstPath, null);\n+                copySucceeded &= copyFile(src, dst);\n+            }\n+            return copySucceeded;\n+        } catch (URISyntaxException e) {\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    @Override\n+    public boolean exists(URI fileUri) throws IOException {\n+        try {\n+            if (isDirectory(fileUri)) {\n+                return true;\n+            }\n+            if (isPathTerminatedByDelimiter(fileUri)) {\n+                return false;\n+            }\n+            return existsFile(fileUri);\n+        }catch(NoSuchKeyException e){\n+            return false;\n+        }\n+    }\n+\n+    @Override\n+    public long length(URI fileUri) throws IOException {\n+        try {\n+            checkState(!isPathTerminatedByDelimiter(fileUri), \"URI is a directory\");\n+            HeadObjectResponse s3ObjectMetadata = getS3ObjectMetadata(fileUri);\n+            checkState((s3ObjectMetadata != null), \"File '%s' does not exist\", fileUri);\n+            if(s3ObjectMetadata.contentLength() == null){\n+                return 0;\n+            }\n+            return s3ObjectMetadata.contentLength();\n+        } catch (Throwable t) {\n+            throw new IOException(t);\n+        }\n+    }\n+\n+    @Override\n+    public String[] listFiles(URI fileUri, boolean recursive) throws IOException {\n+        try {\n+            ImmutableList.Builder<String> builder = ImmutableList.builder();\n+            String prefix = normalizeToDirectoryPrefix(fileUri);\n+            ListObjectsV2Response listObjectsV2Response;\n+            ListObjectsV2Request.Builder listObjectsV2RequestBuilder = ListObjectsV2Request.builder()\n+                    .bucket(fileUri.getHost())\n+                    .prefix(prefix);\n+\n+            if (recursive) {\n+                ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.build();\n+                listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);\n+            } else {\n+                ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.delimiter(DELIMITER).build();\n+                listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a55cc4ceef627cf87d4ce344435ded19f249b49"}, "originalPosition": 362}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjQ0MjQ4OQ==", "bodyText": "done", "url": "https://github.com/apache/pinot/pull/5249#discussion_r412442489", "createdAt": "2020-04-21T19:45:21Z", "author": {"login": "KKcorps"}, "path": "pinot-plugins/pinot-file-system/pinot-s3/src/main/java/org/apache/pinot/plugin/filesystem/S3PinotFS.java", "diffHunk": "@@ -0,0 +1,485 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.plugin.filesystem;\n+\n+import com.google.common.collect.ImmutableList;\n+import org.apache.commons.configuration.Configuration;\n+import org.apache.pinot.spi.filesystem.PinotFS;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import software.amazon.awssdk.auth.credentials.AwsBasicCredentials;\n+import software.amazon.awssdk.auth.credentials.EnvironmentVariableCredentialsProvider;\n+import software.amazon.awssdk.auth.credentials.StaticCredentialsProvider;\n+import software.amazon.awssdk.core.ResponseBytes;\n+import software.amazon.awssdk.core.exception.SdkClientException;\n+import software.amazon.awssdk.core.exception.SdkServiceException;\n+import software.amazon.awssdk.core.sync.RequestBody;\n+import software.amazon.awssdk.core.sync.ResponseTransformer;\n+import software.amazon.awssdk.regions.Region;\n+import software.amazon.awssdk.services.s3.S3Client;\n+import software.amazon.awssdk.services.s3.internal.resource.S3BucketResource;\n+import software.amazon.awssdk.services.s3.model.*;\n+\n+import java.io.*;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.net.URLEncoder;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.Date;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkState;\n+import static java.util.Objects.requireNonNull;\n+import static joptsimple.internal.Strings.isNullOrEmpty;\n+import static org.glassfish.jersey.internal.guava.Preconditions.checkArgument;\n+\n+public class S3PinotFS extends PinotFS {\n+    public static final String ACCESS_KEY = \"accessKey\";\n+    public static final String SECRET_KEY = \"secretKey\";\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(S3PinotFS.class);\n+    private static final String DELIMITER = \"/\";\n+    private S3Client s3Client;\n+\n+    @Override\n+    public void init(Configuration config) {\n+        checkArgument(!isNullOrEmpty(config.getString(ACCESS_KEY)));\n+        checkArgument(!isNullOrEmpty(config.getString(SECRET_KEY)));\n+        String accessKey = config.getString(ACCESS_KEY);\n+        String secretKey = config.getString(SECRET_KEY);\n+        try {\n+            AwsBasicCredentials awsBasicCredentials = AwsBasicCredentials.create(accessKey, secretKey);\n+            s3Client = S3Client.builder()\n+                    .region(Region.AP_SOUTHEAST_1)\n+                    .credentialsProvider(StaticCredentialsProvider.create(awsBasicCredentials))\n+                    .build();\n+\n+        } catch (S3Exception e) {\n+            throw new RuntimeException(\"Could not initialize S3PinotFS\", e);\n+        }\n+    }\n+\n+    private HeadObjectResponse getS3ObjectMetadata(URI uri) throws IOException {\n+            URI base = getBase(uri);\n+            String path = sanitizePath(base.relativize(uri).getPath());\n+            HeadObjectRequest headObjectRequest = HeadObjectRequest.builder()\n+                    .bucket(uri.getHost())\n+                    .key(path)\n+                    .build();\n+\n+            return s3Client.headObject(headObjectRequest);\n+    }\n+\n+    private boolean isPathTerminatedByDelimiter(URI uri) {\n+        return uri.getPath().endsWith(DELIMITER);\n+    }\n+\n+    private String normalizeToDirectoryPrefix(URI uri) throws IOException {\n+        requireNonNull(uri, \"uri is null\");\n+        URI strippedUri = getBase(uri).relativize(uri);\n+        if (isPathTerminatedByDelimiter(strippedUri)) {\n+            return sanitizePath(strippedUri.getPath());\n+        }\n+        return sanitizePath(strippedUri.getPath() + DELIMITER);\n+    }\n+\n+    private URI normalizeToDirectoryUri(URI uri) throws IOException {\n+        if (isPathTerminatedByDelimiter(uri)) {\n+            return uri;\n+        }\n+        try {\n+            return new URI(uri.getScheme(), uri.getHost(), sanitizePath(uri.getPath() + DELIMITER), null);\n+        } catch (URISyntaxException e) {\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    private String sanitizePath(String path) {\n+        path = path.replaceAll(DELIMITER + \"+\", DELIMITER);\n+        if (path.startsWith(DELIMITER) && !path.equals(DELIMITER)) {\n+            path = path.substring(1);\n+        }\n+        return path;\n+    }\n+\n+    private URI getBase(URI uri) throws IOException {\n+        try {\n+            return new URI(uri.getScheme(), uri.getHost(), null, null);\n+        } catch (URISyntaxException e) {\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    private boolean existsFile(URI uri) throws IOException {\n+        try {\n+            URI base = getBase(uri);\n+            String path = sanitizePath(base.relativize(uri).getPath());\n+            HeadObjectRequest headObjectRequest = HeadObjectRequest.builder()\n+                    .bucket(uri.getHost())\n+                    .key(path)\n+                    .build();\n+\n+            s3Client.headObject(headObjectRequest);\n+            return true;\n+        }catch(NoSuchKeyException e){\n+            return false;\n+        }catch(S3Exception e){\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    private boolean isEmptyDirectory(URI uri) throws IOException {\n+        if (!isDirectory(uri)) {\n+            return false;\n+        }\n+        String prefix = normalizeToDirectoryPrefix(uri);\n+        boolean isEmpty = true;\n+        ListObjectsV2Response listObjectsV2Response;\n+        ListObjectsV2Request.Builder listObjectsV2RequestBuilder = ListObjectsV2Request.builder()\n+                .bucket(uri.getHost());\n+\n+        if (prefix.equals(DELIMITER)) {\n+            ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.build();\n+            listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);\n+        } else {\n+            ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.prefix(prefix).build();\n+            listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);\n+        }\n+        for (S3Object s3Object : listObjectsV2Response.contents()) {\n+            if (s3Object.key().equals(prefix)) {\n+                continue;\n+            } else {\n+                isEmpty = false;\n+                break;\n+            }\n+        }\n+        return isEmpty;\n+    }\n+\n+    private boolean copyFile(URI srcUri, URI dstUri) throws IOException {\n+        try {\n+            String encodedUrl = null;\n+            try {\n+                encodedUrl = URLEncoder.encode(srcUri.getHost() + srcUri.getPath(), StandardCharsets.UTF_8.toString());\n+            } catch (UnsupportedEncodingException e) {\n+                LOGGER.info(\"URL could not be encoded: {}\", e.getMessage());\n+            }\n+\n+            String dstPath = sanitizePath(dstUri.getPath());\n+            CopyObjectRequest copyReq = CopyObjectRequest.builder()\n+                    .copySource(encodedUrl)\n+                    .destinationBucket(dstUri.getHost())\n+                    .destinationKey(dstPath)\n+                    .build();\n+\n+            CopyObjectResponse copyObjectResponse = s3Client.copyObject(copyReq);\n+            return copyObjectResponse.sdkHttpResponse().isSuccessful();\n+        }catch(S3Exception e){\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    @Override\n+    public boolean mkdir(URI uri) throws IOException {\n+        LOGGER.info(\"mkdir {}\", uri);\n+        try {\n+            requireNonNull(uri, \"uri is null\");\n+            String path = normalizeToDirectoryPrefix(uri);\n+            // Bucket root directory already exists and cannot be created\n+            if (path.equals(DELIMITER)) {\n+                return true;\n+            }\n+\n+            PutObjectRequest putObjectRequest = PutObjectRequest.builder()\n+                    .bucket(uri.getHost())\n+                    .key(path)\n+                    .build();\n+\n+            PutObjectResponse putObjectResponse = s3Client.putObject(putObjectRequest, RequestBody.fromBytes(new byte[0]));\n+\n+            return putObjectResponse.sdkHttpResponse().isSuccessful();\n+        } catch (Throwable t) {\n+            throw new IOException(t);\n+        }\n+    }\n+\n+    @Override\n+    public boolean delete(URI segmentUri, boolean forceDelete) throws IOException {\n+        LOGGER.info(\"Deleting uri {} force {}\", segmentUri, forceDelete);\n+        try {\n+            if (isDirectory(segmentUri)) {\n+                if (!forceDelete) {\n+                    checkState(isEmptyDirectory(segmentUri), \"ForceDelete flag is not set and directory '%s' is not empty\", segmentUri);\n+                }\n+                String prefix = normalizeToDirectoryPrefix(segmentUri);\n+                ListObjectsV2Response listObjectsV2Response;\n+                ListObjectsV2Request.Builder listObjectsV2RequestBuilder = ListObjectsV2Request.builder()\n+                        .bucket(segmentUri.getHost());\n+\n+                if (prefix.equals(DELIMITER)) {\n+                    ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.build();\n+                    listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);\n+                } else {\n+                    ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.prefix(prefix).build();\n+                    listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);\n+                }\n+                boolean deleteSucceeded = true;\n+                for (S3Object s3Object : listObjectsV2Response.contents()) {\n+                    DeleteObjectRequest deleteObjectRequest = DeleteObjectRequest.builder()\n+                            .bucket(segmentUri.getHost())\n+                            .key(s3Object.key())\n+                            .build();\n+\n+                    DeleteObjectResponse deleteObjectResponse = s3Client.deleteObject(deleteObjectRequest);\n+\n+                    deleteSucceeded &= deleteObjectResponse.sdkHttpResponse().isSuccessful();\n+                }\n+                return deleteSucceeded;\n+            } else {\n+                String prefix = sanitizePath(segmentUri.getPath());\n+                DeleteObjectRequest deleteObjectRequest = DeleteObjectRequest.builder()\n+                        .bucket(segmentUri.getHost())\n+                        .key(prefix)\n+                        .build();\n+\n+                DeleteObjectResponse deleteObjectResponse = s3Client.deleteObject(deleteObjectRequest);\n+\n+                return deleteObjectResponse.sdkHttpResponse().isSuccessful();\n+            }\n+        }catch(NoSuchKeyException e){\n+            return false;\n+        } catch (S3Exception e) {\n+            throw e;\n+        } catch(Throwable t) {\n+            throw new IOException(t);\n+        }\n+    }\n+\n+    @Override\n+    public boolean doMove(URI srcUri, URI dstUri) throws IOException {\n+        if (copy(srcUri, dstUri)) {\n+            return  delete(srcUri, true);\n+        }\n+        return false;\n+    }\n+\n+    @Override\n+    public boolean copy(URI srcUri, URI dstUri) throws IOException {\n+        LOGGER.info(\"Copying uri {} to uri {}\", srcUri, dstUri);\n+        checkState(exists(srcUri), \"Source URI '%s' does not exist\", srcUri);\n+        if (srcUri.equals(dstUri)) {\n+            return true;\n+        }\n+        if (!isDirectory(srcUri)) {\n+            delete(dstUri, true);\n+            return copyFile(srcUri, dstUri);\n+        }\n+        dstUri = normalizeToDirectoryUri(dstUri);\n+        ImmutableList.Builder<URI> builder = ImmutableList.builder();\n+        Path srcPath = Paths.get(srcUri.getPath());\n+        try {\n+            boolean copySucceeded = true;\n+            for (String directoryEntry : listFiles(srcUri, true)) {\n+                URI src = new URI(srcUri.getScheme(), srcUri.getHost(), directoryEntry, null);\n+                String relativeSrcPath = srcPath.relativize(Paths.get(directoryEntry)).toString();\n+                String dstPath = dstUri.resolve(relativeSrcPath).getPath();\n+                URI dst = new URI(dstUri.getScheme(), dstUri.getHost(), dstPath, null);\n+                copySucceeded &= copyFile(src, dst);\n+            }\n+            return copySucceeded;\n+        } catch (URISyntaxException e) {\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    @Override\n+    public boolean exists(URI fileUri) throws IOException {\n+        try {\n+            if (isDirectory(fileUri)) {\n+                return true;\n+            }\n+            if (isPathTerminatedByDelimiter(fileUri)) {\n+                return false;\n+            }\n+            return existsFile(fileUri);\n+        }catch(NoSuchKeyException e){\n+            return false;\n+        }\n+    }\n+\n+    @Override\n+    public long length(URI fileUri) throws IOException {\n+        try {\n+            checkState(!isPathTerminatedByDelimiter(fileUri), \"URI is a directory\");\n+            HeadObjectResponse s3ObjectMetadata = getS3ObjectMetadata(fileUri);\n+            checkState((s3ObjectMetadata != null), \"File '%s' does not exist\", fileUri);\n+            if(s3ObjectMetadata.contentLength() == null){\n+                return 0;\n+            }\n+            return s3ObjectMetadata.contentLength();\n+        } catch (Throwable t) {\n+            throw new IOException(t);\n+        }\n+    }\n+\n+    @Override\n+    public String[] listFiles(URI fileUri, boolean recursive) throws IOException {\n+        try {\n+            ImmutableList.Builder<String> builder = ImmutableList.builder();\n+            String prefix = normalizeToDirectoryPrefix(fileUri);\n+            ListObjectsV2Response listObjectsV2Response;\n+            ListObjectsV2Request.Builder listObjectsV2RequestBuilder = ListObjectsV2Request.builder()\n+                    .bucket(fileUri.getHost())\n+                    .prefix(prefix);\n+\n+            if (recursive) {\n+                ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.build();\n+                listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);\n+            } else {\n+                ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.delimiter(DELIMITER).build();\n+                listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI3MTcyNg=="}, "originalCommit": {"oid": "4a55cc4ceef627cf87d4ce344435ded19f249b49"}, "originalPosition": 362}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0MTAyNjE1OnYy", "diffSide": "RIGHT", "path": "pinot-plugins/pinot-file-system/pinot-s3/src/main/java/org/apache/pinot/plugin/filesystem/S3PinotFS.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwNDoxODoyNVrOGGT-FA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQxOTo0NToxNFrOGJVfSw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI3MTgyOA==", "bodyText": "remove System.out.println", "url": "https://github.com/apache/pinot/pull/5249#discussion_r409271828", "createdAt": "2020-04-16T04:18:25Z", "author": {"login": "haibow"}, "path": "pinot-plugins/pinot-file-system/pinot-s3/src/main/java/org/apache/pinot/plugin/filesystem/S3PinotFS.java", "diffHunk": "@@ -0,0 +1,485 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.plugin.filesystem;\n+\n+import com.google.common.collect.ImmutableList;\n+import org.apache.commons.configuration.Configuration;\n+import org.apache.pinot.spi.filesystem.PinotFS;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import software.amazon.awssdk.auth.credentials.AwsBasicCredentials;\n+import software.amazon.awssdk.auth.credentials.EnvironmentVariableCredentialsProvider;\n+import software.amazon.awssdk.auth.credentials.StaticCredentialsProvider;\n+import software.amazon.awssdk.core.ResponseBytes;\n+import software.amazon.awssdk.core.exception.SdkClientException;\n+import software.amazon.awssdk.core.exception.SdkServiceException;\n+import software.amazon.awssdk.core.sync.RequestBody;\n+import software.amazon.awssdk.core.sync.ResponseTransformer;\n+import software.amazon.awssdk.regions.Region;\n+import software.amazon.awssdk.services.s3.S3Client;\n+import software.amazon.awssdk.services.s3.internal.resource.S3BucketResource;\n+import software.amazon.awssdk.services.s3.model.*;\n+\n+import java.io.*;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.net.URLEncoder;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.Date;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkState;\n+import static java.util.Objects.requireNonNull;\n+import static joptsimple.internal.Strings.isNullOrEmpty;\n+import static org.glassfish.jersey.internal.guava.Preconditions.checkArgument;\n+\n+public class S3PinotFS extends PinotFS {\n+    public static final String ACCESS_KEY = \"accessKey\";\n+    public static final String SECRET_KEY = \"secretKey\";\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(S3PinotFS.class);\n+    private static final String DELIMITER = \"/\";\n+    private S3Client s3Client;\n+\n+    @Override\n+    public void init(Configuration config) {\n+        checkArgument(!isNullOrEmpty(config.getString(ACCESS_KEY)));\n+        checkArgument(!isNullOrEmpty(config.getString(SECRET_KEY)));\n+        String accessKey = config.getString(ACCESS_KEY);\n+        String secretKey = config.getString(SECRET_KEY);\n+        try {\n+            AwsBasicCredentials awsBasicCredentials = AwsBasicCredentials.create(accessKey, secretKey);\n+            s3Client = S3Client.builder()\n+                    .region(Region.AP_SOUTHEAST_1)\n+                    .credentialsProvider(StaticCredentialsProvider.create(awsBasicCredentials))\n+                    .build();\n+\n+        } catch (S3Exception e) {\n+            throw new RuntimeException(\"Could not initialize S3PinotFS\", e);\n+        }\n+    }\n+\n+    private HeadObjectResponse getS3ObjectMetadata(URI uri) throws IOException {\n+            URI base = getBase(uri);\n+            String path = sanitizePath(base.relativize(uri).getPath());\n+            HeadObjectRequest headObjectRequest = HeadObjectRequest.builder()\n+                    .bucket(uri.getHost())\n+                    .key(path)\n+                    .build();\n+\n+            return s3Client.headObject(headObjectRequest);\n+    }\n+\n+    private boolean isPathTerminatedByDelimiter(URI uri) {\n+        return uri.getPath().endsWith(DELIMITER);\n+    }\n+\n+    private String normalizeToDirectoryPrefix(URI uri) throws IOException {\n+        requireNonNull(uri, \"uri is null\");\n+        URI strippedUri = getBase(uri).relativize(uri);\n+        if (isPathTerminatedByDelimiter(strippedUri)) {\n+            return sanitizePath(strippedUri.getPath());\n+        }\n+        return sanitizePath(strippedUri.getPath() + DELIMITER);\n+    }\n+\n+    private URI normalizeToDirectoryUri(URI uri) throws IOException {\n+        if (isPathTerminatedByDelimiter(uri)) {\n+            return uri;\n+        }\n+        try {\n+            return new URI(uri.getScheme(), uri.getHost(), sanitizePath(uri.getPath() + DELIMITER), null);\n+        } catch (URISyntaxException e) {\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    private String sanitizePath(String path) {\n+        path = path.replaceAll(DELIMITER + \"+\", DELIMITER);\n+        if (path.startsWith(DELIMITER) && !path.equals(DELIMITER)) {\n+            path = path.substring(1);\n+        }\n+        return path;\n+    }\n+\n+    private URI getBase(URI uri) throws IOException {\n+        try {\n+            return new URI(uri.getScheme(), uri.getHost(), null, null);\n+        } catch (URISyntaxException e) {\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    private boolean existsFile(URI uri) throws IOException {\n+        try {\n+            URI base = getBase(uri);\n+            String path = sanitizePath(base.relativize(uri).getPath());\n+            HeadObjectRequest headObjectRequest = HeadObjectRequest.builder()\n+                    .bucket(uri.getHost())\n+                    .key(path)\n+                    .build();\n+\n+            s3Client.headObject(headObjectRequest);\n+            return true;\n+        }catch(NoSuchKeyException e){\n+            return false;\n+        }catch(S3Exception e){\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    private boolean isEmptyDirectory(URI uri) throws IOException {\n+        if (!isDirectory(uri)) {\n+            return false;\n+        }\n+        String prefix = normalizeToDirectoryPrefix(uri);\n+        boolean isEmpty = true;\n+        ListObjectsV2Response listObjectsV2Response;\n+        ListObjectsV2Request.Builder listObjectsV2RequestBuilder = ListObjectsV2Request.builder()\n+                .bucket(uri.getHost());\n+\n+        if (prefix.equals(DELIMITER)) {\n+            ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.build();\n+            listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);\n+        } else {\n+            ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.prefix(prefix).build();\n+            listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);\n+        }\n+        for (S3Object s3Object : listObjectsV2Response.contents()) {\n+            if (s3Object.key().equals(prefix)) {\n+                continue;\n+            } else {\n+                isEmpty = false;\n+                break;\n+            }\n+        }\n+        return isEmpty;\n+    }\n+\n+    private boolean copyFile(URI srcUri, URI dstUri) throws IOException {\n+        try {\n+            String encodedUrl = null;\n+            try {\n+                encodedUrl = URLEncoder.encode(srcUri.getHost() + srcUri.getPath(), StandardCharsets.UTF_8.toString());\n+            } catch (UnsupportedEncodingException e) {\n+                LOGGER.info(\"URL could not be encoded: {}\", e.getMessage());\n+            }\n+\n+            String dstPath = sanitizePath(dstUri.getPath());\n+            CopyObjectRequest copyReq = CopyObjectRequest.builder()\n+                    .copySource(encodedUrl)\n+                    .destinationBucket(dstUri.getHost())\n+                    .destinationKey(dstPath)\n+                    .build();\n+\n+            CopyObjectResponse copyObjectResponse = s3Client.copyObject(copyReq);\n+            return copyObjectResponse.sdkHttpResponse().isSuccessful();\n+        }catch(S3Exception e){\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    @Override\n+    public boolean mkdir(URI uri) throws IOException {\n+        LOGGER.info(\"mkdir {}\", uri);\n+        try {\n+            requireNonNull(uri, \"uri is null\");\n+            String path = normalizeToDirectoryPrefix(uri);\n+            // Bucket root directory already exists and cannot be created\n+            if (path.equals(DELIMITER)) {\n+                return true;\n+            }\n+\n+            PutObjectRequest putObjectRequest = PutObjectRequest.builder()\n+                    .bucket(uri.getHost())\n+                    .key(path)\n+                    .build();\n+\n+            PutObjectResponse putObjectResponse = s3Client.putObject(putObjectRequest, RequestBody.fromBytes(new byte[0]));\n+\n+            return putObjectResponse.sdkHttpResponse().isSuccessful();\n+        } catch (Throwable t) {\n+            throw new IOException(t);\n+        }\n+    }\n+\n+    @Override\n+    public boolean delete(URI segmentUri, boolean forceDelete) throws IOException {\n+        LOGGER.info(\"Deleting uri {} force {}\", segmentUri, forceDelete);\n+        try {\n+            if (isDirectory(segmentUri)) {\n+                if (!forceDelete) {\n+                    checkState(isEmptyDirectory(segmentUri), \"ForceDelete flag is not set and directory '%s' is not empty\", segmentUri);\n+                }\n+                String prefix = normalizeToDirectoryPrefix(segmentUri);\n+                ListObjectsV2Response listObjectsV2Response;\n+                ListObjectsV2Request.Builder listObjectsV2RequestBuilder = ListObjectsV2Request.builder()\n+                        .bucket(segmentUri.getHost());\n+\n+                if (prefix.equals(DELIMITER)) {\n+                    ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.build();\n+                    listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);\n+                } else {\n+                    ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.prefix(prefix).build();\n+                    listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);\n+                }\n+                boolean deleteSucceeded = true;\n+                for (S3Object s3Object : listObjectsV2Response.contents()) {\n+                    DeleteObjectRequest deleteObjectRequest = DeleteObjectRequest.builder()\n+                            .bucket(segmentUri.getHost())\n+                            .key(s3Object.key())\n+                            .build();\n+\n+                    DeleteObjectResponse deleteObjectResponse = s3Client.deleteObject(deleteObjectRequest);\n+\n+                    deleteSucceeded &= deleteObjectResponse.sdkHttpResponse().isSuccessful();\n+                }\n+                return deleteSucceeded;\n+            } else {\n+                String prefix = sanitizePath(segmentUri.getPath());\n+                DeleteObjectRequest deleteObjectRequest = DeleteObjectRequest.builder()\n+                        .bucket(segmentUri.getHost())\n+                        .key(prefix)\n+                        .build();\n+\n+                DeleteObjectResponse deleteObjectResponse = s3Client.deleteObject(deleteObjectRequest);\n+\n+                return deleteObjectResponse.sdkHttpResponse().isSuccessful();\n+            }\n+        }catch(NoSuchKeyException e){\n+            return false;\n+        } catch (S3Exception e) {\n+            throw e;\n+        } catch(Throwable t) {\n+            throw new IOException(t);\n+        }\n+    }\n+\n+    @Override\n+    public boolean doMove(URI srcUri, URI dstUri) throws IOException {\n+        if (copy(srcUri, dstUri)) {\n+            return  delete(srcUri, true);\n+        }\n+        return false;\n+    }\n+\n+    @Override\n+    public boolean copy(URI srcUri, URI dstUri) throws IOException {\n+        LOGGER.info(\"Copying uri {} to uri {}\", srcUri, dstUri);\n+        checkState(exists(srcUri), \"Source URI '%s' does not exist\", srcUri);\n+        if (srcUri.equals(dstUri)) {\n+            return true;\n+        }\n+        if (!isDirectory(srcUri)) {\n+            delete(dstUri, true);\n+            return copyFile(srcUri, dstUri);\n+        }\n+        dstUri = normalizeToDirectoryUri(dstUri);\n+        ImmutableList.Builder<URI> builder = ImmutableList.builder();\n+        Path srcPath = Paths.get(srcUri.getPath());\n+        try {\n+            boolean copySucceeded = true;\n+            for (String directoryEntry : listFiles(srcUri, true)) {\n+                URI src = new URI(srcUri.getScheme(), srcUri.getHost(), directoryEntry, null);\n+                String relativeSrcPath = srcPath.relativize(Paths.get(directoryEntry)).toString();\n+                String dstPath = dstUri.resolve(relativeSrcPath).getPath();\n+                URI dst = new URI(dstUri.getScheme(), dstUri.getHost(), dstPath, null);\n+                copySucceeded &= copyFile(src, dst);\n+            }\n+            return copySucceeded;\n+        } catch (URISyntaxException e) {\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    @Override\n+    public boolean exists(URI fileUri) throws IOException {\n+        try {\n+            if (isDirectory(fileUri)) {\n+                return true;\n+            }\n+            if (isPathTerminatedByDelimiter(fileUri)) {\n+                return false;\n+            }\n+            return existsFile(fileUri);\n+        }catch(NoSuchKeyException e){\n+            return false;\n+        }\n+    }\n+\n+    @Override\n+    public long length(URI fileUri) throws IOException {\n+        try {\n+            checkState(!isPathTerminatedByDelimiter(fileUri), \"URI is a directory\");\n+            HeadObjectResponse s3ObjectMetadata = getS3ObjectMetadata(fileUri);\n+            checkState((s3ObjectMetadata != null), \"File '%s' does not exist\", fileUri);\n+            if(s3ObjectMetadata.contentLength() == null){\n+                return 0;\n+            }\n+            return s3ObjectMetadata.contentLength();\n+        } catch (Throwable t) {\n+            throw new IOException(t);\n+        }\n+    }\n+\n+    @Override\n+    public String[] listFiles(URI fileUri, boolean recursive) throws IOException {\n+        try {\n+            ImmutableList.Builder<String> builder = ImmutableList.builder();\n+            String prefix = normalizeToDirectoryPrefix(fileUri);\n+            ListObjectsV2Response listObjectsV2Response;\n+            ListObjectsV2Request.Builder listObjectsV2RequestBuilder = ListObjectsV2Request.builder()\n+                    .bucket(fileUri.getHost())\n+                    .prefix(prefix);\n+\n+            if (recursive) {\n+                ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.build();\n+                listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);\n+            } else {\n+                ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.delimiter(DELIMITER).build();\n+                listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);\n+            }\n+\n+            listObjectsV2Response.contents().stream()\n+                    .forEach(object -> {\n+                        //Only add files and not directories\n+                        if (!object.key().equals(fileUri.getPath()) && !object.key().endsWith(DELIMITER)) {\n+                            builder.add(object.key());\n+                        }\n+                    });\n+            return builder.build().toArray(new String[0]);\n+        } catch (Throwable t) {\n+            throw new IOException(t);\n+        }\n+    }\n+\n+    @Override\n+    public void copyToLocalFile(URI srcUri, File dstFile) throws Exception {\n+        LOGGER.info(\"Copy {} to local {}\", srcUri, dstFile.getAbsolutePath());\n+        URI base = getBase(srcUri);\n+        String prefix = sanitizePath(base.relativize(srcUri).getPath());\n+        GetObjectRequest getObjectRequest = GetObjectRequest.builder()\n+                .bucket(srcUri.getHost())\n+                .key(prefix)\n+                .build();\n+\n+        s3Client.getObject(getObjectRequest, ResponseTransformer.toFile(dstFile));\n+    }\n+\n+    @Override\n+    public void copyFromLocalFile(File srcFile, URI dstUri) throws Exception {\n+        LOGGER.info(\"Copy {} from local to {}\", srcFile.getAbsolutePath(), dstUri);\n+        URI base = getBase(dstUri);\n+        String prefix = sanitizePath(base.relativize(dstUri).getPath());\n+        PutObjectRequest putObjectRequest = PutObjectRequest.builder()\n+                .bucket(dstUri.getHost())\n+                .key(prefix)\n+                .build();\n+\n+        PutObjectResponse putObjectResponse = s3Client.putObject(putObjectRequest, srcFile.toPath());\n+    }\n+\n+    @Override\n+    public boolean isDirectory(URI uri){\n+        try{\n+            String prefix = sanitizePath(uri.getPath());\n+            if (prefix.equals(DELIMITER)) {\n+                return true;\n+            }\n+            HeadObjectResponse s3ObjectMetadata;\n+            HeadObjectRequest headObjectRequest = HeadObjectRequest.builder()\n+                    .bucket(uri.getHost())\n+                    .key(prefix)\n+                    .build();\n+            s3ObjectMetadata = s3Client.headObject(headObjectRequest);\n+            return s3ObjectMetadata.contentType().contentEquals(\"application/x-directory\");\n+        }catch(NoSuchKeyException e){\n+            LOGGER.error(\"Could not get directory entry for {}\", uri);\n+            return false;\n+        }\n+    }\n+\n+    @Override\n+    public long lastModified(URI uri) throws IOException {\n+        return getS3ObjectMetadata(uri).lastModified().toEpochMilli();\n+    }\n+\n+    @Override\n+    public boolean touch(URI uri) throws IOException {\n+        try {\n+                HeadObjectResponse s3ObjectMetadata = getS3ObjectMetadata(uri);\n+                String encodedUrl = null;\n+                try {\n+                    encodedUrl = URLEncoder.encode(uri.getHost() + uri.getPath(), StandardCharsets.UTF_8.toString());\n+                } catch (UnsupportedEncodingException e) {\n+                    LOGGER.info(\"URL could not be encoded: {}\", e.getMessage());\n+                }\n+\n+                String path = sanitizePath(uri.getPath());\n+                Map<String, String> mp = new HashMap<>();\n+                mp.put(\"lastModified\", String.valueOf(System.currentTimeMillis()));\n+                CopyObjectRequest request = CopyObjectRequest.builder()\n+                        .copySource(encodedUrl)\n+                        .destinationBucket(uri.getHost())\n+                        .destinationKey(path)\n+                        .metadata(mp)\n+                        .metadataDirective(MetadataDirective.REPLACE)\n+                        .build();\n+\n+                System.out.println(\"COPY\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a55cc4ceef627cf87d4ce344435ded19f249b49"}, "originalPosition": 451}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjQ0MjQ0Mw==", "bodyText": "done", "url": "https://github.com/apache/pinot/pull/5249#discussion_r412442443", "createdAt": "2020-04-21T19:45:14Z", "author": {"login": "KKcorps"}, "path": "pinot-plugins/pinot-file-system/pinot-s3/src/main/java/org/apache/pinot/plugin/filesystem/S3PinotFS.java", "diffHunk": "@@ -0,0 +1,485 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.plugin.filesystem;\n+\n+import com.google.common.collect.ImmutableList;\n+import org.apache.commons.configuration.Configuration;\n+import org.apache.pinot.spi.filesystem.PinotFS;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import software.amazon.awssdk.auth.credentials.AwsBasicCredentials;\n+import software.amazon.awssdk.auth.credentials.EnvironmentVariableCredentialsProvider;\n+import software.amazon.awssdk.auth.credentials.StaticCredentialsProvider;\n+import software.amazon.awssdk.core.ResponseBytes;\n+import software.amazon.awssdk.core.exception.SdkClientException;\n+import software.amazon.awssdk.core.exception.SdkServiceException;\n+import software.amazon.awssdk.core.sync.RequestBody;\n+import software.amazon.awssdk.core.sync.ResponseTransformer;\n+import software.amazon.awssdk.regions.Region;\n+import software.amazon.awssdk.services.s3.S3Client;\n+import software.amazon.awssdk.services.s3.internal.resource.S3BucketResource;\n+import software.amazon.awssdk.services.s3.model.*;\n+\n+import java.io.*;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.net.URLEncoder;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.Date;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkState;\n+import static java.util.Objects.requireNonNull;\n+import static joptsimple.internal.Strings.isNullOrEmpty;\n+import static org.glassfish.jersey.internal.guava.Preconditions.checkArgument;\n+\n+public class S3PinotFS extends PinotFS {\n+    public static final String ACCESS_KEY = \"accessKey\";\n+    public static final String SECRET_KEY = \"secretKey\";\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(S3PinotFS.class);\n+    private static final String DELIMITER = \"/\";\n+    private S3Client s3Client;\n+\n+    @Override\n+    public void init(Configuration config) {\n+        checkArgument(!isNullOrEmpty(config.getString(ACCESS_KEY)));\n+        checkArgument(!isNullOrEmpty(config.getString(SECRET_KEY)));\n+        String accessKey = config.getString(ACCESS_KEY);\n+        String secretKey = config.getString(SECRET_KEY);\n+        try {\n+            AwsBasicCredentials awsBasicCredentials = AwsBasicCredentials.create(accessKey, secretKey);\n+            s3Client = S3Client.builder()\n+                    .region(Region.AP_SOUTHEAST_1)\n+                    .credentialsProvider(StaticCredentialsProvider.create(awsBasicCredentials))\n+                    .build();\n+\n+        } catch (S3Exception e) {\n+            throw new RuntimeException(\"Could not initialize S3PinotFS\", e);\n+        }\n+    }\n+\n+    private HeadObjectResponse getS3ObjectMetadata(URI uri) throws IOException {\n+            URI base = getBase(uri);\n+            String path = sanitizePath(base.relativize(uri).getPath());\n+            HeadObjectRequest headObjectRequest = HeadObjectRequest.builder()\n+                    .bucket(uri.getHost())\n+                    .key(path)\n+                    .build();\n+\n+            return s3Client.headObject(headObjectRequest);\n+    }\n+\n+    private boolean isPathTerminatedByDelimiter(URI uri) {\n+        return uri.getPath().endsWith(DELIMITER);\n+    }\n+\n+    private String normalizeToDirectoryPrefix(URI uri) throws IOException {\n+        requireNonNull(uri, \"uri is null\");\n+        URI strippedUri = getBase(uri).relativize(uri);\n+        if (isPathTerminatedByDelimiter(strippedUri)) {\n+            return sanitizePath(strippedUri.getPath());\n+        }\n+        return sanitizePath(strippedUri.getPath() + DELIMITER);\n+    }\n+\n+    private URI normalizeToDirectoryUri(URI uri) throws IOException {\n+        if (isPathTerminatedByDelimiter(uri)) {\n+            return uri;\n+        }\n+        try {\n+            return new URI(uri.getScheme(), uri.getHost(), sanitizePath(uri.getPath() + DELIMITER), null);\n+        } catch (URISyntaxException e) {\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    private String sanitizePath(String path) {\n+        path = path.replaceAll(DELIMITER + \"+\", DELIMITER);\n+        if (path.startsWith(DELIMITER) && !path.equals(DELIMITER)) {\n+            path = path.substring(1);\n+        }\n+        return path;\n+    }\n+\n+    private URI getBase(URI uri) throws IOException {\n+        try {\n+            return new URI(uri.getScheme(), uri.getHost(), null, null);\n+        } catch (URISyntaxException e) {\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    private boolean existsFile(URI uri) throws IOException {\n+        try {\n+            URI base = getBase(uri);\n+            String path = sanitizePath(base.relativize(uri).getPath());\n+            HeadObjectRequest headObjectRequest = HeadObjectRequest.builder()\n+                    .bucket(uri.getHost())\n+                    .key(path)\n+                    .build();\n+\n+            s3Client.headObject(headObjectRequest);\n+            return true;\n+        }catch(NoSuchKeyException e){\n+            return false;\n+        }catch(S3Exception e){\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    private boolean isEmptyDirectory(URI uri) throws IOException {\n+        if (!isDirectory(uri)) {\n+            return false;\n+        }\n+        String prefix = normalizeToDirectoryPrefix(uri);\n+        boolean isEmpty = true;\n+        ListObjectsV2Response listObjectsV2Response;\n+        ListObjectsV2Request.Builder listObjectsV2RequestBuilder = ListObjectsV2Request.builder()\n+                .bucket(uri.getHost());\n+\n+        if (prefix.equals(DELIMITER)) {\n+            ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.build();\n+            listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);\n+        } else {\n+            ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.prefix(prefix).build();\n+            listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);\n+        }\n+        for (S3Object s3Object : listObjectsV2Response.contents()) {\n+            if (s3Object.key().equals(prefix)) {\n+                continue;\n+            } else {\n+                isEmpty = false;\n+                break;\n+            }\n+        }\n+        return isEmpty;\n+    }\n+\n+    private boolean copyFile(URI srcUri, URI dstUri) throws IOException {\n+        try {\n+            String encodedUrl = null;\n+            try {\n+                encodedUrl = URLEncoder.encode(srcUri.getHost() + srcUri.getPath(), StandardCharsets.UTF_8.toString());\n+            } catch (UnsupportedEncodingException e) {\n+                LOGGER.info(\"URL could not be encoded: {}\", e.getMessage());\n+            }\n+\n+            String dstPath = sanitizePath(dstUri.getPath());\n+            CopyObjectRequest copyReq = CopyObjectRequest.builder()\n+                    .copySource(encodedUrl)\n+                    .destinationBucket(dstUri.getHost())\n+                    .destinationKey(dstPath)\n+                    .build();\n+\n+            CopyObjectResponse copyObjectResponse = s3Client.copyObject(copyReq);\n+            return copyObjectResponse.sdkHttpResponse().isSuccessful();\n+        }catch(S3Exception e){\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    @Override\n+    public boolean mkdir(URI uri) throws IOException {\n+        LOGGER.info(\"mkdir {}\", uri);\n+        try {\n+            requireNonNull(uri, \"uri is null\");\n+            String path = normalizeToDirectoryPrefix(uri);\n+            // Bucket root directory already exists and cannot be created\n+            if (path.equals(DELIMITER)) {\n+                return true;\n+            }\n+\n+            PutObjectRequest putObjectRequest = PutObjectRequest.builder()\n+                    .bucket(uri.getHost())\n+                    .key(path)\n+                    .build();\n+\n+            PutObjectResponse putObjectResponse = s3Client.putObject(putObjectRequest, RequestBody.fromBytes(new byte[0]));\n+\n+            return putObjectResponse.sdkHttpResponse().isSuccessful();\n+        } catch (Throwable t) {\n+            throw new IOException(t);\n+        }\n+    }\n+\n+    @Override\n+    public boolean delete(URI segmentUri, boolean forceDelete) throws IOException {\n+        LOGGER.info(\"Deleting uri {} force {}\", segmentUri, forceDelete);\n+        try {\n+            if (isDirectory(segmentUri)) {\n+                if (!forceDelete) {\n+                    checkState(isEmptyDirectory(segmentUri), \"ForceDelete flag is not set and directory '%s' is not empty\", segmentUri);\n+                }\n+                String prefix = normalizeToDirectoryPrefix(segmentUri);\n+                ListObjectsV2Response listObjectsV2Response;\n+                ListObjectsV2Request.Builder listObjectsV2RequestBuilder = ListObjectsV2Request.builder()\n+                        .bucket(segmentUri.getHost());\n+\n+                if (prefix.equals(DELIMITER)) {\n+                    ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.build();\n+                    listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);\n+                } else {\n+                    ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.prefix(prefix).build();\n+                    listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);\n+                }\n+                boolean deleteSucceeded = true;\n+                for (S3Object s3Object : listObjectsV2Response.contents()) {\n+                    DeleteObjectRequest deleteObjectRequest = DeleteObjectRequest.builder()\n+                            .bucket(segmentUri.getHost())\n+                            .key(s3Object.key())\n+                            .build();\n+\n+                    DeleteObjectResponse deleteObjectResponse = s3Client.deleteObject(deleteObjectRequest);\n+\n+                    deleteSucceeded &= deleteObjectResponse.sdkHttpResponse().isSuccessful();\n+                }\n+                return deleteSucceeded;\n+            } else {\n+                String prefix = sanitizePath(segmentUri.getPath());\n+                DeleteObjectRequest deleteObjectRequest = DeleteObjectRequest.builder()\n+                        .bucket(segmentUri.getHost())\n+                        .key(prefix)\n+                        .build();\n+\n+                DeleteObjectResponse deleteObjectResponse = s3Client.deleteObject(deleteObjectRequest);\n+\n+                return deleteObjectResponse.sdkHttpResponse().isSuccessful();\n+            }\n+        }catch(NoSuchKeyException e){\n+            return false;\n+        } catch (S3Exception e) {\n+            throw e;\n+        } catch(Throwable t) {\n+            throw new IOException(t);\n+        }\n+    }\n+\n+    @Override\n+    public boolean doMove(URI srcUri, URI dstUri) throws IOException {\n+        if (copy(srcUri, dstUri)) {\n+            return  delete(srcUri, true);\n+        }\n+        return false;\n+    }\n+\n+    @Override\n+    public boolean copy(URI srcUri, URI dstUri) throws IOException {\n+        LOGGER.info(\"Copying uri {} to uri {}\", srcUri, dstUri);\n+        checkState(exists(srcUri), \"Source URI '%s' does not exist\", srcUri);\n+        if (srcUri.equals(dstUri)) {\n+            return true;\n+        }\n+        if (!isDirectory(srcUri)) {\n+            delete(dstUri, true);\n+            return copyFile(srcUri, dstUri);\n+        }\n+        dstUri = normalizeToDirectoryUri(dstUri);\n+        ImmutableList.Builder<URI> builder = ImmutableList.builder();\n+        Path srcPath = Paths.get(srcUri.getPath());\n+        try {\n+            boolean copySucceeded = true;\n+            for (String directoryEntry : listFiles(srcUri, true)) {\n+                URI src = new URI(srcUri.getScheme(), srcUri.getHost(), directoryEntry, null);\n+                String relativeSrcPath = srcPath.relativize(Paths.get(directoryEntry)).toString();\n+                String dstPath = dstUri.resolve(relativeSrcPath).getPath();\n+                URI dst = new URI(dstUri.getScheme(), dstUri.getHost(), dstPath, null);\n+                copySucceeded &= copyFile(src, dst);\n+            }\n+            return copySucceeded;\n+        } catch (URISyntaxException e) {\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    @Override\n+    public boolean exists(URI fileUri) throws IOException {\n+        try {\n+            if (isDirectory(fileUri)) {\n+                return true;\n+            }\n+            if (isPathTerminatedByDelimiter(fileUri)) {\n+                return false;\n+            }\n+            return existsFile(fileUri);\n+        }catch(NoSuchKeyException e){\n+            return false;\n+        }\n+    }\n+\n+    @Override\n+    public long length(URI fileUri) throws IOException {\n+        try {\n+            checkState(!isPathTerminatedByDelimiter(fileUri), \"URI is a directory\");\n+            HeadObjectResponse s3ObjectMetadata = getS3ObjectMetadata(fileUri);\n+            checkState((s3ObjectMetadata != null), \"File '%s' does not exist\", fileUri);\n+            if(s3ObjectMetadata.contentLength() == null){\n+                return 0;\n+            }\n+            return s3ObjectMetadata.contentLength();\n+        } catch (Throwable t) {\n+            throw new IOException(t);\n+        }\n+    }\n+\n+    @Override\n+    public String[] listFiles(URI fileUri, boolean recursive) throws IOException {\n+        try {\n+            ImmutableList.Builder<String> builder = ImmutableList.builder();\n+            String prefix = normalizeToDirectoryPrefix(fileUri);\n+            ListObjectsV2Response listObjectsV2Response;\n+            ListObjectsV2Request.Builder listObjectsV2RequestBuilder = ListObjectsV2Request.builder()\n+                    .bucket(fileUri.getHost())\n+                    .prefix(prefix);\n+\n+            if (recursive) {\n+                ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.build();\n+                listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);\n+            } else {\n+                ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.delimiter(DELIMITER).build();\n+                listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);\n+            }\n+\n+            listObjectsV2Response.contents().stream()\n+                    .forEach(object -> {\n+                        //Only add files and not directories\n+                        if (!object.key().equals(fileUri.getPath()) && !object.key().endsWith(DELIMITER)) {\n+                            builder.add(object.key());\n+                        }\n+                    });\n+            return builder.build().toArray(new String[0]);\n+        } catch (Throwable t) {\n+            throw new IOException(t);\n+        }\n+    }\n+\n+    @Override\n+    public void copyToLocalFile(URI srcUri, File dstFile) throws Exception {\n+        LOGGER.info(\"Copy {} to local {}\", srcUri, dstFile.getAbsolutePath());\n+        URI base = getBase(srcUri);\n+        String prefix = sanitizePath(base.relativize(srcUri).getPath());\n+        GetObjectRequest getObjectRequest = GetObjectRequest.builder()\n+                .bucket(srcUri.getHost())\n+                .key(prefix)\n+                .build();\n+\n+        s3Client.getObject(getObjectRequest, ResponseTransformer.toFile(dstFile));\n+    }\n+\n+    @Override\n+    public void copyFromLocalFile(File srcFile, URI dstUri) throws Exception {\n+        LOGGER.info(\"Copy {} from local to {}\", srcFile.getAbsolutePath(), dstUri);\n+        URI base = getBase(dstUri);\n+        String prefix = sanitizePath(base.relativize(dstUri).getPath());\n+        PutObjectRequest putObjectRequest = PutObjectRequest.builder()\n+                .bucket(dstUri.getHost())\n+                .key(prefix)\n+                .build();\n+\n+        PutObjectResponse putObjectResponse = s3Client.putObject(putObjectRequest, srcFile.toPath());\n+    }\n+\n+    @Override\n+    public boolean isDirectory(URI uri){\n+        try{\n+            String prefix = sanitizePath(uri.getPath());\n+            if (prefix.equals(DELIMITER)) {\n+                return true;\n+            }\n+            HeadObjectResponse s3ObjectMetadata;\n+            HeadObjectRequest headObjectRequest = HeadObjectRequest.builder()\n+                    .bucket(uri.getHost())\n+                    .key(prefix)\n+                    .build();\n+            s3ObjectMetadata = s3Client.headObject(headObjectRequest);\n+            return s3ObjectMetadata.contentType().contentEquals(\"application/x-directory\");\n+        }catch(NoSuchKeyException e){\n+            LOGGER.error(\"Could not get directory entry for {}\", uri);\n+            return false;\n+        }\n+    }\n+\n+    @Override\n+    public long lastModified(URI uri) throws IOException {\n+        return getS3ObjectMetadata(uri).lastModified().toEpochMilli();\n+    }\n+\n+    @Override\n+    public boolean touch(URI uri) throws IOException {\n+        try {\n+                HeadObjectResponse s3ObjectMetadata = getS3ObjectMetadata(uri);\n+                String encodedUrl = null;\n+                try {\n+                    encodedUrl = URLEncoder.encode(uri.getHost() + uri.getPath(), StandardCharsets.UTF_8.toString());\n+                } catch (UnsupportedEncodingException e) {\n+                    LOGGER.info(\"URL could not be encoded: {}\", e.getMessage());\n+                }\n+\n+                String path = sanitizePath(uri.getPath());\n+                Map<String, String> mp = new HashMap<>();\n+                mp.put(\"lastModified\", String.valueOf(System.currentTimeMillis()));\n+                CopyObjectRequest request = CopyObjectRequest.builder()\n+                        .copySource(encodedUrl)\n+                        .destinationBucket(uri.getHost())\n+                        .destinationKey(path)\n+                        .metadata(mp)\n+                        .metadataDirective(MetadataDirective.REPLACE)\n+                        .build();\n+\n+                System.out.println(\"COPY\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI3MTgyOA=="}, "originalCommit": {"oid": "4a55cc4ceef627cf87d4ce344435ded19f249b49"}, "originalPosition": 451}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0MTA4NjMxOnYy", "diffSide": "RIGHT", "path": "pinot-plugins/pinot-file-system/pinot-s3/pom.xml", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwNDo1Mzo1M1rOGGUhSA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQxOTo0NDowM1rOGJVcmw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI4MDg0MA==", "bodyText": "make version into a pom property.", "url": "https://github.com/apache/pinot/pull/5249#discussion_r409280840", "createdAt": "2020-04-16T04:53:53Z", "author": {"login": "xiangfu0"}, "path": "pinot-plugins/pinot-file-system/pinot-s3/pom.xml", "diffHunk": "@@ -0,0 +1,154 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+\n+-->\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n+         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n+         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+    <modelVersion>4.0.0</modelVersion>\n+    <parent>\n+        <artifactId>pinot-file-system</artifactId>\n+        <groupId>org.apache.pinot</groupId>\n+        <version>${revision}${sha1}</version>\n+        <relativePath>..</relativePath>\n+    </parent>\n+\n+    <artifactId>pinot-s3</artifactId>\n+    <name>Pinot Amazon S3</name>\n+    <url>https://pinot.apache.org</url>\n+    <properties>\n+        <pinot.root>${basedir}/../../..</pinot.root>\n+    </properties>\n+\n+    <dependencyManagement>\n+        <dependencies>\n+            <dependency>\n+                <groupId>software.amazon.awssdk</groupId>\n+                <artifactId>bom</artifactId>\n+                <version>2.11.12</version>\n+                <type>pom</type>\n+                <scope>import</scope>\n+            </dependency>\n+        </dependencies>\n+    </dependencyManagement>\n+\n+    <dependencies>\n+        <dependency>\n+            <groupId>commons-configuration</groupId>\n+            <artifactId>commons-configuration</artifactId>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.apache.pinot</groupId>\n+            <artifactId>pinot-spi</artifactId>\n+            <version>0.4.0-SNAPSHOT</version>\n+        </dependency>\n+        <!-- amazon s3 -->\n+        <dependency>\n+            <groupId>software.amazon.awssdk</groupId>\n+            <artifactId>s3</artifactId>\n+            <version>2.11.12</version>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a55cc4ceef627cf87d4ce344435ded19f249b49"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjQ0MTc1NQ==", "bodyText": "done", "url": "https://github.com/apache/pinot/pull/5249#discussion_r412441755", "createdAt": "2020-04-21T19:44:03Z", "author": {"login": "KKcorps"}, "path": "pinot-plugins/pinot-file-system/pinot-s3/pom.xml", "diffHunk": "@@ -0,0 +1,154 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+\n+-->\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n+         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n+         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+    <modelVersion>4.0.0</modelVersion>\n+    <parent>\n+        <artifactId>pinot-file-system</artifactId>\n+        <groupId>org.apache.pinot</groupId>\n+        <version>${revision}${sha1}</version>\n+        <relativePath>..</relativePath>\n+    </parent>\n+\n+    <artifactId>pinot-s3</artifactId>\n+    <name>Pinot Amazon S3</name>\n+    <url>https://pinot.apache.org</url>\n+    <properties>\n+        <pinot.root>${basedir}/../../..</pinot.root>\n+    </properties>\n+\n+    <dependencyManagement>\n+        <dependencies>\n+            <dependency>\n+                <groupId>software.amazon.awssdk</groupId>\n+                <artifactId>bom</artifactId>\n+                <version>2.11.12</version>\n+                <type>pom</type>\n+                <scope>import</scope>\n+            </dependency>\n+        </dependencies>\n+    </dependencyManagement>\n+\n+    <dependencies>\n+        <dependency>\n+            <groupId>commons-configuration</groupId>\n+            <artifactId>commons-configuration</artifactId>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.apache.pinot</groupId>\n+            <artifactId>pinot-spi</artifactId>\n+            <version>0.4.0-SNAPSHOT</version>\n+        </dependency>\n+        <!-- amazon s3 -->\n+        <dependency>\n+            <groupId>software.amazon.awssdk</groupId>\n+            <artifactId>s3</artifactId>\n+            <version>2.11.12</version>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI4MDg0MA=="}, "originalCommit": {"oid": "4a55cc4ceef627cf87d4ce344435ded19f249b49"}, "originalPosition": 66}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0MTA4ODU0OnYy", "diffSide": "RIGHT", "path": "pinot-plugins/pinot-file-system/pinot-s3/src/main/java/org/apache/pinot/plugin/filesystem/S3PinotFS.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwNDo1NDo1NlrOGGUiiA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQxOTo0Mzo1N1rOGJVcYQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI4MTE2MA==", "bodyText": "expand .* imports", "url": "https://github.com/apache/pinot/pull/5249#discussion_r409281160", "createdAt": "2020-04-16T04:54:56Z", "author": {"login": "xiangfu0"}, "path": "pinot-plugins/pinot-file-system/pinot-s3/src/main/java/org/apache/pinot/plugin/filesystem/S3PinotFS.java", "diffHunk": "@@ -0,0 +1,485 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.plugin.filesystem;\n+\n+import com.google.common.collect.ImmutableList;\n+import org.apache.commons.configuration.Configuration;\n+import org.apache.pinot.spi.filesystem.PinotFS;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import software.amazon.awssdk.auth.credentials.AwsBasicCredentials;\n+import software.amazon.awssdk.auth.credentials.EnvironmentVariableCredentialsProvider;\n+import software.amazon.awssdk.auth.credentials.StaticCredentialsProvider;\n+import software.amazon.awssdk.core.ResponseBytes;\n+import software.amazon.awssdk.core.exception.SdkClientException;\n+import software.amazon.awssdk.core.exception.SdkServiceException;\n+import software.amazon.awssdk.core.sync.RequestBody;\n+import software.amazon.awssdk.core.sync.ResponseTransformer;\n+import software.amazon.awssdk.regions.Region;\n+import software.amazon.awssdk.services.s3.S3Client;\n+import software.amazon.awssdk.services.s3.internal.resource.S3BucketResource;\n+import software.amazon.awssdk.services.s3.model.*;\n+\n+import java.io.*;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a55cc4ceef627cf87d4ce344435ded19f249b49"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjQ0MTY5Nw==", "bodyText": "done", "url": "https://github.com/apache/pinot/pull/5249#discussion_r412441697", "createdAt": "2020-04-21T19:43:57Z", "author": {"login": "KKcorps"}, "path": "pinot-plugins/pinot-file-system/pinot-s3/src/main/java/org/apache/pinot/plugin/filesystem/S3PinotFS.java", "diffHunk": "@@ -0,0 +1,485 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.plugin.filesystem;\n+\n+import com.google.common.collect.ImmutableList;\n+import org.apache.commons.configuration.Configuration;\n+import org.apache.pinot.spi.filesystem.PinotFS;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import software.amazon.awssdk.auth.credentials.AwsBasicCredentials;\n+import software.amazon.awssdk.auth.credentials.EnvironmentVariableCredentialsProvider;\n+import software.amazon.awssdk.auth.credentials.StaticCredentialsProvider;\n+import software.amazon.awssdk.core.ResponseBytes;\n+import software.amazon.awssdk.core.exception.SdkClientException;\n+import software.amazon.awssdk.core.exception.SdkServiceException;\n+import software.amazon.awssdk.core.sync.RequestBody;\n+import software.amazon.awssdk.core.sync.ResponseTransformer;\n+import software.amazon.awssdk.regions.Region;\n+import software.amazon.awssdk.services.s3.S3Client;\n+import software.amazon.awssdk.services.s3.internal.resource.S3BucketResource;\n+import software.amazon.awssdk.services.s3.model.*;\n+\n+import java.io.*;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI4MTE2MA=="}, "originalCommit": {"oid": "4a55cc4ceef627cf87d4ce344435ded19f249b49"}, "originalPosition": 39}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0MTA5MjUwOnYy", "diffSide": "RIGHT", "path": "pinot-plugins/pinot-file-system/pinot-s3/src/main/java/org/apache/pinot/plugin/filesystem/S3PinotFS.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwNDo1NzoyM1rOGGUk0w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQxOTo0Mzo0OVrOGJVb_w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI4MTc0Nw==", "bodyText": "Can we also add the support of checking System properties and environment variable?\nThis is to allow more flexible way to config the application.\nAs usually in kubernetes environment, people may store these credential as a Secrets then import as Environment Variables.", "url": "https://github.com/apache/pinot/pull/5249#discussion_r409281747", "createdAt": "2020-04-16T04:57:23Z", "author": {"login": "xiangfu0"}, "path": "pinot-plugins/pinot-file-system/pinot-s3/src/main/java/org/apache/pinot/plugin/filesystem/S3PinotFS.java", "diffHunk": "@@ -0,0 +1,485 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.plugin.filesystem;\n+\n+import com.google.common.collect.ImmutableList;\n+import org.apache.commons.configuration.Configuration;\n+import org.apache.pinot.spi.filesystem.PinotFS;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import software.amazon.awssdk.auth.credentials.AwsBasicCredentials;\n+import software.amazon.awssdk.auth.credentials.EnvironmentVariableCredentialsProvider;\n+import software.amazon.awssdk.auth.credentials.StaticCredentialsProvider;\n+import software.amazon.awssdk.core.ResponseBytes;\n+import software.amazon.awssdk.core.exception.SdkClientException;\n+import software.amazon.awssdk.core.exception.SdkServiceException;\n+import software.amazon.awssdk.core.sync.RequestBody;\n+import software.amazon.awssdk.core.sync.ResponseTransformer;\n+import software.amazon.awssdk.regions.Region;\n+import software.amazon.awssdk.services.s3.S3Client;\n+import software.amazon.awssdk.services.s3.internal.resource.S3BucketResource;\n+import software.amazon.awssdk.services.s3.model.*;\n+\n+import java.io.*;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.net.URLEncoder;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.Date;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkState;\n+import static java.util.Objects.requireNonNull;\n+import static joptsimple.internal.Strings.isNullOrEmpty;\n+import static org.glassfish.jersey.internal.guava.Preconditions.checkArgument;\n+\n+public class S3PinotFS extends PinotFS {\n+    public static final String ACCESS_KEY = \"accessKey\";\n+    public static final String SECRET_KEY = \"secretKey\";\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(S3PinotFS.class);\n+    private static final String DELIMITER = \"/\";\n+    private S3Client s3Client;\n+\n+    @Override\n+    public void init(Configuration config) {\n+        checkArgument(!isNullOrEmpty(config.getString(ACCESS_KEY)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a55cc4ceef627cf87d4ce344435ded19f249b49"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTU3MTU2Mw==", "bodyText": "That makes sense. So should I create like levels of fallbacks i.e. first check Env, then System properties and finally the configuration given?", "url": "https://github.com/apache/pinot/pull/5249#discussion_r409571563", "createdAt": "2020-04-16T13:50:19Z", "author": {"login": "KKcorps"}, "path": "pinot-plugins/pinot-file-system/pinot-s3/src/main/java/org/apache/pinot/plugin/filesystem/S3PinotFS.java", "diffHunk": "@@ -0,0 +1,485 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.plugin.filesystem;\n+\n+import com.google.common.collect.ImmutableList;\n+import org.apache.commons.configuration.Configuration;\n+import org.apache.pinot.spi.filesystem.PinotFS;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import software.amazon.awssdk.auth.credentials.AwsBasicCredentials;\n+import software.amazon.awssdk.auth.credentials.EnvironmentVariableCredentialsProvider;\n+import software.amazon.awssdk.auth.credentials.StaticCredentialsProvider;\n+import software.amazon.awssdk.core.ResponseBytes;\n+import software.amazon.awssdk.core.exception.SdkClientException;\n+import software.amazon.awssdk.core.exception.SdkServiceException;\n+import software.amazon.awssdk.core.sync.RequestBody;\n+import software.amazon.awssdk.core.sync.ResponseTransformer;\n+import software.amazon.awssdk.regions.Region;\n+import software.amazon.awssdk.services.s3.S3Client;\n+import software.amazon.awssdk.services.s3.internal.resource.S3BucketResource;\n+import software.amazon.awssdk.services.s3.model.*;\n+\n+import java.io.*;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.net.URLEncoder;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.Date;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkState;\n+import static java.util.Objects.requireNonNull;\n+import static joptsimple.internal.Strings.isNullOrEmpty;\n+import static org.glassfish.jersey.internal.guava.Preconditions.checkArgument;\n+\n+public class S3PinotFS extends PinotFS {\n+    public static final String ACCESS_KEY = \"accessKey\";\n+    public static final String SECRET_KEY = \"secretKey\";\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(S3PinotFS.class);\n+    private static final String DELIMITER = \"/\";\n+    private S3Client s3Client;\n+\n+    @Override\n+    public void init(Configuration config) {\n+        checkArgument(!isNullOrEmpty(config.getString(ACCESS_KEY)));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI4MTc0Nw=="}, "originalCommit": {"oid": "4a55cc4ceef627cf87d4ce344435ded19f249b49"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTczODUwNA==", "bodyText": "yes, just the order should be reverse, if people specify the config, then we should always honor that. If configs are not existed, then we check system properties. if system properties doesn't exist, then we  check env var.\nAlso this needs to be documented :)\nThanks!", "url": "https://github.com/apache/pinot/pull/5249#discussion_r409738504", "createdAt": "2020-04-16T17:46:15Z", "author": {"login": "xiangfu0"}, "path": "pinot-plugins/pinot-file-system/pinot-s3/src/main/java/org/apache/pinot/plugin/filesystem/S3PinotFS.java", "diffHunk": "@@ -0,0 +1,485 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.plugin.filesystem;\n+\n+import com.google.common.collect.ImmutableList;\n+import org.apache.commons.configuration.Configuration;\n+import org.apache.pinot.spi.filesystem.PinotFS;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import software.amazon.awssdk.auth.credentials.AwsBasicCredentials;\n+import software.amazon.awssdk.auth.credentials.EnvironmentVariableCredentialsProvider;\n+import software.amazon.awssdk.auth.credentials.StaticCredentialsProvider;\n+import software.amazon.awssdk.core.ResponseBytes;\n+import software.amazon.awssdk.core.exception.SdkClientException;\n+import software.amazon.awssdk.core.exception.SdkServiceException;\n+import software.amazon.awssdk.core.sync.RequestBody;\n+import software.amazon.awssdk.core.sync.ResponseTransformer;\n+import software.amazon.awssdk.regions.Region;\n+import software.amazon.awssdk.services.s3.S3Client;\n+import software.amazon.awssdk.services.s3.internal.resource.S3BucketResource;\n+import software.amazon.awssdk.services.s3.model.*;\n+\n+import java.io.*;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.net.URLEncoder;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.Date;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkState;\n+import static java.util.Objects.requireNonNull;\n+import static joptsimple.internal.Strings.isNullOrEmpty;\n+import static org.glassfish.jersey.internal.guava.Preconditions.checkArgument;\n+\n+public class S3PinotFS extends PinotFS {\n+    public static final String ACCESS_KEY = \"accessKey\";\n+    public static final String SECRET_KEY = \"secretKey\";\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(S3PinotFS.class);\n+    private static final String DELIMITER = \"/\";\n+    private S3Client s3Client;\n+\n+    @Override\n+    public void init(Configuration config) {\n+        checkArgument(!isNullOrEmpty(config.getString(ACCESS_KEY)));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI4MTc0Nw=="}, "originalCommit": {"oid": "4a55cc4ceef627cf87d4ce344435ded19f249b49"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTc4NzQwNQ==", "bodyText": "cool. Does it look good now?", "url": "https://github.com/apache/pinot/pull/5249#discussion_r409787405", "createdAt": "2020-04-16T19:10:11Z", "author": {"login": "KKcorps"}, "path": "pinot-plugins/pinot-file-system/pinot-s3/src/main/java/org/apache/pinot/plugin/filesystem/S3PinotFS.java", "diffHunk": "@@ -0,0 +1,485 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.plugin.filesystem;\n+\n+import com.google.common.collect.ImmutableList;\n+import org.apache.commons.configuration.Configuration;\n+import org.apache.pinot.spi.filesystem.PinotFS;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import software.amazon.awssdk.auth.credentials.AwsBasicCredentials;\n+import software.amazon.awssdk.auth.credentials.EnvironmentVariableCredentialsProvider;\n+import software.amazon.awssdk.auth.credentials.StaticCredentialsProvider;\n+import software.amazon.awssdk.core.ResponseBytes;\n+import software.amazon.awssdk.core.exception.SdkClientException;\n+import software.amazon.awssdk.core.exception.SdkServiceException;\n+import software.amazon.awssdk.core.sync.RequestBody;\n+import software.amazon.awssdk.core.sync.ResponseTransformer;\n+import software.amazon.awssdk.regions.Region;\n+import software.amazon.awssdk.services.s3.S3Client;\n+import software.amazon.awssdk.services.s3.internal.resource.S3BucketResource;\n+import software.amazon.awssdk.services.s3.model.*;\n+\n+import java.io.*;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.net.URLEncoder;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.Date;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkState;\n+import static java.util.Objects.requireNonNull;\n+import static joptsimple.internal.Strings.isNullOrEmpty;\n+import static org.glassfish.jersey.internal.guava.Preconditions.checkArgument;\n+\n+public class S3PinotFS extends PinotFS {\n+    public static final String ACCESS_KEY = \"accessKey\";\n+    public static final String SECRET_KEY = \"secretKey\";\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(S3PinotFS.class);\n+    private static final String DELIMITER = \"/\";\n+    private S3Client s3Client;\n+\n+    @Override\n+    public void init(Configuration config) {\n+        checkArgument(!isNullOrEmpty(config.getString(ACCESS_KEY)));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI4MTc0Nw=="}, "originalCommit": {"oid": "4a55cc4ceef627cf87d4ce344435ded19f249b49"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjQ0MTU5OQ==", "bodyText": "done", "url": "https://github.com/apache/pinot/pull/5249#discussion_r412441599", "createdAt": "2020-04-21T19:43:49Z", "author": {"login": "KKcorps"}, "path": "pinot-plugins/pinot-file-system/pinot-s3/src/main/java/org/apache/pinot/plugin/filesystem/S3PinotFS.java", "diffHunk": "@@ -0,0 +1,485 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.plugin.filesystem;\n+\n+import com.google.common.collect.ImmutableList;\n+import org.apache.commons.configuration.Configuration;\n+import org.apache.pinot.spi.filesystem.PinotFS;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import software.amazon.awssdk.auth.credentials.AwsBasicCredentials;\n+import software.amazon.awssdk.auth.credentials.EnvironmentVariableCredentialsProvider;\n+import software.amazon.awssdk.auth.credentials.StaticCredentialsProvider;\n+import software.amazon.awssdk.core.ResponseBytes;\n+import software.amazon.awssdk.core.exception.SdkClientException;\n+import software.amazon.awssdk.core.exception.SdkServiceException;\n+import software.amazon.awssdk.core.sync.RequestBody;\n+import software.amazon.awssdk.core.sync.ResponseTransformer;\n+import software.amazon.awssdk.regions.Region;\n+import software.amazon.awssdk.services.s3.S3Client;\n+import software.amazon.awssdk.services.s3.internal.resource.S3BucketResource;\n+import software.amazon.awssdk.services.s3.model.*;\n+\n+import java.io.*;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.net.URLEncoder;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.Date;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkState;\n+import static java.util.Objects.requireNonNull;\n+import static joptsimple.internal.Strings.isNullOrEmpty;\n+import static org.glassfish.jersey.internal.guava.Preconditions.checkArgument;\n+\n+public class S3PinotFS extends PinotFS {\n+    public static final String ACCESS_KEY = \"accessKey\";\n+    public static final String SECRET_KEY = \"secretKey\";\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(S3PinotFS.class);\n+    private static final String DELIMITER = \"/\";\n+    private S3Client s3Client;\n+\n+    @Override\n+    public void init(Configuration config) {\n+        checkArgument(!isNullOrEmpty(config.getString(ACCESS_KEY)));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI4MTc0Nw=="}, "originalCommit": {"oid": "4a55cc4ceef627cf87d4ce344435ded19f249b49"}, "originalPosition": 68}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0MTA5NDMxOnYy", "diffSide": "RIGHT", "path": "pinot-plugins/pinot-file-system/pinot-s3/src/main/java/org/apache/pinot/plugin/filesystem/S3PinotFS.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwNDo1ODoxNlrOGGUl2w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQxOTo0MzozOVrOGJVbkA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI4MjAxMQ==", "bodyText": "region should also be configurable.", "url": "https://github.com/apache/pinot/pull/5249#discussion_r409282011", "createdAt": "2020-04-16T04:58:16Z", "author": {"login": "xiangfu0"}, "path": "pinot-plugins/pinot-file-system/pinot-s3/src/main/java/org/apache/pinot/plugin/filesystem/S3PinotFS.java", "diffHunk": "@@ -0,0 +1,485 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.plugin.filesystem;\n+\n+import com.google.common.collect.ImmutableList;\n+import org.apache.commons.configuration.Configuration;\n+import org.apache.pinot.spi.filesystem.PinotFS;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import software.amazon.awssdk.auth.credentials.AwsBasicCredentials;\n+import software.amazon.awssdk.auth.credentials.EnvironmentVariableCredentialsProvider;\n+import software.amazon.awssdk.auth.credentials.StaticCredentialsProvider;\n+import software.amazon.awssdk.core.ResponseBytes;\n+import software.amazon.awssdk.core.exception.SdkClientException;\n+import software.amazon.awssdk.core.exception.SdkServiceException;\n+import software.amazon.awssdk.core.sync.RequestBody;\n+import software.amazon.awssdk.core.sync.ResponseTransformer;\n+import software.amazon.awssdk.regions.Region;\n+import software.amazon.awssdk.services.s3.S3Client;\n+import software.amazon.awssdk.services.s3.internal.resource.S3BucketResource;\n+import software.amazon.awssdk.services.s3.model.*;\n+\n+import java.io.*;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.net.URLEncoder;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.Date;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkState;\n+import static java.util.Objects.requireNonNull;\n+import static joptsimple.internal.Strings.isNullOrEmpty;\n+import static org.glassfish.jersey.internal.guava.Preconditions.checkArgument;\n+\n+public class S3PinotFS extends PinotFS {\n+    public static final String ACCESS_KEY = \"accessKey\";\n+    public static final String SECRET_KEY = \"secretKey\";\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(S3PinotFS.class);\n+    private static final String DELIMITER = \"/\";\n+    private S3Client s3Client;\n+\n+    @Override\n+    public void init(Configuration config) {\n+        checkArgument(!isNullOrEmpty(config.getString(ACCESS_KEY)));\n+        checkArgument(!isNullOrEmpty(config.getString(SECRET_KEY)));\n+        String accessKey = config.getString(ACCESS_KEY);\n+        String secretKey = config.getString(SECRET_KEY);\n+        try {\n+            AwsBasicCredentials awsBasicCredentials = AwsBasicCredentials.create(accessKey, secretKey);\n+            s3Client = S3Client.builder()\n+                    .region(Region.AP_SOUTHEAST_1)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a55cc4ceef627cf87d4ce344435ded19f249b49"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjQ0MTQ4OA==", "bodyText": "done", "url": "https://github.com/apache/pinot/pull/5249#discussion_r412441488", "createdAt": "2020-04-21T19:43:39Z", "author": {"login": "KKcorps"}, "path": "pinot-plugins/pinot-file-system/pinot-s3/src/main/java/org/apache/pinot/plugin/filesystem/S3PinotFS.java", "diffHunk": "@@ -0,0 +1,485 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.plugin.filesystem;\n+\n+import com.google.common.collect.ImmutableList;\n+import org.apache.commons.configuration.Configuration;\n+import org.apache.pinot.spi.filesystem.PinotFS;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import software.amazon.awssdk.auth.credentials.AwsBasicCredentials;\n+import software.amazon.awssdk.auth.credentials.EnvironmentVariableCredentialsProvider;\n+import software.amazon.awssdk.auth.credentials.StaticCredentialsProvider;\n+import software.amazon.awssdk.core.ResponseBytes;\n+import software.amazon.awssdk.core.exception.SdkClientException;\n+import software.amazon.awssdk.core.exception.SdkServiceException;\n+import software.amazon.awssdk.core.sync.RequestBody;\n+import software.amazon.awssdk.core.sync.ResponseTransformer;\n+import software.amazon.awssdk.regions.Region;\n+import software.amazon.awssdk.services.s3.S3Client;\n+import software.amazon.awssdk.services.s3.internal.resource.S3BucketResource;\n+import software.amazon.awssdk.services.s3.model.*;\n+\n+import java.io.*;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.net.URLEncoder;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.Date;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkState;\n+import static java.util.Objects.requireNonNull;\n+import static joptsimple.internal.Strings.isNullOrEmpty;\n+import static org.glassfish.jersey.internal.guava.Preconditions.checkArgument;\n+\n+public class S3PinotFS extends PinotFS {\n+    public static final String ACCESS_KEY = \"accessKey\";\n+    public static final String SECRET_KEY = \"secretKey\";\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(S3PinotFS.class);\n+    private static final String DELIMITER = \"/\";\n+    private S3Client s3Client;\n+\n+    @Override\n+    public void init(Configuration config) {\n+        checkArgument(!isNullOrEmpty(config.getString(ACCESS_KEY)));\n+        checkArgument(!isNullOrEmpty(config.getString(SECRET_KEY)));\n+        String accessKey = config.getString(ACCESS_KEY);\n+        String secretKey = config.getString(SECRET_KEY);\n+        try {\n+            AwsBasicCredentials awsBasicCredentials = AwsBasicCredentials.create(accessKey, secretKey);\n+            s3Client = S3Client.builder()\n+                    .region(Region.AP_SOUTHEAST_1)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI4MjAxMQ=="}, "originalCommit": {"oid": "4a55cc4ceef627cf87d4ce344435ded19f249b49"}, "originalPosition": 75}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0MTExMTEwOnYy", "diffSide": "RIGHT", "path": "pinot-plugins/pinot-file-system/pinot-s3/src/main/java/org/apache/pinot/plugin/filesystem/S3PinotFS.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQwNTowNzozOFrOGGUvgA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQxOTo0MzozMFrOGJVbIg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI4NDQ4MA==", "bodyText": "Could you add a test to ensure this copy directory logic is correct?\nEspecially the relative path is correct.", "url": "https://github.com/apache/pinot/pull/5249#discussion_r409284480", "createdAt": "2020-04-16T05:07:38Z", "author": {"login": "xiangfu0"}, "path": "pinot-plugins/pinot-file-system/pinot-s3/src/main/java/org/apache/pinot/plugin/filesystem/S3PinotFS.java", "diffHunk": "@@ -0,0 +1,485 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.plugin.filesystem;\n+\n+import com.google.common.collect.ImmutableList;\n+import org.apache.commons.configuration.Configuration;\n+import org.apache.pinot.spi.filesystem.PinotFS;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import software.amazon.awssdk.auth.credentials.AwsBasicCredentials;\n+import software.amazon.awssdk.auth.credentials.EnvironmentVariableCredentialsProvider;\n+import software.amazon.awssdk.auth.credentials.StaticCredentialsProvider;\n+import software.amazon.awssdk.core.ResponseBytes;\n+import software.amazon.awssdk.core.exception.SdkClientException;\n+import software.amazon.awssdk.core.exception.SdkServiceException;\n+import software.amazon.awssdk.core.sync.RequestBody;\n+import software.amazon.awssdk.core.sync.ResponseTransformer;\n+import software.amazon.awssdk.regions.Region;\n+import software.amazon.awssdk.services.s3.S3Client;\n+import software.amazon.awssdk.services.s3.internal.resource.S3BucketResource;\n+import software.amazon.awssdk.services.s3.model.*;\n+\n+import java.io.*;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.net.URLEncoder;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.Date;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkState;\n+import static java.util.Objects.requireNonNull;\n+import static joptsimple.internal.Strings.isNullOrEmpty;\n+import static org.glassfish.jersey.internal.guava.Preconditions.checkArgument;\n+\n+public class S3PinotFS extends PinotFS {\n+    public static final String ACCESS_KEY = \"accessKey\";\n+    public static final String SECRET_KEY = \"secretKey\";\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(S3PinotFS.class);\n+    private static final String DELIMITER = \"/\";\n+    private S3Client s3Client;\n+\n+    @Override\n+    public void init(Configuration config) {\n+        checkArgument(!isNullOrEmpty(config.getString(ACCESS_KEY)));\n+        checkArgument(!isNullOrEmpty(config.getString(SECRET_KEY)));\n+        String accessKey = config.getString(ACCESS_KEY);\n+        String secretKey = config.getString(SECRET_KEY);\n+        try {\n+            AwsBasicCredentials awsBasicCredentials = AwsBasicCredentials.create(accessKey, secretKey);\n+            s3Client = S3Client.builder()\n+                    .region(Region.AP_SOUTHEAST_1)\n+                    .credentialsProvider(StaticCredentialsProvider.create(awsBasicCredentials))\n+                    .build();\n+\n+        } catch (S3Exception e) {\n+            throw new RuntimeException(\"Could not initialize S3PinotFS\", e);\n+        }\n+    }\n+\n+    private HeadObjectResponse getS3ObjectMetadata(URI uri) throws IOException {\n+            URI base = getBase(uri);\n+            String path = sanitizePath(base.relativize(uri).getPath());\n+            HeadObjectRequest headObjectRequest = HeadObjectRequest.builder()\n+                    .bucket(uri.getHost())\n+                    .key(path)\n+                    .build();\n+\n+            return s3Client.headObject(headObjectRequest);\n+    }\n+\n+    private boolean isPathTerminatedByDelimiter(URI uri) {\n+        return uri.getPath().endsWith(DELIMITER);\n+    }\n+\n+    private String normalizeToDirectoryPrefix(URI uri) throws IOException {\n+        requireNonNull(uri, \"uri is null\");\n+        URI strippedUri = getBase(uri).relativize(uri);\n+        if (isPathTerminatedByDelimiter(strippedUri)) {\n+            return sanitizePath(strippedUri.getPath());\n+        }\n+        return sanitizePath(strippedUri.getPath() + DELIMITER);\n+    }\n+\n+    private URI normalizeToDirectoryUri(URI uri) throws IOException {\n+        if (isPathTerminatedByDelimiter(uri)) {\n+            return uri;\n+        }\n+        try {\n+            return new URI(uri.getScheme(), uri.getHost(), sanitizePath(uri.getPath() + DELIMITER), null);\n+        } catch (URISyntaxException e) {\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    private String sanitizePath(String path) {\n+        path = path.replaceAll(DELIMITER + \"+\", DELIMITER);\n+        if (path.startsWith(DELIMITER) && !path.equals(DELIMITER)) {\n+            path = path.substring(1);\n+        }\n+        return path;\n+    }\n+\n+    private URI getBase(URI uri) throws IOException {\n+        try {\n+            return new URI(uri.getScheme(), uri.getHost(), null, null);\n+        } catch (URISyntaxException e) {\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    private boolean existsFile(URI uri) throws IOException {\n+        try {\n+            URI base = getBase(uri);\n+            String path = sanitizePath(base.relativize(uri).getPath());\n+            HeadObjectRequest headObjectRequest = HeadObjectRequest.builder()\n+                    .bucket(uri.getHost())\n+                    .key(path)\n+                    .build();\n+\n+            s3Client.headObject(headObjectRequest);\n+            return true;\n+        }catch(NoSuchKeyException e){\n+            return false;\n+        }catch(S3Exception e){\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    private boolean isEmptyDirectory(URI uri) throws IOException {\n+        if (!isDirectory(uri)) {\n+            return false;\n+        }\n+        String prefix = normalizeToDirectoryPrefix(uri);\n+        boolean isEmpty = true;\n+        ListObjectsV2Response listObjectsV2Response;\n+        ListObjectsV2Request.Builder listObjectsV2RequestBuilder = ListObjectsV2Request.builder()\n+                .bucket(uri.getHost());\n+\n+        if (prefix.equals(DELIMITER)) {\n+            ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.build();\n+            listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);\n+        } else {\n+            ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.prefix(prefix).build();\n+            listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);\n+        }\n+        for (S3Object s3Object : listObjectsV2Response.contents()) {\n+            if (s3Object.key().equals(prefix)) {\n+                continue;\n+            } else {\n+                isEmpty = false;\n+                break;\n+            }\n+        }\n+        return isEmpty;\n+    }\n+\n+    private boolean copyFile(URI srcUri, URI dstUri) throws IOException {\n+        try {\n+            String encodedUrl = null;\n+            try {\n+                encodedUrl = URLEncoder.encode(srcUri.getHost() + srcUri.getPath(), StandardCharsets.UTF_8.toString());\n+            } catch (UnsupportedEncodingException e) {\n+                LOGGER.info(\"URL could not be encoded: {}\", e.getMessage());\n+            }\n+\n+            String dstPath = sanitizePath(dstUri.getPath());\n+            CopyObjectRequest copyReq = CopyObjectRequest.builder()\n+                    .copySource(encodedUrl)\n+                    .destinationBucket(dstUri.getHost())\n+                    .destinationKey(dstPath)\n+                    .build();\n+\n+            CopyObjectResponse copyObjectResponse = s3Client.copyObject(copyReq);\n+            return copyObjectResponse.sdkHttpResponse().isSuccessful();\n+        }catch(S3Exception e){\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    @Override\n+    public boolean mkdir(URI uri) throws IOException {\n+        LOGGER.info(\"mkdir {}\", uri);\n+        try {\n+            requireNonNull(uri, \"uri is null\");\n+            String path = normalizeToDirectoryPrefix(uri);\n+            // Bucket root directory already exists and cannot be created\n+            if (path.equals(DELIMITER)) {\n+                return true;\n+            }\n+\n+            PutObjectRequest putObjectRequest = PutObjectRequest.builder()\n+                    .bucket(uri.getHost())\n+                    .key(path)\n+                    .build();\n+\n+            PutObjectResponse putObjectResponse = s3Client.putObject(putObjectRequest, RequestBody.fromBytes(new byte[0]));\n+\n+            return putObjectResponse.sdkHttpResponse().isSuccessful();\n+        } catch (Throwable t) {\n+            throw new IOException(t);\n+        }\n+    }\n+\n+    @Override\n+    public boolean delete(URI segmentUri, boolean forceDelete) throws IOException {\n+        LOGGER.info(\"Deleting uri {} force {}\", segmentUri, forceDelete);\n+        try {\n+            if (isDirectory(segmentUri)) {\n+                if (!forceDelete) {\n+                    checkState(isEmptyDirectory(segmentUri), \"ForceDelete flag is not set and directory '%s' is not empty\", segmentUri);\n+                }\n+                String prefix = normalizeToDirectoryPrefix(segmentUri);\n+                ListObjectsV2Response listObjectsV2Response;\n+                ListObjectsV2Request.Builder listObjectsV2RequestBuilder = ListObjectsV2Request.builder()\n+                        .bucket(segmentUri.getHost());\n+\n+                if (prefix.equals(DELIMITER)) {\n+                    ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.build();\n+                    listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);\n+                } else {\n+                    ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.prefix(prefix).build();\n+                    listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);\n+                }\n+                boolean deleteSucceeded = true;\n+                for (S3Object s3Object : listObjectsV2Response.contents()) {\n+                    DeleteObjectRequest deleteObjectRequest = DeleteObjectRequest.builder()\n+                            .bucket(segmentUri.getHost())\n+                            .key(s3Object.key())\n+                            .build();\n+\n+                    DeleteObjectResponse deleteObjectResponse = s3Client.deleteObject(deleteObjectRequest);\n+\n+                    deleteSucceeded &= deleteObjectResponse.sdkHttpResponse().isSuccessful();\n+                }\n+                return deleteSucceeded;\n+            } else {\n+                String prefix = sanitizePath(segmentUri.getPath());\n+                DeleteObjectRequest deleteObjectRequest = DeleteObjectRequest.builder()\n+                        .bucket(segmentUri.getHost())\n+                        .key(prefix)\n+                        .build();\n+\n+                DeleteObjectResponse deleteObjectResponse = s3Client.deleteObject(deleteObjectRequest);\n+\n+                return deleteObjectResponse.sdkHttpResponse().isSuccessful();\n+            }\n+        }catch(NoSuchKeyException e){\n+            return false;\n+        } catch (S3Exception e) {\n+            throw e;\n+        } catch(Throwable t) {\n+            throw new IOException(t);\n+        }\n+    }\n+\n+    @Override\n+    public boolean doMove(URI srcUri, URI dstUri) throws IOException {\n+        if (copy(srcUri, dstUri)) {\n+            return  delete(srcUri, true);\n+        }\n+        return false;\n+    }\n+\n+    @Override\n+    public boolean copy(URI srcUri, URI dstUri) throws IOException {\n+        LOGGER.info(\"Copying uri {} to uri {}\", srcUri, dstUri);\n+        checkState(exists(srcUri), \"Source URI '%s' does not exist\", srcUri);\n+        if (srcUri.equals(dstUri)) {\n+            return true;\n+        }\n+        if (!isDirectory(srcUri)) {\n+            delete(dstUri, true);\n+            return copyFile(srcUri, dstUri);\n+        }\n+        dstUri = normalizeToDirectoryUri(dstUri);\n+        ImmutableList.Builder<URI> builder = ImmutableList.builder();\n+        Path srcPath = Paths.get(srcUri.getPath());\n+        try {\n+            boolean copySucceeded = true;\n+            for (String directoryEntry : listFiles(srcUri, true)) {\n+                URI src = new URI(srcUri.getScheme(), srcUri.getHost(), directoryEntry, null);\n+                String relativeSrcPath = srcPath.relativize(Paths.get(directoryEntry)).toString();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a55cc4ceef627cf87d4ce344435ded19f249b49"}, "originalPosition": 306}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjQ0MTM3OA==", "bodyText": "done", "url": "https://github.com/apache/pinot/pull/5249#discussion_r412441378", "createdAt": "2020-04-21T19:43:30Z", "author": {"login": "KKcorps"}, "path": "pinot-plugins/pinot-file-system/pinot-s3/src/main/java/org/apache/pinot/plugin/filesystem/S3PinotFS.java", "diffHunk": "@@ -0,0 +1,485 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.plugin.filesystem;\n+\n+import com.google.common.collect.ImmutableList;\n+import org.apache.commons.configuration.Configuration;\n+import org.apache.pinot.spi.filesystem.PinotFS;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import software.amazon.awssdk.auth.credentials.AwsBasicCredentials;\n+import software.amazon.awssdk.auth.credentials.EnvironmentVariableCredentialsProvider;\n+import software.amazon.awssdk.auth.credentials.StaticCredentialsProvider;\n+import software.amazon.awssdk.core.ResponseBytes;\n+import software.amazon.awssdk.core.exception.SdkClientException;\n+import software.amazon.awssdk.core.exception.SdkServiceException;\n+import software.amazon.awssdk.core.sync.RequestBody;\n+import software.amazon.awssdk.core.sync.ResponseTransformer;\n+import software.amazon.awssdk.regions.Region;\n+import software.amazon.awssdk.services.s3.S3Client;\n+import software.amazon.awssdk.services.s3.internal.resource.S3BucketResource;\n+import software.amazon.awssdk.services.s3.model.*;\n+\n+import java.io.*;\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.net.URLEncoder;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.Date;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.google.common.base.Preconditions.checkState;\n+import static java.util.Objects.requireNonNull;\n+import static joptsimple.internal.Strings.isNullOrEmpty;\n+import static org.glassfish.jersey.internal.guava.Preconditions.checkArgument;\n+\n+public class S3PinotFS extends PinotFS {\n+    public static final String ACCESS_KEY = \"accessKey\";\n+    public static final String SECRET_KEY = \"secretKey\";\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(S3PinotFS.class);\n+    private static final String DELIMITER = \"/\";\n+    private S3Client s3Client;\n+\n+    @Override\n+    public void init(Configuration config) {\n+        checkArgument(!isNullOrEmpty(config.getString(ACCESS_KEY)));\n+        checkArgument(!isNullOrEmpty(config.getString(SECRET_KEY)));\n+        String accessKey = config.getString(ACCESS_KEY);\n+        String secretKey = config.getString(SECRET_KEY);\n+        try {\n+            AwsBasicCredentials awsBasicCredentials = AwsBasicCredentials.create(accessKey, secretKey);\n+            s3Client = S3Client.builder()\n+                    .region(Region.AP_SOUTHEAST_1)\n+                    .credentialsProvider(StaticCredentialsProvider.create(awsBasicCredentials))\n+                    .build();\n+\n+        } catch (S3Exception e) {\n+            throw new RuntimeException(\"Could not initialize S3PinotFS\", e);\n+        }\n+    }\n+\n+    private HeadObjectResponse getS3ObjectMetadata(URI uri) throws IOException {\n+            URI base = getBase(uri);\n+            String path = sanitizePath(base.relativize(uri).getPath());\n+            HeadObjectRequest headObjectRequest = HeadObjectRequest.builder()\n+                    .bucket(uri.getHost())\n+                    .key(path)\n+                    .build();\n+\n+            return s3Client.headObject(headObjectRequest);\n+    }\n+\n+    private boolean isPathTerminatedByDelimiter(URI uri) {\n+        return uri.getPath().endsWith(DELIMITER);\n+    }\n+\n+    private String normalizeToDirectoryPrefix(URI uri) throws IOException {\n+        requireNonNull(uri, \"uri is null\");\n+        URI strippedUri = getBase(uri).relativize(uri);\n+        if (isPathTerminatedByDelimiter(strippedUri)) {\n+            return sanitizePath(strippedUri.getPath());\n+        }\n+        return sanitizePath(strippedUri.getPath() + DELIMITER);\n+    }\n+\n+    private URI normalizeToDirectoryUri(URI uri) throws IOException {\n+        if (isPathTerminatedByDelimiter(uri)) {\n+            return uri;\n+        }\n+        try {\n+            return new URI(uri.getScheme(), uri.getHost(), sanitizePath(uri.getPath() + DELIMITER), null);\n+        } catch (URISyntaxException e) {\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    private String sanitizePath(String path) {\n+        path = path.replaceAll(DELIMITER + \"+\", DELIMITER);\n+        if (path.startsWith(DELIMITER) && !path.equals(DELIMITER)) {\n+            path = path.substring(1);\n+        }\n+        return path;\n+    }\n+\n+    private URI getBase(URI uri) throws IOException {\n+        try {\n+            return new URI(uri.getScheme(), uri.getHost(), null, null);\n+        } catch (URISyntaxException e) {\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    private boolean existsFile(URI uri) throws IOException {\n+        try {\n+            URI base = getBase(uri);\n+            String path = sanitizePath(base.relativize(uri).getPath());\n+            HeadObjectRequest headObjectRequest = HeadObjectRequest.builder()\n+                    .bucket(uri.getHost())\n+                    .key(path)\n+                    .build();\n+\n+            s3Client.headObject(headObjectRequest);\n+            return true;\n+        }catch(NoSuchKeyException e){\n+            return false;\n+        }catch(S3Exception e){\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    private boolean isEmptyDirectory(URI uri) throws IOException {\n+        if (!isDirectory(uri)) {\n+            return false;\n+        }\n+        String prefix = normalizeToDirectoryPrefix(uri);\n+        boolean isEmpty = true;\n+        ListObjectsV2Response listObjectsV2Response;\n+        ListObjectsV2Request.Builder listObjectsV2RequestBuilder = ListObjectsV2Request.builder()\n+                .bucket(uri.getHost());\n+\n+        if (prefix.equals(DELIMITER)) {\n+            ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.build();\n+            listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);\n+        } else {\n+            ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.prefix(prefix).build();\n+            listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);\n+        }\n+        for (S3Object s3Object : listObjectsV2Response.contents()) {\n+            if (s3Object.key().equals(prefix)) {\n+                continue;\n+            } else {\n+                isEmpty = false;\n+                break;\n+            }\n+        }\n+        return isEmpty;\n+    }\n+\n+    private boolean copyFile(URI srcUri, URI dstUri) throws IOException {\n+        try {\n+            String encodedUrl = null;\n+            try {\n+                encodedUrl = URLEncoder.encode(srcUri.getHost() + srcUri.getPath(), StandardCharsets.UTF_8.toString());\n+            } catch (UnsupportedEncodingException e) {\n+                LOGGER.info(\"URL could not be encoded: {}\", e.getMessage());\n+            }\n+\n+            String dstPath = sanitizePath(dstUri.getPath());\n+            CopyObjectRequest copyReq = CopyObjectRequest.builder()\n+                    .copySource(encodedUrl)\n+                    .destinationBucket(dstUri.getHost())\n+                    .destinationKey(dstPath)\n+                    .build();\n+\n+            CopyObjectResponse copyObjectResponse = s3Client.copyObject(copyReq);\n+            return copyObjectResponse.sdkHttpResponse().isSuccessful();\n+        }catch(S3Exception e){\n+            throw new IOException(e);\n+        }\n+    }\n+\n+    @Override\n+    public boolean mkdir(URI uri) throws IOException {\n+        LOGGER.info(\"mkdir {}\", uri);\n+        try {\n+            requireNonNull(uri, \"uri is null\");\n+            String path = normalizeToDirectoryPrefix(uri);\n+            // Bucket root directory already exists and cannot be created\n+            if (path.equals(DELIMITER)) {\n+                return true;\n+            }\n+\n+            PutObjectRequest putObjectRequest = PutObjectRequest.builder()\n+                    .bucket(uri.getHost())\n+                    .key(path)\n+                    .build();\n+\n+            PutObjectResponse putObjectResponse = s3Client.putObject(putObjectRequest, RequestBody.fromBytes(new byte[0]));\n+\n+            return putObjectResponse.sdkHttpResponse().isSuccessful();\n+        } catch (Throwable t) {\n+            throw new IOException(t);\n+        }\n+    }\n+\n+    @Override\n+    public boolean delete(URI segmentUri, boolean forceDelete) throws IOException {\n+        LOGGER.info(\"Deleting uri {} force {}\", segmentUri, forceDelete);\n+        try {\n+            if (isDirectory(segmentUri)) {\n+                if (!forceDelete) {\n+                    checkState(isEmptyDirectory(segmentUri), \"ForceDelete flag is not set and directory '%s' is not empty\", segmentUri);\n+                }\n+                String prefix = normalizeToDirectoryPrefix(segmentUri);\n+                ListObjectsV2Response listObjectsV2Response;\n+                ListObjectsV2Request.Builder listObjectsV2RequestBuilder = ListObjectsV2Request.builder()\n+                        .bucket(segmentUri.getHost());\n+\n+                if (prefix.equals(DELIMITER)) {\n+                    ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.build();\n+                    listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);\n+                } else {\n+                    ListObjectsV2Request listObjectsV2Request = listObjectsV2RequestBuilder.prefix(prefix).build();\n+                    listObjectsV2Response = s3Client.listObjectsV2(listObjectsV2Request);\n+                }\n+                boolean deleteSucceeded = true;\n+                for (S3Object s3Object : listObjectsV2Response.contents()) {\n+                    DeleteObjectRequest deleteObjectRequest = DeleteObjectRequest.builder()\n+                            .bucket(segmentUri.getHost())\n+                            .key(s3Object.key())\n+                            .build();\n+\n+                    DeleteObjectResponse deleteObjectResponse = s3Client.deleteObject(deleteObjectRequest);\n+\n+                    deleteSucceeded &= deleteObjectResponse.sdkHttpResponse().isSuccessful();\n+                }\n+                return deleteSucceeded;\n+            } else {\n+                String prefix = sanitizePath(segmentUri.getPath());\n+                DeleteObjectRequest deleteObjectRequest = DeleteObjectRequest.builder()\n+                        .bucket(segmentUri.getHost())\n+                        .key(prefix)\n+                        .build();\n+\n+                DeleteObjectResponse deleteObjectResponse = s3Client.deleteObject(deleteObjectRequest);\n+\n+                return deleteObjectResponse.sdkHttpResponse().isSuccessful();\n+            }\n+        }catch(NoSuchKeyException e){\n+            return false;\n+        } catch (S3Exception e) {\n+            throw e;\n+        } catch(Throwable t) {\n+            throw new IOException(t);\n+        }\n+    }\n+\n+    @Override\n+    public boolean doMove(URI srcUri, URI dstUri) throws IOException {\n+        if (copy(srcUri, dstUri)) {\n+            return  delete(srcUri, true);\n+        }\n+        return false;\n+    }\n+\n+    @Override\n+    public boolean copy(URI srcUri, URI dstUri) throws IOException {\n+        LOGGER.info(\"Copying uri {} to uri {}\", srcUri, dstUri);\n+        checkState(exists(srcUri), \"Source URI '%s' does not exist\", srcUri);\n+        if (srcUri.equals(dstUri)) {\n+            return true;\n+        }\n+        if (!isDirectory(srcUri)) {\n+            delete(dstUri, true);\n+            return copyFile(srcUri, dstUri);\n+        }\n+        dstUri = normalizeToDirectoryUri(dstUri);\n+        ImmutableList.Builder<URI> builder = ImmutableList.builder();\n+        Path srcPath = Paths.get(srcUri.getPath());\n+        try {\n+            boolean copySucceeded = true;\n+            for (String directoryEntry : listFiles(srcUri, true)) {\n+                URI src = new URI(srcUri.getScheme(), srcUri.getHost(), directoryEntry, null);\n+                String relativeSrcPath = srcPath.relativize(Paths.get(directoryEntry)).toString();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTI4NDQ4MA=="}, "originalCommit": {"oid": "4a55cc4ceef627cf87d4ce344435ded19f249b49"}, "originalPosition": 306}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0NDY0MDY1OnYy", "diffSide": "RIGHT", "path": "pinot-plugins/pinot-file-system/pinot-s3/pom.xml", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQyMTowOToyMFrOGG3QKA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQxOTo0MzoyM1rOGJVa1g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTg0OTg5Ng==", "bodyText": "where is this used?", "url": "https://github.com/apache/pinot/pull/5249#discussion_r409849896", "createdAt": "2020-04-16T21:09:20Z", "author": {"login": "xiangfu0"}, "path": "pinot-plugins/pinot-file-system/pinot-s3/pom.xml", "diffHunk": "@@ -0,0 +1,156 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+\n+-->\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n+         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n+         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+    <modelVersion>4.0.0</modelVersion>\n+    <parent>\n+        <artifactId>pinot-file-system</artifactId>\n+        <groupId>org.apache.pinot</groupId>\n+        <version>${revision}${sha1}</version>\n+        <relativePath>..</relativePath>\n+    </parent>\n+\n+    <artifactId>pinot-s3</artifactId>\n+    <name>Pinot Amazon S3</name>\n+    <url>https://pinot.apache.org</url>\n+    <properties>\n+        <pinot.root>${basedir}/../../..</pinot.root>\n+        <aws.sdk.version>2.11.12</aws.sdk.version>\n+        <netty.version>4.1.42.Final</netty.version>\n+    </properties>\n+\n+    <dependencyManagement>\n+        <dependencies>\n+            <dependency>\n+                <groupId>software.amazon.awssdk</groupId>\n+                <artifactId>bom</artifactId>\n+                <version>${aws.sdk.version}</version>\n+                <type>pom</type>\n+                <scope>import</scope>\n+            </dependency>\n+        </dependencies>\n+    </dependencyManagement>\n+\n+    <dependencies>\n+        <dependency>\n+            <groupId>commons-configuration</groupId>\n+            <artifactId>commons-configuration</artifactId>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.apache.pinot</groupId>\n+            <artifactId>pinot-spi</artifactId>\n+            <version>0.4.0-SNAPSHOT</version>\n+        </dependency>\n+        <!-- amazon s3 -->\n+        <dependency>\n+            <groupId>software.amazon.awssdk</groupId>\n+            <artifactId>s3</artifactId>\n+            <version>${aws.sdk.version}</version>\n+            <exclusions>\n+                <exclusion>\n+                    <groupId>org.reactivestreams</groupId>\n+                    <artifactId>reactive-streams</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>io.netty</groupId>\n+                    <artifactId>netty-codec</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>io.netty</groupId>\n+                    <artifactId>netty-buffer</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>io.netty</groupId>\n+                    <artifactId>netty-transport</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>io.netty</groupId>\n+                    <artifactId>netty-common</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>org.apache.httpcomponents</groupId>\n+                    <artifactId>httpcore</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>org.apache.httpcomponents</groupId>\n+                    <artifactId>httpclient</artifactId>\n+                </exclusion>\n+            </exclusions>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.apache.httpcomponents</groupId>\n+            <artifactId>httpclient</artifactId>\n+            <version>4.5.5</version>\n+            <exclusions>\n+                <exclusion>\n+                    <groupId>org.apache.httpcomponents</groupId>\n+                    <artifactId>httpcore</artifactId>\n+                </exclusion>\n+            </exclusions>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.apache.httpcomponents</groupId>\n+            <artifactId>httpcore</artifactId>\n+            <version>4.4.9</version>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.reactivestreams</groupId>\n+            <artifactId>reactive-streams</artifactId>\n+            <version>1.0.3</version>\n+        </dependency>\n+        <dependency>\n+            <groupId>io.netty</groupId>\n+            <artifactId>netty-codec</artifactId>\n+            <version>${netty.version}</version>\n+        </dependency>\n+        <dependency>\n+            <groupId>io.netty</groupId>\n+            <artifactId>netty-buffer</artifactId>\n+            <version>${netty.version}</version>\n+        </dependency>\n+        <dependency>\n+            <groupId>io.netty</groupId>\n+            <artifactId>netty-transport</artifactId>\n+            <version>${netty.version}</version>\n+        </dependency>\n+        <dependency>\n+            <groupId>io.netty</groupId>\n+            <artifactId>netty-common</artifactId>\n+            <version>${netty.version}</version>\n+        </dependency>\n+        <dependency>\n+            <groupId>net.sf.jopt-simple</groupId>\n+            <artifactId>jopt-simple</artifactId>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.glassfish.jersey.core</groupId>\n+            <artifactId>jersey-server</artifactId>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.jetbrains</groupId>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "71e40da73e5d829f5521352d24dbeda71004efa6"}, "originalPosition": 150}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjQ0MTMwMg==", "bodyText": "done", "url": "https://github.com/apache/pinot/pull/5249#discussion_r412441302", "createdAt": "2020-04-21T19:43:23Z", "author": {"login": "KKcorps"}, "path": "pinot-plugins/pinot-file-system/pinot-s3/pom.xml", "diffHunk": "@@ -0,0 +1,156 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+\n+-->\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n+         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n+         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+    <modelVersion>4.0.0</modelVersion>\n+    <parent>\n+        <artifactId>pinot-file-system</artifactId>\n+        <groupId>org.apache.pinot</groupId>\n+        <version>${revision}${sha1}</version>\n+        <relativePath>..</relativePath>\n+    </parent>\n+\n+    <artifactId>pinot-s3</artifactId>\n+    <name>Pinot Amazon S3</name>\n+    <url>https://pinot.apache.org</url>\n+    <properties>\n+        <pinot.root>${basedir}/../../..</pinot.root>\n+        <aws.sdk.version>2.11.12</aws.sdk.version>\n+        <netty.version>4.1.42.Final</netty.version>\n+    </properties>\n+\n+    <dependencyManagement>\n+        <dependencies>\n+            <dependency>\n+                <groupId>software.amazon.awssdk</groupId>\n+                <artifactId>bom</artifactId>\n+                <version>${aws.sdk.version}</version>\n+                <type>pom</type>\n+                <scope>import</scope>\n+            </dependency>\n+        </dependencies>\n+    </dependencyManagement>\n+\n+    <dependencies>\n+        <dependency>\n+            <groupId>commons-configuration</groupId>\n+            <artifactId>commons-configuration</artifactId>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.apache.pinot</groupId>\n+            <artifactId>pinot-spi</artifactId>\n+            <version>0.4.0-SNAPSHOT</version>\n+        </dependency>\n+        <!-- amazon s3 -->\n+        <dependency>\n+            <groupId>software.amazon.awssdk</groupId>\n+            <artifactId>s3</artifactId>\n+            <version>${aws.sdk.version}</version>\n+            <exclusions>\n+                <exclusion>\n+                    <groupId>org.reactivestreams</groupId>\n+                    <artifactId>reactive-streams</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>io.netty</groupId>\n+                    <artifactId>netty-codec</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>io.netty</groupId>\n+                    <artifactId>netty-buffer</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>io.netty</groupId>\n+                    <artifactId>netty-transport</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>io.netty</groupId>\n+                    <artifactId>netty-common</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>org.apache.httpcomponents</groupId>\n+                    <artifactId>httpcore</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>org.apache.httpcomponents</groupId>\n+                    <artifactId>httpclient</artifactId>\n+                </exclusion>\n+            </exclusions>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.apache.httpcomponents</groupId>\n+            <artifactId>httpclient</artifactId>\n+            <version>4.5.5</version>\n+            <exclusions>\n+                <exclusion>\n+                    <groupId>org.apache.httpcomponents</groupId>\n+                    <artifactId>httpcore</artifactId>\n+                </exclusion>\n+            </exclusions>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.apache.httpcomponents</groupId>\n+            <artifactId>httpcore</artifactId>\n+            <version>4.4.9</version>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.reactivestreams</groupId>\n+            <artifactId>reactive-streams</artifactId>\n+            <version>1.0.3</version>\n+        </dependency>\n+        <dependency>\n+            <groupId>io.netty</groupId>\n+            <artifactId>netty-codec</artifactId>\n+            <version>${netty.version}</version>\n+        </dependency>\n+        <dependency>\n+            <groupId>io.netty</groupId>\n+            <artifactId>netty-buffer</artifactId>\n+            <version>${netty.version}</version>\n+        </dependency>\n+        <dependency>\n+            <groupId>io.netty</groupId>\n+            <artifactId>netty-transport</artifactId>\n+            <version>${netty.version}</version>\n+        </dependency>\n+        <dependency>\n+            <groupId>io.netty</groupId>\n+            <artifactId>netty-common</artifactId>\n+            <version>${netty.version}</version>\n+        </dependency>\n+        <dependency>\n+            <groupId>net.sf.jopt-simple</groupId>\n+            <artifactId>jopt-simple</artifactId>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.glassfish.jersey.core</groupId>\n+            <artifactId>jersey-server</artifactId>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.jetbrains</groupId>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTg0OTg5Ng=="}, "originalCommit": {"oid": "71e40da73e5d829f5521352d24dbeda71004efa6"}, "originalPosition": 150}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0NDY0ODgyOnYy", "diffSide": "RIGHT", "path": "pinot-plugins/pinot-file-system/pinot-s3/pom.xml", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQyMToxMjowMVrOGG3VPg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQxOTo0MzoxNlrOGJVaig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTg1MTE5OA==", "bodyText": "use property for all the versions", "url": "https://github.com/apache/pinot/pull/5249#discussion_r409851198", "createdAt": "2020-04-16T21:12:01Z", "author": {"login": "xiangfu0"}, "path": "pinot-plugins/pinot-file-system/pinot-s3/pom.xml", "diffHunk": "@@ -0,0 +1,156 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+\n+-->\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n+         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n+         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+    <modelVersion>4.0.0</modelVersion>\n+    <parent>\n+        <artifactId>pinot-file-system</artifactId>\n+        <groupId>org.apache.pinot</groupId>\n+        <version>${revision}${sha1}</version>\n+        <relativePath>..</relativePath>\n+    </parent>\n+\n+    <artifactId>pinot-s3</artifactId>\n+    <name>Pinot Amazon S3</name>\n+    <url>https://pinot.apache.org</url>\n+    <properties>\n+        <pinot.root>${basedir}/../../..</pinot.root>\n+        <aws.sdk.version>2.11.12</aws.sdk.version>\n+        <netty.version>4.1.42.Final</netty.version>\n+    </properties>\n+\n+    <dependencyManagement>\n+        <dependencies>\n+            <dependency>\n+                <groupId>software.amazon.awssdk</groupId>\n+                <artifactId>bom</artifactId>\n+                <version>${aws.sdk.version}</version>\n+                <type>pom</type>\n+                <scope>import</scope>\n+            </dependency>\n+        </dependencies>\n+    </dependencyManagement>\n+\n+    <dependencies>\n+        <dependency>\n+            <groupId>commons-configuration</groupId>\n+            <artifactId>commons-configuration</artifactId>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.apache.pinot</groupId>\n+            <artifactId>pinot-spi</artifactId>\n+            <version>0.4.0-SNAPSHOT</version>\n+        </dependency>\n+        <!-- amazon s3 -->\n+        <dependency>\n+            <groupId>software.amazon.awssdk</groupId>\n+            <artifactId>s3</artifactId>\n+            <version>${aws.sdk.version}</version>\n+            <exclusions>\n+                <exclusion>\n+                    <groupId>org.reactivestreams</groupId>\n+                    <artifactId>reactive-streams</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>io.netty</groupId>\n+                    <artifactId>netty-codec</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>io.netty</groupId>\n+                    <artifactId>netty-buffer</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>io.netty</groupId>\n+                    <artifactId>netty-transport</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>io.netty</groupId>\n+                    <artifactId>netty-common</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>org.apache.httpcomponents</groupId>\n+                    <artifactId>httpcore</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>org.apache.httpcomponents</groupId>\n+                    <artifactId>httpclient</artifactId>\n+                </exclusion>\n+            </exclusions>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.apache.httpcomponents</groupId>\n+            <artifactId>httpclient</artifactId>\n+            <version>4.5.5</version>\n+            <exclusions>\n+                <exclusion>\n+                    <groupId>org.apache.httpcomponents</groupId>\n+                    <artifactId>httpcore</artifactId>\n+                </exclusion>\n+            </exclusions>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.apache.httpcomponents</groupId>\n+            <artifactId>httpcore</artifactId>\n+            <version>4.4.9</version>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.reactivestreams</groupId>\n+            <artifactId>reactive-streams</artifactId>\n+            <version>1.0.3</version>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "71e40da73e5d829f5521352d24dbeda71004efa6"}, "originalPosition": 119}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjQ0MTIyNg==", "bodyText": "done", "url": "https://github.com/apache/pinot/pull/5249#discussion_r412441226", "createdAt": "2020-04-21T19:43:16Z", "author": {"login": "KKcorps"}, "path": "pinot-plugins/pinot-file-system/pinot-s3/pom.xml", "diffHunk": "@@ -0,0 +1,156 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+\n+-->\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n+         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n+         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+    <modelVersion>4.0.0</modelVersion>\n+    <parent>\n+        <artifactId>pinot-file-system</artifactId>\n+        <groupId>org.apache.pinot</groupId>\n+        <version>${revision}${sha1}</version>\n+        <relativePath>..</relativePath>\n+    </parent>\n+\n+    <artifactId>pinot-s3</artifactId>\n+    <name>Pinot Amazon S3</name>\n+    <url>https://pinot.apache.org</url>\n+    <properties>\n+        <pinot.root>${basedir}/../../..</pinot.root>\n+        <aws.sdk.version>2.11.12</aws.sdk.version>\n+        <netty.version>4.1.42.Final</netty.version>\n+    </properties>\n+\n+    <dependencyManagement>\n+        <dependencies>\n+            <dependency>\n+                <groupId>software.amazon.awssdk</groupId>\n+                <artifactId>bom</artifactId>\n+                <version>${aws.sdk.version}</version>\n+                <type>pom</type>\n+                <scope>import</scope>\n+            </dependency>\n+        </dependencies>\n+    </dependencyManagement>\n+\n+    <dependencies>\n+        <dependency>\n+            <groupId>commons-configuration</groupId>\n+            <artifactId>commons-configuration</artifactId>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.apache.pinot</groupId>\n+            <artifactId>pinot-spi</artifactId>\n+            <version>0.4.0-SNAPSHOT</version>\n+        </dependency>\n+        <!-- amazon s3 -->\n+        <dependency>\n+            <groupId>software.amazon.awssdk</groupId>\n+            <artifactId>s3</artifactId>\n+            <version>${aws.sdk.version}</version>\n+            <exclusions>\n+                <exclusion>\n+                    <groupId>org.reactivestreams</groupId>\n+                    <artifactId>reactive-streams</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>io.netty</groupId>\n+                    <artifactId>netty-codec</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>io.netty</groupId>\n+                    <artifactId>netty-buffer</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>io.netty</groupId>\n+                    <artifactId>netty-transport</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>io.netty</groupId>\n+                    <artifactId>netty-common</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>org.apache.httpcomponents</groupId>\n+                    <artifactId>httpcore</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>org.apache.httpcomponents</groupId>\n+                    <artifactId>httpclient</artifactId>\n+                </exclusion>\n+            </exclusions>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.apache.httpcomponents</groupId>\n+            <artifactId>httpclient</artifactId>\n+            <version>4.5.5</version>\n+            <exclusions>\n+                <exclusion>\n+                    <groupId>org.apache.httpcomponents</groupId>\n+                    <artifactId>httpcore</artifactId>\n+                </exclusion>\n+            </exclusions>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.apache.httpcomponents</groupId>\n+            <artifactId>httpcore</artifactId>\n+            <version>4.4.9</version>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.reactivestreams</groupId>\n+            <artifactId>reactive-streams</artifactId>\n+            <version>1.0.3</version>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTg1MTE5OA=="}, "originalCommit": {"oid": "71e40da73e5d829f5521352d24dbeda71004efa6"}, "originalPosition": 119}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0NDY0OTc5OnYy", "diffSide": "RIGHT", "path": "pinot-plugins/pinot-file-system/pinot-s3/pom.xml", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQyMToxMjoxN1rOGG3VzQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQyMToxMjoxN1rOGG3VzQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTg1MTM0MQ==", "bodyText": "use property for version", "url": "https://github.com/apache/pinot/pull/5249#discussion_r409851341", "createdAt": "2020-04-16T21:12:17Z", "author": {"login": "xiangfu0"}, "path": "pinot-plugins/pinot-file-system/pinot-s3/pom.xml", "diffHunk": "@@ -0,0 +1,156 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+\n+-->\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n+         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n+         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+    <modelVersion>4.0.0</modelVersion>\n+    <parent>\n+        <artifactId>pinot-file-system</artifactId>\n+        <groupId>org.apache.pinot</groupId>\n+        <version>${revision}${sha1}</version>\n+        <relativePath>..</relativePath>\n+    </parent>\n+\n+    <artifactId>pinot-s3</artifactId>\n+    <name>Pinot Amazon S3</name>\n+    <url>https://pinot.apache.org</url>\n+    <properties>\n+        <pinot.root>${basedir}/../../..</pinot.root>\n+        <aws.sdk.version>2.11.12</aws.sdk.version>\n+        <netty.version>4.1.42.Final</netty.version>\n+    </properties>\n+\n+    <dependencyManagement>\n+        <dependencies>\n+            <dependency>\n+                <groupId>software.amazon.awssdk</groupId>\n+                <artifactId>bom</artifactId>\n+                <version>${aws.sdk.version}</version>\n+                <type>pom</type>\n+                <scope>import</scope>\n+            </dependency>\n+        </dependencies>\n+    </dependencyManagement>\n+\n+    <dependencies>\n+        <dependency>\n+            <groupId>commons-configuration</groupId>\n+            <artifactId>commons-configuration</artifactId>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.apache.pinot</groupId>\n+            <artifactId>pinot-spi</artifactId>\n+            <version>0.4.0-SNAPSHOT</version>\n+        </dependency>\n+        <!-- amazon s3 -->\n+        <dependency>\n+            <groupId>software.amazon.awssdk</groupId>\n+            <artifactId>s3</artifactId>\n+            <version>${aws.sdk.version}</version>\n+            <exclusions>\n+                <exclusion>\n+                    <groupId>org.reactivestreams</groupId>\n+                    <artifactId>reactive-streams</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>io.netty</groupId>\n+                    <artifactId>netty-codec</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>io.netty</groupId>\n+                    <artifactId>netty-buffer</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>io.netty</groupId>\n+                    <artifactId>netty-transport</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>io.netty</groupId>\n+                    <artifactId>netty-common</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>org.apache.httpcomponents</groupId>\n+                    <artifactId>httpcore</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>org.apache.httpcomponents</groupId>\n+                    <artifactId>httpclient</artifactId>\n+                </exclusion>\n+            </exclusions>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.apache.httpcomponents</groupId>\n+            <artifactId>httpclient</artifactId>\n+            <version>4.5.5</version>\n+            <exclusions>\n+                <exclusion>\n+                    <groupId>org.apache.httpcomponents</groupId>\n+                    <artifactId>httpcore</artifactId>\n+                </exclusion>\n+            </exclusions>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.apache.httpcomponents</groupId>\n+            <artifactId>httpcore</artifactId>\n+            <version>4.4.9</version>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "71e40da73e5d829f5521352d24dbeda71004efa6"}, "originalPosition": 114}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0NDY1MDc0OnYy", "diffSide": "RIGHT", "path": "pinot-plugins/pinot-file-system/pinot-s3/pom.xml", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQyMToxMjo0NFrOGG3Whg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQyMToxMjo0NFrOGG3Whg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTg1MTUyNg==", "bodyText": "use property for version", "url": "https://github.com/apache/pinot/pull/5249#discussion_r409851526", "createdAt": "2020-04-16T21:12:44Z", "author": {"login": "xiangfu0"}, "path": "pinot-plugins/pinot-file-system/pinot-s3/pom.xml", "diffHunk": "@@ -0,0 +1,156 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+\n+-->\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n+         xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n+         xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+    <modelVersion>4.0.0</modelVersion>\n+    <parent>\n+        <artifactId>pinot-file-system</artifactId>\n+        <groupId>org.apache.pinot</groupId>\n+        <version>${revision}${sha1}</version>\n+        <relativePath>..</relativePath>\n+    </parent>\n+\n+    <artifactId>pinot-s3</artifactId>\n+    <name>Pinot Amazon S3</name>\n+    <url>https://pinot.apache.org</url>\n+    <properties>\n+        <pinot.root>${basedir}/../../..</pinot.root>\n+        <aws.sdk.version>2.11.12</aws.sdk.version>\n+        <netty.version>4.1.42.Final</netty.version>\n+    </properties>\n+\n+    <dependencyManagement>\n+        <dependencies>\n+            <dependency>\n+                <groupId>software.amazon.awssdk</groupId>\n+                <artifactId>bom</artifactId>\n+                <version>${aws.sdk.version}</version>\n+                <type>pom</type>\n+                <scope>import</scope>\n+            </dependency>\n+        </dependencies>\n+    </dependencyManagement>\n+\n+    <dependencies>\n+        <dependency>\n+            <groupId>commons-configuration</groupId>\n+            <artifactId>commons-configuration</artifactId>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.apache.pinot</groupId>\n+            <artifactId>pinot-spi</artifactId>\n+            <version>0.4.0-SNAPSHOT</version>\n+        </dependency>\n+        <!-- amazon s3 -->\n+        <dependency>\n+            <groupId>software.amazon.awssdk</groupId>\n+            <artifactId>s3</artifactId>\n+            <version>${aws.sdk.version}</version>\n+            <exclusions>\n+                <exclusion>\n+                    <groupId>org.reactivestreams</groupId>\n+                    <artifactId>reactive-streams</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>io.netty</groupId>\n+                    <artifactId>netty-codec</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>io.netty</groupId>\n+                    <artifactId>netty-buffer</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>io.netty</groupId>\n+                    <artifactId>netty-transport</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>io.netty</groupId>\n+                    <artifactId>netty-common</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>org.apache.httpcomponents</groupId>\n+                    <artifactId>httpcore</artifactId>\n+                </exclusion>\n+                <exclusion>\n+                    <groupId>org.apache.httpcomponents</groupId>\n+                    <artifactId>httpclient</artifactId>\n+                </exclusion>\n+            </exclusions>\n+        </dependency>\n+        <dependency>\n+            <groupId>org.apache.httpcomponents</groupId>\n+            <artifactId>httpclient</artifactId>\n+            <version>4.5.5</version>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "71e40da73e5d829f5521352d24dbeda71004efa6"}, "originalPosition": 103}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0NDgyOTQ0OnYy", "diffSide": "RIGHT", "path": "pinot-plugins/pinot-file-system/pinot-s3/src/main/java/org/apache/pinot/plugin/filesystem/S3PinotFS.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQyMjoxMzo1N1rOGG5DbQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQyMjoxMzo1N1rOGG5DbQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTg3OTQwNQ==", "bodyText": "convention followed is to not have static import. Instead use Preconditions.checkState", "url": "https://github.com/apache/pinot/pull/5249#discussion_r409879405", "createdAt": "2020-04-16T22:13:57Z", "author": {"login": "npawar"}, "path": "pinot-plugins/pinot-file-system/pinot-s3/src/main/java/org/apache/pinot/plugin/filesystem/S3PinotFS.java", "diffHunk": "@@ -0,0 +1,505 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.plugin.filesystem;\n+\n+import com.google.common.collect.ImmutableList;\n+import org.apache.commons.configuration.Configuration;\n+import org.apache.pinot.spi.filesystem.PinotFS;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import software.amazon.awssdk.auth.credentials.AwsBasicCredentials;\n+import software.amazon.awssdk.auth.credentials.AwsCredentialsProvider;\n+import software.amazon.awssdk.auth.credentials.AwsCredentialsProviderChain;\n+import software.amazon.awssdk.auth.credentials.EnvironmentVariableCredentialsProvider;\n+import software.amazon.awssdk.auth.credentials.ProfileCredentialsProvider;\n+import software.amazon.awssdk.auth.credentials.StaticCredentialsProvider;\n+import software.amazon.awssdk.auth.credentials.SystemPropertyCredentialsProvider;\n+import software.amazon.awssdk.core.ResponseBytes;\n+import software.amazon.awssdk.core.sync.RequestBody;\n+import software.amazon.awssdk.core.sync.ResponseTransformer;\n+import software.amazon.awssdk.regions.Region;\n+import software.amazon.awssdk.services.s3.S3Client;\n+\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.net.URLEncoder;\n+import java.nio.charset.StandardCharsets;\n+\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.io.IOException;\n+import java.io.File;\n+import java.io.UnsupportedEncodingException;\n+import java.io.InputStream;\n+\n+import software.amazon.awssdk.services.s3.model.S3Exception;\n+import software.amazon.awssdk.services.s3.model.NoSuchKeyException;\n+import software.amazon.awssdk.services.s3.model.HeadObjectRequest;\n+import software.amazon.awssdk.services.s3.model.HeadObjectResponse;\n+import software.amazon.awssdk.services.s3.model.ListObjectsV2Request;\n+import software.amazon.awssdk.services.s3.model.ListObjectsV2Response;\n+import software.amazon.awssdk.services.s3.model.GetObjectRequest;\n+import software.amazon.awssdk.services.s3.model.CopyObjectRequest;\n+import software.amazon.awssdk.services.s3.model.CopyObjectResponse;\n+import software.amazon.awssdk.services.s3.model.DeleteObjectRequest;\n+import software.amazon.awssdk.services.s3.model.DeleteObjectResponse;\n+import software.amazon.awssdk.services.s3.model.PutObjectRequest;\n+import software.amazon.awssdk.services.s3.model.PutObjectResponse;\n+import software.amazon.awssdk.services.s3.model.S3Object;\n+import software.amazon.awssdk.services.s3.model.MetadataDirective;\n+\n+import static com.google.common.base.Preconditions.checkState;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "71e40da73e5d829f5521352d24dbeda71004efa6"}, "originalPosition": 69}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0NDgzMDQwOnYy", "diffSide": "RIGHT", "path": "pinot-plugins/pinot-file-system/pinot-s3/src/main/java/org/apache/pinot/plugin/filesystem/S3PinotFS.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQyMjoxNDoxOFrOGG5EAQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQyMjoxNDoxOFrOGG5EAQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTg3OTU1Mw==", "bodyText": "Use com.google.common.base.Preconditions instead?", "url": "https://github.com/apache/pinot/pull/5249#discussion_r409879553", "createdAt": "2020-04-16T22:14:18Z", "author": {"login": "npawar"}, "path": "pinot-plugins/pinot-file-system/pinot-s3/src/main/java/org/apache/pinot/plugin/filesystem/S3PinotFS.java", "diffHunk": "@@ -0,0 +1,505 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.plugin.filesystem;\n+\n+import com.google.common.collect.ImmutableList;\n+import org.apache.commons.configuration.Configuration;\n+import org.apache.pinot.spi.filesystem.PinotFS;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import software.amazon.awssdk.auth.credentials.AwsBasicCredentials;\n+import software.amazon.awssdk.auth.credentials.AwsCredentialsProvider;\n+import software.amazon.awssdk.auth.credentials.AwsCredentialsProviderChain;\n+import software.amazon.awssdk.auth.credentials.EnvironmentVariableCredentialsProvider;\n+import software.amazon.awssdk.auth.credentials.ProfileCredentialsProvider;\n+import software.amazon.awssdk.auth.credentials.StaticCredentialsProvider;\n+import software.amazon.awssdk.auth.credentials.SystemPropertyCredentialsProvider;\n+import software.amazon.awssdk.core.ResponseBytes;\n+import software.amazon.awssdk.core.sync.RequestBody;\n+import software.amazon.awssdk.core.sync.ResponseTransformer;\n+import software.amazon.awssdk.regions.Region;\n+import software.amazon.awssdk.services.s3.S3Client;\n+\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.net.URLEncoder;\n+import java.nio.charset.StandardCharsets;\n+\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.io.IOException;\n+import java.io.File;\n+import java.io.UnsupportedEncodingException;\n+import java.io.InputStream;\n+\n+import software.amazon.awssdk.services.s3.model.S3Exception;\n+import software.amazon.awssdk.services.s3.model.NoSuchKeyException;\n+import software.amazon.awssdk.services.s3.model.HeadObjectRequest;\n+import software.amazon.awssdk.services.s3.model.HeadObjectResponse;\n+import software.amazon.awssdk.services.s3.model.ListObjectsV2Request;\n+import software.amazon.awssdk.services.s3.model.ListObjectsV2Response;\n+import software.amazon.awssdk.services.s3.model.GetObjectRequest;\n+import software.amazon.awssdk.services.s3.model.CopyObjectRequest;\n+import software.amazon.awssdk.services.s3.model.CopyObjectResponse;\n+import software.amazon.awssdk.services.s3.model.DeleteObjectRequest;\n+import software.amazon.awssdk.services.s3.model.DeleteObjectResponse;\n+import software.amazon.awssdk.services.s3.model.PutObjectRequest;\n+import software.amazon.awssdk.services.s3.model.PutObjectResponse;\n+import software.amazon.awssdk.services.s3.model.S3Object;\n+import software.amazon.awssdk.services.s3.model.MetadataDirective;\n+\n+import static com.google.common.base.Preconditions.checkState;\n+import static java.util.Objects.requireNonNull;\n+import static joptsimple.internal.Strings.isNullOrEmpty;\n+import static org.glassfish.jersey.internal.guava.Preconditions.checkArgument;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "71e40da73e5d829f5521352d24dbeda71004efa6"}, "originalPosition": 72}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0NDg1MjEzOnYy", "diffSide": "RIGHT", "path": "pinot-plugins/pinot-file-system/pinot-s3/src/main/java/org/apache/pinot/plugin/filesystem/S3PinotFS.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQyMjoyMjozNlrOGG5Q3g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xN1QxMTo1NzowMFrOGHLEiw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTg4Mjg0Ng==", "bodyText": "Preconditions.checkNotNull", "url": "https://github.com/apache/pinot/pull/5249#discussion_r409882846", "createdAt": "2020-04-16T22:22:36Z", "author": {"login": "npawar"}, "path": "pinot-plugins/pinot-file-system/pinot-s3/src/main/java/org/apache/pinot/plugin/filesystem/S3PinotFS.java", "diffHunk": "@@ -0,0 +1,505 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.plugin.filesystem;\n+\n+import com.google.common.collect.ImmutableList;\n+import org.apache.commons.configuration.Configuration;\n+import org.apache.pinot.spi.filesystem.PinotFS;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import software.amazon.awssdk.auth.credentials.AwsBasicCredentials;\n+import software.amazon.awssdk.auth.credentials.AwsCredentialsProvider;\n+import software.amazon.awssdk.auth.credentials.AwsCredentialsProviderChain;\n+import software.amazon.awssdk.auth.credentials.EnvironmentVariableCredentialsProvider;\n+import software.amazon.awssdk.auth.credentials.ProfileCredentialsProvider;\n+import software.amazon.awssdk.auth.credentials.StaticCredentialsProvider;\n+import software.amazon.awssdk.auth.credentials.SystemPropertyCredentialsProvider;\n+import software.amazon.awssdk.core.ResponseBytes;\n+import software.amazon.awssdk.core.sync.RequestBody;\n+import software.amazon.awssdk.core.sync.ResponseTransformer;\n+import software.amazon.awssdk.regions.Region;\n+import software.amazon.awssdk.services.s3.S3Client;\n+\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.net.URLEncoder;\n+import java.nio.charset.StandardCharsets;\n+\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.io.IOException;\n+import java.io.File;\n+import java.io.UnsupportedEncodingException;\n+import java.io.InputStream;\n+\n+import software.amazon.awssdk.services.s3.model.S3Exception;\n+import software.amazon.awssdk.services.s3.model.NoSuchKeyException;\n+import software.amazon.awssdk.services.s3.model.HeadObjectRequest;\n+import software.amazon.awssdk.services.s3.model.HeadObjectResponse;\n+import software.amazon.awssdk.services.s3.model.ListObjectsV2Request;\n+import software.amazon.awssdk.services.s3.model.ListObjectsV2Response;\n+import software.amazon.awssdk.services.s3.model.GetObjectRequest;\n+import software.amazon.awssdk.services.s3.model.CopyObjectRequest;\n+import software.amazon.awssdk.services.s3.model.CopyObjectResponse;\n+import software.amazon.awssdk.services.s3.model.DeleteObjectRequest;\n+import software.amazon.awssdk.services.s3.model.DeleteObjectResponse;\n+import software.amazon.awssdk.services.s3.model.PutObjectRequest;\n+import software.amazon.awssdk.services.s3.model.PutObjectResponse;\n+import software.amazon.awssdk.services.s3.model.S3Object;\n+import software.amazon.awssdk.services.s3.model.MetadataDirective;\n+\n+import static com.google.common.base.Preconditions.checkState;\n+import static java.util.Objects.requireNonNull;\n+import static joptsimple.internal.Strings.isNullOrEmpty;\n+import static org.glassfish.jersey.internal.guava.Preconditions.checkArgument;\n+\n+\n+public class S3PinotFS extends PinotFS {\n+  public static final String ACCESS_KEY = \"accessKey\";\n+  public static final String SECRET_KEY = \"secretKey\";\n+  public static final String REGION = \"region\";\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(S3PinotFS.class);\n+  private static final String DELIMITER = \"/\";\n+  private S3Client _s3Client;\n+\n+  @Override\n+  public void init(Configuration config) {\n+    checkArgument(!isNullOrEmpty(config.getString(REGION)));\n+    String region = config.getString(REGION);\n+\n+    AwsCredentialsProvider awsCredentialsProvider;\n+    try {\n+\n+      if (!isNullOrEmpty(config.getString(ACCESS_KEY)) && !isNullOrEmpty(config.getString(SECRET_KEY))) {\n+        String accessKey = config.getString(ACCESS_KEY);\n+        String secretKey = config.getString(SECRET_KEY);\n+        AwsBasicCredentials awsBasicCredentials = AwsBasicCredentials.create(accessKey, secretKey);\n+        awsCredentialsProvider = StaticCredentialsProvider.create(awsBasicCredentials);\n+      } else {\n+        awsCredentialsProvider =\n+            AwsCredentialsProviderChain.builder().addCredentialsProvider(SystemPropertyCredentialsProvider.create())\n+                .addCredentialsProvider(EnvironmentVariableCredentialsProvider.create()).build();\n+      }\n+\n+      _s3Client = S3Client.builder().region(Region.of(region)).credentialsProvider(awsCredentialsProvider).build();\n+    } catch (S3Exception e) {\n+      throw new RuntimeException(\"Could not initialize S3PinotFS\", e);\n+    }\n+  }\n+\n+  private HeadObjectResponse getS3ObjectMetadata(URI uri)\n+      throws IOException {\n+    URI base = getBase(uri);\n+    String path = sanitizePath(base.relativize(uri).getPath());\n+    HeadObjectRequest headObjectRequest = HeadObjectRequest.builder().bucket(uri.getHost()).key(path).build();\n+\n+    return _s3Client.headObject(headObjectRequest);\n+  }\n+\n+  private boolean isPathTerminatedByDelimiter(URI uri) {\n+    return uri.getPath().endsWith(DELIMITER);\n+  }\n+\n+  private String normalizeToDirectoryPrefix(URI uri)\n+      throws IOException {\n+    requireNonNull(uri, \"uri is null\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "71e40da73e5d829f5521352d24dbeda71004efa6"}, "originalPosition": 124}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDE3NDYwMw==", "bodyText": "Does it look fine now?", "url": "https://github.com/apache/pinot/pull/5249#discussion_r410174603", "createdAt": "2020-04-17T11:57:00Z", "author": {"login": "KKcorps"}, "path": "pinot-plugins/pinot-file-system/pinot-s3/src/main/java/org/apache/pinot/plugin/filesystem/S3PinotFS.java", "diffHunk": "@@ -0,0 +1,505 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.plugin.filesystem;\n+\n+import com.google.common.collect.ImmutableList;\n+import org.apache.commons.configuration.Configuration;\n+import org.apache.pinot.spi.filesystem.PinotFS;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import software.amazon.awssdk.auth.credentials.AwsBasicCredentials;\n+import software.amazon.awssdk.auth.credentials.AwsCredentialsProvider;\n+import software.amazon.awssdk.auth.credentials.AwsCredentialsProviderChain;\n+import software.amazon.awssdk.auth.credentials.EnvironmentVariableCredentialsProvider;\n+import software.amazon.awssdk.auth.credentials.ProfileCredentialsProvider;\n+import software.amazon.awssdk.auth.credentials.StaticCredentialsProvider;\n+import software.amazon.awssdk.auth.credentials.SystemPropertyCredentialsProvider;\n+import software.amazon.awssdk.core.ResponseBytes;\n+import software.amazon.awssdk.core.sync.RequestBody;\n+import software.amazon.awssdk.core.sync.ResponseTransformer;\n+import software.amazon.awssdk.regions.Region;\n+import software.amazon.awssdk.services.s3.S3Client;\n+\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.net.URLEncoder;\n+import java.nio.charset.StandardCharsets;\n+\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.io.IOException;\n+import java.io.File;\n+import java.io.UnsupportedEncodingException;\n+import java.io.InputStream;\n+\n+import software.amazon.awssdk.services.s3.model.S3Exception;\n+import software.amazon.awssdk.services.s3.model.NoSuchKeyException;\n+import software.amazon.awssdk.services.s3.model.HeadObjectRequest;\n+import software.amazon.awssdk.services.s3.model.HeadObjectResponse;\n+import software.amazon.awssdk.services.s3.model.ListObjectsV2Request;\n+import software.amazon.awssdk.services.s3.model.ListObjectsV2Response;\n+import software.amazon.awssdk.services.s3.model.GetObjectRequest;\n+import software.amazon.awssdk.services.s3.model.CopyObjectRequest;\n+import software.amazon.awssdk.services.s3.model.CopyObjectResponse;\n+import software.amazon.awssdk.services.s3.model.DeleteObjectRequest;\n+import software.amazon.awssdk.services.s3.model.DeleteObjectResponse;\n+import software.amazon.awssdk.services.s3.model.PutObjectRequest;\n+import software.amazon.awssdk.services.s3.model.PutObjectResponse;\n+import software.amazon.awssdk.services.s3.model.S3Object;\n+import software.amazon.awssdk.services.s3.model.MetadataDirective;\n+\n+import static com.google.common.base.Preconditions.checkState;\n+import static java.util.Objects.requireNonNull;\n+import static joptsimple.internal.Strings.isNullOrEmpty;\n+import static org.glassfish.jersey.internal.guava.Preconditions.checkArgument;\n+\n+\n+public class S3PinotFS extends PinotFS {\n+  public static final String ACCESS_KEY = \"accessKey\";\n+  public static final String SECRET_KEY = \"secretKey\";\n+  public static final String REGION = \"region\";\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(S3PinotFS.class);\n+  private static final String DELIMITER = \"/\";\n+  private S3Client _s3Client;\n+\n+  @Override\n+  public void init(Configuration config) {\n+    checkArgument(!isNullOrEmpty(config.getString(REGION)));\n+    String region = config.getString(REGION);\n+\n+    AwsCredentialsProvider awsCredentialsProvider;\n+    try {\n+\n+      if (!isNullOrEmpty(config.getString(ACCESS_KEY)) && !isNullOrEmpty(config.getString(SECRET_KEY))) {\n+        String accessKey = config.getString(ACCESS_KEY);\n+        String secretKey = config.getString(SECRET_KEY);\n+        AwsBasicCredentials awsBasicCredentials = AwsBasicCredentials.create(accessKey, secretKey);\n+        awsCredentialsProvider = StaticCredentialsProvider.create(awsBasicCredentials);\n+      } else {\n+        awsCredentialsProvider =\n+            AwsCredentialsProviderChain.builder().addCredentialsProvider(SystemPropertyCredentialsProvider.create())\n+                .addCredentialsProvider(EnvironmentVariableCredentialsProvider.create()).build();\n+      }\n+\n+      _s3Client = S3Client.builder().region(Region.of(region)).credentialsProvider(awsCredentialsProvider).build();\n+    } catch (S3Exception e) {\n+      throw new RuntimeException(\"Could not initialize S3PinotFS\", e);\n+    }\n+  }\n+\n+  private HeadObjectResponse getS3ObjectMetadata(URI uri)\n+      throws IOException {\n+    URI base = getBase(uri);\n+    String path = sanitizePath(base.relativize(uri).getPath());\n+    HeadObjectRequest headObjectRequest = HeadObjectRequest.builder().bucket(uri.getHost()).key(path).build();\n+\n+    return _s3Client.headObject(headObjectRequest);\n+  }\n+\n+  private boolean isPathTerminatedByDelimiter(URI uri) {\n+    return uri.getPath().endsWith(DELIMITER);\n+  }\n+\n+  private String normalizeToDirectoryPrefix(URI uri)\n+      throws IOException {\n+    requireNonNull(uri, \"uri is null\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTg4Mjg0Ng=="}, "originalCommit": {"oid": "71e40da73e5d829f5521352d24dbeda71004efa6"}, "originalPosition": 124}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0NjcxNDUxOnYy", "diffSide": "RIGHT", "path": "pinot-plugins/pinot-file-system/pinot-adls/pom.xml", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xN1QxMTo1OToxMFrOGHLIdA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xN1QxMTo1OToxMFrOGHLIdA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDE3NTYwNA==", "bodyText": "Seems like this extra new line got pushed in commit. Should I remove it ?", "url": "https://github.com/apache/pinot/pull/5249#discussion_r410175604", "createdAt": "2020-04-17T11:59:10Z", "author": {"login": "KKcorps"}, "path": "pinot-plugins/pinot-file-system/pinot-adls/pom.xml", "diffHunk": "@@ -48,3 +48,4 @@\n     </dependency>\n   </dependencies>\n </project>\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2ec54558f142ba068a1063a9702886d8ae363dc3"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU2MjgxMTk1OnYy", "diffSide": "RIGHT", "path": "pinot-plugins/pinot-file-system/pinot-s3/src/test/java/org/apache/pinot/plugin/filesystem/S3PinotFSTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQxOTo1MzoyM1rOGJVyrQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQyMDoxMzoyNFrOGJWjTA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjQ0NzQwNQ==", "bodyText": "license header", "url": "https://github.com/apache/pinot/pull/5249#discussion_r412447405", "createdAt": "2020-04-21T19:53:23Z", "author": {"login": "kishoreg"}, "path": "pinot-plugins/pinot-file-system/pinot-s3/src/test/java/org/apache/pinot/plugin/filesystem/S3PinotFSTest.java", "diffHunk": "@@ -0,0 +1,279 @@\n+package org.apache.pinot.plugin.filesystem;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d095a46181f24a12a54cacf8889c364402a78dad"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjQ1OTg1Mg==", "bodyText": "done", "url": "https://github.com/apache/pinot/pull/5249#discussion_r412459852", "createdAt": "2020-04-21T20:13:24Z", "author": {"login": "KKcorps"}, "path": "pinot-plugins/pinot-file-system/pinot-s3/src/test/java/org/apache/pinot/plugin/filesystem/S3PinotFSTest.java", "diffHunk": "@@ -0,0 +1,279 @@\n+package org.apache.pinot.plugin.filesystem;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjQ0NzQwNQ=="}, "originalCommit": {"oid": "d095a46181f24a12a54cacf8889c364402a78dad"}, "originalPosition": 1}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU2MjgxNTM2OnYy", "diffSide": "RIGHT", "path": "pinot-plugins/pinot-file-system/pinot-s3/src/test/java/org/apache/pinot/plugin/filesystem/S3PinotFSTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQxOTo1NDoxMVrOGJV0rg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQyMDoxMzoxNlrOGJWi-w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjQ0NzkxOA==", "bodyText": "missing annotation", "url": "https://github.com/apache/pinot/pull/5249#discussion_r412447918", "createdAt": "2020-04-21T19:54:11Z", "author": {"login": "kishoreg"}, "path": "pinot-plugins/pinot-file-system/pinot-s3/src/test/java/org/apache/pinot/plugin/filesystem/S3PinotFSTest.java", "diffHunk": "@@ -0,0 +1,279 @@\n+package org.apache.pinot.plugin.filesystem;\n+\n+import com.adobe.testing.s3mock.testng.S3Mock;\n+import java.io.File;\n+import java.io.InputStream;\n+import java.net.URI;\n+import java.nio.charset.StandardCharsets;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import org.apache.commons.io.IOUtils;\n+import org.testng.Assert;\n+import org.testng.annotations.BeforeMethod;\n+import org.testng.annotations.Listeners;\n+import org.testng.annotations.Test;\n+import software.amazon.awssdk.core.sync.RequestBody;\n+import software.amazon.awssdk.services.s3.S3Client;\n+import software.amazon.awssdk.services.s3.model.CreateBucketRequest;\n+import software.amazon.awssdk.services.s3.model.HeadObjectResponse;\n+import software.amazon.awssdk.services.s3.model.ListObjectsV2Response;\n+import software.amazon.awssdk.services.s3.model.S3Object;\n+\n+\n+@Test\n+@Listeners(com.adobe.testing.s3mock.testng.S3MockListener.class)\n+public class S3PinotFSTest {\n+  final String DELIMITER = \"/\";\n+  S3PinotFS _s3PinotFS;\n+  S3Client _s3Client;\n+  final String BUCKET = \"test-bucket\";\n+  final String SCHEME = \"s3\";\n+  final String FILE_FORMAT = \"%s://%s/%s\";\n+  final String DIR_FORMAT = \"%s://%s\";\n+\n+  @BeforeMethod\n+  public void setUp() {\n+    S3Mock s3Mock = S3Mock.getInstance();\n+    _s3Client = s3Mock.createS3ClientV2();\n+    _s3PinotFS = new S3PinotFS();\n+    _s3PinotFS.init(_s3Client);\n+    _s3Client.createBucket(CreateBucketRequest.builder().bucket(BUCKET).build());\n+  }\n+\n+  private void createEmptyFile(String folderName, String fileName) {\n+    String fileNameWithFolder = folderName + DELIMITER + fileName;\n+    _s3Client\n+        .putObject(S3TestUtils.getPutObjectRequest(BUCKET, fileNameWithFolder), RequestBody.fromBytes(new byte[0]));\n+  }\n+\n+  @Test\n+  public void testTouchFileInBucket()\n+      throws Exception {\n+\n+    String[] originalFiles = new String[]{\"a-touch.txt\", \"b-touch.txt\", \"c-touch.txt\"};\n+\n+    for (String fileName : originalFiles) {\n+      _s3PinotFS.touch(URI.create(String.format(FILE_FORMAT, SCHEME, BUCKET, fileName)));\n+    }\n+    ListObjectsV2Response listObjectsV2Response =\n+        _s3Client.listObjectsV2(S3TestUtils.getListObjectRequest(BUCKET, \"\", true));\n+\n+    String[] response = listObjectsV2Response.contents().stream().map(S3Object::key).filter(x -> x.contains(\"touch\"))\n+        .toArray(String[]::new);\n+\n+    Assert.assertEquals(response.length, originalFiles.length);\n+    Assert.assertTrue(Arrays.equals(response, originalFiles));\n+  }\n+\n+  @Test\n+  public void testTouchFilesInFolder()\n+      throws Exception {\n+\n+    String folder = \"my-files\";\n+    String[] originalFiles = new String[]{\"a-touch.txt\", \"b-touch.txt\", \"c-touch.txt\"};\n+\n+    for (String fileName : originalFiles) {\n+      String fileNameWithFolder = folder + DELIMITER + fileName;\n+      _s3PinotFS.touch(URI.create(String.format(FILE_FORMAT, SCHEME, BUCKET, fileNameWithFolder)));\n+    }\n+    ListObjectsV2Response listObjectsV2Response =\n+        _s3Client.listObjectsV2(S3TestUtils.getListObjectRequest(BUCKET, folder, false));\n+\n+    String[] response = listObjectsV2Response.contents().stream().map(S3Object::key).filter(x -> x.contains(\"touch\"))\n+        .toArray(String[]::new);\n+    Assert.assertEquals(response.length, originalFiles.length);\n+\n+    Assert.assertTrue(Arrays.equals(response, Arrays.stream(originalFiles).map(x -> folder + DELIMITER + x).toArray()));\n+  }\n+\n+  public void testListFilesInBucketNonRecursive()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d095a46181f24a12a54cacf8889c364402a78dad"}, "originalPosition": 90}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjQ1OTc3MQ==", "bodyText": "done", "url": "https://github.com/apache/pinot/pull/5249#discussion_r412459771", "createdAt": "2020-04-21T20:13:16Z", "author": {"login": "KKcorps"}, "path": "pinot-plugins/pinot-file-system/pinot-s3/src/test/java/org/apache/pinot/plugin/filesystem/S3PinotFSTest.java", "diffHunk": "@@ -0,0 +1,279 @@\n+package org.apache.pinot.plugin.filesystem;\n+\n+import com.adobe.testing.s3mock.testng.S3Mock;\n+import java.io.File;\n+import java.io.InputStream;\n+import java.net.URI;\n+import java.nio.charset.StandardCharsets;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import org.apache.commons.io.IOUtils;\n+import org.testng.Assert;\n+import org.testng.annotations.BeforeMethod;\n+import org.testng.annotations.Listeners;\n+import org.testng.annotations.Test;\n+import software.amazon.awssdk.core.sync.RequestBody;\n+import software.amazon.awssdk.services.s3.S3Client;\n+import software.amazon.awssdk.services.s3.model.CreateBucketRequest;\n+import software.amazon.awssdk.services.s3.model.HeadObjectResponse;\n+import software.amazon.awssdk.services.s3.model.ListObjectsV2Response;\n+import software.amazon.awssdk.services.s3.model.S3Object;\n+\n+\n+@Test\n+@Listeners(com.adobe.testing.s3mock.testng.S3MockListener.class)\n+public class S3PinotFSTest {\n+  final String DELIMITER = \"/\";\n+  S3PinotFS _s3PinotFS;\n+  S3Client _s3Client;\n+  final String BUCKET = \"test-bucket\";\n+  final String SCHEME = \"s3\";\n+  final String FILE_FORMAT = \"%s://%s/%s\";\n+  final String DIR_FORMAT = \"%s://%s\";\n+\n+  @BeforeMethod\n+  public void setUp() {\n+    S3Mock s3Mock = S3Mock.getInstance();\n+    _s3Client = s3Mock.createS3ClientV2();\n+    _s3PinotFS = new S3PinotFS();\n+    _s3PinotFS.init(_s3Client);\n+    _s3Client.createBucket(CreateBucketRequest.builder().bucket(BUCKET).build());\n+  }\n+\n+  private void createEmptyFile(String folderName, String fileName) {\n+    String fileNameWithFolder = folderName + DELIMITER + fileName;\n+    _s3Client\n+        .putObject(S3TestUtils.getPutObjectRequest(BUCKET, fileNameWithFolder), RequestBody.fromBytes(new byte[0]));\n+  }\n+\n+  @Test\n+  public void testTouchFileInBucket()\n+      throws Exception {\n+\n+    String[] originalFiles = new String[]{\"a-touch.txt\", \"b-touch.txt\", \"c-touch.txt\"};\n+\n+    for (String fileName : originalFiles) {\n+      _s3PinotFS.touch(URI.create(String.format(FILE_FORMAT, SCHEME, BUCKET, fileName)));\n+    }\n+    ListObjectsV2Response listObjectsV2Response =\n+        _s3Client.listObjectsV2(S3TestUtils.getListObjectRequest(BUCKET, \"\", true));\n+\n+    String[] response = listObjectsV2Response.contents().stream().map(S3Object::key).filter(x -> x.contains(\"touch\"))\n+        .toArray(String[]::new);\n+\n+    Assert.assertEquals(response.length, originalFiles.length);\n+    Assert.assertTrue(Arrays.equals(response, originalFiles));\n+  }\n+\n+  @Test\n+  public void testTouchFilesInFolder()\n+      throws Exception {\n+\n+    String folder = \"my-files\";\n+    String[] originalFiles = new String[]{\"a-touch.txt\", \"b-touch.txt\", \"c-touch.txt\"};\n+\n+    for (String fileName : originalFiles) {\n+      String fileNameWithFolder = folder + DELIMITER + fileName;\n+      _s3PinotFS.touch(URI.create(String.format(FILE_FORMAT, SCHEME, BUCKET, fileNameWithFolder)));\n+    }\n+    ListObjectsV2Response listObjectsV2Response =\n+        _s3Client.listObjectsV2(S3TestUtils.getListObjectRequest(BUCKET, folder, false));\n+\n+    String[] response = listObjectsV2Response.contents().stream().map(S3Object::key).filter(x -> x.contains(\"touch\"))\n+        .toArray(String[]::new);\n+    Assert.assertEquals(response.length, originalFiles.length);\n+\n+    Assert.assertTrue(Arrays.equals(response, Arrays.stream(originalFiles).map(x -> folder + DELIMITER + x).toArray()));\n+  }\n+\n+  public void testListFilesInBucketNonRecursive()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjQ0NzkxOA=="}, "originalCommit": {"oid": "d095a46181f24a12a54cacf8889c364402a78dad"}, "originalPosition": 90}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3405, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}