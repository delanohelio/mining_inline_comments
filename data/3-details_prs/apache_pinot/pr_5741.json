{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDU1NTg2NTkz", "number": 5741, "title": "Move lambda expression to inner function in pinot-spark", "bodyText": "Description\nWe observed user reporting issue that Spark cannot serialize lambda expressions. So need to explicitly use inner function for this.", "createdAt": "2020-07-23T09:34:11Z", "url": "https://github.com/apache/pinot/pull/5741", "merged": true, "mergeCommit": {"oid": "48fb6f309a452707981482cbf2bd4bb18edf9d25"}, "closed": true, "closedAt": "2020-07-23T20:11:22Z", "author": {"login": "xiangfu0"}, "timelineItems": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc3tH2QgBqjM1Nzk0MDU4MjI=", "endCursor": "Y3Vyc29yOnYyOpPPAAABc30WtTgBqjM1ODEzNTYyOTU=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "514896e805d2ac6d3f9c0e6acd4f89febc51136f", "author": {"user": {"login": "xiangfu0", "name": "Xiang Fu"}}, "url": "https://github.com/apache/pinot/commit/514896e805d2ac6d3f9c0e6acd4f89febc51136f", "committedDate": "2020-07-23T09:35:21Z", "message": "Update SparkSegmentGenerationJobRunner.java"}, "afterCommit": {"oid": "4b6eb03d04b0b25ebf4a67d76c8856c8d8c805a3", "author": {"user": {"login": "xiangfu0", "name": "Xiang Fu"}}, "url": "https://github.com/apache/pinot/commit/4b6eb03d04b0b25ebf4a67d76c8856c8d8c805a3", "committedDate": "2020-07-23T10:45:59Z", "message": "Move lambda expression to inner function in pinot-spark"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "4b6eb03d04b0b25ebf4a67d76c8856c8d8c805a3", "author": {"user": {"login": "xiangfu0", "name": "Xiang Fu"}}, "url": "https://github.com/apache/pinot/commit/4b6eb03d04b0b25ebf4a67d76c8856c8d8c805a3", "committedDate": "2020-07-23T10:45:59Z", "message": "Move lambda expression to inner function in pinot-spark"}, "afterCommit": {"oid": "aaf69d8d26f1cb6ecebcad8660c95bd139eb24e6", "author": {"user": {"login": "xiangfu0", "name": "Xiang Fu"}}, "url": "https://github.com/apache/pinot/commit/aaf69d8d26f1cb6ecebcad8660c95bd139eb24e6", "committedDate": "2020-07-23T10:50:08Z", "message": "Move lambda expression to inner function in pinot-spark"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU0MTU2NTA4", "url": "https://github.com/apache/pinot/pull/5741#pullrequestreview-454156508", "createdAt": "2020-07-23T13:55:06Z", "commit": {"oid": "aaf69d8d26f1cb6ecebcad8660c95bd139eb24e6"}, "state": "APPROVED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QxMzo1NTowNlrOG2LqhQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QxMzo1NTo0MFrOG2Ls-g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTQ2NzM5Nw==", "bodyText": "I can't tell if the original or the new formatting adheres to the Pinot Style, please ensure the new one does.", "url": "https://github.com/apache/pinot/pull/5741#discussion_r459467397", "createdAt": "2020-07-23T13:55:06Z", "author": {"login": "mayankshriv"}, "path": "pinot-plugins/pinot-batch-ingestion/pinot-batch-ingestion-spark/src/main/java/org/apache/pinot/plugin/ingestion/batch/spark/SparkSegmentGenerationJobRunner.java", "diffHunk": "@@ -209,93 +210,99 @@ public void run()\n               .get(PLUGINS_INCLUDE_PROPERTY_NAME) : null;\n       final URI finalInputDirURI = inputDirURI;\n       final URI finalOutputDirURI = (stagingDirURI == null) ? outputDirURI : stagingDirURI;\n-      pathRDD.foreach(pathAndIdx -> {\n-        for (PinotFSSpec pinotFSSpec : _spec.getPinotFSSpecs()) {\n-          PinotFSFactory.register(pinotFSSpec.getScheme(), pinotFSSpec.getClassName(), new PinotConfiguration(pinotFSSpec));\n-        }\n-        PinotFS finalOutputDirFS = PinotFSFactory.create(finalOutputDirURI.getScheme());\n-        String[] splits = pathAndIdx.split(\" \");\n-        String path = splits[0];\n-        int idx = Integer.valueOf(splits[1]);\n-        // Load Pinot Plugins copied from Distributed cache.\n-        File localPluginsTarFile = new File(PINOT_PLUGINS_TAR_GZ);\n-        if (localPluginsTarFile.exists()) {\n-          File pluginsDirFile = new File(PINOT_PLUGINS_DIR + \"-\" + idx);\n-          try {\n-            TarGzCompressionUtils.untar(localPluginsTarFile, pluginsDirFile);\n-          } catch (Exception e) {\n-            LOGGER.error(\"Failed to untar local Pinot plugins tarball file [{}]\", localPluginsTarFile, e);\n-            throw new RuntimeException(e);\n+      // Prevent using lambda expression in Spark to avoid potential serialization exceptions, use inner function instead.\n+      pathRDD.foreach(new VoidFunction<String>() {\n+        @Override\n+        public void call(String pathAndIdx)\n+            throws Exception {\n+          PluginManager.get().init();\n+          for (PinotFSSpec pinotFSSpec : _spec.getPinotFSSpecs()) {\n+            PinotFSFactory.register(pinotFSSpec.getScheme(), pinotFSSpec.getClassName(), new PinotConfiguration(pinotFSSpec));\n           }\n-          LOGGER.info(\"Trying to set System Property: [{}={}]\", PLUGINS_DIR_PROPERTY_NAME,\n-              pluginsDirFile.getAbsolutePath());\n-          System.setProperty(PLUGINS_DIR_PROPERTY_NAME, pluginsDirFile.getAbsolutePath());\n-          if (pluginsInclude != null) {\n-            LOGGER.info(\"Trying to set System Property: [{}={}]\", PLUGINS_INCLUDE_PROPERTY_NAME, pluginsInclude);\n-            System.setProperty(PLUGINS_INCLUDE_PROPERTY_NAME, pluginsInclude);\n+          PinotFS finalOutputDirFS = PinotFSFactory.create(finalOutputDirURI.getScheme());\n+          String[] splits = pathAndIdx.split(\" \");\n+          String path = splits[0];\n+          int idx = Integer.valueOf(splits[1]);\n+          // Load Pinot Plugins copied from Distributed cache.\n+          File localPluginsTarFile = new File(PINOT_PLUGINS_TAR_GZ);\n+          if (localPluginsTarFile.exists()) {\n+            File pluginsDirFile = new File(PINOT_PLUGINS_DIR + \"-\" + idx);\n+            try {\n+              TarGzCompressionUtils.untar(localPluginsTarFile, pluginsDirFile);\n+            } catch (Exception e) {\n+              LOGGER.error(\"Failed to untar local Pinot plugins tarball file [{}]\", localPluginsTarFile, e);\n+              throw new RuntimeException(e);\n+            }\n+            LOGGER.info(\"Trying to set System Property: [{}={}]\", PLUGINS_DIR_PROPERTY_NAME,\n+                pluginsDirFile.getAbsolutePath());\n+            System.setProperty(PLUGINS_DIR_PROPERTY_NAME, pluginsDirFile.getAbsolutePath());\n+            if (pluginsInclude != null) {\n+              LOGGER.info(\"Trying to set System Property: [{}={}]\", PLUGINS_INCLUDE_PROPERTY_NAME, pluginsInclude);\n+              System.setProperty(PLUGINS_INCLUDE_PROPERTY_NAME, pluginsInclude);\n+            }\n+            LOGGER.info(\"Pinot plugins System Properties are set at [{}], plugins includes [{}]\",\n+                System.getProperty(PLUGINS_DIR_PROPERTY_NAME), System.getProperty(PLUGINS_INCLUDE_PROPERTY_NAME));\n+          } else {\n+            LOGGER.warn(\"Cannot find local Pinot plugins tar file at [{}]\", localPluginsTarFile.getAbsolutePath());\n+          }\n+          URI inputFileURI = URI.create(path);\n+          if (inputFileURI.getScheme() == null) {\n+            inputFileURI =\n+                new URI(finalInputDirURI.getScheme(), inputFileURI.getSchemeSpecificPart(), inputFileURI.getFragment());\n           }\n-          LOGGER.info(\"Pinot plugins System Properties are set at [{}], plugins includes [{}]\",\n-              System.getProperty(PLUGINS_DIR_PROPERTY_NAME), System.getProperty(PLUGINS_INCLUDE_PROPERTY_NAME));\n-        } else {\n-          LOGGER.warn(\"Cannot find local Pinot plugins tar file at [{}]\", localPluginsTarFile.getAbsolutePath());\n-        }\n-        URI inputFileURI = URI.create(path);\n-        if (inputFileURI.getScheme() == null) {\n-          inputFileURI =\n-              new URI(finalInputDirURI.getScheme(), inputFileURI.getSchemeSpecificPart(), inputFileURI.getFragment());\n-        }\n \n-        //create localTempDir for input and output\n-        File localTempDir = new File(FileUtils.getTempDirectory(), \"pinot-\" + UUID.randomUUID());\n-        File localInputTempDir = new File(localTempDir, \"input\");\n-        FileUtils.forceMkdir(localInputTempDir);\n-        File localOutputTempDir = new File(localTempDir, \"output\");\n-        FileUtils.forceMkdir(localOutputTempDir);\n+          //create localTempDir for input and output", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aaf69d8d26f1cb6ecebcad8660c95bd139eb24e6"}, "originalPosition": 92}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTQ2ODAyNg==", "bodyText": "Thanks for fixing this, how to prevent this from happening in future? Is this unit testable?", "url": "https://github.com/apache/pinot/pull/5741#discussion_r459468026", "createdAt": "2020-07-23T13:55:40Z", "author": {"login": "mayankshriv"}, "path": "pinot-plugins/pinot-batch-ingestion/pinot-batch-ingestion-spark/src/main/java/org/apache/pinot/plugin/ingestion/batch/spark/SparkSegmentGenerationJobRunner.java", "diffHunk": "@@ -209,93 +210,99 @@ public void run()\n               .get(PLUGINS_INCLUDE_PROPERTY_NAME) : null;\n       final URI finalInputDirURI = inputDirURI;\n       final URI finalOutputDirURI = (stagingDirURI == null) ? outputDirURI : stagingDirURI;\n-      pathRDD.foreach(pathAndIdx -> {\n-        for (PinotFSSpec pinotFSSpec : _spec.getPinotFSSpecs()) {\n-          PinotFSFactory.register(pinotFSSpec.getScheme(), pinotFSSpec.getClassName(), new PinotConfiguration(pinotFSSpec));\n-        }\n-        PinotFS finalOutputDirFS = PinotFSFactory.create(finalOutputDirURI.getScheme());\n-        String[] splits = pathAndIdx.split(\" \");\n-        String path = splits[0];\n-        int idx = Integer.valueOf(splits[1]);\n-        // Load Pinot Plugins copied from Distributed cache.\n-        File localPluginsTarFile = new File(PINOT_PLUGINS_TAR_GZ);\n-        if (localPluginsTarFile.exists()) {\n-          File pluginsDirFile = new File(PINOT_PLUGINS_DIR + \"-\" + idx);\n-          try {\n-            TarGzCompressionUtils.untar(localPluginsTarFile, pluginsDirFile);\n-          } catch (Exception e) {\n-            LOGGER.error(\"Failed to untar local Pinot plugins tarball file [{}]\", localPluginsTarFile, e);\n-            throw new RuntimeException(e);\n+      // Prevent using lambda expression in Spark to avoid potential serialization exceptions, use inner function instead.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aaf69d8d26f1cb6ecebcad8660c95bd139eb24e6"}, "originalPosition": 29}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9d1759aa7e1b58855dc8e72c59b15b1281993c21", "author": {"user": {"login": "xiangfu0", "name": "Xiang Fu"}}, "url": "https://github.com/apache/pinot/commit/9d1759aa7e1b58855dc8e72c59b15b1281993c21", "committedDate": "2020-07-23T19:11:39Z", "message": "Move lambda expression to inner function in pinot-spark"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "aaf69d8d26f1cb6ecebcad8660c95bd139eb24e6", "author": {"user": {"login": "xiangfu0", "name": "Xiang Fu"}}, "url": "https://github.com/apache/pinot/commit/aaf69d8d26f1cb6ecebcad8660c95bd139eb24e6", "committedDate": "2020-07-23T10:50:08Z", "message": "Move lambda expression to inner function in pinot-spark"}, "afterCommit": {"oid": "9d1759aa7e1b58855dc8e72c59b15b1281993c21", "author": {"user": {"login": "xiangfu0", "name": "Xiang Fu"}}, "url": "https://github.com/apache/pinot/commit/9d1759aa7e1b58855dc8e72c59b15b1281993c21", "committedDate": "2020-07-23T19:11:39Z", "message": "Move lambda expression to inner function in pinot-spark"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 445, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}