{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTI3MzUzNTg2", "number": 6290, "reviewThreads": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0zMFQxNzozNTozNFrOE-w3vw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0zMFQxNzo1ODowMFrOE-xcvg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0MjQ3ODcxOnYy", "diffSide": "RIGHT", "path": "thirdeye/thirdeye-frontend/app/utils/anomalies-tree-parser.js", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0zMFQxNzozNTozNFrOH8GEwA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMTozOToyMVrOH8Uvcw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjc3NjEyOA==", "bodyText": "please keep code style consistency. I remember we enable the single quote rule. You could run prettier to format it.", "url": "https://github.com/apache/pinot/pull/6290#discussion_r532776128", "createdAt": "2020-11-30T17:35:34Z", "author": {"login": "zhangloo333"}, "path": "thirdeye/thirdeye-frontend/app/utils/anomalies-tree-parser.js", "diffHunk": "@@ -0,0 +1,563 @@\n+import { isEmpty } from \"@ember/utils\";\n+import { set } from \"@ember/object\";\n+import moment from \"moment\";\n+\n+const CLASSIFICATIONS = {\n+  METRICS: {\n+    KEY: \"metrics\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dcf352e0e03982aeec28fbaab61224c541e0d0e0"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjk3NDk4NA==", "bodyText": "Can you tell me what is the exact command for it? Is it tied to your code changes in #6245? If so, I may not be able to do as your changes are not merged yet.", "url": "https://github.com/apache/pinot/pull/6290#discussion_r532974984", "createdAt": "2020-11-30T23:39:21Z", "author": {"login": "tejasajmera"}, "path": "thirdeye/thirdeye-frontend/app/utils/anomalies-tree-parser.js", "diffHunk": "@@ -0,0 +1,563 @@\n+import { isEmpty } from \"@ember/utils\";\n+import { set } from \"@ember/object\";\n+import moment from \"moment\";\n+\n+const CLASSIFICATIONS = {\n+  METRICS: {\n+    KEY: \"metrics\",", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjc3NjEyOA=="}, "originalCommit": {"oid": "dcf352e0e03982aeec28fbaab61224c541e0d0e0"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAxNjQzNQ==", "bodyText": "I haven't realized my code hasn't merged yet. The command npm run eslint-app only can detect errors, but not fix them. You need to fix manually or set your vscode prettier with the rule of a single quote.", "url": "https://github.com/apache/pinot/pull/6290#discussion_r533016435", "createdAt": "2020-12-01T01:39:21Z", "author": {"login": "zhangloo333"}, "path": "thirdeye/thirdeye-frontend/app/utils/anomalies-tree-parser.js", "diffHunk": "@@ -0,0 +1,563 @@\n+import { isEmpty } from \"@ember/utils\";\n+import { set } from \"@ember/object\";\n+import moment from \"moment\";\n+\n+const CLASSIFICATIONS = {\n+  METRICS: {\n+    KEY: \"metrics\",", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjc3NjEyOA=="}, "originalCommit": {"oid": "dcf352e0e03982aeec28fbaab61224c541e0d0e0"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0MjQ5ODE5OnYy", "diffSide": "RIGHT", "path": "thirdeye/thirdeye-frontend/app/utils/anomalies-tree-parser.js", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0zMFQxNzo0MDoxNlrOH8GQuQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0zMFQyMzozOToyOFrOH8SNrw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjc3OTE5Mw==", "bodyText": "I suggest you put this time format in the constant.js or to create a constant folder. it's a common useful variable. We can inject into the function.", "url": "https://github.com/apache/pinot/pull/6290#discussion_r532779193", "createdAt": "2020-11-30T17:40:16Z", "author": {"login": "zhangloo333"}, "path": "thirdeye/thirdeye-frontend/app/utils/anomalies-tree-parser.js", "diffHunk": "@@ -0,0 +1,563 @@\n+import { isEmpty } from \"@ember/utils\";\n+import { set } from \"@ember/object\";\n+import moment from \"moment\";\n+\n+const CLASSIFICATIONS = {\n+  METRICS: {\n+    KEY: \"metrics\",\n+    COMPONENT_PATH: \"entity-metrics\",\n+    DEFAULT_TITLE: \"Metric Anomalies\"\n+  },\n+  GROUPS: {\n+    KEY: \"groups\",\n+    COMPONENT_PATH: \"entity-groups\",\n+    DEFAULT_TITLE: \"ENTITY:\"\n+  },\n+  ENTITIES: {\n+    KEY: \"entities\",\n+    COMPONENT_PATH: \"parent-anomalies\",\n+    DEFAULT_TITLE: \"Entity\"\n+  }\n+};\n+const BREADCRUMB_TIME_DISPLAY_FORMAT = \"MMM D HH:mm\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dcf352e0e03982aeec28fbaab61224c541e0d0e0"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjk3NTAyMw==", "bodyText": "Sure.", "url": "https://github.com/apache/pinot/pull/6290#discussion_r532975023", "createdAt": "2020-11-30T23:39:28Z", "author": {"login": "tejasajmera"}, "path": "thirdeye/thirdeye-frontend/app/utils/anomalies-tree-parser.js", "diffHunk": "@@ -0,0 +1,563 @@\n+import { isEmpty } from \"@ember/utils\";\n+import { set } from \"@ember/object\";\n+import moment from \"moment\";\n+\n+const CLASSIFICATIONS = {\n+  METRICS: {\n+    KEY: \"metrics\",\n+    COMPONENT_PATH: \"entity-metrics\",\n+    DEFAULT_TITLE: \"Metric Anomalies\"\n+  },\n+  GROUPS: {\n+    KEY: \"groups\",\n+    COMPONENT_PATH: \"entity-groups\",\n+    DEFAULT_TITLE: \"ENTITY:\"\n+  },\n+  ENTITIES: {\n+    KEY: \"entities\",\n+    COMPONENT_PATH: \"parent-anomalies\",\n+    DEFAULT_TITLE: \"Entity\"\n+  }\n+};\n+const BREADCRUMB_TIME_DISPLAY_FORMAT = \"MMM D HH:mm\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjc3OTE5Mw=="}, "originalCommit": {"oid": "dcf352e0e03982aeec28fbaab61224c541e0d0e0"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0MjUxNTkxOnYy", "diffSide": "RIGHT", "path": "thirdeye/thirdeye-frontend/app/utils/anomalies-tree-parser.js", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0zMFQxNzo0NDoyNFrOH8GbfQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0zMFQyMzozOTozOFrOH8SN6Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjc4MTk0OQ==", "bodyText": "Please add parentheses for input to keep clarity and obey the eslint rule(arrow-parens).\nFor more detail to check 8.4 Always include parentheses around arguments for clarity and consistency. eslint: arrow-parens", "url": "https://github.com/apache/pinot/pull/6290#discussion_r532781949", "createdAt": "2020-11-30T17:44:24Z", "author": {"login": "zhangloo333"}, "path": "thirdeye/thirdeye-frontend/app/utils/anomalies-tree-parser.js", "diffHunk": "@@ -0,0 +1,563 @@\n+import { isEmpty } from \"@ember/utils\";\n+import { set } from \"@ember/object\";\n+import moment from \"moment\";\n+\n+const CLASSIFICATIONS = {\n+  METRICS: {\n+    KEY: \"metrics\",\n+    COMPONENT_PATH: \"entity-metrics\",\n+    DEFAULT_TITLE: \"Metric Anomalies\"\n+  },\n+  GROUPS: {\n+    KEY: \"groups\",\n+    COMPONENT_PATH: \"entity-groups\",\n+    DEFAULT_TITLE: \"ENTITY:\"\n+  },\n+  ENTITIES: {\n+    KEY: \"entities\",\n+    COMPONENT_PATH: \"parent-anomalies\",\n+    DEFAULT_TITLE: \"Entity\"\n+  }\n+};\n+const BREADCRUMB_TIME_DISPLAY_FORMAT = \"MMM D HH:mm\";\n+\n+/**\n+ * Format the timestamp into the form to be shown in the breadcrumb\n+ *\n+ * @param {Number} timestamp\n+ *   The timestamp of anomaly creation time in milliseconds\n+ *\n+ * @returns {String}\n+ *   Formatted timestamp. Example of the required format - \"Sep 15 16:49 EST\"\n+ */\n+const getFormattedBreadcrumbTime = timestamp => {\n+  const zoneName = moment.tz.guess();\n+  const timeZoneAbbreviation = moment.tz(zoneName).zoneAbbr();\n+\n+  return `${moment(timestamp).format(\n+    BREADCRUMB_TIME_DISPLAY_FORMAT\n+  )} ${timeZoneAbbreviation}`;\n+};\n+\n+/**\n+ * Parse the anomalies generated by the composite alert to populate parent-anomalies table with relevent details about\n+ * children for each anomaly.\n+ *\n+ * @param {Array<Object>} input\n+ *   The anomalies for composite alert.\n+ *\n+ * @returns {Array<Object>}\n+ *   Parsed out contents to populate parent-anomalies table\n+ */\n+const populateParentAnomaliesTable = input => {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dcf352e0e03982aeec28fbaab61224c541e0d0e0"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjk3NTA4MQ==", "bodyText": "Sure.", "url": "https://github.com/apache/pinot/pull/6290#discussion_r532975081", "createdAt": "2020-11-30T23:39:38Z", "author": {"login": "tejasajmera"}, "path": "thirdeye/thirdeye-frontend/app/utils/anomalies-tree-parser.js", "diffHunk": "@@ -0,0 +1,563 @@\n+import { isEmpty } from \"@ember/utils\";\n+import { set } from \"@ember/object\";\n+import moment from \"moment\";\n+\n+const CLASSIFICATIONS = {\n+  METRICS: {\n+    KEY: \"metrics\",\n+    COMPONENT_PATH: \"entity-metrics\",\n+    DEFAULT_TITLE: \"Metric Anomalies\"\n+  },\n+  GROUPS: {\n+    KEY: \"groups\",\n+    COMPONENT_PATH: \"entity-groups\",\n+    DEFAULT_TITLE: \"ENTITY:\"\n+  },\n+  ENTITIES: {\n+    KEY: \"entities\",\n+    COMPONENT_PATH: \"parent-anomalies\",\n+    DEFAULT_TITLE: \"Entity\"\n+  }\n+};\n+const BREADCRUMB_TIME_DISPLAY_FORMAT = \"MMM D HH:mm\";\n+\n+/**\n+ * Format the timestamp into the form to be shown in the breadcrumb\n+ *\n+ * @param {Number} timestamp\n+ *   The timestamp of anomaly creation time in milliseconds\n+ *\n+ * @returns {String}\n+ *   Formatted timestamp. Example of the required format - \"Sep 15 16:49 EST\"\n+ */\n+const getFormattedBreadcrumbTime = timestamp => {\n+  const zoneName = moment.tz.guess();\n+  const timeZoneAbbreviation = moment.tz(zoneName).zoneAbbr();\n+\n+  return `${moment(timestamp).format(\n+    BREADCRUMB_TIME_DISPLAY_FORMAT\n+  )} ${timeZoneAbbreviation}`;\n+};\n+\n+/**\n+ * Parse the anomalies generated by the composite alert to populate parent-anomalies table with relevent details about\n+ * children for each anomaly.\n+ *\n+ * @param {Array<Object>} input\n+ *   The anomalies for composite alert.\n+ *\n+ * @returns {Array<Object>}\n+ *   Parsed out contents to populate parent-anomalies table\n+ */\n+const populateParentAnomaliesTable = input => {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjc4MTk0OQ=="}, "originalCommit": {"oid": "dcf352e0e03982aeec28fbaab61224c541e0d0e0"}, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0MjUyNTgyOnYy", "diffSide": "RIGHT", "path": "thirdeye/thirdeye-frontend/app/utils/anomalies-tree-parser.js", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0zMFQxNzo0Njo0NFrOH8Ghtw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0zMFQyMzo0Nzo1MVrOH8SaYA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjc4MzU0Mw==", "bodyText": "if there is no complicated logic, you could use the ternary to shorter logic and reduce code.", "url": "https://github.com/apache/pinot/pull/6290#discussion_r532783543", "createdAt": "2020-11-30T17:46:44Z", "author": {"login": "zhangloo333"}, "path": "thirdeye/thirdeye-frontend/app/utils/anomalies-tree-parser.js", "diffHunk": "@@ -0,0 +1,563 @@\n+import { isEmpty } from \"@ember/utils\";\n+import { set } from \"@ember/object\";\n+import moment from \"moment\";\n+\n+const CLASSIFICATIONS = {\n+  METRICS: {\n+    KEY: \"metrics\",\n+    COMPONENT_PATH: \"entity-metrics\",\n+    DEFAULT_TITLE: \"Metric Anomalies\"\n+  },\n+  GROUPS: {\n+    KEY: \"groups\",\n+    COMPONENT_PATH: \"entity-groups\",\n+    DEFAULT_TITLE: \"ENTITY:\"\n+  },\n+  ENTITIES: {\n+    KEY: \"entities\",\n+    COMPONENT_PATH: \"parent-anomalies\",\n+    DEFAULT_TITLE: \"Entity\"\n+  }\n+};\n+const BREADCRUMB_TIME_DISPLAY_FORMAT = \"MMM D HH:mm\";\n+\n+/**\n+ * Format the timestamp into the form to be shown in the breadcrumb\n+ *\n+ * @param {Number} timestamp\n+ *   The timestamp of anomaly creation time in milliseconds\n+ *\n+ * @returns {String}\n+ *   Formatted timestamp. Example of the required format - \"Sep 15 16:49 EST\"\n+ */\n+const getFormattedBreadcrumbTime = timestamp => {\n+  const zoneName = moment.tz.guess();\n+  const timeZoneAbbreviation = moment.tz(zoneName).zoneAbbr();\n+\n+  return `${moment(timestamp).format(\n+    BREADCRUMB_TIME_DISPLAY_FORMAT\n+  )} ${timeZoneAbbreviation}`;\n+};\n+\n+/**\n+ * Parse the anomalies generated by the composite alert to populate parent-anomalies table with relevent details about\n+ * children for each anomaly.\n+ *\n+ * @param {Array<Object>} input\n+ *   The anomalies for composite alert.\n+ *\n+ * @returns {Array<Object>}\n+ *   Parsed out contents to populate parent-anomalies table\n+ */\n+const populateParentAnomaliesTable = input => {\n+  const output = [];\n+\n+  for (const entry of input) {\n+    const { id, startTime, endTime, feedback, children } = entry;\n+    const entryOutput = {\n+      id,\n+      startTime,\n+      endTime,\n+      feedback\n+    };\n+\n+    const details = {};\n+    let item;\n+    if (children.length > 0) {\n+      for (const child of children) {\n+        const { metric, properties: { subEntityName } = {} } = child;\n+\n+        if (!isEmpty(metric)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dcf352e0e03982aeec28fbaab61224c541e0d0e0"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjk3ODI3Mg==", "bodyText": "Will do.", "url": "https://github.com/apache/pinot/pull/6290#discussion_r532978272", "createdAt": "2020-11-30T23:47:51Z", "author": {"login": "tejasajmera"}, "path": "thirdeye/thirdeye-frontend/app/utils/anomalies-tree-parser.js", "diffHunk": "@@ -0,0 +1,563 @@\n+import { isEmpty } from \"@ember/utils\";\n+import { set } from \"@ember/object\";\n+import moment from \"moment\";\n+\n+const CLASSIFICATIONS = {\n+  METRICS: {\n+    KEY: \"metrics\",\n+    COMPONENT_PATH: \"entity-metrics\",\n+    DEFAULT_TITLE: \"Metric Anomalies\"\n+  },\n+  GROUPS: {\n+    KEY: \"groups\",\n+    COMPONENT_PATH: \"entity-groups\",\n+    DEFAULT_TITLE: \"ENTITY:\"\n+  },\n+  ENTITIES: {\n+    KEY: \"entities\",\n+    COMPONENT_PATH: \"parent-anomalies\",\n+    DEFAULT_TITLE: \"Entity\"\n+  }\n+};\n+const BREADCRUMB_TIME_DISPLAY_FORMAT = \"MMM D HH:mm\";\n+\n+/**\n+ * Format the timestamp into the form to be shown in the breadcrumb\n+ *\n+ * @param {Number} timestamp\n+ *   The timestamp of anomaly creation time in milliseconds\n+ *\n+ * @returns {String}\n+ *   Formatted timestamp. Example of the required format - \"Sep 15 16:49 EST\"\n+ */\n+const getFormattedBreadcrumbTime = timestamp => {\n+  const zoneName = moment.tz.guess();\n+  const timeZoneAbbreviation = moment.tz(zoneName).zoneAbbr();\n+\n+  return `${moment(timestamp).format(\n+    BREADCRUMB_TIME_DISPLAY_FORMAT\n+  )} ${timeZoneAbbreviation}`;\n+};\n+\n+/**\n+ * Parse the anomalies generated by the composite alert to populate parent-anomalies table with relevent details about\n+ * children for each anomaly.\n+ *\n+ * @param {Array<Object>} input\n+ *   The anomalies for composite alert.\n+ *\n+ * @returns {Array<Object>}\n+ *   Parsed out contents to populate parent-anomalies table\n+ */\n+const populateParentAnomaliesTable = input => {\n+  const output = [];\n+\n+  for (const entry of input) {\n+    const { id, startTime, endTime, feedback, children } = entry;\n+    const entryOutput = {\n+      id,\n+      startTime,\n+      endTime,\n+      feedback\n+    };\n+\n+    const details = {};\n+    let item;\n+    if (children.length > 0) {\n+      for (const child of children) {\n+        const { metric, properties: { subEntityName } = {} } = child;\n+\n+        if (!isEmpty(metric)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjc4MzU0Mw=="}, "originalCommit": {"oid": "dcf352e0e03982aeec28fbaab61224c541e0d0e0"}, "originalPosition": 70}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0MjUzMzY5OnYy", "diffSide": "RIGHT", "path": "thirdeye/thirdeye-frontend/app/utils/anomalies-tree-parser.js", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0zMFQxNzo0ODo0MFrOH8Gmrg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0zMFQyMzozOTo0N1rOH8SOIw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjc4NDgxNA==", "bodyText": "ditto, coding style", "url": "https://github.com/apache/pinot/pull/6290#discussion_r532784814", "createdAt": "2020-11-30T17:48:40Z", "author": {"login": "zhangloo333"}, "path": "thirdeye/thirdeye-frontend/app/utils/anomalies-tree-parser.js", "diffHunk": "@@ -0,0 +1,563 @@\n+import { isEmpty } from \"@ember/utils\";\n+import { set } from \"@ember/object\";\n+import moment from \"moment\";\n+\n+const CLASSIFICATIONS = {\n+  METRICS: {\n+    KEY: \"metrics\",\n+    COMPONENT_PATH: \"entity-metrics\",\n+    DEFAULT_TITLE: \"Metric Anomalies\"\n+  },\n+  GROUPS: {\n+    KEY: \"groups\",\n+    COMPONENT_PATH: \"entity-groups\",\n+    DEFAULT_TITLE: \"ENTITY:\"\n+  },\n+  ENTITIES: {\n+    KEY: \"entities\",\n+    COMPONENT_PATH: \"parent-anomalies\",\n+    DEFAULT_TITLE: \"Entity\"\n+  }\n+};\n+const BREADCRUMB_TIME_DISPLAY_FORMAT = \"MMM D HH:mm\";\n+\n+/**\n+ * Format the timestamp into the form to be shown in the breadcrumb\n+ *\n+ * @param {Number} timestamp\n+ *   The timestamp of anomaly creation time in milliseconds\n+ *\n+ * @returns {String}\n+ *   Formatted timestamp. Example of the required format - \"Sep 15 16:49 EST\"\n+ */\n+const getFormattedBreadcrumbTime = timestamp => {\n+  const zoneName = moment.tz.guess();\n+  const timeZoneAbbreviation = moment.tz(zoneName).zoneAbbr();\n+\n+  return `${moment(timestamp).format(\n+    BREADCRUMB_TIME_DISPLAY_FORMAT\n+  )} ${timeZoneAbbreviation}`;\n+};\n+\n+/**\n+ * Parse the anomalies generated by the composite alert to populate parent-anomalies table with relevent details about\n+ * children for each anomaly.\n+ *\n+ * @param {Array<Object>} input\n+ *   The anomalies for composite alert.\n+ *\n+ * @returns {Array<Object>}\n+ *   Parsed out contents to populate parent-anomalies table\n+ */\n+const populateParentAnomaliesTable = input => {\n+  const output = [];\n+\n+  for (const entry of input) {\n+    const { id, startTime, endTime, feedback, children } = entry;\n+    const entryOutput = {\n+      id,\n+      startTime,\n+      endTime,\n+      feedback\n+    };\n+\n+    const details = {};\n+    let item;\n+    if (children.length > 0) {\n+      for (const child of children) {\n+        const { metric, properties: { subEntityName } = {} } = child;\n+\n+        if (!isEmpty(metric)) {\n+          item = metric;\n+        } else {\n+          item = subEntityName;\n+        }\n+\n+        if (item in details) {\n+          details[item]++;\n+        } else {\n+          details[item] = 1;\n+        }\n+      }\n+      entryOutput.details = details;\n+      output.push(entryOutput);\n+    }\n+  }\n+\n+  return output;\n+};\n+\n+/**\n+ * Parse the generated bucket for metric anomalies into the schema for the entity-metrics component\n+ *\n+ * @param {Object} input\n+ *   The metric anomalies bucket constituents\n+ *\n+ * @returns {Array<Object>}\n+ *   The content to be passed into the the leaf level entity-metrics component. Each item in the array represents\n+ *   contents for the row in the table.\n+ */\n+const parseMetricsBucket = input => {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dcf352e0e03982aeec28fbaab61224c541e0d0e0"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjk3NTEzOQ==", "bodyText": "Sure.", "url": "https://github.com/apache/pinot/pull/6290#discussion_r532975139", "createdAt": "2020-11-30T23:39:47Z", "author": {"login": "tejasajmera"}, "path": "thirdeye/thirdeye-frontend/app/utils/anomalies-tree-parser.js", "diffHunk": "@@ -0,0 +1,563 @@\n+import { isEmpty } from \"@ember/utils\";\n+import { set } from \"@ember/object\";\n+import moment from \"moment\";\n+\n+const CLASSIFICATIONS = {\n+  METRICS: {\n+    KEY: \"metrics\",\n+    COMPONENT_PATH: \"entity-metrics\",\n+    DEFAULT_TITLE: \"Metric Anomalies\"\n+  },\n+  GROUPS: {\n+    KEY: \"groups\",\n+    COMPONENT_PATH: \"entity-groups\",\n+    DEFAULT_TITLE: \"ENTITY:\"\n+  },\n+  ENTITIES: {\n+    KEY: \"entities\",\n+    COMPONENT_PATH: \"parent-anomalies\",\n+    DEFAULT_TITLE: \"Entity\"\n+  }\n+};\n+const BREADCRUMB_TIME_DISPLAY_FORMAT = \"MMM D HH:mm\";\n+\n+/**\n+ * Format the timestamp into the form to be shown in the breadcrumb\n+ *\n+ * @param {Number} timestamp\n+ *   The timestamp of anomaly creation time in milliseconds\n+ *\n+ * @returns {String}\n+ *   Formatted timestamp. Example of the required format - \"Sep 15 16:49 EST\"\n+ */\n+const getFormattedBreadcrumbTime = timestamp => {\n+  const zoneName = moment.tz.guess();\n+  const timeZoneAbbreviation = moment.tz(zoneName).zoneAbbr();\n+\n+  return `${moment(timestamp).format(\n+    BREADCRUMB_TIME_DISPLAY_FORMAT\n+  )} ${timeZoneAbbreviation}`;\n+};\n+\n+/**\n+ * Parse the anomalies generated by the composite alert to populate parent-anomalies table with relevent details about\n+ * children for each anomaly.\n+ *\n+ * @param {Array<Object>} input\n+ *   The anomalies for composite alert.\n+ *\n+ * @returns {Array<Object>}\n+ *   Parsed out contents to populate parent-anomalies table\n+ */\n+const populateParentAnomaliesTable = input => {\n+  const output = [];\n+\n+  for (const entry of input) {\n+    const { id, startTime, endTime, feedback, children } = entry;\n+    const entryOutput = {\n+      id,\n+      startTime,\n+      endTime,\n+      feedback\n+    };\n+\n+    const details = {};\n+    let item;\n+    if (children.length > 0) {\n+      for (const child of children) {\n+        const { metric, properties: { subEntityName } = {} } = child;\n+\n+        if (!isEmpty(metric)) {\n+          item = metric;\n+        } else {\n+          item = subEntityName;\n+        }\n+\n+        if (item in details) {\n+          details[item]++;\n+        } else {\n+          details[item] = 1;\n+        }\n+      }\n+      entryOutput.details = details;\n+      output.push(entryOutput);\n+    }\n+  }\n+\n+  return output;\n+};\n+\n+/**\n+ * Parse the generated bucket for metric anomalies into the schema for the entity-metrics component\n+ *\n+ * @param {Object} input\n+ *   The metric anomalies bucket constituents\n+ *\n+ * @returns {Array<Object>}\n+ *   The content to be passed into the the leaf level entity-metrics component. Each item in the array represents\n+ *   contents for the row in the table.\n+ */\n+const parseMetricsBucket = input => {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjc4NDgxNA=="}, "originalCommit": {"oid": "dcf352e0e03982aeec28fbaab61224c541e0d0e0"}, "originalPosition": 100}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0MjU3MzQyOnYy", "diffSide": "RIGHT", "path": "thirdeye/thirdeye-frontend/app/utils/anomalies-tree-parser.js", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0zMFQxNzo1ODowMFrOH8G-fA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0zMFQyMzo0OTozMFrOH8Scuw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjc5MDkwOA==", "bodyText": "Please keep the code concise. If an if block always executes a return statement, the subsequent else block is unnecessary.\nPlease check the Airbnb rule. 16.3 or no-else-return", "url": "https://github.com/apache/pinot/pull/6290#discussion_r532790908", "createdAt": "2020-11-30T17:58:00Z", "author": {"login": "zhangloo333"}, "path": "thirdeye/thirdeye-frontend/app/utils/anomalies-tree-parser.js", "diffHunk": "@@ -0,0 +1,563 @@\n+import { isEmpty } from \"@ember/utils\";\n+import { set } from \"@ember/object\";\n+import moment from \"moment\";\n+\n+const CLASSIFICATIONS = {\n+  METRICS: {\n+    KEY: \"metrics\",\n+    COMPONENT_PATH: \"entity-metrics\",\n+    DEFAULT_TITLE: \"Metric Anomalies\"\n+  },\n+  GROUPS: {\n+    KEY: \"groups\",\n+    COMPONENT_PATH: \"entity-groups\",\n+    DEFAULT_TITLE: \"ENTITY:\"\n+  },\n+  ENTITIES: {\n+    KEY: \"entities\",\n+    COMPONENT_PATH: \"parent-anomalies\",\n+    DEFAULT_TITLE: \"Entity\"\n+  }\n+};\n+const BREADCRUMB_TIME_DISPLAY_FORMAT = \"MMM D HH:mm\";\n+\n+/**\n+ * Format the timestamp into the form to be shown in the breadcrumb\n+ *\n+ * @param {Number} timestamp\n+ *   The timestamp of anomaly creation time in milliseconds\n+ *\n+ * @returns {String}\n+ *   Formatted timestamp. Example of the required format - \"Sep 15 16:49 EST\"\n+ */\n+const getFormattedBreadcrumbTime = timestamp => {\n+  const zoneName = moment.tz.guess();\n+  const timeZoneAbbreviation = moment.tz(zoneName).zoneAbbr();\n+\n+  return `${moment(timestamp).format(\n+    BREADCRUMB_TIME_DISPLAY_FORMAT\n+  )} ${timeZoneAbbreviation}`;\n+};\n+\n+/**\n+ * Parse the anomalies generated by the composite alert to populate parent-anomalies table with relevent details about\n+ * children for each anomaly.\n+ *\n+ * @param {Array<Object>} input\n+ *   The anomalies for composite alert.\n+ *\n+ * @returns {Array<Object>}\n+ *   Parsed out contents to populate parent-anomalies table\n+ */\n+const populateParentAnomaliesTable = input => {\n+  const output = [];\n+\n+  for (const entry of input) {\n+    const { id, startTime, endTime, feedback, children } = entry;\n+    const entryOutput = {\n+      id,\n+      startTime,\n+      endTime,\n+      feedback\n+    };\n+\n+    const details = {};\n+    let item;\n+    if (children.length > 0) {\n+      for (const child of children) {\n+        const { metric, properties: { subEntityName } = {} } = child;\n+\n+        if (!isEmpty(metric)) {\n+          item = metric;\n+        } else {\n+          item = subEntityName;\n+        }\n+\n+        if (item in details) {\n+          details[item]++;\n+        } else {\n+          details[item] = 1;\n+        }\n+      }\n+      entryOutput.details = details;\n+      output.push(entryOutput);\n+    }\n+  }\n+\n+  return output;\n+};\n+\n+/**\n+ * Parse the generated bucket for metric anomalies into the schema for the entity-metrics component\n+ *\n+ * @param {Object} input\n+ *   The metric anomalies bucket constituents\n+ *\n+ * @returns {Array<Object>}\n+ *   The content to be passed into the the leaf level entity-metrics component. Each item in the array represents\n+ *   contents for the row in the table.\n+ */\n+const parseMetricsBucket = input => {\n+  return [input];\n+};\n+\n+/**\n+ * Parse the generated bucket for parent anomalies into the schema for the entity-groups component\n+ *\n+ * @param {Object} input\n+ *   The group anomalies bucket constituents\n+ *\n+ * @returns {Array<Object>}\n+ *   The content to be passed into the the entity-groups component. Each item in the array represents\n+ *   contents for the row in the table.\n+ */\n+const parseGroupsBucket = input => {\n+  const output = [];\n+\n+  for (const group in input) {\n+    output.push(input[group]);\n+  }\n+\n+  return output;\n+};\n+\n+/**\n+ * Parse the generated bucket for parent anomalies into the schema for the parent-anomalies component\n+ *\n+ * @param {Object} input\n+ *   The parent anomalies bucket constituents\n+ *\n+ * @returns {Array<Object>}\n+ *   The content to be passed into the parent-anomalies component. Each item in the array represents\n+ *   contents for the row in the table.\n+ */\n+const parseEntitiesBucket = input => {\n+  const output = [];\n+\n+  for (const entity in input) {\n+    const { componentPath, title, data } = input[entity];\n+\n+    output.push({\n+      componentPath,\n+      title,\n+      data: populateParentAnomaliesTable(data)\n+    });\n+  }\n+\n+  return output;\n+};\n+\n+/**\n+ * Add the anomaly referencing a metric to the metric bucket\n+ *\n+ * @param {Object} buckets\n+ *   The reference to buckets object within which the anomaly needs to be classified\n+ * @param {Object} anomaly\n+ *   The metric anomaly that needs be classified added to the metric bucket\n+ * @param {String} metric\n+ *   The metric for which this anomaly was generated\n+ */\n+const setMetricsBucket = (buckets, anomaly, metric) => {\n+  const {\n+    METRICS: { KEY: metricKey, DEFAULT_TITLE, COMPONENT_PATH }\n+  } = CLASSIFICATIONS;\n+  const { [metricKey]: { data } = {} } = buckets;\n+  const {\n+    id,\n+    startTime,\n+    endTime,\n+    feedback,\n+    avgCurrentVal: current,\n+    avgBaselineVal: predicted\n+  } = anomaly;\n+\n+  const metricTableRow = {\n+    id,\n+    startTime,\n+    endTime,\n+    metric,\n+    feedback,\n+    current,\n+    predicted\n+  };\n+\n+  if (isEmpty(data)) {\n+    const metricBucketObj = {\n+      componentPath: COMPONENT_PATH,\n+      title: DEFAULT_TITLE,\n+      data: [metricTableRow]\n+    };\n+\n+    set(buckets, `${metricKey}`, metricBucketObj);\n+  } else {\n+    data.push(metricTableRow);\n+  }\n+};\n+\n+/**\n+ * Add the anomaly referencing a group constitient to the right group characterized by the subEntityName\n+ *\n+ * @param {Object} buckets\n+ *   The reference to buckets object within which the anomaly needs to be classified\n+ * @param {Object} anomaly\n+ *   The anomaly produced due to the anomaly summarize grouper that needs be classified into the appropriate bucket\n+ * @param {String} subEntityName\n+ *   The entity name under which certain set of metrics would be grouped\n+ * @param {String} groupName\n+ *   The group constituent name. Each group constituent hosts anomalies from one metric.\n+ */\n+const setGroupsBucket = (buckets, anomaly, subEntityName, groupName) => {\n+  const {\n+    GROUPS: { KEY: groupKey, COMPONENT_PATH, DEFAULT_TITLE }\n+  } = CLASSIFICATIONS;\n+  const {\n+    id,\n+    startTime,\n+    endTime,\n+    feedback,\n+    avgCurrentVal: current,\n+    avgBaselineVal: predicted,\n+    properties: { groupScore: criticality }\n+  } = anomaly;\n+  const groupTableRow = {\n+    id,\n+    groupName,\n+    startTime,\n+    endTime,\n+    feedback,\n+    criticality,\n+    current,\n+    predicted\n+  };\n+\n+  if ([groupKey] in buckets) {\n+    if (subEntityName in buckets[groupKey]) {\n+      const {\n+        [subEntityName]: { data }\n+      } = buckets[groupKey];\n+\n+      data.push(groupTableRow);\n+    } else {\n+      set(buckets, `${groupKey}.${subEntityName}`, {\n+        componentPath: COMPONENT_PATH,\n+        title: `${DEFAULT_TITLE}${subEntityName}`,\n+        data: [groupTableRow]\n+      });\n+    }\n+  } else {\n+    set(buckets, `${groupKey}`, {\n+      [subEntityName]: {\n+        componentPath: COMPONENT_PATH,\n+        title: `${DEFAULT_TITLE}${subEntityName}`,\n+        data: [groupTableRow]\n+      }\n+    });\n+  }\n+};\n+\n+/**\n+ * Add the composite anomaly to the right bucket characterized by the subEntityName\n+ *\n+ * @param {Object} buckets\n+ *   The reference to buckets object within which the anomaly needs to be classified\n+ * @param {Object} anomaly\n+ *   The composite anomaly that needs be classified into the appropriate bucket\n+ * @param {String} subEntityName\n+ *   The entity name under which this anomaly falls\n+ */\n+const setEntitiesBucket = (buckets, anomaly, subEntityName) => {\n+  const {\n+    ENTITIES: { KEY: entityKey, COMPONENT_PATH }\n+  } = CLASSIFICATIONS;\n+  let title;\n+\n+  if (isEmpty(subEntityName)) {\n+    const {\n+      ENTITIES: { DEFAULT_TITLE }\n+    } = CLASSIFICATIONS;\n+\n+    title = DEFAULT_TITLE;\n+  } else {\n+    title = subEntityName;\n+  }\n+\n+  if ([entityKey] in buckets) {\n+    if (subEntityName in buckets[entityKey]) {\n+      const {\n+        [subEntityName]: { data }\n+      } = buckets[entityKey];\n+\n+      data.push(anomaly);\n+    } else {\n+      set(buckets, `${entityKey}.${subEntityName}`, {\n+        componentPath: COMPONENT_PATH,\n+        title: title,\n+        data: [anomaly]\n+      });\n+    }\n+  } else {\n+    set(buckets, `${entityKey}`, {\n+      [subEntityName]: {\n+        componentPath: COMPONENT_PATH,\n+        title: title,\n+        data: [anomaly]\n+      }\n+    });\n+  }\n+};\n+\n+/**\n+ * Classify the child anomalies of particular anomaly into metrics, groups and parent-anomalies\n+ *   -Anomalies of the yaml type METRIC_ALERT classify into \"metrics\"\n+ *   -Anomalies of the yaml type METRIC_ALERT and grouper as ANOMALY_SUMMARIZE classify into \"groups\"\n+ *   -Anomalies of the yaml type COMPOSITE_ALERT classify into \"parent-anomalies\"\n+ *\n+ * @param {Object} input\n+ *   The subtree structure that needs to be parsed\n+ *\n+ * @return {Object}\n+ *   The classification of children anomalies into the buckets of \"metrics\", \"groups\" and \"entities\".\n+ *   The structure will take the form as below\n+ *   {\n+ *     metrics: {\n+ *        componentPath: '',\n+ *        title: '',\n+ *        data:[{},{}] //anomaly entries\n+ *      },\n+ *     groups: {\n+ *         groupEntity1: {\n+ *            componentPath: '',\n+ *            title:'',\n+ *            data:[{},{}]  //each entry in array corresponds to information for 1 group constituent\n+ *         },\n+ *         groupEntity2: {\n+ *         }\n+ *      },\n+ *     entities: {\n+ *         entity1: {\n+ *           componentPath: '',\n+ *            title:'',\n+ *            data:[{},{}]\n+ *         },\n+ *         entity2: {\n+ *         }\n+ *     }\n+ *   }\n+ */\n+const generateBuckets = input => {\n+  const buckets = {};\n+  const { children } = input;\n+\n+  for (const child of children) {\n+    const {\n+      metric,\n+      properties: { detectorComponentName = \"\", subEntityName, groupKey } = {}\n+    } = child;\n+\n+    if (!isEmpty(metric)) {\n+      setMetricsBucket(buckets, child, metric);\n+    } else if (\n+      isEmpty(metric) &&\n+      detectorComponentName.includes(\"ANOMALY_SUMMARIZE\")\n+    ) {\n+      setGroupsBucket(buckets, child, subEntityName, groupKey);\n+    } else {\n+      setEntitiesBucket(buckets, child, subEntityName);\n+    }\n+  }\n+\n+  return buckets;\n+};\n+\n+/**\n+ * Perform drilldown of anomaly grouped by anomaly summarize grouper. This involves generating the breadcrumb information\n+ * and component details for the subtree for this anomaly.\n+ *\n+ * @param {Object} input\n+ *   The subtree structure that needs to be parsed\n+ *\n+ * @return {Object}\n+ *   The breadcrumb info and data for populating component comprising of group constituents\n+ */\n+const parseGroupAnomaly = input => {\n+  const output = [];\n+  const data = [];\n+  const {\n+    GROUPS: { DEFAULT_TITLE, COMPONENT_PATH }\n+  } = CLASSIFICATIONS;\n+  const {\n+    id,\n+    children,\n+    properties: { subEntityName, groupKey }\n+  } = input;\n+  const breadcrumbInfo = {\n+    title: `${subEntityName}/${groupKey}`,\n+    id\n+  };\n+\n+  for (const anomaly of children) {\n+    const {\n+      id,\n+      startTime,\n+      endTime,\n+      metric,\n+      dimensions,\n+      avgCurrentVal: current,\n+      avgBaselineVal: predicted,\n+      feedback\n+    } = anomaly;\n+\n+    data.push({\n+      id,\n+      startTime,\n+      endTime,\n+      feedback,\n+      metric,\n+      dimensions,\n+      current,\n+      predicted\n+    });\n+  }\n+\n+  output.push({\n+    componentPath: COMPONENT_PATH,\n+    title: DEFAULT_TITLE,\n+    data\n+  });\n+\n+  return { breadcrumbInfo, output };\n+};\n+\n+/**\n+ * Perform drilldown of composite anomaly. This involves generating the breadcrumb information\n+ * and component details for the subtree for the composite anomaly\n+ *\n+ * @param {Object} input\n+ *   The subtree structure that needs to be parsed\n+ *\n+ * @return {Object}\n+ *   The breadcrumb info and data for populating child components from input subtree.\n+ */\n+const parseCompositeAnomaly = input => {\n+  const output = [];\n+  const buckets = generateBuckets(input);\n+  const {\n+    METRICS: { KEY: metricKey },\n+    GROUPS: { KEY: groupKey }\n+  } = CLASSIFICATIONS;\n+  const { id, startTime } = input;\n+  const breadcrumbInfo = {\n+    id,\n+    title: getFormattedBreadcrumbTime(startTime)\n+  };\n+\n+  for (const key in buckets) {\n+    const entry = buckets[key];\n+\n+    if (key === metricKey) {\n+      output.push(...parseMetricsBucket(entry));\n+    } else if (key === groupKey) {\n+      output.push(...parseGroupsBucket(entry));\n+    } else {\n+      output.push(...parseEntitiesBucket(entry));\n+    }\n+  }\n+\n+  return { breadcrumbInfo, output };\n+};\n+\n+/**\n+ * Perform depth-first-search to retrieve anomaly in the tree\n+ *\n+ * @param {Number} id\n+ *   The id of the anomaly to be searched\n+ * @param {Object} input\n+ *   The subtree structure comprising the anomaly\n+ *\n+ * @return {Object}\n+ *   The anomaly referenced by id\n+ */\n+const findAnomaly = (id, input) => {\n+  const { id: anomalyId, children } = input;\n+\n+  if (anomalyId === id) {\n+    return input;\n+  } else {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dcf352e0e03982aeec28fbaab61224c541e0d0e0"}, "originalPosition": 485}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjk3ODg3NQ==", "bodyText": "Yeah more than aiming for conciseness I was just trying to keeping it explicit. Anyway will remove the else.", "url": "https://github.com/apache/pinot/pull/6290#discussion_r532978875", "createdAt": "2020-11-30T23:49:30Z", "author": {"login": "tejasajmera"}, "path": "thirdeye/thirdeye-frontend/app/utils/anomalies-tree-parser.js", "diffHunk": "@@ -0,0 +1,563 @@\n+import { isEmpty } from \"@ember/utils\";\n+import { set } from \"@ember/object\";\n+import moment from \"moment\";\n+\n+const CLASSIFICATIONS = {\n+  METRICS: {\n+    KEY: \"metrics\",\n+    COMPONENT_PATH: \"entity-metrics\",\n+    DEFAULT_TITLE: \"Metric Anomalies\"\n+  },\n+  GROUPS: {\n+    KEY: \"groups\",\n+    COMPONENT_PATH: \"entity-groups\",\n+    DEFAULT_TITLE: \"ENTITY:\"\n+  },\n+  ENTITIES: {\n+    KEY: \"entities\",\n+    COMPONENT_PATH: \"parent-anomalies\",\n+    DEFAULT_TITLE: \"Entity\"\n+  }\n+};\n+const BREADCRUMB_TIME_DISPLAY_FORMAT = \"MMM D HH:mm\";\n+\n+/**\n+ * Format the timestamp into the form to be shown in the breadcrumb\n+ *\n+ * @param {Number} timestamp\n+ *   The timestamp of anomaly creation time in milliseconds\n+ *\n+ * @returns {String}\n+ *   Formatted timestamp. Example of the required format - \"Sep 15 16:49 EST\"\n+ */\n+const getFormattedBreadcrumbTime = timestamp => {\n+  const zoneName = moment.tz.guess();\n+  const timeZoneAbbreviation = moment.tz(zoneName).zoneAbbr();\n+\n+  return `${moment(timestamp).format(\n+    BREADCRUMB_TIME_DISPLAY_FORMAT\n+  )} ${timeZoneAbbreviation}`;\n+};\n+\n+/**\n+ * Parse the anomalies generated by the composite alert to populate parent-anomalies table with relevent details about\n+ * children for each anomaly.\n+ *\n+ * @param {Array<Object>} input\n+ *   The anomalies for composite alert.\n+ *\n+ * @returns {Array<Object>}\n+ *   Parsed out contents to populate parent-anomalies table\n+ */\n+const populateParentAnomaliesTable = input => {\n+  const output = [];\n+\n+  for (const entry of input) {\n+    const { id, startTime, endTime, feedback, children } = entry;\n+    const entryOutput = {\n+      id,\n+      startTime,\n+      endTime,\n+      feedback\n+    };\n+\n+    const details = {};\n+    let item;\n+    if (children.length > 0) {\n+      for (const child of children) {\n+        const { metric, properties: { subEntityName } = {} } = child;\n+\n+        if (!isEmpty(metric)) {\n+          item = metric;\n+        } else {\n+          item = subEntityName;\n+        }\n+\n+        if (item in details) {\n+          details[item]++;\n+        } else {\n+          details[item] = 1;\n+        }\n+      }\n+      entryOutput.details = details;\n+      output.push(entryOutput);\n+    }\n+  }\n+\n+  return output;\n+};\n+\n+/**\n+ * Parse the generated bucket for metric anomalies into the schema for the entity-metrics component\n+ *\n+ * @param {Object} input\n+ *   The metric anomalies bucket constituents\n+ *\n+ * @returns {Array<Object>}\n+ *   The content to be passed into the the leaf level entity-metrics component. Each item in the array represents\n+ *   contents for the row in the table.\n+ */\n+const parseMetricsBucket = input => {\n+  return [input];\n+};\n+\n+/**\n+ * Parse the generated bucket for parent anomalies into the schema for the entity-groups component\n+ *\n+ * @param {Object} input\n+ *   The group anomalies bucket constituents\n+ *\n+ * @returns {Array<Object>}\n+ *   The content to be passed into the the entity-groups component. Each item in the array represents\n+ *   contents for the row in the table.\n+ */\n+const parseGroupsBucket = input => {\n+  const output = [];\n+\n+  for (const group in input) {\n+    output.push(input[group]);\n+  }\n+\n+  return output;\n+};\n+\n+/**\n+ * Parse the generated bucket for parent anomalies into the schema for the parent-anomalies component\n+ *\n+ * @param {Object} input\n+ *   The parent anomalies bucket constituents\n+ *\n+ * @returns {Array<Object>}\n+ *   The content to be passed into the parent-anomalies component. Each item in the array represents\n+ *   contents for the row in the table.\n+ */\n+const parseEntitiesBucket = input => {\n+  const output = [];\n+\n+  for (const entity in input) {\n+    const { componentPath, title, data } = input[entity];\n+\n+    output.push({\n+      componentPath,\n+      title,\n+      data: populateParentAnomaliesTable(data)\n+    });\n+  }\n+\n+  return output;\n+};\n+\n+/**\n+ * Add the anomaly referencing a metric to the metric bucket\n+ *\n+ * @param {Object} buckets\n+ *   The reference to buckets object within which the anomaly needs to be classified\n+ * @param {Object} anomaly\n+ *   The metric anomaly that needs be classified added to the metric bucket\n+ * @param {String} metric\n+ *   The metric for which this anomaly was generated\n+ */\n+const setMetricsBucket = (buckets, anomaly, metric) => {\n+  const {\n+    METRICS: { KEY: metricKey, DEFAULT_TITLE, COMPONENT_PATH }\n+  } = CLASSIFICATIONS;\n+  const { [metricKey]: { data } = {} } = buckets;\n+  const {\n+    id,\n+    startTime,\n+    endTime,\n+    feedback,\n+    avgCurrentVal: current,\n+    avgBaselineVal: predicted\n+  } = anomaly;\n+\n+  const metricTableRow = {\n+    id,\n+    startTime,\n+    endTime,\n+    metric,\n+    feedback,\n+    current,\n+    predicted\n+  };\n+\n+  if (isEmpty(data)) {\n+    const metricBucketObj = {\n+      componentPath: COMPONENT_PATH,\n+      title: DEFAULT_TITLE,\n+      data: [metricTableRow]\n+    };\n+\n+    set(buckets, `${metricKey}`, metricBucketObj);\n+  } else {\n+    data.push(metricTableRow);\n+  }\n+};\n+\n+/**\n+ * Add the anomaly referencing a group constitient to the right group characterized by the subEntityName\n+ *\n+ * @param {Object} buckets\n+ *   The reference to buckets object within which the anomaly needs to be classified\n+ * @param {Object} anomaly\n+ *   The anomaly produced due to the anomaly summarize grouper that needs be classified into the appropriate bucket\n+ * @param {String} subEntityName\n+ *   The entity name under which certain set of metrics would be grouped\n+ * @param {String} groupName\n+ *   The group constituent name. Each group constituent hosts anomalies from one metric.\n+ */\n+const setGroupsBucket = (buckets, anomaly, subEntityName, groupName) => {\n+  const {\n+    GROUPS: { KEY: groupKey, COMPONENT_PATH, DEFAULT_TITLE }\n+  } = CLASSIFICATIONS;\n+  const {\n+    id,\n+    startTime,\n+    endTime,\n+    feedback,\n+    avgCurrentVal: current,\n+    avgBaselineVal: predicted,\n+    properties: { groupScore: criticality }\n+  } = anomaly;\n+  const groupTableRow = {\n+    id,\n+    groupName,\n+    startTime,\n+    endTime,\n+    feedback,\n+    criticality,\n+    current,\n+    predicted\n+  };\n+\n+  if ([groupKey] in buckets) {\n+    if (subEntityName in buckets[groupKey]) {\n+      const {\n+        [subEntityName]: { data }\n+      } = buckets[groupKey];\n+\n+      data.push(groupTableRow);\n+    } else {\n+      set(buckets, `${groupKey}.${subEntityName}`, {\n+        componentPath: COMPONENT_PATH,\n+        title: `${DEFAULT_TITLE}${subEntityName}`,\n+        data: [groupTableRow]\n+      });\n+    }\n+  } else {\n+    set(buckets, `${groupKey}`, {\n+      [subEntityName]: {\n+        componentPath: COMPONENT_PATH,\n+        title: `${DEFAULT_TITLE}${subEntityName}`,\n+        data: [groupTableRow]\n+      }\n+    });\n+  }\n+};\n+\n+/**\n+ * Add the composite anomaly to the right bucket characterized by the subEntityName\n+ *\n+ * @param {Object} buckets\n+ *   The reference to buckets object within which the anomaly needs to be classified\n+ * @param {Object} anomaly\n+ *   The composite anomaly that needs be classified into the appropriate bucket\n+ * @param {String} subEntityName\n+ *   The entity name under which this anomaly falls\n+ */\n+const setEntitiesBucket = (buckets, anomaly, subEntityName) => {\n+  const {\n+    ENTITIES: { KEY: entityKey, COMPONENT_PATH }\n+  } = CLASSIFICATIONS;\n+  let title;\n+\n+  if (isEmpty(subEntityName)) {\n+    const {\n+      ENTITIES: { DEFAULT_TITLE }\n+    } = CLASSIFICATIONS;\n+\n+    title = DEFAULT_TITLE;\n+  } else {\n+    title = subEntityName;\n+  }\n+\n+  if ([entityKey] in buckets) {\n+    if (subEntityName in buckets[entityKey]) {\n+      const {\n+        [subEntityName]: { data }\n+      } = buckets[entityKey];\n+\n+      data.push(anomaly);\n+    } else {\n+      set(buckets, `${entityKey}.${subEntityName}`, {\n+        componentPath: COMPONENT_PATH,\n+        title: title,\n+        data: [anomaly]\n+      });\n+    }\n+  } else {\n+    set(buckets, `${entityKey}`, {\n+      [subEntityName]: {\n+        componentPath: COMPONENT_PATH,\n+        title: title,\n+        data: [anomaly]\n+      }\n+    });\n+  }\n+};\n+\n+/**\n+ * Classify the child anomalies of particular anomaly into metrics, groups and parent-anomalies\n+ *   -Anomalies of the yaml type METRIC_ALERT classify into \"metrics\"\n+ *   -Anomalies of the yaml type METRIC_ALERT and grouper as ANOMALY_SUMMARIZE classify into \"groups\"\n+ *   -Anomalies of the yaml type COMPOSITE_ALERT classify into \"parent-anomalies\"\n+ *\n+ * @param {Object} input\n+ *   The subtree structure that needs to be parsed\n+ *\n+ * @return {Object}\n+ *   The classification of children anomalies into the buckets of \"metrics\", \"groups\" and \"entities\".\n+ *   The structure will take the form as below\n+ *   {\n+ *     metrics: {\n+ *        componentPath: '',\n+ *        title: '',\n+ *        data:[{},{}] //anomaly entries\n+ *      },\n+ *     groups: {\n+ *         groupEntity1: {\n+ *            componentPath: '',\n+ *            title:'',\n+ *            data:[{},{}]  //each entry in array corresponds to information for 1 group constituent\n+ *         },\n+ *         groupEntity2: {\n+ *         }\n+ *      },\n+ *     entities: {\n+ *         entity1: {\n+ *           componentPath: '',\n+ *            title:'',\n+ *            data:[{},{}]\n+ *         },\n+ *         entity2: {\n+ *         }\n+ *     }\n+ *   }\n+ */\n+const generateBuckets = input => {\n+  const buckets = {};\n+  const { children } = input;\n+\n+  for (const child of children) {\n+    const {\n+      metric,\n+      properties: { detectorComponentName = \"\", subEntityName, groupKey } = {}\n+    } = child;\n+\n+    if (!isEmpty(metric)) {\n+      setMetricsBucket(buckets, child, metric);\n+    } else if (\n+      isEmpty(metric) &&\n+      detectorComponentName.includes(\"ANOMALY_SUMMARIZE\")\n+    ) {\n+      setGroupsBucket(buckets, child, subEntityName, groupKey);\n+    } else {\n+      setEntitiesBucket(buckets, child, subEntityName);\n+    }\n+  }\n+\n+  return buckets;\n+};\n+\n+/**\n+ * Perform drilldown of anomaly grouped by anomaly summarize grouper. This involves generating the breadcrumb information\n+ * and component details for the subtree for this anomaly.\n+ *\n+ * @param {Object} input\n+ *   The subtree structure that needs to be parsed\n+ *\n+ * @return {Object}\n+ *   The breadcrumb info and data for populating component comprising of group constituents\n+ */\n+const parseGroupAnomaly = input => {\n+  const output = [];\n+  const data = [];\n+  const {\n+    GROUPS: { DEFAULT_TITLE, COMPONENT_PATH }\n+  } = CLASSIFICATIONS;\n+  const {\n+    id,\n+    children,\n+    properties: { subEntityName, groupKey }\n+  } = input;\n+  const breadcrumbInfo = {\n+    title: `${subEntityName}/${groupKey}`,\n+    id\n+  };\n+\n+  for (const anomaly of children) {\n+    const {\n+      id,\n+      startTime,\n+      endTime,\n+      metric,\n+      dimensions,\n+      avgCurrentVal: current,\n+      avgBaselineVal: predicted,\n+      feedback\n+    } = anomaly;\n+\n+    data.push({\n+      id,\n+      startTime,\n+      endTime,\n+      feedback,\n+      metric,\n+      dimensions,\n+      current,\n+      predicted\n+    });\n+  }\n+\n+  output.push({\n+    componentPath: COMPONENT_PATH,\n+    title: DEFAULT_TITLE,\n+    data\n+  });\n+\n+  return { breadcrumbInfo, output };\n+};\n+\n+/**\n+ * Perform drilldown of composite anomaly. This involves generating the breadcrumb information\n+ * and component details for the subtree for the composite anomaly\n+ *\n+ * @param {Object} input\n+ *   The subtree structure that needs to be parsed\n+ *\n+ * @return {Object}\n+ *   The breadcrumb info and data for populating child components from input subtree.\n+ */\n+const parseCompositeAnomaly = input => {\n+  const output = [];\n+  const buckets = generateBuckets(input);\n+  const {\n+    METRICS: { KEY: metricKey },\n+    GROUPS: { KEY: groupKey }\n+  } = CLASSIFICATIONS;\n+  const { id, startTime } = input;\n+  const breadcrumbInfo = {\n+    id,\n+    title: getFormattedBreadcrumbTime(startTime)\n+  };\n+\n+  for (const key in buckets) {\n+    const entry = buckets[key];\n+\n+    if (key === metricKey) {\n+      output.push(...parseMetricsBucket(entry));\n+    } else if (key === groupKey) {\n+      output.push(...parseGroupsBucket(entry));\n+    } else {\n+      output.push(...parseEntitiesBucket(entry));\n+    }\n+  }\n+\n+  return { breadcrumbInfo, output };\n+};\n+\n+/**\n+ * Perform depth-first-search to retrieve anomaly in the tree\n+ *\n+ * @param {Number} id\n+ *   The id of the anomaly to be searched\n+ * @param {Object} input\n+ *   The subtree structure comprising the anomaly\n+ *\n+ * @return {Object}\n+ *   The anomaly referenced by id\n+ */\n+const findAnomaly = (id, input) => {\n+  const { id: anomalyId, children } = input;\n+\n+  if (anomalyId === id) {\n+    return input;\n+  } else {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjc5MDkwOA=="}, "originalCommit": {"oid": "dcf352e0e03982aeec28fbaab61224c541e0d0e0"}, "originalPosition": 485}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3164, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}