{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDM3MzQ1MTUx", "number": 5597, "title": "Filtering during ingestion", "bodyText": "Description\nAdded support for filtering during ingestion\nDesign doc: https://docs.google.com/document/d/1Cahnas3nh0XErETH0KHLaecN6xCnRVYWNKO3rDn7qcI/edit?usp=sharing\nIssue: #5268\nTLDR\n\nNew config added:\n\ntableConfig: {\n    tableName: ...,\n    tableType: ...,\n    ingestionConfig: {\n        filterConfig: {\n            filterFunction: \u201c<expression>\u201d\n        }\n    }\n}\n\nFor example, Consider a table with a string column campaign and a multi-value column double column prices. To filter out records where campaign = X or Y and sum of all elements in prices is less than 100\ningestionConfig: {\n    filterConfig: {\n        filterFunction: \u201cGroovy({(campaign == \\\"X\\\" || campaign == \\\"Y\\\") && prices.sum() < 100}, prices, campaign)\u201d\n    }\n}\n\nThe expressions allowed here will be within the scope of the transform functions support that we have in Pinot today i.e. Groovy expressions, or any inbuilt functions.\n\nFiltering has been modeled as a RecordTransformer called FilterTransformer.\nIn order to filter the record, we will use a special key $FILTER_RECORD_KEY$ Inside the FilterTransformer, if filterFunction evaluates to true, this key will be put into the GenericRow, with value true.\n\nFollowup items\n\nMove transform functions from schema to IngestionConfig\nIntegration test to test all ingestion configs\n\nRelease Notes\n\nAdded support for filtering during ingestion\nRemoved SchemaUtils#extractSourceFields(Schema schema) method. Use IngestionUtils#getFieldsForRecordExtractor(IngestionConfig ingestionConfig, Schema schema) instead\n\nDocumentation\nTBD", "createdAt": "2020-06-20T01:13:39Z", "url": "https://github.com/apache/pinot/pull/5597", "merged": true, "mergeCommit": {"oid": "60ebe7180fd108c9353e34ae44b8cf3768c76b6b"}, "closed": true, "closedAt": "2020-06-23T23:37:04Z", "author": {"login": "npawar"}, "timelineItems": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcs9BRggH2gAyNDM3MzQ1MTUxOmZhMmEwOGNiNjgyNDI4YTlhNGVjNWNiMTQwZDY2N2NlNjdiMmJmZTk=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcuNY_wAFqTQzNjIwOTMxOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "fa2a08cb682428a9a4ec5cb140d667ce67b2bfe9", "author": {"user": {"login": "npawar", "name": "Neha Pawar"}}, "url": "https://github.com/apache/pinot/commit/fa2a08cb682428a9a4ec5cb140d667ce67b2bfe9", "committedDate": "2020-06-20T01:04:21Z", "message": "Filtering during ingestion"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM0NDQ1OTkw", "url": "https://github.com/apache/pinot/pull/5597#pullrequestreview-434445990", "createdAt": "2020-06-20T18:32:59Z", "commit": {"oid": "fa2a08cb682428a9a4ec5cb140d667ce67b2bfe9"}, "state": "COMMENTED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMFQxODozMzowMFrOGmnxYA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMFQxOToxNjo1M1rOGmn8kg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzE1MDY4OA==", "bodyText": "High level comment, recording it here so that I dont forget. Intuitively, rows ingested should be indicated by the schema, not by whether the row is filtered or not.  So, I am not sure what this change implies.", "url": "https://github.com/apache/pinot/pull/5597#discussion_r443150688", "createdAt": "2020-06-20T18:33:00Z", "author": {"login": "mcvsubbu"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/data/manager/realtime/HLRealtimeSegmentDataManager.java", "diffHunk": "@@ -169,9 +169,9 @@ public HLRealtimeSegmentDataManager(final RealtimeSegmentZKMetadata realtimeSegm\n     // create and init stream level consumer\n     StreamConsumerFactory streamConsumerFactory = StreamConsumerFactoryProvider.create(_streamConfig);\n     String clientId = HLRealtimeSegmentDataManager.class.getSimpleName() + \"-\" + _streamConfig.getTopicName();\n-    _streamLevelConsumer = streamConsumerFactory\n-        .createStreamLevelConsumer(clientId, _tableNameWithType, SchemaUtils.extractSourceFields(schema),\n-            instanceMetadata.getGroupId(_tableNameWithType));\n+    _streamLevelConsumer = streamConsumerFactory.createStreamLevelConsumer(clientId, _tableNameWithType,\n+        IngestionUtils.getFieldsForRecordExtractor(tableConfig, schema),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fa2a08cb682428a9a4ec5cb140d667ce67b2bfe9"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzE1MTI0OQ==", "bodyText": "On this note, can you add some comments on GenericRow as to how MULTIPLE_RECORDS_KEY is used for (in GenericRow class) and also document it in the decoders description in the documentation? It seems to be used only in test files now, and there is no doc on what it means. Thanks.\nIt looks like the MULTIPLE stuff is a decoder feature. So, when you add a FIXME like this, does this mean that the decoders using multiple recorsd key will break? Or, will they simply not be able to use filters? When is this planned to be fixed? Is this just an interim state from which we should take care not to cut a release? Is this work in progress?", "url": "https://github.com/apache/pinot/pull/5597#discussion_r443151249", "createdAt": "2020-06-20T18:41:35Z", "author": {"login": "mcvsubbu"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/data/manager/realtime/HLRealtimeSegmentDataManager.java", "diffHunk": "@@ -245,7 +245,8 @@ public void run() {\n             if (consumedRow != null) {\n               try {\n                 GenericRow transformedRow = _recordTransformer.transform(consumedRow);\n-                if (transformedRow != null) {\n+                // FIXME: MULTIPLE_RECORDS_KEY is not handled here", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fa2a08cb682428a9a4ec5cb140d667ce67b2bfe9"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzE1MTUwNw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                          if (transformedRow != null && IngestionUtils.passedFilter(transformedRow)) {\n          \n          \n            \n                          if (transformedRow != null && IngestionUtils.isRowPruned(transformedRow)) {\n          \n      \n    \n    \n  \n\nOr, IngestionUtils.shouldIngestRow()?\nJust a suggestion, you decide", "url": "https://github.com/apache/pinot/pull/5597#discussion_r443151507", "createdAt": "2020-06-20T18:45:00Z", "author": {"login": "mcvsubbu"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/data/manager/realtime/LLRealtimeSegmentDataManager.java", "diffHunk": "@@ -471,7 +471,7 @@ private void processStreamEvents(MessageBatch messagesAndOffsets, long idlePipeS\n           if (decodedRow.getValue(GenericRow.MULTIPLE_RECORDS_KEY) != null) {\n             for (Object singleRow : (Collection) decodedRow.getValue(GenericRow.MULTIPLE_RECORDS_KEY)) {\n               GenericRow transformedRow = _recordTransformer.transform((GenericRow) singleRow);\n-              if (transformedRow != null) {\n+              if (transformedRow != null && IngestionUtils.passedFilter(transformedRow)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fa2a08cb682428a9a4ec5cb140d667ce67b2bfe9"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzE1MTYxNA==", "bodyText": "Same comment as before", "url": "https://github.com/apache/pinot/pull/5597#discussion_r443151614", "createdAt": "2020-06-20T18:46:36Z", "author": {"login": "mcvsubbu"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/data/manager/realtime/LLRealtimeSegmentDataManager.java", "diffHunk": "@@ -1185,12 +1185,12 @@ public LLRealtimeSegmentDataManager(RealtimeSegmentZKMetadata segmentZKMetadata,\n             .setConsumerDir(consumerDir);\n \n     // Create message decoder\n-    _messageDecoder =\n-        StreamDecoderProvider.create(_partitionLevelStreamConfig, SchemaUtils.extractSourceFields(_schema));\n+    _messageDecoder = StreamDecoderProvider\n+        .create(_partitionLevelStreamConfig, IngestionUtils.getFieldsForRecordExtractor(_tableConfig, _schema));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fa2a08cb682428a9a4ec5cb140d667ce67b2bfe9"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzE1MjYyOQ==", "bodyText": "I think I have the answer for my question. I think this is because we may have filter expressions on columns that are not present in the schema.\nIf this explanation is right, can you please document it some place? (Perhaps in IngestionUtils class?) Also, it may be worthwhile to make two separate calls, and let the caller decide whether to union the fields or otherwise use them independently. Not sure if there is a use case, but think about it. It certainly makes the code more readable. getFieldsToExtractFromStream(), and getFieldsToFilterOn().\nLastly, is it enough to pass in the IngestionConfig (or, maybe even just the FilterConfig) rather than entire TableConfig? This will keep the discipline of adding any ingestion related item to IngestionConfig than looking some place else in the TableConfig", "url": "https://github.com/apache/pinot/pull/5597#discussion_r443152629", "createdAt": "2020-06-20T19:02:24Z", "author": {"login": "mcvsubbu"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/data/manager/realtime/HLRealtimeSegmentDataManager.java", "diffHunk": "@@ -169,9 +169,9 @@ public HLRealtimeSegmentDataManager(final RealtimeSegmentZKMetadata realtimeSegm\n     // create and init stream level consumer\n     StreamConsumerFactory streamConsumerFactory = StreamConsumerFactoryProvider.create(_streamConfig);\n     String clientId = HLRealtimeSegmentDataManager.class.getSimpleName() + \"-\" + _streamConfig.getTopicName();\n-    _streamLevelConsumer = streamConsumerFactory\n-        .createStreamLevelConsumer(clientId, _tableNameWithType, SchemaUtils.extractSourceFields(schema),\n-            instanceMetadata.getGroupId(_tableNameWithType));\n+    _streamLevelConsumer = streamConsumerFactory.createStreamLevelConsumer(clientId, _tableNameWithType,\n+        IngestionUtils.getFieldsForRecordExtractor(tableConfig, schema),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzE1MDY4OA=="}, "originalCommit": {"oid": "fa2a08cb682428a9a4ec5cb140d667ce67b2bfe9"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzE1MjY5MA==", "bodyText": "Consider making two methods below public, for readability.\ngetFieldsToFilterOn()\ngetFieldsToExtract()\nOr, keep one in the schema and the other here, but that may lead callers to ignore this one.", "url": "https://github.com/apache/pinot/pull/5597#discussion_r443152690", "createdAt": "2020-06-20T19:03:24Z", "author": {"login": "mcvsubbu"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/util/IngestionUtils.java", "diffHunk": "@@ -0,0 +1,91 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.util;\n+\n+import com.google.common.collect.Sets;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.Set;\n+import javax.annotation.Nullable;\n+import org.apache.pinot.core.data.function.FunctionEvaluator;\n+import org.apache.pinot.core.data.function.FunctionEvaluatorFactory;\n+import org.apache.pinot.spi.config.table.IngestionConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.spi.data.readers.GenericRow;\n+\n+\n+/**\n+ * Utility methods for extracting source and destination fields from ingestion configs\n+ */\n+public class IngestionUtils {\n+\n+  /**\n+   * Extracts all fields required by the {@link org.apache.pinot.spi.data.readers.RecordExtractor} from the given TableConfig and Schema\n+   */\n+  public static Set<String> getFieldsForRecordExtractor(TableConfig tableConfig, Schema schema) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fa2a08cb682428a9a4ec5cb140d667ce67b2bfe9"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzE1MjczNQ==", "bodyText": "Spark/Hadoop jobs that depend on this method may break. Consider deprecating it in stead of removing it. Or, atleast add a backward incompat", "url": "https://github.com/apache/pinot/pull/5597#discussion_r443152735", "createdAt": "2020-06-20T19:04:10Z", "author": {"login": "mcvsubbu"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/util/SchemaUtils.java", "diffHunk": "@@ -41,28 +39,6 @@\n \n   private static final Logger LOGGER = LoggerFactory.getLogger(SchemaUtils.class);\n \n-  /**\n-   * Extracts the source fields and destination fields from the schema\n-   * For field specs with a transform expression defined, use the arguments provided to the function\n-   * By default, add the field spec name\n-   *\n-   * TODO: for now, we assume that arguments to transform function are in the source i.e. there's no columns which are derived from transformed columns\n-   */\n-  public static Set<String> extractSourceFields(Schema schema) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fa2a08cb682428a9a4ec5cb140d667ce67b2bfe9"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzE1MzU1NA==", "bodyText": "Shouldn't this be a list of filter functions applied in sequence specified? How do we indicate filter like:\n\nSample x% of the records\nfilter out those with age > 40\n\nOr,\n\nFilter out those with age > 40\nSample x% of these records.", "url": "https://github.com/apache/pinot/pull/5597#discussion_r443153554", "createdAt": "2020-06-20T19:16:53Z", "author": {"login": "mcvsubbu"}, "path": "pinot-spi/src/main/java/org/apache/pinot/spi/config/table/ingestion/FilterConfig.java", "diffHunk": "@@ -0,0 +1,45 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.config.table.ingestion;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.annotation.JsonPropertyDescription;\n+import javax.annotation.Nullable;\n+import org.apache.pinot.spi.config.BaseJsonConfig;\n+\n+\n+/**\n+ * Configs related to filtering records during ingestion\n+ */\n+public class FilterConfig extends BaseJsonConfig {\n+\n+  @JsonPropertyDescription(\"Filter function string. Filter out records during ingestion, if this evaluates to true\")\n+  private final String _filterFunction;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fa2a08cb682428a9a4ec5cb140d667ce67b2bfe9"}, "originalPosition": 34}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4270fc669e0134d0bd1610304849e86cbf779dfc", "author": {"user": {"login": "npawar", "name": "Neha Pawar"}}, "url": "https://github.com/apache/pinot/commit/4270fc669e0134d0bd1610304849e86cbf779dfc", "committedDate": "2020-06-22T16:57:14Z", "message": "Review comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM1MjgwNzQ1", "url": "https://github.com/apache/pinot/pull/5597#pullrequestreview-435280745", "createdAt": "2020-06-22T21:17:44Z", "commit": {"oid": "4270fc669e0134d0bd1610304849e86cbf779dfc"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQyMToxNzo0NFrOGnRV6g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yMlQyMToyMToyNVrOGnRchA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzgzMTc4Ng==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              @JsonPropertyDescription(value = \"Config related to table ingestion\")\n          \n          \n            \n              @JsonPropertyDescription(value = \"Config related to ingesting data into the table\")\n          \n      \n    \n    \n  \n\nShould we consider moving append frequency into this?", "url": "https://github.com/apache/pinot/pull/5597#discussion_r443831786", "createdAt": "2020-06-22T21:17:44Z", "author": {"login": "mcvsubbu"}, "path": "pinot-spi/src/main/java/org/apache/pinot/spi/config/table/TableConfig.java", "diffHunk": "@@ -79,6 +80,9 @@\n   @JsonPropertyDescription(value = \"upsert related config\")\n   private UpsertConfig _upsertConfig;\n \n+  @JsonPropertyDescription(value = \"Config related to table ingestion\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4270fc669e0134d0bd1610304849e86cbf779dfc"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzgzMzQ3Ng==", "bodyText": "I would suggest renaming these as \"$PINOT_INTERNAL_MULTIPLE_RECORDS_KEY$\" and \"$PINOT_INTERNAL_SHOULD_INGEST_ROW$\". Of course, this will mean that the decoders that put in the existing MULTIPLE_RECORDS_KEY should be handled right (if we released this in 0.4.0 without documentation). I don't see any documentation for it in our docs. Let me know if I am not looking at the right place.", "url": "https://github.com/apache/pinot/pull/5597#discussion_r443833476", "createdAt": "2020-06-22T21:21:25Z", "author": {"login": "mcvsubbu"}, "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/readers/GenericRow.java", "diffHunk": "@@ -49,7 +49,17 @@\n  */\n public class GenericRow {\n \n+  /**\n+   * This key is used by a Decoder/RecordReader to handle 1 record to many records flattening.\n+   * If a Decoder/RecordReader produces multiple GenericRows from the given record, they must be put into the destination GenericRow as a List<GenericRow> with this key\n+   * The segment generation drivers handle this key as a special case and process the multiple records\n+   */\n   public static final String MULTIPLE_RECORDS_KEY = \"$MULTIPLE_RECORDS_KEY$\";\n+  /**\n+   * This key is used by the FilterTransformer to handle filtering out of records during ingestion\n+   * The FilterTransformer puts this key into the GenericRow with value true, if the record matches the filtering out criteria, based on FilterConfig\n+   */\n+  public static final String FILTER_RECORD_KEY = \"$FILTER_RECORD_KEY$\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4270fc669e0134d0bd1610304849e86cbf779dfc"}, "originalPosition": 14}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM2MDcyNjc5", "url": "https://github.com/apache/pinot/pull/5597#pullrequestreview-436072679", "createdAt": "2020-06-23T19:04:00Z", "commit": {"oid": "4270fc669e0134d0bd1610304849e86cbf779dfc"}, "state": "APPROVED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QxOTowNDowMFrOGn2s0g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QxOToxODozOVrOGn3L6w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ0Mzg1OA==", "bodyText": "(nit) Make it final", "url": "https://github.com/apache/pinot/pull/5597#discussion_r444443858", "createdAt": "2020-06-23T19:04:00Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/data/recordtransformer/FilterTransformer.java", "diffHunk": "@@ -0,0 +1,54 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.data.recordtransformer;\n+\n+import org.apache.pinot.core.data.function.FunctionEvaluator;\n+import org.apache.pinot.core.data.function.FunctionEvaluatorFactory;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.readers.GenericRow;\n+\n+\n+/**\n+ * Based on filter config, decide whether to skip or allow this record.\n+ * If record should be skipped, puts a special key in the record.\n+ */\n+public class FilterTransformer implements RecordTransformer {\n+\n+  private FunctionEvaluator _evaluator = null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4270fc669e0134d0bd1610304849e86cbf779dfc"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ0NTczNw==", "bodyText": "(nit) Can we put table config in front of schema for consistency?", "url": "https://github.com/apache/pinot/pull/5597#discussion_r444445737", "createdAt": "2020-06-23T19:07:10Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/segment/creator/StatsCollectorConfig.java", "diffHunk": "@@ -35,16 +36,19 @@\n public class StatsCollectorConfig {\n \n   private final Schema _schema;\n+  private final TableConfig _tableConfig;\n   private final SegmentPartitionConfig _segmentPartitionConfig;\n \n   /**\n    * Constructor for the class.\n    * @param schema Data schema\n    * @param segmentPartitionConfig Segment partitioning config\n    */\n-  public StatsCollectorConfig(@Nonnull Schema schema, SegmentPartitionConfig segmentPartitionConfig) {\n+  public StatsCollectorConfig(Schema schema, TableConfig tableConfig, @Nullable SegmentPartitionConfig segmentPartitionConfig) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4270fc669e0134d0bd1610304849e86cbf779dfc"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ0NjU3Nw==", "bodyText": "(nit) annotate ingestionConfig as nullable", "url": "https://github.com/apache/pinot/pull/5597#discussion_r444446577", "createdAt": "2020-06-23T19:08:42Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/util/IngestionUtils.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.util;\n+\n+import com.google.common.collect.Sets;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.Set;\n+import javax.annotation.Nullable;\n+import org.apache.pinot.core.data.function.FunctionEvaluator;\n+import org.apache.pinot.core.data.function.FunctionEvaluatorFactory;\n+import org.apache.pinot.spi.config.table.IngestionConfig;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.spi.data.readers.GenericRow;\n+\n+\n+/**\n+ * Utility methods for extracting source and destination fields from ingestion configs\n+ */\n+public class IngestionUtils {\n+\n+  /**\n+   * Extracts all fields required by the {@link org.apache.pinot.spi.data.readers.RecordExtractor} from the given TableConfig and Schema\n+   * Fields for ingestion come from 2 places:\n+   * 1. The schema\n+   * 2. The ingestion config in the table config. The ingestion config (e.g. filter) can have fields which are not in the schema.\n+   */\n+  public static Set<String> getFieldsForRecordExtractor(IngestionConfig ingestionConfig, Schema schema) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4270fc669e0134d0bd1610304849e86cbf779dfc"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ0NzgwOQ==", "bodyText": "Recommend passing the set into the helper method to prevent creating multiple sets.", "url": "https://github.com/apache/pinot/pull/5597#discussion_r444447809", "createdAt": "2020-06-23T19:11:01Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/util/IngestionUtils.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.util;\n+\n+import com.google.common.collect.Sets;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.Set;\n+import javax.annotation.Nullable;\n+import org.apache.pinot.core.data.function.FunctionEvaluator;\n+import org.apache.pinot.core.data.function.FunctionEvaluatorFactory;\n+import org.apache.pinot.spi.config.table.IngestionConfig;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.spi.data.readers.GenericRow;\n+\n+\n+/**\n+ * Utility methods for extracting source and destination fields from ingestion configs\n+ */\n+public class IngestionUtils {\n+\n+  /**\n+   * Extracts all fields required by the {@link org.apache.pinot.spi.data.readers.RecordExtractor} from the given TableConfig and Schema\n+   * Fields for ingestion come from 2 places:\n+   * 1. The schema\n+   * 2. The ingestion config in the table config. The ingestion config (e.g. filter) can have fields which are not in the schema.\n+   */\n+  public static Set<String> getFieldsForRecordExtractor(IngestionConfig ingestionConfig, Schema schema) {\n+    Set<String> fieldsForRecordExtractor = new HashSet<>();\n+    fieldsForRecordExtractor.addAll(getFieldsFromIngestionConfig(ingestionConfig));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4270fc669e0134d0bd1610304849e86cbf779dfc"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ0OTE5MA==", "bodyText": "Please rename this class to *Test or the framework cannot auto-detect this as a test", "url": "https://github.com/apache/pinot/pull/5597#discussion_r444449190", "createdAt": "2020-06-23T19:13:32Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/test/java/org/apache/pinot/core/segment/index/creator/SegmentGenerationWithFilterRecordsKey.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.segment.index.creator;\n+\n+import com.google.common.collect.Lists;\n+import java.io.File;\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.commons.io.FileUtils;\n+import org.apache.pinot.core.data.readers.GenericRowRecordReader;\n+import org.apache.pinot.core.data.readers.PinotSegmentRecordReader;\n+import org.apache.pinot.core.indexsegment.generator.SegmentGeneratorConfig;\n+import org.apache.pinot.core.segment.creator.impl.SegmentIndexCreationDriverImpl;\n+import org.apache.pinot.core.segment.index.metadata.SegmentMetadataImpl;\n+import org.apache.pinot.core.segment.store.SegmentDirectory;\n+import org.apache.pinot.spi.config.table.IngestionConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.TableType;\n+import org.apache.pinot.spi.config.table.ingestion.FilterConfig;\n+import org.apache.pinot.spi.data.FieldSpec;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.spi.data.readers.GenericRow;\n+import org.apache.pinot.spi.utils.builder.TableConfigBuilder;\n+import org.testng.Assert;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.BeforeMethod;\n+import org.testng.annotations.Test;\n+\n+\n+public class SegmentGenerationWithFilterRecordsKey {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4270fc669e0134d0bd1610304849e86cbf779dfc"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDQ1MTgxOQ==", "bodyText": "Rename it to SKIP_RECORD_KEY for clarity?\n@mcvsubbu The $ already denotes the field to be internal. I wouldn't recommend making the key too long because it will add cost for the hash lookup.", "url": "https://github.com/apache/pinot/pull/5597#discussion_r444451819", "createdAt": "2020-06-23T19:18:39Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-spi/src/main/java/org/apache/pinot/spi/data/readers/GenericRow.java", "diffHunk": "@@ -49,7 +49,17 @@\n  */\n public class GenericRow {\n \n+  /**\n+   * This key is used by a Decoder/RecordReader to handle 1 record to many records flattening.\n+   * If a Decoder/RecordReader produces multiple GenericRows from the given record, they must be put into the destination GenericRow as a List<GenericRow> with this key\n+   * The segment generation drivers handle this key as a special case and process the multiple records\n+   */\n   public static final String MULTIPLE_RECORDS_KEY = \"$MULTIPLE_RECORDS_KEY$\";\n+  /**\n+   * This key is used by the FilterTransformer to handle filtering out of records during ingestion\n+   * The FilterTransformer puts this key into the GenericRow with value true, if the record matches the filtering out criteria, based on FilterConfig\n+   */\n+  public static final String FILTER_RECORD_KEY = \"$FILTER_RECORD_KEY$\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4270fc669e0134d0bd1610304849e86cbf779dfc"}, "originalPosition": 14}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c869999cc11885e977af15a3b30991c3a0e2d518", "author": {"user": {"login": "npawar", "name": "Neha Pawar"}}, "url": "https://github.com/apache/pinot/commit/c869999cc11885e977af15a3b30991c3a0e2d518", "committedDate": "2020-06-23T22:22:43Z", "message": "Review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1e35d28c8d792b8515b4aa0dba444d7a5a736763", "author": {"user": {"login": "npawar", "name": "Neha Pawar"}}, "url": "https://github.com/apache/pinot/commit/1e35d28c8d792b8515b4aa0dba444d7a5a736763", "committedDate": "2020-06-23T22:28:10Z", "message": "Change StatsCollectorConfig constructor params order"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM2MjA5MzE5", "url": "https://github.com/apache/pinot/pull/5597#pullrequestreview-436209319", "createdAt": "2020-06-23T22:42:27Z", "commit": {"oid": "1e35d28c8d792b8515b4aa0dba444d7a5a736763"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QyMjo0MjoyN1rOGn9DRQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QyMjo0MjoyN1rOGn9DRQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU0NzkwOQ==", "bodyText": "we can add it later, just wanted to know what the interface would look like if we added a function. So, in this case, the samplePercent(n) should return a boolean?", "url": "https://github.com/apache/pinot/pull/5597#discussion_r444547909", "createdAt": "2020-06-23T22:42:27Z", "author": {"login": "mcvsubbu"}, "path": "pinot-spi/src/main/java/org/apache/pinot/spi/config/table/ingestion/FilterConfig.java", "diffHunk": "@@ -0,0 +1,45 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.spi.config.table.ingestion;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.annotation.JsonPropertyDescription;\n+import javax.annotation.Nullable;\n+import org.apache.pinot.spi.config.BaseJsonConfig;\n+\n+\n+/**\n+ * Configs related to filtering records during ingestion\n+ */\n+public class FilterConfig extends BaseJsonConfig {\n+\n+  @JsonPropertyDescription(\"Filter function string. Filter out records during ingestion, if this evaluates to true\")\n+  private final String _filterFunction;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MzE1MzU1NA=="}, "originalCommit": {"oid": "fa2a08cb682428a9a4ec5cb140d667ce67b2bfe9"}, "originalPosition": 34}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 659, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}