{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTM5OTUxODkz", "number": 6354, "title": "Ingestion resource with APIs for ingestion via file/URI", "bodyText": "Description\nAdding APIs for uploading data to an offline table. These are meant for quick testing/trials, and not intended for production usage. We will be using these in the Cluster Manager to introduce a \"Test a file\" flow.\nFile ingest\ncurl \"http://localhost:9000/ingestFromFile?tableNameWithType=transcript_OFFLINE&batchConfigMapStr={\"inputFormat\":\"json\"}\"  \\\n-F file=@part1.json\n\n\nURI ingest\nNote:\n\nThe fs details only need to be provided if scheme is not already registered.\nCredentials will by default be taken from local aws credentials\n\ncurl \"http://localhost:9000/ingestFromURI?tableNameWithType=transcript_OFFLINE&\nbatchConfigMapStr={\"inputFormat\":\"json\",\"input.fs.className\":\"org.apache.pinot.plugin.filesystem.S3PinotFS\",\"input.fs.prop.region\":\"us-central\",\"input.fs.prop.accessKey\":\"foo\",\"input.fs.prop.secretKey\":\"bar\"}\n&sourceURIStr=s3://test.bucket/jsondata/part1.json\" \n  -X POST\n\n\nRelease Notes\nIntroduced 2 new APIs /ingestFromFile and /ingestFromURI", "createdAt": "2020-12-15T03:39:52Z", "url": "https://github.com/apache/pinot/pull/6354", "merged": true, "mergeCommit": {"oid": "10dad7d6c8c9697ff5606422afda1257fc5e3fe2"}, "closed": true, "closedAt": "2020-12-22T00:52:27Z", "author": {"login": "npawar"}, "timelineItems": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdmRn-AAH2gAyNTM5OTUxODkzOmUwMTYxNzY1YTc2MjEwNTU2Mjk0ZmQ5MzQzMGM2MGZjZGJlMmNiYjE=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdoe5WcAH2gAyNTM5OTUxODkzOjU2ZDVlMTI4OTc0YTc2N2VhNjEwOTkxZTEzOTkyMmY3YWI4ZDY5MzA=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "e0161765a76210556294fd93430c60fcdbe2cbb1", "author": {"user": {"login": "npawar", "name": "Neha Pawar"}}, "url": "https://github.com/apache/pinot/commit/e0161765a76210556294fd93430c60fcdbe2cbb1", "committedDate": "2020-12-15T03:18:24Z", "message": "Ingestion resource with APIs for ingestion via file/URI"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ec99e833c9c0b4de988c7a3b287442322ba26370", "author": {"user": {"login": "npawar", "name": "Neha Pawar"}}, "url": "https://github.com/apache/pinot/commit/ec99e833c9c0b4de988c7a3b287442322ba26370", "committedDate": "2020-12-15T03:39:28Z", "message": "remove extra spaces"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3f446dc039c65db41efd9f07f93692dc1d1b0e93", "author": {"user": {"login": "npawar", "name": "Neha Pawar"}}, "url": "https://github.com/apache/pinot/commit/3f446dc039c65db41efd9f07f93692dc1d1b0e93", "committedDate": "2020-12-16T03:19:31Z", "message": "Test with csv reader configs"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1MTYwMjQx", "url": "https://github.com/apache/pinot/pull/6354#pullrequestreview-555160241", "createdAt": "2020-12-18T04:08:18Z", "commit": {"oid": "3f446dc039c65db41efd9f07f93692dc1d1b0e93"}, "state": "APPROVED", "comments": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwNDowODoxOVrOIISY0w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQwNDozODoxMlrOIIS1pg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU2MDc4Nw==", "bodyText": "Add sample calls here. will be great if it can show up as part of swagger", "url": "https://github.com/apache/pinot/pull/6354#discussion_r545560787", "createdAt": "2020-12-18T04:08:19Z", "author": {"login": "kishoreg"}, "path": "pinot-controller/src/main/java/org/apache/pinot/controller/api/resources/PinotIngestionRestletResource.java", "diffHunk": "@@ -0,0 +1,145 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.api.resources;\n+\n+import com.fasterxml.jackson.core.type.TypeReference;\n+import com.google.common.base.Preconditions;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import io.swagger.annotations.ApiParam;\n+import java.net.URI;\n+import java.util.Map;\n+import javax.inject.Inject;\n+import javax.ws.rs.Consumes;\n+import javax.ws.rs.POST;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.QueryParam;\n+import javax.ws.rs.container.AsyncResponse;\n+import javax.ws.rs.container.Suspended;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import org.apache.pinot.controller.ControllerConf;\n+import org.apache.pinot.controller.helix.core.PinotHelixResourceManager;\n+import org.apache.pinot.controller.util.FileIngestionHelper;\n+import org.apache.pinot.controller.util.FileIngestionHelper.DataPayload;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.TableType;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.spi.ingestion.batch.BatchConfig;\n+import org.apache.pinot.spi.utils.JsonUtils;\n+import org.apache.pinot.spi.utils.builder.TableNameBuilder;\n+import org.glassfish.jersey.media.multipart.FormDataMultiPart;\n+import org.glassfish.jersey.server.ManagedAsync;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * APIs related to ingestion", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f446dc039c65db41efd9f07f93692dc1d1b0e93"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU2MTAwNA==", "bodyText": "missing async response doc", "url": "https://github.com/apache/pinot/pull/6354#discussion_r545561004", "createdAt": "2020-12-18T04:09:09Z", "author": {"login": "kishoreg"}, "path": "pinot-controller/src/main/java/org/apache/pinot/controller/api/resources/PinotIngestionRestletResource.java", "diffHunk": "@@ -0,0 +1,145 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.api.resources;\n+\n+import com.fasterxml.jackson.core.type.TypeReference;\n+import com.google.common.base.Preconditions;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import io.swagger.annotations.ApiParam;\n+import java.net.URI;\n+import java.util.Map;\n+import javax.inject.Inject;\n+import javax.ws.rs.Consumes;\n+import javax.ws.rs.POST;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.QueryParam;\n+import javax.ws.rs.container.AsyncResponse;\n+import javax.ws.rs.container.Suspended;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import org.apache.pinot.controller.ControllerConf;\n+import org.apache.pinot.controller.helix.core.PinotHelixResourceManager;\n+import org.apache.pinot.controller.util.FileIngestionHelper;\n+import org.apache.pinot.controller.util.FileIngestionHelper.DataPayload;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.TableType;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.spi.ingestion.batch.BatchConfig;\n+import org.apache.pinot.spi.utils.JsonUtils;\n+import org.apache.pinot.spi.utils.builder.TableNameBuilder;\n+import org.glassfish.jersey.media.multipart.FormDataMultiPart;\n+import org.glassfish.jersey.server.ManagedAsync;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * APIs related to ingestion\n+ */\n+@Api(tags = Constants.TABLE_TAG)\n+@Path(\"/\")\n+public class PinotIngestionRestletResource {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(PinotIngestionRestletResource.class);\n+\n+  @Inject\n+  PinotHelixResourceManager _pinotHelixResourceManager;\n+\n+  @Inject\n+  ControllerConf _controllerConf;\n+\n+  /**\n+   * API to upload a file and ingest it into a Pinot table\n+   * @param tableName Name of the table to upload to\n+   * @param batchConfigMapStr Batch config Map as a string. Provide the\n+   *                          input format (inputFormat)\n+   *                          record reader configs (recordReader.prop.<property>),\n+   *                          fs class name (input.fs.className)\n+   *                          fs configs (input.fs.prop.<property>)\n+   * @param fileUpload file to upload as a multipart", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f446dc039c65db41efd9f07f93692dc1d1b0e93"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU2MjAwNg==", "bodyText": "add some documentation on what the caller should expect. Will this call return something immediately or wait until the operation is done", "url": "https://github.com/apache/pinot/pull/6354#discussion_r545562006", "createdAt": "2020-12-18T04:13:25Z", "author": {"login": "kishoreg"}, "path": "pinot-controller/src/main/java/org/apache/pinot/controller/api/resources/PinotIngestionRestletResource.java", "diffHunk": "@@ -0,0 +1,145 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.api.resources;\n+\n+import com.fasterxml.jackson.core.type.TypeReference;\n+import com.google.common.base.Preconditions;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import io.swagger.annotations.ApiParam;\n+import java.net.URI;\n+import java.util.Map;\n+import javax.inject.Inject;\n+import javax.ws.rs.Consumes;\n+import javax.ws.rs.POST;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.QueryParam;\n+import javax.ws.rs.container.AsyncResponse;\n+import javax.ws.rs.container.Suspended;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import org.apache.pinot.controller.ControllerConf;\n+import org.apache.pinot.controller.helix.core.PinotHelixResourceManager;\n+import org.apache.pinot.controller.util.FileIngestionHelper;\n+import org.apache.pinot.controller.util.FileIngestionHelper.DataPayload;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.TableType;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.spi.ingestion.batch.BatchConfig;\n+import org.apache.pinot.spi.utils.JsonUtils;\n+import org.apache.pinot.spi.utils.builder.TableNameBuilder;\n+import org.glassfish.jersey.media.multipart.FormDataMultiPart;\n+import org.glassfish.jersey.server.ManagedAsync;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * APIs related to ingestion\n+ */\n+@Api(tags = Constants.TABLE_TAG)\n+@Path(\"/\")\n+public class PinotIngestionRestletResource {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(PinotIngestionRestletResource.class);\n+\n+  @Inject\n+  PinotHelixResourceManager _pinotHelixResourceManager;\n+\n+  @Inject\n+  ControllerConf _controllerConf;\n+\n+  /**\n+   * API to upload a file and ingest it into a Pinot table", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f446dc039c65db41efd9f07f93692dc1d1b0e93"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU2MjIwNA==", "bodyText": "this should be tableNameWithType right", "url": "https://github.com/apache/pinot/pull/6354#discussion_r545562204", "createdAt": "2020-12-18T04:14:12Z", "author": {"login": "kishoreg"}, "path": "pinot-controller/src/main/java/org/apache/pinot/controller/api/resources/PinotIngestionRestletResource.java", "diffHunk": "@@ -0,0 +1,145 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.api.resources;\n+\n+import com.fasterxml.jackson.core.type.TypeReference;\n+import com.google.common.base.Preconditions;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import io.swagger.annotations.ApiParam;\n+import java.net.URI;\n+import java.util.Map;\n+import javax.inject.Inject;\n+import javax.ws.rs.Consumes;\n+import javax.ws.rs.POST;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.QueryParam;\n+import javax.ws.rs.container.AsyncResponse;\n+import javax.ws.rs.container.Suspended;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import org.apache.pinot.controller.ControllerConf;\n+import org.apache.pinot.controller.helix.core.PinotHelixResourceManager;\n+import org.apache.pinot.controller.util.FileIngestionHelper;\n+import org.apache.pinot.controller.util.FileIngestionHelper.DataPayload;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.TableType;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.spi.ingestion.batch.BatchConfig;\n+import org.apache.pinot.spi.utils.JsonUtils;\n+import org.apache.pinot.spi.utils.builder.TableNameBuilder;\n+import org.glassfish.jersey.media.multipart.FormDataMultiPart;\n+import org.glassfish.jersey.server.ManagedAsync;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * APIs related to ingestion\n+ */\n+@Api(tags = Constants.TABLE_TAG)\n+@Path(\"/\")\n+public class PinotIngestionRestletResource {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(PinotIngestionRestletResource.class);\n+\n+  @Inject\n+  PinotHelixResourceManager _pinotHelixResourceManager;\n+\n+  @Inject\n+  ControllerConf _controllerConf;\n+\n+  /**\n+   * API to upload a file and ingest it into a Pinot table\n+   * @param tableName Name of the table to upload to", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f446dc039c65db41efd9f07f93692dc1d1b0e93"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU2MjI3OA==", "bodyText": "tableName ->tableNameWithType", "url": "https://github.com/apache/pinot/pull/6354#discussion_r545562278", "createdAt": "2020-12-18T04:14:36Z", "author": {"login": "kishoreg"}, "path": "pinot-controller/src/main/java/org/apache/pinot/controller/api/resources/PinotIngestionRestletResource.java", "diffHunk": "@@ -0,0 +1,145 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.api.resources;\n+\n+import com.fasterxml.jackson.core.type.TypeReference;\n+import com.google.common.base.Preconditions;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import io.swagger.annotations.ApiParam;\n+import java.net.URI;\n+import java.util.Map;\n+import javax.inject.Inject;\n+import javax.ws.rs.Consumes;\n+import javax.ws.rs.POST;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.QueryParam;\n+import javax.ws.rs.container.AsyncResponse;\n+import javax.ws.rs.container.Suspended;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import org.apache.pinot.controller.ControllerConf;\n+import org.apache.pinot.controller.helix.core.PinotHelixResourceManager;\n+import org.apache.pinot.controller.util.FileIngestionHelper;\n+import org.apache.pinot.controller.util.FileIngestionHelper.DataPayload;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.TableType;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.spi.ingestion.batch.BatchConfig;\n+import org.apache.pinot.spi.utils.JsonUtils;\n+import org.apache.pinot.spi.utils.builder.TableNameBuilder;\n+import org.glassfish.jersey.media.multipart.FormDataMultiPart;\n+import org.glassfish.jersey.server.ManagedAsync;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * APIs related to ingestion\n+ */\n+@Api(tags = Constants.TABLE_TAG)\n+@Path(\"/\")\n+public class PinotIngestionRestletResource {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(PinotIngestionRestletResource.class);\n+\n+  @Inject\n+  PinotHelixResourceManager _pinotHelixResourceManager;\n+\n+  @Inject\n+  ControllerConf _controllerConf;\n+\n+  /**\n+   * API to upload a file and ingest it into a Pinot table\n+   * @param tableName Name of the table to upload to\n+   * @param batchConfigMapStr Batch config Map as a string. Provide the\n+   *                          input format (inputFormat)\n+   *                          record reader configs (recordReader.prop.<property>),\n+   *                          fs class name (input.fs.className)\n+   *                          fs configs (input.fs.prop.<property>)\n+   * @param fileUpload file to upload as a multipart\n+   */\n+  @POST\n+  @ManagedAsync\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @Consumes(MediaType.MULTIPART_FORM_DATA)\n+  @Path(\"/ingestFromFile\")\n+  @ApiOperation(value = \"Ingest a file\", notes = \"Creates a segment using given file and pushes it to Pinot\")\n+  public void ingestFromFile(\n+      @ApiParam(value = \"Name of the table to upload the file to\", required = true) @QueryParam(\"tableName\") String tableName,\n+      @ApiParam(value = \"Batch config map as string\", required = true) @QueryParam(\"batchConfigMapStr\") String batchConfigMapStr,\n+      FormDataMultiPart fileUpload,\n+      @Suspended final AsyncResponse asyncResponse) {\n+    try {\n+      asyncResponse.resume(ingestData(tableName, batchConfigMapStr, new DataPayload(fileUpload)));\n+    } catch (Exception e) {\n+      asyncResponse.resume(new ControllerApplicationException(LOGGER,\n+          String.format(\"Caught exception when ingesting file into table: %s. %s\", tableName, e.getMessage()),\n+          Response.Status.INTERNAL_SERVER_ERROR, e));\n+    }\n+  }\n+\n+  /**\n+   * API to ingest a file into Pinot from a URI\n+   * @param tableName Name of the table to upload to\n+   * @param batchConfigMapStr Batch config Map as a string. Provide the\n+   *                          input format (inputFormat)\n+   *                          record reader configs (recordReader.prop.<property>),\n+   *                          fs class name (input.fs.className)\n+   *                          fs configs (input.fs.prop.<property>)\n+   * @param sourceURIStr URI for input file to ingest\n+   */\n+  @POST\n+  @ManagedAsync\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @Consumes(MediaType.MULTIPART_FORM_DATA)\n+  @Path(\"/ingestFromURI\")\n+  @ApiOperation(value = \"Ingest from the given URI\", notes = \"Creates a segment using file at the given URI and pushes it to Pinot\")\n+  public void ingestFromURI(\n+      @ApiParam(value = \"Name of the table to upload the file to\", required = true) @QueryParam(\"tableName\") String tableName,\n+      @ApiParam(value = \"Batch config map as string\", required = true) @QueryParam(\"batchConfigMapStr\") String batchConfigMapStr,\n+      @ApiParam(value = \"URI\", required = true) @QueryParam(\"sourceURIStr\") String sourceURIStr,\n+      @Suspended final AsyncResponse asyncResponse) {\n+    try {\n+      asyncResponse.resume(ingestData(tableName, batchConfigMapStr, new DataPayload(new URI(sourceURIStr))));\n+    } catch (Exception e) {\n+      asyncResponse.resume(new ControllerApplicationException(LOGGER,\n+          String.format(\"Caught exception when ingesting file into table: %s. %s\", tableName, e.getMessage()),\n+          Response.Status.INTERNAL_SERVER_ERROR, e));\n+    }\n+  }\n+\n+  private SuccessResponse ingestData(String tableName, String batchConfigMapStr, DataPayload payload)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f446dc039c65db41efd9f07f93692dc1d1b0e93"}, "originalPosition": 129}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU2MjUzMg==", "bodyText": "I thought the input is already tableName with Type?", "url": "https://github.com/apache/pinot/pull/6354#discussion_r545562532", "createdAt": "2020-12-18T04:15:37Z", "author": {"login": "kishoreg"}, "path": "pinot-controller/src/main/java/org/apache/pinot/controller/api/resources/PinotIngestionRestletResource.java", "diffHunk": "@@ -0,0 +1,145 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.api.resources;\n+\n+import com.fasterxml.jackson.core.type.TypeReference;\n+import com.google.common.base.Preconditions;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import io.swagger.annotations.ApiParam;\n+import java.net.URI;\n+import java.util.Map;\n+import javax.inject.Inject;\n+import javax.ws.rs.Consumes;\n+import javax.ws.rs.POST;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.QueryParam;\n+import javax.ws.rs.container.AsyncResponse;\n+import javax.ws.rs.container.Suspended;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import org.apache.pinot.controller.ControllerConf;\n+import org.apache.pinot.controller.helix.core.PinotHelixResourceManager;\n+import org.apache.pinot.controller.util.FileIngestionHelper;\n+import org.apache.pinot.controller.util.FileIngestionHelper.DataPayload;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.TableType;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.spi.ingestion.batch.BatchConfig;\n+import org.apache.pinot.spi.utils.JsonUtils;\n+import org.apache.pinot.spi.utils.builder.TableNameBuilder;\n+import org.glassfish.jersey.media.multipart.FormDataMultiPart;\n+import org.glassfish.jersey.server.ManagedAsync;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * APIs related to ingestion\n+ */\n+@Api(tags = Constants.TABLE_TAG)\n+@Path(\"/\")\n+public class PinotIngestionRestletResource {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(PinotIngestionRestletResource.class);\n+\n+  @Inject\n+  PinotHelixResourceManager _pinotHelixResourceManager;\n+\n+  @Inject\n+  ControllerConf _controllerConf;\n+\n+  /**\n+   * API to upload a file and ingest it into a Pinot table\n+   * @param tableName Name of the table to upload to\n+   * @param batchConfigMapStr Batch config Map as a string. Provide the\n+   *                          input format (inputFormat)\n+   *                          record reader configs (recordReader.prop.<property>),\n+   *                          fs class name (input.fs.className)\n+   *                          fs configs (input.fs.prop.<property>)\n+   * @param fileUpload file to upload as a multipart\n+   */\n+  @POST\n+  @ManagedAsync\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @Consumes(MediaType.MULTIPART_FORM_DATA)\n+  @Path(\"/ingestFromFile\")\n+  @ApiOperation(value = \"Ingest a file\", notes = \"Creates a segment using given file and pushes it to Pinot\")\n+  public void ingestFromFile(\n+      @ApiParam(value = \"Name of the table to upload the file to\", required = true) @QueryParam(\"tableName\") String tableName,\n+      @ApiParam(value = \"Batch config map as string\", required = true) @QueryParam(\"batchConfigMapStr\") String batchConfigMapStr,\n+      FormDataMultiPart fileUpload,\n+      @Suspended final AsyncResponse asyncResponse) {\n+    try {\n+      asyncResponse.resume(ingestData(tableName, batchConfigMapStr, new DataPayload(fileUpload)));\n+    } catch (Exception e) {\n+      asyncResponse.resume(new ControllerApplicationException(LOGGER,\n+          String.format(\"Caught exception when ingesting file into table: %s. %s\", tableName, e.getMessage()),\n+          Response.Status.INTERNAL_SERVER_ERROR, e));\n+    }\n+  }\n+\n+  /**\n+   * API to ingest a file into Pinot from a URI\n+   * @param tableName Name of the table to upload to\n+   * @param batchConfigMapStr Batch config Map as a string. Provide the\n+   *                          input format (inputFormat)\n+   *                          record reader configs (recordReader.prop.<property>),\n+   *                          fs class name (input.fs.className)\n+   *                          fs configs (input.fs.prop.<property>)\n+   * @param sourceURIStr URI for input file to ingest\n+   */\n+  @POST\n+  @ManagedAsync\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @Consumes(MediaType.MULTIPART_FORM_DATA)\n+  @Path(\"/ingestFromURI\")\n+  @ApiOperation(value = \"Ingest from the given URI\", notes = \"Creates a segment using file at the given URI and pushes it to Pinot\")\n+  public void ingestFromURI(\n+      @ApiParam(value = \"Name of the table to upload the file to\", required = true) @QueryParam(\"tableName\") String tableName,\n+      @ApiParam(value = \"Batch config map as string\", required = true) @QueryParam(\"batchConfigMapStr\") String batchConfigMapStr,\n+      @ApiParam(value = \"URI\", required = true) @QueryParam(\"sourceURIStr\") String sourceURIStr,\n+      @Suspended final AsyncResponse asyncResponse) {\n+    try {\n+      asyncResponse.resume(ingestData(tableName, batchConfigMapStr, new DataPayload(new URI(sourceURIStr))));\n+    } catch (Exception e) {\n+      asyncResponse.resume(new ControllerApplicationException(LOGGER,\n+          String.format(\"Caught exception when ingesting file into table: %s. %s\", tableName, e.getMessage()),\n+          Response.Status.INTERNAL_SERVER_ERROR, e));\n+    }\n+  }\n+\n+  private SuccessResponse ingestData(String tableName, String batchConfigMapStr, DataPayload payload)\n+      throws Exception {\n+    TableType tableType = TableNameBuilder.getTableTypeFromTableName(tableName);\n+    Preconditions\n+        .checkState(TableType.REALTIME != tableType, \"Cannot ingest file into REALTIME table: %s\", tableName);\n+    String tableNameWithType = TableNameBuilder.forType(TableType.OFFLINE).tableNameWithType(tableName);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f446dc039c65db41efd9f07f93692dc1d1b0e93"}, "originalPosition": 134}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU2MzEzMQ==", "bodyText": "this is a good class, can we take only the info needed from ControllerConf. This can be used in other places", "url": "https://github.com/apache/pinot/pull/6354#discussion_r545563131", "createdAt": "2020-12-18T04:17:47Z", "author": {"login": "kishoreg"}, "path": "pinot-controller/src/main/java/org/apache/pinot/controller/util/FileIngestionHelper.java", "diffHunk": "@@ -0,0 +1,140 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.util;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import java.io.File;\n+import java.net.URI;\n+import org.apache.commons.io.FileUtils;\n+import org.apache.pinot.common.utils.TarGzCompressionUtils;\n+import org.apache.pinot.controller.ControllerConf;\n+import org.apache.pinot.controller.api.resources.SuccessResponse;\n+import org.apache.pinot.core.indexsegment.generator.SegmentGeneratorConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.spi.ingestion.batch.BatchConfig;\n+import org.glassfish.jersey.media.multipart.FormDataMultiPart;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * A driver for the ingestion process of the provided file.\n+ * Responsible for copying the file locally, building a segment and uploading it to the controller.\n+ */\n+public class FileIngestionHelper {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(FileIngestionHelper.class);\n+\n+  private static final String WORKING_DIR_PREFIX = \"working_dir\";\n+  private static final String INPUT_DATA_DIR = \"input_data_dir\";\n+  private static final String OUTPUT_SEGMENT_DIR = \"output_segment_dir\";\n+  private static final String SEGMENT_TAR_DIR = \"segment_tar_dir\";\n+  private static final String DATA_FILE_PREFIX = \"data\";\n+\n+  private final TableConfig _tableConfig;\n+  private final Schema _schema;\n+  private final BatchConfig _batchConfig;\n+  private final ControllerConf _controllerConf;\n+\n+  public FileIngestionHelper(TableConfig tableConfig, Schema schema,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f446dc039c65db41efd9f07f93692dc1d1b0e93"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU2MzM2Ng==", "bodyText": "better to log this somewhere for debugging purpose", "url": "https://github.com/apache/pinot/pull/6354#discussion_r545563366", "createdAt": "2020-12-18T04:18:45Z", "author": {"login": "kishoreg"}, "path": "pinot-controller/src/main/java/org/apache/pinot/controller/util/FileIngestionHelper.java", "diffHunk": "@@ -0,0 +1,140 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.util;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import java.io.File;\n+import java.net.URI;\n+import org.apache.commons.io.FileUtils;\n+import org.apache.pinot.common.utils.TarGzCompressionUtils;\n+import org.apache.pinot.controller.ControllerConf;\n+import org.apache.pinot.controller.api.resources.SuccessResponse;\n+import org.apache.pinot.core.indexsegment.generator.SegmentGeneratorConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.spi.ingestion.batch.BatchConfig;\n+import org.glassfish.jersey.media.multipart.FormDataMultiPart;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * A driver for the ingestion process of the provided file.\n+ * Responsible for copying the file locally, building a segment and uploading it to the controller.\n+ */\n+public class FileIngestionHelper {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(FileIngestionHelper.class);\n+\n+  private static final String WORKING_DIR_PREFIX = \"working_dir\";\n+  private static final String INPUT_DATA_DIR = \"input_data_dir\";\n+  private static final String OUTPUT_SEGMENT_DIR = \"output_segment_dir\";\n+  private static final String SEGMENT_TAR_DIR = \"segment_tar_dir\";\n+  private static final String DATA_FILE_PREFIX = \"data\";\n+\n+  private final TableConfig _tableConfig;\n+  private final Schema _schema;\n+  private final BatchConfig _batchConfig;\n+  private final ControllerConf _controllerConf;\n+\n+  public FileIngestionHelper(TableConfig tableConfig, Schema schema,\n+      BatchConfig batchConfig, ControllerConf controllerConf) {\n+    _tableConfig = tableConfig;\n+    _schema = schema;\n+    _batchConfig = batchConfig;\n+    _controllerConf = controllerConf;\n+  }\n+\n+  /**\n+   * Creates a segment using the provided data file/URI and uploads to Pinot\n+   */\n+  public SuccessResponse buildSegmentAndPush(DataPayload payload)\n+      throws Exception {\n+    String tableNameWithType = _tableConfig.getTableName();\n+\n+    // Setup working dir\n+    File workingDir = new File(FileUtils.getTempDirectory(),\n+        String.format(\"%s_%s_%d\", WORKING_DIR_PREFIX, tableNameWithType, System.currentTimeMillis()));\n+    File inputDir = new File(workingDir, INPUT_DATA_DIR);\n+    File outputDir = new File(workingDir, OUTPUT_SEGMENT_DIR);\n+    File segmentTarDir = new File(workingDir, SEGMENT_TAR_DIR);\n+    try {\n+      Preconditions\n+          .checkState(inputDir.mkdirs(), \"Could not create directory for downloading input file locally: %s\", inputDir);\n+      Preconditions.checkState(segmentTarDir.mkdirs(), \"Could not create directory for segment tar file: %s\", inputDir);\n+\n+      // Copy file to local working dir\n+      File inputFile =\n+          new File(inputDir, String.format(\"%s.%s\", DATA_FILE_PREFIX, _batchConfig.getInputFormat().toString().toLowerCase()));\n+      if (payload._dataSource.equals(DataSource.URI)) {\n+        FileIngestionUtils.copyURIToLocal(_batchConfig, payload._uri, inputFile);\n+      } else {\n+        FileIngestionUtils.copyMultipartToLocal(payload._multiPart, inputFile);\n+      }\n+\n+      // Build segment\n+      SegmentGeneratorConfig segmentGeneratorConfig =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f446dc039c65db41efd9f07f93692dc1d1b0e93"}, "originalPosition": 92}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU2MzYxOQ==", "bodyText": "what happens if the segment already exists? can we say replace if it already exists?", "url": "https://github.com/apache/pinot/pull/6354#discussion_r545563619", "createdAt": "2020-12-18T04:19:47Z", "author": {"login": "kishoreg"}, "path": "pinot-controller/src/main/java/org/apache/pinot/controller/util/FileIngestionHelper.java", "diffHunk": "@@ -0,0 +1,140 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.util;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import java.io.File;\n+import java.net.URI;\n+import org.apache.commons.io.FileUtils;\n+import org.apache.pinot.common.utils.TarGzCompressionUtils;\n+import org.apache.pinot.controller.ControllerConf;\n+import org.apache.pinot.controller.api.resources.SuccessResponse;\n+import org.apache.pinot.core.indexsegment.generator.SegmentGeneratorConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.spi.ingestion.batch.BatchConfig;\n+import org.glassfish.jersey.media.multipart.FormDataMultiPart;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * A driver for the ingestion process of the provided file.\n+ * Responsible for copying the file locally, building a segment and uploading it to the controller.\n+ */\n+public class FileIngestionHelper {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(FileIngestionHelper.class);\n+\n+  private static final String WORKING_DIR_PREFIX = \"working_dir\";\n+  private static final String INPUT_DATA_DIR = \"input_data_dir\";\n+  private static final String OUTPUT_SEGMENT_DIR = \"output_segment_dir\";\n+  private static final String SEGMENT_TAR_DIR = \"segment_tar_dir\";\n+  private static final String DATA_FILE_PREFIX = \"data\";\n+\n+  private final TableConfig _tableConfig;\n+  private final Schema _schema;\n+  private final BatchConfig _batchConfig;\n+  private final ControllerConf _controllerConf;\n+\n+  public FileIngestionHelper(TableConfig tableConfig, Schema schema,\n+      BatchConfig batchConfig, ControllerConf controllerConf) {\n+    _tableConfig = tableConfig;\n+    _schema = schema;\n+    _batchConfig = batchConfig;\n+    _controllerConf = controllerConf;\n+  }\n+\n+  /**\n+   * Creates a segment using the provided data file/URI and uploads to Pinot\n+   */\n+  public SuccessResponse buildSegmentAndPush(DataPayload payload)\n+      throws Exception {\n+    String tableNameWithType = _tableConfig.getTableName();\n+\n+    // Setup working dir\n+    File workingDir = new File(FileUtils.getTempDirectory(),\n+        String.format(\"%s_%s_%d\", WORKING_DIR_PREFIX, tableNameWithType, System.currentTimeMillis()));\n+    File inputDir = new File(workingDir, INPUT_DATA_DIR);\n+    File outputDir = new File(workingDir, OUTPUT_SEGMENT_DIR);\n+    File segmentTarDir = new File(workingDir, SEGMENT_TAR_DIR);\n+    try {\n+      Preconditions\n+          .checkState(inputDir.mkdirs(), \"Could not create directory for downloading input file locally: %s\", inputDir);\n+      Preconditions.checkState(segmentTarDir.mkdirs(), \"Could not create directory for segment tar file: %s\", inputDir);\n+\n+      // Copy file to local working dir\n+      File inputFile =\n+          new File(inputDir, String.format(\"%s.%s\", DATA_FILE_PREFIX, _batchConfig.getInputFormat().toString().toLowerCase()));\n+      if (payload._dataSource.equals(DataSource.URI)) {\n+        FileIngestionUtils.copyURIToLocal(_batchConfig, payload._uri, inputFile);\n+      } else {\n+        FileIngestionUtils.copyMultipartToLocal(payload._multiPart, inputFile);\n+      }\n+\n+      // Build segment\n+      SegmentGeneratorConfig segmentGeneratorConfig =\n+          FileIngestionUtils.generateSegmentGeneratorConfig(_tableConfig, _batchConfig, _schema, inputFile, outputDir);\n+      String segmentName = FileIngestionUtils.buildSegment(segmentGeneratorConfig);\n+\n+      // Tar and push segment\n+      File segmentTarFile =\n+          new File(segmentTarDir, segmentName + org.apache.pinot.spi.ingestion.batch.spec.Constants.TAR_GZ_FILE_EXT);\n+      TarGzCompressionUtils.createTarGzFile(new File(outputDir, segmentName), segmentTarFile);\n+      FileIngestionUtils", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f446dc039c65db41efd9f07f93692dc1d1b0e93"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU2NDM2Mg==", "bodyText": "will be good to provide the ability to configure the file.upload.dir as input this class. Useful for testing and also the controller can initialize this with a directory under the data.dir.", "url": "https://github.com/apache/pinot/pull/6354#discussion_r545564362", "createdAt": "2020-12-18T04:23:12Z", "author": {"login": "kishoreg"}, "path": "pinot-controller/src/main/java/org/apache/pinot/controller/util/FileIngestionHelper.java", "diffHunk": "@@ -0,0 +1,140 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.util;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import java.io.File;\n+import java.net.URI;\n+import org.apache.commons.io.FileUtils;\n+import org.apache.pinot.common.utils.TarGzCompressionUtils;\n+import org.apache.pinot.controller.ControllerConf;\n+import org.apache.pinot.controller.api.resources.SuccessResponse;\n+import org.apache.pinot.core.indexsegment.generator.SegmentGeneratorConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.spi.ingestion.batch.BatchConfig;\n+import org.glassfish.jersey.media.multipart.FormDataMultiPart;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * A driver for the ingestion process of the provided file.\n+ * Responsible for copying the file locally, building a segment and uploading it to the controller.\n+ */\n+public class FileIngestionHelper {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(FileIngestionHelper.class);\n+\n+  private static final String WORKING_DIR_PREFIX = \"working_dir\";\n+  private static final String INPUT_DATA_DIR = \"input_data_dir\";\n+  private static final String OUTPUT_SEGMENT_DIR = \"output_segment_dir\";\n+  private static final String SEGMENT_TAR_DIR = \"segment_tar_dir\";\n+  private static final String DATA_FILE_PREFIX = \"data\";\n+\n+  private final TableConfig _tableConfig;\n+  private final Schema _schema;\n+  private final BatchConfig _batchConfig;\n+  private final ControllerConf _controllerConf;\n+\n+  public FileIngestionHelper(TableConfig tableConfig, Schema schema,\n+      BatchConfig batchConfig, ControllerConf controllerConf) {\n+    _tableConfig = tableConfig;\n+    _schema = schema;\n+    _batchConfig = batchConfig;\n+    _controllerConf = controllerConf;\n+  }\n+\n+  /**\n+   * Creates a segment using the provided data file/URI and uploads to Pinot\n+   */\n+  public SuccessResponse buildSegmentAndPush(DataPayload payload)\n+      throws Exception {\n+    String tableNameWithType = _tableConfig.getTableName();\n+\n+    // Setup working dir\n+    File workingDir = new File(FileUtils.getTempDirectory(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f446dc039c65db41efd9f07f93692dc1d1b0e93"}, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU2NjM3NQ==", "bodyText": "why is this called DataSource and why do we need this?", "url": "https://github.com/apache/pinot/pull/6354#discussion_r545566375", "createdAt": "2020-12-18T04:30:59Z", "author": {"login": "kishoreg"}, "path": "pinot-controller/src/main/java/org/apache/pinot/controller/util/FileIngestionHelper.java", "diffHunk": "@@ -0,0 +1,140 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.util;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import java.io.File;\n+import java.net.URI;\n+import org.apache.commons.io.FileUtils;\n+import org.apache.pinot.common.utils.TarGzCompressionUtils;\n+import org.apache.pinot.controller.ControllerConf;\n+import org.apache.pinot.controller.api.resources.SuccessResponse;\n+import org.apache.pinot.core.indexsegment.generator.SegmentGeneratorConfig;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.spi.ingestion.batch.BatchConfig;\n+import org.glassfish.jersey.media.multipart.FormDataMultiPart;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * A driver for the ingestion process of the provided file.\n+ * Responsible for copying the file locally, building a segment and uploading it to the controller.\n+ */\n+public class FileIngestionHelper {\n+  private static final Logger LOGGER = LoggerFactory.getLogger(FileIngestionHelper.class);\n+\n+  private static final String WORKING_DIR_PREFIX = \"working_dir\";\n+  private static final String INPUT_DATA_DIR = \"input_data_dir\";\n+  private static final String OUTPUT_SEGMENT_DIR = \"output_segment_dir\";\n+  private static final String SEGMENT_TAR_DIR = \"segment_tar_dir\";\n+  private static final String DATA_FILE_PREFIX = \"data\";\n+\n+  private final TableConfig _tableConfig;\n+  private final Schema _schema;\n+  private final BatchConfig _batchConfig;\n+  private final ControllerConf _controllerConf;\n+\n+  public FileIngestionHelper(TableConfig tableConfig, Schema schema,\n+      BatchConfig batchConfig, ControllerConf controllerConf) {\n+    _tableConfig = tableConfig;\n+    _schema = schema;\n+    _batchConfig = batchConfig;\n+    _controllerConf = controllerConf;\n+  }\n+\n+  /**\n+   * Creates a segment using the provided data file/URI and uploads to Pinot\n+   */\n+  public SuccessResponse buildSegmentAndPush(DataPayload payload)\n+      throws Exception {\n+    String tableNameWithType = _tableConfig.getTableName();\n+\n+    // Setup working dir\n+    File workingDir = new File(FileUtils.getTempDirectory(),\n+        String.format(\"%s_%s_%d\", WORKING_DIR_PREFIX, tableNameWithType, System.currentTimeMillis()));\n+    File inputDir = new File(workingDir, INPUT_DATA_DIR);\n+    File outputDir = new File(workingDir, OUTPUT_SEGMENT_DIR);\n+    File segmentTarDir = new File(workingDir, SEGMENT_TAR_DIR);\n+    try {\n+      Preconditions\n+          .checkState(inputDir.mkdirs(), \"Could not create directory for downloading input file locally: %s\", inputDir);\n+      Preconditions.checkState(segmentTarDir.mkdirs(), \"Could not create directory for segment tar file: %s\", inputDir);\n+\n+      // Copy file to local working dir\n+      File inputFile =\n+          new File(inputDir, String.format(\"%s.%s\", DATA_FILE_PREFIX, _batchConfig.getInputFormat().toString().toLowerCase()));\n+      if (payload._dataSource.equals(DataSource.URI)) {\n+        FileIngestionUtils.copyURIToLocal(_batchConfig, payload._uri, inputFile);\n+      } else {\n+        FileIngestionUtils.copyMultipartToLocal(payload._multiPart, inputFile);\n+      }\n+\n+      // Build segment\n+      SegmentGeneratorConfig segmentGeneratorConfig =\n+          FileIngestionUtils.generateSegmentGeneratorConfig(_tableConfig, _batchConfig, _schema, inputFile, outputDir);\n+      String segmentName = FileIngestionUtils.buildSegment(segmentGeneratorConfig);\n+\n+      // Tar and push segment\n+      File segmentTarFile =\n+          new File(segmentTarDir, segmentName + org.apache.pinot.spi.ingestion.batch.spec.Constants.TAR_GZ_FILE_EXT);\n+      TarGzCompressionUtils.createTarGzFile(new File(outputDir, segmentName), segmentTarFile);\n+      FileIngestionUtils\n+          .uploadSegment(tableNameWithType, Lists.newArrayList(segmentTarFile), _controllerConf.getControllerHost(),\n+              Integer.parseInt(_controllerConf.getControllerPort()));\n+\n+      return new SuccessResponse(\n+          \"Successfully ingested file into table: \" + tableNameWithType + \" as segment: \" + segmentName);\n+    } catch (Exception e) {\n+      LOGGER.error(\"Caught exception when ingesting file to table: {}\", tableNameWithType, e);\n+      throw e;\n+    } finally {\n+      FileUtils.deleteQuietly(workingDir);\n+    }\n+  }\n+\n+  /**\n+   * Enum to identify the source of ingestion file\n+   */\n+  private enum DataSource {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f446dc039c65db41efd9f07f93692dc1d1b0e93"}, "originalPosition": 117}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTU2ODE2Ng==", "bodyText": "it's probably better to copy the data locally for both URI based and multipart right", "url": "https://github.com/apache/pinot/pull/6354#discussion_r545568166", "createdAt": "2020-12-18T04:38:12Z", "author": {"login": "kishoreg"}, "path": "pinot-controller/src/main/java/org/apache/pinot/controller/api/resources/PinotIngestionRestletResource.java", "diffHunk": "@@ -0,0 +1,145 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.api.resources;\n+\n+import com.fasterxml.jackson.core.type.TypeReference;\n+import com.google.common.base.Preconditions;\n+import io.swagger.annotations.Api;\n+import io.swagger.annotations.ApiOperation;\n+import io.swagger.annotations.ApiParam;\n+import java.net.URI;\n+import java.util.Map;\n+import javax.inject.Inject;\n+import javax.ws.rs.Consumes;\n+import javax.ws.rs.POST;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.QueryParam;\n+import javax.ws.rs.container.AsyncResponse;\n+import javax.ws.rs.container.Suspended;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+import org.apache.pinot.controller.ControllerConf;\n+import org.apache.pinot.controller.helix.core.PinotHelixResourceManager;\n+import org.apache.pinot.controller.util.FileIngestionHelper;\n+import org.apache.pinot.controller.util.FileIngestionHelper.DataPayload;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.config.table.TableType;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.spi.ingestion.batch.BatchConfig;\n+import org.apache.pinot.spi.utils.JsonUtils;\n+import org.apache.pinot.spi.utils.builder.TableNameBuilder;\n+import org.glassfish.jersey.media.multipart.FormDataMultiPart;\n+import org.glassfish.jersey.server.ManagedAsync;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * APIs related to ingestion\n+ */\n+@Api(tags = Constants.TABLE_TAG)\n+@Path(\"/\")\n+public class PinotIngestionRestletResource {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(PinotIngestionRestletResource.class);\n+\n+  @Inject\n+  PinotHelixResourceManager _pinotHelixResourceManager;\n+\n+  @Inject\n+  ControllerConf _controllerConf;\n+\n+  /**\n+   * API to upload a file and ingest it into a Pinot table\n+   * @param tableName Name of the table to upload to\n+   * @param batchConfigMapStr Batch config Map as a string. Provide the\n+   *                          input format (inputFormat)\n+   *                          record reader configs (recordReader.prop.<property>),\n+   *                          fs class name (input.fs.className)\n+   *                          fs configs (input.fs.prop.<property>)\n+   * @param fileUpload file to upload as a multipart\n+   */\n+  @POST\n+  @ManagedAsync\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @Consumes(MediaType.MULTIPART_FORM_DATA)\n+  @Path(\"/ingestFromFile\")\n+  @ApiOperation(value = \"Ingest a file\", notes = \"Creates a segment using given file and pushes it to Pinot\")\n+  public void ingestFromFile(\n+      @ApiParam(value = \"Name of the table to upload the file to\", required = true) @QueryParam(\"tableName\") String tableName,\n+      @ApiParam(value = \"Batch config map as string\", required = true) @QueryParam(\"batchConfigMapStr\") String batchConfigMapStr,\n+      FormDataMultiPart fileUpload,\n+      @Suspended final AsyncResponse asyncResponse) {\n+    try {\n+      asyncResponse.resume(ingestData(tableName, batchConfigMapStr, new DataPayload(fileUpload)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f446dc039c65db41efd9f07f93692dc1d1b0e93"}, "originalPosition": 91}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d535d9d64f4c1619acc213619d6ca5b3c75cb1d0", "author": {"user": {"login": "npawar", "name": "Neha Pawar"}}, "url": "https://github.com/apache/pinot/commit/d535d9d64f4c1619acc213619d6ca5b3c75cb1d0", "committedDate": "2020-12-21T19:41:17Z", "message": "Review changes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "35c8fd2a1cd1d2c7d983ace5ab69161742afa931", "author": {"user": {"login": "npawar", "name": "Neha Pawar"}}, "url": "https://github.com/apache/pinot/commit/35c8fd2a1cd1d2c7d983ace5ab69161742afa931", "committedDate": "2020-12-21T20:00:36Z", "message": "Upload dir as param for FileIngestionHelper constructor"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a8eeb6b378798971899ed0b38788a4b954fbcac2", "author": {"user": {"login": "npawar", "name": "Neha Pawar"}}, "url": "https://github.com/apache/pinot/commit/a8eeb6b378798971899ed0b38788a4b954fbcac2", "committedDate": "2020-12-21T20:12:02Z", "message": "Add message"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1OTg5MTA4", "url": "https://github.com/apache/pinot/pull/6354#pullrequestreview-555989108", "createdAt": "2020-12-20T06:20:30Z", "commit": {"oid": "3f446dc039c65db41efd9f07f93692dc1d1b0e93"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMFQwNjoyMDozMFrOIJBQcA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMFQwNjo0Mjo0NFrOIJBYFQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjMyODY4OA==", "bodyText": "Shall we also add an API of\npublic String forIngestFromFile(String tableNameWithType, Map<String, String> batchConfig)\nand\npublic String forIngestFromURI(String tableNameWithType, Map<String, String> batchConfig, String sourceURIStr)", "url": "https://github.com/apache/pinot/pull/6354#discussion_r546328688", "createdAt": "2020-12-20T06:20:30Z", "author": {"login": "xiangfu0"}, "path": "pinot-controller/src/main/java/org/apache/pinot/controller/helix/ControllerRequestURLBuilder.java", "diffHunk": "@@ -289,4 +292,18 @@ public String forInstanceReplace(String tableName, @Nullable InstancePartitionsT\n     }\n     return url;\n   }\n+\n+  public String forIngestFromFile(String tableNameWithType, String batchConfigMapStr)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f446dc039c65db41efd9f07f93692dc1d1b0e93"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjMzMDY0NQ==", "bodyText": "Shall we extract this to a common class into RecordReaderFactory.getRecordReaderConfig(...)?", "url": "https://github.com/apache/pinot/pull/6354#discussion_r546330645", "createdAt": "2020-12-20T06:42:44Z", "author": {"login": "xiangfu0"}, "path": "pinot-controller/src/main/java/org/apache/pinot/controller/util/FileIngestionUtils.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.controller.util;\n+\n+import com.fasterxml.jackson.databind.JsonNode;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.google.common.base.Preconditions;\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import java.net.URI;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.commons.io.IOUtils;\n+import org.apache.pinot.common.exception.HttpErrorStatusException;\n+import org.apache.pinot.common.utils.FileUploadDownloadClient;\n+import org.apache.pinot.common.utils.SimpleHttpResponse;\n+import org.apache.pinot.core.indexsegment.generator.SegmentGeneratorConfig;\n+import org.apache.pinot.core.segment.creator.impl.SegmentIndexCreationDriverImpl;\n+import org.apache.pinot.core.segment.name.SimpleSegmentNameGenerator;\n+import org.apache.pinot.spi.config.table.TableConfig;\n+import org.apache.pinot.spi.data.Schema;\n+import org.apache.pinot.spi.data.readers.FileFormat;\n+import org.apache.pinot.spi.data.readers.RecordReaderConfig;\n+import org.apache.pinot.spi.data.readers.RecordReaderFactory;\n+import org.apache.pinot.spi.filesystem.PinotFSFactory;\n+import org.apache.pinot.spi.ingestion.batch.BatchConfig;\n+import org.apache.pinot.spi.plugin.PluginManager;\n+import org.apache.pinot.spi.utils.IngestionConfigUtils;\n+import org.apache.pinot.spi.utils.JsonUtils;\n+import org.apache.pinot.spi.utils.retry.AttemptsExceededException;\n+import org.apache.pinot.spi.utils.retry.RetriableOperationException;\n+import org.apache.pinot.spi.utils.retry.RetryPolicies;\n+import org.glassfish.jersey.media.multipart.FormDataBodyPart;\n+import org.glassfish.jersey.media.multipart.FormDataMultiPart;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+\n+/**\n+ * Helper methods for ingestion from file\n+ */\n+public final class FileIngestionUtils {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(FileIngestionUtils.class);\n+  private static final long DEFAULT_RETRY_WAIT_MS = 1000L;\n+  private static final int DEFAULT_ATTEMPTS = 3;\n+  private static final FileUploadDownloadClient FILE_UPLOAD_DOWNLOAD_CLIENT = new FileUploadDownloadClient();\n+\n+  private FileIngestionUtils() {\n+  }\n+\n+  /**\n+   * Copy the file from given URI to local file\n+   */\n+  public static void copyURIToLocal(BatchConfig batchConfig, URI sourceFileURI, File destFile)\n+      throws Exception {\n+    String sourceFileURIScheme = sourceFileURI.getScheme();\n+    if (!PinotFSFactory.isSchemeSupported(sourceFileURIScheme)) {\n+      PinotFSFactory.register(sourceFileURIScheme, batchConfig.getInputFsClassName(),\n+          IngestionConfigUtils.getFsProps(batchConfig.getInputFsProps()));\n+    }\n+    PinotFSFactory.create(sourceFileURIScheme).copyToLocalFile(sourceFileURI, destFile);\n+  }\n+\n+  /**\n+   * Copy the file from the uploaded multipart to a local file\n+   */\n+  public static void copyMultipartToLocal(FormDataMultiPart multiPart, File destFile)\n+      throws IOException {\n+    FormDataBodyPart formDataBodyPart = multiPart.getFields().values().iterator().next().get(0);\n+    try (InputStream inputStream = formDataBodyPart.getValueAs(InputStream.class);\n+        OutputStream outputStream = new FileOutputStream(destFile)) {\n+      IOUtils.copyLarge(inputStream, outputStream);\n+    } finally {\n+      multiPart.cleanup();\n+    }\n+  }\n+\n+  /**\n+   * Creates a {@link SegmentGeneratorConfig}\n+   * @param tableConfig Table config\n+   * @param batchConfig Batch config override provided by the user during upload\n+   * @param schema Table schema\n+   * @param inputFile The input file\n+   * @param outputSegmentDir The output dir\n+   */\n+  public static SegmentGeneratorConfig generateSegmentGeneratorConfig(TableConfig tableConfig, BatchConfig batchConfig,\n+      Schema schema, File inputFile, File outputSegmentDir)\n+      throws ClassNotFoundException, IOException {\n+    SegmentGeneratorConfig segmentGeneratorConfig = new SegmentGeneratorConfig(tableConfig, schema);\n+    segmentGeneratorConfig.setTableName(tableConfig.getTableName());\n+    segmentGeneratorConfig.setOutDir(outputSegmentDir.getAbsolutePath());\n+    segmentGeneratorConfig.setInputFilePath(inputFile.getAbsolutePath());\n+\n+    FileFormat fileFormat = batchConfig.getInputFormat();\n+    segmentGeneratorConfig.setFormat(fileFormat);\n+    segmentGeneratorConfig.setRecordReaderPath(RecordReaderFactory.getRecordReaderClassName(fileFormat.toString()));\n+    String readerConfigClassName = RecordReaderFactory.getRecordReaderConfigClassName(fileFormat.toString());\n+    if (readerConfigClassName != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f446dc039c65db41efd9f07f93692dc1d1b0e93"}, "originalPosition": 121}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e4615e6f849af9aa4c8c840bdf1cb497cc8dc49d", "author": {"user": {"login": "npawar", "name": "Neha Pawar"}}, "url": "https://github.com/apache/pinot/commit/e4615e6f849af9aa4c8c840bdf1cb497cc8dc49d", "committedDate": "2020-12-21T22:39:37Z", "message": "Message about encoding"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU2NzA5ODk5", "url": "https://github.com/apache/pinot/pull/6354#pullrequestreview-556709899", "createdAt": "2020-12-21T22:46:07Z", "commit": {"oid": "e4615e6f849af9aa4c8c840bdf1cb497cc8dc49d"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "56d5e128974a767ea610991e139922f7ab8d6930", "author": {"user": {"login": "npawar", "name": "Neha Pawar"}}, "url": "https://github.com/apache/pinot/commit/56d5e128974a767ea610991e139922f7ab8d6930", "committedDate": "2020-12-21T23:54:00Z", "message": "Review comments"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1665, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}