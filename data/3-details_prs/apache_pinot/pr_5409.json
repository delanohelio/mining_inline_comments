{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE5NzgzMzUz", "number": 5409, "title": "Faster vectorized bit unpacking (Part 1)", "bodyText": "Couple of improvements have been done for bit-unpacking.\n\nUse hand-written unpack methods for power of 2 (1, 2, 4, 8, 16, 32) number of bits used to encode the dictionaryId. The hand-written methods are faster than generic due to simplified bit math.\nAmortize the overhead of function calls.\n\nRight now, the new code isn't yet wired into existing bit reader and writer. Couple of follow-ups will be coming soon:\n\nEvaluate this optimization for non power of 2 number of bits. It is fairly possible but the performance benefit of using a special hand-written function for unpacking seems to get lost as the bit math itself gets complicated with branches for non power of 2 number of bits.\nConsider using a new format where if the number of bits to encode is non power of 2, we convert it to nearest power of 2. This means if you need more than 16 bits, we use 32 bits (raw value). We get diminished returns as the overhead of unpacking itself increases at the cost of saving 10-12 bits.\nIntegrate the new changes with existing code.\n\nDescription of changes:\nA new version of FixedBitIntReaderWriter is written that underneath uses a new version of fast bit unpack reader PinotDataBitSetV2.\nThere are 3 important APIs here:\npublic int readInt(int index)\nExists in the current code as well - Used by the scan operator to read through the forward index and dictId for each docId\npublic void readInt(int startDocId, int length, int[] buffer)\nExists in the current code as well - Used by the multi-value bit reader to get dictId for all MVs in a given cell.\npublic void readValues(int[] docIds, int docIdStartIndex, int docIdLength, int[] values, int valuesStartIndex)\nExists at the FixedBitSingleColumnSingleValueReader interface and used by the dictionary based group by executor to get dictIds for a set of docIds (monotonically increasing but not necessarily contiguous). But the API still issued single read calls underneath. This PR introduces this API at the FixedBitIntReaderWriterV2 level so that group by executor can leverage it using the bulk read semantics.\nWhen this code is wired in, the scan operator will start using one of the second or third API.\nPlease see the spreadsheet for performance numbers.\nTwo kinds of tests were done:\n\nCompare the performance of sequential consecutive reads using single read API getInt(index) with faster bit unpacking code.\nCompare the performance of sequential consecutive reads using array API readInt(int startDocId, int length, int[] buffer) with faster bit unpacking code.\n\nWill be adding some units tests. The current PR has performance test.", "createdAt": "2020-05-18T22:59:26Z", "url": "https://github.com/apache/pinot/pull/5409", "merged": true, "mergeCommit": {"oid": "b40dd992874f9bc38b911870e041a8f6e24c3776"}, "closed": true, "closedAt": "2020-05-29T21:08:04Z", "author": {"login": "siddharthteotia"}, "timelineItems": {"totalCount": 13, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcinE3PgH2gAyNDE5NzgzMzUzOmE2NTQwOWY4NzNmMzczNWQzNDM3OGY0YWIzNTI2Nzk1ZjdhOTE5YTU=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcl1zqugH2gAyNDE5NzgzMzUzOjdlODRlNDFlNzAwNGI0MzIwNzg3MDExYWYzOGUxMzVjZDlkZTM3MzQ=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "a65409f873f3735d34378f4ab3526795f7a919a5", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/a65409f873f3735d34378f4ab3526795f7a919a5", "committedDate": "2020-05-18T21:51:07Z", "message": "Faster bit unpacking"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE0MDI3ODAz", "url": "https://github.com/apache/pinot/pull/5409#pullrequestreview-414027803", "createdAt": "2020-05-19T00:46:20Z", "commit": {"oid": "a65409f873f3735d34378f4ab3526795f7a919a5"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQwMDo0NjoyMFrOGXMBpg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQwMDo1NToyN1rOGXMLGg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk2NzQ2Mg==", "bodyText": "Consider writing a header for backward/forward compatibility.", "url": "https://github.com/apache/pinot/pull/5409#discussion_r426967462", "createdAt": "2020-05-19T00:46:20Z", "author": {"login": "mayankshriv"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/io/util/FixedBitIntReaderWriterV2.java", "diffHunk": "@@ -0,0 +1,104 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.io.util;\n+\n+import com.google.common.base.Preconditions;\n+import java.io.Closeable;\n+import java.io.IOException;\n+import org.apache.pinot.core.plan.DocIdSetPlanNode;\n+import org.apache.pinot.core.segment.memory.PinotDataBuffer;\n+\n+\n+public final class FixedBitIntReaderWriterV2 implements Closeable {\n+  private volatile PinotDataBitSetV2 _dataBitSet;\n+  private final int _numBitsPerValue;\n+\n+  public FixedBitIntReaderWriterV2(PinotDataBuffer dataBuffer, int numValues, int numBitsPerValue) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a65409f873f3735d34378f4ab3526795f7a919a5"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk2NzY0Ng==", "bodyText": "Reasoning for magic number?", "url": "https://github.com/apache/pinot/pull/5409#discussion_r426967646", "createdAt": "2020-05-19T00:47:08Z", "author": {"login": "mayankshriv"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/io/util/FixedBitIntReaderWriterV2.java", "diffHunk": "@@ -0,0 +1,104 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.io.util;\n+\n+import com.google.common.base.Preconditions;\n+import java.io.Closeable;\n+import java.io.IOException;\n+import org.apache.pinot.core.plan.DocIdSetPlanNode;\n+import org.apache.pinot.core.segment.memory.PinotDataBuffer;\n+\n+\n+public final class FixedBitIntReaderWriterV2 implements Closeable {\n+  private volatile PinotDataBitSetV2 _dataBitSet;\n+  private final int _numBitsPerValue;\n+\n+  public FixedBitIntReaderWriterV2(PinotDataBuffer dataBuffer, int numValues, int numBitsPerValue) {\n+    Preconditions\n+        .checkState(dataBuffer.size() == (int) (((long) numValues * numBitsPerValue + Byte.SIZE - 1) / Byte.SIZE));\n+    _dataBitSet = PinotDataBitSetV2.createBitSet(dataBuffer, numBitsPerValue);\n+    _numBitsPerValue = numBitsPerValue;\n+  }\n+\n+  /**\n+   * Read dictionaryId for a particular docId\n+   * @param index docId to get the dictionaryId for\n+   * @return dictionaryId\n+   */\n+  public int readInt(int index) {\n+    return _dataBitSet.readInt(index);\n+  }\n+\n+  /**\n+   * Array based API to read dictionaryIds for a contiguous\n+   * range of docIds starting at startDocId for a given length\n+   * @param startDocId docId range start\n+   * @param length length of contiguous docId range\n+   * @param buffer out buffer to read dictionaryIds into\n+   */\n+  public void readInt(int startDocId, int length, int[] buffer) {\n+    _dataBitSet.readInt(startDocId, length, buffer);\n+  }\n+\n+  /**\n+   * Array based API to read dictionaryIds for an array of docIds\n+   * which are monotonically increasing but not necessarily contiguous\n+   * @param docIds array of docIds to read the dictionaryIds for\n+   * @param docIdStartIndex start index in docIds array\n+   * @param docIdLength length to process in docIds array\n+   * @param values out array to store the dictionaryIds into\n+   * @param valuesStartIndex start index in values array\n+   */\n+  public void readValues(int[] docIds, int docIdStartIndex, int docIdLength, int[] values, int valuesStartIndex) {\n+    int docIdEndIndex = docIdStartIndex + docIdLength - 1;\n+    if (shouldBulkRead(docIds, docIdStartIndex, docIdEndIndex)) {\n+      _dataBitSet.readInt(docIds, docIdStartIndex, docIdLength, values, valuesStartIndex);\n+    } else {\n+      for (int i = docIdStartIndex; i <= docIdEndIndex; i++) {\n+        values[valuesStartIndex++] = _dataBitSet.readInt(docIds[i]);\n+      }\n+    }\n+  }\n+\n+  private boolean shouldBulkRead(int[] docIds, int startIndex, int endIndex) {\n+    int numDocsToRead = endIndex - startIndex + 1;\n+    int docIdRange = docIds[endIndex] - docIds[startIndex] + 1;\n+    if (docIdRange > DocIdSetPlanNode.MAX_DOC_PER_CALL) {\n+      return false;\n+    }\n+    return numDocsToRead >= ((double)docIdRange * 0.7);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a65409f873f3735d34378f4ab3526795f7a919a5"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk2OTM3OQ==", "bodyText": "Would be good to use JMH to make benchmark more accurate.", "url": "https://github.com/apache/pinot/pull/5409#discussion_r426969379", "createdAt": "2020-05-19T00:53:33Z", "author": {"login": "mayankshriv"}, "path": "pinot-perf/src/main/java/org/apache/pinot/perf/ForwardIndexBenchmark.java", "diffHunk": "@@ -0,0 +1,269 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.perf;\n+\n+import com.google.common.base.Stopwatch;\n+import java.io.BufferedReader;\n+import java.io.BufferedWriter;\n+import java.io.DataInputStream;\n+import java.io.DataOutputStream;\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileNotFoundException;\n+import java.io.FileOutputStream;\n+import java.io.FileReader;\n+import java.io.FileWriter;\n+import java.io.IOException;\n+import java.io.RandomAccessFile;\n+import java.nio.ByteBuffer;\n+import java.nio.ByteOrder;\n+import java.nio.channels.FileChannel;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Random;\n+import java.util.concurrent.TimeUnit;\n+import me.lemire.integercompression.BitPacking;\n+import org.apache.commons.math.util.MathUtils;\n+import org.apache.pinot.core.io.reader.impl.v1.FixedBitSingleValueReader;\n+import org.apache.pinot.core.io.util.FixedBitIntReaderWriter;\n+import org.apache.pinot.core.io.util.FixedBitIntReaderWriterV2;\n+import org.apache.pinot.core.io.util.FixedByteValueReaderWriter;\n+import org.apache.pinot.core.io.util.PinotDataBitSet;\n+import org.apache.pinot.core.io.writer.impl.v1.FixedBitSingleValueWriter;\n+import org.apache.pinot.core.segment.memory.PinotDataBuffer;\n+\n+public class ForwardIndexBenchmark {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a65409f873f3735d34378f4ab3526795f7a919a5"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk2OTg4Mg==", "bodyText": "This class needs exhaustive unit tests to ensure all cases are covered.", "url": "https://github.com/apache/pinot/pull/5409#discussion_r426969882", "createdAt": "2020-05-19T00:55:27Z", "author": {"login": "mayankshriv"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/io/util/PinotDataBitSetV2.java", "diffHunk": "@@ -0,0 +1,418 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.io.util;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import org.apache.pinot.core.plan.DocIdSetPlanNode;\n+import org.apache.pinot.core.segment.memory.PinotDataBuffer;\n+\n+\n+public abstract class PinotDataBitSetV2 implements Closeable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a65409f873f3735d34378f4ab3526795f7a919a5"}, "originalPosition": 27}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f0679eca59cacdd600fce7d43cd95a0e7244ea94", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/f0679eca59cacdd600fce7d43cd95a0e7244ea94", "committedDate": "2020-05-20T07:29:13Z", "message": "Add unit tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3cf936181ec2a69422a355bb328e60f3f4aa1adb", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/3cf936181ec2a69422a355bb328e60f3f4aa1adb", "committedDate": "2020-05-21T06:04:47Z", "message": "new"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "942ef3ed41afc4b81e3166f80d0ba33c1a27ab78", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/942ef3ed41afc4b81e3166f80d0ba33c1a27ab78", "committedDate": "2020-05-21T08:26:06Z", "message": "Improved degree of vectorization and more tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "45bd3a39fbe6b0a0efeedd5bcf673484fe91ba98", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/45bd3a39fbe6b0a0efeedd5bcf673484fe91ba98", "committedDate": "2020-05-21T16:54:18Z", "message": "fix build"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "14543bbe7905e74dc2439f06c26ad246c3462fba", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/14543bbe7905e74dc2439f06c26ad246c3462fba", "committedDate": "2020-05-22T07:01:56Z", "message": "cleanup"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4798b799496d39b9828fb8a2de0a4bcdba3bdc0c", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/4798b799496d39b9828fb8a2de0a4bcdba3bdc0c", "committedDate": "2020-05-22T07:18:17Z", "message": "docs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ab19454de0c1c3d3e1fd25e62f682d5cd4f5d210", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/ab19454de0c1c3d3e1fd25e62f682d5cd4f5d210", "committedDate": "2020-05-22T07:25:53Z", "message": "change file name"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDEzOTk2MDQ3", "url": "https://github.com/apache/pinot/pull/5409#pullrequestreview-413996047", "createdAt": "2020-05-18T23:08:29Z", "commit": {"oid": "a65409f873f3735d34378f4ab3526795f7a919a5"}, "state": "APPROVED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQyMzowODoyOVrOGXKW1Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQwNjowMzo1NlrOGaPtUg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk0MDExNw==", "bodyText": "why is this check needed?", "url": "https://github.com/apache/pinot/pull/5409#discussion_r426940117", "createdAt": "2020-05-18T23:08:29Z", "author": {"login": "kishoreg"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/io/util/FixedBitIntReaderWriterV2.java", "diffHunk": "@@ -0,0 +1,104 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.io.util;\n+\n+import com.google.common.base.Preconditions;\n+import java.io.Closeable;\n+import java.io.IOException;\n+import org.apache.pinot.core.plan.DocIdSetPlanNode;\n+import org.apache.pinot.core.segment.memory.PinotDataBuffer;\n+\n+\n+public final class FixedBitIntReaderWriterV2 implements Closeable {\n+  private volatile PinotDataBitSetV2 _dataBitSet;\n+  private final int _numBitsPerValue;\n+\n+  public FixedBitIntReaderWriterV2(PinotDataBuffer dataBuffer, int numValues, int numBitsPerValue) {\n+    Preconditions\n+        .checkState(dataBuffer.size() == (int) (((long) numValues * numBitsPerValue + Byte.SIZE - 1) / Byte.SIZE));\n+    _dataBitSet = PinotDataBitSetV2.createBitSet(dataBuffer, numBitsPerValue);\n+    _numBitsPerValue = numBitsPerValue;\n+  }\n+\n+  /**\n+   * Read dictionaryId for a particular docId\n+   * @param index docId to get the dictionaryId for\n+   * @return dictionaryId\n+   */\n+  public int readInt(int index) {\n+    return _dataBitSet.readInt(index);\n+  }\n+\n+  /**\n+   * Array based API to read dictionaryIds for a contiguous\n+   * range of docIds starting at startDocId for a given length\n+   * @param startDocId docId range start\n+   * @param length length of contiguous docId range\n+   * @param buffer out buffer to read dictionaryIds into\n+   */\n+  public void readInt(int startDocId, int length, int[] buffer) {\n+    _dataBitSet.readInt(startDocId, length, buffer);\n+  }\n+\n+  /**\n+   * Array based API to read dictionaryIds for an array of docIds\n+   * which are monotonically increasing but not necessarily contiguous\n+   * @param docIds array of docIds to read the dictionaryIds for\n+   * @param docIdStartIndex start index in docIds array\n+   * @param docIdLength length to process in docIds array\n+   * @param values out array to store the dictionaryIds into\n+   * @param valuesStartIndex start index in values array\n+   */\n+  public void readValues(int[] docIds, int docIdStartIndex, int docIdLength, int[] values, int valuesStartIndex) {\n+    int docIdEndIndex = docIdStartIndex + docIdLength - 1;\n+    if (shouldBulkRead(docIds, docIdStartIndex, docIdEndIndex)) {\n+      _dataBitSet.readInt(docIds, docIdStartIndex, docIdLength, values, valuesStartIndex);\n+    } else {\n+      for (int i = docIdStartIndex; i <= docIdEndIndex; i++) {\n+        values[valuesStartIndex++] = _dataBitSet.readInt(docIds[i]);\n+      }\n+    }\n+  }\n+\n+  private boolean shouldBulkRead(int[] docIds, int startIndex, int endIndex) {\n+    int numDocsToRead = endIndex - startIndex + 1;\n+    int docIdRange = docIds[endIndex] - docIds[startIndex] + 1;\n+    if (docIdRange > DocIdSetPlanNode.MAX_DOC_PER_CALL) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a65409f873f3735d34378f4ab3526795f7a919a5"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDE3MzUyMg==", "bodyText": "when you do this, please write a standalone header buffer that can be used in other places", "url": "https://github.com/apache/pinot/pull/5409#discussion_r430173522", "createdAt": "2020-05-26T06:03:56Z", "author": {"login": "kishoreg"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/io/util/FixedBitIntReaderWriterV2.java", "diffHunk": "@@ -0,0 +1,104 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.io.util;\n+\n+import com.google.common.base.Preconditions;\n+import java.io.Closeable;\n+import java.io.IOException;\n+import org.apache.pinot.core.plan.DocIdSetPlanNode;\n+import org.apache.pinot.core.segment.memory.PinotDataBuffer;\n+\n+\n+public final class FixedBitIntReaderWriterV2 implements Closeable {\n+  private volatile PinotDataBitSetV2 _dataBitSet;\n+  private final int _numBitsPerValue;\n+\n+  public FixedBitIntReaderWriterV2(PinotDataBuffer dataBuffer, int numValues, int numBitsPerValue) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk2NzQ2Mg=="}, "originalCommit": {"oid": "a65409f873f3735d34378f4ab3526795f7a919a5"}, "originalPosition": 32}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4NTMxMzE4", "url": "https://github.com/apache/pinot/pull/5409#pullrequestreview-418531318", "createdAt": "2020-05-26T17:42:47Z", "commit": {"oid": "ab19454de0c1c3d3e1fd25e62f682d5cd4f5d210"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxNzo0Mjo0OFrOGapSRA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxNzo1Nzo1MFrOGap1pA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDU5MjU4MA==", "bodyText": "You don't need to make this volatile and set it to null in close(). This issue has been addressed in #4764", "url": "https://github.com/apache/pinot/pull/5409#discussion_r430592580", "createdAt": "2020-05-26T17:42:48Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/io/util/FixedBitIntReaderWriterV2.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.io.util;\n+\n+import com.google.common.base.Preconditions;\n+import java.io.Closeable;\n+import java.io.IOException;\n+import org.apache.pinot.core.plan.DocIdSetPlanNode;\n+import org.apache.pinot.core.segment.memory.PinotDataBuffer;\n+\n+\n+public final class FixedBitIntReaderWriterV2 implements Closeable {\n+  private volatile PinotDataBitSetV2 _dataBitSet;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ab19454de0c1c3d3e1fd25e62f682d5cd4f5d210"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDU5NDY1Nw==", "bodyText": "Don't limit it to dictId and docId in the javadoc. The BitSet is a general reader/writer which can be used for different purposes.", "url": "https://github.com/apache/pinot/pull/5409#discussion_r430594657", "createdAt": "2020-05-26T17:46:18Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/io/util/PinotDataBitSetV2.java", "diffHunk": "@@ -0,0 +1,516 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.io.util;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import org.apache.pinot.core.plan.DocIdSetPlanNode;\n+import org.apache.pinot.core.segment.memory.PinotDataBuffer;\n+\n+\n+public abstract class PinotDataBitSetV2 implements Closeable {\n+  private static final int BYTE_MASK = 0xFF;\n+  static final int MAX_VALUES_UNPACKED_SINGLE_ALIGNED_READ = 16; // comes from 2-bit encoding\n+\n+  private static final ThreadLocal<int[]> THREAD_LOCAL_DICT_IDS =\n+      ThreadLocal.withInitial(() -> new int[DocIdSetPlanNode.MAX_DOC_PER_CALL]);\n+\n+  protected PinotDataBuffer _dataBuffer;\n+  protected int _numBitsPerValue;\n+\n+  /**\n+   * Unpack single dictId at the given docId. This is efficient", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ab19454de0c1c3d3e1fd25e62f682d5cd4f5d210"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDU5NzgwMA==", "bodyText": "For performance concern, we can remove the docIdsStartIndex and outpos and always assume they are 0", "url": "https://github.com/apache/pinot/pull/5409#discussion_r430597800", "createdAt": "2020-05-26T17:51:40Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/io/util/PinotDataBitSetV2.java", "diffHunk": "@@ -0,0 +1,516 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.io.util;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import org.apache.pinot.core.plan.DocIdSetPlanNode;\n+import org.apache.pinot.core.segment.memory.PinotDataBuffer;\n+\n+\n+public abstract class PinotDataBitSetV2 implements Closeable {\n+  private static final int BYTE_MASK = 0xFF;\n+  static final int MAX_VALUES_UNPACKED_SINGLE_ALIGNED_READ = 16; // comes from 2-bit encoding\n+\n+  private static final ThreadLocal<int[]> THREAD_LOCAL_DICT_IDS =\n+      ThreadLocal.withInitial(() -> new int[DocIdSetPlanNode.MAX_DOC_PER_CALL]);\n+\n+  protected PinotDataBuffer _dataBuffer;\n+  protected int _numBitsPerValue;\n+\n+  /**\n+   * Unpack single dictId at the given docId. This is efficient\n+   * because of simplified bitmath.\n+   * @param index docId\n+   * @return unpacked dictId\n+   */\n+  public abstract int readInt(int index);\n+\n+  /**\n+   * Unpack dictIds for a contiguous range of docIds represented by startIndex\n+   * and length. This uses vectorization as much as possible for all the aligned\n+   * reads and also takes care of the small byte-sized window of unaligned read.\n+   * @param startIndex start docId\n+   * @param length length\n+   * @param out out array to store the unpacked dictIds\n+   */\n+  public abstract void readInt(int startIndex, int length, int[] out);\n+\n+  /**\n+   * Unpack dictIds for an array of docIds[] which is not necessarily\n+   * contiguous. So there could be gaps in the array:\n+   * e.g: [1, 3, 7, 9, 11, 12]\n+   * The actual read is done by the previous API since that is efficient\n+   * as it exploits contiguity and uses vectorization. However, since\n+   * the out[] array has to be correctly populated with the unpacked dictId\n+   * for each docId, a post-processing step is needed after the bulk contiguous\n+   * read to correctly set the unpacked dictId into the out array throwing away\n+   * the unnecessary dictIds unpacked as part of contiguous read\n+   * @param docIds docIds array\n+   * @param docIdsStartIndex starting index in the docIds array\n+   * @param length length to read (number of docIds to read in the array)\n+   * @param out out array to store the unpacked dictIds\n+   * @param outpos starting index in the out array\n+   */\n+  public void readInt(int[] docIds, int docIdsStartIndex, int length, int[] out, int outpos) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ab19454de0c1c3d3e1fd25e62f682d5cd4f5d210"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDU5OTQ2Mg==", "bodyText": "This won't work because docIds might not be contiguous and endDocId - startDocId + 1 could be much larger than DocIdSetPlanNode.MAX_DOC_PER_CALL. Also, we should not always do such bulk read, docIds can be very sparse.", "url": "https://github.com/apache/pinot/pull/5409#discussion_r430599462", "createdAt": "2020-05-26T17:54:28Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/io/util/PinotDataBitSetV2.java", "diffHunk": "@@ -0,0 +1,516 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.io.util;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import org.apache.pinot.core.plan.DocIdSetPlanNode;\n+import org.apache.pinot.core.segment.memory.PinotDataBuffer;\n+\n+\n+public abstract class PinotDataBitSetV2 implements Closeable {\n+  private static final int BYTE_MASK = 0xFF;\n+  static final int MAX_VALUES_UNPACKED_SINGLE_ALIGNED_READ = 16; // comes from 2-bit encoding\n+\n+  private static final ThreadLocal<int[]> THREAD_LOCAL_DICT_IDS =\n+      ThreadLocal.withInitial(() -> new int[DocIdSetPlanNode.MAX_DOC_PER_CALL]);\n+\n+  protected PinotDataBuffer _dataBuffer;\n+  protected int _numBitsPerValue;\n+\n+  /**\n+   * Unpack single dictId at the given docId. This is efficient\n+   * because of simplified bitmath.\n+   * @param index docId\n+   * @return unpacked dictId\n+   */\n+  public abstract int readInt(int index);\n+\n+  /**\n+   * Unpack dictIds for a contiguous range of docIds represented by startIndex\n+   * and length. This uses vectorization as much as possible for all the aligned\n+   * reads and also takes care of the small byte-sized window of unaligned read.\n+   * @param startIndex start docId\n+   * @param length length\n+   * @param out out array to store the unpacked dictIds\n+   */\n+  public abstract void readInt(int startIndex, int length, int[] out);\n+\n+  /**\n+   * Unpack dictIds for an array of docIds[] which is not necessarily\n+   * contiguous. So there could be gaps in the array:\n+   * e.g: [1, 3, 7, 9, 11, 12]\n+   * The actual read is done by the previous API since that is efficient\n+   * as it exploits contiguity and uses vectorization. However, since\n+   * the out[] array has to be correctly populated with the unpacked dictId\n+   * for each docId, a post-processing step is needed after the bulk contiguous\n+   * read to correctly set the unpacked dictId into the out array throwing away\n+   * the unnecessary dictIds unpacked as part of contiguous read\n+   * @param docIds docIds array\n+   * @param docIdsStartIndex starting index in the docIds array\n+   * @param length length to read (number of docIds to read in the array)\n+   * @param out out array to store the unpacked dictIds\n+   * @param outpos starting index in the out array\n+   */\n+  public void readInt(int[] docIds, int docIdsStartIndex, int length, int[] out, int outpos) {\n+    int startDocId = docIds[docIdsStartIndex];\n+    int endDocId = docIds[docIdsStartIndex + length - 1];\n+    int[] dictIds = THREAD_LOCAL_DICT_IDS.get();\n+    // do a contiguous bulk read\n+    readInt(startDocId, endDocId - startDocId + 1, dictIds);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ab19454de0c1c3d3e1fd25e62f682d5cd4f5d210"}, "originalPosition": 76}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDYwMDg0Mg==", "bodyText": "Use long to index the dataBuffer so that we can handle big buffer (> 2G)", "url": "https://github.com/apache/pinot/pull/5409#discussion_r430600842", "createdAt": "2020-05-26T17:56:40Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/io/util/PinotDataBitSetV2.java", "diffHunk": "@@ -0,0 +1,516 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.io.util;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import org.apache.pinot.core.plan.DocIdSetPlanNode;\n+import org.apache.pinot.core.segment.memory.PinotDataBuffer;\n+\n+\n+public abstract class PinotDataBitSetV2 implements Closeable {\n+  private static final int BYTE_MASK = 0xFF;\n+  static final int MAX_VALUES_UNPACKED_SINGLE_ALIGNED_READ = 16; // comes from 2-bit encoding\n+\n+  private static final ThreadLocal<int[]> THREAD_LOCAL_DICT_IDS =\n+      ThreadLocal.withInitial(() -> new int[DocIdSetPlanNode.MAX_DOC_PER_CALL]);\n+\n+  protected PinotDataBuffer _dataBuffer;\n+  protected int _numBitsPerValue;\n+\n+  /**\n+   * Unpack single dictId at the given docId. This is efficient\n+   * because of simplified bitmath.\n+   * @param index docId\n+   * @return unpacked dictId\n+   */\n+  public abstract int readInt(int index);\n+\n+  /**\n+   * Unpack dictIds for a contiguous range of docIds represented by startIndex\n+   * and length. This uses vectorization as much as possible for all the aligned\n+   * reads and also takes care of the small byte-sized window of unaligned read.\n+   * @param startIndex start docId\n+   * @param length length\n+   * @param out out array to store the unpacked dictIds\n+   */\n+  public abstract void readInt(int startIndex, int length, int[] out);\n+\n+  /**\n+   * Unpack dictIds for an array of docIds[] which is not necessarily\n+   * contiguous. So there could be gaps in the array:\n+   * e.g: [1, 3, 7, 9, 11, 12]\n+   * The actual read is done by the previous API since that is efficient\n+   * as it exploits contiguity and uses vectorization. However, since\n+   * the out[] array has to be correctly populated with the unpacked dictId\n+   * for each docId, a post-processing step is needed after the bulk contiguous\n+   * read to correctly set the unpacked dictId into the out array throwing away\n+   * the unnecessary dictIds unpacked as part of contiguous read\n+   * @param docIds docIds array\n+   * @param docIdsStartIndex starting index in the docIds array\n+   * @param length length to read (number of docIds to read in the array)\n+   * @param out out array to store the unpacked dictIds\n+   * @param outpos starting index in the out array\n+   */\n+  public void readInt(int[] docIds, int docIdsStartIndex, int length, int[] out, int outpos) {\n+    int startDocId = docIds[docIdsStartIndex];\n+    int endDocId = docIds[docIdsStartIndex + length - 1];\n+    int[] dictIds = THREAD_LOCAL_DICT_IDS.get();\n+    // do a contiguous bulk read\n+    readInt(startDocId, endDocId - startDocId + 1, dictIds);\n+    out[outpos] = dictIds[0];\n+    // set the unpacked dictId correctly. this is needed since there could\n+    // be gaps and some dictIds may have to be thrown/ignored.\n+    for (int i = 1; i < length; i++) {\n+      out[outpos + i] = dictIds[docIds[docIdsStartIndex + i] - startDocId];\n+    }\n+  }\n+\n+  public static PinotDataBitSetV2 createBitSet(PinotDataBuffer pinotDataBuffer, int numBitsPerValue) {\n+    switch (numBitsPerValue) {\n+      case 2:\n+        return new Bit2Encoded(pinotDataBuffer, numBitsPerValue);\n+      case 4:\n+        return new Bit4Encoded(pinotDataBuffer, numBitsPerValue);\n+      case 8:\n+        return new Bit8Encoded(pinotDataBuffer, numBitsPerValue);\n+      case 16:\n+        return new Bit16Encoded(pinotDataBuffer, numBitsPerValue);\n+      case 32:\n+        return new RawInt(pinotDataBuffer, numBitsPerValue);\n+      default:\n+        throw new UnsupportedOperationException(numBitsPerValue + \"not supported by PinotDataBitSetV2\");\n+    }\n+  }\n+\n+  public static class Bit2Encoded extends PinotDataBitSetV2 {\n+    Bit2Encoded(PinotDataBuffer dataBuffer, int numBits) {\n+      _dataBuffer = dataBuffer;\n+      _numBitsPerValue = numBits;\n+    }\n+\n+    @Override\n+    public int readInt(int index) {\n+      long bitOffset = (long) index * _numBitsPerValue;\n+      int byteOffset = (int) (bitOffset / Byte.SIZE);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ab19454de0c1c3d3e1fd25e62f682d5cd4f5d210"}, "originalPosition": 111}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDYwMTYzNg==", "bodyText": "We might also have 0 (all zeros) and 1 (0/1)", "url": "https://github.com/apache/pinot/pull/5409#discussion_r430601636", "createdAt": "2020-05-26T17:57:50Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/io/util/PinotDataBitSetV2.java", "diffHunk": "@@ -0,0 +1,516 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.io.util;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import org.apache.pinot.core.plan.DocIdSetPlanNode;\n+import org.apache.pinot.core.segment.memory.PinotDataBuffer;\n+\n+\n+public abstract class PinotDataBitSetV2 implements Closeable {\n+  private static final int BYTE_MASK = 0xFF;\n+  static final int MAX_VALUES_UNPACKED_SINGLE_ALIGNED_READ = 16; // comes from 2-bit encoding\n+\n+  private static final ThreadLocal<int[]> THREAD_LOCAL_DICT_IDS =\n+      ThreadLocal.withInitial(() -> new int[DocIdSetPlanNode.MAX_DOC_PER_CALL]);\n+\n+  protected PinotDataBuffer _dataBuffer;\n+  protected int _numBitsPerValue;\n+\n+  /**\n+   * Unpack single dictId at the given docId. This is efficient\n+   * because of simplified bitmath.\n+   * @param index docId\n+   * @return unpacked dictId\n+   */\n+  public abstract int readInt(int index);\n+\n+  /**\n+   * Unpack dictIds for a contiguous range of docIds represented by startIndex\n+   * and length. This uses vectorization as much as possible for all the aligned\n+   * reads and also takes care of the small byte-sized window of unaligned read.\n+   * @param startIndex start docId\n+   * @param length length\n+   * @param out out array to store the unpacked dictIds\n+   */\n+  public abstract void readInt(int startIndex, int length, int[] out);\n+\n+  /**\n+   * Unpack dictIds for an array of docIds[] which is not necessarily\n+   * contiguous. So there could be gaps in the array:\n+   * e.g: [1, 3, 7, 9, 11, 12]\n+   * The actual read is done by the previous API since that is efficient\n+   * as it exploits contiguity and uses vectorization. However, since\n+   * the out[] array has to be correctly populated with the unpacked dictId\n+   * for each docId, a post-processing step is needed after the bulk contiguous\n+   * read to correctly set the unpacked dictId into the out array throwing away\n+   * the unnecessary dictIds unpacked as part of contiguous read\n+   * @param docIds docIds array\n+   * @param docIdsStartIndex starting index in the docIds array\n+   * @param length length to read (number of docIds to read in the array)\n+   * @param out out array to store the unpacked dictIds\n+   * @param outpos starting index in the out array\n+   */\n+  public void readInt(int[] docIds, int docIdsStartIndex, int length, int[] out, int outpos) {\n+    int startDocId = docIds[docIdsStartIndex];\n+    int endDocId = docIds[docIdsStartIndex + length - 1];\n+    int[] dictIds = THREAD_LOCAL_DICT_IDS.get();\n+    // do a contiguous bulk read\n+    readInt(startDocId, endDocId - startDocId + 1, dictIds);\n+    out[outpos] = dictIds[0];\n+    // set the unpacked dictId correctly. this is needed since there could\n+    // be gaps and some dictIds may have to be thrown/ignored.\n+    for (int i = 1; i < length; i++) {\n+      out[outpos + i] = dictIds[docIds[docIdsStartIndex + i] - startDocId];\n+    }\n+  }\n+\n+  public static PinotDataBitSetV2 createBitSet(PinotDataBuffer pinotDataBuffer, int numBitsPerValue) {\n+    switch (numBitsPerValue) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ab19454de0c1c3d3e1fd25e62f682d5cd4f5d210"}, "originalPosition": 86}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4NTU1MTI3", "url": "https://github.com/apache/pinot/pull/5409#pullrequestreview-418555127", "createdAt": "2020-05-26T18:12:45Z", "commit": {"oid": "ab19454de0c1c3d3e1fd25e62f682d5cd4f5d210"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxODoxMjo0NlrOGaqbpg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxODoxMjo0NlrOGaqbpg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDYxMTM2Ng==", "bodyText": "Do not close the buffer (see #5400)", "url": "https://github.com/apache/pinot/pull/5409#discussion_r430611366", "createdAt": "2020-05-26T18:12:46Z", "author": {"login": "Jackie-Jiang"}, "path": "pinot-core/src/main/java/org/apache/pinot/core/io/util/PinotDataBitSetV2.java", "diffHunk": "@@ -0,0 +1,516 @@\n+/**\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package org.apache.pinot.core.io.util;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import org.apache.pinot.core.plan.DocIdSetPlanNode;\n+import org.apache.pinot.core.segment.memory.PinotDataBuffer;\n+\n+\n+public abstract class PinotDataBitSetV2 implements Closeable {\n+  private static final int BYTE_MASK = 0xFF;\n+  static final int MAX_VALUES_UNPACKED_SINGLE_ALIGNED_READ = 16; // comes from 2-bit encoding\n+\n+  private static final ThreadLocal<int[]> THREAD_LOCAL_DICT_IDS =\n+      ThreadLocal.withInitial(() -> new int[DocIdSetPlanNode.MAX_DOC_PER_CALL]);\n+\n+  protected PinotDataBuffer _dataBuffer;\n+  protected int _numBitsPerValue;\n+\n+  /**\n+   * Unpack single dictId at the given docId. This is efficient\n+   * because of simplified bitmath.\n+   * @param index docId\n+   * @return unpacked dictId\n+   */\n+  public abstract int readInt(int index);\n+\n+  /**\n+   * Unpack dictIds for a contiguous range of docIds represented by startIndex\n+   * and length. This uses vectorization as much as possible for all the aligned\n+   * reads and also takes care of the small byte-sized window of unaligned read.\n+   * @param startIndex start docId\n+   * @param length length\n+   * @param out out array to store the unpacked dictIds\n+   */\n+  public abstract void readInt(int startIndex, int length, int[] out);\n+\n+  /**\n+   * Unpack dictIds for an array of docIds[] which is not necessarily\n+   * contiguous. So there could be gaps in the array:\n+   * e.g: [1, 3, 7, 9, 11, 12]\n+   * The actual read is done by the previous API since that is efficient\n+   * as it exploits contiguity and uses vectorization. However, since\n+   * the out[] array has to be correctly populated with the unpacked dictId\n+   * for each docId, a post-processing step is needed after the bulk contiguous\n+   * read to correctly set the unpacked dictId into the out array throwing away\n+   * the unnecessary dictIds unpacked as part of contiguous read\n+   * @param docIds docIds array\n+   * @param docIdsStartIndex starting index in the docIds array\n+   * @param length length to read (number of docIds to read in the array)\n+   * @param out out array to store the unpacked dictIds\n+   * @param outpos starting index in the out array\n+   */\n+  public void readInt(int[] docIds, int docIdsStartIndex, int length, int[] out, int outpos) {\n+    int startDocId = docIds[docIdsStartIndex];\n+    int endDocId = docIds[docIdsStartIndex + length - 1];\n+    int[] dictIds = THREAD_LOCAL_DICT_IDS.get();\n+    // do a contiguous bulk read\n+    readInt(startDocId, endDocId - startDocId + 1, dictIds);\n+    out[outpos] = dictIds[0];\n+    // set the unpacked dictId correctly. this is needed since there could\n+    // be gaps and some dictIds may have to be thrown/ignored.\n+    for (int i = 1; i < length; i++) {\n+      out[outpos + i] = dictIds[docIds[docIdsStartIndex + i] - startDocId];\n+    }\n+  }\n+\n+  public static PinotDataBitSetV2 createBitSet(PinotDataBuffer pinotDataBuffer, int numBitsPerValue) {\n+    switch (numBitsPerValue) {\n+      case 2:\n+        return new Bit2Encoded(pinotDataBuffer, numBitsPerValue);\n+      case 4:\n+        return new Bit4Encoded(pinotDataBuffer, numBitsPerValue);\n+      case 8:\n+        return new Bit8Encoded(pinotDataBuffer, numBitsPerValue);\n+      case 16:\n+        return new Bit16Encoded(pinotDataBuffer, numBitsPerValue);\n+      case 32:\n+        return new RawInt(pinotDataBuffer, numBitsPerValue);\n+      default:\n+        throw new UnsupportedOperationException(numBitsPerValue + \"not supported by PinotDataBitSetV2\");\n+    }\n+  }\n+\n+  public static class Bit2Encoded extends PinotDataBitSetV2 {\n+    Bit2Encoded(PinotDataBuffer dataBuffer, int numBits) {\n+      _dataBuffer = dataBuffer;\n+      _numBitsPerValue = numBits;\n+    }\n+\n+    @Override\n+    public int readInt(int index) {\n+      long bitOffset = (long) index * _numBitsPerValue;\n+      int byteOffset = (int) (bitOffset / Byte.SIZE);\n+      int val = (int)_dataBuffer.getByte(byteOffset) & 0xff;\n+      bitOffset = bitOffset & 7;\n+      return  (val >>> (6 - bitOffset)) & 3;\n+    }\n+\n+    @Override\n+    public void readInt(int startIndex, int length, int[] out) {\n+      long bitOffset = (long) startIndex * _numBitsPerValue;\n+      int byteOffset = (int) (bitOffset / Byte.SIZE);\n+      bitOffset = bitOffset & 7;\n+      int packed = 0;\n+      int i = 0;\n+\n+      /*\n+       * Bytes are read as follows to get maximum vectorization\n+       *\n+       * [1 byte] - read from either the 2nd/4th/6th bit to 7th bit to unpack 1/2/3 integers\n+       * [chunks of 4 bytes] - read 4 bytes at a time to unpack 16 integers\n+       * [1 chunk of 2 bytes] - read 2 bytes to unpack 8 integers\n+       * [1 byte] - read the byte to unpack 4 integers\n+       * [1 byte] - unpack 1/2/3 integers from first 2/4/6 bits\n+       */\n+\n+      // unaligned read within a byte\n+      if (bitOffset != 0) {\n+        packed = (int)_dataBuffer.getByte(byteOffset) & 0xff;\n+        if (bitOffset == 2) {\n+          // unpack 3 integers from bits 2-7\n+          out[0] = (packed >>> 4) & 3;\n+          out[1] = (packed >>> 2) & 3;\n+          out[2] = packed & 3;\n+          i = 3;\n+          length -= 3;\n+        }\n+        else if (bitOffset == 4) {\n+          // unpack 2 integers from bits 4 to 7\n+          out[0] = (packed >>> 2) & 3;\n+          out[1] = packed & 3;\n+          i = 2;\n+          length -= 2;\n+        } else {\n+          // unpack integer from bits 6 to 7\n+          out[0] = packed & 3;\n+          i = 1;\n+          length -= 1;\n+        }\n+        byteOffset++;\n+      }\n+\n+      // aligned reads at 4-byte boundary to unpack 16 integers\n+      while (length >= 16) {\n+        packed = _dataBuffer.getInt(byteOffset);\n+        out[i] = packed >>> 30;\n+        out[i + 1] = (packed >>> 28) & 3;\n+        out[i + 2] = (packed >>> 26) & 3;\n+        out[i + 3] = (packed >>> 24) & 3;\n+        out[i + 4] = (packed >>> 22) & 3;\n+        out[i + 5] = (packed >>> 20) & 3;\n+        out[i + 6] = (packed >>> 18) & 3;\n+        out[i + 7] = (packed >>> 16) & 3;\n+        out[i + 8] = (packed >>> 14) & 3;\n+        out[i + 9] = (packed >>> 12) & 3;\n+        out[i + 10] = (packed >>> 10) & 3;\n+        out[i + 11] = (packed >>> 8) & 3;\n+        out[i + 12] = (packed >>> 6) & 3;\n+        out[i + 13] = (packed >>> 4) & 3;\n+        out[i + 14] = (packed >>> 2) & 3;\n+        out[i + 15] = packed & 3;\n+        length -= 16;\n+        byteOffset += 4;\n+        i += 16;\n+      }\n+\n+      if (length >= 8) {\n+        packed = (int)_dataBuffer.getShort(byteOffset) & 0xffff;\n+        out[i] = (packed >>> 14) & 3;\n+        out[i + 1] = (packed >>> 12) & 3;\n+        out[i + 2] = (packed >>> 10) & 3;\n+        out[i + 3] = (packed >>> 8) & 3;\n+        out[i + 4] = (packed >>> 6) & 3;\n+        out[i + 5] = (packed >>> 4) & 3;\n+        out[i + 6] = (packed >>> 2) & 3;\n+        out[i + 7] = packed & 3;\n+        length -= 8;\n+        byteOffset += 2;\n+        i += 8;\n+      }\n+\n+      // aligned read at byte boundary to unpack 4 integers\n+      if (length >= 4) {\n+        packed = (int)_dataBuffer.getByte(byteOffset) & 0xff;\n+        out[i] = packed >>> 6;\n+        out[i + 1] = (packed >>> 4) & 3;\n+        out[i + 2] = (packed >>> 2) & 3;\n+        out[i + 3] = packed & 3;\n+        length -= 4;\n+        byteOffset++;\n+        i += 4;\n+      }\n+\n+      // handle spill-over\n+\n+      if (length > 0) {\n+        // unpack from bits 0-1\n+        packed = (int)_dataBuffer.getByte(byteOffset) & 0xff;\n+        out[i] = packed >>> 6;\n+        length--;\n+      }\n+\n+      if (length > 0) {\n+        // unpack from bits 2-3\n+        out[i + 1] = (packed >>> 4) & 3;\n+        length--;\n+      }\n+\n+      if (length > 0) {\n+        // unpack from bits 4-5\n+        out[i + 2] = (packed >>> 2) & 3;\n+        length--;\n+      }\n+    }\n+  }\n+\n+  public static class Bit4Encoded extends PinotDataBitSetV2 {\n+    Bit4Encoded(PinotDataBuffer dataBuffer, int numBits) {\n+      _dataBuffer = dataBuffer;\n+      _numBitsPerValue = numBits;\n+    }\n+\n+    @Override\n+    public int readInt(int index) {\n+      long bitOffset = (long) index * _numBitsPerValue;\n+      int byteOffset = (int) (bitOffset / Byte.SIZE);\n+      int val = (int)_dataBuffer.getByte(byteOffset) & 0xff;\n+      bitOffset = bitOffset & 7;\n+      return (bitOffset == 0) ? val >>> 4 : val & 0xf;\n+    }\n+\n+    @Override\n+    public void readInt(int startIndex, int length, int[] out) {\n+      long bitOffset = (long) startIndex * _numBitsPerValue;\n+      int byteOffset = (int) (bitOffset / Byte.SIZE);\n+      bitOffset = bitOffset & 7;\n+      int packed = 0;\n+      int i = 0;\n+\n+      /*\n+       * Bytes are read as follows to get maximum vectorization\n+       *\n+       * [1 byte] - read from the 4th bit to 7th bit to unpack 1 integer\n+       * [chunks of 4 bytes] - read 4 bytes at a time to unpack 8 integers\n+       * [1 chunk of 2 bytes] - read 2 bytes to unpack 4 integers\n+       * [1 byte] - unpack 1 integer from first 4 bits\n+       */\n+\n+      // unaligned read within a byte from bits 4-7\n+      if (bitOffset != 0) {\n+        packed = (int)_dataBuffer.getByte(byteOffset) & 0xff;\n+        out[0] = packed & 0xf;\n+        i = 1;\n+        byteOffset++;\n+        length--;\n+      }\n+\n+      // aligned read at 4-byte boundary to unpack 8 integers\n+      while (length >= 8) {\n+        packed = _dataBuffer.getInt(byteOffset);\n+        out[i] = packed >>> 28;\n+        out[i + 1] = (packed >>> 24) & 0xf;\n+        out[i + 2] = (packed >>> 20) & 0xf;\n+        out[i + 3] = (packed >>> 16) & 0xf;\n+        out[i + 4] = (packed >>> 12) & 0xf;\n+        out[i + 5] = (packed >>> 8) & 0xf;\n+        out[i + 6] = (packed >>> 4) & 0xf;\n+        out[i + 7] = packed & 0xf;\n+        length -= 8;\n+        i += 8;\n+        byteOffset += 4;\n+      }\n+\n+      // aligned read at 2-byte boundary to unpack 4 integers\n+      if (length >= 4) {\n+        packed = (int)_dataBuffer.getShort(byteOffset) & 0xffff;\n+        out[i] = (packed >>> 12) & 0xf;\n+        out[i + 1] = (packed >>> 8) & 0xf;\n+        out[i + 2] = (packed >>> 4) & 0xf;\n+        out[i + 3] = packed & 0xf;\n+        length -= 4;\n+        i += 4;\n+        byteOffset += 2;\n+      }\n+\n+      // aligned read at byte boundary to unpack 2 integers\n+      if (length >= 2) {\n+        packed = (int)_dataBuffer.getByte(byteOffset) & 0xff;\n+        out[i] = packed >>> 4;\n+        out[i + 1] = packed & 0xf;\n+        length -= 2;\n+        i += 2;\n+        byteOffset++;\n+      }\n+\n+      // handle spill over -- unpack from bits 0-3\n+      if (length > 0) {\n+        packed = (int)_dataBuffer.getByte(byteOffset) & 0xff;\n+        out[i] = packed >>> 4;\n+        length--;\n+      }\n+    }\n+  }\n+\n+  public static class Bit8Encoded extends PinotDataBitSetV2 {\n+    Bit8Encoded(PinotDataBuffer dataBuffer, int numBits) {\n+      _dataBuffer = dataBuffer;\n+      _numBitsPerValue = numBits;\n+    }\n+\n+    @Override\n+    public int readInt(int index) {\n+      long bitOffset = (long) index * _numBitsPerValue;\n+      int byteOffset = (int) (bitOffset / Byte.SIZE);\n+      return ((int)_dataBuffer.getByte(byteOffset)) & 0xff;\n+    }\n+\n+    @Override\n+    public void readInt(int startIndex, int length, int[] out) {\n+      long bitOffset = (long) startIndex * _numBitsPerValue;\n+      int byteOffset = (int) (bitOffset / Byte.SIZE);\n+      int i = 0;\n+      int packed = 0;\n+\n+      /*\n+       * Bytes are read as follows to get maximum vectorization\n+       *\n+       * [chunks of 4 bytes] - read 4 bytes at a time to unpack 4 integers\n+       * [1 chunk of 2 bytes] - read 2 bytes to unpack 4 integers\n+       * [1 byte] - unpack 1 integer from first 4 bits\n+       */\n+\n+      // aligned read at 4-byte boundary to unpack 4 integers\n+      while (length >= 4) {\n+        packed = _dataBuffer.getInt(byteOffset);\n+        out[i] = packed >>> 24;\n+        out[i + 1] = (packed >>> 16) & 0xff;\n+        out[i + 2] = (packed >>> 8) & 0xff;\n+        out[i + 3] = packed & 0xff;\n+        length -= 4;\n+        byteOffset += 4;\n+        i += 4;\n+      }\n+\n+      // aligned read at 2-byte boundary to unpack 2 integers\n+      if (length >= 2) {\n+        packed = (int)_dataBuffer.getShort(byteOffset) & 0xffff;\n+        out[i] = (packed >>> 8) & 0xff;\n+        out[i + 1] = packed & 0xff;\n+        length -= 2;\n+        byteOffset += 2;\n+        i += 2;\n+      }\n+\n+      // handle spill over at byte boundary to unpack 1 integer\n+      if (length > 0) {\n+        out[i] = (int)_dataBuffer.getByte(byteOffset) & 0xff;\n+        length--;\n+      }\n+    }\n+  }\n+\n+  public static class Bit16Encoded extends PinotDataBitSetV2 {\n+    Bit16Encoded(PinotDataBuffer dataBuffer, int numBits) {\n+      _dataBuffer = dataBuffer;\n+      _numBitsPerValue = numBits;\n+    }\n+\n+    @Override\n+    public int readInt(int index) {\n+      long bitOffset = (long) index * _numBitsPerValue;\n+      int byteOffset = (int) (bitOffset / Byte.SIZE);\n+      return ((int)_dataBuffer.getShort(byteOffset)) & 0xffff;\n+    }\n+\n+    @Override\n+    public void readInt(int startIndex, int length, int[] out) {\n+      long bitOffset = (long) startIndex * _numBitsPerValue;\n+      int byteOffset = (int) (bitOffset / Byte.SIZE);\n+      int i = 0;\n+      int packed;\n+\n+      /*\n+       * Bytes are read as follows to get maximum vectorization\n+       *\n+       * [chunks of 4 bytes] - read 4 bytes at a time to unpack 2 integers\n+       * [1 chunk of 2 bytes] - read 2 bytes to unpack 1 integer\n+       */\n+\n+      // aligned reads at 4-byte boundary to unpack 2 integers\n+      while (length >= 2) {\n+        packed = _dataBuffer.getInt(byteOffset);\n+        out[i] = packed >>> 16;\n+        out[i + 1] = packed & 0xffff;\n+        length -= 2;\n+        i += 2;\n+        byteOffset += 4;\n+      }\n+\n+      // handle spill over at 2-byte boundary to unpack 1 integer\n+      if (length > 0) {\n+        out[i] = (int)_dataBuffer.getShort(byteOffset) & 0xffff;\n+        length--;\n+      }\n+    }\n+  }\n+\n+  public static class RawInt extends PinotDataBitSetV2 {\n+    RawInt(PinotDataBuffer dataBuffer, int numBits) {\n+      _dataBuffer = dataBuffer;\n+      _numBitsPerValue = numBits;\n+    }\n+\n+    @Override\n+    public int readInt(int index) {\n+      return _dataBuffer.getInt(index * Integer.BYTES);\n+    }\n+\n+    @Override\n+    public void readInt(int startIndex, int length, int[] out) {\n+      int byteOffset = startIndex * Integer.BYTES;\n+      for (int i = 0; i < length; i++) {\n+        out[i] = _dataBuffer.getInt(byteOffset);\n+        byteOffset += 4;\n+      }\n+    }\n+  }\n+\n+  protected void writeInt(int index, int value) {\n+    long bitOffset = (long) index * _numBitsPerValue;\n+    int byteOffset = (int) (bitOffset / Byte.SIZE);\n+    int bitOffsetInFirstByte = (int) (bitOffset % Byte.SIZE);\n+\n+    int firstByte = _dataBuffer.getByte(byteOffset);\n+\n+    int firstByteMask = BYTE_MASK >>> bitOffsetInFirstByte;\n+    int numBitsLeft = _numBitsPerValue - (Byte.SIZE - bitOffsetInFirstByte);\n+    if (numBitsLeft <= 0) {\n+      // The value is inside the first byte\n+      firstByteMask &= BYTE_MASK << -numBitsLeft;\n+      _dataBuffer.putByte(byteOffset, (byte) ((firstByte & ~firstByteMask) | (value << -numBitsLeft)));\n+    } else {\n+      // The value is in multiple bytes\n+      _dataBuffer\n+          .putByte(byteOffset, (byte) ((firstByte & ~firstByteMask) | ((value >>> numBitsLeft) & firstByteMask)));\n+      while (numBitsLeft > Byte.SIZE) {\n+        numBitsLeft -= Byte.SIZE;\n+        _dataBuffer.putByte(++byteOffset, (byte) (value >> numBitsLeft));\n+      }\n+      int lastByte = _dataBuffer.getByte(++byteOffset);\n+      _dataBuffer.putByte(byteOffset,\n+          (byte) ((lastByte & (BYTE_MASK >>> numBitsLeft)) | (value << (Byte.SIZE - numBitsLeft))));\n+    }\n+  }\n+\n+  public void writeInt(int startIndex, int length, int[] values) {\n+    long startBitOffset = (long) startIndex * _numBitsPerValue;\n+    int byteOffset = (int) (startBitOffset / Byte.SIZE);\n+    int bitOffsetInFirstByte = (int) (startBitOffset % Byte.SIZE);\n+\n+    int firstByte = _dataBuffer.getByte(byteOffset);\n+\n+    for (int i = 0; i < length; i++) {\n+      int value = values[i];\n+      if (bitOffsetInFirstByte == Byte.SIZE) {\n+        bitOffsetInFirstByte = 0;\n+        firstByte = _dataBuffer.getByte(++byteOffset);\n+      }\n+      int firstByteMask = BYTE_MASK >>> bitOffsetInFirstByte;\n+      int numBitsLeft = _numBitsPerValue - (Byte.SIZE - bitOffsetInFirstByte);\n+      if (numBitsLeft <= 0) {\n+        // The value is inside the first byte\n+        firstByteMask &= BYTE_MASK << -numBitsLeft;\n+        firstByte = ((firstByte & ~firstByteMask) | (value << -numBitsLeft));\n+        _dataBuffer.putByte(byteOffset, (byte) firstByte);\n+        bitOffsetInFirstByte = Byte.SIZE + numBitsLeft;\n+      } else {\n+        // The value is in multiple bytes\n+        _dataBuffer\n+            .putByte(byteOffset, (byte) ((firstByte & ~firstByteMask) | ((value >>> numBitsLeft) & firstByteMask)));\n+        while (numBitsLeft > Byte.SIZE) {\n+          numBitsLeft -= Byte.SIZE;\n+          _dataBuffer.putByte(++byteOffset, (byte) (value >> numBitsLeft));\n+        }\n+        int lastByte = _dataBuffer.getByte(++byteOffset);\n+        firstByte = (lastByte & (0xFF >>> numBitsLeft)) | (value << (Byte.SIZE - numBitsLeft));\n+        _dataBuffer.putByte(byteOffset, (byte) firstByte);\n+        bitOffsetInFirstByte = numBitsLeft;\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public void close()\n+      throws IOException {\n+    _dataBuffer.close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ab19454de0c1c3d3e1fd25e62f682d5cd4f5d210"}, "originalPosition": 514}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7e84e41e7004b4320787011af38e135cd9de3734", "author": {"user": null}, "url": "https://github.com/apache/pinot/commit/7e84e41e7004b4320787011af38e135cd9de3734", "committedDate": "2020-05-28T22:42:41Z", "message": "address review comments and add more benchmarks"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 805, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}