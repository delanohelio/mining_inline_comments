{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzcyMTY5Nzg0", "number": 5056, "title": "[TE] [data-availability] Scheduling of data availability tasks & some clean up", "bodyText": "This PR is part of the effort to enable data availability (SLA) monitoring across metrics/datasets. This particular PR only deals with the scheduling of data availability tasks.\nIt is also worth mentioning that we are dealing with the data availability checks only for detection jobs. In the next phase, we will have a DataSLACronScheduler which will allow users to define custom SLAs independent of detection.\nScheduling Criteria - we schedule a data availability (SLA checker) task in the following cases.\na. Cron based scheduler - Schedule a DA tasks with every detection task.\nb. Event based scheduler - Schedule a DA task whenever we perform a fallback & schedule a detection.\nList of changes:\na. Scheduling logic - schedules Data availability tasks as per the criteria above\nb. Added a counter(ingraph) to track the number of data availability tasks.\nc. Created a  generic ThirdEyeScheduler interface for all the scheduling components.\nd. Renamed DetectionPipelineScheduler to DetectionScheduler and DetectionAlertScheduler  to SubscriptionScheduler.\ne. Created a Task utility class - removed duplicate code & updated all references.\nf: Added Unit test to verify if the data availability tasks are created correctly.", "createdAt": "2020-02-06T23:55:31Z", "url": "https://github.com/apache/pinot/pull/5056", "merged": true, "mergeCommit": {"oid": "7cca1442d7ad41705643862b7237f445e8803368"}, "closed": true, "closedAt": "2020-02-12T19:22:52Z", "author": {"login": "akshayrai"}, "timelineItems": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcBzfQHAH2gAyMzcyMTY5Nzg0OjYyYWI3ODkxNWYwZjQyOWUxNWI5ZWQ3M2JhYTc4NzdjMGZjOTg5NmI=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcDf5CqgFqTM1NzIwNDQ4MA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b", "author": {"user": {"login": "akshayrai", "name": "Akshay Rai"}}, "url": "https://github.com/apache/pinot/commit/62ab78915f0f429e15b9ed73baa7877c0fc9896b", "committedDate": "2020-02-06T23:39:18Z", "message": "Test"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU0ODYyNTQz", "url": "https://github.com/apache/pinot/pull/5056#pullrequestreview-354862543", "createdAt": "2020-02-07T00:19:07Z", "commit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QwMDoxOTowOFrOFmuqkw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QwMDoxOTowOFrOFmuqkw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjE1NDc3MQ==", "bodyText": "I think these name changes are great for adding clarity and consistency", "url": "https://github.com/apache/pinot/pull/5056#discussion_r376154771", "createdAt": "2020-02-07T00:19:08Z", "author": {"login": "harleyjj"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/ThirdEyeAnomalyApplication.java", "diffHunk": "@@ -41,8 +41,8 @@\n import org.apache.pinot.thirdeye.datasource.DAORegistry;\n import org.apache.pinot.thirdeye.datasource.ThirdEyeCacheRegistry;\n import org.apache.pinot.thirdeye.datasource.pinot.resources.PinotDataSourceResource;\n-import org.apache.pinot.thirdeye.detection.DetectionPipelineScheduler;\n-import org.apache.pinot.thirdeye.detection.alert.DetectionAlertScheduler;\n+import org.apache.pinot.thirdeye.scheduler.DetectionScheduler;\n+import org.apache.pinot.thirdeye.scheduler.SubscriptionScheduler;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "originalPosition": 7}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU1MzY0NDQ0", "url": "https://github.com/apache/pinot/pull/5056#pullrequestreview-355364444", "createdAt": "2020-02-07T18:52:53Z", "commit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QxODo1Mjo1M1rOFnG1Mw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QxOToxNjozNlrOFnHeXg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU1MDcwNw==", "bodyText": "Do you suggest to change the naming convention?\nFrom DetectionAlert -> Subscription? We have detection_alert_config_index table and all the subscription tasks are with the name \"detection_alert_xxx\".", "url": "https://github.com/apache/pinot/pull/5056#discussion_r376550707", "createdAt": "2020-02-07T18:52:53Z", "author": {"login": "xiaohui-sun"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/ThirdEyeAnomalyApplication.java", "diffHunk": "@@ -41,8 +41,8 @@\n import org.apache.pinot.thirdeye.datasource.DAORegistry;\n import org.apache.pinot.thirdeye.datasource.ThirdEyeCacheRegistry;\n import org.apache.pinot.thirdeye.datasource.pinot.resources.PinotDataSourceResource;\n-import org.apache.pinot.thirdeye.detection.DetectionPipelineScheduler;\n-import org.apache.pinot.thirdeye.detection.alert.DetectionAlertScheduler;\n+import org.apache.pinot.thirdeye.scheduler.DetectionScheduler;\n+import org.apache.pinot.thirdeye.scheduler.SubscriptionScheduler;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjE1NDc3MQ=="}, "originalCommit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU1NjAxMg==", "bodyText": "\"DataAvailability\" is a heavily overloaded term now.\nWe have DataAvailabilityTaskScheduler which is actually \"EventTriggerTaskScheduler\".\nHere we have another \"data availability\" task. It is too confusing.\nCan you do a refactoring?\nAlso @vincentchenjl  FYI", "url": "https://github.com/apache/pinot/pull/5056#discussion_r376556012", "createdAt": "2020-02-07T19:04:31Z", "author": {"login": "xiaohui-sun"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/detection/trigger/DataAvailabilityTaskScheduler.java", "diffHunk": "@@ -176,35 +198,43 @@ private void populateDetectionMapAndDatasetConfigMap(\n     return res;\n   }\n \n-  private long createDetectionTask(DetectionConfigDTO detectionConfig) throws JsonProcessingException {\n-    long detectionConfigId = detectionConfig.getId();\n+  private DetectionPipelineTaskInfo getDetectionPipelineTaskInfo(DetectionConfigDTO detectionConfig, long end) {\n     // Make sure start time is not out of DETECTION_TASK_MAX_LOOKBACK_WINDOW\n-    long end = System.currentTimeMillis();\n     long start = Math.max(detectionConfig.getLastTimestamp(),\n         end - ThirdEyeUtils.DETECTION_TASK_MAX_LOOKBACK_WINDOW);\n-    DetectionPipelineTaskInfo taskInfo = new DetectionPipelineTaskInfo(detectionConfigId, start, end);\n+\n+    return new DetectionPipelineTaskInfo(detectionConfig.getId(), start, end);\n+  }\n+\n+  private long createTask(TaskConstants.TaskType taskType, DetectionConfigDTO detectionConfig, long end)\n+      throws JsonProcessingException {\n+    DetectionPipelineTaskInfo taskInfo = getDetectionPipelineTaskInfo(detectionConfig, end);\n     String taskInfoJson = OBJECT_MAPPER.writeValueAsString(taskInfo);\n-    TaskDTO taskDTO = new TaskDTO();\n-    taskDTO.setTaskType(TaskConstants.TaskType.DETECTION);\n-    taskDTO.setJobName(TaskConstants.TaskType.DETECTION.toString() + \"_\" + detectionConfigId);\n-    taskDTO.setStatus(TaskConstants.TaskStatus.WAITING);\n-    taskDTO.setTaskInfo(taskInfoJson);\n-    long taskId = taskDAO.save(taskDTO);\n-    LOG.info(\"Created detection pipeline task {} with taskId {}\", taskDTO, taskId);\n-    taskLastCreateTimeMap.put(detectionConfigId, end);\n-    return taskId;\n+    TaskDTO taskDTO = TaskUtils.buildTask(detectionConfig.getId(), taskInfoJson, taskType);\n+    long id = taskDAO.save(taskDTO);\n+    LOG.info(\"Created {} task {} with taskId {}\", taskType, taskDTO, id);\n+    return id;\n+  }\n+\n+  private long createDetectionTask(DetectionConfigDTO detectionConfig, long end) throws JsonProcessingException {\n+    return createTask(TaskConstants.TaskType.DETECTION, detectionConfig, end);\n+  }\n+\n+  private long createDataAvailabilityTask(DetectionConfigDTO detectionConfig, long end) throws JsonProcessingException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "originalPosition": 112}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU1ODQ4MA==", "bodyText": "Why changing the interface to add endtime?", "url": "https://github.com/apache/pinot/pull/5056#discussion_r376558480", "createdAt": "2020-02-07T19:10:07Z", "author": {"login": "xiaohui-sun"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/detection/trigger/DataAvailabilityTaskScheduler.java", "diffHunk": "@@ -95,16 +103,30 @@ public void run() {\n           if (isAllDatasetUpdated(detectionConfig, detection2DatasetMap.get(detectionConfig), datasetConfigMap)) {\n             if (isWithinSchedulingWindow(detection2DatasetMap.get(detectionConfig), datasetConfigMap)) {\n               //TODO: additional check is required if detection is based on aggregated value across multiple data points\n-              createDetectionTask(detectionConfig);\n+              long endtime = System.currentTimeMillis();\n+              createDetectionTask(detectionConfig, endtime);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU2MDE3Ng==", "bodyText": "Do you create data availability task elsewhere? Is this the only place to trigger data availability task?", "url": "https://github.com/apache/pinot/pull/5056#discussion_r376560176", "createdAt": "2020-02-07T19:14:04Z", "author": {"login": "xiaohui-sun"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/detection/trigger/DataAvailabilityTaskScheduler.java", "diffHunk": "@@ -95,16 +103,30 @@ public void run() {\n           if (isAllDatasetUpdated(detectionConfig, detection2DatasetMap.get(detectionConfig), datasetConfigMap)) {\n             if (isWithinSchedulingWindow(detection2DatasetMap.get(detectionConfig), datasetConfigMap)) {\n               //TODO: additional check is required if detection is based on aggregated value across multiple data points\n-              createDetectionTask(detectionConfig);\n+              long endtime = System.currentTimeMillis();\n+              createDetectionTask(detectionConfig, endtime);\n+              detectionIdToWatermarkMap.put(detectionConfig.getId(), endtime);\n               ThirdeyeMetricsUtil.eventScheduledTaskCounter.inc();\n               taskCount++;\n             } else {\n               LOG.warn(\"Unable to schedule a task for {}, because it is out of scheduling window.\", detectionConfigId);\n             }\n           }\n+\n+          // Note: Fallback SLA & Data availability SLA are independent of each other.\n+          // For example, if an event doesn't arrive within 24 hours, do a fallback.\n+          // On the other hand, a user can setup an SLA alert if there is no data for 3 days.\n           if (needFallback(detectionConfig)) {\n             LOG.info(\"Scheduling a task for detection {} due to the fallback mechanism.\", detectionConfigId);\n-            createDetectionTask(detectionConfig);\n+            long endtime = System.currentTimeMillis();\n+            createDetectionTask(detectionConfig, endtime);\n+\n+            if (DetectionUtils.isDataAvailabilityCheckEnabled(detectionConfig)) {\n+              createDataAvailabilityTask(detectionConfig, endtime);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU2MTI0Ng==", "bodyText": "Do we only run availability detection together with the normal detection job?", "url": "https://github.com/apache/pinot/pull/5056#discussion_r376561246", "createdAt": "2020-02-07T19:16:36Z", "author": {"login": "xiaohui-sun"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/scheduler/DetectionScheduler.java", "diffHunk": "@@ -120,34 +126,41 @@ public void run() {\n           LOG.error(\"Error removing job key {}\", jobKey);\n         }\n       }\n-\n     } catch (SchedulerException e) {\n       LOG.error(\"Error while scheduling detection pipeline\", e);\n     }\n   }\n \n-  private boolean jobUpdated(DetectionConfigDTO config, JobKey key) throws SchedulerException {\n-    List<Trigger> triggers = (List<Trigger>) scheduler.getTriggersOfJob(key);\n-    CronTrigger cronTrigger = (CronTrigger) triggers.get(0);\n-    String cronInSchedule = cronTrigger.getCronExpression();\n+  @Override\n+  public Set<JobKey> getScheduledJobs() throws SchedulerException {\n+    return this.scheduler.getJobKeys(GroupMatcher.jobGroupEquals(TaskConstants.TaskType.DETECTION.toString()));\n+  }\n \n-    if (!config.getCron().equals(cronInSchedule)) {\n-      LOG.info(\"Cron expression for detection pipeline {} has been changed from {}  to {}. \" + \"Restarting schedule\",\n-          config.getId(), cronInSchedule, config.getCron());\n-      return true;\n-    }\n-    return false;\n+  @Override\n+  public void shutdown() throws SchedulerException {\n+    AnomalyUtils.safelyShutdownExecutionService(executorService, this.getClass());\n+    scheduler.shutdown();\n   }\n \n-  private void startJob(DetectionConfigDTO config, JobKey key) throws SchedulerException {\n-    Trigger trigger =\n-        TriggerBuilder.newTrigger().withSchedule(CronScheduleBuilder.cronSchedule(config.getCron())).build();\n-    JobDetail job = JobBuilder.newJob(DetectionPipelineJob.class).withIdentity(key).build();\n-    this.scheduler.scheduleJob(job, trigger);\n-    LOG.info(String.format(\"scheduled detection pipeline job %s.\", key.getName()));\n+  @Override\n+  public void startJob(AbstractBean config, JobKey key) throws SchedulerException {\n+    Trigger trigger = TriggerBuilder.newTrigger().withSchedule(\n+        CronScheduleBuilder.cronSchedule(((DetectionConfigBean) config).getCron())).build();\n+    JobDetail detectionJob = JobBuilder.newJob(DetectionPipelineJob.class).withIdentity(key).build();\n+\n+    this.scheduler.scheduleJob(detectionJob, trigger);\n+    LOG.info(String.format(\"scheduled detection pipeline job %s\", detectionJob.getKey().getName()));\n+\n+    // Data availability alerts will be scheduled only when enabled by the user.\n+    if (DetectionUtils.isDataAvailabilityCheckEnabled((DetectionConfigDTO) config)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "originalPosition": 150}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU1NDE0OTM5", "url": "https://github.com/apache/pinot/pull/5056#pullrequestreview-355414939", "createdAt": "2020-02-07T20:22:40Z", "commit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QyMDoyMjo0MFrOFnJNzg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QyMjowOTowOVrOFnLtww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU4OTc3NA==", "bodyText": "Maybe we can rename it to something like detectionIdToLastTaskCreateTimeMap? Because I think watermark is also overloaded in the context.  \ud83d\ude42\nNot clear whether it's the detection last time stamp, task create time or the latest data point.", "url": "https://github.com/apache/pinot/pull/5056#discussion_r376589774", "createdAt": "2020-02-07T20:22:40Z", "author": {"login": "jihaozh"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/detection/trigger/DataAvailabilityTaskScheduler.java", "diffHunk": "@@ -74,7 +82,7 @@ public DataAvailabilityTaskScheduler(long delayInSec, long fallBackTimeInSec, lo\n     this.delayInSec = delayInSec;\n     this.fallBackTimeInSec = fallBackTimeInSec;\n     this.schedulingWindowInSec = schedulingWindowInSec;\n-    this.taskLastCreateTimeMap = new HashMap<>();\n+    this.detectionIdToWatermarkMap = new HashMap<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjYzMDcyMw==", "bodyText": "Does the availability task and the detection task share the same cron?", "url": "https://github.com/apache/pinot/pull/5056#discussion_r376630723", "createdAt": "2020-02-07T22:09:09Z", "author": {"login": "jihaozh"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/scheduler/DetectionScheduler.java", "diffHunk": "@@ -120,34 +126,41 @@ public void run() {\n           LOG.error(\"Error removing job key {}\", jobKey);\n         }\n       }\n-\n     } catch (SchedulerException e) {\n       LOG.error(\"Error while scheduling detection pipeline\", e);\n     }\n   }\n \n-  private boolean jobUpdated(DetectionConfigDTO config, JobKey key) throws SchedulerException {\n-    List<Trigger> triggers = (List<Trigger>) scheduler.getTriggersOfJob(key);\n-    CronTrigger cronTrigger = (CronTrigger) triggers.get(0);\n-    String cronInSchedule = cronTrigger.getCronExpression();\n+  @Override\n+  public Set<JobKey> getScheduledJobs() throws SchedulerException {\n+    return this.scheduler.getJobKeys(GroupMatcher.jobGroupEquals(TaskConstants.TaskType.DETECTION.toString()));\n+  }\n \n-    if (!config.getCron().equals(cronInSchedule)) {\n-      LOG.info(\"Cron expression for detection pipeline {} has been changed from {}  to {}. \" + \"Restarting schedule\",\n-          config.getId(), cronInSchedule, config.getCron());\n-      return true;\n-    }\n-    return false;\n+  @Override\n+  public void shutdown() throws SchedulerException {\n+    AnomalyUtils.safelyShutdownExecutionService(executorService, this.getClass());\n+    scheduler.shutdown();\n   }\n \n-  private void startJob(DetectionConfigDTO config, JobKey key) throws SchedulerException {\n-    Trigger trigger =\n-        TriggerBuilder.newTrigger().withSchedule(CronScheduleBuilder.cronSchedule(config.getCron())).build();\n-    JobDetail job = JobBuilder.newJob(DetectionPipelineJob.class).withIdentity(key).build();\n-    this.scheduler.scheduleJob(job, trigger);\n-    LOG.info(String.format(\"scheduled detection pipeline job %s.\", key.getName()));\n+  @Override\n+  public void startJob(AbstractBean config, JobKey key) throws SchedulerException {\n+    Trigger trigger = TriggerBuilder.newTrigger().withSchedule(\n+        CronScheduleBuilder.cronSchedule(((DetectionConfigBean) config).getCron())).build();\n+    JobDetail detectionJob = JobBuilder.newJob(DetectionPipelineJob.class).withIdentity(key).build();\n+\n+    this.scheduler.scheduleJob(detectionJob, trigger);\n+    LOG.info(String.format(\"scheduled detection pipeline job %s\", detectionJob.getKey().getName()));\n+\n+    // Data availability alerts will be scheduled only when enabled by the user.\n+    if (DetectionUtils.isDataAvailabilityCheckEnabled((DetectionConfigDTO) config)) {\n+      JobDetail dataAvailabilityJob = JobBuilder.newJob(DetectionDataAvailabilityJob.class).withIdentity(key).build();\n+      this.scheduler.scheduleJob(dataAvailabilityJob, trigger);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "originalPosition": 152}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU1NDc0OTY5", "url": "https://github.com/apache/pinot/pull/5056#pullrequestreview-355474969", "createdAt": "2020-02-07T22:28:45Z", "commit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QyMjoyODo0NVrOFnMIiA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QyMzowODoxOFrOFnM3Kg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjYzNzU3Ng==", "bodyText": "+1\nThe only case that it stores watermark is when there is no task for the detection at all, which should be minor case.", "url": "https://github.com/apache/pinot/pull/5056#discussion_r376637576", "createdAt": "2020-02-07T22:28:45Z", "author": {"login": "vincentchenjl"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/detection/trigger/DataAvailabilityTaskScheduler.java", "diffHunk": "@@ -74,7 +82,7 @@ public DataAvailabilityTaskScheduler(long delayInSec, long fallBackTimeInSec, lo\n     this.delayInSec = delayInSec;\n     this.fallBackTimeInSec = fallBackTimeInSec;\n     this.schedulingWindowInSec = schedulingWindowInSec;\n-    this.taskLastCreateTimeMap = new HashMap<>();\n+    this.detectionIdToWatermarkMap = new HashMap<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU4OTc3NA=="}, "originalCommit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjYzOTkwOA==", "bodyText": "DetectionScheduler can probably be changed to DetectionCronScheduler, since it is not the only scheduler to schedule detection tasks and it is the only cron based scheduler for detection.", "url": "https://github.com/apache/pinot/pull/5056#discussion_r376639908", "createdAt": "2020-02-07T22:36:11Z", "author": {"login": "vincentchenjl"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/ThirdEyeAnomalyApplication.java", "diffHunk": "@@ -41,8 +41,8 @@\n import org.apache.pinot.thirdeye.datasource.DAORegistry;\n import org.apache.pinot.thirdeye.datasource.ThirdEyeCacheRegistry;\n import org.apache.pinot.thirdeye.datasource.pinot.resources.PinotDataSourceResource;\n-import org.apache.pinot.thirdeye.detection.DetectionPipelineScheduler;\n-import org.apache.pinot.thirdeye.detection.alert.DetectionAlertScheduler;\n+import org.apache.pinot.thirdeye.scheduler.DetectionScheduler;\n+import org.apache.pinot.thirdeye.scheduler.SubscriptionScheduler;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjE1NDc3MQ=="}, "originalCommit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjY0MzYyNw==", "bodyText": "My thought here is that we keep DataAvailabilityTaskScheduler here, because all these tasks are scheduled based on data availability.  I agree that createDataAvailabilityTask is still confusing with the DataAvailabilityTaskScheduler, so maybe we can change it to createDataSLACheckTask, which is more descriptive.", "url": "https://github.com/apache/pinot/pull/5056#discussion_r376643627", "createdAt": "2020-02-07T22:49:12Z", "author": {"login": "vincentchenjl"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/detection/trigger/DataAvailabilityTaskScheduler.java", "diffHunk": "@@ -176,35 +198,43 @@ private void populateDetectionMapAndDatasetConfigMap(\n     return res;\n   }\n \n-  private long createDetectionTask(DetectionConfigDTO detectionConfig) throws JsonProcessingException {\n-    long detectionConfigId = detectionConfig.getId();\n+  private DetectionPipelineTaskInfo getDetectionPipelineTaskInfo(DetectionConfigDTO detectionConfig, long end) {\n     // Make sure start time is not out of DETECTION_TASK_MAX_LOOKBACK_WINDOW\n-    long end = System.currentTimeMillis();\n     long start = Math.max(detectionConfig.getLastTimestamp(),\n         end - ThirdEyeUtils.DETECTION_TASK_MAX_LOOKBACK_WINDOW);\n-    DetectionPipelineTaskInfo taskInfo = new DetectionPipelineTaskInfo(detectionConfigId, start, end);\n+\n+    return new DetectionPipelineTaskInfo(detectionConfig.getId(), start, end);\n+  }\n+\n+  private long createTask(TaskConstants.TaskType taskType, DetectionConfigDTO detectionConfig, long end)\n+      throws JsonProcessingException {\n+    DetectionPipelineTaskInfo taskInfo = getDetectionPipelineTaskInfo(detectionConfig, end);\n     String taskInfoJson = OBJECT_MAPPER.writeValueAsString(taskInfo);\n-    TaskDTO taskDTO = new TaskDTO();\n-    taskDTO.setTaskType(TaskConstants.TaskType.DETECTION);\n-    taskDTO.setJobName(TaskConstants.TaskType.DETECTION.toString() + \"_\" + detectionConfigId);\n-    taskDTO.setStatus(TaskConstants.TaskStatus.WAITING);\n-    taskDTO.setTaskInfo(taskInfoJson);\n-    long taskId = taskDAO.save(taskDTO);\n-    LOG.info(\"Created detection pipeline task {} with taskId {}\", taskDTO, taskId);\n-    taskLastCreateTimeMap.put(detectionConfigId, end);\n-    return taskId;\n+    TaskDTO taskDTO = TaskUtils.buildTask(detectionConfig.getId(), taskInfoJson, taskType);\n+    long id = taskDAO.save(taskDTO);\n+    LOG.info(\"Created {} task {} with taskId {}\", taskType, taskDTO, id);\n+    return id;\n+  }\n+\n+  private long createDetectionTask(DetectionConfigDTO detectionConfig, long end) throws JsonProcessingException {\n+    return createTask(TaskConstants.TaskType.DETECTION, detectionConfig, end);\n+  }\n+\n+  private long createDataAvailabilityTask(DetectionConfigDTO detectionConfig, long end) throws JsonProcessingException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU1NjAxMg=="}, "originalCommit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "originalPosition": 112}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjY0Mzk1NQ==", "bodyText": "Why this line is only executed whenDetectionUtils.isDataAvailabilityCheckEnabled(detectionConfig) is true?", "url": "https://github.com/apache/pinot/pull/5056#discussion_r376643955", "createdAt": "2020-02-07T22:50:22Z", "author": {"login": "vincentchenjl"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/anomaly/detection/trigger/DataAvailabilityTaskScheduler.java", "diffHunk": "@@ -95,16 +103,30 @@ public void run() {\n           if (isAllDatasetUpdated(detectionConfig, detection2DatasetMap.get(detectionConfig), datasetConfigMap)) {\n             if (isWithinSchedulingWindow(detection2DatasetMap.get(detectionConfig), datasetConfigMap)) {\n               //TODO: additional check is required if detection is based on aggregated value across multiple data points\n-              createDetectionTask(detectionConfig);\n+              long endtime = System.currentTimeMillis();\n+              createDetectionTask(detectionConfig, endtime);\n+              detectionIdToWatermarkMap.put(detectionConfig.getId(), endtime);\n               ThirdeyeMetricsUtil.eventScheduledTaskCounter.inc();\n               taskCount++;\n             } else {\n               LOG.warn(\"Unable to schedule a task for {}, because it is out of scheduling window.\", detectionConfigId);\n             }\n           }\n+\n+          // Note: Fallback SLA & Data availability SLA are independent of each other.\n+          // For example, if an event doesn't arrive within 24 hours, do a fallback.\n+          // On the other hand, a user can setup an SLA alert if there is no data for 3 days.\n           if (needFallback(detectionConfig)) {\n             LOG.info(\"Scheduling a task for detection {} due to the fallback mechanism.\", detectionConfigId);\n-            createDetectionTask(detectionConfig);\n+            long endtime = System.currentTimeMillis();\n+            createDetectionTask(detectionConfig, endtime);\n+\n+            if (DetectionUtils.isDataAvailabilityCheckEnabled(detectionConfig)) {\n+              createDataAvailabilityTask(detectionConfig, endtime);\n+              LOG.info(\"Scheduling a task for data availability {} due to the fallback mechanism.\", detectionConfigId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjY0OTUxNA==", "bodyText": "Should we can call it ThirdEyeCronScheduler to be more specific? I am not sure the interfaces defined here apply to any scheduler that listens to external events, data availability for instance. Even we can put the instance of Quatz scheuler here.", "url": "https://github.com/apache/pinot/pull/5056#discussion_r376649514", "createdAt": "2020-02-07T23:08:18Z", "author": {"login": "vincentchenjl"}, "path": "thirdeye/thirdeye-pinot/src/main/java/org/apache/pinot/thirdeye/scheduler/ThirdEyeScheduler.java", "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ *\n+ *  * Licensed to the Apache Software Foundation (ASF) under one\n+ *  * or more contributor license agreements.  See the NOTICE file\n+ *  * distributed with this work for additional information\n+ *  * regarding copyright ownership.  The ASF licenses this file\n+ *  * to you under the Apache License, Version 2.0 (the\n+ *  * \"License\"); you may not use this file except in compliance\n+ *  * with the License.  You may obtain a copy of the License at\n+ *  *\n+ *  *   http://www.apache.org/licenses/LICENSE-2.0\n+ *  *\n+ *  * Unless required by applicable law or agreed to in writing,\n+ *  * software distributed under the License is distributed on an\n+ *  * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ *  * KIND, either express or implied.  See the License for the\n+ *  * specific language governing permissions and limitations\n+ *  * under the License.\n+ *\n+ *\n+ */\n+\n+package org.apache.pinot.thirdeye.scheduler;\n+\n+import java.util.Set;\n+import org.apache.pinot.thirdeye.datalayer.pojo.AbstractBean;\n+import org.quartz.JobKey;\n+import org.quartz.SchedulerException;\n+\n+\n+/**\n+ * Interface for ThirdEye's scheduling components\n+ */\n+public interface ThirdEyeScheduler extends Runnable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62ab78915f0f429e15b9ed73baa7877c0fc9896b"}, "originalPosition": 34}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ac2f5cb3fd7b6b4dd1f4e55c24931b2f0854e623", "author": {"user": {"login": "akshayrai", "name": "Akshay Rai"}}, "url": "https://github.com/apache/pinot/commit/ac2f5cb3fd7b6b4dd1f4e55c24931b2f0854e623", "committedDate": "2020-02-11T23:27:52Z", "message": "[TE] renaming classes and introduce some naming convention"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU3MjA0NDgw", "url": "https://github.com/apache/pinot/pull/5056#pullrequestreview-357204480", "createdAt": "2020-02-12T05:57:13Z", "commit": {"oid": "ac2f5cb3fd7b6b4dd1f4e55c24931b2f0854e623"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1264, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}