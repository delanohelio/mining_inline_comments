{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzk5NDE0NDE2", "number": 4233, "title": "Process execution metrics", "bodyText": "Description\nDuring the engine latency investigation we created several new metrics to investigate the behavior and have better insights into the system latency.\nNew Metrics which are added by this PR:\n\nprocess execution time, shows the time between creating and completing/terminating a workflow instance\njob activation time, shows the time between creating an job and activating it\njob lifetime, show the time between creating an job and completing it\n\nNew latency metris look like this:\n\nPull Request Checklist\n\n All commit messages match our commit message guidelines\n The submitting code follows our code style\n If submitting code, please run mvn clean install -DskipTests locally before committing", "createdAt": "2020-04-06T06:37:50Z", "url": "https://github.com/camunda-cloud/zeebe/pull/4233", "merged": true, "mergeCommit": {"oid": "baa8c70f443fcc14e78fbf1bbd60d2a9b5d75f1b"}, "closed": true, "closedAt": "2020-04-15T08:26:48Z", "author": {"login": "Zelldon"}, "timelineItems": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcU_CNaAFqTM4ODI0NjQyMQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcXzPOsABqjMyMzQyNTY1NjM=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg4MjQ2NDIx", "url": "https://github.com/camunda-cloud/zeebe/pull/4233#pullrequestreview-388246421", "createdAt": "2020-04-06T13:27:01Z", "commit": {"oid": "b41991df06e7991e64b2d6f797c9a602fc5b9c3d"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxMzoyNzowMlrOGBXoDw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxMzoyOTo0OFrOGBXvqg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDA4ODg0Nw==", "bodyText": "Nipick: Can we pass the elapsed time directly so we don't use ActorClock directly here? Just seems strange to couple this to the ActorClock here\nEDIT: same below I guess", "url": "https://github.com/camunda-cloud/zeebe/pull/4233#discussion_r404088847", "createdAt": "2020-04-06T13:27:02Z", "author": {"login": "npepinpe"}, "path": "engine/src/main/java/io/zeebe/engine/metrics/ExecutionMetrics.java", "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.engine.metrics;\n+\n+import io.prometheus.client.Histogram;\n+import io.zeebe.util.sched.clock.ActorClock;\n+\n+public class ExecutionMetrics {\n+\n+  private static final Histogram WORKFLOW_INSTANCE_EXECUTION =\n+      Histogram.build()\n+          .namespace(\"zeebe\")\n+          .name(\"workflow_instance_execution_time\")\n+          .help(\"The execution time of processing a complete workflow instance\")\n+          .labelNames(\"partition\")\n+          .register();\n+\n+  private final String partitionIdLabel;\n+\n+  public ExecutionMetrics(final int partitionId) {\n+    this.partitionIdLabel = String.valueOf(partitionId);\n+  }\n+\n+  public void observeWorkflowInstanceExecutionTime(final long created) {\n+    WORKFLOW_INSTANCE_EXECUTION\n+        .labels(partitionIdLabel)\n+        .observe((ActorClock.currentTimeMillis() - created) / 1000f);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b41991df06e7991e64b2d6f797c9a602fc5b9c3d"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDA4OTY1OA==", "bodyText": "Weren't you the one who asked not to create new column families? \ud83d\ude1c", "url": "https://github.com/camunda-cloud/zeebe/pull/4233#discussion_r404089658", "createdAt": "2020-04-06T13:28:10Z", "author": {"login": "npepinpe"}, "path": "engine/src/main/java/io/zeebe/engine/state/ZbColumnFamilies.java", "diffHunk": "@@ -42,6 +42,7 @@\n \n   // jobs\n   JOBS,\n+  JOBS_CREATION,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b41991df06e7991e64b2d6f797c9a602fc5b9c3d"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDA5MDc5NA==", "bodyText": "Hm, don't know how I feel about using the ActorClock as a default, which has different behaviour based on which thread calls it \ud83d\ude05\nAlso, what about existing instances? Will this metric give me initially incredibly fast jobs since creation time will be instantiated with the current timestamp? \ud83d\ude05", "url": "https://github.com/camunda-cloud/zeebe/pull/4233#discussion_r404090794", "createdAt": "2020-04-06T13:29:48Z", "author": {"login": "npepinpe"}, "path": "engine/src/main/java/io/zeebe/engine/state/instance/ElementInstance.java", "diffHunk": "@@ -15,10 +15,13 @@\n import io.zeebe.msgpack.property.ObjectProperty;\n import io.zeebe.protocol.impl.record.value.workflowinstance.WorkflowInstanceRecord;\n import io.zeebe.protocol.record.intent.WorkflowInstanceIntent;\n+import io.zeebe.util.sched.clock.ActorClock;\n \n public final class ElementInstance extends UnpackedObject implements DbValue {\n \n   private final LongProperty parentKeyProp = new LongProperty(\"parentKey\", -1L);\n+  private final LongProperty creationTimeProp =\n+      new LongProperty(\"creationTime\", ActorClock.currentTimeMillis());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b41991df06e7991e64b2d6f797c9a602fc5b9c3d"}, "originalPosition": 10}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "084092f49f231b9d0fdbe99634319ff664e8e23e", "author": {"user": {"login": "Zelldon", "name": "Christopher Zell"}}, "url": "https://github.com/camunda-cloud/zeebe/commit/084092f49f231b9d0fdbe99634319ff664e8e23e", "committedDate": "2020-04-08T14:51:07Z", "message": "chore(monitor): add latency metrics to dashboard"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b41991df06e7991e64b2d6f797c9a602fc5b9c3d", "author": {"user": {"login": "Zelldon", "name": "Christopher Zell"}}, "url": "https://github.com/camunda-cloud/zeebe/commit/b41991df06e7991e64b2d6f797c9a602fc5b9c3d", "committedDate": "2020-04-06T06:34:10Z", "message": "chore(monitor): add latency metrics to dashboard"}, "afterCommit": {"oid": "13b2b31f9159d7d834cd2ed758eb9e178046108b", "author": {"user": {"login": "Zelldon", "name": "Christopher Zell"}}, "url": "https://github.com/camunda-cloud/zeebe/commit/13b2b31f9159d7d834cd2ed758eb9e178046108b", "committedDate": "2020-04-08T14:55:15Z", "message": "chore(benchmarks): enable metrics exporter"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkyOTg5NzQ3", "url": "https://github.com/camunda-cloud/zeebe/pull/4233#pullrequestreview-392989747", "createdAt": "2020-04-14T14:35:16Z", "commit": {"oid": "13b2b31f9159d7d834cd2ed758eb9e178046108b"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQxNDozNToxNlrOGFRtEg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQxOTowMzo1OFrOGFc0uA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE4NjEzMA==", "bodyText": "Nitpick: do we need to know from the variable name that it is a tree map? I guess creationTimeToJobKeyNavigableMap doesn't have the same ring ;) I guess I'm just surprised since we don't really want to care about the concrete time except when creating it \ud83e\udd37\u200d\u2642\ufe0f\nJust a nitpick, feel free to ignore", "url": "https://github.com/camunda-cloud/zeebe/pull/4233#discussion_r408186130", "createdAt": "2020-04-14T14:35:16Z", "author": {"login": "npepinpe"}, "path": "broker/src/main/java/io/zeebe/broker/exporter/metrics/MetricsExporter.java", "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.exporter.metrics;\n+\n+import io.zeebe.broker.system.configuration.ExporterCfg;\n+import io.zeebe.exporter.api.Exporter;\n+import io.zeebe.exporter.api.context.Controller;\n+import io.zeebe.protocol.record.Record;\n+import io.zeebe.protocol.record.RecordType;\n+import io.zeebe.protocol.record.ValueType;\n+import io.zeebe.protocol.record.intent.JobIntent;\n+import io.zeebe.protocol.record.intent.WorkflowInstanceIntent;\n+import io.zeebe.protocol.record.value.WorkflowInstanceRecordValue;\n+import java.time.Duration;\n+import java.util.NavigableMap;\n+import java.util.TreeMap;\n+import org.agrona.collections.Long2LongHashMap;\n+\n+public class MetricsExporter implements Exporter {\n+\n+  public static final Duration TIME_TO_LIVE = Duration.ofSeconds(10);\n+  private final ExecutionLatencyMetrics executionLatencyMetrics;\n+  private final Long2LongHashMap jobKeyToCreationTimeMap;\n+  private final Long2LongHashMap workflowInstanceKeyToCreationTimeMap;\n+\n+  private final NavigableMap<Long, Long> creationTimeToJobKeyTreeMap;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13b2b31f9159d7d834cd2ed758eb9e178046108b"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE4ODA1OA==", "bodyText": "Nitpick: any reason to use the concrete type instead of Map<Long, Long>?", "url": "https://github.com/camunda-cloud/zeebe/pull/4233#discussion_r408188058", "createdAt": "2020-04-14T14:37:44Z", "author": {"login": "npepinpe"}, "path": "broker/src/main/java/io/zeebe/broker/exporter/metrics/MetricsExporter.java", "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.exporter.metrics;\n+\n+import io.zeebe.broker.system.configuration.ExporterCfg;\n+import io.zeebe.exporter.api.Exporter;\n+import io.zeebe.exporter.api.context.Controller;\n+import io.zeebe.protocol.record.Record;\n+import io.zeebe.protocol.record.RecordType;\n+import io.zeebe.protocol.record.ValueType;\n+import io.zeebe.protocol.record.intent.JobIntent;\n+import io.zeebe.protocol.record.intent.WorkflowInstanceIntent;\n+import io.zeebe.protocol.record.value.WorkflowInstanceRecordValue;\n+import java.time.Duration;\n+import java.util.NavigableMap;\n+import java.util.TreeMap;\n+import org.agrona.collections.Long2LongHashMap;\n+\n+public class MetricsExporter implements Exporter {\n+\n+  public static final Duration TIME_TO_LIVE = Duration.ofSeconds(10);\n+  private final ExecutionLatencyMetrics executionLatencyMetrics;\n+  private final Long2LongHashMap jobKeyToCreationTimeMap;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13b2b31f9159d7d834cd2ed758eb9e178046108b"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODM1ODYxNQ==", "bodyText": "How likely is it to get collision? If we write a batch of follow up events, it's likely they all have the same creation time, no? Especially if we use the ActorClock? Could we end up with \"garbage\" over time? I put it in quotes since technically we should eventually see the completion record for that entity, but still.", "url": "https://github.com/camunda-cloud/zeebe/pull/4233#discussion_r408358615", "createdAt": "2020-04-14T18:47:49Z", "author": {"login": "npepinpe"}, "path": "broker/src/main/java/io/zeebe/broker/exporter/metrics/MetricsExporter.java", "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.exporter.metrics;\n+\n+import io.zeebe.broker.system.configuration.ExporterCfg;\n+import io.zeebe.exporter.api.Exporter;\n+import io.zeebe.exporter.api.context.Controller;\n+import io.zeebe.protocol.record.Record;\n+import io.zeebe.protocol.record.RecordType;\n+import io.zeebe.protocol.record.ValueType;\n+import io.zeebe.protocol.record.intent.JobIntent;\n+import io.zeebe.protocol.record.intent.WorkflowInstanceIntent;\n+import io.zeebe.protocol.record.value.WorkflowInstanceRecordValue;\n+import java.time.Duration;\n+import java.util.NavigableMap;\n+import java.util.TreeMap;\n+import org.agrona.collections.Long2LongHashMap;\n+\n+public class MetricsExporter implements Exporter {\n+\n+  public static final Duration TIME_TO_LIVE = Duration.ofSeconds(10);\n+  private final ExecutionLatencyMetrics executionLatencyMetrics;\n+  private final Long2LongHashMap jobKeyToCreationTimeMap;\n+  private final Long2LongHashMap workflowInstanceKeyToCreationTimeMap;\n+\n+  private final NavigableMap<Long, Long> creationTimeToJobKeyTreeMap;\n+  private final NavigableMap<Long, Long> creationTimeToWorkflowInstanceKeyTreeMap;\n+\n+  private Controller controller;\n+\n+  public MetricsExporter() {\n+    this.executionLatencyMetrics = new ExecutionLatencyMetrics();\n+    this.jobKeyToCreationTimeMap = new Long2LongHashMap(-1);\n+    this.workflowInstanceKeyToCreationTimeMap = new Long2LongHashMap(-1);\n+    this.creationTimeToJobKeyTreeMap = new TreeMap<>();\n+    this.creationTimeToWorkflowInstanceKeyTreeMap = new TreeMap<>();\n+  }\n+\n+  @Override\n+  public void open(final Controller controller) {\n+    this.controller = controller;\n+\n+    controller.scheduleTask(TIME_TO_LIVE, this::cleanUp);\n+  }\n+\n+  @Override\n+  public void close() {\n+    jobKeyToCreationTimeMap.clear();\n+    workflowInstanceKeyToCreationTimeMap.clear();\n+  }\n+\n+  @Override\n+  public void export(final Record record) {\n+    if (record.getRecordType() != RecordType.EVENT) {\n+      controller.updateLastExportedRecordPosition(record.getPosition());\n+      return;\n+    }\n+\n+    final var partitionId = record.getPartitionId();\n+    final var recordKey = record.getKey();\n+\n+    final var currentValueType = record.getValueType();\n+    if (currentValueType == ValueType.JOB) {\n+      handleJobRecord(record, partitionId, recordKey);\n+    } else if (currentValueType == ValueType.WORKFLOW_INSTANCE) {\n+      handleWorkflowInstanceRecord(record, partitionId, recordKey);\n+    }\n+\n+    controller.updateLastExportedRecordPosition(record.getPosition());\n+  }\n+\n+  private void handleWorkflowInstanceRecord(\n+      final Record<?> record, final int partitionId, final long recordKey) {\n+    final var currentIntent = record.getIntent();\n+\n+    if (currentIntent == WorkflowInstanceIntent.ELEMENT_ACTIVATING\n+        && isWorkflowInstanceRecord(record)) {\n+      storeWorkflowInstanceCreation(record.getTimestamp(), recordKey);\n+    } else if (currentIntent == WorkflowInstanceIntent.ELEMENT_COMPLETED\n+        && isWorkflowInstanceRecord(record)) {\n+      final var creationTime = workflowInstanceKeyToCreationTimeMap.remove(recordKey);\n+      executionLatencyMetrics.observeWorkflowInstanceExecutionTime(\n+          partitionId, creationTime, record.getTimestamp());\n+    }\n+  }\n+\n+  private void storeWorkflowInstanceCreation(final long creationTime, final long recordKey) {\n+    workflowInstanceKeyToCreationTimeMap.put(recordKey, creationTime);\n+    creationTimeToWorkflowInstanceKeyTreeMap.put(creationTime, recordKey);\n+  }\n+\n+  private void handleJobRecord(\n+      final Record<?> record, final int partitionId, final long recordKey) {\n+    final var currentIntent = record.getIntent();\n+\n+    if (currentIntent == JobIntent.CREATED) {\n+      storeJobCreation(record.getTimestamp(), recordKey);\n+    } else if (currentIntent == JobIntent.ACTIVATED) {\n+      final var creationTime = jobKeyToCreationTimeMap.get(recordKey);\n+      executionLatencyMetrics.observeJobActivationTime(\n+          partitionId, creationTime, record.getTimestamp());\n+    } else if (currentIntent == JobIntent.COMPLETED) {\n+      final var creationTime = jobKeyToCreationTimeMap.remove(recordKey);\n+      executionLatencyMetrics.observeJobLifeTime(partitionId, creationTime, record.getTimestamp());\n+    }\n+  }\n+\n+  private void storeJobCreation(final long creationTime, final long recordKey) {\n+    jobKeyToCreationTimeMap.put(recordKey, creationTime);\n+    creationTimeToJobKeyTreeMap.put(creationTime, recordKey);\n+  }\n+\n+  private void cleanUp() {\n+    final var currentTimeMillis = System.currentTimeMillis();\n+\n+    final var deadTime = currentTimeMillis - TIME_TO_LIVE.toMillis();\n+    clearMaps(deadTime, creationTimeToJobKeyTreeMap, jobKeyToCreationTimeMap);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13b2b31f9159d7d834cd2ed758eb9e178046108b"}, "originalPosition": 122}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODM2MTEzNQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                for (final Long key : outOfScopeInstances.values()) {\n          \n          \n            \n                  keyToTimestampMap.remove(key);\n          \n          \n            \n                }\n          \n          \n            \n                keyToTimestampMap.keySet().removeAll(outOfScopeInstances.values())\n          \n      \n    \n    \n  \n\nFrom what I understand, changes to keySet() are reflected in the map. From the docs:\n\nThe set is backed by the map, so changes to the map are reflected in the set, and vice-versa\n...\nThe set supports element removal, which removes the corresponding mapping from the map, via the Iterator.remove, Set.remove, removeAll, retainAll, and clear operations. It does not support the add or addAll operations.", "url": "https://github.com/camunda-cloud/zeebe/pull/4233#discussion_r408361135", "createdAt": "2020-04-14T18:52:10Z", "author": {"login": "npepinpe"}, "path": "broker/src/main/java/io/zeebe/broker/exporter/metrics/MetricsExporter.java", "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.exporter.metrics;\n+\n+import io.zeebe.broker.system.configuration.ExporterCfg;\n+import io.zeebe.exporter.api.Exporter;\n+import io.zeebe.exporter.api.context.Controller;\n+import io.zeebe.protocol.record.Record;\n+import io.zeebe.protocol.record.RecordType;\n+import io.zeebe.protocol.record.ValueType;\n+import io.zeebe.protocol.record.intent.JobIntent;\n+import io.zeebe.protocol.record.intent.WorkflowInstanceIntent;\n+import io.zeebe.protocol.record.value.WorkflowInstanceRecordValue;\n+import java.time.Duration;\n+import java.util.NavigableMap;\n+import java.util.TreeMap;\n+import org.agrona.collections.Long2LongHashMap;\n+\n+public class MetricsExporter implements Exporter {\n+\n+  public static final Duration TIME_TO_LIVE = Duration.ofSeconds(10);\n+  private final ExecutionLatencyMetrics executionLatencyMetrics;\n+  private final Long2LongHashMap jobKeyToCreationTimeMap;\n+  private final Long2LongHashMap workflowInstanceKeyToCreationTimeMap;\n+\n+  private final NavigableMap<Long, Long> creationTimeToJobKeyTreeMap;\n+  private final NavigableMap<Long, Long> creationTimeToWorkflowInstanceKeyTreeMap;\n+\n+  private Controller controller;\n+\n+  public MetricsExporter() {\n+    this.executionLatencyMetrics = new ExecutionLatencyMetrics();\n+    this.jobKeyToCreationTimeMap = new Long2LongHashMap(-1);\n+    this.workflowInstanceKeyToCreationTimeMap = new Long2LongHashMap(-1);\n+    this.creationTimeToJobKeyTreeMap = new TreeMap<>();\n+    this.creationTimeToWorkflowInstanceKeyTreeMap = new TreeMap<>();\n+  }\n+\n+  @Override\n+  public void open(final Controller controller) {\n+    this.controller = controller;\n+\n+    controller.scheduleTask(TIME_TO_LIVE, this::cleanUp);\n+  }\n+\n+  @Override\n+  public void close() {\n+    jobKeyToCreationTimeMap.clear();\n+    workflowInstanceKeyToCreationTimeMap.clear();\n+  }\n+\n+  @Override\n+  public void export(final Record record) {\n+    if (record.getRecordType() != RecordType.EVENT) {\n+      controller.updateLastExportedRecordPosition(record.getPosition());\n+      return;\n+    }\n+\n+    final var partitionId = record.getPartitionId();\n+    final var recordKey = record.getKey();\n+\n+    final var currentValueType = record.getValueType();\n+    if (currentValueType == ValueType.JOB) {\n+      handleJobRecord(record, partitionId, recordKey);\n+    } else if (currentValueType == ValueType.WORKFLOW_INSTANCE) {\n+      handleWorkflowInstanceRecord(record, partitionId, recordKey);\n+    }\n+\n+    controller.updateLastExportedRecordPosition(record.getPosition());\n+  }\n+\n+  private void handleWorkflowInstanceRecord(\n+      final Record<?> record, final int partitionId, final long recordKey) {\n+    final var currentIntent = record.getIntent();\n+\n+    if (currentIntent == WorkflowInstanceIntent.ELEMENT_ACTIVATING\n+        && isWorkflowInstanceRecord(record)) {\n+      storeWorkflowInstanceCreation(record.getTimestamp(), recordKey);\n+    } else if (currentIntent == WorkflowInstanceIntent.ELEMENT_COMPLETED\n+        && isWorkflowInstanceRecord(record)) {\n+      final var creationTime = workflowInstanceKeyToCreationTimeMap.remove(recordKey);\n+      executionLatencyMetrics.observeWorkflowInstanceExecutionTime(\n+          partitionId, creationTime, record.getTimestamp());\n+    }\n+  }\n+\n+  private void storeWorkflowInstanceCreation(final long creationTime, final long recordKey) {\n+    workflowInstanceKeyToCreationTimeMap.put(recordKey, creationTime);\n+    creationTimeToWorkflowInstanceKeyTreeMap.put(creationTime, recordKey);\n+  }\n+\n+  private void handleJobRecord(\n+      final Record<?> record, final int partitionId, final long recordKey) {\n+    final var currentIntent = record.getIntent();\n+\n+    if (currentIntent == JobIntent.CREATED) {\n+      storeJobCreation(record.getTimestamp(), recordKey);\n+    } else if (currentIntent == JobIntent.ACTIVATED) {\n+      final var creationTime = jobKeyToCreationTimeMap.get(recordKey);\n+      executionLatencyMetrics.observeJobActivationTime(\n+          partitionId, creationTime, record.getTimestamp());\n+    } else if (currentIntent == JobIntent.COMPLETED) {\n+      final var creationTime = jobKeyToCreationTimeMap.remove(recordKey);\n+      executionLatencyMetrics.observeJobLifeTime(partitionId, creationTime, record.getTimestamp());\n+    }\n+  }\n+\n+  private void storeJobCreation(final long creationTime, final long recordKey) {\n+    jobKeyToCreationTimeMap.put(recordKey, creationTime);\n+    creationTimeToJobKeyTreeMap.put(creationTime, recordKey);\n+  }\n+\n+  private void cleanUp() {\n+    final var currentTimeMillis = System.currentTimeMillis();\n+\n+    final var deadTime = currentTimeMillis - TIME_TO_LIVE.toMillis();\n+    clearMaps(deadTime, creationTimeToJobKeyTreeMap, jobKeyToCreationTimeMap);\n+    clearMaps(\n+        deadTime, creationTimeToWorkflowInstanceKeyTreeMap, workflowInstanceKeyToCreationTimeMap);\n+  }\n+\n+  private void clearMaps(\n+      final long deadTime,\n+      final NavigableMap<Long, Long> timeToKeyMap,\n+      final Long2LongHashMap keyToTimestampMap) {\n+    final var outOfScopeInstances = timeToKeyMap.headMap(deadTime);\n+\n+    for (final Long key : outOfScopeInstances.values()) {\n+      keyToTimestampMap.remove(key);\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13b2b31f9159d7d834cd2ed758eb9e178046108b"}, "originalPosition": 135}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODM2Nzg3Ng==", "bodyText": "Why is it static?", "url": "https://github.com/camunda-cloud/zeebe/pull/4233#discussion_r408367876", "createdAt": "2020-04-14T19:03:16Z", "author": {"login": "npepinpe"}, "path": "broker/src/main/java/io/zeebe/broker/exporter/metrics/MetricsExporter.java", "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.exporter.metrics;\n+\n+import io.zeebe.broker.system.configuration.ExporterCfg;\n+import io.zeebe.exporter.api.Exporter;\n+import io.zeebe.exporter.api.context.Controller;\n+import io.zeebe.protocol.record.Record;\n+import io.zeebe.protocol.record.RecordType;\n+import io.zeebe.protocol.record.ValueType;\n+import io.zeebe.protocol.record.intent.JobIntent;\n+import io.zeebe.protocol.record.intent.WorkflowInstanceIntent;\n+import io.zeebe.protocol.record.value.WorkflowInstanceRecordValue;\n+import java.time.Duration;\n+import java.util.NavigableMap;\n+import java.util.TreeMap;\n+import org.agrona.collections.Long2LongHashMap;\n+\n+public class MetricsExporter implements Exporter {\n+\n+  public static final Duration TIME_TO_LIVE = Duration.ofSeconds(10);\n+  private final ExecutionLatencyMetrics executionLatencyMetrics;\n+  private final Long2LongHashMap jobKeyToCreationTimeMap;\n+  private final Long2LongHashMap workflowInstanceKeyToCreationTimeMap;\n+\n+  private final NavigableMap<Long, Long> creationTimeToJobKeyTreeMap;\n+  private final NavigableMap<Long, Long> creationTimeToWorkflowInstanceKeyTreeMap;\n+\n+  private Controller controller;\n+\n+  public MetricsExporter() {\n+    this.executionLatencyMetrics = new ExecutionLatencyMetrics();\n+    this.jobKeyToCreationTimeMap = new Long2LongHashMap(-1);\n+    this.workflowInstanceKeyToCreationTimeMap = new Long2LongHashMap(-1);\n+    this.creationTimeToJobKeyTreeMap = new TreeMap<>();\n+    this.creationTimeToWorkflowInstanceKeyTreeMap = new TreeMap<>();\n+  }\n+\n+  @Override\n+  public void open(final Controller controller) {\n+    this.controller = controller;\n+\n+    controller.scheduleTask(TIME_TO_LIVE, this::cleanUp);\n+  }\n+\n+  @Override\n+  public void close() {\n+    jobKeyToCreationTimeMap.clear();\n+    workflowInstanceKeyToCreationTimeMap.clear();\n+  }\n+\n+  @Override\n+  public void export(final Record record) {\n+    if (record.getRecordType() != RecordType.EVENT) {\n+      controller.updateLastExportedRecordPosition(record.getPosition());\n+      return;\n+    }\n+\n+    final var partitionId = record.getPartitionId();\n+    final var recordKey = record.getKey();\n+\n+    final var currentValueType = record.getValueType();\n+    if (currentValueType == ValueType.JOB) {\n+      handleJobRecord(record, partitionId, recordKey);\n+    } else if (currentValueType == ValueType.WORKFLOW_INSTANCE) {\n+      handleWorkflowInstanceRecord(record, partitionId, recordKey);\n+    }\n+\n+    controller.updateLastExportedRecordPosition(record.getPosition());\n+  }\n+\n+  private void handleWorkflowInstanceRecord(\n+      final Record<?> record, final int partitionId, final long recordKey) {\n+    final var currentIntent = record.getIntent();\n+\n+    if (currentIntent == WorkflowInstanceIntent.ELEMENT_ACTIVATING\n+        && isWorkflowInstanceRecord(record)) {\n+      storeWorkflowInstanceCreation(record.getTimestamp(), recordKey);\n+    } else if (currentIntent == WorkflowInstanceIntent.ELEMENT_COMPLETED\n+        && isWorkflowInstanceRecord(record)) {\n+      final var creationTime = workflowInstanceKeyToCreationTimeMap.remove(recordKey);\n+      executionLatencyMetrics.observeWorkflowInstanceExecutionTime(\n+          partitionId, creationTime, record.getTimestamp());\n+    }\n+  }\n+\n+  private void storeWorkflowInstanceCreation(final long creationTime, final long recordKey) {\n+    workflowInstanceKeyToCreationTimeMap.put(recordKey, creationTime);\n+    creationTimeToWorkflowInstanceKeyTreeMap.put(creationTime, recordKey);\n+  }\n+\n+  private void handleJobRecord(\n+      final Record<?> record, final int partitionId, final long recordKey) {\n+    final var currentIntent = record.getIntent();\n+\n+    if (currentIntent == JobIntent.CREATED) {\n+      storeJobCreation(record.getTimestamp(), recordKey);\n+    } else if (currentIntent == JobIntent.ACTIVATED) {\n+      final var creationTime = jobKeyToCreationTimeMap.get(recordKey);\n+      executionLatencyMetrics.observeJobActivationTime(\n+          partitionId, creationTime, record.getTimestamp());\n+    } else if (currentIntent == JobIntent.COMPLETED) {\n+      final var creationTime = jobKeyToCreationTimeMap.remove(recordKey);\n+      executionLatencyMetrics.observeJobLifeTime(partitionId, creationTime, record.getTimestamp());\n+    }\n+  }\n+\n+  private void storeJobCreation(final long creationTime, final long recordKey) {\n+    jobKeyToCreationTimeMap.put(recordKey, creationTime);\n+    creationTimeToJobKeyTreeMap.put(creationTime, recordKey);\n+  }\n+\n+  private void cleanUp() {\n+    final var currentTimeMillis = System.currentTimeMillis();\n+\n+    final var deadTime = currentTimeMillis - TIME_TO_LIVE.toMillis();\n+    clearMaps(deadTime, creationTimeToJobKeyTreeMap, jobKeyToCreationTimeMap);\n+    clearMaps(\n+        deadTime, creationTimeToWorkflowInstanceKeyTreeMap, workflowInstanceKeyToCreationTimeMap);\n+  }\n+\n+  private void clearMaps(\n+      final long deadTime,\n+      final NavigableMap<Long, Long> timeToKeyMap,\n+      final Long2LongHashMap keyToTimestampMap) {\n+    final var outOfScopeInstances = timeToKeyMap.headMap(deadTime);\n+\n+    for (final Long key : outOfScopeInstances.values()) {\n+      keyToTimestampMap.remove(key);\n+    }\n+    outOfScopeInstances.clear();\n+  }\n+\n+  public static ExporterCfg defaultConfig() {\n+    final ExporterCfg exporterCfg = new ExporterCfg();\n+    exporterCfg.setClassName(MetricsExporter.class.getName());\n+    return exporterCfg;\n+  }\n+\n+  public static String defaultExporterId() {\n+    return MetricsExporter.class.getSimpleName();\n+  }\n+\n+  private static boolean isWorkflowInstanceRecord(final Record<?> record) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13b2b31f9159d7d834cd2ed758eb9e178046108b"}, "originalPosition": 149}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODM2ODMxMg==", "bodyText": "Nice catch", "url": "https://github.com/camunda-cloud/zeebe/pull/4233#discussion_r408368312", "createdAt": "2020-04-14T19:03:58Z", "author": {"login": "npepinpe"}, "path": "broker/src/test/java/io/zeebe/broker/system/configuration/BrokerCfgTest.java", "diffHunk": "@@ -60,8 +61,10 @@\n \n   private static final String ZEEBE_BROKER_NETWORK_HOST = \"zeebe.broker.network.host\";\n   private static final String ZEEBE_BROKER_NETWORK_ADVERTISED_HOST =\n-      \"zeebe.broker.network.advertised-host\";\n+      \"zeebe.broker.network.advertisedHost\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13b2b31f9159d7d834cd2ed758eb9e178046108b"}, "originalPosition": 13}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkzNTE5Mjg5", "url": "https://github.com/camunda-cloud/zeebe/pull/4233#pullrequestreview-393519289", "createdAt": "2020-04-15T07:27:51Z", "commit": {"oid": "c709e0ec7c6a84d404c31c8c37fc8560b5c88be9"}, "state": "APPROVED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNzoyNzo1MVrOGFtHBg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNzoyOToxMlrOGFtKAw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYzNTE0Mg==", "bodyText": "Nit: Could we also just check if recordValue.getBpmnElementType() == BpmnElementType.PROCESS? I think this is how we do it in WorkflowInstanceMetrics", "url": "https://github.com/camunda-cloud/zeebe/pull/4233#discussion_r408635142", "createdAt": "2020-04-15T07:27:51Z", "author": {"login": "npepinpe"}, "path": "broker/src/main/java/io/zeebe/broker/exporter/metrics/MetricsExporter.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.exporter.metrics;\n+\n+import io.zeebe.broker.system.configuration.ExporterCfg;\n+import io.zeebe.exporter.api.Exporter;\n+import io.zeebe.exporter.api.context.Controller;\n+import io.zeebe.protocol.record.Record;\n+import io.zeebe.protocol.record.RecordType;\n+import io.zeebe.protocol.record.ValueType;\n+import io.zeebe.protocol.record.intent.JobIntent;\n+import io.zeebe.protocol.record.intent.WorkflowInstanceIntent;\n+import io.zeebe.protocol.record.value.WorkflowInstanceRecordValue;\n+import java.time.Duration;\n+import java.util.NavigableMap;\n+import java.util.TreeMap;\n+import org.agrona.collections.Long2LongHashMap;\n+\n+public class MetricsExporter implements Exporter {\n+\n+  public static final Duration TIME_TO_LIVE = Duration.ofSeconds(10);\n+  private final ExecutionLatencyMetrics executionLatencyMetrics;\n+  private final Long2LongHashMap jobKeyToCreationTimeMap;\n+  private final Long2LongHashMap workflowInstanceKeyToCreationTimeMap;\n+\n+  private final NavigableMap<Long, Long> creationTimeToJobKeyTreeMap;\n+  private final NavigableMap<Long, Long> creationTimeToWorkflowInstanceKeyTreeMap;\n+\n+  private Controller controller;\n+\n+  public MetricsExporter() {\n+    this.executionLatencyMetrics = new ExecutionLatencyMetrics();\n+    this.jobKeyToCreationTimeMap = new Long2LongHashMap(-1);\n+    this.workflowInstanceKeyToCreationTimeMap = new Long2LongHashMap(-1);\n+    this.creationTimeToJobKeyTreeMap = new TreeMap<>();\n+    this.creationTimeToWorkflowInstanceKeyTreeMap = new TreeMap<>();\n+  }\n+\n+  @Override\n+  public void open(final Controller controller) {\n+    this.controller = controller;\n+\n+    controller.scheduleTask(TIME_TO_LIVE, this::cleanUp);\n+  }\n+\n+  @Override\n+  public void close() {\n+    jobKeyToCreationTimeMap.clear();\n+    workflowInstanceKeyToCreationTimeMap.clear();\n+  }\n+\n+  @Override\n+  public void export(final Record record) {\n+    if (record.getRecordType() != RecordType.EVENT) {\n+      controller.updateLastExportedRecordPosition(record.getPosition());\n+      return;\n+    }\n+\n+    final var partitionId = record.getPartitionId();\n+    final var recordKey = record.getKey();\n+\n+    final var currentValueType = record.getValueType();\n+    if (currentValueType == ValueType.JOB) {\n+      handleJobRecord(record, partitionId, recordKey);\n+    } else if (currentValueType == ValueType.WORKFLOW_INSTANCE) {\n+      handleWorkflowInstanceRecord(record, partitionId, recordKey);\n+    }\n+\n+    controller.updateLastExportedRecordPosition(record.getPosition());\n+  }\n+\n+  private void handleWorkflowInstanceRecord(\n+      final Record<?> record, final int partitionId, final long recordKey) {\n+    final var currentIntent = record.getIntent();\n+\n+    if (currentIntent == WorkflowInstanceIntent.ELEMENT_ACTIVATING\n+        && isWorkflowInstanceRecord(record)) {\n+      storeWorkflowInstanceCreation(record.getTimestamp(), recordKey);\n+    } else if (currentIntent == WorkflowInstanceIntent.ELEMENT_COMPLETED\n+        && isWorkflowInstanceRecord(record)) {\n+      final var creationTime = workflowInstanceKeyToCreationTimeMap.remove(recordKey);\n+      executionLatencyMetrics.observeWorkflowInstanceExecutionTime(\n+          partitionId, creationTime, record.getTimestamp());\n+    }\n+  }\n+\n+  private void storeWorkflowInstanceCreation(final long creationTime, final long recordKey) {\n+    workflowInstanceKeyToCreationTimeMap.put(recordKey, creationTime);\n+    creationTimeToWorkflowInstanceKeyTreeMap.put(creationTime, recordKey);\n+  }\n+\n+  private void handleJobRecord(\n+      final Record<?> record, final int partitionId, final long recordKey) {\n+    final var currentIntent = record.getIntent();\n+\n+    if (currentIntent == JobIntent.CREATED) {\n+      storeJobCreation(record.getTimestamp(), recordKey);\n+    } else if (currentIntent == JobIntent.ACTIVATED) {\n+      final var creationTime = jobKeyToCreationTimeMap.get(recordKey);\n+      executionLatencyMetrics.observeJobActivationTime(\n+          partitionId, creationTime, record.getTimestamp());\n+    } else if (currentIntent == JobIntent.COMPLETED) {\n+      final var creationTime = jobKeyToCreationTimeMap.remove(recordKey);\n+      executionLatencyMetrics.observeJobLifeTime(partitionId, creationTime, record.getTimestamp());\n+    }\n+  }\n+\n+  private void storeJobCreation(final long creationTime, final long recordKey) {\n+    jobKeyToCreationTimeMap.put(recordKey, creationTime);\n+    creationTimeToJobKeyTreeMap.put(creationTime, recordKey);\n+  }\n+\n+  private void cleanUp() {\n+    final var currentTimeMillis = System.currentTimeMillis();\n+\n+    final var deadTime = currentTimeMillis - TIME_TO_LIVE.toMillis();\n+    clearMaps(deadTime, creationTimeToJobKeyTreeMap, jobKeyToCreationTimeMap);\n+    clearMaps(\n+        deadTime, creationTimeToWorkflowInstanceKeyTreeMap, workflowInstanceKeyToCreationTimeMap);\n+  }\n+\n+  private void clearMaps(\n+      final long deadTime,\n+      final NavigableMap<Long, Long> timeToKeyMap,\n+      final Long2LongHashMap keyToTimestampMap) {\n+    final var outOfScopeInstances = timeToKeyMap.headMap(deadTime);\n+\n+    keyToTimestampMap.keySet().removeAll(outOfScopeInstances.values())\n+    outOfScopeInstances.clear();\n+  }\n+\n+  public static ExporterCfg defaultConfig() {\n+    final ExporterCfg exporterCfg = new ExporterCfg();\n+    exporterCfg.setClassName(MetricsExporter.class.getName());\n+    return exporterCfg;\n+  }\n+\n+  public static String defaultExporterId() {\n+    return MetricsExporter.class.getSimpleName();\n+  }\n+\n+  private static boolean isWorkflowInstanceRecord(final Record<?> record) {\n+    final var recordKey = record.getKey();\n+    final var recordValue = (WorkflowInstanceRecordValue) record.getValue();\n+    return recordKey == recordValue.getWorkflowInstanceKey();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c709e0ec7c6a84d404c31c8c37fc8560b5c88be9"}, "originalPosition": 150}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYzNTkwNw==", "bodyText": "Ah true, we only store for processes and jobs, so they are never part of a batch (I think? Can't remember how a multi-instance call activity would look like \ud83d\ude05)", "url": "https://github.com/camunda-cloud/zeebe/pull/4233#discussion_r408635907", "createdAt": "2020-04-15T07:29:12Z", "author": {"login": "npepinpe"}, "path": "broker/src/main/java/io/zeebe/broker/exporter/metrics/MetricsExporter.java", "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.exporter.metrics;\n+\n+import io.zeebe.broker.system.configuration.ExporterCfg;\n+import io.zeebe.exporter.api.Exporter;\n+import io.zeebe.exporter.api.context.Controller;\n+import io.zeebe.protocol.record.Record;\n+import io.zeebe.protocol.record.RecordType;\n+import io.zeebe.protocol.record.ValueType;\n+import io.zeebe.protocol.record.intent.JobIntent;\n+import io.zeebe.protocol.record.intent.WorkflowInstanceIntent;\n+import io.zeebe.protocol.record.value.WorkflowInstanceRecordValue;\n+import java.time.Duration;\n+import java.util.NavigableMap;\n+import java.util.TreeMap;\n+import org.agrona.collections.Long2LongHashMap;\n+\n+public class MetricsExporter implements Exporter {\n+\n+  public static final Duration TIME_TO_LIVE = Duration.ofSeconds(10);\n+  private final ExecutionLatencyMetrics executionLatencyMetrics;\n+  private final Long2LongHashMap jobKeyToCreationTimeMap;\n+  private final Long2LongHashMap workflowInstanceKeyToCreationTimeMap;\n+\n+  private final NavigableMap<Long, Long> creationTimeToJobKeyTreeMap;\n+  private final NavigableMap<Long, Long> creationTimeToWorkflowInstanceKeyTreeMap;\n+\n+  private Controller controller;\n+\n+  public MetricsExporter() {\n+    this.executionLatencyMetrics = new ExecutionLatencyMetrics();\n+    this.jobKeyToCreationTimeMap = new Long2LongHashMap(-1);\n+    this.workflowInstanceKeyToCreationTimeMap = new Long2LongHashMap(-1);\n+    this.creationTimeToJobKeyTreeMap = new TreeMap<>();\n+    this.creationTimeToWorkflowInstanceKeyTreeMap = new TreeMap<>();\n+  }\n+\n+  @Override\n+  public void open(final Controller controller) {\n+    this.controller = controller;\n+\n+    controller.scheduleTask(TIME_TO_LIVE, this::cleanUp);\n+  }\n+\n+  @Override\n+  public void close() {\n+    jobKeyToCreationTimeMap.clear();\n+    workflowInstanceKeyToCreationTimeMap.clear();\n+  }\n+\n+  @Override\n+  public void export(final Record record) {\n+    if (record.getRecordType() != RecordType.EVENT) {\n+      controller.updateLastExportedRecordPosition(record.getPosition());\n+      return;\n+    }\n+\n+    final var partitionId = record.getPartitionId();\n+    final var recordKey = record.getKey();\n+\n+    final var currentValueType = record.getValueType();\n+    if (currentValueType == ValueType.JOB) {\n+      handleJobRecord(record, partitionId, recordKey);\n+    } else if (currentValueType == ValueType.WORKFLOW_INSTANCE) {\n+      handleWorkflowInstanceRecord(record, partitionId, recordKey);\n+    }\n+\n+    controller.updateLastExportedRecordPosition(record.getPosition());\n+  }\n+\n+  private void handleWorkflowInstanceRecord(\n+      final Record<?> record, final int partitionId, final long recordKey) {\n+    final var currentIntent = record.getIntent();\n+\n+    if (currentIntent == WorkflowInstanceIntent.ELEMENT_ACTIVATING\n+        && isWorkflowInstanceRecord(record)) {\n+      storeWorkflowInstanceCreation(record.getTimestamp(), recordKey);\n+    } else if (currentIntent == WorkflowInstanceIntent.ELEMENT_COMPLETED\n+        && isWorkflowInstanceRecord(record)) {\n+      final var creationTime = workflowInstanceKeyToCreationTimeMap.remove(recordKey);\n+      executionLatencyMetrics.observeWorkflowInstanceExecutionTime(\n+          partitionId, creationTime, record.getTimestamp());\n+    }\n+  }\n+\n+  private void storeWorkflowInstanceCreation(final long creationTime, final long recordKey) {\n+    workflowInstanceKeyToCreationTimeMap.put(recordKey, creationTime);\n+    creationTimeToWorkflowInstanceKeyTreeMap.put(creationTime, recordKey);\n+  }\n+\n+  private void handleJobRecord(\n+      final Record<?> record, final int partitionId, final long recordKey) {\n+    final var currentIntent = record.getIntent();\n+\n+    if (currentIntent == JobIntent.CREATED) {\n+      storeJobCreation(record.getTimestamp(), recordKey);\n+    } else if (currentIntent == JobIntent.ACTIVATED) {\n+      final var creationTime = jobKeyToCreationTimeMap.get(recordKey);\n+      executionLatencyMetrics.observeJobActivationTime(\n+          partitionId, creationTime, record.getTimestamp());\n+    } else if (currentIntent == JobIntent.COMPLETED) {\n+      final var creationTime = jobKeyToCreationTimeMap.remove(recordKey);\n+      executionLatencyMetrics.observeJobLifeTime(partitionId, creationTime, record.getTimestamp());\n+    }\n+  }\n+\n+  private void storeJobCreation(final long creationTime, final long recordKey) {\n+    jobKeyToCreationTimeMap.put(recordKey, creationTime);\n+    creationTimeToJobKeyTreeMap.put(creationTime, recordKey);\n+  }\n+\n+  private void cleanUp() {\n+    final var currentTimeMillis = System.currentTimeMillis();\n+\n+    final var deadTime = currentTimeMillis - TIME_TO_LIVE.toMillis();\n+    clearMaps(deadTime, creationTimeToJobKeyTreeMap, jobKeyToCreationTimeMap);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODM1ODYxNQ=="}, "originalCommit": {"oid": "13b2b31f9159d7d834cd2ed758eb9e178046108b"}, "originalPosition": 122}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "54db1cb8727df8ef402849b55591f7557313f0ba", "author": {"user": {"login": "Zelldon", "name": "Christopher Zell"}}, "url": "https://github.com/camunda-cloud/zeebe/commit/54db1cb8727df8ef402849b55591f7557313f0ba", "committedDate": "2020-04-15T07:47:45Z", "message": "chore(broker): add metric exporter\n\nThe execution metric exporter will collect informations based on the seen records\nand publish latency metric like:\n\n * process execution time, shows the time between creating and completing/terminating a workflow instance\n * job activation time, shows the time between creating an job and activating it\n * job lifetime, show the time between creating an job and completing it\n\nAs it makes more sense for short running process and not on all use cases it is disabled by default.\nWe can enabled it for example with a env variable, which we will do with\nout benchmark setup. For performance analysis the metrics are quite\ninteresting. We moved these metrics into an exporter, such that we not\nhave this in our current state (db) since it is not always needed and\ncan easily be extended."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6e4005ddb1238577a8f72f7abeeb8a257bf372f4", "author": {"user": {"login": "Zelldon", "name": "Christopher Zell"}}, "url": "https://github.com/camunda-cloud/zeebe/commit/6e4005ddb1238577a8f72f7abeeb8a257bf372f4", "committedDate": "2020-04-15T07:47:51Z", "message": "chore(benchmarks): enable metrics exporter"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c709e0ec7c6a84d404c31c8c37fc8560b5c88be9", "author": {"user": {"login": "Zelldon", "name": "Christopher Zell"}}, "url": "https://github.com/camunda-cloud/zeebe/commit/c709e0ec7c6a84d404c31c8c37fc8560b5c88be9", "committedDate": "2020-04-15T05:43:36Z", "message": "chore(broker): update broker/src/main/java/io/zeebe/broker/exporter/metrics/MetricsExporter.java\n\nCo-Authored-By: Nicolas Pepin-Perreault <nicolas.pepin-perreault@camunda.com>"}, "afterCommit": {"oid": "6e4005ddb1238577a8f72f7abeeb8a257bf372f4", "author": {"user": {"login": "Zelldon", "name": "Christopher Zell"}}, "url": "https://github.com/camunda-cloud/zeebe/commit/6e4005ddb1238577a8f72f7abeeb8a257bf372f4", "committedDate": "2020-04-15T07:47:51Z", "message": "chore(benchmarks): enable metrics exporter"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2983, "cost": 1, "resetAt": "2021-11-01T13:07:16Z"}}}