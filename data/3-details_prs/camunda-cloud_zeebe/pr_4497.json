{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE2MjAzMTY3", "number": 4497, "title": "chore(gateway): retry when partitions not available", "bodyText": "Description\nFor requests that can be send to any partition retry with different partition when leader not available.\n\nRefactor automatic retry in io.zeebe.transport.impl.sender so that create workflow and activate job requests are not retried with the same partition when leader not available.\nAdd 'CreateWorkflowHandler' to retry requests with different partition\nRefactor RoundRobinStrategy to include only partitions where leader is available\n\nRelated issues\nRelated to #4496\nPull Request Checklist\n\n All commit messages match our commit message guidelines\n The submitting code follows our code style\n If submitting code, please run mvn clean install -DskipTests locally before committing", "createdAt": "2020-05-11T16:12:45Z", "url": "https://github.com/camunda-cloud/zeebe/pull/4497", "merged": true, "mergeCommit": {"oid": "37fbb826e88d5974d4a7a82cec1d1d95a569282c"}, "closed": true, "closedAt": "2020-05-12T14:30:48Z", "author": {"login": "deepthidevaki"}, "timelineItems": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcggGFaABqjMzMjYzODU4NTg=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcgiccdABqjMzMjcwMTAyNzY=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "717e2d3076fc9c56bd5d769fb5f7723a4808d691", "author": {"user": {"login": "deepthidevaki", "name": "Deepthi Devaki Akkoorath"}}, "url": "https://github.com/camunda-cloud/zeebe/commit/717e2d3076fc9c56bd5d769fb5f7723a4808d691", "committedDate": "2020-05-12T08:28:52Z", "message": "chore(qa): wait for leaders after restart"}, "afterCommit": {"oid": "235aefb294a462e1018bc6f69a3ba4f08230e2c7", "author": {"user": {"login": "deepthidevaki", "name": "Deepthi Devaki Akkoorath"}}, "url": "https://github.com/camunda-cloud/zeebe/commit/235aefb294a462e1018bc6f69a3ba4f08230e2c7", "committedDate": "2020-05-12T08:35:03Z", "message": "chore(qa): wait for leaders after restart"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "235aefb294a462e1018bc6f69a3ba4f08230e2c7", "author": {"user": {"login": "deepthidevaki", "name": "Deepthi Devaki Akkoorath"}}, "url": "https://github.com/camunda-cloud/zeebe/commit/235aefb294a462e1018bc6f69a3ba4f08230e2c7", "committedDate": "2020-05-12T08:35:03Z", "message": "chore(qa): wait for leaders after restart"}, "afterCommit": {"oid": "f6bd2fd07556839bb228aeefe840f88baa1a54f3", "author": {"user": {"login": "deepthidevaki", "name": "Deepthi Devaki Akkoorath"}}, "url": "https://github.com/camunda-cloud/zeebe/commit/f6bd2fd07556839bb228aeefe840f88baa1a54f3", "committedDate": "2020-05-12T08:44:51Z", "message": "chore(qa): wait for leaders after restart"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA5ODA1MjQy", "url": "https://github.com/camunda-cloud/zeebe/pull/4497#pullrequestreview-409805242", "createdAt": "2020-05-12T08:17:28Z", "commit": {"oid": "3c34e240e5fc271c5c894d98f102d0270beec87e"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQwODoxNzoyOFrOGT7UMg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQwODo1NTo0MFrOGT82uw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU0Nzk1NA==", "bodyText": "What was the previous behaviour here? Did we also return an invalid argument error code? I mean it makes sense, I just want to make sure we're not breaking anything.", "url": "https://github.com/camunda-cloud/zeebe/pull/4497#discussion_r423547954", "createdAt": "2020-05-12T08:17:28Z", "author": {"login": "npepinpe"}, "path": "gateway/src/main/java/io/zeebe/gateway/EndpointManager.java", "diffHunk": "@@ -140,103 +109,163 @@ private void addPartitionInfoToBrokerInfo(\n   }\n \n   @Override\n-  public void deployWorkflow(\n-      final DeployWorkflowRequest request,\n-      final StreamObserver<DeployWorkflowResponse> responseObserver) {\n-\n-    sendRequest(\n-        request,\n-        RequestMapper::toDeployWorkflowRequest,\n-        ResponseMapper::toDeployWorkflowResponse,\n-        responseObserver);\n+  public void activateJobs(\n+      final ActivateJobsRequest request,\n+      final StreamObserver<ActivateJobsResponse> responseObserver) {\n+    final BrokerClusterState topology = topologyManager.getTopology();\n+    activateJobsHandler.activateJobs(topology.getPartitionsCount(), request, responseObserver);\n   }\n \n   @Override\n-  public void publishMessage(\n-      PublishMessageRequest request, StreamObserver<PublishMessageResponse> responseObserver) {\n-\n+  public void cancelWorkflowInstance(\n+      final CancelWorkflowInstanceRequest request,\n+      final StreamObserver<CancelWorkflowInstanceResponse> responseObserver) {\n     sendRequest(\n         request,\n-        RequestMapper::toPublishMessageRequest,\n-        ResponseMapper::toPublishMessageResponse,\n+        RequestMapper::toCancelWorkflowInstanceRequest,\n+        ResponseMapper::toCancelWorkflowInstanceResponse,\n         responseObserver);\n   }\n \n   @Override\n-  public void updateJobRetries(\n-      UpdateJobRetriesRequest request, StreamObserver<UpdateJobRetriesResponse> responseObserver) {\n+  public void completeJob(\n+      final CompleteJobRequest request,\n+      final StreamObserver<CompleteJobResponse> responseObserver) {\n     sendRequest(\n         request,\n-        RequestMapper::toUpdateJobRetriesRequest,\n-        ResponseMapper::toUpdateJobRetriesResponse,\n+        RequestMapper::toCompleteJobRequest,\n+        ResponseMapper::toCompleteJobResponse,\n         responseObserver);\n   }\n \n   @Override\n   public void createWorkflowInstance(\n-      CreateWorkflowInstanceRequest request,\n-      StreamObserver<CreateWorkflowInstanceResponse> responseObserver) {\n+      final CreateWorkflowInstanceRequest request,\n+      final StreamObserver<CreateWorkflowInstanceResponse> responseObserver) {\n+    final BrokerCreateWorkflowInstanceRequest brokerRequest;\n+    try {\n+      brokerRequest = RequestMapper.toCreateWorkflowInstanceRequest(request);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3c34e240e5fc271c5c894d98f102d0270beec87e"}, "originalPosition": 146}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU0ODg5MQ==", "bodyText": "With ActivateJobsHandler, I think we defer the complete logic there, and the endpoint here is quite small - should we do the same here, and let the handler also perform the mapping and error handling logic? I would lean towards yes to keep this class here more about dispatching to the right handler. Let me know what you think", "url": "https://github.com/camunda-cloud/zeebe/pull/4497#discussion_r423548891", "createdAt": "2020-05-12T08:19:06Z", "author": {"login": "npepinpe"}, "path": "gateway/src/main/java/io/zeebe/gateway/EndpointManager.java", "diffHunk": "@@ -140,103 +109,163 @@ private void addPartitionInfoToBrokerInfo(\n   }\n \n   @Override\n-  public void deployWorkflow(\n-      final DeployWorkflowRequest request,\n-      final StreamObserver<DeployWorkflowResponse> responseObserver) {\n-\n-    sendRequest(\n-        request,\n-        RequestMapper::toDeployWorkflowRequest,\n-        ResponseMapper::toDeployWorkflowResponse,\n-        responseObserver);\n+  public void activateJobs(\n+      final ActivateJobsRequest request,\n+      final StreamObserver<ActivateJobsResponse> responseObserver) {\n+    final BrokerClusterState topology = topologyManager.getTopology();\n+    activateJobsHandler.activateJobs(topology.getPartitionsCount(), request, responseObserver);\n   }\n \n   @Override\n-  public void publishMessage(\n-      PublishMessageRequest request, StreamObserver<PublishMessageResponse> responseObserver) {\n-\n+  public void cancelWorkflowInstance(\n+      final CancelWorkflowInstanceRequest request,\n+      final StreamObserver<CancelWorkflowInstanceResponse> responseObserver) {\n     sendRequest(\n         request,\n-        RequestMapper::toPublishMessageRequest,\n-        ResponseMapper::toPublishMessageResponse,\n+        RequestMapper::toCancelWorkflowInstanceRequest,\n+        ResponseMapper::toCancelWorkflowInstanceResponse,\n         responseObserver);\n   }\n \n   @Override\n-  public void updateJobRetries(\n-      UpdateJobRetriesRequest request, StreamObserver<UpdateJobRetriesResponse> responseObserver) {\n+  public void completeJob(\n+      final CompleteJobRequest request,\n+      final StreamObserver<CompleteJobResponse> responseObserver) {\n     sendRequest(\n         request,\n-        RequestMapper::toUpdateJobRetriesRequest,\n-        ResponseMapper::toUpdateJobRetriesResponse,\n+        RequestMapper::toCompleteJobRequest,\n+        ResponseMapper::toCompleteJobResponse,\n         responseObserver);\n   }\n \n   @Override\n   public void createWorkflowInstance(\n-      CreateWorkflowInstanceRequest request,\n-      StreamObserver<CreateWorkflowInstanceResponse> responseObserver) {\n+      final CreateWorkflowInstanceRequest request,\n+      final StreamObserver<CreateWorkflowInstanceResponse> responseObserver) {\n+    final BrokerCreateWorkflowInstanceRequest brokerRequest;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3c34e240e5fc271c5c894d98f102d0270beec87e"}, "originalPosition": 144}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU1MDQ4Nw==", "bodyText": "Can we rename this so it's more explicit where/when it should be used? Something like\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              private static boolean shouldRetryRequest(final IncomingResponse response) {\n          \n          \n            \n              private static boolean shouldRetryFixedPartitionRequestfinal IncomingResponse response) {\n          \n      \n    \n    \n  \n\nOr something similar", "url": "https://github.com/camunda-cloud/zeebe/pull/4497#discussion_r423550487", "createdAt": "2020-05-12T08:21:36Z", "author": {"login": "npepinpe"}, "path": "gateway/src/main/java/io/zeebe/gateway/impl/broker/BrokerRequestManager.java", "diffHunk": "@@ -46,17 +49,22 @@\n   private final Duration requestTimeout;\n \n   public BrokerRequestManager(\n-      ClientOutput clientOutput,\n-      BrokerTopologyManagerImpl topologyManager,\n-      RequestDispatchStrategy dispatchStrategy,\n-      Duration requestTimeout) {\n+      final ClientOutput clientOutput,\n+      final BrokerTopologyManagerImpl topologyManager,\n+      final RequestDispatchStrategy dispatchStrategy,\n+      final Duration requestTimeout) {\n     this.clientOutput = clientOutput;\n     this.dispatchStrategy = dispatchStrategy;\n     this.topologyManager = topologyManager;\n     this.requestTimeout = requestTimeout;\n   }\n \n-  private static boolean shouldRetryRequest(final DirectBuffer responseContent) {\n+  private static boolean shouldRetryRequest(final IncomingResponse response) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3c34e240e5fc271c5c894d98f102d0270beec87e"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU1MTQ1Mg==", "bodyText": "Can be removed, this was there for the metrics right?", "url": "https://github.com/camunda-cloud/zeebe/pull/4497#discussion_r423551452", "createdAt": "2020-05-12T08:23:01Z", "author": {"login": "npepinpe"}, "path": "gateway/src/main/java/io/zeebe/gateway/impl/broker/BrokerRequestManager.java", "diffHunk": "@@ -129,27 +141,33 @@ private static boolean shouldRetryRequest(final DirectBuffer responseContent) {\n             } else {\n               throwableConsumer.accept(error);\n             }\n-          } catch (RuntimeException e) {\n+          } catch (final RuntimeException e) {\n             throwableConsumer.accept(new BrokerResponseException(e));\n           }\n-        });\n+        },\n+        shouldRetryPredicate);\n   }\n \n   private <T> void sendRequest(\n-      BrokerRequest<T> request, BiConsumer<BrokerResponse<T>, Throwable> responseConsumer) {\n+      final BrokerRequest<T> request,\n+      final BiConsumer<BrokerResponse<T>, Throwable> responseConsumer,\n+      final Predicate<IncomingResponse> shouldRetryPredicate) {\n     request.serializeValue();\n-    actor.run(() -> sendRequestInternal(request, responseConsumer));\n+    actor.run(() -> sendRequestInternal(request, responseConsumer, shouldRetryPredicate));\n   }\n \n   private <T> void sendRequestInternal(\n-      BrokerRequest<T> request, BiConsumer<BrokerResponse<T>, Throwable> responseConsumer) {\n+      final BrokerRequest<T> request,\n+      final BiConsumer<BrokerResponse<T>, Throwable> responseConsumer,\n+      final Predicate<IncomingResponse> shouldRetryPredicate) {\n     final BrokerNodeIdProvider nodeIdProvider = determineBrokerNodeIdProvider(request);\n \n     final ActorFuture<ClientResponse> responseFuture =\n         clientOutput.sendRequestWithRetry(\n-            nodeIdProvider, BrokerRequestManager::shouldRetryRequest, request, requestTimeout);\n+            nodeIdProvider, shouldRetryPredicate, request, requestTimeout);\n \n     if (responseFuture != null) {\n+      final long start = System.currentTimeMillis();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3c34e240e5fc271c5c894d98f102d0270beec87e"}, "originalPosition": 134}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU1MjM2Nw==", "bodyText": "Can be removed, or reworded to better explain why we're skipping non-leaders. Though maybe we should just comment the class, as you mentioned this is only sort of round-robin now.", "url": "https://github.com/camunda-cloud/zeebe/pull/4497#discussion_r423552367", "createdAt": "2020-05-12T08:24:32Z", "author": {"login": "npepinpe"}, "path": "gateway/src/main/java/io/zeebe/gateway/impl/broker/RoundRobinDispatchStrategy.java", "diffHunk": "@@ -25,10 +25,16 @@ public int determinePartition() {\n     final BrokerClusterState topology = topologyManager.getTopology();\n \n     if (topology != null) {\n-      final int offset = partitions.getAndIncrement();\n-      return topology.getPartition(offset);\n-    } else {\n-      return BrokerClusterState.PARTITION_ID_NULL;\n+      // go over all partitions once", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3c34e240e5fc271c5c894d98f102d0270beec87e"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU1NDcyMw==", "bodyText": "Is this what we did in the activate jobs handler? Because now we won't know the real reason we couldn't create a workflow anymore, right? I guess we at least send the last error, which is already better than nothing. We had a short discussion on slack about it, and basically it boils down to what can the user do with the error you return? So in this sense, it's quite application specific, and you need to figure out the hierarchy of errors, e.g. which carries more information such that the user can actually do something about it (e.g. retry, retry with backoff, etc.).\nAnyway, this is probably fine for now, I guess - we can figure out error handling for the 0.24 implementation, unless you see any major issues here from a client PoV.", "url": "https://github.com/camunda-cloud/zeebe/pull/4497#discussion_r423554723", "createdAt": "2020-05-12T08:28:05Z", "author": {"login": "npepinpe"}, "path": "gateway/src/main/java/io/zeebe/gateway/impl/job/CreateWorkflowHandler.java", "diffHunk": "@@ -0,0 +1,95 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.gateway.impl.job;\n+\n+import io.zeebe.gateway.Loggers;\n+import io.zeebe.gateway.cmd.BrokerErrorException;\n+import io.zeebe.gateway.impl.broker.BrokerClient;\n+import io.zeebe.gateway.impl.broker.BrokerResponseConsumer;\n+import io.zeebe.gateway.impl.broker.RoundRobinDispatchStrategy;\n+import io.zeebe.gateway.impl.broker.cluster.BrokerTopologyManager;\n+import io.zeebe.gateway.impl.broker.request.BrokerCreateWorkflowInstanceRequest;\n+import io.zeebe.protocol.impl.record.value.workflowinstance.WorkflowInstanceCreationRecord;\n+import io.zeebe.protocol.record.ErrorCode;\n+import io.zeebe.transport.impl.sender.NoRemoteAddressFoundException;\n+import java.util.function.Consumer;\n+\n+public class CreateWorkflowHandler {\n+\n+  private final BrokerClient brokerClient;\n+  private final RoundRobinDispatchStrategy roundRobinDispatchStrategy;\n+\n+  public CreateWorkflowHandler(\n+      final BrokerClient brokerClient, final BrokerTopologyManager topologyManager) {\n+    this.brokerClient = brokerClient;\n+    roundRobinDispatchStrategy = new RoundRobinDispatchStrategy(topologyManager);\n+  }\n+\n+  public void createWorkflow(\n+      final int partitionsCount,\n+      final BrokerCreateWorkflowInstanceRequest request,\n+      final BrokerResponseConsumer<WorkflowInstanceCreationRecord> responseConsumer,\n+      final Consumer<Throwable> throwableConsumer) {\n+    createWorkflow(\n+        request,\n+        partitionIdIteratorForType(partitionsCount),\n+        responseConsumer,\n+        throwableConsumer,\n+        null);\n+  }\n+\n+  private void createWorkflow(\n+      final BrokerCreateWorkflowInstanceRequest request,\n+      final PartitionIdIterator partitionIdIterator,\n+      final BrokerResponseConsumer<WorkflowInstanceCreationRecord> responseConsumer,\n+      final Consumer<Throwable> throwableConsumer,\n+      final Throwable lastError) {\n+\n+    if (partitionIdIterator.hasNext()) {\n+      final int partitionId = partitionIdIterator.next();\n+\n+      // partitions to check\n+      request.setPartitionId(partitionId);\n+      brokerClient.sendRequest(\n+          request,\n+          responseConsumer,\n+          error -> {\n+            if (shouldRetry(error)) {\n+              Loggers.GATEWAY_LOGGER.trace(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3c34e240e5fc271c5c894d98f102d0270beec87e"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU1NjI4NQ==", "bodyText": "This can be confusing with the notion of the retry predicate - I would rename to something like\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              private boolean shouldRetry(final Throwable error) {\n          \n          \n            \n              private boolean shouldTryNextPartition(final Throwable error) {", "url": "https://github.com/camunda-cloud/zeebe/pull/4497#discussion_r423556285", "createdAt": "2020-05-12T08:30:16Z", "author": {"login": "npepinpe"}, "path": "gateway/src/main/java/io/zeebe/gateway/impl/job/CreateWorkflowHandler.java", "diffHunk": "@@ -0,0 +1,95 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.gateway.impl.job;\n+\n+import io.zeebe.gateway.Loggers;\n+import io.zeebe.gateway.cmd.BrokerErrorException;\n+import io.zeebe.gateway.impl.broker.BrokerClient;\n+import io.zeebe.gateway.impl.broker.BrokerResponseConsumer;\n+import io.zeebe.gateway.impl.broker.RoundRobinDispatchStrategy;\n+import io.zeebe.gateway.impl.broker.cluster.BrokerTopologyManager;\n+import io.zeebe.gateway.impl.broker.request.BrokerCreateWorkflowInstanceRequest;\n+import io.zeebe.protocol.impl.record.value.workflowinstance.WorkflowInstanceCreationRecord;\n+import io.zeebe.protocol.record.ErrorCode;\n+import io.zeebe.transport.impl.sender.NoRemoteAddressFoundException;\n+import java.util.function.Consumer;\n+\n+public class CreateWorkflowHandler {\n+\n+  private final BrokerClient brokerClient;\n+  private final RoundRobinDispatchStrategy roundRobinDispatchStrategy;\n+\n+  public CreateWorkflowHandler(\n+      final BrokerClient brokerClient, final BrokerTopologyManager topologyManager) {\n+    this.brokerClient = brokerClient;\n+    roundRobinDispatchStrategy = new RoundRobinDispatchStrategy(topologyManager);\n+  }\n+\n+  public void createWorkflow(\n+      final int partitionsCount,\n+      final BrokerCreateWorkflowInstanceRequest request,\n+      final BrokerResponseConsumer<WorkflowInstanceCreationRecord> responseConsumer,\n+      final Consumer<Throwable> throwableConsumer) {\n+    createWorkflow(\n+        request,\n+        partitionIdIteratorForType(partitionsCount),\n+        responseConsumer,\n+        throwableConsumer,\n+        null);\n+  }\n+\n+  private void createWorkflow(\n+      final BrokerCreateWorkflowInstanceRequest request,\n+      final PartitionIdIterator partitionIdIterator,\n+      final BrokerResponseConsumer<WorkflowInstanceCreationRecord> responseConsumer,\n+      final Consumer<Throwable> throwableConsumer,\n+      final Throwable lastError) {\n+\n+    if (partitionIdIterator.hasNext()) {\n+      final int partitionId = partitionIdIterator.next();\n+\n+      // partitions to check\n+      request.setPartitionId(partitionId);\n+      brokerClient.sendRequest(\n+          request,\n+          responseConsumer,\n+          error -> {\n+            if (shouldRetry(error)) {\n+              Loggers.GATEWAY_LOGGER.trace(\n+                  \"Failed to create workflow on partition {}\",\n+                  partitionIdIterator.getCurrentPartitionId(),\n+                  error);\n+              createWorkflow(\n+                  request, partitionIdIterator, responseConsumer, throwableConsumer, error);\n+            } else {\n+              throwableConsumer.accept(error);\n+            }\n+          },\n+          response -> false);\n+    } else {\n+      // no partition left to check\n+      throwableConsumer.accept(lastError);\n+    }\n+  }\n+\n+  private boolean shouldRetry(final Throwable error) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3c34e240e5fc271c5c894d98f102d0270beec87e"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU1ODcyNQ==", "bodyText": "Let's revisit the whitelist here for the 0.24 implementation, because there may be more than resource exhausted required (e.g. when upgrading maybe you want have different broker versions, so you might want to try a different partition on INVALID_CLIENT_VERSION?). When we write the issue for it, we should make sure not to forget about it.", "url": "https://github.com/camunda-cloud/zeebe/pull/4497#discussion_r423558725", "createdAt": "2020-05-12T08:34:07Z", "author": {"login": "npepinpe"}, "path": "gateway/src/main/java/io/zeebe/gateway/impl/job/CreateWorkflowHandler.java", "diffHunk": "@@ -0,0 +1,95 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.gateway.impl.job;\n+\n+import io.zeebe.gateway.Loggers;\n+import io.zeebe.gateway.cmd.BrokerErrorException;\n+import io.zeebe.gateway.impl.broker.BrokerClient;\n+import io.zeebe.gateway.impl.broker.BrokerResponseConsumer;\n+import io.zeebe.gateway.impl.broker.RoundRobinDispatchStrategy;\n+import io.zeebe.gateway.impl.broker.cluster.BrokerTopologyManager;\n+import io.zeebe.gateway.impl.broker.request.BrokerCreateWorkflowInstanceRequest;\n+import io.zeebe.protocol.impl.record.value.workflowinstance.WorkflowInstanceCreationRecord;\n+import io.zeebe.protocol.record.ErrorCode;\n+import io.zeebe.transport.impl.sender.NoRemoteAddressFoundException;\n+import java.util.function.Consumer;\n+\n+public class CreateWorkflowHandler {\n+\n+  private final BrokerClient brokerClient;\n+  private final RoundRobinDispatchStrategy roundRobinDispatchStrategy;\n+\n+  public CreateWorkflowHandler(\n+      final BrokerClient brokerClient, final BrokerTopologyManager topologyManager) {\n+    this.brokerClient = brokerClient;\n+    roundRobinDispatchStrategy = new RoundRobinDispatchStrategy(topologyManager);\n+  }\n+\n+  public void createWorkflow(\n+      final int partitionsCount,\n+      final BrokerCreateWorkflowInstanceRequest request,\n+      final BrokerResponseConsumer<WorkflowInstanceCreationRecord> responseConsumer,\n+      final Consumer<Throwable> throwableConsumer) {\n+    createWorkflow(\n+        request,\n+        partitionIdIteratorForType(partitionsCount),\n+        responseConsumer,\n+        throwableConsumer,\n+        null);\n+  }\n+\n+  private void createWorkflow(\n+      final BrokerCreateWorkflowInstanceRequest request,\n+      final PartitionIdIterator partitionIdIterator,\n+      final BrokerResponseConsumer<WorkflowInstanceCreationRecord> responseConsumer,\n+      final Consumer<Throwable> throwableConsumer,\n+      final Throwable lastError) {\n+\n+    if (partitionIdIterator.hasNext()) {\n+      final int partitionId = partitionIdIterator.next();\n+\n+      // partitions to check\n+      request.setPartitionId(partitionId);\n+      brokerClient.sendRequest(\n+          request,\n+          responseConsumer,\n+          error -> {\n+            if (shouldRetry(error)) {\n+              Loggers.GATEWAY_LOGGER.trace(\n+                  \"Failed to create workflow on partition {}\",\n+                  partitionIdIterator.getCurrentPartitionId(),\n+                  error);\n+              createWorkflow(\n+                  request, partitionIdIterator, responseConsumer, throwableConsumer, error);\n+            } else {\n+              throwableConsumer.accept(error);\n+            }\n+          },\n+          response -> false);\n+    } else {\n+      // no partition left to check\n+      throwableConsumer.accept(lastError);\n+    }\n+  }\n+\n+  private boolean shouldRetry(final Throwable error) {\n+    if (error instanceof NoRemoteAddressFoundException) {\n+      return true;\n+    } else if (error instanceof BrokerErrorException) {\n+      return ((BrokerErrorException) error).getError().getCode()\n+          == ErrorCode.PARTITION_LEADER_MISMATCH;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3c34e240e5fc271c5c894d98f102d0270beec87e"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU2MzkyMw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            .filter(r -> r.getPartitionId() == failingPartition)\n          \n          \n            \n                            .exists())\n          \n          \n            \n                    .isTrue();\n          \n          \n            \n                            .filter(r -> r.getPartitionId() == failingPartition))\n          \n          \n            \n                    .hasSizeGreaterThanOrEqualTo(1);", "url": "https://github.com/camunda-cloud/zeebe/pull/4497#discussion_r423563923", "createdAt": "2020-05-12T08:42:12Z", "author": {"login": "npepinpe"}, "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/clustering/AvailabilityTest.java", "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.it.clustering;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import io.zeebe.broker.it.GrpcClientRule;\n+import io.zeebe.client.api.response.ActivatedJob;\n+import io.zeebe.client.api.response.BrokerInfo;\n+import io.zeebe.model.bpmn.Bpmn;\n+import io.zeebe.model.bpmn.BpmnModelInstance;\n+import io.zeebe.protocol.record.Record;\n+import io.zeebe.protocol.record.intent.WorkflowInstanceCreationIntent;\n+import io.zeebe.test.util.record.RecordingExporter;\n+import java.time.Duration;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.RuleChain;\n+import org.junit.rules.Timeout;\n+\n+public class AvailabilityTest {\n+\n+  private static final String JOBTYPE = \"availability-test\";\n+  private static final BpmnModelInstance WORKFLOW =\n+      Bpmn.createExecutableProcess(\"process\")\n+          .startEvent()\n+          .serviceTask(\n+              \"task\",\n+              t -> {\n+                t.zeebeTaskType(JOBTYPE);\n+              })\n+          .endEvent()\n+          .done();\n+  private final int partitionCount = 3;\n+  private final Timeout testTimeout = Timeout.seconds(120);\n+  private final ClusteringRule clusteringRule = new ClusteringRule(partitionCount, 1, 3);\n+  private final GrpcClientRule clientRule = new GrpcClientRule(clusteringRule);\n+\n+  @Rule\n+  public RuleChain ruleChain =\n+      RuleChain.outerRule(testTimeout).around(clusteringRule).around(clientRule);\n+\n+  private long workflowKey;\n+\n+  @Before\n+  public void setup() {\n+    workflowKey = clientRule.deployWorkflow(WORKFLOW);\n+  }\n+\n+  @Test\n+  public void shouldCreateWorkflowWhenOnePartitionDown() {\n+    final BrokerInfo leaderForPartition = clusteringRule.getLeaderForPartition(partitionCount);\n+\n+    // when\n+    clusteringRule.stopBroker(leaderForPartition.getNodeId(), false);\n+\n+    for (int i = 0; i < 2 * partitionCount; i++) {\n+      clientRule.createWorkflowInstance(workflowKey);\n+    }\n+\n+    // then\n+    // all create instance requests should complete successfully\n+    assertThat(\n+            RecordingExporter.workflowInstanceCreationRecords()\n+                .withIntent(WorkflowInstanceCreationIntent.CREATED)\n+                .map(Record::getPartitionId)\n+                .limit(2 * partitionCount)\n+                .count())\n+        .isEqualTo(2 * partitionCount);\n+  }\n+\n+  @Test\n+  public void shouldCreateWorkflowWhenPartitionRecovers() {\n+    // given\n+    final int failingPartition = partitionCount;\n+    final BrokerInfo leaderForPartition = clusteringRule.getLeaderForPartition(failingPartition);\n+    clusteringRule.stopBroker(leaderForPartition.getNodeId(), false);\n+\n+    for (int i = 0; i < partitionCount; i++) {\n+      clientRule.createWorkflowInstance(workflowKey);\n+    }\n+\n+    // when\n+    clusteringRule.restartBroker(leaderForPartition.getNodeId());\n+\n+    for (int i = 0; i < partitionCount; i++) {\n+      clientRule.createWorkflowInstance(workflowKey);\n+    }\n+\n+    // then\n+    // all create instance requests should complete successfully\n+    assertThat(\n+            RecordingExporter.workflowInstanceCreationRecords()\n+                .withIntent(WorkflowInstanceCreationIntent.CREATED)\n+                .filter(r -> r.getPartitionId() == failingPartition)\n+                .exists())\n+        .isTrue();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "235aefb294a462e1018bc6f69a3ba4f08230e2c7"}, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU2NDU4OA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                assertThat(activatedJobsKey.size()).isEqualTo(numInstances);\n          \n          \n            \n                assertThat(activatedJobsKey).hasSize(numInstances);", "url": "https://github.com/camunda-cloud/zeebe/pull/4497#discussion_r423564588", "createdAt": "2020-05-12T08:43:13Z", "author": {"login": "npepinpe"}, "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/clustering/AvailabilityTest.java", "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.it.clustering;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import io.zeebe.broker.it.GrpcClientRule;\n+import io.zeebe.client.api.response.ActivatedJob;\n+import io.zeebe.client.api.response.BrokerInfo;\n+import io.zeebe.model.bpmn.Bpmn;\n+import io.zeebe.model.bpmn.BpmnModelInstance;\n+import io.zeebe.protocol.record.Record;\n+import io.zeebe.protocol.record.intent.WorkflowInstanceCreationIntent;\n+import io.zeebe.test.util.record.RecordingExporter;\n+import java.time.Duration;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.RuleChain;\n+import org.junit.rules.Timeout;\n+\n+public class AvailabilityTest {\n+\n+  private static final String JOBTYPE = \"availability-test\";\n+  private static final BpmnModelInstance WORKFLOW =\n+      Bpmn.createExecutableProcess(\"process\")\n+          .startEvent()\n+          .serviceTask(\n+              \"task\",\n+              t -> {\n+                t.zeebeTaskType(JOBTYPE);\n+              })\n+          .endEvent()\n+          .done();\n+  private final int partitionCount = 3;\n+  private final Timeout testTimeout = Timeout.seconds(120);\n+  private final ClusteringRule clusteringRule = new ClusteringRule(partitionCount, 1, 3);\n+  private final GrpcClientRule clientRule = new GrpcClientRule(clusteringRule);\n+\n+  @Rule\n+  public RuleChain ruleChain =\n+      RuleChain.outerRule(testTimeout).around(clusteringRule).around(clientRule);\n+\n+  private long workflowKey;\n+\n+  @Before\n+  public void setup() {\n+    workflowKey = clientRule.deployWorkflow(WORKFLOW);\n+  }\n+\n+  @Test\n+  public void shouldCreateWorkflowWhenOnePartitionDown() {\n+    final BrokerInfo leaderForPartition = clusteringRule.getLeaderForPartition(partitionCount);\n+\n+    // when\n+    clusteringRule.stopBroker(leaderForPartition.getNodeId(), false);\n+\n+    for (int i = 0; i < 2 * partitionCount; i++) {\n+      clientRule.createWorkflowInstance(workflowKey);\n+    }\n+\n+    // then\n+    // all create instance requests should complete successfully\n+    assertThat(\n+            RecordingExporter.workflowInstanceCreationRecords()\n+                .withIntent(WorkflowInstanceCreationIntent.CREATED)\n+                .map(Record::getPartitionId)\n+                .limit(2 * partitionCount)\n+                .count())\n+        .isEqualTo(2 * partitionCount);\n+  }\n+\n+  @Test\n+  public void shouldCreateWorkflowWhenPartitionRecovers() {\n+    // given\n+    final int failingPartition = partitionCount;\n+    final BrokerInfo leaderForPartition = clusteringRule.getLeaderForPartition(failingPartition);\n+    clusteringRule.stopBroker(leaderForPartition.getNodeId(), false);\n+\n+    for (int i = 0; i < partitionCount; i++) {\n+      clientRule.createWorkflowInstance(workflowKey);\n+    }\n+\n+    // when\n+    clusteringRule.restartBroker(leaderForPartition.getNodeId());\n+\n+    for (int i = 0; i < partitionCount; i++) {\n+      clientRule.createWorkflowInstance(workflowKey);\n+    }\n+\n+    // then\n+    // all create instance requests should complete successfully\n+    assertThat(\n+            RecordingExporter.workflowInstanceCreationRecords()\n+                .withIntent(WorkflowInstanceCreationIntent.CREATED)\n+                .filter(r -> r.getPartitionId() == failingPartition)\n+                .exists())\n+        .isTrue();\n+  }\n+\n+  @Test\n+  public void shouldActivateJobsWhenOnePartitionDown() {\n+    // given\n+    final int numInstances = 2 * partitionCount;\n+    final BrokerInfo leaderForPartition = clusteringRule.getLeaderForPartition(partitionCount);\n+    clusteringRule.stopBroker(leaderForPartition.getNodeId(), false);\n+\n+    for (int i = 0; i < numInstances; i++) {\n+      clientRule.createWorkflowInstance(workflowKey);\n+    }\n+\n+    // when\n+\n+    final Set<Long> activatedJobsKey = new HashSet<>();\n+    for (int i = 0; i < numInstances; i++) {\n+      final List<ActivatedJob> jobs =\n+          clientRule\n+              .getClient()\n+              .newActivateJobsCommand()\n+              .jobType(JOBTYPE)\n+              .maxJobsToActivate(1)\n+              .timeout(Duration.ofMinutes(5))\n+              .requestTimeout(Duration.ofSeconds(5)) // put a lower timeout than gateway timeout\n+              .send()\n+              .join()\n+              .getJobs();\n+      jobs.forEach(job -> activatedJobsKey.add(job.getKey()));\n+    }\n+\n+    // then\n+    assertThat(activatedJobsKey.size()).isEqualTo(numInstances);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "235aefb294a462e1018bc6f69a3ba4f08230e2c7"}, "originalPosition": 139}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU2NzE0Ng==", "bodyText": "I'm not sure what the changes here have to do with the PR - what am I missing?", "url": "https://github.com/camunda-cloud/zeebe/pull/4497#discussion_r423567146", "createdAt": "2020-05-12T08:46:53Z", "author": {"login": "npepinpe"}, "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/startup/BrokerReprocessingTest.java", "diffHunk": "@@ -27,6 +27,8 @@\n import io.zeebe.client.api.response.ActivateJobsResponse;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f6bd2fd07556839bb228aeefe840f88baa1a54f3"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU2ODQ3Mg==", "bodyText": "Is this change because the transport was previously automatically retrying all NoRemoteAddressFoundException?", "url": "https://github.com/camunda-cloud/zeebe/pull/4497#discussion_r423568472", "createdAt": "2020-05-12T08:48:40Z", "author": {"login": "npepinpe"}, "path": "transport/src/main/java/io/zeebe/transport/impl/ClientOutputImpl.java", "diffHunk": "@@ -80,22 +80,22 @@ private boolean sendTransportMessage(int remoteStreamId, BufferWriter writer) {\n   }\n \n   @Override\n-  public ActorFuture<ClientResponse> sendRequest(Integer nodeId, BufferWriter writer) {\n+  public ActorFuture<ClientResponse> sendRequest(final Integer nodeId, final BufferWriter writer) {\n     return sendRequest(nodeId, writer, defaultRequestRetryTimeout);\n   }\n \n   @Override\n   public ActorFuture<ClientResponse> sendRequest(\n-      Integer nodeId, BufferWriter writer, Duration timeout) {\n-    return sendRequestWithRetry(() -> nodeId, (b) -> false, writer, timeout);\n+      final Integer nodeId, final BufferWriter writer, final Duration timeout) {\n+    return sendRequestWithRetry(() -> nodeId, this::shouldRetry, writer, timeout);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f6bd2fd07556839bb228aeefe840f88baa1a54f3"}, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU3MTAwNA==", "bodyText": "Can we declare this as a variable instead of passing it as is, so we can name it in a way that it makes it explicit we're generating a failed response to propagate that no remote address was found? e.g. final IncomingResponse failedResponse = ... or something.", "url": "https://github.com/camunda-cloud/zeebe/pull/4497#discussion_r423571004", "createdAt": "2020-05-12T08:52:26Z", "author": {"login": "npepinpe"}, "path": "transport/src/main/java/io/zeebe/transport/impl/sender/Sender.java", "diffHunk": "@@ -198,8 +188,13 @@ private void onRequestSubmitted(final OutgoingRequest request) {\n           actor.runDelayed(Duration.ofMillis(10), () -> submittedRequests.offer(request));\n         }\n       } else {\n-        // no remote address available, retry\n-        actor.runDelayed(Duration.ofMillis(10), () -> submittedRequests.offer(request));\n+        if (request.shouldRetry(\n+            new IncomingResponse(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f6bd2fd07556839bb228aeefe840f88baa1a54f3"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzU3MzE3OQ==", "bodyText": "I can only see two usages for the predicate, here when we have no remote address, and when we try to complete the request and an error has occurred.\nThis makes me think maybe for the 0.24 implementation we can avoid conflating the two and have the \"should-retry-if-no-remote-handler-found\" more as a property of the request than part of the predicate itself. Anyway we can discuss that later.", "url": "https://github.com/camunda-cloud/zeebe/pull/4497#discussion_r423573179", "createdAt": "2020-05-12T08:55:40Z", "author": {"login": "npepinpe"}, "path": "transport/src/main/java/io/zeebe/transport/impl/sender/Sender.java", "diffHunk": "@@ -198,8 +188,13 @@ private void onRequestSubmitted(final OutgoingRequest request) {\n           actor.runDelayed(Duration.ofMillis(10), () -> submittedRequests.offer(request));\n         }\n       } else {\n-        // no remote address available, retry\n-        actor.runDelayed(Duration.ofMillis(10), () -> submittedRequests.offer(request));\n+        if (request.shouldRetry(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f6bd2fd07556839bb228aeefe840f88baa1a54f3"}, "originalPosition": 79}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA5OTE1Mjk1", "url": "https://github.com/camunda-cloud/zeebe/pull/4497#pullrequestreview-409915295", "createdAt": "2020-05-12T10:40:05Z", "commit": {"oid": "f00c35d3caeafaadb920453f0ce3d16311d9bbab"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "24a00f67dff69626ba940154417284b0af02b2de", "author": {"user": {"login": "deepthidevaki", "name": "Deepthi Devaki Akkoorath"}}, "url": "https://github.com/camunda-cloud/zeebe/commit/24a00f67dff69626ba940154417284b0af02b2de", "committedDate": "2020-05-12T11:19:09Z", "message": "chore(gateway): retry requests with a different partition if leader not available\n\nFor requests that can be send to any partition (create workflow instace), retry with different partition when leader not available."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f00c35d3caeafaadb920453f0ce3d16311d9bbab", "author": {"user": {"login": "deepthidevaki", "name": "Deepthi Devaki Akkoorath"}}, "url": "https://github.com/camunda-cloud/zeebe/commit/f00c35d3caeafaadb920453f0ce3d16311d9bbab", "committedDate": "2020-05-12T10:03:18Z", "message": "chore(gateway): review comments"}, "afterCommit": {"oid": "24a00f67dff69626ba940154417284b0af02b2de", "author": {"user": {"login": "deepthidevaki", "name": "Deepthi Devaki Akkoorath"}}, "url": "https://github.com/camunda-cloud/zeebe/commit/24a00f67dff69626ba940154417284b0af02b2de", "committedDate": "2020-05-12T11:19:09Z", "message": "chore(gateway): retry requests with a different partition if leader not available\n\nFor requests that can be send to any partition (create workflow instace), retry with different partition when leader not available."}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2899, "cost": 1, "resetAt": "2021-11-01T13:07:16Z"}}}