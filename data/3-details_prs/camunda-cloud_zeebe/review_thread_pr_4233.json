{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzk5NDE0NDE2", "number": 4233, "reviewThreads": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxMzoyNzowMlrODvIHxQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNzoyNzo1MVrODx8o1Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwNzQyNzI1OnYy", "diffSide": "RIGHT", "path": "engine/src/main/java/io/zeebe/engine/metrics/ExecutionMetrics.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxMzoyNzowMlrOGBXoDw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxMzoyNzowMlrOGBXoDw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDA4ODg0Nw==", "bodyText": "Nipick: Can we pass the elapsed time directly so we don't use ActorClock directly here? Just seems strange to couple this to the ActorClock here\nEDIT: same below I guess", "url": "https://github.com/camunda-cloud/zeebe/pull/4233#discussion_r404088847", "createdAt": "2020-04-06T13:27:02Z", "author": {"login": "npepinpe"}, "path": "engine/src/main/java/io/zeebe/engine/metrics/ExecutionMetrics.java", "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.engine.metrics;\n+\n+import io.prometheus.client.Histogram;\n+import io.zeebe.util.sched.clock.ActorClock;\n+\n+public class ExecutionMetrics {\n+\n+  private static final Histogram WORKFLOW_INSTANCE_EXECUTION =\n+      Histogram.build()\n+          .namespace(\"zeebe\")\n+          .name(\"workflow_instance_execution_time\")\n+          .help(\"The execution time of processing a complete workflow instance\")\n+          .labelNames(\"partition\")\n+          .register();\n+\n+  private final String partitionIdLabel;\n+\n+  public ExecutionMetrics(final int partitionId) {\n+    this.partitionIdLabel = String.valueOf(partitionId);\n+  }\n+\n+  public void observeWorkflowInstanceExecutionTime(final long created) {\n+    WORKFLOW_INSTANCE_EXECUTION\n+        .labels(partitionIdLabel)\n+        .observe((ActorClock.currentTimeMillis() - created) / 1000f);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b41991df06e7991e64b2d6f797c9a602fc5b9c3d"}, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwNzQzMjUyOnYy", "diffSide": "RIGHT", "path": "engine/src/main/java/io/zeebe/engine/state/ZbColumnFamilies.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxMzoyODoxMFrOGBXrOg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNDowMjo0NVrOGBZP1A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDA4OTY1OA==", "bodyText": "Weren't you the one who asked not to create new column families? \ud83d\ude1c", "url": "https://github.com/camunda-cloud/zeebe/pull/4233#discussion_r404089658", "createdAt": "2020-04-06T13:28:10Z", "author": {"login": "npepinpe"}, "path": "engine/src/main/java/io/zeebe/engine/state/ZbColumnFamilies.java", "diffHunk": "@@ -42,6 +42,7 @@\n \n   // jobs\n   JOBS,\n+  JOBS_CREATION,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b41991df06e7991e64b2d6f797c9a602fc5b9c3d"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDExNTQxMg==", "bodyText": "Jep but we didn't decided against it so \ud83e\udd37\u200d\u2642\ufe0f", "url": "https://github.com/camunda-cloud/zeebe/pull/4233#discussion_r404115412", "createdAt": "2020-04-06T14:02:45Z", "author": {"login": "Zelldon"}, "path": "engine/src/main/java/io/zeebe/engine/state/ZbColumnFamilies.java", "diffHunk": "@@ -42,6 +42,7 @@\n \n   // jobs\n   JOBS,\n+  JOBS_CREATION,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDA4OTY1OA=="}, "originalCommit": {"oid": "b41991df06e7991e64b2d6f797c9a602fc5b9c3d"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwNzQzOTQ5OnYy", "diffSide": "RIGHT", "path": "engine/src/main/java/io/zeebe/engine/state/instance/ElementInstance.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxMzoyOTo0OFrOGBXvqg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNDowNDozMlrOGBZVLg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDA5MDc5NA==", "bodyText": "Hm, don't know how I feel about using the ActorClock as a default, which has different behaviour based on which thread calls it \ud83d\ude05\nAlso, what about existing instances? Will this metric give me initially incredibly fast jobs since creation time will be instantiated with the current timestamp? \ud83d\ude05", "url": "https://github.com/camunda-cloud/zeebe/pull/4233#discussion_r404090794", "createdAt": "2020-04-06T13:29:48Z", "author": {"login": "npepinpe"}, "path": "engine/src/main/java/io/zeebe/engine/state/instance/ElementInstance.java", "diffHunk": "@@ -15,10 +15,13 @@\n import io.zeebe.msgpack.property.ObjectProperty;\n import io.zeebe.protocol.impl.record.value.workflowinstance.WorkflowInstanceRecord;\n import io.zeebe.protocol.record.intent.WorkflowInstanceIntent;\n+import io.zeebe.util.sched.clock.ActorClock;\n \n public final class ElementInstance extends UnpackedObject implements DbValue {\n \n   private final LongProperty parentKeyProp = new LongProperty(\"parentKey\", -1L);\n+  private final LongProperty creationTimeProp =\n+      new LongProperty(\"creationTime\", ActorClock.currentTimeMillis());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b41991df06e7991e64b2d6f797c9a602fc5b9c3d"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDExNjc4Mg==", "bodyText": "Hm, don't know how I feel about using the ActorClock as a default, which has different behaviour based on which thread calls it sweat_smile\n\nWhat is the alternative? You want to use system time? I mean we did in our test but actually the clock was introduced to avoid calling system time to often.\n\nAlso, what about existing instances? Will this metric give me initially incredibly fast jobs since creation time will be instantiated with the current timestamp?\n\ndont get this question to be honest", "url": "https://github.com/camunda-cloud/zeebe/pull/4233#discussion_r404116782", "createdAt": "2020-04-06T14:04:32Z", "author": {"login": "Zelldon"}, "path": "engine/src/main/java/io/zeebe/engine/state/instance/ElementInstance.java", "diffHunk": "@@ -15,10 +15,13 @@\n import io.zeebe.msgpack.property.ObjectProperty;\n import io.zeebe.protocol.impl.record.value.workflowinstance.WorkflowInstanceRecord;\n import io.zeebe.protocol.record.intent.WorkflowInstanceIntent;\n+import io.zeebe.util.sched.clock.ActorClock;\n \n public final class ElementInstance extends UnpackedObject implements DbValue {\n \n   private final LongProperty parentKeyProp = new LongProperty(\"parentKey\", -1L);\n+  private final LongProperty creationTimeProp =\n+      new LongProperty(\"creationTime\", ActorClock.currentTimeMillis());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDA5MDc5NA=="}, "originalCommit": {"oid": "b41991df06e7991e64b2d6f797c9a602fc5b9c3d"}, "originalPosition": 10}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNDE0Njc5OnYy", "diffSide": "RIGHT", "path": "broker/src/main/java/io/zeebe/broker/exporter/metrics/MetricsExporter.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQxNDozNToxNlrOGFRtEg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNzoxNjozM1rOGFswDw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE4NjEzMA==", "bodyText": "Nitpick: do we need to know from the variable name that it is a tree map? I guess creationTimeToJobKeyNavigableMap doesn't have the same ring ;) I guess I'm just surprised since we don't really want to care about the concrete time except when creating it \ud83e\udd37\u200d\u2642\ufe0f\nJust a nitpick, feel free to ignore", "url": "https://github.com/camunda-cloud/zeebe/pull/4233#discussion_r408186130", "createdAt": "2020-04-14T14:35:16Z", "author": {"login": "npepinpe"}, "path": "broker/src/main/java/io/zeebe/broker/exporter/metrics/MetricsExporter.java", "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.exporter.metrics;\n+\n+import io.zeebe.broker.system.configuration.ExporterCfg;\n+import io.zeebe.exporter.api.Exporter;\n+import io.zeebe.exporter.api.context.Controller;\n+import io.zeebe.protocol.record.Record;\n+import io.zeebe.protocol.record.RecordType;\n+import io.zeebe.protocol.record.ValueType;\n+import io.zeebe.protocol.record.intent.JobIntent;\n+import io.zeebe.protocol.record.intent.WorkflowInstanceIntent;\n+import io.zeebe.protocol.record.value.WorkflowInstanceRecordValue;\n+import java.time.Duration;\n+import java.util.NavigableMap;\n+import java.util.TreeMap;\n+import org.agrona.collections.Long2LongHashMap;\n+\n+public class MetricsExporter implements Exporter {\n+\n+  public static final Duration TIME_TO_LIVE = Duration.ofSeconds(10);\n+  private final ExecutionLatencyMetrics executionLatencyMetrics;\n+  private final Long2LongHashMap jobKeyToCreationTimeMap;\n+  private final Long2LongHashMap workflowInstanceKeyToCreationTimeMap;\n+\n+  private final NavigableMap<Long, Long> creationTimeToJobKeyTreeMap;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13b2b31f9159d7d834cd2ed758eb9e178046108b"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODU4OTYxNA==", "bodyText": "I added the TreeMap just to know that we can use these subMap stuff, but yes NavigableMap would also be ok.\n\nI guess I'm just surprised since we don't really want to care about the concrete time except when creating it man_shrugging\n\nSorry but I don't get this comment.", "url": "https://github.com/camunda-cloud/zeebe/pull/4233#discussion_r408589614", "createdAt": "2020-04-15T05:30:07Z", "author": {"login": "Zelldon"}, "path": "broker/src/main/java/io/zeebe/broker/exporter/metrics/MetricsExporter.java", "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.exporter.metrics;\n+\n+import io.zeebe.broker.system.configuration.ExporterCfg;\n+import io.zeebe.exporter.api.Exporter;\n+import io.zeebe.exporter.api.context.Controller;\n+import io.zeebe.protocol.record.Record;\n+import io.zeebe.protocol.record.RecordType;\n+import io.zeebe.protocol.record.ValueType;\n+import io.zeebe.protocol.record.intent.JobIntent;\n+import io.zeebe.protocol.record.intent.WorkflowInstanceIntent;\n+import io.zeebe.protocol.record.value.WorkflowInstanceRecordValue;\n+import java.time.Duration;\n+import java.util.NavigableMap;\n+import java.util.TreeMap;\n+import org.agrona.collections.Long2LongHashMap;\n+\n+public class MetricsExporter implements Exporter {\n+\n+  public static final Duration TIME_TO_LIVE = Duration.ofSeconds(10);\n+  private final ExecutionLatencyMetrics executionLatencyMetrics;\n+  private final Long2LongHashMap jobKeyToCreationTimeMap;\n+  private final Long2LongHashMap workflowInstanceKeyToCreationTimeMap;\n+\n+  private final NavigableMap<Long, Long> creationTimeToJobKeyTreeMap;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE4NjEzMA=="}, "originalCommit": {"oid": "13b2b31f9159d7d834cd2ed758eb9e178046108b"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYyODMyOQ==", "bodyText": "Sorry, typo, I meant to write concrete type not concrete time haha, as treeMap the concrete type is part of the name \ud83d\ude05", "url": "https://github.com/camunda-cloud/zeebe/pull/4233#discussion_r408628329", "createdAt": "2020-04-15T07:14:34Z", "author": {"login": "npepinpe"}, "path": "broker/src/main/java/io/zeebe/broker/exporter/metrics/MetricsExporter.java", "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.exporter.metrics;\n+\n+import io.zeebe.broker.system.configuration.ExporterCfg;\n+import io.zeebe.exporter.api.Exporter;\n+import io.zeebe.exporter.api.context.Controller;\n+import io.zeebe.protocol.record.Record;\n+import io.zeebe.protocol.record.RecordType;\n+import io.zeebe.protocol.record.ValueType;\n+import io.zeebe.protocol.record.intent.JobIntent;\n+import io.zeebe.protocol.record.intent.WorkflowInstanceIntent;\n+import io.zeebe.protocol.record.value.WorkflowInstanceRecordValue;\n+import java.time.Duration;\n+import java.util.NavigableMap;\n+import java.util.TreeMap;\n+import org.agrona.collections.Long2LongHashMap;\n+\n+public class MetricsExporter implements Exporter {\n+\n+  public static final Duration TIME_TO_LIVE = Duration.ofSeconds(10);\n+  private final ExecutionLatencyMetrics executionLatencyMetrics;\n+  private final Long2LongHashMap jobKeyToCreationTimeMap;\n+  private final Long2LongHashMap workflowInstanceKeyToCreationTimeMap;\n+\n+  private final NavigableMap<Long, Long> creationTimeToJobKeyTreeMap;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE4NjEzMA=="}, "originalCommit": {"oid": "13b2b31f9159d7d834cd2ed758eb9e178046108b"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYyOTI2Mw==", "bodyText": "Haha that makes much more sense\ud83d\ude00\ud83d\udc4d", "url": "https://github.com/camunda-cloud/zeebe/pull/4233#discussion_r408629263", "createdAt": "2020-04-15T07:16:33Z", "author": {"login": "Zelldon"}, "path": "broker/src/main/java/io/zeebe/broker/exporter/metrics/MetricsExporter.java", "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.exporter.metrics;\n+\n+import io.zeebe.broker.system.configuration.ExporterCfg;\n+import io.zeebe.exporter.api.Exporter;\n+import io.zeebe.exporter.api.context.Controller;\n+import io.zeebe.protocol.record.Record;\n+import io.zeebe.protocol.record.RecordType;\n+import io.zeebe.protocol.record.ValueType;\n+import io.zeebe.protocol.record.intent.JobIntent;\n+import io.zeebe.protocol.record.intent.WorkflowInstanceIntent;\n+import io.zeebe.protocol.record.value.WorkflowInstanceRecordValue;\n+import java.time.Duration;\n+import java.util.NavigableMap;\n+import java.util.TreeMap;\n+import org.agrona.collections.Long2LongHashMap;\n+\n+public class MetricsExporter implements Exporter {\n+\n+  public static final Duration TIME_TO_LIVE = Duration.ofSeconds(10);\n+  private final ExecutionLatencyMetrics executionLatencyMetrics;\n+  private final Long2LongHashMap jobKeyToCreationTimeMap;\n+  private final Long2LongHashMap workflowInstanceKeyToCreationTimeMap;\n+\n+  private final NavigableMap<Long, Long> creationTimeToJobKeyTreeMap;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE4NjEzMA=="}, "originalCommit": {"oid": "13b2b31f9159d7d834cd2ed758eb9e178046108b"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNDE1ODM1OnYy", "diffSide": "RIGHT", "path": "broker/src/main/java/io/zeebe/broker/exporter/metrics/MetricsExporter.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQxNDozNzo0NFrOGFR0mg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNzozNzoxOFrOGFta-g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE4ODA1OA==", "bodyText": "Nitpick: any reason to use the concrete type instead of Map<Long, Long>?", "url": "https://github.com/camunda-cloud/zeebe/pull/4233#discussion_r408188058", "createdAt": "2020-04-14T14:37:44Z", "author": {"login": "npepinpe"}, "path": "broker/src/main/java/io/zeebe/broker/exporter/metrics/MetricsExporter.java", "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.exporter.metrics;\n+\n+import io.zeebe.broker.system.configuration.ExporterCfg;\n+import io.zeebe.exporter.api.Exporter;\n+import io.zeebe.exporter.api.context.Controller;\n+import io.zeebe.protocol.record.Record;\n+import io.zeebe.protocol.record.RecordType;\n+import io.zeebe.protocol.record.ValueType;\n+import io.zeebe.protocol.record.intent.JobIntent;\n+import io.zeebe.protocol.record.intent.WorkflowInstanceIntent;\n+import io.zeebe.protocol.record.value.WorkflowInstanceRecordValue;\n+import java.time.Duration;\n+import java.util.NavigableMap;\n+import java.util.TreeMap;\n+import org.agrona.collections.Long2LongHashMap;\n+\n+public class MetricsExporter implements Exporter {\n+\n+  public static final Duration TIME_TO_LIVE = Duration.ofSeconds(10);\n+  private final ExecutionLatencyMetrics executionLatencyMetrics;\n+  private final Long2LongHashMap jobKeyToCreationTimeMap;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13b2b31f9159d7d834cd2ed758eb9e178046108b"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODU4ODU1MQ==", "bodyText": "Actually yes because I wanted to avoid the auto boxing.", "url": "https://github.com/camunda-cloud/zeebe/pull/4233#discussion_r408588551", "createdAt": "2020-04-15T05:26:24Z", "author": {"login": "Zelldon"}, "path": "broker/src/main/java/io/zeebe/broker/exporter/metrics/MetricsExporter.java", "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.exporter.metrics;\n+\n+import io.zeebe.broker.system.configuration.ExporterCfg;\n+import io.zeebe.exporter.api.Exporter;\n+import io.zeebe.exporter.api.context.Controller;\n+import io.zeebe.protocol.record.Record;\n+import io.zeebe.protocol.record.RecordType;\n+import io.zeebe.protocol.record.ValueType;\n+import io.zeebe.protocol.record.intent.JobIntent;\n+import io.zeebe.protocol.record.intent.WorkflowInstanceIntent;\n+import io.zeebe.protocol.record.value.WorkflowInstanceRecordValue;\n+import java.time.Duration;\n+import java.util.NavigableMap;\n+import java.util.TreeMap;\n+import org.agrona.collections.Long2LongHashMap;\n+\n+public class MetricsExporter implements Exporter {\n+\n+  public static final Duration TIME_TO_LIVE = Duration.ofSeconds(10);\n+  private final ExecutionLatencyMetrics executionLatencyMetrics;\n+  private final Long2LongHashMap jobKeyToCreationTimeMap;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE4ODA1OA=="}, "originalCommit": {"oid": "13b2b31f9159d7d834cd2ed758eb9e178046108b"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYyODY0OA==", "bodyText": "Ah, right, doing a get(Long) would auto-box, true \ud83d\udc4d Though I wonder if the JIT would optimize if we did final long l = map.get(1) since we always auto-box/auto-unbox \ud83e\udd14", "url": "https://github.com/camunda-cloud/zeebe/pull/4233#discussion_r408628648", "createdAt": "2020-04-15T07:15:14Z", "author": {"login": "npepinpe"}, "path": "broker/src/main/java/io/zeebe/broker/exporter/metrics/MetricsExporter.java", "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.exporter.metrics;\n+\n+import io.zeebe.broker.system.configuration.ExporterCfg;\n+import io.zeebe.exporter.api.Exporter;\n+import io.zeebe.exporter.api.context.Controller;\n+import io.zeebe.protocol.record.Record;\n+import io.zeebe.protocol.record.RecordType;\n+import io.zeebe.protocol.record.ValueType;\n+import io.zeebe.protocol.record.intent.JobIntent;\n+import io.zeebe.protocol.record.intent.WorkflowInstanceIntent;\n+import io.zeebe.protocol.record.value.WorkflowInstanceRecordValue;\n+import java.time.Duration;\n+import java.util.NavigableMap;\n+import java.util.TreeMap;\n+import org.agrona.collections.Long2LongHashMap;\n+\n+public class MetricsExporter implements Exporter {\n+\n+  public static final Duration TIME_TO_LIVE = Duration.ofSeconds(10);\n+  private final ExecutionLatencyMetrics executionLatencyMetrics;\n+  private final Long2LongHashMap jobKeyToCreationTimeMap;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE4ODA1OA=="}, "originalCommit": {"oid": "13b2b31f9159d7d834cd2ed758eb9e178046108b"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODY0MDI1MA==", "bodyText": "I don't think so since you use different method then", "url": "https://github.com/camunda-cloud/zeebe/pull/4233#discussion_r408640250", "createdAt": "2020-04-15T07:37:18Z", "author": {"login": "Zelldon"}, "path": "broker/src/main/java/io/zeebe/broker/exporter/metrics/MetricsExporter.java", "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.exporter.metrics;\n+\n+import io.zeebe.broker.system.configuration.ExporterCfg;\n+import io.zeebe.exporter.api.Exporter;\n+import io.zeebe.exporter.api.context.Controller;\n+import io.zeebe.protocol.record.Record;\n+import io.zeebe.protocol.record.RecordType;\n+import io.zeebe.protocol.record.ValueType;\n+import io.zeebe.protocol.record.intent.JobIntent;\n+import io.zeebe.protocol.record.intent.WorkflowInstanceIntent;\n+import io.zeebe.protocol.record.value.WorkflowInstanceRecordValue;\n+import java.time.Duration;\n+import java.util.NavigableMap;\n+import java.util.TreeMap;\n+import org.agrona.collections.Long2LongHashMap;\n+\n+public class MetricsExporter implements Exporter {\n+\n+  public static final Duration TIME_TO_LIVE = Duration.ofSeconds(10);\n+  private final ExecutionLatencyMetrics executionLatencyMetrics;\n+  private final Long2LongHashMap jobKeyToCreationTimeMap;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODE4ODA1OA=="}, "originalCommit": {"oid": "13b2b31f9159d7d834cd2ed758eb9e178046108b"}, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNTIxMTUzOnYy", "diffSide": "RIGHT", "path": "broker/src/main/java/io/zeebe/broker/exporter/metrics/MetricsExporter.java", "isResolved": true, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQxODo0Nzo0OVrOGFcO1w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNzozNjoyN1rOGFtZGQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODM1ODYxNQ==", "bodyText": "How likely is it to get collision? If we write a batch of follow up events, it's likely they all have the same creation time, no? Especially if we use the ActorClock? Could we end up with \"garbage\" over time? I put it in quotes since technically we should eventually see the completion record for that entity, but still.", "url": "https://github.com/camunda-cloud/zeebe/pull/4233#discussion_r408358615", "createdAt": "2020-04-14T18:47:49Z", "author": {"login": "npepinpe"}, "path": "broker/src/main/java/io/zeebe/broker/exporter/metrics/MetricsExporter.java", "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.exporter.metrics;\n+\n+import io.zeebe.broker.system.configuration.ExporterCfg;\n+import io.zeebe.exporter.api.Exporter;\n+import io.zeebe.exporter.api.context.Controller;\n+import io.zeebe.protocol.record.Record;\n+import io.zeebe.protocol.record.RecordType;\n+import io.zeebe.protocol.record.ValueType;\n+import io.zeebe.protocol.record.intent.JobIntent;\n+import io.zeebe.protocol.record.intent.WorkflowInstanceIntent;\n+import io.zeebe.protocol.record.value.WorkflowInstanceRecordValue;\n+import java.time.Duration;\n+import java.util.NavigableMap;\n+import java.util.TreeMap;\n+import org.agrona.collections.Long2LongHashMap;\n+\n+public class MetricsExporter implements Exporter {\n+\n+  public static final Duration TIME_TO_LIVE = Duration.ofSeconds(10);\n+  private final ExecutionLatencyMetrics executionLatencyMetrics;\n+  private final Long2LongHashMap jobKeyToCreationTimeMap;\n+  private final Long2LongHashMap workflowInstanceKeyToCreationTimeMap;\n+\n+  private final NavigableMap<Long, Long> creationTimeToJobKeyTreeMap;\n+  private final NavigableMap<Long, Long> creationTimeToWorkflowInstanceKeyTreeMap;\n+\n+  private Controller controller;\n+\n+  public MetricsExporter() {\n+    this.executionLatencyMetrics = new ExecutionLatencyMetrics();\n+    this.jobKeyToCreationTimeMap = new Long2LongHashMap(-1);\n+    this.workflowInstanceKeyToCreationTimeMap = new Long2LongHashMap(-1);\n+    this.creationTimeToJobKeyTreeMap = new TreeMap<>();\n+    this.creationTimeToWorkflowInstanceKeyTreeMap = new TreeMap<>();\n+  }\n+\n+  @Override\n+  public void open(final Controller controller) {\n+    this.controller = controller;\n+\n+    controller.scheduleTask(TIME_TO_LIVE, this::cleanUp);\n+  }\n+\n+  @Override\n+  public void close() {\n+    jobKeyToCreationTimeMap.clear();\n+    workflowInstanceKeyToCreationTimeMap.clear();\n+  }\n+\n+  @Override\n+  public void export(final Record record) {\n+    if (record.getRecordType() != RecordType.EVENT) {\n+      controller.updateLastExportedRecordPosition(record.getPosition());\n+      return;\n+    }\n+\n+    final var partitionId = record.getPartitionId();\n+    final var recordKey = record.getKey();\n+\n+    final var currentValueType = record.getValueType();\n+    if (currentValueType == ValueType.JOB) {\n+      handleJobRecord(record, partitionId, recordKey);\n+    } else if (currentValueType == ValueType.WORKFLOW_INSTANCE) {\n+      handleWorkflowInstanceRecord(record, partitionId, recordKey);\n+    }\n+\n+    controller.updateLastExportedRecordPosition(record.getPosition());\n+  }\n+\n+  private void handleWorkflowInstanceRecord(\n+      final Record<?> record, final int partitionId, final long recordKey) {\n+    final var currentIntent = record.getIntent();\n+\n+    if (currentIntent == WorkflowInstanceIntent.ELEMENT_ACTIVATING\n+        && isWorkflowInstanceRecord(record)) {\n+      storeWorkflowInstanceCreation(record.getTimestamp(), recordKey);\n+    } else if (currentIntent == WorkflowInstanceIntent.ELEMENT_COMPLETED\n+        && isWorkflowInstanceRecord(record)) {\n+      final var creationTime = workflowInstanceKeyToCreationTimeMap.remove(recordKey);\n+      executionLatencyMetrics.observeWorkflowInstanceExecutionTime(\n+          partitionId, creationTime, record.getTimestamp());\n+    }\n+  }\n+\n+  private void storeWorkflowInstanceCreation(final long creationTime, final long recordKey) {\n+    workflowInstanceKeyToCreationTimeMap.put(recordKey, creationTime);\n+    creationTimeToWorkflowInstanceKeyTreeMap.put(creationTime, recordKey);\n+  }\n+\n+  private void handleJobRecord(\n+      final Record<?> record, final int partitionId, final long recordKey) {\n+    final var currentIntent = record.getIntent();\n+\n+    if (currentIntent == JobIntent.CREATED) {\n+      storeJobCreation(record.getTimestamp(), recordKey);\n+    } else if (currentIntent == JobIntent.ACTIVATED) {\n+      final var creationTime = jobKeyToCreationTimeMap.get(recordKey);\n+      executionLatencyMetrics.observeJobActivationTime(\n+          partitionId, creationTime, record.getTimestamp());\n+    } else if (currentIntent == JobIntent.COMPLETED) {\n+      final var creationTime = jobKeyToCreationTimeMap.remove(recordKey);\n+      executionLatencyMetrics.observeJobLifeTime(partitionId, creationTime, record.getTimestamp());\n+    }\n+  }\n+\n+  private void storeJobCreation(final long creationTime, final long recordKey) {\n+    jobKeyToCreationTimeMap.put(recordKey, creationTime);\n+    creationTimeToJobKeyTreeMap.put(creationTime, recordKey);\n+  }\n+\n+  private void cleanUp() {\n+    final var currentTimeMillis = System.currentTimeMillis();\n+\n+    final var deadTime = currentTimeMillis - TIME_TO_LIVE.toMillis();\n+    clearMaps(deadTime, creationTimeToJobKeyTreeMap, jobKeyToCreationTimeMap);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13b2b31f9159d7d834cd2ed758eb9e178046108b"}, "originalPosition": 122}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODU4OTU4Ng==", "bodyText": "If we write a batch of follow up events, it's likely they all have the same creation time, no?\n\nI think they have the same time on a batch.\n\nCould we end up with \"garbage\" over time? I put it in quotes since technically we should eventually see the completion record for that entity, but still.\n\nCan you elaborate on that?", "url": "https://github.com/camunda-cloud/zeebe/pull/4233#discussion_r408589586", "createdAt": "2020-04-15T05:29:58Z", "author": {"login": "Zelldon"}, "path": "broker/src/main/java/io/zeebe/broker/exporter/metrics/MetricsExporter.java", "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.exporter.metrics;\n+\n+import io.zeebe.broker.system.configuration.ExporterCfg;\n+import io.zeebe.exporter.api.Exporter;\n+import io.zeebe.exporter.api.context.Controller;\n+import io.zeebe.protocol.record.Record;\n+import io.zeebe.protocol.record.RecordType;\n+import io.zeebe.protocol.record.ValueType;\n+import io.zeebe.protocol.record.intent.JobIntent;\n+import io.zeebe.protocol.record.intent.WorkflowInstanceIntent;\n+import io.zeebe.protocol.record.value.WorkflowInstanceRecordValue;\n+import java.time.Duration;\n+import java.util.NavigableMap;\n+import java.util.TreeMap;\n+import org.agrona.collections.Long2LongHashMap;\n+\n+public class MetricsExporter implements Exporter {\n+\n+  public static final Duration TIME_TO_LIVE = Duration.ofSeconds(10);\n+  private final ExecutionLatencyMetrics executionLatencyMetrics;\n+  private final Long2LongHashMap jobKeyToCreationTimeMap;\n+  private final Long2LongHashMap workflowInstanceKeyToCreationTimeMap;\n+\n+  private final NavigableMap<Long, Long> creationTimeToJobKeyTreeMap;\n+  private final NavigableMap<Long, Long> creationTimeToWorkflowInstanceKeyTreeMap;\n+\n+  private Controller controller;\n+\n+  public MetricsExporter() {\n+    this.executionLatencyMetrics = new ExecutionLatencyMetrics();\n+    this.jobKeyToCreationTimeMap = new Long2LongHashMap(-1);\n+    this.workflowInstanceKeyToCreationTimeMap = new Long2LongHashMap(-1);\n+    this.creationTimeToJobKeyTreeMap = new TreeMap<>();\n+    this.creationTimeToWorkflowInstanceKeyTreeMap = new TreeMap<>();\n+  }\n+\n+  @Override\n+  public void open(final Controller controller) {\n+    this.controller = controller;\n+\n+    controller.scheduleTask(TIME_TO_LIVE, this::cleanUp);\n+  }\n+\n+  @Override\n+  public void close() {\n+    jobKeyToCreationTimeMap.clear();\n+    workflowInstanceKeyToCreationTimeMap.clear();\n+  }\n+\n+  @Override\n+  public void export(final Record record) {\n+    if (record.getRecordType() != RecordType.EVENT) {\n+      controller.updateLastExportedRecordPosition(record.getPosition());\n+      return;\n+    }\n+\n+    final var partitionId = record.getPartitionId();\n+    final var recordKey = record.getKey();\n+\n+    final var currentValueType = record.getValueType();\n+    if (currentValueType == ValueType.JOB) {\n+      handleJobRecord(record, partitionId, recordKey);\n+    } else if (currentValueType == ValueType.WORKFLOW_INSTANCE) {\n+      handleWorkflowInstanceRecord(record, partitionId, recordKey);\n+    }\n+\n+    controller.updateLastExportedRecordPosition(record.getPosition());\n+  }\n+\n+  private void handleWorkflowInstanceRecord(\n+      final Record<?> record, final int partitionId, final long recordKey) {\n+    final var currentIntent = record.getIntent();\n+\n+    if (currentIntent == WorkflowInstanceIntent.ELEMENT_ACTIVATING\n+        && isWorkflowInstanceRecord(record)) {\n+      storeWorkflowInstanceCreation(record.getTimestamp(), recordKey);\n+    } else if (currentIntent == WorkflowInstanceIntent.ELEMENT_COMPLETED\n+        && isWorkflowInstanceRecord(record)) {\n+      final var creationTime = workflowInstanceKeyToCreationTimeMap.remove(recordKey);\n+      executionLatencyMetrics.observeWorkflowInstanceExecutionTime(\n+          partitionId, creationTime, record.getTimestamp());\n+    }\n+  }\n+\n+  private void storeWorkflowInstanceCreation(final long creationTime, final long recordKey) {\n+    workflowInstanceKeyToCreationTimeMap.put(recordKey, creationTime);\n+    creationTimeToWorkflowInstanceKeyTreeMap.put(creationTime, recordKey);\n+  }\n+\n+  private void handleJobRecord(\n+      final Record<?> record, final int partitionId, final long recordKey) {\n+    final var currentIntent = record.getIntent();\n+\n+    if (currentIntent == JobIntent.CREATED) {\n+      storeJobCreation(record.getTimestamp(), recordKey);\n+    } else if (currentIntent == JobIntent.ACTIVATED) {\n+      final var creationTime = jobKeyToCreationTimeMap.get(recordKey);\n+      executionLatencyMetrics.observeJobActivationTime(\n+          partitionId, creationTime, record.getTimestamp());\n+    } else if (currentIntent == JobIntent.COMPLETED) {\n+      final var creationTime = jobKeyToCreationTimeMap.remove(recordKey);\n+      executionLatencyMetrics.observeJobLifeTime(partitionId, creationTime, record.getTimestamp());\n+    }\n+  }\n+\n+  private void storeJobCreation(final long creationTime, final long recordKey) {\n+    jobKeyToCreationTimeMap.put(recordKey, creationTime);\n+    creationTimeToJobKeyTreeMap.put(creationTime, recordKey);\n+  }\n+\n+  private void cleanUp() {\n+    final var currentTimeMillis = System.currentTimeMillis();\n+\n+    final var deadTime = currentTimeMillis - TIME_TO_LIVE.toMillis();\n+    clearMaps(deadTime, creationTimeToJobKeyTreeMap, jobKeyToCreationTimeMap);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODM1ODYxNQ=="}, "originalCommit": {"oid": "13b2b31f9159d7d834cd2ed758eb9e178046108b"}, "originalPosition": 122}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYyOTU2Nw==", "bodyText": "So I add a bunch of keys with the same creation time into the creationTimeToJobKeyTreeMap (or the other one). It's a map, so it only saves the latest value, no? So when I clean up, I actually only clean up that value, not any of the others from the map? Or am I missing something?", "url": "https://github.com/camunda-cloud/zeebe/pull/4233#discussion_r408629567", "createdAt": "2020-04-15T07:17:10Z", "author": {"login": "npepinpe"}, "path": "broker/src/main/java/io/zeebe/broker/exporter/metrics/MetricsExporter.java", "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.exporter.metrics;\n+\n+import io.zeebe.broker.system.configuration.ExporterCfg;\n+import io.zeebe.exporter.api.Exporter;\n+import io.zeebe.exporter.api.context.Controller;\n+import io.zeebe.protocol.record.Record;\n+import io.zeebe.protocol.record.RecordType;\n+import io.zeebe.protocol.record.ValueType;\n+import io.zeebe.protocol.record.intent.JobIntent;\n+import io.zeebe.protocol.record.intent.WorkflowInstanceIntent;\n+import io.zeebe.protocol.record.value.WorkflowInstanceRecordValue;\n+import java.time.Duration;\n+import java.util.NavigableMap;\n+import java.util.TreeMap;\n+import org.agrona.collections.Long2LongHashMap;\n+\n+public class MetricsExporter implements Exporter {\n+\n+  public static final Duration TIME_TO_LIVE = Duration.ofSeconds(10);\n+  private final ExecutionLatencyMetrics executionLatencyMetrics;\n+  private final Long2LongHashMap jobKeyToCreationTimeMap;\n+  private final Long2LongHashMap workflowInstanceKeyToCreationTimeMap;\n+\n+  private final NavigableMap<Long, Long> creationTimeToJobKeyTreeMap;\n+  private final NavigableMap<Long, Long> creationTimeToWorkflowInstanceKeyTreeMap;\n+\n+  private Controller controller;\n+\n+  public MetricsExporter() {\n+    this.executionLatencyMetrics = new ExecutionLatencyMetrics();\n+    this.jobKeyToCreationTimeMap = new Long2LongHashMap(-1);\n+    this.workflowInstanceKeyToCreationTimeMap = new Long2LongHashMap(-1);\n+    this.creationTimeToJobKeyTreeMap = new TreeMap<>();\n+    this.creationTimeToWorkflowInstanceKeyTreeMap = new TreeMap<>();\n+  }\n+\n+  @Override\n+  public void open(final Controller controller) {\n+    this.controller = controller;\n+\n+    controller.scheduleTask(TIME_TO_LIVE, this::cleanUp);\n+  }\n+\n+  @Override\n+  public void close() {\n+    jobKeyToCreationTimeMap.clear();\n+    workflowInstanceKeyToCreationTimeMap.clear();\n+  }\n+\n+  @Override\n+  public void export(final Record record) {\n+    if (record.getRecordType() != RecordType.EVENT) {\n+      controller.updateLastExportedRecordPosition(record.getPosition());\n+      return;\n+    }\n+\n+    final var partitionId = record.getPartitionId();\n+    final var recordKey = record.getKey();\n+\n+    final var currentValueType = record.getValueType();\n+    if (currentValueType == ValueType.JOB) {\n+      handleJobRecord(record, partitionId, recordKey);\n+    } else if (currentValueType == ValueType.WORKFLOW_INSTANCE) {\n+      handleWorkflowInstanceRecord(record, partitionId, recordKey);\n+    }\n+\n+    controller.updateLastExportedRecordPosition(record.getPosition());\n+  }\n+\n+  private void handleWorkflowInstanceRecord(\n+      final Record<?> record, final int partitionId, final long recordKey) {\n+    final var currentIntent = record.getIntent();\n+\n+    if (currentIntent == WorkflowInstanceIntent.ELEMENT_ACTIVATING\n+        && isWorkflowInstanceRecord(record)) {\n+      storeWorkflowInstanceCreation(record.getTimestamp(), recordKey);\n+    } else if (currentIntent == WorkflowInstanceIntent.ELEMENT_COMPLETED\n+        && isWorkflowInstanceRecord(record)) {\n+      final var creationTime = workflowInstanceKeyToCreationTimeMap.remove(recordKey);\n+      executionLatencyMetrics.observeWorkflowInstanceExecutionTime(\n+          partitionId, creationTime, record.getTimestamp());\n+    }\n+  }\n+\n+  private void storeWorkflowInstanceCreation(final long creationTime, final long recordKey) {\n+    workflowInstanceKeyToCreationTimeMap.put(recordKey, creationTime);\n+    creationTimeToWorkflowInstanceKeyTreeMap.put(creationTime, recordKey);\n+  }\n+\n+  private void handleJobRecord(\n+      final Record<?> record, final int partitionId, final long recordKey) {\n+    final var currentIntent = record.getIntent();\n+\n+    if (currentIntent == JobIntent.CREATED) {\n+      storeJobCreation(record.getTimestamp(), recordKey);\n+    } else if (currentIntent == JobIntent.ACTIVATED) {\n+      final var creationTime = jobKeyToCreationTimeMap.get(recordKey);\n+      executionLatencyMetrics.observeJobActivationTime(\n+          partitionId, creationTime, record.getTimestamp());\n+    } else if (currentIntent == JobIntent.COMPLETED) {\n+      final var creationTime = jobKeyToCreationTimeMap.remove(recordKey);\n+      executionLatencyMetrics.observeJobLifeTime(partitionId, creationTime, record.getTimestamp());\n+    }\n+  }\n+\n+  private void storeJobCreation(final long creationTime, final long recordKey) {\n+    jobKeyToCreationTimeMap.put(recordKey, creationTime);\n+    creationTimeToJobKeyTreeMap.put(creationTime, recordKey);\n+  }\n+\n+  private void cleanUp() {\n+    final var currentTimeMillis = System.currentTimeMillis();\n+\n+    final var deadTime = currentTimeMillis - TIME_TO_LIVE.toMillis();\n+    clearMaps(deadTime, creationTimeToJobKeyTreeMap, jobKeyToCreationTimeMap);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODM1ODYxNQ=="}, "originalCommit": {"oid": "13b2b31f9159d7d834cd2ed758eb9e178046108b"}, "originalPosition": 122}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYzMjI5MQ==", "bodyText": "Ok got what you mean, but everything which is stored is not created due to batches. So job created for example is not written in a batch and also the workflow instance creation is not.", "url": "https://github.com/camunda-cloud/zeebe/pull/4233#discussion_r408632291", "createdAt": "2020-04-15T07:22:28Z", "author": {"login": "Zelldon"}, "path": "broker/src/main/java/io/zeebe/broker/exporter/metrics/MetricsExporter.java", "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.exporter.metrics;\n+\n+import io.zeebe.broker.system.configuration.ExporterCfg;\n+import io.zeebe.exporter.api.Exporter;\n+import io.zeebe.exporter.api.context.Controller;\n+import io.zeebe.protocol.record.Record;\n+import io.zeebe.protocol.record.RecordType;\n+import io.zeebe.protocol.record.ValueType;\n+import io.zeebe.protocol.record.intent.JobIntent;\n+import io.zeebe.protocol.record.intent.WorkflowInstanceIntent;\n+import io.zeebe.protocol.record.value.WorkflowInstanceRecordValue;\n+import java.time.Duration;\n+import java.util.NavigableMap;\n+import java.util.TreeMap;\n+import org.agrona.collections.Long2LongHashMap;\n+\n+public class MetricsExporter implements Exporter {\n+\n+  public static final Duration TIME_TO_LIVE = Duration.ofSeconds(10);\n+  private final ExecutionLatencyMetrics executionLatencyMetrics;\n+  private final Long2LongHashMap jobKeyToCreationTimeMap;\n+  private final Long2LongHashMap workflowInstanceKeyToCreationTimeMap;\n+\n+  private final NavigableMap<Long, Long> creationTimeToJobKeyTreeMap;\n+  private final NavigableMap<Long, Long> creationTimeToWorkflowInstanceKeyTreeMap;\n+\n+  private Controller controller;\n+\n+  public MetricsExporter() {\n+    this.executionLatencyMetrics = new ExecutionLatencyMetrics();\n+    this.jobKeyToCreationTimeMap = new Long2LongHashMap(-1);\n+    this.workflowInstanceKeyToCreationTimeMap = new Long2LongHashMap(-1);\n+    this.creationTimeToJobKeyTreeMap = new TreeMap<>();\n+    this.creationTimeToWorkflowInstanceKeyTreeMap = new TreeMap<>();\n+  }\n+\n+  @Override\n+  public void open(final Controller controller) {\n+    this.controller = controller;\n+\n+    controller.scheduleTask(TIME_TO_LIVE, this::cleanUp);\n+  }\n+\n+  @Override\n+  public void close() {\n+    jobKeyToCreationTimeMap.clear();\n+    workflowInstanceKeyToCreationTimeMap.clear();\n+  }\n+\n+  @Override\n+  public void export(final Record record) {\n+    if (record.getRecordType() != RecordType.EVENT) {\n+      controller.updateLastExportedRecordPosition(record.getPosition());\n+      return;\n+    }\n+\n+    final var partitionId = record.getPartitionId();\n+    final var recordKey = record.getKey();\n+\n+    final var currentValueType = record.getValueType();\n+    if (currentValueType == ValueType.JOB) {\n+      handleJobRecord(record, partitionId, recordKey);\n+    } else if (currentValueType == ValueType.WORKFLOW_INSTANCE) {\n+      handleWorkflowInstanceRecord(record, partitionId, recordKey);\n+    }\n+\n+    controller.updateLastExportedRecordPosition(record.getPosition());\n+  }\n+\n+  private void handleWorkflowInstanceRecord(\n+      final Record<?> record, final int partitionId, final long recordKey) {\n+    final var currentIntent = record.getIntent();\n+\n+    if (currentIntent == WorkflowInstanceIntent.ELEMENT_ACTIVATING\n+        && isWorkflowInstanceRecord(record)) {\n+      storeWorkflowInstanceCreation(record.getTimestamp(), recordKey);\n+    } else if (currentIntent == WorkflowInstanceIntent.ELEMENT_COMPLETED\n+        && isWorkflowInstanceRecord(record)) {\n+      final var creationTime = workflowInstanceKeyToCreationTimeMap.remove(recordKey);\n+      executionLatencyMetrics.observeWorkflowInstanceExecutionTime(\n+          partitionId, creationTime, record.getTimestamp());\n+    }\n+  }\n+\n+  private void storeWorkflowInstanceCreation(final long creationTime, final long recordKey) {\n+    workflowInstanceKeyToCreationTimeMap.put(recordKey, creationTime);\n+    creationTimeToWorkflowInstanceKeyTreeMap.put(creationTime, recordKey);\n+  }\n+\n+  private void handleJobRecord(\n+      final Record<?> record, final int partitionId, final long recordKey) {\n+    final var currentIntent = record.getIntent();\n+\n+    if (currentIntent == JobIntent.CREATED) {\n+      storeJobCreation(record.getTimestamp(), recordKey);\n+    } else if (currentIntent == JobIntent.ACTIVATED) {\n+      final var creationTime = jobKeyToCreationTimeMap.get(recordKey);\n+      executionLatencyMetrics.observeJobActivationTime(\n+          partitionId, creationTime, record.getTimestamp());\n+    } else if (currentIntent == JobIntent.COMPLETED) {\n+      final var creationTime = jobKeyToCreationTimeMap.remove(recordKey);\n+      executionLatencyMetrics.observeJobLifeTime(partitionId, creationTime, record.getTimestamp());\n+    }\n+  }\n+\n+  private void storeJobCreation(final long creationTime, final long recordKey) {\n+    jobKeyToCreationTimeMap.put(recordKey, creationTime);\n+    creationTimeToJobKeyTreeMap.put(creationTime, recordKey);\n+  }\n+\n+  private void cleanUp() {\n+    final var currentTimeMillis = System.currentTimeMillis();\n+\n+    final var deadTime = currentTimeMillis - TIME_TO_LIVE.toMillis();\n+    clearMaps(deadTime, creationTimeToJobKeyTreeMap, jobKeyToCreationTimeMap);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODM1ODYxNQ=="}, "originalCommit": {"oid": "13b2b31f9159d7d834cd2ed758eb9e178046108b"}, "originalPosition": 122}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYzNTkwNw==", "bodyText": "Ah true, we only store for processes and jobs, so they are never part of a batch (I think? Can't remember how a multi-instance call activity would look like \ud83d\ude05)", "url": "https://github.com/camunda-cloud/zeebe/pull/4233#discussion_r408635907", "createdAt": "2020-04-15T07:29:12Z", "author": {"login": "npepinpe"}, "path": "broker/src/main/java/io/zeebe/broker/exporter/metrics/MetricsExporter.java", "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.exporter.metrics;\n+\n+import io.zeebe.broker.system.configuration.ExporterCfg;\n+import io.zeebe.exporter.api.Exporter;\n+import io.zeebe.exporter.api.context.Controller;\n+import io.zeebe.protocol.record.Record;\n+import io.zeebe.protocol.record.RecordType;\n+import io.zeebe.protocol.record.ValueType;\n+import io.zeebe.protocol.record.intent.JobIntent;\n+import io.zeebe.protocol.record.intent.WorkflowInstanceIntent;\n+import io.zeebe.protocol.record.value.WorkflowInstanceRecordValue;\n+import java.time.Duration;\n+import java.util.NavigableMap;\n+import java.util.TreeMap;\n+import org.agrona.collections.Long2LongHashMap;\n+\n+public class MetricsExporter implements Exporter {\n+\n+  public static final Duration TIME_TO_LIVE = Duration.ofSeconds(10);\n+  private final ExecutionLatencyMetrics executionLatencyMetrics;\n+  private final Long2LongHashMap jobKeyToCreationTimeMap;\n+  private final Long2LongHashMap workflowInstanceKeyToCreationTimeMap;\n+\n+  private final NavigableMap<Long, Long> creationTimeToJobKeyTreeMap;\n+  private final NavigableMap<Long, Long> creationTimeToWorkflowInstanceKeyTreeMap;\n+\n+  private Controller controller;\n+\n+  public MetricsExporter() {\n+    this.executionLatencyMetrics = new ExecutionLatencyMetrics();\n+    this.jobKeyToCreationTimeMap = new Long2LongHashMap(-1);\n+    this.workflowInstanceKeyToCreationTimeMap = new Long2LongHashMap(-1);\n+    this.creationTimeToJobKeyTreeMap = new TreeMap<>();\n+    this.creationTimeToWorkflowInstanceKeyTreeMap = new TreeMap<>();\n+  }\n+\n+  @Override\n+  public void open(final Controller controller) {\n+    this.controller = controller;\n+\n+    controller.scheduleTask(TIME_TO_LIVE, this::cleanUp);\n+  }\n+\n+  @Override\n+  public void close() {\n+    jobKeyToCreationTimeMap.clear();\n+    workflowInstanceKeyToCreationTimeMap.clear();\n+  }\n+\n+  @Override\n+  public void export(final Record record) {\n+    if (record.getRecordType() != RecordType.EVENT) {\n+      controller.updateLastExportedRecordPosition(record.getPosition());\n+      return;\n+    }\n+\n+    final var partitionId = record.getPartitionId();\n+    final var recordKey = record.getKey();\n+\n+    final var currentValueType = record.getValueType();\n+    if (currentValueType == ValueType.JOB) {\n+      handleJobRecord(record, partitionId, recordKey);\n+    } else if (currentValueType == ValueType.WORKFLOW_INSTANCE) {\n+      handleWorkflowInstanceRecord(record, partitionId, recordKey);\n+    }\n+\n+    controller.updateLastExportedRecordPosition(record.getPosition());\n+  }\n+\n+  private void handleWorkflowInstanceRecord(\n+      final Record<?> record, final int partitionId, final long recordKey) {\n+    final var currentIntent = record.getIntent();\n+\n+    if (currentIntent == WorkflowInstanceIntent.ELEMENT_ACTIVATING\n+        && isWorkflowInstanceRecord(record)) {\n+      storeWorkflowInstanceCreation(record.getTimestamp(), recordKey);\n+    } else if (currentIntent == WorkflowInstanceIntent.ELEMENT_COMPLETED\n+        && isWorkflowInstanceRecord(record)) {\n+      final var creationTime = workflowInstanceKeyToCreationTimeMap.remove(recordKey);\n+      executionLatencyMetrics.observeWorkflowInstanceExecutionTime(\n+          partitionId, creationTime, record.getTimestamp());\n+    }\n+  }\n+\n+  private void storeWorkflowInstanceCreation(final long creationTime, final long recordKey) {\n+    workflowInstanceKeyToCreationTimeMap.put(recordKey, creationTime);\n+    creationTimeToWorkflowInstanceKeyTreeMap.put(creationTime, recordKey);\n+  }\n+\n+  private void handleJobRecord(\n+      final Record<?> record, final int partitionId, final long recordKey) {\n+    final var currentIntent = record.getIntent();\n+\n+    if (currentIntent == JobIntent.CREATED) {\n+      storeJobCreation(record.getTimestamp(), recordKey);\n+    } else if (currentIntent == JobIntent.ACTIVATED) {\n+      final var creationTime = jobKeyToCreationTimeMap.get(recordKey);\n+      executionLatencyMetrics.observeJobActivationTime(\n+          partitionId, creationTime, record.getTimestamp());\n+    } else if (currentIntent == JobIntent.COMPLETED) {\n+      final var creationTime = jobKeyToCreationTimeMap.remove(recordKey);\n+      executionLatencyMetrics.observeJobLifeTime(partitionId, creationTime, record.getTimestamp());\n+    }\n+  }\n+\n+  private void storeJobCreation(final long creationTime, final long recordKey) {\n+    jobKeyToCreationTimeMap.put(recordKey, creationTime);\n+    creationTimeToJobKeyTreeMap.put(creationTime, recordKey);\n+  }\n+\n+  private void cleanUp() {\n+    final var currentTimeMillis = System.currentTimeMillis();\n+\n+    final var deadTime = currentTimeMillis - TIME_TO_LIVE.toMillis();\n+    clearMaps(deadTime, creationTimeToJobKeyTreeMap, jobKeyToCreationTimeMap);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODM1ODYxNQ=="}, "originalCommit": {"oid": "13b2b31f9159d7d834cd2ed758eb9e178046108b"}, "originalPosition": 122}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYzOTc2OQ==", "bodyText": "Even if multi instances creates multiple jobs the CREATED will be written again one by one \ud83d\ude42 so should be fine", "url": "https://github.com/camunda-cloud/zeebe/pull/4233#discussion_r408639769", "createdAt": "2020-04-15T07:36:27Z", "author": {"login": "Zelldon"}, "path": "broker/src/main/java/io/zeebe/broker/exporter/metrics/MetricsExporter.java", "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.exporter.metrics;\n+\n+import io.zeebe.broker.system.configuration.ExporterCfg;\n+import io.zeebe.exporter.api.Exporter;\n+import io.zeebe.exporter.api.context.Controller;\n+import io.zeebe.protocol.record.Record;\n+import io.zeebe.protocol.record.RecordType;\n+import io.zeebe.protocol.record.ValueType;\n+import io.zeebe.protocol.record.intent.JobIntent;\n+import io.zeebe.protocol.record.intent.WorkflowInstanceIntent;\n+import io.zeebe.protocol.record.value.WorkflowInstanceRecordValue;\n+import java.time.Duration;\n+import java.util.NavigableMap;\n+import java.util.TreeMap;\n+import org.agrona.collections.Long2LongHashMap;\n+\n+public class MetricsExporter implements Exporter {\n+\n+  public static final Duration TIME_TO_LIVE = Duration.ofSeconds(10);\n+  private final ExecutionLatencyMetrics executionLatencyMetrics;\n+  private final Long2LongHashMap jobKeyToCreationTimeMap;\n+  private final Long2LongHashMap workflowInstanceKeyToCreationTimeMap;\n+\n+  private final NavigableMap<Long, Long> creationTimeToJobKeyTreeMap;\n+  private final NavigableMap<Long, Long> creationTimeToWorkflowInstanceKeyTreeMap;\n+\n+  private Controller controller;\n+\n+  public MetricsExporter() {\n+    this.executionLatencyMetrics = new ExecutionLatencyMetrics();\n+    this.jobKeyToCreationTimeMap = new Long2LongHashMap(-1);\n+    this.workflowInstanceKeyToCreationTimeMap = new Long2LongHashMap(-1);\n+    this.creationTimeToJobKeyTreeMap = new TreeMap<>();\n+    this.creationTimeToWorkflowInstanceKeyTreeMap = new TreeMap<>();\n+  }\n+\n+  @Override\n+  public void open(final Controller controller) {\n+    this.controller = controller;\n+\n+    controller.scheduleTask(TIME_TO_LIVE, this::cleanUp);\n+  }\n+\n+  @Override\n+  public void close() {\n+    jobKeyToCreationTimeMap.clear();\n+    workflowInstanceKeyToCreationTimeMap.clear();\n+  }\n+\n+  @Override\n+  public void export(final Record record) {\n+    if (record.getRecordType() != RecordType.EVENT) {\n+      controller.updateLastExportedRecordPosition(record.getPosition());\n+      return;\n+    }\n+\n+    final var partitionId = record.getPartitionId();\n+    final var recordKey = record.getKey();\n+\n+    final var currentValueType = record.getValueType();\n+    if (currentValueType == ValueType.JOB) {\n+      handleJobRecord(record, partitionId, recordKey);\n+    } else if (currentValueType == ValueType.WORKFLOW_INSTANCE) {\n+      handleWorkflowInstanceRecord(record, partitionId, recordKey);\n+    }\n+\n+    controller.updateLastExportedRecordPosition(record.getPosition());\n+  }\n+\n+  private void handleWorkflowInstanceRecord(\n+      final Record<?> record, final int partitionId, final long recordKey) {\n+    final var currentIntent = record.getIntent();\n+\n+    if (currentIntent == WorkflowInstanceIntent.ELEMENT_ACTIVATING\n+        && isWorkflowInstanceRecord(record)) {\n+      storeWorkflowInstanceCreation(record.getTimestamp(), recordKey);\n+    } else if (currentIntent == WorkflowInstanceIntent.ELEMENT_COMPLETED\n+        && isWorkflowInstanceRecord(record)) {\n+      final var creationTime = workflowInstanceKeyToCreationTimeMap.remove(recordKey);\n+      executionLatencyMetrics.observeWorkflowInstanceExecutionTime(\n+          partitionId, creationTime, record.getTimestamp());\n+    }\n+  }\n+\n+  private void storeWorkflowInstanceCreation(final long creationTime, final long recordKey) {\n+    workflowInstanceKeyToCreationTimeMap.put(recordKey, creationTime);\n+    creationTimeToWorkflowInstanceKeyTreeMap.put(creationTime, recordKey);\n+  }\n+\n+  private void handleJobRecord(\n+      final Record<?> record, final int partitionId, final long recordKey) {\n+    final var currentIntent = record.getIntent();\n+\n+    if (currentIntent == JobIntent.CREATED) {\n+      storeJobCreation(record.getTimestamp(), recordKey);\n+    } else if (currentIntent == JobIntent.ACTIVATED) {\n+      final var creationTime = jobKeyToCreationTimeMap.get(recordKey);\n+      executionLatencyMetrics.observeJobActivationTime(\n+          partitionId, creationTime, record.getTimestamp());\n+    } else if (currentIntent == JobIntent.COMPLETED) {\n+      final var creationTime = jobKeyToCreationTimeMap.remove(recordKey);\n+      executionLatencyMetrics.observeJobLifeTime(partitionId, creationTime, record.getTimestamp());\n+    }\n+  }\n+\n+  private void storeJobCreation(final long creationTime, final long recordKey) {\n+    jobKeyToCreationTimeMap.put(recordKey, creationTime);\n+    creationTimeToJobKeyTreeMap.put(creationTime, recordKey);\n+  }\n+\n+  private void cleanUp() {\n+    final var currentTimeMillis = System.currentTimeMillis();\n+\n+    final var deadTime = currentTimeMillis - TIME_TO_LIVE.toMillis();\n+    clearMaps(deadTime, creationTimeToJobKeyTreeMap, jobKeyToCreationTimeMap);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODM1ODYxNQ=="}, "originalCommit": {"oid": "13b2b31f9159d7d834cd2ed758eb9e178046108b"}, "originalPosition": 122}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNTIyNjg3OnYy", "diffSide": "RIGHT", "path": "broker/src/main/java/io/zeebe/broker/exporter/metrics/MetricsExporter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQxODo1MjoxMFrOGFcYrw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQxODo1MjoxMFrOGFcYrw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODM2MTEzNQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                for (final Long key : outOfScopeInstances.values()) {\n          \n          \n            \n                  keyToTimestampMap.remove(key);\n          \n          \n            \n                }\n          \n          \n            \n                keyToTimestampMap.keySet().removeAll(outOfScopeInstances.values())\n          \n      \n    \n    \n  \n\nFrom what I understand, changes to keySet() are reflected in the map. From the docs:\n\nThe set is backed by the map, so changes to the map are reflected in the set, and vice-versa\n...\nThe set supports element removal, which removes the corresponding mapping from the map, via the Iterator.remove, Set.remove, removeAll, retainAll, and clear operations. It does not support the add or addAll operations.", "url": "https://github.com/camunda-cloud/zeebe/pull/4233#discussion_r408361135", "createdAt": "2020-04-14T18:52:10Z", "author": {"login": "npepinpe"}, "path": "broker/src/main/java/io/zeebe/broker/exporter/metrics/MetricsExporter.java", "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.exporter.metrics;\n+\n+import io.zeebe.broker.system.configuration.ExporterCfg;\n+import io.zeebe.exporter.api.Exporter;\n+import io.zeebe.exporter.api.context.Controller;\n+import io.zeebe.protocol.record.Record;\n+import io.zeebe.protocol.record.RecordType;\n+import io.zeebe.protocol.record.ValueType;\n+import io.zeebe.protocol.record.intent.JobIntent;\n+import io.zeebe.protocol.record.intent.WorkflowInstanceIntent;\n+import io.zeebe.protocol.record.value.WorkflowInstanceRecordValue;\n+import java.time.Duration;\n+import java.util.NavigableMap;\n+import java.util.TreeMap;\n+import org.agrona.collections.Long2LongHashMap;\n+\n+public class MetricsExporter implements Exporter {\n+\n+  public static final Duration TIME_TO_LIVE = Duration.ofSeconds(10);\n+  private final ExecutionLatencyMetrics executionLatencyMetrics;\n+  private final Long2LongHashMap jobKeyToCreationTimeMap;\n+  private final Long2LongHashMap workflowInstanceKeyToCreationTimeMap;\n+\n+  private final NavigableMap<Long, Long> creationTimeToJobKeyTreeMap;\n+  private final NavigableMap<Long, Long> creationTimeToWorkflowInstanceKeyTreeMap;\n+\n+  private Controller controller;\n+\n+  public MetricsExporter() {\n+    this.executionLatencyMetrics = new ExecutionLatencyMetrics();\n+    this.jobKeyToCreationTimeMap = new Long2LongHashMap(-1);\n+    this.workflowInstanceKeyToCreationTimeMap = new Long2LongHashMap(-1);\n+    this.creationTimeToJobKeyTreeMap = new TreeMap<>();\n+    this.creationTimeToWorkflowInstanceKeyTreeMap = new TreeMap<>();\n+  }\n+\n+  @Override\n+  public void open(final Controller controller) {\n+    this.controller = controller;\n+\n+    controller.scheduleTask(TIME_TO_LIVE, this::cleanUp);\n+  }\n+\n+  @Override\n+  public void close() {\n+    jobKeyToCreationTimeMap.clear();\n+    workflowInstanceKeyToCreationTimeMap.clear();\n+  }\n+\n+  @Override\n+  public void export(final Record record) {\n+    if (record.getRecordType() != RecordType.EVENT) {\n+      controller.updateLastExportedRecordPosition(record.getPosition());\n+      return;\n+    }\n+\n+    final var partitionId = record.getPartitionId();\n+    final var recordKey = record.getKey();\n+\n+    final var currentValueType = record.getValueType();\n+    if (currentValueType == ValueType.JOB) {\n+      handleJobRecord(record, partitionId, recordKey);\n+    } else if (currentValueType == ValueType.WORKFLOW_INSTANCE) {\n+      handleWorkflowInstanceRecord(record, partitionId, recordKey);\n+    }\n+\n+    controller.updateLastExportedRecordPosition(record.getPosition());\n+  }\n+\n+  private void handleWorkflowInstanceRecord(\n+      final Record<?> record, final int partitionId, final long recordKey) {\n+    final var currentIntent = record.getIntent();\n+\n+    if (currentIntent == WorkflowInstanceIntent.ELEMENT_ACTIVATING\n+        && isWorkflowInstanceRecord(record)) {\n+      storeWorkflowInstanceCreation(record.getTimestamp(), recordKey);\n+    } else if (currentIntent == WorkflowInstanceIntent.ELEMENT_COMPLETED\n+        && isWorkflowInstanceRecord(record)) {\n+      final var creationTime = workflowInstanceKeyToCreationTimeMap.remove(recordKey);\n+      executionLatencyMetrics.observeWorkflowInstanceExecutionTime(\n+          partitionId, creationTime, record.getTimestamp());\n+    }\n+  }\n+\n+  private void storeWorkflowInstanceCreation(final long creationTime, final long recordKey) {\n+    workflowInstanceKeyToCreationTimeMap.put(recordKey, creationTime);\n+    creationTimeToWorkflowInstanceKeyTreeMap.put(creationTime, recordKey);\n+  }\n+\n+  private void handleJobRecord(\n+      final Record<?> record, final int partitionId, final long recordKey) {\n+    final var currentIntent = record.getIntent();\n+\n+    if (currentIntent == JobIntent.CREATED) {\n+      storeJobCreation(record.getTimestamp(), recordKey);\n+    } else if (currentIntent == JobIntent.ACTIVATED) {\n+      final var creationTime = jobKeyToCreationTimeMap.get(recordKey);\n+      executionLatencyMetrics.observeJobActivationTime(\n+          partitionId, creationTime, record.getTimestamp());\n+    } else if (currentIntent == JobIntent.COMPLETED) {\n+      final var creationTime = jobKeyToCreationTimeMap.remove(recordKey);\n+      executionLatencyMetrics.observeJobLifeTime(partitionId, creationTime, record.getTimestamp());\n+    }\n+  }\n+\n+  private void storeJobCreation(final long creationTime, final long recordKey) {\n+    jobKeyToCreationTimeMap.put(recordKey, creationTime);\n+    creationTimeToJobKeyTreeMap.put(creationTime, recordKey);\n+  }\n+\n+  private void cleanUp() {\n+    final var currentTimeMillis = System.currentTimeMillis();\n+\n+    final var deadTime = currentTimeMillis - TIME_TO_LIVE.toMillis();\n+    clearMaps(deadTime, creationTimeToJobKeyTreeMap, jobKeyToCreationTimeMap);\n+    clearMaps(\n+        deadTime, creationTimeToWorkflowInstanceKeyTreeMap, workflowInstanceKeyToCreationTimeMap);\n+  }\n+\n+  private void clearMaps(\n+      final long deadTime,\n+      final NavigableMap<Long, Long> timeToKeyMap,\n+      final Long2LongHashMap keyToTimestampMap) {\n+    final var outOfScopeInstances = timeToKeyMap.headMap(deadTime);\n+\n+    for (final Long key : outOfScopeInstances.values()) {\n+      keyToTimestampMap.remove(key);\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13b2b31f9159d7d834cd2ed758eb9e178046108b"}, "originalPosition": 135}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNTI3MDc2OnYy", "diffSide": "RIGHT", "path": "broker/src/main/java/io/zeebe/broker/exporter/metrics/MetricsExporter.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQxOTowMzoxNlrOGFczBA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNTo0NDozMlrOGFqmHQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODM2Nzg3Ng==", "bodyText": "Why is it static?", "url": "https://github.com/camunda-cloud/zeebe/pull/4233#discussion_r408367876", "createdAt": "2020-04-14T19:03:16Z", "author": {"login": "npepinpe"}, "path": "broker/src/main/java/io/zeebe/broker/exporter/metrics/MetricsExporter.java", "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.exporter.metrics;\n+\n+import io.zeebe.broker.system.configuration.ExporterCfg;\n+import io.zeebe.exporter.api.Exporter;\n+import io.zeebe.exporter.api.context.Controller;\n+import io.zeebe.protocol.record.Record;\n+import io.zeebe.protocol.record.RecordType;\n+import io.zeebe.protocol.record.ValueType;\n+import io.zeebe.protocol.record.intent.JobIntent;\n+import io.zeebe.protocol.record.intent.WorkflowInstanceIntent;\n+import io.zeebe.protocol.record.value.WorkflowInstanceRecordValue;\n+import java.time.Duration;\n+import java.util.NavigableMap;\n+import java.util.TreeMap;\n+import org.agrona.collections.Long2LongHashMap;\n+\n+public class MetricsExporter implements Exporter {\n+\n+  public static final Duration TIME_TO_LIVE = Duration.ofSeconds(10);\n+  private final ExecutionLatencyMetrics executionLatencyMetrics;\n+  private final Long2LongHashMap jobKeyToCreationTimeMap;\n+  private final Long2LongHashMap workflowInstanceKeyToCreationTimeMap;\n+\n+  private final NavigableMap<Long, Long> creationTimeToJobKeyTreeMap;\n+  private final NavigableMap<Long, Long> creationTimeToWorkflowInstanceKeyTreeMap;\n+\n+  private Controller controller;\n+\n+  public MetricsExporter() {\n+    this.executionLatencyMetrics = new ExecutionLatencyMetrics();\n+    this.jobKeyToCreationTimeMap = new Long2LongHashMap(-1);\n+    this.workflowInstanceKeyToCreationTimeMap = new Long2LongHashMap(-1);\n+    this.creationTimeToJobKeyTreeMap = new TreeMap<>();\n+    this.creationTimeToWorkflowInstanceKeyTreeMap = new TreeMap<>();\n+  }\n+\n+  @Override\n+  public void open(final Controller controller) {\n+    this.controller = controller;\n+\n+    controller.scheduleTask(TIME_TO_LIVE, this::cleanUp);\n+  }\n+\n+  @Override\n+  public void close() {\n+    jobKeyToCreationTimeMap.clear();\n+    workflowInstanceKeyToCreationTimeMap.clear();\n+  }\n+\n+  @Override\n+  public void export(final Record record) {\n+    if (record.getRecordType() != RecordType.EVENT) {\n+      controller.updateLastExportedRecordPosition(record.getPosition());\n+      return;\n+    }\n+\n+    final var partitionId = record.getPartitionId();\n+    final var recordKey = record.getKey();\n+\n+    final var currentValueType = record.getValueType();\n+    if (currentValueType == ValueType.JOB) {\n+      handleJobRecord(record, partitionId, recordKey);\n+    } else if (currentValueType == ValueType.WORKFLOW_INSTANCE) {\n+      handleWorkflowInstanceRecord(record, partitionId, recordKey);\n+    }\n+\n+    controller.updateLastExportedRecordPosition(record.getPosition());\n+  }\n+\n+  private void handleWorkflowInstanceRecord(\n+      final Record<?> record, final int partitionId, final long recordKey) {\n+    final var currentIntent = record.getIntent();\n+\n+    if (currentIntent == WorkflowInstanceIntent.ELEMENT_ACTIVATING\n+        && isWorkflowInstanceRecord(record)) {\n+      storeWorkflowInstanceCreation(record.getTimestamp(), recordKey);\n+    } else if (currentIntent == WorkflowInstanceIntent.ELEMENT_COMPLETED\n+        && isWorkflowInstanceRecord(record)) {\n+      final var creationTime = workflowInstanceKeyToCreationTimeMap.remove(recordKey);\n+      executionLatencyMetrics.observeWorkflowInstanceExecutionTime(\n+          partitionId, creationTime, record.getTimestamp());\n+    }\n+  }\n+\n+  private void storeWorkflowInstanceCreation(final long creationTime, final long recordKey) {\n+    workflowInstanceKeyToCreationTimeMap.put(recordKey, creationTime);\n+    creationTimeToWorkflowInstanceKeyTreeMap.put(creationTime, recordKey);\n+  }\n+\n+  private void handleJobRecord(\n+      final Record<?> record, final int partitionId, final long recordKey) {\n+    final var currentIntent = record.getIntent();\n+\n+    if (currentIntent == JobIntent.CREATED) {\n+      storeJobCreation(record.getTimestamp(), recordKey);\n+    } else if (currentIntent == JobIntent.ACTIVATED) {\n+      final var creationTime = jobKeyToCreationTimeMap.get(recordKey);\n+      executionLatencyMetrics.observeJobActivationTime(\n+          partitionId, creationTime, record.getTimestamp());\n+    } else if (currentIntent == JobIntent.COMPLETED) {\n+      final var creationTime = jobKeyToCreationTimeMap.remove(recordKey);\n+      executionLatencyMetrics.observeJobLifeTime(partitionId, creationTime, record.getTimestamp());\n+    }\n+  }\n+\n+  private void storeJobCreation(final long creationTime, final long recordKey) {\n+    jobKeyToCreationTimeMap.put(recordKey, creationTime);\n+    creationTimeToJobKeyTreeMap.put(creationTime, recordKey);\n+  }\n+\n+  private void cleanUp() {\n+    final var currentTimeMillis = System.currentTimeMillis();\n+\n+    final var deadTime = currentTimeMillis - TIME_TO_LIVE.toMillis();\n+    clearMaps(deadTime, creationTimeToJobKeyTreeMap, jobKeyToCreationTimeMap);\n+    clearMaps(\n+        deadTime, creationTimeToWorkflowInstanceKeyTreeMap, workflowInstanceKeyToCreationTimeMap);\n+  }\n+\n+  private void clearMaps(\n+      final long deadTime,\n+      final NavigableMap<Long, Long> timeToKeyMap,\n+      final Long2LongHashMap keyToTimestampMap) {\n+    final var outOfScopeInstances = timeToKeyMap.headMap(deadTime);\n+\n+    for (final Long key : outOfScopeInstances.values()) {\n+      keyToTimestampMap.remove(key);\n+    }\n+    outOfScopeInstances.clear();\n+  }\n+\n+  public static ExporterCfg defaultConfig() {\n+    final ExporterCfg exporterCfg = new ExporterCfg();\n+    exporterCfg.setClassName(MetricsExporter.class.getName());\n+    return exporterCfg;\n+  }\n+\n+  public static String defaultExporterId() {\n+    return MetricsExporter.class.getSimpleName();\n+  }\n+\n+  private static boolean isWorkflowInstanceRecord(final Record<?> record) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13b2b31f9159d7d834cd2ed758eb9e178046108b"}, "originalPosition": 149}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODU5Mzk0OQ==", "bodyText": "Hm not sure anymore I think because it is a helper method and it can also moved elsewhere", "url": "https://github.com/camunda-cloud/zeebe/pull/4233#discussion_r408593949", "createdAt": "2020-04-15T05:44:32Z", "author": {"login": "Zelldon"}, "path": "broker/src/main/java/io/zeebe/broker/exporter/metrics/MetricsExporter.java", "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.exporter.metrics;\n+\n+import io.zeebe.broker.system.configuration.ExporterCfg;\n+import io.zeebe.exporter.api.Exporter;\n+import io.zeebe.exporter.api.context.Controller;\n+import io.zeebe.protocol.record.Record;\n+import io.zeebe.protocol.record.RecordType;\n+import io.zeebe.protocol.record.ValueType;\n+import io.zeebe.protocol.record.intent.JobIntent;\n+import io.zeebe.protocol.record.intent.WorkflowInstanceIntent;\n+import io.zeebe.protocol.record.value.WorkflowInstanceRecordValue;\n+import java.time.Duration;\n+import java.util.NavigableMap;\n+import java.util.TreeMap;\n+import org.agrona.collections.Long2LongHashMap;\n+\n+public class MetricsExporter implements Exporter {\n+\n+  public static final Duration TIME_TO_LIVE = Duration.ofSeconds(10);\n+  private final ExecutionLatencyMetrics executionLatencyMetrics;\n+  private final Long2LongHashMap jobKeyToCreationTimeMap;\n+  private final Long2LongHashMap workflowInstanceKeyToCreationTimeMap;\n+\n+  private final NavigableMap<Long, Long> creationTimeToJobKeyTreeMap;\n+  private final NavigableMap<Long, Long> creationTimeToWorkflowInstanceKeyTreeMap;\n+\n+  private Controller controller;\n+\n+  public MetricsExporter() {\n+    this.executionLatencyMetrics = new ExecutionLatencyMetrics();\n+    this.jobKeyToCreationTimeMap = new Long2LongHashMap(-1);\n+    this.workflowInstanceKeyToCreationTimeMap = new Long2LongHashMap(-1);\n+    this.creationTimeToJobKeyTreeMap = new TreeMap<>();\n+    this.creationTimeToWorkflowInstanceKeyTreeMap = new TreeMap<>();\n+  }\n+\n+  @Override\n+  public void open(final Controller controller) {\n+    this.controller = controller;\n+\n+    controller.scheduleTask(TIME_TO_LIVE, this::cleanUp);\n+  }\n+\n+  @Override\n+  public void close() {\n+    jobKeyToCreationTimeMap.clear();\n+    workflowInstanceKeyToCreationTimeMap.clear();\n+  }\n+\n+  @Override\n+  public void export(final Record record) {\n+    if (record.getRecordType() != RecordType.EVENT) {\n+      controller.updateLastExportedRecordPosition(record.getPosition());\n+      return;\n+    }\n+\n+    final var partitionId = record.getPartitionId();\n+    final var recordKey = record.getKey();\n+\n+    final var currentValueType = record.getValueType();\n+    if (currentValueType == ValueType.JOB) {\n+      handleJobRecord(record, partitionId, recordKey);\n+    } else if (currentValueType == ValueType.WORKFLOW_INSTANCE) {\n+      handleWorkflowInstanceRecord(record, partitionId, recordKey);\n+    }\n+\n+    controller.updateLastExportedRecordPosition(record.getPosition());\n+  }\n+\n+  private void handleWorkflowInstanceRecord(\n+      final Record<?> record, final int partitionId, final long recordKey) {\n+    final var currentIntent = record.getIntent();\n+\n+    if (currentIntent == WorkflowInstanceIntent.ELEMENT_ACTIVATING\n+        && isWorkflowInstanceRecord(record)) {\n+      storeWorkflowInstanceCreation(record.getTimestamp(), recordKey);\n+    } else if (currentIntent == WorkflowInstanceIntent.ELEMENT_COMPLETED\n+        && isWorkflowInstanceRecord(record)) {\n+      final var creationTime = workflowInstanceKeyToCreationTimeMap.remove(recordKey);\n+      executionLatencyMetrics.observeWorkflowInstanceExecutionTime(\n+          partitionId, creationTime, record.getTimestamp());\n+    }\n+  }\n+\n+  private void storeWorkflowInstanceCreation(final long creationTime, final long recordKey) {\n+    workflowInstanceKeyToCreationTimeMap.put(recordKey, creationTime);\n+    creationTimeToWorkflowInstanceKeyTreeMap.put(creationTime, recordKey);\n+  }\n+\n+  private void handleJobRecord(\n+      final Record<?> record, final int partitionId, final long recordKey) {\n+    final var currentIntent = record.getIntent();\n+\n+    if (currentIntent == JobIntent.CREATED) {\n+      storeJobCreation(record.getTimestamp(), recordKey);\n+    } else if (currentIntent == JobIntent.ACTIVATED) {\n+      final var creationTime = jobKeyToCreationTimeMap.get(recordKey);\n+      executionLatencyMetrics.observeJobActivationTime(\n+          partitionId, creationTime, record.getTimestamp());\n+    } else if (currentIntent == JobIntent.COMPLETED) {\n+      final var creationTime = jobKeyToCreationTimeMap.remove(recordKey);\n+      executionLatencyMetrics.observeJobLifeTime(partitionId, creationTime, record.getTimestamp());\n+    }\n+  }\n+\n+  private void storeJobCreation(final long creationTime, final long recordKey) {\n+    jobKeyToCreationTimeMap.put(recordKey, creationTime);\n+    creationTimeToJobKeyTreeMap.put(creationTime, recordKey);\n+  }\n+\n+  private void cleanUp() {\n+    final var currentTimeMillis = System.currentTimeMillis();\n+\n+    final var deadTime = currentTimeMillis - TIME_TO_LIVE.toMillis();\n+    clearMaps(deadTime, creationTimeToJobKeyTreeMap, jobKeyToCreationTimeMap);\n+    clearMaps(\n+        deadTime, creationTimeToWorkflowInstanceKeyTreeMap, workflowInstanceKeyToCreationTimeMap);\n+  }\n+\n+  private void clearMaps(\n+      final long deadTime,\n+      final NavigableMap<Long, Long> timeToKeyMap,\n+      final Long2LongHashMap keyToTimestampMap) {\n+    final var outOfScopeInstances = timeToKeyMap.headMap(deadTime);\n+\n+    for (final Long key : outOfScopeInstances.values()) {\n+      keyToTimestampMap.remove(key);\n+    }\n+    outOfScopeInstances.clear();\n+  }\n+\n+  public static ExporterCfg defaultConfig() {\n+    final ExporterCfg exporterCfg = new ExporterCfg();\n+    exporterCfg.setClassName(MetricsExporter.class.getName());\n+    return exporterCfg;\n+  }\n+\n+  public static String defaultExporterId() {\n+    return MetricsExporter.class.getSimpleName();\n+  }\n+\n+  private static boolean isWorkflowInstanceRecord(final Record<?> record) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODM2Nzg3Ng=="}, "originalCommit": {"oid": "13b2b31f9159d7d834cd2ed758eb9e178046108b"}, "originalPosition": 149}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNTI3MzY2OnYy", "diffSide": "RIGHT", "path": "broker/src/test/java/io/zeebe/broker/system/configuration/BrokerCfgTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQxOTowMzo1OFrOGFc0uA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQxOTowMzo1OFrOGFc0uA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODM2ODMxMg==", "bodyText": "Nice catch", "url": "https://github.com/camunda-cloud/zeebe/pull/4233#discussion_r408368312", "createdAt": "2020-04-14T19:03:58Z", "author": {"login": "npepinpe"}, "path": "broker/src/test/java/io/zeebe/broker/system/configuration/BrokerCfgTest.java", "diffHunk": "@@ -60,8 +61,10 @@\n \n   private static final String ZEEBE_BROKER_NETWORK_HOST = \"zeebe.broker.network.host\";\n   private static final String ZEEBE_BROKER_NETWORK_ADVERTISED_HOST =\n-      \"zeebe.broker.network.advertised-host\";\n+      \"zeebe.broker.network.advertisedHost\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13b2b31f9159d7d834cd2ed758eb9e178046108b"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzNzAwMzA5OnYy", "diffSide": "RIGHT", "path": "broker/src/main/java/io/zeebe/broker/exporter/metrics/MetricsExporter.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNzoyNzo1MVrOGFtHBg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNzozNToxMVrOGFtWkQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYzNTE0Mg==", "bodyText": "Nit: Could we also just check if recordValue.getBpmnElementType() == BpmnElementType.PROCESS? I think this is how we do it in WorkflowInstanceMetrics", "url": "https://github.com/camunda-cloud/zeebe/pull/4233#discussion_r408635142", "createdAt": "2020-04-15T07:27:51Z", "author": {"login": "npepinpe"}, "path": "broker/src/main/java/io/zeebe/broker/exporter/metrics/MetricsExporter.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.exporter.metrics;\n+\n+import io.zeebe.broker.system.configuration.ExporterCfg;\n+import io.zeebe.exporter.api.Exporter;\n+import io.zeebe.exporter.api.context.Controller;\n+import io.zeebe.protocol.record.Record;\n+import io.zeebe.protocol.record.RecordType;\n+import io.zeebe.protocol.record.ValueType;\n+import io.zeebe.protocol.record.intent.JobIntent;\n+import io.zeebe.protocol.record.intent.WorkflowInstanceIntent;\n+import io.zeebe.protocol.record.value.WorkflowInstanceRecordValue;\n+import java.time.Duration;\n+import java.util.NavigableMap;\n+import java.util.TreeMap;\n+import org.agrona.collections.Long2LongHashMap;\n+\n+public class MetricsExporter implements Exporter {\n+\n+  public static final Duration TIME_TO_LIVE = Duration.ofSeconds(10);\n+  private final ExecutionLatencyMetrics executionLatencyMetrics;\n+  private final Long2LongHashMap jobKeyToCreationTimeMap;\n+  private final Long2LongHashMap workflowInstanceKeyToCreationTimeMap;\n+\n+  private final NavigableMap<Long, Long> creationTimeToJobKeyTreeMap;\n+  private final NavigableMap<Long, Long> creationTimeToWorkflowInstanceKeyTreeMap;\n+\n+  private Controller controller;\n+\n+  public MetricsExporter() {\n+    this.executionLatencyMetrics = new ExecutionLatencyMetrics();\n+    this.jobKeyToCreationTimeMap = new Long2LongHashMap(-1);\n+    this.workflowInstanceKeyToCreationTimeMap = new Long2LongHashMap(-1);\n+    this.creationTimeToJobKeyTreeMap = new TreeMap<>();\n+    this.creationTimeToWorkflowInstanceKeyTreeMap = new TreeMap<>();\n+  }\n+\n+  @Override\n+  public void open(final Controller controller) {\n+    this.controller = controller;\n+\n+    controller.scheduleTask(TIME_TO_LIVE, this::cleanUp);\n+  }\n+\n+  @Override\n+  public void close() {\n+    jobKeyToCreationTimeMap.clear();\n+    workflowInstanceKeyToCreationTimeMap.clear();\n+  }\n+\n+  @Override\n+  public void export(final Record record) {\n+    if (record.getRecordType() != RecordType.EVENT) {\n+      controller.updateLastExportedRecordPosition(record.getPosition());\n+      return;\n+    }\n+\n+    final var partitionId = record.getPartitionId();\n+    final var recordKey = record.getKey();\n+\n+    final var currentValueType = record.getValueType();\n+    if (currentValueType == ValueType.JOB) {\n+      handleJobRecord(record, partitionId, recordKey);\n+    } else if (currentValueType == ValueType.WORKFLOW_INSTANCE) {\n+      handleWorkflowInstanceRecord(record, partitionId, recordKey);\n+    }\n+\n+    controller.updateLastExportedRecordPosition(record.getPosition());\n+  }\n+\n+  private void handleWorkflowInstanceRecord(\n+      final Record<?> record, final int partitionId, final long recordKey) {\n+    final var currentIntent = record.getIntent();\n+\n+    if (currentIntent == WorkflowInstanceIntent.ELEMENT_ACTIVATING\n+        && isWorkflowInstanceRecord(record)) {\n+      storeWorkflowInstanceCreation(record.getTimestamp(), recordKey);\n+    } else if (currentIntent == WorkflowInstanceIntent.ELEMENT_COMPLETED\n+        && isWorkflowInstanceRecord(record)) {\n+      final var creationTime = workflowInstanceKeyToCreationTimeMap.remove(recordKey);\n+      executionLatencyMetrics.observeWorkflowInstanceExecutionTime(\n+          partitionId, creationTime, record.getTimestamp());\n+    }\n+  }\n+\n+  private void storeWorkflowInstanceCreation(final long creationTime, final long recordKey) {\n+    workflowInstanceKeyToCreationTimeMap.put(recordKey, creationTime);\n+    creationTimeToWorkflowInstanceKeyTreeMap.put(creationTime, recordKey);\n+  }\n+\n+  private void handleJobRecord(\n+      final Record<?> record, final int partitionId, final long recordKey) {\n+    final var currentIntent = record.getIntent();\n+\n+    if (currentIntent == JobIntent.CREATED) {\n+      storeJobCreation(record.getTimestamp(), recordKey);\n+    } else if (currentIntent == JobIntent.ACTIVATED) {\n+      final var creationTime = jobKeyToCreationTimeMap.get(recordKey);\n+      executionLatencyMetrics.observeJobActivationTime(\n+          partitionId, creationTime, record.getTimestamp());\n+    } else if (currentIntent == JobIntent.COMPLETED) {\n+      final var creationTime = jobKeyToCreationTimeMap.remove(recordKey);\n+      executionLatencyMetrics.observeJobLifeTime(partitionId, creationTime, record.getTimestamp());\n+    }\n+  }\n+\n+  private void storeJobCreation(final long creationTime, final long recordKey) {\n+    jobKeyToCreationTimeMap.put(recordKey, creationTime);\n+    creationTimeToJobKeyTreeMap.put(creationTime, recordKey);\n+  }\n+\n+  private void cleanUp() {\n+    final var currentTimeMillis = System.currentTimeMillis();\n+\n+    final var deadTime = currentTimeMillis - TIME_TO_LIVE.toMillis();\n+    clearMaps(deadTime, creationTimeToJobKeyTreeMap, jobKeyToCreationTimeMap);\n+    clearMaps(\n+        deadTime, creationTimeToWorkflowInstanceKeyTreeMap, workflowInstanceKeyToCreationTimeMap);\n+  }\n+\n+  private void clearMaps(\n+      final long deadTime,\n+      final NavigableMap<Long, Long> timeToKeyMap,\n+      final Long2LongHashMap keyToTimestampMap) {\n+    final var outOfScopeInstances = timeToKeyMap.headMap(deadTime);\n+\n+    keyToTimestampMap.keySet().removeAll(outOfScopeInstances.values())\n+    outOfScopeInstances.clear();\n+  }\n+\n+  public static ExporterCfg defaultConfig() {\n+    final ExporterCfg exporterCfg = new ExporterCfg();\n+    exporterCfg.setClassName(MetricsExporter.class.getName());\n+    return exporterCfg;\n+  }\n+\n+  public static String defaultExporterId() {\n+    return MetricsExporter.class.getSimpleName();\n+  }\n+\n+  private static boolean isWorkflowInstanceRecord(final Record<?> record) {\n+    final var recordKey = record.getKey();\n+    final var recordValue = (WorkflowInstanceRecordValue) record.getValue();\n+    return recordKey == recordValue.getWorkflowInstanceKey();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c709e0ec7c6a84d404c31c8c37fc8560b5c88be9"}, "originalPosition": 150}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYzOTEyMQ==", "bodyText": "Ah yes thanks always forget this elementType thing \ud83d\ude05", "url": "https://github.com/camunda-cloud/zeebe/pull/4233#discussion_r408639121", "createdAt": "2020-04-15T07:35:11Z", "author": {"login": "Zelldon"}, "path": "broker/src/main/java/io/zeebe/broker/exporter/metrics/MetricsExporter.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.exporter.metrics;\n+\n+import io.zeebe.broker.system.configuration.ExporterCfg;\n+import io.zeebe.exporter.api.Exporter;\n+import io.zeebe.exporter.api.context.Controller;\n+import io.zeebe.protocol.record.Record;\n+import io.zeebe.protocol.record.RecordType;\n+import io.zeebe.protocol.record.ValueType;\n+import io.zeebe.protocol.record.intent.JobIntent;\n+import io.zeebe.protocol.record.intent.WorkflowInstanceIntent;\n+import io.zeebe.protocol.record.value.WorkflowInstanceRecordValue;\n+import java.time.Duration;\n+import java.util.NavigableMap;\n+import java.util.TreeMap;\n+import org.agrona.collections.Long2LongHashMap;\n+\n+public class MetricsExporter implements Exporter {\n+\n+  public static final Duration TIME_TO_LIVE = Duration.ofSeconds(10);\n+  private final ExecutionLatencyMetrics executionLatencyMetrics;\n+  private final Long2LongHashMap jobKeyToCreationTimeMap;\n+  private final Long2LongHashMap workflowInstanceKeyToCreationTimeMap;\n+\n+  private final NavigableMap<Long, Long> creationTimeToJobKeyTreeMap;\n+  private final NavigableMap<Long, Long> creationTimeToWorkflowInstanceKeyTreeMap;\n+\n+  private Controller controller;\n+\n+  public MetricsExporter() {\n+    this.executionLatencyMetrics = new ExecutionLatencyMetrics();\n+    this.jobKeyToCreationTimeMap = new Long2LongHashMap(-1);\n+    this.workflowInstanceKeyToCreationTimeMap = new Long2LongHashMap(-1);\n+    this.creationTimeToJobKeyTreeMap = new TreeMap<>();\n+    this.creationTimeToWorkflowInstanceKeyTreeMap = new TreeMap<>();\n+  }\n+\n+  @Override\n+  public void open(final Controller controller) {\n+    this.controller = controller;\n+\n+    controller.scheduleTask(TIME_TO_LIVE, this::cleanUp);\n+  }\n+\n+  @Override\n+  public void close() {\n+    jobKeyToCreationTimeMap.clear();\n+    workflowInstanceKeyToCreationTimeMap.clear();\n+  }\n+\n+  @Override\n+  public void export(final Record record) {\n+    if (record.getRecordType() != RecordType.EVENT) {\n+      controller.updateLastExportedRecordPosition(record.getPosition());\n+      return;\n+    }\n+\n+    final var partitionId = record.getPartitionId();\n+    final var recordKey = record.getKey();\n+\n+    final var currentValueType = record.getValueType();\n+    if (currentValueType == ValueType.JOB) {\n+      handleJobRecord(record, partitionId, recordKey);\n+    } else if (currentValueType == ValueType.WORKFLOW_INSTANCE) {\n+      handleWorkflowInstanceRecord(record, partitionId, recordKey);\n+    }\n+\n+    controller.updateLastExportedRecordPosition(record.getPosition());\n+  }\n+\n+  private void handleWorkflowInstanceRecord(\n+      final Record<?> record, final int partitionId, final long recordKey) {\n+    final var currentIntent = record.getIntent();\n+\n+    if (currentIntent == WorkflowInstanceIntent.ELEMENT_ACTIVATING\n+        && isWorkflowInstanceRecord(record)) {\n+      storeWorkflowInstanceCreation(record.getTimestamp(), recordKey);\n+    } else if (currentIntent == WorkflowInstanceIntent.ELEMENT_COMPLETED\n+        && isWorkflowInstanceRecord(record)) {\n+      final var creationTime = workflowInstanceKeyToCreationTimeMap.remove(recordKey);\n+      executionLatencyMetrics.observeWorkflowInstanceExecutionTime(\n+          partitionId, creationTime, record.getTimestamp());\n+    }\n+  }\n+\n+  private void storeWorkflowInstanceCreation(final long creationTime, final long recordKey) {\n+    workflowInstanceKeyToCreationTimeMap.put(recordKey, creationTime);\n+    creationTimeToWorkflowInstanceKeyTreeMap.put(creationTime, recordKey);\n+  }\n+\n+  private void handleJobRecord(\n+      final Record<?> record, final int partitionId, final long recordKey) {\n+    final var currentIntent = record.getIntent();\n+\n+    if (currentIntent == JobIntent.CREATED) {\n+      storeJobCreation(record.getTimestamp(), recordKey);\n+    } else if (currentIntent == JobIntent.ACTIVATED) {\n+      final var creationTime = jobKeyToCreationTimeMap.get(recordKey);\n+      executionLatencyMetrics.observeJobActivationTime(\n+          partitionId, creationTime, record.getTimestamp());\n+    } else if (currentIntent == JobIntent.COMPLETED) {\n+      final var creationTime = jobKeyToCreationTimeMap.remove(recordKey);\n+      executionLatencyMetrics.observeJobLifeTime(partitionId, creationTime, record.getTimestamp());\n+    }\n+  }\n+\n+  private void storeJobCreation(final long creationTime, final long recordKey) {\n+    jobKeyToCreationTimeMap.put(recordKey, creationTime);\n+    creationTimeToJobKeyTreeMap.put(creationTime, recordKey);\n+  }\n+\n+  private void cleanUp() {\n+    final var currentTimeMillis = System.currentTimeMillis();\n+\n+    final var deadTime = currentTimeMillis - TIME_TO_LIVE.toMillis();\n+    clearMaps(deadTime, creationTimeToJobKeyTreeMap, jobKeyToCreationTimeMap);\n+    clearMaps(\n+        deadTime, creationTimeToWorkflowInstanceKeyTreeMap, workflowInstanceKeyToCreationTimeMap);\n+  }\n+\n+  private void clearMaps(\n+      final long deadTime,\n+      final NavigableMap<Long, Long> timeToKeyMap,\n+      final Long2LongHashMap keyToTimestampMap) {\n+    final var outOfScopeInstances = timeToKeyMap.headMap(deadTime);\n+\n+    keyToTimestampMap.keySet().removeAll(outOfScopeInstances.values())\n+    outOfScopeInstances.clear();\n+  }\n+\n+  public static ExporterCfg defaultConfig() {\n+    final ExporterCfg exporterCfg = new ExporterCfg();\n+    exporterCfg.setClassName(MetricsExporter.class.getName());\n+    return exporterCfg;\n+  }\n+\n+  public static String defaultExporterId() {\n+    return MetricsExporter.class.getSimpleName();\n+  }\n+\n+  private static boolean isWorkflowInstanceRecord(final Record<?> record) {\n+    final var recordKey = record.getKey();\n+    final var recordValue = (WorkflowInstanceRecordValue) record.getValue();\n+    return recordKey == recordValue.getWorkflowInstanceKey();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYzNTE0Mg=="}, "originalCommit": {"oid": "c709e0ec7c6a84d404c31c8c37fc8560b5c88be9"}, "originalPosition": 150}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4850, "cost": 1, "resetAt": "2021-11-12T18:49:56Z"}}}