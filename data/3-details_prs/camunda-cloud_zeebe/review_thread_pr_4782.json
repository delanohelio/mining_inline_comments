{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDM3NzE0NTgw", "number": 4782, "reviewThreads": {"totalCount": 26, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QxMToyNTowNlrOEH7PkQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wNlQwNzoxNzo0NFrOELkUAg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2NzQ2MTI5OnYy", "diffSide": "RIGHT", "path": "atomix/cluster/pom.xml", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QxMToyNTowNlrOGnk1Cw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QxMToyNToxNVrOGnk1Rg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE1MTA1MQ==", "bodyText": "please remove the version", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r444151051", "createdAt": "2020-06-23T11:25:06Z", "author": {"login": "Zelldon"}, "path": "atomix/cluster/pom.xml", "diffHunk": "@@ -119,6 +119,11 @@\n       <artifactId>assertj-core</artifactId>\n       <scope>test</scope>\n     </dependency>\n+    <dependency>\n+      <groupId>io.zeebe</groupId>\n+      <artifactId>zeebe-util</artifactId>\n+      <version>0.24.0-SNAPSHOT</version>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dd6fcd629b4ef93f6531638f77fb74942691a4bb"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE1MTExMA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  <version>0.24.0-SNAPSHOT</version>", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r444151110", "createdAt": "2020-06-23T11:25:15Z", "author": {"login": "Zelldon"}, "path": "atomix/cluster/pom.xml", "diffHunk": "@@ -119,6 +119,11 @@\n       <artifactId>assertj-core</artifactId>\n       <scope>test</scope>\n     </dependency>\n+    <dependency>\n+      <groupId>io.zeebe</groupId>\n+      <artifactId>zeebe-util</artifactId>\n+      <version>0.24.0-SNAPSHOT</version>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE1MTA1MQ=="}, "originalCommit": {"oid": "dd6fcd629b4ef93f6531638f77fb74942691a4bb"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2NzQ2NDE4OnYy", "diffSide": "RIGHT", "path": "atomix/cluster/src/main/java/io/atomix/raft/partition/RaftPartitionGroup.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QxMToyNjowM1rOGnk24Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QxMToyNjowM1rOGnk24Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE1MTUyMQ==", "bodyText": "Maybe Space instead of Buffer", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r444151521", "createdAt": "2020-06-23T11:26:03Z", "author": {"login": "Zelldon"}, "path": "atomix/cluster/src/main/java/io/atomix/raft/partition/RaftPartitionGroup.java", "diffHunk": "@@ -440,6 +440,17 @@ public Builder withMaxEntrySize(final MemorySize maxEntrySize) {\n       return this;\n     }\n \n+    /**\n+     * Set the minimum free disk space (in bytes) to leave when allocating a new segment\n+     *\n+     * @param freeDiskBuffer free disk space in bytes\n+     * @return the Raft partition group builder\n+     */\n+    public Builder withFreeDiskBuffer(final long freeDiskBuffer) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dd6fcd629b4ef93f6531638f77fb74942691a4bb"}, "originalPosition": 10}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2NzQ3NjY2OnYy", "diffSide": "RIGHT", "path": "atomix/cluster/src/test/java/io/atomix/raft/RaftRule.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QxMTozMDowMVrOGnk-lg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QxMTozMDowMVrOGnk-lg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE1MzQ5NA==", "bodyText": "This was just again reordering? Seems that there is still something wrong with my setup \ud83d\ude05", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r444153494", "createdAt": "2020-06-23T11:30:01Z", "author": {"login": "Zelldon"}, "path": "atomix/cluster/src/test/java/io/atomix/raft/RaftRule.java", "diffHunk": "@@ -623,4 +597,31 @@ public long awaitCommit() throws Exception {\n       return commitFuture.get(30, TimeUnit.SECONDS);\n     }\n   }\n+\n+  private final class RaftSnapshotListener implements PersistedSnapshotListener {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dd6fcd629b4ef93f6531638f77fb74942691a4bb"}, "originalPosition": 47}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2NzQ5MTQ5OnYy", "diffSide": "RIGHT", "path": "broker/src/main/java/io/zeebe/broker/Broker.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QxMTozNDo1MVrOGnlHxw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QxMTozNDo1MVrOGnlHxw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE1NTg0Nw==", "bodyText": "IF you would add as a separate last step the disk space monitor installation then you dont need this if.", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r444155847", "createdAt": "2020-06-23T11:34:51Z", "author": {"login": "Zelldon"}, "path": "broker/src/main/java/io/zeebe/broker/Broker.java", "diffHunk": "@@ -253,9 +258,18 @@ private AutoCloseable subscriptionAPIStep(final BrokerInfo localBroker) {\n         new SubscriptionApiCommandMessageHandlerService(localBroker, atomix);\n     partitionListeners.add(messageHandlerService);\n     scheduleActor(messageHandlerService);\n+    addDiskSpaceUsageListener(messageHandlerService);\n     return messageHandlerService;\n   }\n \n+  private void addDiskSpaceUsageListener(final DiskSpaceUsageListener diskSpaceUsageListener) {\n+    if (diskSpaceUsageMonitor == null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dd6fcd629b4ef93f6531638f77fb74942691a4bb"}, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2NzUyMDY4OnYy", "diffSide": "RIGHT", "path": "broker/src/main/java/io/zeebe/broker/system/configuration/DataCfg.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QxMTo0Mzo1M1rOGnlZgw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QxMTo0Mzo1M1rOGnlZgw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE2MDM4Nw==", "bodyText": "As I said I would felt more comfortable if we use percentage here, because I have the feeling the user need to set that setting currently in respect to there used pvc size always. If we had a percentage we would be more dynamically and then the user only needs to set it when he has really small pvcs, but even then I think it would be possible to run it. If the user uses a small pvc it might even not have such a big load or expect not a big state at all.", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r444160387", "createdAt": "2020-06-23T11:43:53Z", "author": {"login": "Zelldon"}, "path": "broker/src/main/java/io/zeebe/broker/system/configuration/DataCfg.java", "diffHunk": "@@ -19,6 +19,9 @@\n public final class DataCfg implements ConfigurationEntry {\n   public static final String DEFAULT_DIRECTORY = \"data\";\n   private static final DataSize DEFAULT_DATA_SIZE = DataSize.ofMegabytes(512);\n+  private static final DataSize DEFAULT_LOW_FREE_DISKSPACE_WATERMARK = DataSize.ofGigabytes(1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dd6fcd629b4ef93f6531638f77fb74942691a4bb"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2NzUyNzM2OnYy", "diffSide": "RIGHT", "path": "broker/src/main/java/io/zeebe/broker/system/monitoring/DiskSpaceUsageMonitor.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QxMTo0NTo1MlrOGnldeg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQwNzowMjoxNlrOGoFdaA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE2MTQwMg==", "bodyText": "If you make this as an parameter you would be able to unit test the complete logic much easier", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r444161402", "createdAt": "2020-06-23T11:45:52Z", "author": {"login": "Zelldon"}, "path": "broker/src/main/java/io/zeebe/broker/system/monitoring/DiskSpaceUsageMonitor.java", "diffHunk": "@@ -0,0 +1,72 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.system.monitoring;\n+\n+import static io.zeebe.broker.Broker.LOG;\n+\n+import io.zeebe.broker.system.configuration.DataCfg;\n+import io.zeebe.util.sched.Actor;\n+import java.io.File;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.function.LongSupplier;\n+\n+public class DiskSpaceUsageMonitor extends Actor {\n+\n+  private final List<DiskSpaceUsageListener> diskSpaceUsageListeners = new ArrayList<>();\n+  private boolean currentDiskAvailableStatus = true;\n+  private LongSupplier diskSpaceSupplier;\n+  private final Duration monitoringDelay;\n+  private final long minFreeDiskRequired;\n+\n+  public DiskSpaceUsageMonitor(final DataCfg dataCfg) {\n+    this.monitoringDelay = dataCfg.getDiskUsageCheckDelay();\n+    this.minFreeDiskRequired = dataCfg.getHighFreeDiskSpaceWatermarkInBytes();\n+    final var directory = new File(dataCfg.getDirectories().get(0));\n+    diskSpaceSupplier = directory::getUsableSpace;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dd6fcd629b4ef93f6531638f77fb74942691a4bb"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDY4NTY3Mg==", "bodyText": "Do you mean unit testing DiskSpaceUsageMonitor ? Is it required when we have the integration test?", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r444685672", "createdAt": "2020-06-24T07:02:16Z", "author": {"login": "deepthidevaki"}, "path": "broker/src/main/java/io/zeebe/broker/system/monitoring/DiskSpaceUsageMonitor.java", "diffHunk": "@@ -0,0 +1,72 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.system.monitoring;\n+\n+import static io.zeebe.broker.Broker.LOG;\n+\n+import io.zeebe.broker.system.configuration.DataCfg;\n+import io.zeebe.util.sched.Actor;\n+import java.io.File;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.function.LongSupplier;\n+\n+public class DiskSpaceUsageMonitor extends Actor {\n+\n+  private final List<DiskSpaceUsageListener> diskSpaceUsageListeners = new ArrayList<>();\n+  private boolean currentDiskAvailableStatus = true;\n+  private LongSupplier diskSpaceSupplier;\n+  private final Duration monitoringDelay;\n+  private final long minFreeDiskRequired;\n+\n+  public DiskSpaceUsageMonitor(final DataCfg dataCfg) {\n+    this.monitoringDelay = dataCfg.getDiskUsageCheckDelay();\n+    this.minFreeDiskRequired = dataCfg.getHighFreeDiskSpaceWatermarkInBytes();\n+    final var directory = new File(dataCfg.getDirectories().get(0));\n+    diskSpaceSupplier = directory::getUsableSpace;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE2MTQwMg=="}, "originalCommit": {"oid": "dd6fcd629b4ef93f6531638f77fb74942691a4bb"}, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2NzUzMTk2OnYy", "diffSide": "RIGHT", "path": "broker/src/main/java/io/zeebe/broker/system/monitoring/DiskSpaceUsageMonitor.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QxMTo0NzowOFrOGnlgIg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QxMTo0NzowOFrOGnlgIg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE2MjA4Mg==", "bodyText": "This variable name is a bit misleading. It should be diskFreeSpace or usable space", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r444162082", "createdAt": "2020-06-23T11:47:08Z", "author": {"login": "Zelldon"}, "path": "broker/src/main/java/io/zeebe/broker/system/monitoring/DiskSpaceUsageMonitor.java", "diffHunk": "@@ -0,0 +1,72 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.system.monitoring;\n+\n+import static io.zeebe.broker.Broker.LOG;\n+\n+import io.zeebe.broker.system.configuration.DataCfg;\n+import io.zeebe.util.sched.Actor;\n+import java.io.File;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.function.LongSupplier;\n+\n+public class DiskSpaceUsageMonitor extends Actor {\n+\n+  private final List<DiskSpaceUsageListener> diskSpaceUsageListeners = new ArrayList<>();\n+  private boolean currentDiskAvailableStatus = true;\n+  private LongSupplier diskSpaceSupplier;\n+  private final Duration monitoringDelay;\n+  private final long minFreeDiskRequired;\n+\n+  public DiskSpaceUsageMonitor(final DataCfg dataCfg) {\n+    this.monitoringDelay = dataCfg.getDiskUsageCheckDelay();\n+    this.minFreeDiskRequired = dataCfg.getHighFreeDiskSpaceWatermarkInBytes();\n+    final var directory = new File(dataCfg.getDirectories().get(0));\n+    diskSpaceSupplier = directory::getUsableSpace;\n+  }\n+\n+  @Override\n+  protected void onActorStarted() {\n+    actor.runAtFixedRate(monitoringDelay, this::checkDiskUsageAndNotifyListeners);\n+  }\n+\n+  private void checkDiskUsageAndNotifyListeners() {\n+    final long diskSpaceUsage = diskSpaceSupplier.getAsLong();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dd6fcd629b4ef93f6531638f77fb74942691a4bb"}, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2NzUzNzE0OnYy", "diffSide": "RIGHT", "path": "broker/src/main/java/io/zeebe/broker/system/monitoring/DiskSpaceUsageMonitor.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QxMTo0ODozOVrOGnljWg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QxMTo0ODozOVrOGnljWg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE2MjkwNg==", "bodyText": "Maybe also rename the methods to diskSpace available; noDiskSpace available. I think it makes it more clear then below and above threshold", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r444162906", "createdAt": "2020-06-23T11:48:39Z", "author": {"login": "Zelldon"}, "path": "broker/src/main/java/io/zeebe/broker/system/monitoring/DiskSpaceUsageMonitor.java", "diffHunk": "@@ -0,0 +1,72 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.system.monitoring;\n+\n+import static io.zeebe.broker.Broker.LOG;\n+\n+import io.zeebe.broker.system.configuration.DataCfg;\n+import io.zeebe.util.sched.Actor;\n+import java.io.File;\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.function.LongSupplier;\n+\n+public class DiskSpaceUsageMonitor extends Actor {\n+\n+  private final List<DiskSpaceUsageListener> diskSpaceUsageListeners = new ArrayList<>();\n+  private boolean currentDiskAvailableStatus = true;\n+  private LongSupplier diskSpaceSupplier;\n+  private final Duration monitoringDelay;\n+  private final long minFreeDiskRequired;\n+\n+  public DiskSpaceUsageMonitor(final DataCfg dataCfg) {\n+    this.monitoringDelay = dataCfg.getDiskUsageCheckDelay();\n+    this.minFreeDiskRequired = dataCfg.getHighFreeDiskSpaceWatermarkInBytes();\n+    final var directory = new File(dataCfg.getDirectories().get(0));\n+    diskSpaceSupplier = directory::getUsableSpace;\n+  }\n+\n+  @Override\n+  protected void onActorStarted() {\n+    actor.runAtFixedRate(monitoringDelay, this::checkDiskUsageAndNotifyListeners);\n+  }\n+\n+  private void checkDiskUsageAndNotifyListeners() {\n+    final long diskSpaceUsage = diskSpaceSupplier.getAsLong();\n+    final boolean previousStatus = currentDiskAvailableStatus;\n+    currentDiskAvailableStatus = diskSpaceUsage >= minFreeDiskRequired;\n+    if (currentDiskAvailableStatus != previousStatus) {\n+      if (!currentDiskAvailableStatus) {\n+        LOG.debug(\n+            \"Out of disk space. Current available {} bytes. Minimum needed {} bytes.\",\n+            diskSpaceUsage,\n+            minFreeDiskRequired);\n+        diskSpaceUsageListeners.forEach(\n+            DiskSpaceUsageListener::onDiskSpaceUsageIncreasedAboveThreshold);\n+      } else {\n+        LOG.debug(\"Disk space available again. Current available {} bytes\", diskSpaceUsage);\n+        diskSpaceUsageListeners.forEach(\n+            DiskSpaceUsageListener::onDiskSpaceUsageReducedBelowThreshold);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dd6fcd629b4ef93f6531638f77fb74942691a4bb"}, "originalPosition": 55}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2NzU0NTAxOnYy", "diffSide": "RIGHT", "path": "broker/src/main/java/io/zeebe/broker/system/partitions/ZeebePartition.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QxMTo1MTowMlrOGnloKA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxMzoxMTo0NlrOGrlQZw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE2NDEzNg==", "bodyText": "So many listeners \ud83d\ude06", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r444164136", "createdAt": "2020-06-23T11:51:02Z", "author": {"login": "Zelldon"}, "path": "broker/src/main/java/io/zeebe/broker/system/partitions/ZeebePartition.java", "diffHunk": "@@ -66,7 +67,11 @@\n import org.slf4j.Logger;\n \n public final class ZeebePartition extends Actor\n-    implements RaftCommitListener, RaftRoleChangeListener, HealthMonitorable, FailureListener {\n+    implements RaftCommitListener,\n+        RaftRoleChangeListener,\n+        HealthMonitorable,\n+        FailureListener,\n+        DiskSpaceUsageListener {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dd6fcd629b4ef93f6531638f77fb74942691a4bb"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM1MjM1OQ==", "bodyText": "Just waiting for the ListenerListener interface now \ud83d\udc40", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448352359", "createdAt": "2020-07-01T13:11:46Z", "author": {"login": "npepinpe"}, "path": "broker/src/main/java/io/zeebe/broker/system/partitions/ZeebePartition.java", "diffHunk": "@@ -66,7 +67,11 @@\n import org.slf4j.Logger;\n \n public final class ZeebePartition extends Actor\n-    implements RaftCommitListener, RaftRoleChangeListener, HealthMonitorable, FailureListener {\n+    implements RaftCommitListener,\n+        RaftRoleChangeListener,\n+        HealthMonitorable,\n+        FailureListener,\n+        DiskSpaceUsageListener {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE2NDEzNg=="}, "originalCommit": {"oid": "dd6fcd629b4ef93f6531638f77fb74942691a4bb"}, "originalPosition": 17}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc2Nzc1NzMwOnYy", "diffSide": "RIGHT", "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryTest.java", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QxMjo1MTowNFrOGnnr9g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QxMjo1MzoxNlrOGt9IDg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE5Nzg3OA==", "bodyText": "Maybe assert that we get an response", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r444197878", "createdAt": "2020-06-23T12:51:04Z", "author": {"login": "Zelldon"}, "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryTest.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.it.health;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatCode;\n+\n+import io.zeebe.broker.it.util.GrpcClientRule;\n+import io.zeebe.broker.system.monitoring.DiskSpaceUsageListener;\n+import io.zeebe.broker.test.EmbeddedBrokerRule;\n+import io.zeebe.model.bpmn.Bpmn;\n+import io.zeebe.model.bpmn.BpmnModelInstance;\n+import io.zeebe.protocol.record.intent.JobIntent;\n+import io.zeebe.protocol.record.intent.TimerIntent;\n+import io.zeebe.protocol.record.value.JobRecordValueAssert;\n+import io.zeebe.protocol.record.value.TimerRecordValueAssert;\n+import io.zeebe.test.util.record.RecordingExporter;\n+import java.time.Duration;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import org.assertj.core.api.Assertions;\n+import org.awaitility.Awaitility;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.RuleChain;\n+import org.junit.rules.Timeout;\n+import org.springframework.util.unit.DataSize;\n+\n+public class DiskSpaceRecoveryTest {\n+  private final Timeout testTimeout = Timeout.seconds(120);\n+  private final EmbeddedBrokerRule embeddedBrokerRule =\n+      new EmbeddedBrokerRule(\n+          cfg -> {\n+            cfg.getData().setDiskUsageCheckDelay(Duration.ofSeconds(1));\n+            cfg.getData().setHighFreeDiskSpaceWatermark(DataSize.ofGigabytes(4));\n+          });\n+  private final GrpcClientRule clientRule = new GrpcClientRule(embeddedBrokerRule);\n+\n+  @Rule\n+  public RuleChain ruleChain =\n+      RuleChain.outerRule(testTimeout).around(embeddedBrokerRule).around(clientRule);\n+\n+  @Test\n+  public void shouldStopAcceptingRequestWhenDiskSpaceFull() throws InterruptedException {\n+    // given\n+    waitUntilDiskSpaceNotAvailable();\n+\n+    // when\n+    final var resultFuture =\n+        clientRule\n+            .getClient()\n+            .newPublishMessageCommand()\n+            .messageName(\"test\")\n+            .correlationKey(\"test\")\n+            .send();\n+\n+    // then\n+    Assertions.assertThatThrownBy(resultFuture::join)\n+        .hasRootCauseMessage(\n+            \"RESOURCE_EXHAUSTED: Cannot accept requests for partition 1. Broker is out of disk space\");\n+  }\n+\n+  @Test\n+  public void shouldRestartAcceptingRequestWhenDiskSpaceAvailableAgain()\n+      throws InterruptedException {\n+    // given\n+    waitUntilDiskSpaceNotAvailable();\n+\n+    // when\n+    waitUntilDiskSpaceAvailable();\n+    final var resultFuture =\n+        clientRule\n+            .getClient()\n+            .newPublishMessageCommand()\n+            .messageName(\"test\")\n+            .correlationKey(\"Test\")\n+            .send();\n+\n+    // then\n+    assertThatCode(resultFuture::join).doesNotThrowAnyException();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dd6fcd629b4ef93f6531638f77fb74942691a4bb"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDY4NDc4NQ==", "bodyText": "assertThat(resultFuture.join()).isNotNull(); did not work because the response is empty for publish message.", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r444684785", "createdAt": "2020-06-24T07:00:14Z", "author": {"login": "deepthidevaki"}, "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryTest.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.it.health;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatCode;\n+\n+import io.zeebe.broker.it.util.GrpcClientRule;\n+import io.zeebe.broker.system.monitoring.DiskSpaceUsageListener;\n+import io.zeebe.broker.test.EmbeddedBrokerRule;\n+import io.zeebe.model.bpmn.Bpmn;\n+import io.zeebe.model.bpmn.BpmnModelInstance;\n+import io.zeebe.protocol.record.intent.JobIntent;\n+import io.zeebe.protocol.record.intent.TimerIntent;\n+import io.zeebe.protocol.record.value.JobRecordValueAssert;\n+import io.zeebe.protocol.record.value.TimerRecordValueAssert;\n+import io.zeebe.test.util.record.RecordingExporter;\n+import java.time.Duration;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import org.assertj.core.api.Assertions;\n+import org.awaitility.Awaitility;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.RuleChain;\n+import org.junit.rules.Timeout;\n+import org.springframework.util.unit.DataSize;\n+\n+public class DiskSpaceRecoveryTest {\n+  private final Timeout testTimeout = Timeout.seconds(120);\n+  private final EmbeddedBrokerRule embeddedBrokerRule =\n+      new EmbeddedBrokerRule(\n+          cfg -> {\n+            cfg.getData().setDiskUsageCheckDelay(Duration.ofSeconds(1));\n+            cfg.getData().setHighFreeDiskSpaceWatermark(DataSize.ofGigabytes(4));\n+          });\n+  private final GrpcClientRule clientRule = new GrpcClientRule(embeddedBrokerRule);\n+\n+  @Rule\n+  public RuleChain ruleChain =\n+      RuleChain.outerRule(testTimeout).around(embeddedBrokerRule).around(clientRule);\n+\n+  @Test\n+  public void shouldStopAcceptingRequestWhenDiskSpaceFull() throws InterruptedException {\n+    // given\n+    waitUntilDiskSpaceNotAvailable();\n+\n+    // when\n+    final var resultFuture =\n+        clientRule\n+            .getClient()\n+            .newPublishMessageCommand()\n+            .messageName(\"test\")\n+            .correlationKey(\"test\")\n+            .send();\n+\n+    // then\n+    Assertions.assertThatThrownBy(resultFuture::join)\n+        .hasRootCauseMessage(\n+            \"RESOURCE_EXHAUSTED: Cannot accept requests for partition 1. Broker is out of disk space\");\n+  }\n+\n+  @Test\n+  public void shouldRestartAcceptingRequestWhenDiskSpaceAvailableAgain()\n+      throws InterruptedException {\n+    // given\n+    waitUntilDiskSpaceNotAvailable();\n+\n+    // when\n+    waitUntilDiskSpaceAvailable();\n+    final var resultFuture =\n+        clientRule\n+            .getClient()\n+            .newPublishMessageCommand()\n+            .messageName(\"test\")\n+            .correlationKey(\"Test\")\n+            .send();\n+\n+    // then\n+    assertThatCode(resultFuture::join).doesNotThrowAnyException();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE5Nzg3OA=="}, "originalCommit": {"oid": "dd6fcd629b4ef93f6531638f77fb74942691a4bb"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2NTc2Nw==", "bodyText": "Can we use another command then?", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448365767", "createdAt": "2020-07-01T13:32:47Z", "author": {"login": "npepinpe"}, "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryTest.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.it.health;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatCode;\n+\n+import io.zeebe.broker.it.util.GrpcClientRule;\n+import io.zeebe.broker.system.monitoring.DiskSpaceUsageListener;\n+import io.zeebe.broker.test.EmbeddedBrokerRule;\n+import io.zeebe.model.bpmn.Bpmn;\n+import io.zeebe.model.bpmn.BpmnModelInstance;\n+import io.zeebe.protocol.record.intent.JobIntent;\n+import io.zeebe.protocol.record.intent.TimerIntent;\n+import io.zeebe.protocol.record.value.JobRecordValueAssert;\n+import io.zeebe.protocol.record.value.TimerRecordValueAssert;\n+import io.zeebe.test.util.record.RecordingExporter;\n+import java.time.Duration;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import org.assertj.core.api.Assertions;\n+import org.awaitility.Awaitility;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.RuleChain;\n+import org.junit.rules.Timeout;\n+import org.springframework.util.unit.DataSize;\n+\n+public class DiskSpaceRecoveryTest {\n+  private final Timeout testTimeout = Timeout.seconds(120);\n+  private final EmbeddedBrokerRule embeddedBrokerRule =\n+      new EmbeddedBrokerRule(\n+          cfg -> {\n+            cfg.getData().setDiskUsageCheckDelay(Duration.ofSeconds(1));\n+            cfg.getData().setHighFreeDiskSpaceWatermark(DataSize.ofGigabytes(4));\n+          });\n+  private final GrpcClientRule clientRule = new GrpcClientRule(embeddedBrokerRule);\n+\n+  @Rule\n+  public RuleChain ruleChain =\n+      RuleChain.outerRule(testTimeout).around(embeddedBrokerRule).around(clientRule);\n+\n+  @Test\n+  public void shouldStopAcceptingRequestWhenDiskSpaceFull() throws InterruptedException {\n+    // given\n+    waitUntilDiskSpaceNotAvailable();\n+\n+    // when\n+    final var resultFuture =\n+        clientRule\n+            .getClient()\n+            .newPublishMessageCommand()\n+            .messageName(\"test\")\n+            .correlationKey(\"test\")\n+            .send();\n+\n+    // then\n+    Assertions.assertThatThrownBy(resultFuture::join)\n+        .hasRootCauseMessage(\n+            \"RESOURCE_EXHAUSTED: Cannot accept requests for partition 1. Broker is out of disk space\");\n+  }\n+\n+  @Test\n+  public void shouldRestartAcceptingRequestWhenDiskSpaceAvailableAgain()\n+      throws InterruptedException {\n+    // given\n+    waitUntilDiskSpaceNotAvailable();\n+\n+    // when\n+    waitUntilDiskSpaceAvailable();\n+    final var resultFuture =\n+        clientRule\n+            .getClient()\n+            .newPublishMessageCommand()\n+            .messageName(\"test\")\n+            .correlationKey(\"Test\")\n+            .send();\n+\n+    // then\n+    assertThatCode(resultFuture::join).doesNotThrowAnyException();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE5Nzg3OA=="}, "originalCommit": {"oid": "dd6fcd629b4ef93f6531638f77fb74942691a4bb"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc3MjE1NA==", "bodyText": "Why is it no good if we assert doesNotThrowAnyException? I can use deploy workflow command instead, if you insist.", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448772154", "createdAt": "2020-07-02T06:19:20Z", "author": {"login": "deepthidevaki"}, "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryTest.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.it.health;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatCode;\n+\n+import io.zeebe.broker.it.util.GrpcClientRule;\n+import io.zeebe.broker.system.monitoring.DiskSpaceUsageListener;\n+import io.zeebe.broker.test.EmbeddedBrokerRule;\n+import io.zeebe.model.bpmn.Bpmn;\n+import io.zeebe.model.bpmn.BpmnModelInstance;\n+import io.zeebe.protocol.record.intent.JobIntent;\n+import io.zeebe.protocol.record.intent.TimerIntent;\n+import io.zeebe.protocol.record.value.JobRecordValueAssert;\n+import io.zeebe.protocol.record.value.TimerRecordValueAssert;\n+import io.zeebe.test.util.record.RecordingExporter;\n+import java.time.Duration;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import org.assertj.core.api.Assertions;\n+import org.awaitility.Awaitility;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.RuleChain;\n+import org.junit.rules.Timeout;\n+import org.springframework.util.unit.DataSize;\n+\n+public class DiskSpaceRecoveryTest {\n+  private final Timeout testTimeout = Timeout.seconds(120);\n+  private final EmbeddedBrokerRule embeddedBrokerRule =\n+      new EmbeddedBrokerRule(\n+          cfg -> {\n+            cfg.getData().setDiskUsageCheckDelay(Duration.ofSeconds(1));\n+            cfg.getData().setHighFreeDiskSpaceWatermark(DataSize.ofGigabytes(4));\n+          });\n+  private final GrpcClientRule clientRule = new GrpcClientRule(embeddedBrokerRule);\n+\n+  @Rule\n+  public RuleChain ruleChain =\n+      RuleChain.outerRule(testTimeout).around(embeddedBrokerRule).around(clientRule);\n+\n+  @Test\n+  public void shouldStopAcceptingRequestWhenDiskSpaceFull() throws InterruptedException {\n+    // given\n+    waitUntilDiskSpaceNotAvailable();\n+\n+    // when\n+    final var resultFuture =\n+        clientRule\n+            .getClient()\n+            .newPublishMessageCommand()\n+            .messageName(\"test\")\n+            .correlationKey(\"test\")\n+            .send();\n+\n+    // then\n+    Assertions.assertThatThrownBy(resultFuture::join)\n+        .hasRootCauseMessage(\n+            \"RESOURCE_EXHAUSTED: Cannot accept requests for partition 1. Broker is out of disk space\");\n+  }\n+\n+  @Test\n+  public void shouldRestartAcceptingRequestWhenDiskSpaceAvailableAgain()\n+      throws InterruptedException {\n+    // given\n+    waitUntilDiskSpaceNotAvailable();\n+\n+    // when\n+    waitUntilDiskSpaceAvailable();\n+    final var resultFuture =\n+        clientRule\n+            .getClient()\n+            .newPublishMessageCommand()\n+            .messageName(\"test\")\n+            .correlationKey(\"Test\")\n+            .send();\n+\n+    // then\n+    assertThatCode(resultFuture::join).doesNotThrowAnyException();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE5Nzg3OA=="}, "originalCommit": {"oid": "dd6fcd629b4ef93f6531638f77fb74942691a4bb"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDg0MDU5MA==", "bodyText": "Code shouldn't generally throw exception so it's usually a weird assertion to have. But I'm not insisting, it's more of a rule of thumb - I'd rather we assert something happened than it didn't, e.g. no exception thrown.", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r450840590", "createdAt": "2020-07-07T12:53:16Z", "author": {"login": "npepinpe"}, "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryTest.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.it.health;\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.assertj.core.api.Assertions.assertThatCode;\n+\n+import io.zeebe.broker.it.util.GrpcClientRule;\n+import io.zeebe.broker.system.monitoring.DiskSpaceUsageListener;\n+import io.zeebe.broker.test.EmbeddedBrokerRule;\n+import io.zeebe.model.bpmn.Bpmn;\n+import io.zeebe.model.bpmn.BpmnModelInstance;\n+import io.zeebe.protocol.record.intent.JobIntent;\n+import io.zeebe.protocol.record.intent.TimerIntent;\n+import io.zeebe.protocol.record.value.JobRecordValueAssert;\n+import io.zeebe.protocol.record.value.TimerRecordValueAssert;\n+import io.zeebe.test.util.record.RecordingExporter;\n+import java.time.Duration;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import org.assertj.core.api.Assertions;\n+import org.awaitility.Awaitility;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.RuleChain;\n+import org.junit.rules.Timeout;\n+import org.springframework.util.unit.DataSize;\n+\n+public class DiskSpaceRecoveryTest {\n+  private final Timeout testTimeout = Timeout.seconds(120);\n+  private final EmbeddedBrokerRule embeddedBrokerRule =\n+      new EmbeddedBrokerRule(\n+          cfg -> {\n+            cfg.getData().setDiskUsageCheckDelay(Duration.ofSeconds(1));\n+            cfg.getData().setHighFreeDiskSpaceWatermark(DataSize.ofGigabytes(4));\n+          });\n+  private final GrpcClientRule clientRule = new GrpcClientRule(embeddedBrokerRule);\n+\n+  @Rule\n+  public RuleChain ruleChain =\n+      RuleChain.outerRule(testTimeout).around(embeddedBrokerRule).around(clientRule);\n+\n+  @Test\n+  public void shouldStopAcceptingRequestWhenDiskSpaceFull() throws InterruptedException {\n+    // given\n+    waitUntilDiskSpaceNotAvailable();\n+\n+    // when\n+    final var resultFuture =\n+        clientRule\n+            .getClient()\n+            .newPublishMessageCommand()\n+            .messageName(\"test\")\n+            .correlationKey(\"test\")\n+            .send();\n+\n+    // then\n+    Assertions.assertThatThrownBy(resultFuture::join)\n+        .hasRootCauseMessage(\n+            \"RESOURCE_EXHAUSTED: Cannot accept requests for partition 1. Broker is out of disk space\");\n+  }\n+\n+  @Test\n+  public void shouldRestartAcceptingRequestWhenDiskSpaceAvailableAgain()\n+      throws InterruptedException {\n+    // given\n+    waitUntilDiskSpaceNotAvailable();\n+\n+    // when\n+    waitUntilDiskSpaceAvailable();\n+    final var resultFuture =\n+        clientRule\n+            .getClient()\n+            .newPublishMessageCommand()\n+            .messageName(\"test\")\n+            .correlationKey(\"Test\")\n+            .send();\n+\n+    // then\n+    assertThatCode(resultFuture::join).doesNotThrowAnyException();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDE5Nzg3OA=="}, "originalCommit": {"oid": "dd6fcd629b4ef93f6531638f77fb74942691a4bb"}, "originalPosition": 85}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5MzcyMTczOnYy", "diffSide": "RIGHT", "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryClusteredTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQwOToxMToxOFrOGrdohA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQwOToxMToxOFrOGrdohA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODIyNzQ2MA==", "bodyText": "Could you reference here the issue please", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448227460", "createdAt": "2020-07-01T09:11:18Z", "author": {"login": "Zelldon"}, "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryClusteredTest.java", "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.it.health;\n+\n+import static io.zeebe.broker.it.util.ZeebeAssertHelper.assertWorkflowInstanceCompleted;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import io.zeebe.broker.Broker;\n+import io.zeebe.broker.it.clustering.ClusteringRule;\n+import io.zeebe.broker.it.util.GrpcClientRule;\n+import io.zeebe.broker.system.monitoring.DiskSpaceUsageListener;\n+import io.zeebe.client.api.response.DeploymentEvent;\n+import io.zeebe.model.bpmn.Bpmn;\n+import io.zeebe.model.bpmn.BpmnModelInstance;\n+import io.zeebe.protocol.record.intent.DeploymentIntent;\n+import io.zeebe.protocol.record.intent.MessageSubscriptionIntent;\n+import io.zeebe.protocol.record.intent.WorkflowInstanceSubscriptionIntent;\n+import io.zeebe.test.util.record.RecordingExporter;\n+import java.time.Duration;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import org.awaitility.Awaitility;\n+import org.junit.Ignore;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.RuleChain;\n+import org.junit.rules.Timeout;\n+import org.springframework.util.unit.DataSize;\n+\n+public class DiskSpaceRecoveryClusteredTest {\n+  private static final String CORRELATION_KEY = \"item-2\";\n+  private final String messageName = \"test\";\n+  private final Timeout testTimeout = Timeout.seconds(120);\n+  private final ClusteringRule clusteringRule =\n+      new ClusteringRule(\n+          3,\n+          1,\n+          3,\n+          cfg -> {\n+            cfg.getData().setDiskUsageCheckDelay(Duration.ofSeconds(1));\n+            cfg.getData().setHighFreeDiskSpaceWatermark(DataSize.ofGigabytes(4));\n+          });\n+  private final GrpcClientRule clientRule = new GrpcClientRule(clusteringRule);\n+\n+  @Rule\n+  public RuleChain ruleChain =\n+      RuleChain.outerRule(testTimeout).around(clusteringRule).around(clientRule);\n+\n+  @Test\n+  public void shouldDistributeDeploymentAfterDiskSpaceAvailableAgain() throws InterruptedException {\n+    // given\n+    final var failingBroker =\n+        clusteringRule.getBroker(clusteringRule.getLeaderForPartition(3).getNodeId());\n+    waitUntilDiskSpaceNotAvailable(failingBroker);\n+\n+    final long deploymentKey =\n+        deployWorkflow(Bpmn.createExecutableProcess(\"test\").startEvent().endEvent().done());\n+\n+    // when\n+    Awaitility.await()\n+        .timeout(Duration.ofSeconds(60))\n+        .until(\n+            () ->\n+                RecordingExporter.deploymentRecords(DeploymentIntent.DISTRIBUTE).limit(1).exists());\n+\n+    waitUntilDiskSpaceAvailable(failingBroker);\n+\n+    // then\n+    clientRule.waitUntilDeploymentIsDone(deploymentKey);\n+  }\n+\n+  @Ignore(\"Apparently a message correlation is not retried if failed\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a28589048f8248828671adc6cb0ecec032c4fc87"}, "originalPosition": 78}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NDEyMDI4OnYy", "diffSide": "RIGHT", "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryITTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxMToxMjo1NFrOGrhiuA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxMzozMjoxNVrOGrmDiA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODI5MTUxMg==", "bodyText": "Ok this test will take at least 1 minute right - wouldn't be nice to have something like zeebe-io/enhancements#5", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448291512", "createdAt": "2020-07-01T11:12:54Z", "author": {"login": "Zelldon"}, "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryITTest.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.it.health;\n+\n+import static org.assertj.core.api.Assertions.assertThatCode;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+import static org.awaitility.Awaitility.await;\n+\n+import com.github.dockerjava.api.model.Bind;\n+import com.github.dockerjava.api.model.Volume;\n+import io.zeebe.client.ZeebeClient;\n+import io.zeebe.containers.ZeebeBrokerContainer;\n+import java.time.Duration;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.elasticsearch.client.RestClient;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.testcontainers.containers.Network;\n+import org.testcontainers.elasticsearch.ElasticsearchContainer;\n+\n+public class DiskSpaceRecoveryITTest {\n+  static ZeebeBrokerContainer zeebeBroker;\n+  private static final Logger LOG = LoggerFactory.getLogger(\"TEST\");\n+  private static final String VOLUME_NAME = \"tmpdata1\";\n+  private static String containerIPAddress;\n+  private static Integer apiPort;\n+  private static ElasticsearchContainer elastic;\n+  private ZeebeClient client;\n+\n+  @BeforeClass\n+  public static void setUpClass() {\n+    final var elasticHostInternal = \"http://elastic:9200\";\n+    zeebeBroker = createZeebe(elasticHostInternal);\n+    final var network = zeebeBroker.getNetwork();\n+    elastic = createElastic(network);\n+    zeebeBroker.start();\n+\n+    apiPort = zeebeBroker.getMappedPort(26500);\n+    containerIPAddress = zeebeBroker.getContainerIpAddress();\n+  }\n+\n+  private static ZeebeBrokerContainer createZeebe(final String elasticHost) {\n+    zeebeBroker =\n+        new ZeebeBrokerContainer(\"current-test\")\n+            .withEnv(\n+                \"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_CLASSNAME\",\n+                \"io.zeebe.exporter.ElasticsearchExporter\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_URL\", elasticHost)\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_DELAY\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_SIZE\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_SNAPSHOTPERIOD\", \"1m\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ef515fed93020dc76d7b339d99e86b0fc50d4514"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2NTQ0OA==", "bodyText": "Is there something else we could do at all? Just wondering", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448365448", "createdAt": "2020-07-01T13:32:15Z", "author": {"login": "npepinpe"}, "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryITTest.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.it.health;\n+\n+import static org.assertj.core.api.Assertions.assertThatCode;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+import static org.awaitility.Awaitility.await;\n+\n+import com.github.dockerjava.api.model.Bind;\n+import com.github.dockerjava.api.model.Volume;\n+import io.zeebe.client.ZeebeClient;\n+import io.zeebe.containers.ZeebeBrokerContainer;\n+import java.time.Duration;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.elasticsearch.client.RestClient;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.testcontainers.containers.Network;\n+import org.testcontainers.elasticsearch.ElasticsearchContainer;\n+\n+public class DiskSpaceRecoveryITTest {\n+  static ZeebeBrokerContainer zeebeBroker;\n+  private static final Logger LOG = LoggerFactory.getLogger(\"TEST\");\n+  private static final String VOLUME_NAME = \"tmpdata1\";\n+  private static String containerIPAddress;\n+  private static Integer apiPort;\n+  private static ElasticsearchContainer elastic;\n+  private ZeebeClient client;\n+\n+  @BeforeClass\n+  public static void setUpClass() {\n+    final var elasticHostInternal = \"http://elastic:9200\";\n+    zeebeBroker = createZeebe(elasticHostInternal);\n+    final var network = zeebeBroker.getNetwork();\n+    elastic = createElastic(network);\n+    zeebeBroker.start();\n+\n+    apiPort = zeebeBroker.getMappedPort(26500);\n+    containerIPAddress = zeebeBroker.getContainerIpAddress();\n+  }\n+\n+  private static ZeebeBrokerContainer createZeebe(final String elasticHost) {\n+    zeebeBroker =\n+        new ZeebeBrokerContainer(\"current-test\")\n+            .withEnv(\n+                \"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_CLASSNAME\",\n+                \"io.zeebe.exporter.ElasticsearchExporter\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_URL\", elasticHost)\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_DELAY\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_SIZE\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_SNAPSHOTPERIOD\", \"1m\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODI5MTUxMg=="}, "originalCommit": {"oid": "ef515fed93020dc76d7b339d99e86b0fc50d4514"}, "originalPosition": 60}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NDI3NTU0OnYy", "diffSide": "RIGHT", "path": "atomix/cluster/pom.xml", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxMjowNDoxN1rOGrjCpA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxMjowNDoxN1rOGrjCpA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODMxNjA2OA==", "bodyText": "This is duplicated", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448316068", "createdAt": "2020-07-01T12:04:17Z", "author": {"login": "npepinpe"}, "path": "atomix/cluster/pom.xml", "diffHunk": "@@ -119,6 +119,10 @@\n       <artifactId>assertj-core</artifactId>\n       <scope>test</scope>\n     </dependency>\n+    <dependency>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ef515fed93020dc76d7b339d99e86b0fc50d4514"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NDI4Nzk5OnYy", "diffSide": "RIGHT", "path": "atomix/cluster/src/main/java/io/atomix/raft/storage/RaftStorage.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxMjowODoxOVrOGrjKXQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxMjowODoxOVrOGrjKXQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODMxODA0NQ==", "bodyText": "Is there any reason not to rename the getter if we rename the property?", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448318045", "createdAt": "2020-07-01T12:08:19Z", "author": {"login": "npepinpe"}, "path": "atomix/cluster/src/main/java/io/atomix/raft/storage/RaftStorage.java", "diffHunk": "@@ -189,8 +189,8 @@ public boolean dynamicCompaction() {\n    *\n    * @return the percentage of disk space that must be available before log compaction is forced\n    */\n-  public double freeDiskBuffer() {\n-    return freeDiskBuffer;\n+  public long freeDiskBuffer() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ef515fed93020dc76d7b339d99e86b0fc50d4514"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NDMwNTY4OnYy", "diffSide": "RIGHT", "path": "broker/src/main/java/io/zeebe/broker/Broker.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxMjoxMzo1MVrOGrjU8w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxMjoxMzo1MVrOGrjU8w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODMyMDc1NQ==", "bodyText": "If the close could fail, we should wrap it in a try catch to make sure we also close the disk space usage monitor.", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448320755", "createdAt": "2020-07-01T12:13:51Z", "author": {"login": "npepinpe"}, "path": "broker/src/main/java/io/zeebe/broker/Broker.java", "diffHunk": "@@ -271,20 +282,26 @@ private AutoCloseable topologyManagerStep(\n     return topologyManager;\n   }\n \n-  private AutoCloseable monitoringServerStep(\n-      final NetworkCfg networkCfg, final BrokerInfo localBroker) {\n+  private AutoCloseable monitoringServerStep(final DataCfg data, final BrokerInfo localBroker) {\n     healthCheckService = new BrokerHealthCheckService(localBroker, atomix);\n     springBrokerBridge.registerBrokerHealthCheckServiceSupplier(() -> healthCheckService);\n     partitionListeners.add(healthCheckService);\n     scheduleActor(healthCheckService);\n \n-    return () -> healthCheckService.close();\n+    diskSpaceUsageMonitor = new DiskSpaceUsageMonitor(data);\n+    scheduleActor(diskSpaceUsageMonitor);\n+    diskSpaceUsageListeners.forEach(l -> diskSpaceUsageMonitor.addDiskUsageListener(l));\n+    return () -> {\n+      healthCheckService.close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ef515fed93020dc76d7b339d99e86b0fc50d4514"}, "originalPosition": 80}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NDMzMjQ4OnYy", "diffSide": "RIGHT", "path": "broker/src/main/java/io/zeebe/broker/engine/impl/SubscriptionApiCommandMessageHandlerService.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxMjoyMjoxNlrOGrjlVA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQwNjowNToxNFrOGr-lDw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODMyNDk0OA==", "bodyText": "I assume this is to avoid the NoRemoteHandler errors - my question here would be, shouldn't we handle these as possible cases on the other side? Why are we expecting the service to always be there? I imagine that's a little out of scope though...just a question", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448324948", "createdAt": "2020-07-01T12:22:16Z", "author": {"login": "npepinpe"}, "path": "broker/src/main/java/io/zeebe/broker/engine/impl/SubscriptionApiCommandMessageHandlerService.java", "diffHunk": "@@ -77,4 +82,31 @@ protected void onActorStarting() {\n                     }));\n     return future;\n   }\n+\n+  @Override\n+  public void onDiskSpaceNotAvailable() {\n+    actor.call(\n+        () -> {\n+          LOG.debug(\n+              \"Broker is out of disk space. All requests with topic {} will be rejected.\",\n+              SUBSCRIPTION_TOPIC);\n+          atomix.getCommunicationService().unsubscribe(SUBSCRIPTION_TOPIC);\n+          atomix", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ef515fed93020dc76d7b339d99e86b0fc50d4514"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc2NzI0Nw==", "bodyText": "Here it doesn't make a difference because the sender is not expecting any response. Ideally this should respond with a \"Resource exhausted\" error similar to the deployment request. But the current interface for subscription message request returns nothing. This would probably be fixed by #4786", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448767247", "createdAt": "2020-07-02T06:05:14Z", "author": {"login": "deepthidevaki"}, "path": "broker/src/main/java/io/zeebe/broker/engine/impl/SubscriptionApiCommandMessageHandlerService.java", "diffHunk": "@@ -77,4 +82,31 @@ protected void onActorStarting() {\n                     }));\n     return future;\n   }\n+\n+  @Override\n+  public void onDiskSpaceNotAvailable() {\n+    actor.call(\n+        () -> {\n+          LOG.debug(\n+              \"Broker is out of disk space. All requests with topic {} will be rejected.\",\n+              SUBSCRIPTION_TOPIC);\n+          atomix.getCommunicationService().unsubscribe(SUBSCRIPTION_TOPIC);\n+          atomix", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODMyNDk0OA=="}, "originalCommit": {"oid": "ef515fed93020dc76d7b339d99e86b0fc50d4514"}, "originalPosition": 64}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NDM0NTUzOnYy", "diffSide": "RIGHT", "path": "broker/src/main/java/io/zeebe/broker/system/configuration/DataCfg.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxMjoyNjowMFrOGrjtfA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQwNjowNTo1OFrOGr-mOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODMyNzAzNg==", "bodyText": "Hm, at the moment I think we do most of our validation in SystemContext#validateConfiguration. Or maybe I'm mistaken? I'm not sure if that was a conscious decision or I just thought we did that.", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448327036", "createdAt": "2020-07-01T12:26:00Z", "author": {"login": "npepinpe"}, "path": "broker/src/main/java/io/zeebe/broker/system/configuration/DataCfg.java", "diffHunk": "@@ -85,21 +92,67 @@ public StorageLevel getAtomixStorageLevel() {\n     return useMmap() ? StorageLevel.MAPPED : StorageLevel.DISK;\n   }\n \n+  public double getDiskUsageCommandWatermark() {\n+    return diskUsageCommandWatermark;\n+  }\n+\n+  public void setDiskUsageCommandWatermark(final double diskUsageCommandWatermark) {\n+    Preconditions.checkArgument(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ef515fed93020dc76d7b339d99e86b0fc50d4514"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc2NzU0NQ==", "bodyText": "Didn't knew about SystemContext#validateConfiguration. I can move the validation there.", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448767545", "createdAt": "2020-07-02T06:05:58Z", "author": {"login": "deepthidevaki"}, "path": "broker/src/main/java/io/zeebe/broker/system/configuration/DataCfg.java", "diffHunk": "@@ -85,21 +92,67 @@ public StorageLevel getAtomixStorageLevel() {\n     return useMmap() ? StorageLevel.MAPPED : StorageLevel.DISK;\n   }\n \n+  public double getDiskUsageCommandWatermark() {\n+    return diskUsageCommandWatermark;\n+  }\n+\n+  public void setDiskUsageCommandWatermark(final double diskUsageCommandWatermark) {\n+    Preconditions.checkArgument(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODMyNzAzNg=="}, "originalCommit": {"oid": "ef515fed93020dc76d7b339d99e86b0fc50d4514"}, "originalPosition": 43}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NDM5MTI1OnYy", "diffSide": "RIGHT", "path": "broker/src/main/java/io/zeebe/broker/system/monitoring/DiskSpaceUsageListener.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxMjozOTowNlrOGrkJfw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxMjozOTowNlrOGrkJfw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODMzNDIwNw==", "bodyText": "If possible we should document public interfaces \ud83d\ude42", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448334207", "createdAt": "2020-07-01T12:39:06Z", "author": {"login": "npepinpe"}, "path": "broker/src/main/java/io/zeebe/broker/system/monitoring/DiskSpaceUsageListener.java", "diffHunk": "@@ -0,0 +1,15 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.system.monitoring;\n+\n+public interface DiskSpaceUsageListener {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ef515fed93020dc76d7b339d99e86b0fc50d4514"}, "originalPosition": 10}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NDUwOTQwOnYy", "diffSide": "RIGHT", "path": "broker/src/main/java/io/zeebe/broker/transport/commandapi/CommandApiRequestHandler.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxMzoxMzowM1rOGrlTsQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QxMzowNToxMlrOGt9k5A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM1MzIwMQ==", "bodyText": "Can we write the current disk space and the threshold as context info?", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448353201", "createdAt": "2020-07-01T13:13:03Z", "author": {"login": "npepinpe"}, "path": "broker/src/main/java/io/zeebe/broker/transport/commandapi/CommandApiRequestHandler.java", "diffHunk": "@@ -81,6 +82,17 @@ private void handleExecuteCommandRequest(\n       final DirectBuffer buffer,\n       final int messageOffset,\n       final int messageLength) {\n+\n+    if (!isDiskSpaceAvailable) {\n+      errorResponseWriter\n+          .resourceExhausted(\n+              String.format(\n+                  \"Cannot accept requests for partition %d. Broker is out of disk space\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ef515fed93020dc76d7b339d99e86b0fc50d4514"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc2ODIxNg==", "bodyText": "Is it useful for the clients? We log it in DiskSpaceUsageMonitor.", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448768216", "createdAt": "2020-07-02T06:07:50Z", "author": {"login": "deepthidevaki"}, "path": "broker/src/main/java/io/zeebe/broker/transport/commandapi/CommandApiRequestHandler.java", "diffHunk": "@@ -81,6 +82,17 @@ private void handleExecuteCommandRequest(\n       final DirectBuffer buffer,\n       final int messageOffset,\n       final int messageLength) {\n+\n+    if (!isDiskSpaceAvailable) {\n+      errorResponseWriter\n+          .resourceExhausted(\n+              String.format(\n+                  \"Cannot accept requests for partition %d. Broker is out of disk space\",", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM1MzIwMQ=="}, "originalCommit": {"oid": "ef515fed93020dc76d7b339d99e86b0fc50d4514"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDg0Mjc3MQ==", "bodyText": "It's useful for us that's for sure, hard to say yet if it's useful for normal users. Do you think adding it would confuse them? What are the reasons for omitting them?", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r450842771", "createdAt": "2020-07-07T12:56:48Z", "author": {"login": "npepinpe"}, "path": "broker/src/main/java/io/zeebe/broker/transport/commandapi/CommandApiRequestHandler.java", "diffHunk": "@@ -81,6 +82,17 @@ private void handleExecuteCommandRequest(\n       final DirectBuffer buffer,\n       final int messageOffset,\n       final int messageLength) {\n+\n+    if (!isDiskSpaceAvailable) {\n+      errorResponseWriter\n+          .resourceExhausted(\n+              String.format(\n+                  \"Cannot accept requests for partition %d. Broker is out of disk space\",", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM1MzIwMQ=="}, "originalCommit": {"oid": "ef515fed93020dc76d7b339d99e86b0fc50d4514"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDg0Nzk3Mg==", "bodyText": "CommandApi does not now how much disk space is available or required. It only knows that there is not enough. If we want to provide this information to the users, the listener interface should be changed. Since user's can't do anything with that information, I don't think it is necessary. We log both required and available disk space in DiskSpaceUsageMonitor, which can be used by an operator.", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r450847972", "createdAt": "2020-07-07T13:05:12Z", "author": {"login": "deepthidevaki"}, "path": "broker/src/main/java/io/zeebe/broker/transport/commandapi/CommandApiRequestHandler.java", "diffHunk": "@@ -81,6 +82,17 @@ private void handleExecuteCommandRequest(\n       final DirectBuffer buffer,\n       final int messageOffset,\n       final int messageLength) {\n+\n+    if (!isDiskSpaceAvailable) {\n+      errorResponseWriter\n+          .resourceExhausted(\n+              String.format(\n+                  \"Cannot accept requests for partition %d. Broker is out of disk space\",", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM1MzIwMQ=="}, "originalCommit": {"oid": "ef515fed93020dc76d7b339d99e86b0fc50d4514"}, "originalPosition": 17}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NDU2MjA1OnYy", "diffSide": "RIGHT", "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryClusteredTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxMzoyNjozMlrOGrl01Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQwNjowOTozNFrOGr-q_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2MTY4NQ==", "bodyText": "We don't have a test for user commands? I see we have one for deployment and messages (subscription API).", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448361685", "createdAt": "2020-07-01T13:26:32Z", "author": {"login": "npepinpe"}, "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryClusteredTest.java", "diffHunk": "@@ -0,0 +1,214 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.it.health;\n+\n+import static io.zeebe.broker.it.util.ZeebeAssertHelper.assertWorkflowInstanceCompleted;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import io.zeebe.broker.Broker;\n+import io.zeebe.broker.it.clustering.ClusteringRule;\n+import io.zeebe.broker.it.util.GrpcClientRule;\n+import io.zeebe.broker.system.monitoring.DiskSpaceUsageListener;\n+import io.zeebe.client.api.response.DeploymentEvent;\n+import io.zeebe.model.bpmn.Bpmn;\n+import io.zeebe.model.bpmn.BpmnModelInstance;\n+import io.zeebe.protocol.record.intent.DeploymentIntent;\n+import io.zeebe.protocol.record.intent.MessageSubscriptionIntent;\n+import io.zeebe.protocol.record.intent.WorkflowInstanceSubscriptionIntent;\n+import io.zeebe.test.util.record.RecordingExporter;\n+import java.time.Duration;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import org.awaitility.Awaitility;\n+import org.junit.Ignore;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.RuleChain;\n+import org.junit.rules.Timeout;\n+import org.springframework.util.unit.DataSize;\n+\n+public class DiskSpaceRecoveryClusteredTest {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ef515fed93020dc76d7b339d99e86b0fc50d4514"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc2ODc2NQ==", "bodyText": "We have it in DiskSpaceRecoveryTest with single broker.", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448768765", "createdAt": "2020-07-02T06:09:34Z", "author": {"login": "deepthidevaki"}, "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryClusteredTest.java", "diffHunk": "@@ -0,0 +1,214 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.it.health;\n+\n+import static io.zeebe.broker.it.util.ZeebeAssertHelper.assertWorkflowInstanceCompleted;\n+import static org.assertj.core.api.Assertions.assertThat;\n+\n+import io.zeebe.broker.Broker;\n+import io.zeebe.broker.it.clustering.ClusteringRule;\n+import io.zeebe.broker.it.util.GrpcClientRule;\n+import io.zeebe.broker.system.monitoring.DiskSpaceUsageListener;\n+import io.zeebe.client.api.response.DeploymentEvent;\n+import io.zeebe.model.bpmn.Bpmn;\n+import io.zeebe.model.bpmn.BpmnModelInstance;\n+import io.zeebe.protocol.record.intent.DeploymentIntent;\n+import io.zeebe.protocol.record.intent.MessageSubscriptionIntent;\n+import io.zeebe.protocol.record.intent.WorkflowInstanceSubscriptionIntent;\n+import io.zeebe.test.util.record.RecordingExporter;\n+import java.time.Duration;\n+import java.util.Map;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import org.awaitility.Awaitility;\n+import org.junit.Ignore;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.RuleChain;\n+import org.junit.rules.Timeout;\n+import org.springframework.util.unit.DataSize;\n+\n+public class DiskSpaceRecoveryClusteredTest {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2MTY4NQ=="}, "originalCommit": {"oid": "ef515fed93020dc76d7b339d99e86b0fc50d4514"}, "originalPosition": 36}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NDU3MTY5OnYy", "diffSide": "RIGHT", "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryITTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxMzoyODo1M1rOGrl6yQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxMzoyODo1M1rOGrl6yQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2MzIwOQ==", "bodyText": "I'm guessing this is testing left over?", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448363209", "createdAt": "2020-07-01T13:28:53Z", "author": {"login": "npepinpe"}, "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryITTest.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.it.health;\n+\n+import static org.assertj.core.api.Assertions.assertThatCode;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+import static org.awaitility.Awaitility.await;\n+\n+import com.github.dockerjava.api.model.Bind;\n+import com.github.dockerjava.api.model.Volume;\n+import io.zeebe.client.ZeebeClient;\n+import io.zeebe.containers.ZeebeBrokerContainer;\n+import java.time.Duration;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.elasticsearch.client.RestClient;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.testcontainers.containers.Network;\n+import org.testcontainers.elasticsearch.ElasticsearchContainer;\n+\n+public class DiskSpaceRecoveryITTest {\n+  static ZeebeBrokerContainer zeebeBroker;\n+  private static final Logger LOG = LoggerFactory.getLogger(\"TEST\");\n+  private static final String VOLUME_NAME = \"tmpdata1\";\n+  private static String containerIPAddress;\n+  private static Integer apiPort;\n+  private static ElasticsearchContainer elastic;\n+  private ZeebeClient client;\n+\n+  @BeforeClass\n+  public static void setUpClass() {\n+    final var elasticHostInternal = \"http://elastic:9200\";\n+    zeebeBroker = createZeebe(elasticHostInternal);\n+    final var network = zeebeBroker.getNetwork();\n+    elastic = createElastic(network);\n+    zeebeBroker.start();\n+\n+    apiPort = zeebeBroker.getMappedPort(26500);\n+    containerIPAddress = zeebeBroker.getContainerIpAddress();\n+  }\n+\n+  private static ZeebeBrokerContainer createZeebe(final String elasticHost) {\n+    zeebeBroker =\n+        new ZeebeBrokerContainer(\"current-test\")\n+            .withEnv(\n+                \"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_CLASSNAME\",\n+                \"io.zeebe.exporter.ElasticsearchExporter\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_URL\", elasticHost)\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_DELAY\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_SIZE\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_SNAPSHOTPERIOD\", \"1m\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_LOGSEGMENTSIZE\", \"4MB\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_DISKUSAGECOMMANDWATERMARK\", \"0.5\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_LOGINDEXDENSITY\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_INDEX_MESSAGE\", \"true\");\n+\n+    zeebeBroker\n+        .getDockerClient()\n+        .createVolumeCmd()\n+        .withDriver(\"local\")\n+        .withDriverOpts(Map.of(\"type\", \"tmpfs\", \"device\", \"tmpfs\", \"o\", \"size=32m\"))\n+        .withName(VOLUME_NAME)\n+        .exec();\n+    final Volume newVolume = new Volume(\"/usr/local/zeebe/data\");\n+    zeebeBroker.withCreateContainerCmdModifier(\n+        cmd ->\n+            cmd.withHostConfig(cmd.getHostConfig().withBinds(new Bind(VOLUME_NAME, newVolume)))\n+                .withName(\"zeebe-test\"));\n+\n+    return zeebeBroker;\n+  }\n+\n+  private static ElasticsearchContainer createElastic(final Network network) {\n+    final ElasticsearchContainer container =\n+        new ElasticsearchContainer(\n+            \"docker.elastic.co/elasticsearch/elasticsearch:\"\n+                + RestClient.class.getPackage().getImplementationVersion());\n+\n+    container.withNetwork(network).withEnv(\"discovery.type\", \"single-node\");\n+    container.withCreateContainerCmdModifier(cmd -> cmd.withName(\"elastic\"));\n+    return container;\n+  }\n+\n+  @AfterClass\n+  public static void tearDownClass() {\n+    LoggerFactory.getLogger(\"Test\").info(zeebeBroker.getLogs());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ef515fed93020dc76d7b339d99e86b0fc50d4514"}, "originalPosition": 95}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NDU3NzY0OnYy", "diffSide": "RIGHT", "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryITTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxMzozMDoxOFrOGrl-fg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQwNjoyNzo0NFrOGr_EVQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2NDE1OA==", "bodyText": "Not sure if we have to do this - stop from Testcontainers is actually more of a kill command, so it may also already be cleaning up the volumes, though we'd have to verify that.", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448364158", "createdAt": "2020-07-01T13:30:18Z", "author": {"login": "npepinpe"}, "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryITTest.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.it.health;\n+\n+import static org.assertj.core.api.Assertions.assertThatCode;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+import static org.awaitility.Awaitility.await;\n+\n+import com.github.dockerjava.api.model.Bind;\n+import com.github.dockerjava.api.model.Volume;\n+import io.zeebe.client.ZeebeClient;\n+import io.zeebe.containers.ZeebeBrokerContainer;\n+import java.time.Duration;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.elasticsearch.client.RestClient;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.testcontainers.containers.Network;\n+import org.testcontainers.elasticsearch.ElasticsearchContainer;\n+\n+public class DiskSpaceRecoveryITTest {\n+  static ZeebeBrokerContainer zeebeBroker;\n+  private static final Logger LOG = LoggerFactory.getLogger(\"TEST\");\n+  private static final String VOLUME_NAME = \"tmpdata1\";\n+  private static String containerIPAddress;\n+  private static Integer apiPort;\n+  private static ElasticsearchContainer elastic;\n+  private ZeebeClient client;\n+\n+  @BeforeClass\n+  public static void setUpClass() {\n+    final var elasticHostInternal = \"http://elastic:9200\";\n+    zeebeBroker = createZeebe(elasticHostInternal);\n+    final var network = zeebeBroker.getNetwork();\n+    elastic = createElastic(network);\n+    zeebeBroker.start();\n+\n+    apiPort = zeebeBroker.getMappedPort(26500);\n+    containerIPAddress = zeebeBroker.getContainerIpAddress();\n+  }\n+\n+  private static ZeebeBrokerContainer createZeebe(final String elasticHost) {\n+    zeebeBroker =\n+        new ZeebeBrokerContainer(\"current-test\")\n+            .withEnv(\n+                \"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_CLASSNAME\",\n+                \"io.zeebe.exporter.ElasticsearchExporter\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_URL\", elasticHost)\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_DELAY\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_SIZE\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_SNAPSHOTPERIOD\", \"1m\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_LOGSEGMENTSIZE\", \"4MB\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_DISKUSAGECOMMANDWATERMARK\", \"0.5\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_LOGINDEXDENSITY\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_INDEX_MESSAGE\", \"true\");\n+\n+    zeebeBroker\n+        .getDockerClient()\n+        .createVolumeCmd()\n+        .withDriver(\"local\")\n+        .withDriverOpts(Map.of(\"type\", \"tmpfs\", \"device\", \"tmpfs\", \"o\", \"size=32m\"))\n+        .withName(VOLUME_NAME)\n+        .exec();\n+    final Volume newVolume = new Volume(\"/usr/local/zeebe/data\");\n+    zeebeBroker.withCreateContainerCmdModifier(\n+        cmd ->\n+            cmd.withHostConfig(cmd.getHostConfig().withBinds(new Bind(VOLUME_NAME, newVolume)))\n+                .withName(\"zeebe-test\"));\n+\n+    return zeebeBroker;\n+  }\n+\n+  private static ElasticsearchContainer createElastic(final Network network) {\n+    final ElasticsearchContainer container =\n+        new ElasticsearchContainer(\n+            \"docker.elastic.co/elasticsearch/elasticsearch:\"\n+                + RestClient.class.getPackage().getImplementationVersion());\n+\n+    container.withNetwork(network).withEnv(\"discovery.type\", \"single-node\");\n+    container.withCreateContainerCmdModifier(cmd -> cmd.withName(\"elastic\"));\n+    return container;\n+  }\n+\n+  @AfterClass\n+  public static void tearDownClass() {\n+    LoggerFactory.getLogger(\"Test\").info(zeebeBroker.getLogs());\n+    zeebeBroker.stop();\n+    zeebeBroker.getDockerClient().removeVolumeCmd(VOLUME_NAME).exec();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ef515fed93020dc76d7b339d99e86b0fc50d4514"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc3NTI1Mw==", "bodyText": "Volume should be closed explicitly. I just verified it.", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448775253", "createdAt": "2020-07-02T06:27:44Z", "author": {"login": "deepthidevaki"}, "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryITTest.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.it.health;\n+\n+import static org.assertj.core.api.Assertions.assertThatCode;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+import static org.awaitility.Awaitility.await;\n+\n+import com.github.dockerjava.api.model.Bind;\n+import com.github.dockerjava.api.model.Volume;\n+import io.zeebe.client.ZeebeClient;\n+import io.zeebe.containers.ZeebeBrokerContainer;\n+import java.time.Duration;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.elasticsearch.client.RestClient;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.testcontainers.containers.Network;\n+import org.testcontainers.elasticsearch.ElasticsearchContainer;\n+\n+public class DiskSpaceRecoveryITTest {\n+  static ZeebeBrokerContainer zeebeBroker;\n+  private static final Logger LOG = LoggerFactory.getLogger(\"TEST\");\n+  private static final String VOLUME_NAME = \"tmpdata1\";\n+  private static String containerIPAddress;\n+  private static Integer apiPort;\n+  private static ElasticsearchContainer elastic;\n+  private ZeebeClient client;\n+\n+  @BeforeClass\n+  public static void setUpClass() {\n+    final var elasticHostInternal = \"http://elastic:9200\";\n+    zeebeBroker = createZeebe(elasticHostInternal);\n+    final var network = zeebeBroker.getNetwork();\n+    elastic = createElastic(network);\n+    zeebeBroker.start();\n+\n+    apiPort = zeebeBroker.getMappedPort(26500);\n+    containerIPAddress = zeebeBroker.getContainerIpAddress();\n+  }\n+\n+  private static ZeebeBrokerContainer createZeebe(final String elasticHost) {\n+    zeebeBroker =\n+        new ZeebeBrokerContainer(\"current-test\")\n+            .withEnv(\n+                \"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_CLASSNAME\",\n+                \"io.zeebe.exporter.ElasticsearchExporter\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_URL\", elasticHost)\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_DELAY\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_SIZE\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_SNAPSHOTPERIOD\", \"1m\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_LOGSEGMENTSIZE\", \"4MB\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_DISKUSAGECOMMANDWATERMARK\", \"0.5\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_LOGINDEXDENSITY\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_INDEX_MESSAGE\", \"true\");\n+\n+    zeebeBroker\n+        .getDockerClient()\n+        .createVolumeCmd()\n+        .withDriver(\"local\")\n+        .withDriverOpts(Map.of(\"type\", \"tmpfs\", \"device\", \"tmpfs\", \"o\", \"size=32m\"))\n+        .withName(VOLUME_NAME)\n+        .exec();\n+    final Volume newVolume = new Volume(\"/usr/local/zeebe/data\");\n+    zeebeBroker.withCreateContainerCmdModifier(\n+        cmd ->\n+            cmd.withHostConfig(cmd.getHostConfig().withBinds(new Bind(VOLUME_NAME, newVolume)))\n+                .withName(\"zeebe-test\"));\n+\n+    return zeebeBroker;\n+  }\n+\n+  private static ElasticsearchContainer createElastic(final Network network) {\n+    final ElasticsearchContainer container =\n+        new ElasticsearchContainer(\n+            \"docker.elastic.co/elasticsearch/elasticsearch:\"\n+                + RestClient.class.getPackage().getImplementationVersion());\n+\n+    container.withNetwork(network).withEnv(\"discovery.type\", \"single-node\");\n+    container.withCreateContainerCmdModifier(cmd -> cmd.withName(\"elastic\"));\n+    return container;\n+  }\n+\n+  @AfterClass\n+  public static void tearDownClass() {\n+    LoggerFactory.getLogger(\"Test\").info(zeebeBroker.getLogs());\n+    zeebeBroker.stop();\n+    zeebeBroker.getDockerClient().removeVolumeCmd(VOLUME_NAME).exec();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2NDE1OA=="}, "originalCommit": {"oid": "ef515fed93020dc76d7b339d99e86b0fc50d4514"}, "originalPosition": 97}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NDU4MTQ5OnYy", "diffSide": "RIGHT", "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryITTest.java", "isResolved": true, "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxMzozMToxN1rOGrmA_Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QxMjo1Nzo0M1rOGt9S7A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2NDc5Nw==", "bodyText": "I'm not a fan of doesNotThrowAnyException - can't we assert that the message was published in some way?", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448364797", "createdAt": "2020-07-01T13:31:17Z", "author": {"login": "npepinpe"}, "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryITTest.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.it.health;\n+\n+import static org.assertj.core.api.Assertions.assertThatCode;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+import static org.awaitility.Awaitility.await;\n+\n+import com.github.dockerjava.api.model.Bind;\n+import com.github.dockerjava.api.model.Volume;\n+import io.zeebe.client.ZeebeClient;\n+import io.zeebe.containers.ZeebeBrokerContainer;\n+import java.time.Duration;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.elasticsearch.client.RestClient;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.testcontainers.containers.Network;\n+import org.testcontainers.elasticsearch.ElasticsearchContainer;\n+\n+public class DiskSpaceRecoveryITTest {\n+  static ZeebeBrokerContainer zeebeBroker;\n+  private static final Logger LOG = LoggerFactory.getLogger(\"TEST\");\n+  private static final String VOLUME_NAME = \"tmpdata1\";\n+  private static String containerIPAddress;\n+  private static Integer apiPort;\n+  private static ElasticsearchContainer elastic;\n+  private ZeebeClient client;\n+\n+  @BeforeClass\n+  public static void setUpClass() {\n+    final var elasticHostInternal = \"http://elastic:9200\";\n+    zeebeBroker = createZeebe(elasticHostInternal);\n+    final var network = zeebeBroker.getNetwork();\n+    elastic = createElastic(network);\n+    zeebeBroker.start();\n+\n+    apiPort = zeebeBroker.getMappedPort(26500);\n+    containerIPAddress = zeebeBroker.getContainerIpAddress();\n+  }\n+\n+  private static ZeebeBrokerContainer createZeebe(final String elasticHost) {\n+    zeebeBroker =\n+        new ZeebeBrokerContainer(\"current-test\")\n+            .withEnv(\n+                \"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_CLASSNAME\",\n+                \"io.zeebe.exporter.ElasticsearchExporter\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_URL\", elasticHost)\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_DELAY\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_SIZE\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_SNAPSHOTPERIOD\", \"1m\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_LOGSEGMENTSIZE\", \"4MB\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_DISKUSAGECOMMANDWATERMARK\", \"0.5\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_LOGINDEXDENSITY\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_INDEX_MESSAGE\", \"true\");\n+\n+    zeebeBroker\n+        .getDockerClient()\n+        .createVolumeCmd()\n+        .withDriver(\"local\")\n+        .withDriverOpts(Map.of(\"type\", \"tmpfs\", \"device\", \"tmpfs\", \"o\", \"size=32m\"))\n+        .withName(VOLUME_NAME)\n+        .exec();\n+    final Volume newVolume = new Volume(\"/usr/local/zeebe/data\");\n+    zeebeBroker.withCreateContainerCmdModifier(\n+        cmd ->\n+            cmd.withHostConfig(cmd.getHostConfig().withBinds(new Bind(VOLUME_NAME, newVolume)))\n+                .withName(\"zeebe-test\"));\n+\n+    return zeebeBroker;\n+  }\n+\n+  private static ElasticsearchContainer createElastic(final Network network) {\n+    final ElasticsearchContainer container =\n+        new ElasticsearchContainer(\n+            \"docker.elastic.co/elasticsearch/elasticsearch:\"\n+                + RestClient.class.getPackage().getImplementationVersion());\n+\n+    container.withNetwork(network).withEnv(\"discovery.type\", \"single-node\");\n+    container.withCreateContainerCmdModifier(cmd -> cmd.withName(\"elastic\"));\n+    return container;\n+  }\n+\n+  @AfterClass\n+  public static void tearDownClass() {\n+    LoggerFactory.getLogger(\"Test\").info(zeebeBroker.getLogs());\n+    zeebeBroker.stop();\n+    zeebeBroker.getDockerClient().removeVolumeCmd(VOLUME_NAME).exec();\n+    elastic.stop();\n+  }\n+\n+  @Test\n+  public void shouldRecoverAfterOutOfDiskSpaceWhenExporterStarts() {\n+    // given\n+    client =\n+        ZeebeClient.newClientBuilder()\n+            .brokerContactPoint(containerIPAddress + \":\" + apiPort)\n+            .usePlaintext()\n+            .build();\n+\n+    // when\n+    LOG.info(\"Wait until broker is out of disk space\");\n+    await()\n+        .timeout(Duration.ofMinutes(3))\n+        .pollInterval(1, TimeUnit.MICROSECONDS)\n+        .untilAsserted(\n+            () ->\n+                assertThatThrownBy(this::publishMessage)\n+                    .hasRootCauseMessage(\n+                        \"RESOURCE_EXHAUSTED: Cannot accept requests for partition 1. Broker is out of disk space\"));\n+\n+    elastic.start();\n+\n+    // then\n+    await()\n+        .pollInterval(Duration.ofSeconds(10))\n+        .timeout(Duration.ofMinutes(5))\n+        .untilAsserted(() -> assertThatCode(this::publishMessage).doesNotThrowAnyException());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ef515fed93020dc76d7b339d99e86b0fc50d4514"}, "originalPosition": 127}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM3NDAxMg==", "bodyText": "Btw I thought we fixed that publish message doesnt return anything? Shouldn't it return a response now?", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448374012", "createdAt": "2020-07-01T13:45:35Z", "author": {"login": "Zelldon"}, "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryITTest.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.it.health;\n+\n+import static org.assertj.core.api.Assertions.assertThatCode;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+import static org.awaitility.Awaitility.await;\n+\n+import com.github.dockerjava.api.model.Bind;\n+import com.github.dockerjava.api.model.Volume;\n+import io.zeebe.client.ZeebeClient;\n+import io.zeebe.containers.ZeebeBrokerContainer;\n+import java.time.Duration;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.elasticsearch.client.RestClient;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.testcontainers.containers.Network;\n+import org.testcontainers.elasticsearch.ElasticsearchContainer;\n+\n+public class DiskSpaceRecoveryITTest {\n+  static ZeebeBrokerContainer zeebeBroker;\n+  private static final Logger LOG = LoggerFactory.getLogger(\"TEST\");\n+  private static final String VOLUME_NAME = \"tmpdata1\";\n+  private static String containerIPAddress;\n+  private static Integer apiPort;\n+  private static ElasticsearchContainer elastic;\n+  private ZeebeClient client;\n+\n+  @BeforeClass\n+  public static void setUpClass() {\n+    final var elasticHostInternal = \"http://elastic:9200\";\n+    zeebeBroker = createZeebe(elasticHostInternal);\n+    final var network = zeebeBroker.getNetwork();\n+    elastic = createElastic(network);\n+    zeebeBroker.start();\n+\n+    apiPort = zeebeBroker.getMappedPort(26500);\n+    containerIPAddress = zeebeBroker.getContainerIpAddress();\n+  }\n+\n+  private static ZeebeBrokerContainer createZeebe(final String elasticHost) {\n+    zeebeBroker =\n+        new ZeebeBrokerContainer(\"current-test\")\n+            .withEnv(\n+                \"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_CLASSNAME\",\n+                \"io.zeebe.exporter.ElasticsearchExporter\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_URL\", elasticHost)\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_DELAY\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_SIZE\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_SNAPSHOTPERIOD\", \"1m\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_LOGSEGMENTSIZE\", \"4MB\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_DISKUSAGECOMMANDWATERMARK\", \"0.5\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_LOGINDEXDENSITY\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_INDEX_MESSAGE\", \"true\");\n+\n+    zeebeBroker\n+        .getDockerClient()\n+        .createVolumeCmd()\n+        .withDriver(\"local\")\n+        .withDriverOpts(Map.of(\"type\", \"tmpfs\", \"device\", \"tmpfs\", \"o\", \"size=32m\"))\n+        .withName(VOLUME_NAME)\n+        .exec();\n+    final Volume newVolume = new Volume(\"/usr/local/zeebe/data\");\n+    zeebeBroker.withCreateContainerCmdModifier(\n+        cmd ->\n+            cmd.withHostConfig(cmd.getHostConfig().withBinds(new Bind(VOLUME_NAME, newVolume)))\n+                .withName(\"zeebe-test\"));\n+\n+    return zeebeBroker;\n+  }\n+\n+  private static ElasticsearchContainer createElastic(final Network network) {\n+    final ElasticsearchContainer container =\n+        new ElasticsearchContainer(\n+            \"docker.elastic.co/elasticsearch/elasticsearch:\"\n+                + RestClient.class.getPackage().getImplementationVersion());\n+\n+    container.withNetwork(network).withEnv(\"discovery.type\", \"single-node\");\n+    container.withCreateContainerCmdModifier(cmd -> cmd.withName(\"elastic\"));\n+    return container;\n+  }\n+\n+  @AfterClass\n+  public static void tearDownClass() {\n+    LoggerFactory.getLogger(\"Test\").info(zeebeBroker.getLogs());\n+    zeebeBroker.stop();\n+    zeebeBroker.getDockerClient().removeVolumeCmd(VOLUME_NAME).exec();\n+    elastic.stop();\n+  }\n+\n+  @Test\n+  public void shouldRecoverAfterOutOfDiskSpaceWhenExporterStarts() {\n+    // given\n+    client =\n+        ZeebeClient.newClientBuilder()\n+            .brokerContactPoint(containerIPAddress + \":\" + apiPort)\n+            .usePlaintext()\n+            .build();\n+\n+    // when\n+    LOG.info(\"Wait until broker is out of disk space\");\n+    await()\n+        .timeout(Duration.ofMinutes(3))\n+        .pollInterval(1, TimeUnit.MICROSECONDS)\n+        .untilAsserted(\n+            () ->\n+                assertThatThrownBy(this::publishMessage)\n+                    .hasRootCauseMessage(\n+                        \"RESOURCE_EXHAUSTED: Cannot accept requests for partition 1. Broker is out of disk space\"));\n+\n+    elastic.start();\n+\n+    // then\n+    await()\n+        .pollInterval(Duration.ofSeconds(10))\n+        .timeout(Duration.ofMinutes(5))\n+        .untilAsserted(() -> assertThatCode(this::publishMessage).doesNotThrowAnyException());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2NDc5Nw=="}, "originalCommit": {"oid": "ef515fed93020dc76d7b339d99e86b0fc50d4514"}, "originalPosition": 127}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM3NTQ2MA==", "bodyText": "Was added with #3820", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448375460", "createdAt": "2020-07-01T13:47:52Z", "author": {"login": "Zelldon"}, "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryITTest.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.it.health;\n+\n+import static org.assertj.core.api.Assertions.assertThatCode;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+import static org.awaitility.Awaitility.await;\n+\n+import com.github.dockerjava.api.model.Bind;\n+import com.github.dockerjava.api.model.Volume;\n+import io.zeebe.client.ZeebeClient;\n+import io.zeebe.containers.ZeebeBrokerContainer;\n+import java.time.Duration;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.elasticsearch.client.RestClient;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.testcontainers.containers.Network;\n+import org.testcontainers.elasticsearch.ElasticsearchContainer;\n+\n+public class DiskSpaceRecoveryITTest {\n+  static ZeebeBrokerContainer zeebeBroker;\n+  private static final Logger LOG = LoggerFactory.getLogger(\"TEST\");\n+  private static final String VOLUME_NAME = \"tmpdata1\";\n+  private static String containerIPAddress;\n+  private static Integer apiPort;\n+  private static ElasticsearchContainer elastic;\n+  private ZeebeClient client;\n+\n+  @BeforeClass\n+  public static void setUpClass() {\n+    final var elasticHostInternal = \"http://elastic:9200\";\n+    zeebeBroker = createZeebe(elasticHostInternal);\n+    final var network = zeebeBroker.getNetwork();\n+    elastic = createElastic(network);\n+    zeebeBroker.start();\n+\n+    apiPort = zeebeBroker.getMappedPort(26500);\n+    containerIPAddress = zeebeBroker.getContainerIpAddress();\n+  }\n+\n+  private static ZeebeBrokerContainer createZeebe(final String elasticHost) {\n+    zeebeBroker =\n+        new ZeebeBrokerContainer(\"current-test\")\n+            .withEnv(\n+                \"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_CLASSNAME\",\n+                \"io.zeebe.exporter.ElasticsearchExporter\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_URL\", elasticHost)\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_DELAY\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_SIZE\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_SNAPSHOTPERIOD\", \"1m\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_LOGSEGMENTSIZE\", \"4MB\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_DISKUSAGECOMMANDWATERMARK\", \"0.5\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_LOGINDEXDENSITY\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_INDEX_MESSAGE\", \"true\");\n+\n+    zeebeBroker\n+        .getDockerClient()\n+        .createVolumeCmd()\n+        .withDriver(\"local\")\n+        .withDriverOpts(Map.of(\"type\", \"tmpfs\", \"device\", \"tmpfs\", \"o\", \"size=32m\"))\n+        .withName(VOLUME_NAME)\n+        .exec();\n+    final Volume newVolume = new Volume(\"/usr/local/zeebe/data\");\n+    zeebeBroker.withCreateContainerCmdModifier(\n+        cmd ->\n+            cmd.withHostConfig(cmd.getHostConfig().withBinds(new Bind(VOLUME_NAME, newVolume)))\n+                .withName(\"zeebe-test\"));\n+\n+    return zeebeBroker;\n+  }\n+\n+  private static ElasticsearchContainer createElastic(final Network network) {\n+    final ElasticsearchContainer container =\n+        new ElasticsearchContainer(\n+            \"docker.elastic.co/elasticsearch/elasticsearch:\"\n+                + RestClient.class.getPackage().getImplementationVersion());\n+\n+    container.withNetwork(network).withEnv(\"discovery.type\", \"single-node\");\n+    container.withCreateContainerCmdModifier(cmd -> cmd.withName(\"elastic\"));\n+    return container;\n+  }\n+\n+  @AfterClass\n+  public static void tearDownClass() {\n+    LoggerFactory.getLogger(\"Test\").info(zeebeBroker.getLogs());\n+    zeebeBroker.stop();\n+    zeebeBroker.getDockerClient().removeVolumeCmd(VOLUME_NAME).exec();\n+    elastic.stop();\n+  }\n+\n+  @Test\n+  public void shouldRecoverAfterOutOfDiskSpaceWhenExporterStarts() {\n+    // given\n+    client =\n+        ZeebeClient.newClientBuilder()\n+            .brokerContactPoint(containerIPAddress + \":\" + apiPort)\n+            .usePlaintext()\n+            .build();\n+\n+    // when\n+    LOG.info(\"Wait until broker is out of disk space\");\n+    await()\n+        .timeout(Duration.ofMinutes(3))\n+        .pollInterval(1, TimeUnit.MICROSECONDS)\n+        .untilAsserted(\n+            () ->\n+                assertThatThrownBy(this::publishMessage)\n+                    .hasRootCauseMessage(\n+                        \"RESOURCE_EXHAUSTED: Cannot accept requests for partition 1. Broker is out of disk space\"));\n+\n+    elastic.start();\n+\n+    // then\n+    await()\n+        .pollInterval(Duration.ofSeconds(10))\n+        .timeout(Duration.ofMinutes(5))\n+        .untilAsserted(() -> assertThatCode(this::publishMessage).doesNotThrowAnyException());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2NDc5Nw=="}, "originalCommit": {"oid": "ef515fed93020dc76d7b339d99e86b0fc50d4514"}, "originalPosition": 127}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc3MDYzOQ==", "bodyText": "It returns a type 'PublishMessageResponse'. But it is still empty.", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448770639", "createdAt": "2020-07-02T06:14:57Z", "author": {"login": "deepthidevaki"}, "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryITTest.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.it.health;\n+\n+import static org.assertj.core.api.Assertions.assertThatCode;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+import static org.awaitility.Awaitility.await;\n+\n+import com.github.dockerjava.api.model.Bind;\n+import com.github.dockerjava.api.model.Volume;\n+import io.zeebe.client.ZeebeClient;\n+import io.zeebe.containers.ZeebeBrokerContainer;\n+import java.time.Duration;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.elasticsearch.client.RestClient;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.testcontainers.containers.Network;\n+import org.testcontainers.elasticsearch.ElasticsearchContainer;\n+\n+public class DiskSpaceRecoveryITTest {\n+  static ZeebeBrokerContainer zeebeBroker;\n+  private static final Logger LOG = LoggerFactory.getLogger(\"TEST\");\n+  private static final String VOLUME_NAME = \"tmpdata1\";\n+  private static String containerIPAddress;\n+  private static Integer apiPort;\n+  private static ElasticsearchContainer elastic;\n+  private ZeebeClient client;\n+\n+  @BeforeClass\n+  public static void setUpClass() {\n+    final var elasticHostInternal = \"http://elastic:9200\";\n+    zeebeBroker = createZeebe(elasticHostInternal);\n+    final var network = zeebeBroker.getNetwork();\n+    elastic = createElastic(network);\n+    zeebeBroker.start();\n+\n+    apiPort = zeebeBroker.getMappedPort(26500);\n+    containerIPAddress = zeebeBroker.getContainerIpAddress();\n+  }\n+\n+  private static ZeebeBrokerContainer createZeebe(final String elasticHost) {\n+    zeebeBroker =\n+        new ZeebeBrokerContainer(\"current-test\")\n+            .withEnv(\n+                \"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_CLASSNAME\",\n+                \"io.zeebe.exporter.ElasticsearchExporter\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_URL\", elasticHost)\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_DELAY\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_SIZE\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_SNAPSHOTPERIOD\", \"1m\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_LOGSEGMENTSIZE\", \"4MB\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_DISKUSAGECOMMANDWATERMARK\", \"0.5\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_LOGINDEXDENSITY\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_INDEX_MESSAGE\", \"true\");\n+\n+    zeebeBroker\n+        .getDockerClient()\n+        .createVolumeCmd()\n+        .withDriver(\"local\")\n+        .withDriverOpts(Map.of(\"type\", \"tmpfs\", \"device\", \"tmpfs\", \"o\", \"size=32m\"))\n+        .withName(VOLUME_NAME)\n+        .exec();\n+    final Volume newVolume = new Volume(\"/usr/local/zeebe/data\");\n+    zeebeBroker.withCreateContainerCmdModifier(\n+        cmd ->\n+            cmd.withHostConfig(cmd.getHostConfig().withBinds(new Bind(VOLUME_NAME, newVolume)))\n+                .withName(\"zeebe-test\"));\n+\n+    return zeebeBroker;\n+  }\n+\n+  private static ElasticsearchContainer createElastic(final Network network) {\n+    final ElasticsearchContainer container =\n+        new ElasticsearchContainer(\n+            \"docker.elastic.co/elasticsearch/elasticsearch:\"\n+                + RestClient.class.getPackage().getImplementationVersion());\n+\n+    container.withNetwork(network).withEnv(\"discovery.type\", \"single-node\");\n+    container.withCreateContainerCmdModifier(cmd -> cmd.withName(\"elastic\"));\n+    return container;\n+  }\n+\n+  @AfterClass\n+  public static void tearDownClass() {\n+    LoggerFactory.getLogger(\"Test\").info(zeebeBroker.getLogs());\n+    zeebeBroker.stop();\n+    zeebeBroker.getDockerClient().removeVolumeCmd(VOLUME_NAME).exec();\n+    elastic.stop();\n+  }\n+\n+  @Test\n+  public void shouldRecoverAfterOutOfDiskSpaceWhenExporterStarts() {\n+    // given\n+    client =\n+        ZeebeClient.newClientBuilder()\n+            .brokerContactPoint(containerIPAddress + \":\" + apiPort)\n+            .usePlaintext()\n+            .build();\n+\n+    // when\n+    LOG.info(\"Wait until broker is out of disk space\");\n+    await()\n+        .timeout(Duration.ofMinutes(3))\n+        .pollInterval(1, TimeUnit.MICROSECONDS)\n+        .untilAsserted(\n+            () ->\n+                assertThatThrownBy(this::publishMessage)\n+                    .hasRootCauseMessage(\n+                        \"RESOURCE_EXHAUSTED: Cannot accept requests for partition 1. Broker is out of disk space\"));\n+\n+    elastic.start();\n+\n+    // then\n+    await()\n+        .pollInterval(Duration.ofSeconds(10))\n+        .timeout(Duration.ofMinutes(5))\n+        .untilAsserted(() -> assertThatCode(this::publishMessage).doesNotThrowAnyException());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2NDc5Nw=="}, "originalCommit": {"oid": "ef515fed93020dc76d7b339d99e86b0fc50d4514"}, "originalPosition": 127}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkwOTM3Ng==", "bodyText": "Similar as how we return deployment keys, we should return message keys - helpful to correlate things with an exporter stream, for example. @Zelldon already opened an issue for it \ud83d\ude09 #4794\nThat said, you can still assert you get an non null PublishMessageResponse (or whatever it is) as a result, no? Wouldn't that always indicate success?", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448909376", "createdAt": "2020-07-02T10:36:22Z", "author": {"login": "npepinpe"}, "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryITTest.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.it.health;\n+\n+import static org.assertj.core.api.Assertions.assertThatCode;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+import static org.awaitility.Awaitility.await;\n+\n+import com.github.dockerjava.api.model.Bind;\n+import com.github.dockerjava.api.model.Volume;\n+import io.zeebe.client.ZeebeClient;\n+import io.zeebe.containers.ZeebeBrokerContainer;\n+import java.time.Duration;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.elasticsearch.client.RestClient;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.testcontainers.containers.Network;\n+import org.testcontainers.elasticsearch.ElasticsearchContainer;\n+\n+public class DiskSpaceRecoveryITTest {\n+  static ZeebeBrokerContainer zeebeBroker;\n+  private static final Logger LOG = LoggerFactory.getLogger(\"TEST\");\n+  private static final String VOLUME_NAME = \"tmpdata1\";\n+  private static String containerIPAddress;\n+  private static Integer apiPort;\n+  private static ElasticsearchContainer elastic;\n+  private ZeebeClient client;\n+\n+  @BeforeClass\n+  public static void setUpClass() {\n+    final var elasticHostInternal = \"http://elastic:9200\";\n+    zeebeBroker = createZeebe(elasticHostInternal);\n+    final var network = zeebeBroker.getNetwork();\n+    elastic = createElastic(network);\n+    zeebeBroker.start();\n+\n+    apiPort = zeebeBroker.getMappedPort(26500);\n+    containerIPAddress = zeebeBroker.getContainerIpAddress();\n+  }\n+\n+  private static ZeebeBrokerContainer createZeebe(final String elasticHost) {\n+    zeebeBroker =\n+        new ZeebeBrokerContainer(\"current-test\")\n+            .withEnv(\n+                \"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_CLASSNAME\",\n+                \"io.zeebe.exporter.ElasticsearchExporter\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_URL\", elasticHost)\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_DELAY\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_SIZE\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_SNAPSHOTPERIOD\", \"1m\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_LOGSEGMENTSIZE\", \"4MB\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_DISKUSAGECOMMANDWATERMARK\", \"0.5\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_LOGINDEXDENSITY\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_INDEX_MESSAGE\", \"true\");\n+\n+    zeebeBroker\n+        .getDockerClient()\n+        .createVolumeCmd()\n+        .withDriver(\"local\")\n+        .withDriverOpts(Map.of(\"type\", \"tmpfs\", \"device\", \"tmpfs\", \"o\", \"size=32m\"))\n+        .withName(VOLUME_NAME)\n+        .exec();\n+    final Volume newVolume = new Volume(\"/usr/local/zeebe/data\");\n+    zeebeBroker.withCreateContainerCmdModifier(\n+        cmd ->\n+            cmd.withHostConfig(cmd.getHostConfig().withBinds(new Bind(VOLUME_NAME, newVolume)))\n+                .withName(\"zeebe-test\"));\n+\n+    return zeebeBroker;\n+  }\n+\n+  private static ElasticsearchContainer createElastic(final Network network) {\n+    final ElasticsearchContainer container =\n+        new ElasticsearchContainer(\n+            \"docker.elastic.co/elasticsearch/elasticsearch:\"\n+                + RestClient.class.getPackage().getImplementationVersion());\n+\n+    container.withNetwork(network).withEnv(\"discovery.type\", \"single-node\");\n+    container.withCreateContainerCmdModifier(cmd -> cmd.withName(\"elastic\"));\n+    return container;\n+  }\n+\n+  @AfterClass\n+  public static void tearDownClass() {\n+    LoggerFactory.getLogger(\"Test\").info(zeebeBroker.getLogs());\n+    zeebeBroker.stop();\n+    zeebeBroker.getDockerClient().removeVolumeCmd(VOLUME_NAME).exec();\n+    elastic.stop();\n+  }\n+\n+  @Test\n+  public void shouldRecoverAfterOutOfDiskSpaceWhenExporterStarts() {\n+    // given\n+    client =\n+        ZeebeClient.newClientBuilder()\n+            .brokerContactPoint(containerIPAddress + \":\" + apiPort)\n+            .usePlaintext()\n+            .build();\n+\n+    // when\n+    LOG.info(\"Wait until broker is out of disk space\");\n+    await()\n+        .timeout(Duration.ofMinutes(3))\n+        .pollInterval(1, TimeUnit.MICROSECONDS)\n+        .untilAsserted(\n+            () ->\n+                assertThatThrownBy(this::publishMessage)\n+                    .hasRootCauseMessage(\n+                        \"RESOURCE_EXHAUSTED: Cannot accept requests for partition 1. Broker is out of disk space\"));\n+\n+    elastic.start();\n+\n+    // then\n+    await()\n+        .pollInterval(Duration.ofSeconds(10))\n+        .timeout(Duration.ofMinutes(5))\n+        .untilAsserted(() -> assertThatCode(this::publishMessage).doesNotThrowAnyException());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2NDc5Nw=="}, "originalCommit": {"oid": "ef515fed93020dc76d7b339d99e86b0fc50d4514"}, "originalPosition": 127}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkyNzgzNA==", "bodyText": "assert(..).isNotNull() did not work.", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448927834", "createdAt": "2020-07-02T11:14:48Z", "author": {"login": "deepthidevaki"}, "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryITTest.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.it.health;\n+\n+import static org.assertj.core.api.Assertions.assertThatCode;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+import static org.awaitility.Awaitility.await;\n+\n+import com.github.dockerjava.api.model.Bind;\n+import com.github.dockerjava.api.model.Volume;\n+import io.zeebe.client.ZeebeClient;\n+import io.zeebe.containers.ZeebeBrokerContainer;\n+import java.time.Duration;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.elasticsearch.client.RestClient;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.testcontainers.containers.Network;\n+import org.testcontainers.elasticsearch.ElasticsearchContainer;\n+\n+public class DiskSpaceRecoveryITTest {\n+  static ZeebeBrokerContainer zeebeBroker;\n+  private static final Logger LOG = LoggerFactory.getLogger(\"TEST\");\n+  private static final String VOLUME_NAME = \"tmpdata1\";\n+  private static String containerIPAddress;\n+  private static Integer apiPort;\n+  private static ElasticsearchContainer elastic;\n+  private ZeebeClient client;\n+\n+  @BeforeClass\n+  public static void setUpClass() {\n+    final var elasticHostInternal = \"http://elastic:9200\";\n+    zeebeBroker = createZeebe(elasticHostInternal);\n+    final var network = zeebeBroker.getNetwork();\n+    elastic = createElastic(network);\n+    zeebeBroker.start();\n+\n+    apiPort = zeebeBroker.getMappedPort(26500);\n+    containerIPAddress = zeebeBroker.getContainerIpAddress();\n+  }\n+\n+  private static ZeebeBrokerContainer createZeebe(final String elasticHost) {\n+    zeebeBroker =\n+        new ZeebeBrokerContainer(\"current-test\")\n+            .withEnv(\n+                \"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_CLASSNAME\",\n+                \"io.zeebe.exporter.ElasticsearchExporter\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_URL\", elasticHost)\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_DELAY\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_SIZE\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_SNAPSHOTPERIOD\", \"1m\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_LOGSEGMENTSIZE\", \"4MB\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_DISKUSAGECOMMANDWATERMARK\", \"0.5\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_LOGINDEXDENSITY\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_INDEX_MESSAGE\", \"true\");\n+\n+    zeebeBroker\n+        .getDockerClient()\n+        .createVolumeCmd()\n+        .withDriver(\"local\")\n+        .withDriverOpts(Map.of(\"type\", \"tmpfs\", \"device\", \"tmpfs\", \"o\", \"size=32m\"))\n+        .withName(VOLUME_NAME)\n+        .exec();\n+    final Volume newVolume = new Volume(\"/usr/local/zeebe/data\");\n+    zeebeBroker.withCreateContainerCmdModifier(\n+        cmd ->\n+            cmd.withHostConfig(cmd.getHostConfig().withBinds(new Bind(VOLUME_NAME, newVolume)))\n+                .withName(\"zeebe-test\"));\n+\n+    return zeebeBroker;\n+  }\n+\n+  private static ElasticsearchContainer createElastic(final Network network) {\n+    final ElasticsearchContainer container =\n+        new ElasticsearchContainer(\n+            \"docker.elastic.co/elasticsearch/elasticsearch:\"\n+                + RestClient.class.getPackage().getImplementationVersion());\n+\n+    container.withNetwork(network).withEnv(\"discovery.type\", \"single-node\");\n+    container.withCreateContainerCmdModifier(cmd -> cmd.withName(\"elastic\"));\n+    return container;\n+  }\n+\n+  @AfterClass\n+  public static void tearDownClass() {\n+    LoggerFactory.getLogger(\"Test\").info(zeebeBroker.getLogs());\n+    zeebeBroker.stop();\n+    zeebeBroker.getDockerClient().removeVolumeCmd(VOLUME_NAME).exec();\n+    elastic.stop();\n+  }\n+\n+  @Test\n+  public void shouldRecoverAfterOutOfDiskSpaceWhenExporterStarts() {\n+    // given\n+    client =\n+        ZeebeClient.newClientBuilder()\n+            .brokerContactPoint(containerIPAddress + \":\" + apiPort)\n+            .usePlaintext()\n+            .build();\n+\n+    // when\n+    LOG.info(\"Wait until broker is out of disk space\");\n+    await()\n+        .timeout(Duration.ofMinutes(3))\n+        .pollInterval(1, TimeUnit.MICROSECONDS)\n+        .untilAsserted(\n+            () ->\n+                assertThatThrownBy(this::publishMessage)\n+                    .hasRootCauseMessage(\n+                        \"RESOURCE_EXHAUSTED: Cannot accept requests for partition 1. Broker is out of disk space\"));\n+\n+    elastic.start();\n+\n+    // then\n+    await()\n+        .pollInterval(Duration.ofSeconds(10))\n+        .timeout(Duration.ofMinutes(5))\n+        .untilAsserted(() -> assertThatCode(this::publishMessage).doesNotThrowAnyException());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2NDc5Nw=="}, "originalCommit": {"oid": "ef515fed93020dc76d7b339d99e86b0fc50d4514"}, "originalPosition": 127}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDg0MzM3Mg==", "bodyText": "Hm, curious, wasn't expecting that. Well I'm fine leaving it like this, but I would propose we try to avoid it in general.", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r450843372", "createdAt": "2020-07-07T12:57:43Z", "author": {"login": "npepinpe"}, "path": "qa/integration-tests/src/test/java/io/zeebe/broker/it/health/DiskSpaceRecoveryITTest.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Copyright Camunda Services GmbH and/or licensed to Camunda Services GmbH under\n+ * one or more contributor license agreements. See the NOTICE file distributed\n+ * with this work for additional information regarding copyright ownership.\n+ * Licensed under the Zeebe Community License 1.0. You may not use this file\n+ * except in compliance with the Zeebe Community License 1.0.\n+ */\n+package io.zeebe.broker.it.health;\n+\n+import static org.assertj.core.api.Assertions.assertThatCode;\n+import static org.assertj.core.api.Assertions.assertThatThrownBy;\n+import static org.awaitility.Awaitility.await;\n+\n+import com.github.dockerjava.api.model.Bind;\n+import com.github.dockerjava.api.model.Volume;\n+import io.zeebe.client.ZeebeClient;\n+import io.zeebe.containers.ZeebeBrokerContainer;\n+import java.time.Duration;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.elasticsearch.client.RestClient;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.testcontainers.containers.Network;\n+import org.testcontainers.elasticsearch.ElasticsearchContainer;\n+\n+public class DiskSpaceRecoveryITTest {\n+  static ZeebeBrokerContainer zeebeBroker;\n+  private static final Logger LOG = LoggerFactory.getLogger(\"TEST\");\n+  private static final String VOLUME_NAME = \"tmpdata1\";\n+  private static String containerIPAddress;\n+  private static Integer apiPort;\n+  private static ElasticsearchContainer elastic;\n+  private ZeebeClient client;\n+\n+  @BeforeClass\n+  public static void setUpClass() {\n+    final var elasticHostInternal = \"http://elastic:9200\";\n+    zeebeBroker = createZeebe(elasticHostInternal);\n+    final var network = zeebeBroker.getNetwork();\n+    elastic = createElastic(network);\n+    zeebeBroker.start();\n+\n+    apiPort = zeebeBroker.getMappedPort(26500);\n+    containerIPAddress = zeebeBroker.getContainerIpAddress();\n+  }\n+\n+  private static ZeebeBrokerContainer createZeebe(final String elasticHost) {\n+    zeebeBroker =\n+        new ZeebeBrokerContainer(\"current-test\")\n+            .withEnv(\n+                \"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_CLASSNAME\",\n+                \"io.zeebe.exporter.ElasticsearchExporter\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_URL\", elasticHost)\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_DELAY\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_SIZE\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_SNAPSHOTPERIOD\", \"1m\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_LOGSEGMENTSIZE\", \"4MB\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_DISKUSAGECOMMANDWATERMARK\", \"0.5\")\n+            .withEnv(\"ZEEBE_BROKER_DATA_LOGINDEXDENSITY\", \"1\")\n+            .withEnv(\"ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_INDEX_MESSAGE\", \"true\");\n+\n+    zeebeBroker\n+        .getDockerClient()\n+        .createVolumeCmd()\n+        .withDriver(\"local\")\n+        .withDriverOpts(Map.of(\"type\", \"tmpfs\", \"device\", \"tmpfs\", \"o\", \"size=32m\"))\n+        .withName(VOLUME_NAME)\n+        .exec();\n+    final Volume newVolume = new Volume(\"/usr/local/zeebe/data\");\n+    zeebeBroker.withCreateContainerCmdModifier(\n+        cmd ->\n+            cmd.withHostConfig(cmd.getHostConfig().withBinds(new Bind(VOLUME_NAME, newVolume)))\n+                .withName(\"zeebe-test\"));\n+\n+    return zeebeBroker;\n+  }\n+\n+  private static ElasticsearchContainer createElastic(final Network network) {\n+    final ElasticsearchContainer container =\n+        new ElasticsearchContainer(\n+            \"docker.elastic.co/elasticsearch/elasticsearch:\"\n+                + RestClient.class.getPackage().getImplementationVersion());\n+\n+    container.withNetwork(network).withEnv(\"discovery.type\", \"single-node\");\n+    container.withCreateContainerCmdModifier(cmd -> cmd.withName(\"elastic\"));\n+    return container;\n+  }\n+\n+  @AfterClass\n+  public static void tearDownClass() {\n+    LoggerFactory.getLogger(\"Test\").info(zeebeBroker.getLogs());\n+    zeebeBroker.stop();\n+    zeebeBroker.getDockerClient().removeVolumeCmd(VOLUME_NAME).exec();\n+    elastic.stop();\n+  }\n+\n+  @Test\n+  public void shouldRecoverAfterOutOfDiskSpaceWhenExporterStarts() {\n+    // given\n+    client =\n+        ZeebeClient.newClientBuilder()\n+            .brokerContactPoint(containerIPAddress + \":\" + apiPort)\n+            .usePlaintext()\n+            .build();\n+\n+    // when\n+    LOG.info(\"Wait until broker is out of disk space\");\n+    await()\n+        .timeout(Duration.ofMinutes(3))\n+        .pollInterval(1, TimeUnit.MICROSECONDS)\n+        .untilAsserted(\n+            () ->\n+                assertThatThrownBy(this::publishMessage)\n+                    .hasRootCauseMessage(\n+                        \"RESOURCE_EXHAUSTED: Cannot accept requests for partition 1. Broker is out of disk space\"));\n+\n+    elastic.start();\n+\n+    // then\n+    await()\n+        .pollInterval(Duration.ofSeconds(10))\n+        .timeout(Duration.ofMinutes(5))\n+        .untilAsserted(() -> assertThatCode(this::publishMessage).doesNotThrowAnyException());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM2NDc5Nw=="}, "originalCommit": {"oid": "ef515fed93020dc76d7b339d99e86b0fc50d4514"}, "originalPosition": 127}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NDY2MjI1OnYy", "diffSide": "RIGHT", "path": "dist/src/main/config/broker.standalone.yaml.template", "isResolved": false, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxMzo1MTo0N1rOGrm0fg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QxMjo1OTowM1rOGt9WKA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM3Nzk4Mg==", "bodyText": "Replication will not be paused right? It is more that the follower will stop accepting appends.", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448377982", "createdAt": "2020-07-01T13:51:47Z", "author": {"login": "Zelldon"}, "path": "dist/src/main/config/broker.standalone.yaml.template", "diffHunk": "@@ -187,6 +187,23 @@\n       # This setting can also be overridden using the environment variable ZEEBE_BROKER_DATA_SNAPSHOTPERIOD.\n       # snapshotPeriod: 15m\n \n+      # When the disk usage is above this value all client commands will be rejected.\n+      # The value is specified as a percentage of the total disk space.\n+      # The value should be in the range (0, 1).\n+      # This setting can also be overridden using the environment variable ZEEBE_BROKER_DATA_DISKUSAGECOMMANDWATERMARK\n+      # diskUsageCommandWatermark = 0.8\n+\n+      # When the disk usage is above this value replication will be paused.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ef515fed93020dc76d7b339d99e86b0fc50d4514"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODc2ODU3Mg==", "bodyText": "This broker will not replicate events from others. So it is like pausing replication, right?", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448768572", "createdAt": "2020-07-02T06:09:00Z", "author": {"login": "deepthidevaki"}, "path": "dist/src/main/config/broker.standalone.yaml.template", "diffHunk": "@@ -187,6 +187,23 @@\n       # This setting can also be overridden using the environment variable ZEEBE_BROKER_DATA_SNAPSHOTPERIOD.\n       # snapshotPeriod: 15m\n \n+      # When the disk usage is above this value all client commands will be rejected.\n+      # The value is specified as a percentage of the total disk space.\n+      # The value should be in the range (0, 1).\n+      # This setting can also be overridden using the environment variable ZEEBE_BROKER_DATA_DISKUSAGECOMMANDWATERMARK\n+      # diskUsageCommandWatermark = 0.8\n+\n+      # When the disk usage is above this value replication will be paused.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM3Nzk4Mg=="}, "originalCommit": {"oid": "ef515fed93020dc76d7b339d99e86b0fc50d4514"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTk5MjU5NQ==", "bodyText": "The thing is it will still replicate to the other follower when the other one has no full disk. For more me when we say stop replication I think the leader will no longer send, but it is just that the follower will stop accepting, which is different.", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r449992595", "createdAt": "2020-07-06T05:35:57Z", "author": {"login": "Zelldon"}, "path": "dist/src/main/config/broker.standalone.yaml.template", "diffHunk": "@@ -187,6 +187,23 @@\n       # This setting can also be overridden using the environment variable ZEEBE_BROKER_DATA_SNAPSHOTPERIOD.\n       # snapshotPeriod: 15m\n \n+      # When the disk usage is above this value all client commands will be rejected.\n+      # The value is specified as a percentage of the total disk space.\n+      # The value should be in the range (0, 1).\n+      # This setting can also be overridden using the environment variable ZEEBE_BROKER_DATA_DISKUSAGECOMMANDWATERMARK\n+      # diskUsageCommandWatermark = 0.8\n+\n+      # When the disk usage is above this value replication will be paused.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM3Nzk4Mg=="}, "originalCommit": {"oid": "ef515fed93020dc76d7b339d99e86b0fc50d4514"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDA2Nzg1Ng==", "bodyText": "How about re-wording it as \"When the disk usage is above this value, this broker will not replicate events from other brokers\"?", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r450067856", "createdAt": "2020-07-06T08:35:33Z", "author": {"login": "deepthidevaki"}, "path": "dist/src/main/config/broker.standalone.yaml.template", "diffHunk": "@@ -187,6 +187,23 @@\n       # This setting can also be overridden using the environment variable ZEEBE_BROKER_DATA_SNAPSHOTPERIOD.\n       # snapshotPeriod: 15m\n \n+      # When the disk usage is above this value all client commands will be rejected.\n+      # The value is specified as a percentage of the total disk space.\n+      # The value should be in the range (0, 1).\n+      # This setting can also be overridden using the environment variable ZEEBE_BROKER_DATA_DISKUSAGECOMMANDWATERMARK\n+      # diskUsageCommandWatermark = 0.8\n+\n+      # When the disk usage is above this value replication will be paused.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM3Nzk4Mg=="}, "originalCommit": {"oid": "ef515fed93020dc76d7b339d99e86b0fc50d4514"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDEwMzk4MQ==", "bodyText": "It still sounds for my like this node is the active part - but it is not. As follower it just accepts or not accepts. Idk. Maybe it is just me. @npepinpe any opinion on this?", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r450103981", "createdAt": "2020-07-06T09:39:11Z", "author": {"login": "Zelldon"}, "path": "dist/src/main/config/broker.standalone.yaml.template", "diffHunk": "@@ -187,6 +187,23 @@\n       # This setting can also be overridden using the environment variable ZEEBE_BROKER_DATA_SNAPSHOTPERIOD.\n       # snapshotPeriod: 15m\n \n+      # When the disk usage is above this value all client commands will be rejected.\n+      # The value is specified as a percentage of the total disk space.\n+      # The value should be in the range (0, 1).\n+      # This setting can also be overridden using the environment variable ZEEBE_BROKER_DATA_DISKUSAGECOMMANDWATERMARK\n+      # diskUsageCommandWatermark = 0.8\n+\n+      # When the disk usage is above this value replication will be paused.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM3Nzk4Mg=="}, "originalCommit": {"oid": "ef515fed93020dc76d7b339d99e86b0fc50d4514"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDg0NDIwMA==", "bodyText": "When the disk usage is above this value, this broker will stop writing replicated events it receives from other brokers\n\n?", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r450844200", "createdAt": "2020-07-07T12:59:03Z", "author": {"login": "npepinpe"}, "path": "dist/src/main/config/broker.standalone.yaml.template", "diffHunk": "@@ -187,6 +187,23 @@\n       # This setting can also be overridden using the environment variable ZEEBE_BROKER_DATA_SNAPSHOTPERIOD.\n       # snapshotPeriod: 15m\n \n+      # When the disk usage is above this value all client commands will be rejected.\n+      # The value is specified as a percentage of the total disk space.\n+      # The value should be in the range (0, 1).\n+      # This setting can also be overridden using the environment variable ZEEBE_BROKER_DATA_DISKUSAGECOMMANDWATERMARK\n+      # diskUsageCommandWatermark = 0.8\n+\n+      # When the disk usage is above this value replication will be paused.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM3Nzk4Mg=="}, "originalCommit": {"oid": "ef515fed93020dc76d7b339d99e86b0fc50d4514"}, "originalPosition": 10}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5ODAxOTI0OnYy", "diffSide": "RIGHT", "path": "atomix/cluster/src/main/java/io/atomix/raft/storage/RaftStorage.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQxMDozMTowNlrOGsHF4g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQxMDozMTowNlrOGsHF4g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkwNjcyMg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n               * @return the percentage of disk space that must be available before log compaction is forced\n          \n          \n            \n               * @return the amount of disk space that must be available before log compaction is forced", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r448906722", "createdAt": "2020-07-02T10:31:06Z", "author": {"login": "npepinpe"}, "path": "atomix/cluster/src/main/java/io/atomix/raft/storage/RaftStorage.java", "diffHunk": "@@ -189,7 +189,7 @@ public boolean dynamicCompaction() {\n    *\n    * @return the percentage of disk space that must be available before log compaction is forced", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e908944dc07b3762a4370ca610633fcae49d05d"}, "originalPosition": 2}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwNTY0NzM4OnYy", "diffSide": "RIGHT", "path": "atomix/cluster/src/main/java/io/atomix/raft/storage/RaftStorage.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wNlQwNzoxNzo0NFrOGtLg5A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wNlQwNzoxNzo0NFrOGtLg5A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDAyNzc0OA==", "bodyText": "This needs then probably also be changed\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n               * Returns the percentage of disk space that must be available before log compaction is forced.\n          \n          \n            \n               * Returns the amount of disk space that must be available before log compaction is forced.", "url": "https://github.com/camunda-cloud/zeebe/pull/4782#discussion_r450027748", "createdAt": "2020-07-06T07:17:44Z", "author": {"login": "Zelldon"}, "path": "atomix/cluster/src/main/java/io/atomix/raft/storage/RaftStorage.java", "diffHunk": "@@ -187,7 +187,7 @@ public boolean dynamicCompaction() {\n   /**\n    * Returns the percentage of disk space that must be available before log compaction is forced.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cf6a16feb70194668781c9f18e9733526ebd0f67"}, "originalPosition": 2}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 550, "cost": 1, "resetAt": "2021-11-12T13:16:51Z"}}}