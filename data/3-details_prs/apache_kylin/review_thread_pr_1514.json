{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTQxNTc5NDU0", "number": 1514, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QwNTo1NjozOFrOFGieag==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QwNzowNToyNlrOFGjmfA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQyNDAwNjE4OnYy", "diffSide": "RIGHT", "path": "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/builder/CubeSnapshotBuilder.scala", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QwNTo1NjozOFrOIHl4pA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QwNTo1NjozOFrOIHl4pA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDgzMTY1Mg==", "bodyText": "Please remove toString, it is meaningless.", "url": "https://github.com/apache/kylin/pull/1514#discussion_r544831652", "createdAt": "2020-12-17T05:56:38Z", "author": {"login": "hit-lacus"}, "path": "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/builder/CubeSnapshotBuilder.scala", "diffHunk": "@@ -183,6 +185,22 @@ class CubeSnapshotBuilder extends Logging {\n   }\n   import org.apache.kylin.engine.spark.utils.SparkDataSource._\n \n+  def checkDupKey() = {\n+    val joinDescs = seg.joindescs\n+    joinDescs.foreach {\n+      joinDesc =>\n+        val tableInfo = joinDesc.lookupTable\n+        val lookupTableName = tableInfo.tableName\n+        val df = ss.table(tableInfo)\n+        val countColumn = df.count().toString", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ba01ded37ac005669c7e1152e99e2a9dc4428c46"}, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQyNDEzODY5OnYy", "diffSide": "RIGHT", "path": "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/builder/CubeSnapshotBuilder.scala", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QwNjo0NTo1N1rOIHm_XQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QwNjo0NTo1N1rOIHm_XQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDg0OTc1Nw==", "bodyText": "Replace lookupTablePKS: _* with lookupTablePKS.tail : _*.", "url": "https://github.com/apache/kylin/pull/1514#discussion_r544849757", "createdAt": "2020-12-17T06:45:57Z", "author": {"login": "hit-lacus"}, "path": "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/builder/CubeSnapshotBuilder.scala", "diffHunk": "@@ -183,6 +185,22 @@ class CubeSnapshotBuilder extends Logging {\n   }\n   import org.apache.kylin.engine.spark.utils.SparkDataSource._\n \n+  def checkDupKey() = {\n+    val joinDescs = seg.joindescs\n+    joinDescs.foreach {\n+      joinDesc =>\n+        val tableInfo = joinDesc.lookupTable\n+        val lookupTableName = tableInfo.tableName\n+        val df = ss.table(tableInfo)\n+        val countColumn = df.count()\n+        val lookupTablePKS = joinDesc.PKS.map(lookupTablePK => lookupTablePK.columnName)\n+        val countDistinctColumn = df.agg(countDistinct(joinDesc.PKS(0).columnName, lookupTablePKS: _*)).collect().map(_(0)).toList(0)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f433bc1e3b85939257f107f54e1228b236ea2fa1"}, "originalPosition": 34}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQyNDE5MDY4OnYy", "diffSide": "RIGHT", "path": "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/builder/CubeSnapshotBuilder.scala", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QwNzowNToyNlrOIHnb0A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QwNzoxMzozNVrOIHnpHQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDg1NzA0MA==", "bodyText": "better change to : df.agg(countDistinct(lookupTablePKS(0), lookupTablePKS.tail : _*)).collect().map(_.getLong(0)).head", "url": "https://github.com/apache/kylin/pull/1514#discussion_r544857040", "createdAt": "2020-12-17T07:05:26Z", "author": {"login": "zzcclp"}, "path": "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/builder/CubeSnapshotBuilder.scala", "diffHunk": "@@ -183,6 +185,22 @@ class CubeSnapshotBuilder extends Logging {\n   }\n   import org.apache.kylin.engine.spark.utils.SparkDataSource._\n \n+  def checkDupKey() = {\n+    val joinDescs = seg.joindescs\n+    joinDescs.foreach {\n+      joinDesc =>\n+        val tableInfo = joinDesc.lookupTable\n+        val lookupTableName = tableInfo.tableName\n+        val df = ss.table(tableInfo)\n+        val countColumn = df.count()\n+        val lookupTablePKS = joinDesc.PKS.map(lookupTablePK => lookupTablePK.columnName)\n+        val countDistinctColumn = df.agg(countDistinct(joinDesc.PKS(0).columnName, lookupTablePKS: _*)).collect().map(_(0)).toList(0)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f433bc1e3b85939257f107f54e1228b236ea2fa1"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDg2MDQ0NQ==", "bodyText": "Thank you for your review @hit-lacus  @zzcclp  I have updated this PR.", "url": "https://github.com/apache/kylin/pull/1514#discussion_r544860445", "createdAt": "2020-12-17T07:13:35Z", "author": {"login": "zhangayqian"}, "path": "kylin-spark-project/kylin-spark-engine/src/main/scala/org/apache/kylin/engine/spark/builder/CubeSnapshotBuilder.scala", "diffHunk": "@@ -183,6 +185,22 @@ class CubeSnapshotBuilder extends Logging {\n   }\n   import org.apache.kylin.engine.spark.utils.SparkDataSource._\n \n+  def checkDupKey() = {\n+    val joinDescs = seg.joindescs\n+    joinDescs.foreach {\n+      joinDesc =>\n+        val tableInfo = joinDesc.lookupTable\n+        val lookupTableName = tableInfo.tableName\n+        val df = ss.table(tableInfo)\n+        val countColumn = df.count()\n+        val lookupTablePKS = joinDesc.PKS.map(lookupTablePK => lookupTablePK.columnName)\n+        val countDistinctColumn = df.agg(countDistinct(joinDesc.PKS(0).columnName, lookupTablePKS: _*)).collect().map(_(0)).toList(0)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDg1NzA0MA=="}, "originalCommit": {"oid": "f433bc1e3b85939257f107f54e1228b236ea2fa1"}, "originalPosition": 34}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1583, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}