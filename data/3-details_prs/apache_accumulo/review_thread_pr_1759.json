{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTEyOTQ4MDQy", "number": 1759, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QwMTowMDoxM1rOE0n1IA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QxOTo0ODo0NVrOE09OkQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIzNjEzOTg0OnYy", "diffSide": "RIGHT", "path": "server/manager/src/main/java/org/apache/accumulo/master/tableOps/create/ChooseDir.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QwMTowMDoxM1rOHsdBkQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QxNTo1OTowMlrOHs1gOw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM3NDkyOQ==", "bodyText": "When on the receiving end of an error like this its really nice to have some information that helps correlate it with other activity in the system.  However the danger of trying to get more information for an error is that the code may fail.  I think the following is pretty safe and gives a good bit of helpful info.\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  log.error(\"Failed to undo ChooseDir operation\", e);\n          \n          \n            \n                  var spdir = Optional.ofNullable(tableInfo).map(TableInfo::getSplitDirsPath).orElse(null);\n          \n          \n            \n                  log.error(\"{} Failed to undo ChooseDir operation, split dir {} \",FateTxId.format(tid), spdir, e);", "url": "https://github.com/apache/accumulo/pull/1759#discussion_r516374929", "createdAt": "2020-11-03T01:00:13Z", "author": {"login": "keith-turner"}, "path": "server/manager/src/main/java/org/apache/accumulo/master/tableOps/create/ChooseDir.java", "diffHunk": "@@ -60,9 +63,16 @@ public long isReady(long tid, Master environment) {\n \n   @Override\n   public void undo(long tid, Master master) throws Exception {\n-    Path p = tableInfo.getSplitDirsPath();\n-    FileSystem fs = p.getFileSystem(master.getContext().getHadoopConf());\n-    fs.delete(p, true);\n+    // Clean up split files if ChooseDir operation fails\n+    try {\n+      if (tableInfo.getInitialSplitSize() > 0) {\n+        Path p = tableInfo.getSplitDirsPath();\n+        FileSystem fs = p.getFileSystem(master.getContext().getHadoopConf());\n+        fs.delete(p, true);\n+      }\n+    } catch (NullPointerException | IOException e) {\n+      log.error(\"Failed to undo ChooseDir operation\", e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e3d6c5fb4a18f9c179bfcb302ccd6a54bab1cd9d"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjYyMzk4MQ==", "bodyText": "I made the requested error changes or each of the catch blocks. Let me know if there is anything else I need to tweak.", "url": "https://github.com/apache/accumulo/pull/1759#discussion_r516623981", "createdAt": "2020-11-03T12:17:03Z", "author": {"login": "Manno15"}, "path": "server/manager/src/main/java/org/apache/accumulo/master/tableOps/create/ChooseDir.java", "diffHunk": "@@ -60,9 +63,16 @@ public long isReady(long tid, Master environment) {\n \n   @Override\n   public void undo(long tid, Master master) throws Exception {\n-    Path p = tableInfo.getSplitDirsPath();\n-    FileSystem fs = p.getFileSystem(master.getContext().getHadoopConf());\n-    fs.delete(p, true);\n+    // Clean up split files if ChooseDir operation fails\n+    try {\n+      if (tableInfo.getInitialSplitSize() > 0) {\n+        Path p = tableInfo.getSplitDirsPath();\n+        FileSystem fs = p.getFileSystem(master.getContext().getHadoopConf());\n+        fs.delete(p, true);\n+      }\n+    } catch (NullPointerException | IOException e) {\n+      log.error(\"Failed to undo ChooseDir operation\", e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM3NDkyOQ=="}, "originalCommit": {"oid": "e3d6c5fb4a18f9c179bfcb302ccd6a54bab1cd9d"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjc3NTk5NQ==", "bodyText": "Looks good.", "url": "https://github.com/apache/accumulo/pull/1759#discussion_r516775995", "createdAt": "2020-11-03T15:59:02Z", "author": {"login": "keith-turner"}, "path": "server/manager/src/main/java/org/apache/accumulo/master/tableOps/create/ChooseDir.java", "diffHunk": "@@ -60,9 +63,16 @@ public long isReady(long tid, Master environment) {\n \n   @Override\n   public void undo(long tid, Master master) throws Exception {\n-    Path p = tableInfo.getSplitDirsPath();\n-    FileSystem fs = p.getFileSystem(master.getContext().getHadoopConf());\n-    fs.delete(p, true);\n+    // Clean up split files if ChooseDir operation fails\n+    try {\n+      if (tableInfo.getInitialSplitSize() > 0) {\n+        Path p = tableInfo.getSplitDirsPath();\n+        FileSystem fs = p.getFileSystem(master.getContext().getHadoopConf());\n+        fs.delete(p, true);\n+      }\n+    } catch (NullPointerException | IOException e) {\n+      log.error(\"Failed to undo ChooseDir operation\", e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM3NDkyOQ=="}, "originalCommit": {"oid": "e3d6c5fb4a18f9c179bfcb302ccd6a54bab1cd9d"}, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIzOTQ1MDQ3OnYy", "diffSide": "RIGHT", "path": "server/manager/src/main/java/org/apache/accumulo/master/tableOps/create/CreateTable.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QxODo1MzoxNVrOHs8Ouw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QyMDowOToxOVrOHs-wdQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjg4NjIwMw==", "bodyText": "This needs to be removed. A user could have a table by this name.", "url": "https://github.com/apache/accumulo/pull/1759#discussion_r516886203", "createdAt": "2020-11-03T18:53:15Z", "author": {"login": "ctubbsii"}, "path": "server/manager/src/main/java/org/apache/accumulo/master/tableOps/create/CreateTable.java", "diffHunk": "@@ -72,6 +77,9 @@ public long isReady(long tid, Master environment) throws Exception {\n     Utils.getIdLock().lock();\n     try {\n       String tName = tableInfo.getTableName();\n+      if(tName.equals(\"ci\")){\n+        Thread.sleep(10000000);\n+      }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "59da0bf7171e1c2210acf81da25b105547cf9d64"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkyNzYwNQ==", "bodyText": "That is my mistake, this shouldn't be here. I used this to force it to hang. Forgot to remove it.", "url": "https://github.com/apache/accumulo/pull/1759#discussion_r516927605", "createdAt": "2020-11-03T20:09:19Z", "author": {"login": "Manno15"}, "path": "server/manager/src/main/java/org/apache/accumulo/master/tableOps/create/CreateTable.java", "diffHunk": "@@ -72,6 +77,9 @@ public long isReady(long tid, Master environment) throws Exception {\n     Utils.getIdLock().lock();\n     try {\n       String tName = tableInfo.getTableName();\n+      if(tName.equals(\"ci\")){\n+        Thread.sleep(10000000);\n+      }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjg4NjIwMw=="}, "originalCommit": {"oid": "59da0bf7171e1c2210acf81da25b105547cf9d64"}, "originalPosition": 34}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIzOTY0NTYxOnYy", "diffSide": "RIGHT", "path": "server/manager/src/main/java/org/apache/accumulo/master/tableOps/create/FinishCreateTable.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QxOTo0ODo0NVrOHs-E4g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QyMDoxMjo1MFrOHs-3Gg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkxNjQ1MA==", "bodyText": "I don't think it's possible for tableInfo to be null here, given how this class is constructed. And, if the split size is >0, it's also not possible for the splits file locations to be null. Also, I think we should focus just on handling exceptions pertaining to the specific cleanup task that we're performing. So, if these do happen to be null because of some serialization bug or whatever, that shouldn't be handled here, but handled by the framework if the exception is thrown from the method (if the framework isn't capable of handling exceptions thrown by this method, the interface shouldn't have throws Exception on the method, and if that's a problem, it is a separate issue that should be fixed in a separate PR to fix the FaTE framework itself).\nAlso, the tx id is already in the path to the splits file, so it's possibly redundant to have that here (but I'm not opposed to keeping it).\nAlso, we probably want to log the parent path (the one we're trying to delete recursively), rather than just one of the two file names.\nSo, all told, I think something like this would be a little cleaner (with similar changes made in the other places):\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                try {\n          \n          \n            \n                  Path p = tableInfo.getSplitPath().getParent();\n          \n          \n            \n                  FileSystem fs = p.getFileSystem(env.getContext().getHadoopConf());\n          \n          \n            \n                  fs.delete(p, true);\n          \n          \n            \n                } catch (NullPointerException | IOException e) {\n          \n          \n            \n                  var spdir = Optional.ofNullable(tableInfo).map(TableInfo::getSplitDirsPath).orElse(null);\n          \n          \n            \n                  log.error(\"{} Failed to cleanup splits file after table was created, split dir {} \",\n          \n          \n            \n                      FateTxId.formatTid(tid), spdir, e);\n          \n          \n            \n                }\n          \n          \n            \n                Path p = null;\n          \n          \n            \n                try {\n          \n          \n            \n                  p = tableInfo.getSplitPath().getParent();\n          \n          \n            \n                  FileSystem fs = p.getFileSystem(env.getContext().getHadoopConf());\n          \n          \n            \n                  fs.delete(p, true);\n          \n          \n            \n                } catch (IOException e) {\n          \n          \n            \n                  log.error(\"Table was created, but failed to clean up temporary splits files at {}\", p, e);\n          \n          \n            \n                }", "url": "https://github.com/apache/accumulo/pull/1759#discussion_r516916450", "createdAt": "2020-11-03T19:48:45Z", "author": {"login": "ctubbsii"}, "path": "server/manager/src/main/java/org/apache/accumulo/master/tableOps/create/FinishCreateTable.java", "diffHunk": "@@ -62,17 +67,23 @@ public long isReady(long tid, Master environment) {\n     env.getEventCoordinator().event(\"Created table %s \", tableInfo.getTableName());\n \n     if (tableInfo.getInitialSplitSize() > 0) {\n-      cleanupSplitFiles(env);\n+      cleanupSplitFiles(tid, env);\n     }\n     return null;\n   }\n \n-  private void cleanupSplitFiles(Master env) throws IOException {\n+  private void cleanupSplitFiles(long tid, Master env) throws IOException {\n     // it is sufficient to delete from the parent, because both files are in the same directory, and\n     // we want to delete the directory also\n-    Path p = tableInfo.getSplitPath().getParent();\n-    FileSystem fs = p.getFileSystem(env.getContext().getHadoopConf());\n-    fs.delete(p, true);\n+    try {\n+      Path p = tableInfo.getSplitPath().getParent();\n+      FileSystem fs = p.getFileSystem(env.getContext().getHadoopConf());\n+      fs.delete(p, true);\n+    } catch (NullPointerException | IOException e) {\n+      var spdir = Optional.ofNullable(tableInfo).map(TableInfo::getSplitDirsPath).orElse(null);\n+      log.error(\"{} Failed to cleanup splits file after table was created, split dir {} \",\n+          FateTxId.formatTid(tid), spdir, e);\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "59da0bf7171e1c2210acf81da25b105547cf9d64"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkyOTMwNg==", "bodyText": "I don't think it's possible for tableInfo to be null here, given how this class is constructed. And, if the split size is >0, it's also not possible for the splits file locations to be null.\n\nI agree. I wasn't quite sure so I kept the null exception handling in there. I will remove and look to make the other changes you suggested as well.", "url": "https://github.com/apache/accumulo/pull/1759#discussion_r516929306", "createdAt": "2020-11-03T20:12:50Z", "author": {"login": "Manno15"}, "path": "server/manager/src/main/java/org/apache/accumulo/master/tableOps/create/FinishCreateTable.java", "diffHunk": "@@ -62,17 +67,23 @@ public long isReady(long tid, Master environment) {\n     env.getEventCoordinator().event(\"Created table %s \", tableInfo.getTableName());\n \n     if (tableInfo.getInitialSplitSize() > 0) {\n-      cleanupSplitFiles(env);\n+      cleanupSplitFiles(tid, env);\n     }\n     return null;\n   }\n \n-  private void cleanupSplitFiles(Master env) throws IOException {\n+  private void cleanupSplitFiles(long tid, Master env) throws IOException {\n     // it is sufficient to delete from the parent, because both files are in the same directory, and\n     // we want to delete the directory also\n-    Path p = tableInfo.getSplitPath().getParent();\n-    FileSystem fs = p.getFileSystem(env.getContext().getHadoopConf());\n-    fs.delete(p, true);\n+    try {\n+      Path p = tableInfo.getSplitPath().getParent();\n+      FileSystem fs = p.getFileSystem(env.getContext().getHadoopConf());\n+      fs.delete(p, true);\n+    } catch (NullPointerException | IOException e) {\n+      var spdir = Optional.ofNullable(tableInfo).map(TableInfo::getSplitDirsPath).orElse(null);\n+      log.error(\"{} Failed to cleanup splits file after table was created, split dir {} \",\n+          FateTxId.formatTid(tid), spdir, e);\n+    }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjkxNjQ1MA=="}, "originalCommit": {"oid": "59da0bf7171e1c2210acf81da25b105547cf9d64"}, "originalPosition": 51}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4084, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}