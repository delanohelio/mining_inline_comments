{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTMyNjM3MzYw", "number": 1822, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwNToxNDowOFrOFBE-eA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQyMDozNzoyMlrOFFNkpA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM2Njc0NDI0OnYy", "diffSide": "RIGHT", "path": "start/src/main/java/org/apache/accumulo/start/Main.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwNToxNDowOFrOH_qWxw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwNToxNDowOFrOH_qWxw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjUxNjI5NQ==", "bodyText": "This one might actually be a legitimate use for System.exit(1), since the expectation here is that it scripts or users should see a non-zero return code, and that our usage information that we print is more useful than any ugly stack trace.", "url": "https://github.com/apache/accumulo/pull/1822#discussion_r536516295", "createdAt": "2020-12-05T05:14:08Z", "author": {"login": "ctubbsii"}, "path": "start/src/main/java/org/apache/accumulo/start/Main.java", "diffHunk": "@@ -41,63 +41,57 @@\n   private static Class<?> vfsClassLoader;\n   private static Map<String,KeywordExecutable> servicesMap;\n \n-  public static void main(final String[] args) {\n+  public static void main(final String[] args) throws Exception {\n+    // Preload classes that cause a deadlock between the ServiceLoader and the DFSClient when\n+    // using the VFSClassLoader with jars in HDFS.\n+    ClassLoader loader = getClassLoader();\n+    Class<?> confClass = null;\n     try {\n-      // Preload classes that cause a deadlock between the ServiceLoader and the DFSClient when\n-      // using the VFSClassLoader with jars in HDFS.\n-      ClassLoader loader = getClassLoader();\n-      Class<?> confClass = null;\n-      try {\n-        @SuppressWarnings(\"deprecation\")\n-        var deprecatedConfClass = org.apache.accumulo.start.classloader.AccumuloClassLoader\n-            .getClassLoader().loadClass(\"org.apache.hadoop.conf.Configuration\");\n-        confClass = deprecatedConfClass;\n-      } catch (ClassNotFoundException e) {\n-        log.error(\"Unable to find Hadoop Configuration class on classpath, check configuration.\",\n-            e);\n-        System.exit(1);\n-      }\n-      Object conf = null;\n-      try {\n-        conf = confClass.getDeclaredConstructor().newInstance();\n-      } catch (Exception e) {\n-        log.error(\"Error creating new instance of Hadoop Configuration\", e);\n-        System.exit(1);\n-      }\n-      try {\n-        Method getClassByNameOrNullMethod =\n-            conf.getClass().getMethod(\"getClassByNameOrNull\", String.class);\n-        getClassByNameOrNullMethod.invoke(conf, \"org.apache.hadoop.mapred.JobConf\");\n-        getClassByNameOrNullMethod.invoke(conf, \"org.apache.hadoop.mapred.JobConfigurable\");\n-      } catch (Exception e) {\n-        log.error(\"Error pre-loading JobConf and JobConfigurable classes, VFS classloader with \"\n-            + \"system classes in HDFS may not work correctly\", e);\n-        System.exit(1);\n-      }\n-\n-      if (args.length == 0) {\n-        printUsage();\n-        System.exit(1);\n-      }\n-      if (args[0].equals(\"-h\") || args[0].equals(\"-help\") || args[0].equals(\"--help\")) {\n-        printUsage();\n-        System.exit(1);\n-      }\n+      @SuppressWarnings(\"deprecation\")\n+      var deprecatedConfClass = org.apache.accumulo.start.classloader.AccumuloClassLoader\n+          .getClassLoader().loadClass(\"org.apache.hadoop.conf.Configuration\");\n+      confClass = deprecatedConfClass;\n+    } catch (ClassNotFoundException e) {\n+      log.error(\"Unable to find Hadoop Configuration class on classpath, check configuration.\", e);\n+      throw e;\n+    }\n+    Object conf = null;\n+    try {\n+      conf = confClass.getDeclaredConstructor().newInstance();\n+    } catch (Exception e) {\n+      log.error(\"Error creating new instance of Hadoop Configuration\", e);\n+      throw e;\n+    }\n+    try {\n+      Method getClassByNameOrNullMethod =\n+          conf.getClass().getMethod(\"getClassByNameOrNull\", String.class);\n+      getClassByNameOrNullMethod.invoke(conf, \"org.apache.hadoop.mapred.JobConf\");\n+      getClassByNameOrNullMethod.invoke(conf, \"org.apache.hadoop.mapred.JobConfigurable\");\n+    } catch (Exception e) {\n+      log.error(\"Error pre-loading JobConf and JobConfigurable classes, VFS classloader with \"\n+          + \"system classes in HDFS may not work correctly\", e);\n+      throw e;\n+    }\n \n-      // determine whether a keyword was used or a class name, and execute it with the remaining\n-      // args\n-      String keywordOrClassName = args[0];\n-      KeywordExecutable keywordExec = getExecutables(loader).get(keywordOrClassName);\n-      if (keywordExec != null) {\n-        execKeyword(keywordExec, stripArgs(args, 1));\n-      } else {\n-        execMainClassName(keywordOrClassName, stripArgs(args, 1));\n-      }\n+    if (args.length == 0) {\n+      printUsage();\n+      throw new IllegalArgumentException(\"No arguments passed to Main\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "590d64121fda123fdf5205d81dd1af69e216e972"}, "originalPosition": 88}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQxMDA5NTcyOnYy", "diffSide": "RIGHT", "path": "start/src/main/java/org/apache/accumulo/start/Main.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQyMDozNzoyMlrOIFnK7w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQyMTowODo0NFrOIFpNJg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mjc1NTU2Nw==", "bodyText": "Even though this is a legitimate use of exit, if we want consistency with the help options, we could just return without an exit code here as well. I'm fine either way, as long as we don't throw an exception here.", "url": "https://github.com/apache/accumulo/pull/1822#discussion_r542755567", "createdAt": "2020-12-14T20:37:22Z", "author": {"login": "ctubbsii"}, "path": "start/src/main/java/org/apache/accumulo/start/Main.java", "diffHunk": "@@ -41,63 +41,57 @@\n   private static Class<?> vfsClassLoader;\n   private static Map<String,KeywordExecutable> servicesMap;\n \n-  public static void main(final String[] args) {\n+  public static void main(final String[] args) throws Exception {\n+    // Preload classes that cause a deadlock between the ServiceLoader and the DFSClient when\n+    // using the VFSClassLoader with jars in HDFS.\n+    ClassLoader loader = getClassLoader();\n+    Class<?> confClass = null;\n     try {\n-      // Preload classes that cause a deadlock between the ServiceLoader and the DFSClient when\n-      // using the VFSClassLoader with jars in HDFS.\n-      ClassLoader loader = getClassLoader();\n-      Class<?> confClass = null;\n-      try {\n-        @SuppressWarnings(\"deprecation\")\n-        var deprecatedConfClass = org.apache.accumulo.start.classloader.AccumuloClassLoader\n-            .getClassLoader().loadClass(\"org.apache.hadoop.conf.Configuration\");\n-        confClass = deprecatedConfClass;\n-      } catch (ClassNotFoundException e) {\n-        log.error(\"Unable to find Hadoop Configuration class on classpath, check configuration.\",\n-            e);\n-        System.exit(1);\n-      }\n-      Object conf = null;\n-      try {\n-        conf = confClass.getDeclaredConstructor().newInstance();\n-      } catch (Exception e) {\n-        log.error(\"Error creating new instance of Hadoop Configuration\", e);\n-        System.exit(1);\n-      }\n-      try {\n-        Method getClassByNameOrNullMethod =\n-            conf.getClass().getMethod(\"getClassByNameOrNull\", String.class);\n-        getClassByNameOrNullMethod.invoke(conf, \"org.apache.hadoop.mapred.JobConf\");\n-        getClassByNameOrNullMethod.invoke(conf, \"org.apache.hadoop.mapred.JobConfigurable\");\n-      } catch (Exception e) {\n-        log.error(\"Error pre-loading JobConf and JobConfigurable classes, VFS classloader with \"\n-            + \"system classes in HDFS may not work correctly\", e);\n-        System.exit(1);\n-      }\n-\n-      if (args.length == 0) {\n-        printUsage();\n-        System.exit(1);\n-      }\n-      if (args[0].equals(\"-h\") || args[0].equals(\"-help\") || args[0].equals(\"--help\")) {\n-        printUsage();\n-        System.exit(1);\n-      }\n-\n-      // determine whether a keyword was used or a class name, and execute it with the remaining\n-      // args\n-      String keywordOrClassName = args[0];\n-      KeywordExecutable keywordExec = getExecutables(loader).get(keywordOrClassName);\n-      if (keywordExec != null) {\n-        execKeyword(keywordExec, stripArgs(args, 1));\n-      } else {\n-        execMainClassName(keywordOrClassName, stripArgs(args, 1));\n-      }\n+      @SuppressWarnings(\"deprecation\")\n+      var deprecatedConfClass = org.apache.accumulo.start.classloader.AccumuloClassLoader\n+          .getClassLoader().loadClass(\"org.apache.hadoop.conf.Configuration\");\n+      confClass = deprecatedConfClass;\n+    } catch (ClassNotFoundException e) {\n+      log.error(\"Unable to find Hadoop Configuration class on classpath, check configuration.\", e);\n+      throw e;\n+    }\n+    Object conf = null;\n+    try {\n+      conf = confClass.getDeclaredConstructor().newInstance();\n+    } catch (Exception e) {\n+      log.error(\"Error creating new instance of Hadoop Configuration\", e);\n+      throw e;\n+    }\n+    try {\n+      Method getClassByNameOrNullMethod =\n+          conf.getClass().getMethod(\"getClassByNameOrNull\", String.class);\n+      getClassByNameOrNullMethod.invoke(conf, \"org.apache.hadoop.mapred.JobConf\");\n+      getClassByNameOrNullMethod.invoke(conf, \"org.apache.hadoop.mapred.JobConfigurable\");\n+    } catch (Exception e) {\n+      log.error(\"Error pre-loading JobConf and JobConfigurable classes, VFS classloader with \"\n+          + \"system classes in HDFS may not work correctly\", e);\n+      throw e;\n+    }\n \n-    } catch (Throwable t) {\n-      log.error(\"Uncaught exception\", t);\n+    if (args.length == 0) {\n+      printUsage();\n       System.exit(1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a5336f2d53ccc889981b4a5e15c5f27ba2a5d6aa"}, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mjc2NDk3Mg==", "bodyText": "@dlmarion Not sure if you saw this comment. I made it after marking \"Approve\" on my last review. Feel free to mark this as \"resolved\" if you're fine with it as-is.", "url": "https://github.com/apache/accumulo/pull/1822#discussion_r542764972", "createdAt": "2020-12-14T20:46:20Z", "author": {"login": "ctubbsii"}, "path": "start/src/main/java/org/apache/accumulo/start/Main.java", "diffHunk": "@@ -41,63 +41,57 @@\n   private static Class<?> vfsClassLoader;\n   private static Map<String,KeywordExecutable> servicesMap;\n \n-  public static void main(final String[] args) {\n+  public static void main(final String[] args) throws Exception {\n+    // Preload classes that cause a deadlock between the ServiceLoader and the DFSClient when\n+    // using the VFSClassLoader with jars in HDFS.\n+    ClassLoader loader = getClassLoader();\n+    Class<?> confClass = null;\n     try {\n-      // Preload classes that cause a deadlock between the ServiceLoader and the DFSClient when\n-      // using the VFSClassLoader with jars in HDFS.\n-      ClassLoader loader = getClassLoader();\n-      Class<?> confClass = null;\n-      try {\n-        @SuppressWarnings(\"deprecation\")\n-        var deprecatedConfClass = org.apache.accumulo.start.classloader.AccumuloClassLoader\n-            .getClassLoader().loadClass(\"org.apache.hadoop.conf.Configuration\");\n-        confClass = deprecatedConfClass;\n-      } catch (ClassNotFoundException e) {\n-        log.error(\"Unable to find Hadoop Configuration class on classpath, check configuration.\",\n-            e);\n-        System.exit(1);\n-      }\n-      Object conf = null;\n-      try {\n-        conf = confClass.getDeclaredConstructor().newInstance();\n-      } catch (Exception e) {\n-        log.error(\"Error creating new instance of Hadoop Configuration\", e);\n-        System.exit(1);\n-      }\n-      try {\n-        Method getClassByNameOrNullMethod =\n-            conf.getClass().getMethod(\"getClassByNameOrNull\", String.class);\n-        getClassByNameOrNullMethod.invoke(conf, \"org.apache.hadoop.mapred.JobConf\");\n-        getClassByNameOrNullMethod.invoke(conf, \"org.apache.hadoop.mapred.JobConfigurable\");\n-      } catch (Exception e) {\n-        log.error(\"Error pre-loading JobConf and JobConfigurable classes, VFS classloader with \"\n-            + \"system classes in HDFS may not work correctly\", e);\n-        System.exit(1);\n-      }\n-\n-      if (args.length == 0) {\n-        printUsage();\n-        System.exit(1);\n-      }\n-      if (args[0].equals(\"-h\") || args[0].equals(\"-help\") || args[0].equals(\"--help\")) {\n-        printUsage();\n-        System.exit(1);\n-      }\n-\n-      // determine whether a keyword was used or a class name, and execute it with the remaining\n-      // args\n-      String keywordOrClassName = args[0];\n-      KeywordExecutable keywordExec = getExecutables(loader).get(keywordOrClassName);\n-      if (keywordExec != null) {\n-        execKeyword(keywordExec, stripArgs(args, 1));\n-      } else {\n-        execMainClassName(keywordOrClassName, stripArgs(args, 1));\n-      }\n+      @SuppressWarnings(\"deprecation\")\n+      var deprecatedConfClass = org.apache.accumulo.start.classloader.AccumuloClassLoader\n+          .getClassLoader().loadClass(\"org.apache.hadoop.conf.Configuration\");\n+      confClass = deprecatedConfClass;\n+    } catch (ClassNotFoundException e) {\n+      log.error(\"Unable to find Hadoop Configuration class on classpath, check configuration.\", e);\n+      throw e;\n+    }\n+    Object conf = null;\n+    try {\n+      conf = confClass.getDeclaredConstructor().newInstance();\n+    } catch (Exception e) {\n+      log.error(\"Error creating new instance of Hadoop Configuration\", e);\n+      throw e;\n+    }\n+    try {\n+      Method getClassByNameOrNullMethod =\n+          conf.getClass().getMethod(\"getClassByNameOrNull\", String.class);\n+      getClassByNameOrNullMethod.invoke(conf, \"org.apache.hadoop.mapred.JobConf\");\n+      getClassByNameOrNullMethod.invoke(conf, \"org.apache.hadoop.mapred.JobConfigurable\");\n+    } catch (Exception e) {\n+      log.error(\"Error pre-loading JobConf and JobConfigurable classes, VFS classloader with \"\n+          + \"system classes in HDFS may not work correctly\", e);\n+      throw e;\n+    }\n \n-    } catch (Throwable t) {\n-      log.error(\"Uncaught exception\", t);\n+    if (args.length == 0) {\n+      printUsage();\n       System.exit(1);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mjc1NTU2Nw=="}, "originalCommit": {"oid": "a5336f2d53ccc889981b4a5e15c5f27ba2a5d6aa"}, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mjc4ODkwMg==", "bodyText": "I'm fine with it as is.", "url": "https://github.com/apache/accumulo/pull/1822#discussion_r542788902", "createdAt": "2020-12-14T21:08:44Z", "author": {"login": "dlmarion"}, "path": "start/src/main/java/org/apache/accumulo/start/Main.java", "diffHunk": "@@ -41,63 +41,57 @@\n   private static Class<?> vfsClassLoader;\n   private static Map<String,KeywordExecutable> servicesMap;\n \n-  public static void main(final String[] args) {\n+  public static void main(final String[] args) throws Exception {\n+    // Preload classes that cause a deadlock between the ServiceLoader and the DFSClient when\n+    // using the VFSClassLoader with jars in HDFS.\n+    ClassLoader loader = getClassLoader();\n+    Class<?> confClass = null;\n     try {\n-      // Preload classes that cause a deadlock between the ServiceLoader and the DFSClient when\n-      // using the VFSClassLoader with jars in HDFS.\n-      ClassLoader loader = getClassLoader();\n-      Class<?> confClass = null;\n-      try {\n-        @SuppressWarnings(\"deprecation\")\n-        var deprecatedConfClass = org.apache.accumulo.start.classloader.AccumuloClassLoader\n-            .getClassLoader().loadClass(\"org.apache.hadoop.conf.Configuration\");\n-        confClass = deprecatedConfClass;\n-      } catch (ClassNotFoundException e) {\n-        log.error(\"Unable to find Hadoop Configuration class on classpath, check configuration.\",\n-            e);\n-        System.exit(1);\n-      }\n-      Object conf = null;\n-      try {\n-        conf = confClass.getDeclaredConstructor().newInstance();\n-      } catch (Exception e) {\n-        log.error(\"Error creating new instance of Hadoop Configuration\", e);\n-        System.exit(1);\n-      }\n-      try {\n-        Method getClassByNameOrNullMethod =\n-            conf.getClass().getMethod(\"getClassByNameOrNull\", String.class);\n-        getClassByNameOrNullMethod.invoke(conf, \"org.apache.hadoop.mapred.JobConf\");\n-        getClassByNameOrNullMethod.invoke(conf, \"org.apache.hadoop.mapred.JobConfigurable\");\n-      } catch (Exception e) {\n-        log.error(\"Error pre-loading JobConf and JobConfigurable classes, VFS classloader with \"\n-            + \"system classes in HDFS may not work correctly\", e);\n-        System.exit(1);\n-      }\n-\n-      if (args.length == 0) {\n-        printUsage();\n-        System.exit(1);\n-      }\n-      if (args[0].equals(\"-h\") || args[0].equals(\"-help\") || args[0].equals(\"--help\")) {\n-        printUsage();\n-        System.exit(1);\n-      }\n-\n-      // determine whether a keyword was used or a class name, and execute it with the remaining\n-      // args\n-      String keywordOrClassName = args[0];\n-      KeywordExecutable keywordExec = getExecutables(loader).get(keywordOrClassName);\n-      if (keywordExec != null) {\n-        execKeyword(keywordExec, stripArgs(args, 1));\n-      } else {\n-        execMainClassName(keywordOrClassName, stripArgs(args, 1));\n-      }\n+      @SuppressWarnings(\"deprecation\")\n+      var deprecatedConfClass = org.apache.accumulo.start.classloader.AccumuloClassLoader\n+          .getClassLoader().loadClass(\"org.apache.hadoop.conf.Configuration\");\n+      confClass = deprecatedConfClass;\n+    } catch (ClassNotFoundException e) {\n+      log.error(\"Unable to find Hadoop Configuration class on classpath, check configuration.\", e);\n+      throw e;\n+    }\n+    Object conf = null;\n+    try {\n+      conf = confClass.getDeclaredConstructor().newInstance();\n+    } catch (Exception e) {\n+      log.error(\"Error creating new instance of Hadoop Configuration\", e);\n+      throw e;\n+    }\n+    try {\n+      Method getClassByNameOrNullMethod =\n+          conf.getClass().getMethod(\"getClassByNameOrNull\", String.class);\n+      getClassByNameOrNullMethod.invoke(conf, \"org.apache.hadoop.mapred.JobConf\");\n+      getClassByNameOrNullMethod.invoke(conf, \"org.apache.hadoop.mapred.JobConfigurable\");\n+    } catch (Exception e) {\n+      log.error(\"Error pre-loading JobConf and JobConfigurable classes, VFS classloader with \"\n+          + \"system classes in HDFS may not work correctly\", e);\n+      throw e;\n+    }\n \n-    } catch (Throwable t) {\n-      log.error(\"Uncaught exception\", t);\n+    if (args.length == 0) {\n+      printUsage();\n       System.exit(1);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mjc1NTU2Nw=="}, "originalCommit": {"oid": "a5336f2d53ccc889981b4a5e15c5f27ba2a5d6aa"}, "originalPosition": 91}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4001, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}