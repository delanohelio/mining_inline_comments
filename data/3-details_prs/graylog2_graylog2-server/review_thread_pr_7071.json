{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzU4NjI3MjQy", "number": 7071, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wOFQxNzowMDozN1rODWm6aw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wOFQxNzo1NDowNVrODWnz9w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1MDMyODExOnYy", "diffSide": "RIGHT", "path": "graylog2-server/src/main/java/org/graylog2/indexer/messages/Messages.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wOFQxNzowMDozN1rOFbdgbQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQxMjo1NDowMFrOFcTR7Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDMzOTMwOQ==", "bodyText": "I noticed the following in the documentation for RequestConfig#isExpectContinueEnabled():\n\n'Expect: 100-continue' handshake should be used with caution, as it may cause problems with HTTP servers and proxies that do not support HTTP/1.1 protocol.\n\nSo I wonder if we should make this configurable in graylog.conf? (default: enabled) Otherwise we cannot do anything if a user has a broken proxy in front of Elasticsearch.", "url": "https://github.com/Graylog2/graylog2-server/pull/7071#discussion_r364339309", "createdAt": "2020-01-08T17:00:37Z", "author": {"login": "bernd"}, "path": "graylog2-server/src/main/java/org/graylog2/indexer/messages/Messages.java", "diffHunk": "@@ -185,7 +238,9 @@ private void recordTimestamp(List<Map.Entry<IndexSet, Message>> messageList, Set\n \n     private BulkResult runBulkRequest(final Bulk request, int count) {\n         try {\n-            return BULK_REQUEST_RETRYER.call(() -> client.execute(request));\n+            // Enable Expect-Continue to catch 413 errors before we send the actual data\n+            final RequestConfig requestConfig = RequestConfig.custom().setExpectContinueEnabled(true).build();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6383ac8c537138e216ca6334b511dd127936c74a"}, "originalPosition": 146}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTIyMDMzMw==", "bodyText": "good idea. I've added an option", "url": "https://github.com/Graylog2/graylog2-server/pull/7071#discussion_r365220333", "createdAt": "2020-01-10T12:54:00Z", "author": {"login": "mpfz0r"}, "path": "graylog2-server/src/main/java/org/graylog2/indexer/messages/Messages.java", "diffHunk": "@@ -185,7 +238,9 @@ private void recordTimestamp(List<Map.Entry<IndexSet, Message>> messageList, Set\n \n     private BulkResult runBulkRequest(final Bulk request, int count) {\n         try {\n-            return BULK_REQUEST_RETRYER.call(() -> client.execute(request));\n+            // Enable Expect-Continue to catch 413 errors before we send the actual data\n+            final RequestConfig requestConfig = RequestConfig.custom().setExpectContinueEnabled(true).build();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDMzOTMwOQ=="}, "originalCommit": {"oid": "6383ac8c537138e216ca6334b511dd127936c74a"}, "originalPosition": 146}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1MDQzOTczOnYy", "diffSide": "RIGHT", "path": "graylog2-server/src/main/java/org/graylog2/indexer/messages/Messages.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wOFQxNzo0MDozNFrOFbelwQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQxMTowMjo1NlrOFcQ9Kw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDM1NzA1Nw==", "bodyText": "I think this implementation assumes that the messages inside messageList are uniformly sized.\nLet's say we have a body limit of 10 MB and we have a messageList with message sizes of [1 MB, 1 MB, 1 MB, 10 MB]. If we run this, we will get a 413 for the first try and split the message list into two partitions. The first partition (two messages) will be successfully written to ES but for the second partition we will get a 413 response from ES again. Then we throw an EntityTooLargeException and start over indexing all messages again.\nThis will result in duplicated messages.\nOne possible solution could be to store the offset of the successfully written messages in the EntityTooLargeException and then use List#subList() to only pass in the remaining messages into bulkIndexChunked().\nThis would still not handle the issue that failedItems of successful bulk requests would be lost. (we could include them in the exception as well...)\nThere might be a better way.", "url": "https://github.com/Graylog2/graylog2-server/pull/7071#discussion_r364357057", "createdAt": "2020-01-08T17:40:34Z", "author": {"login": "bernd"}, "path": "graylog2-server/src/main/java/org/graylog2/indexer/messages/Messages.java", "diffHunk": "@@ -137,40 +142,88 @@ public ResultMessage get(String messageId, String index) throws DocumentNotFound\n             return Collections.emptyList();\n         }\n \n-        final Bulk.Builder bulk = new Bulk.Builder();\n-        for (Map.Entry<IndexSet, Message> entry : messageList) {\n-            final Message message = entry.getValue();\n-            if (isSystemTraffic) {\n-                systemTrafficCounter.inc(message.getSize());\n-            } else {\n-                outputByteCounter.inc(message.getSize());\n+        int chunkSize = messageList.size();\n+        List<BulkResult.BulkResultItem> failedItems = new ArrayList<>();\n+        for (;;) {\n+            try {\n+                failedItems = bulkIndexChunked(messageList, isSystemTraffic, chunkSize);\n+                break; // on success\n+            } catch (EntityTooLargeException e) {\n+                LOG.warn(\"Bulk index failed with 'Request Entity Too Large' error. Retrying by splitting up batch size <{}>.\", chunkSize);\n+                if (chunkSize == messageList.size()) {\n+                    LOG.warn(\"Consider lowering the \\\"output_batch_size\\\" setting.\");\n+                }\n+                chunkSize /= 2;\n+            }\n+            if (chunkSize == 0) {\n+                throw new ElasticsearchException(\"Bulk index cannot split output batch any further.\");\n             }\n-\n-            bulk.addAction(new Index.Builder(message.toElasticSearchObject(invalidTimestampMeter))\n-                .index(entry.getKey().getWriteIndexAlias())\n-                .type(IndexMapping.TYPE_MESSAGE)\n-                .id(message.getId())\n-                .build());\n         }\n \n-        final BulkResult result = runBulkRequest(bulk.build(), messageList.size());\n-        final List<BulkResult.BulkResultItem> failedItems = result.getFailedItems();\n-\n-        if (LOG.isDebugEnabled()) {\n-            LOG.debug(\"Index: Bulk indexed {} messages, took {} ms, failures: {}\",\n-                    result.getItems().size(), result, failedItems.size());\n-        }\n \n         if (!failedItems.isEmpty()) {\n             final Set<String> failedIds = failedItems.stream().map(item -> item.id).collect(Collectors.toSet());\n             recordTimestamp(messageList, failedIds);\n-            return propagateFailure(failedItems, messageList, result.getErrorMessage());\n+            return propagateFailure(failedItems, messageList);\n         } else {\n             recordTimestamp(messageList, Collections.emptySet());\n             return Collections.emptyList();\n         }\n     }\n \n+    private List<BulkResult.BulkResultItem> bulkIndexChunked(final List<Map.Entry<IndexSet, Message>> messageList, boolean isSystemTraffic, int chunkSize) throws EntityTooLargeException {\n+        chunkSize = Math.min(messageList.size(), chunkSize);\n+\n+        final List<BulkResult.BulkResultItem> failedItems = new ArrayList<>();\n+        final Iterable<List<Map.Entry<IndexSet, Message>>> partition = Iterables.partition(messageList, chunkSize);\n+        int partitionCount = 1;\n+        for (List<Map.Entry<IndexSet, Message>> subMessageList: partition) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6383ac8c537138e216ca6334b511dd127936c74a"}, "originalPosition": 90}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTE4MjI1MQ==", "bodyText": "Good catch! I've made some changes to handle this.", "url": "https://github.com/Graylog2/graylog2-server/pull/7071#discussion_r365182251", "createdAt": "2020-01-10T11:02:56Z", "author": {"login": "mpfz0r"}, "path": "graylog2-server/src/main/java/org/graylog2/indexer/messages/Messages.java", "diffHunk": "@@ -137,40 +142,88 @@ public ResultMessage get(String messageId, String index) throws DocumentNotFound\n             return Collections.emptyList();\n         }\n \n-        final Bulk.Builder bulk = new Bulk.Builder();\n-        for (Map.Entry<IndexSet, Message> entry : messageList) {\n-            final Message message = entry.getValue();\n-            if (isSystemTraffic) {\n-                systemTrafficCounter.inc(message.getSize());\n-            } else {\n-                outputByteCounter.inc(message.getSize());\n+        int chunkSize = messageList.size();\n+        List<BulkResult.BulkResultItem> failedItems = new ArrayList<>();\n+        for (;;) {\n+            try {\n+                failedItems = bulkIndexChunked(messageList, isSystemTraffic, chunkSize);\n+                break; // on success\n+            } catch (EntityTooLargeException e) {\n+                LOG.warn(\"Bulk index failed with 'Request Entity Too Large' error. Retrying by splitting up batch size <{}>.\", chunkSize);\n+                if (chunkSize == messageList.size()) {\n+                    LOG.warn(\"Consider lowering the \\\"output_batch_size\\\" setting.\");\n+                }\n+                chunkSize /= 2;\n+            }\n+            if (chunkSize == 0) {\n+                throw new ElasticsearchException(\"Bulk index cannot split output batch any further.\");\n             }\n-\n-            bulk.addAction(new Index.Builder(message.toElasticSearchObject(invalidTimestampMeter))\n-                .index(entry.getKey().getWriteIndexAlias())\n-                .type(IndexMapping.TYPE_MESSAGE)\n-                .id(message.getId())\n-                .build());\n         }\n \n-        final BulkResult result = runBulkRequest(bulk.build(), messageList.size());\n-        final List<BulkResult.BulkResultItem> failedItems = result.getFailedItems();\n-\n-        if (LOG.isDebugEnabled()) {\n-            LOG.debug(\"Index: Bulk indexed {} messages, took {} ms, failures: {}\",\n-                    result.getItems().size(), result, failedItems.size());\n-        }\n \n         if (!failedItems.isEmpty()) {\n             final Set<String> failedIds = failedItems.stream().map(item -> item.id).collect(Collectors.toSet());\n             recordTimestamp(messageList, failedIds);\n-            return propagateFailure(failedItems, messageList, result.getErrorMessage());\n+            return propagateFailure(failedItems, messageList);\n         } else {\n             recordTimestamp(messageList, Collections.emptySet());\n             return Collections.emptyList();\n         }\n     }\n \n+    private List<BulkResult.BulkResultItem> bulkIndexChunked(final List<Map.Entry<IndexSet, Message>> messageList, boolean isSystemTraffic, int chunkSize) throws EntityTooLargeException {\n+        chunkSize = Math.min(messageList.size(), chunkSize);\n+\n+        final List<BulkResult.BulkResultItem> failedItems = new ArrayList<>();\n+        final Iterable<List<Map.Entry<IndexSet, Message>>> partition = Iterables.partition(messageList, chunkSize);\n+        int partitionCount = 1;\n+        for (List<Map.Entry<IndexSet, Message>> subMessageList: partition) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDM1NzA1Nw=="}, "originalCommit": {"oid": "6383ac8c537138e216ca6334b511dd127936c74a"}, "originalPosition": 90}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI1MDQ3NTQzOnYy", "diffSide": "RIGHT", "path": "graylog2-server/src/main/java/org/graylog2/outputs/ElasticSearchOutput.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wOFQxNzo1NDowNVrOFbe8sg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xMFQxMTowMzo1NVrOFcQ-rg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDM2MjkzMA==", "bodyText": "I think we don't exclude the failed IDs because we don't know if we can retry the failed messages. If we have a message that couldn't be written to ES due to a data type error and we don't commit its offset, then it will be retried over and over again. Okay, in practice it will most probably not because that would require the message to be the last one.\nBut then it also doesn't make sense to exclude the offset either because if the faulty message is in the middle of a batch and we commit the last offset, it's gone anyway.", "url": "https://github.com/Graylog2/graylog2-server/pull/7071#discussion_r364362930", "createdAt": "2020-01-08T17:54:05Z", "author": {"login": "bernd"}, "path": "graylog2-server/src/main/java/org/graylog2/outputs/ElasticSearchOutput.java", "diffHunk": "@@ -112,6 +112,7 @@ public void writeMessageEntries(List<Map.Entry<IndexSet, Message>> messageList)\n         }\n         failures.mark(failedMessageIds.size());\n \n+        // TODO why doesn't this exclude the failedMessageIds?", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6383ac8c537138e216ca6334b511dd127936c74a"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NTE4MjYzOA==", "bodyText": "fair enough. should I add that to the comment?", "url": "https://github.com/Graylog2/graylog2-server/pull/7071#discussion_r365182638", "createdAt": "2020-01-10T11:03:55Z", "author": {"login": "mpfz0r"}, "path": "graylog2-server/src/main/java/org/graylog2/outputs/ElasticSearchOutput.java", "diffHunk": "@@ -112,6 +112,7 @@ public void writeMessageEntries(List<Map.Entry<IndexSet, Message>> messageList)\n         }\n         failures.mark(failedMessageIds.size());\n \n+        // TODO why doesn't this exclude the failedMessageIds?", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDM2MjkzMA=="}, "originalCommit": {"oid": "6383ac8c537138e216ca6334b511dd127936c74a"}, "originalPosition": 4}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3968, "cost": 1, "resetAt": "2021-11-12T20:28:25Z"}}}