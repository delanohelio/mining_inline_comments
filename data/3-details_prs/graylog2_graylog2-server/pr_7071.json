{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzU4NjI3MjQy", "number": 7071, "title": "Handle Request Entity Too Large errors in ElasticSearchOutput", "bodyText": "If we try to bulk index a batch of messages that exceeds the\nelastic search http.max_content_length setting. (default 100MB)\nElastic will respond with an HTTP 413 Entity Too Large error.\nIn this case we retry the request by splitting the message batch\nin half.\nWhen responding with an HTTP 413 error, the server is allowed to close the connection\nimmediately. This means that our HTTP client (Jest) will simply report\nan IOException (Broken pipe) instead of the actual error.\nThis can be avoided by sending the request with an Expect-Continue\nheader, which also avoids sending data that will be discarded later on.\nFixes #5091\nFixes #6965", "createdAt": "2020-01-02T11:21:42Z", "url": "https://github.com/Graylog2/graylog2-server/pull/7071", "merged": true, "mergeCommit": {"oid": "085930aa59ff3087d446efbf8f95bb735cae296e"}, "closed": true, "closedAt": "2020-01-10T17:33:24Z", "author": {"login": "mpfz0r"}, "timelineItems": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABb2w5NLABqjI5MjA2MjEyMjg=", "endCursor": "Y3Vyc29yOnYyOpPPAAABb5CDnHAFqTM0MTMxNDU4OA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "4a88d56f6e15b27fd02ef3f4a4f69af697ee915a", "author": {"user": {"login": "mpfz0r", "name": "Marco Pfatschbacher"}}, "url": "https://github.com/Graylog2/graylog2-server/commit/4a88d56f6e15b27fd02ef3f4a4f69af697ee915a", "committedDate": "2020-01-02T11:19:07Z", "message": "Handle Request Entity Too Large errors in ElasticSearchOutput\n\nIf we try to bulk index a batch of messages that exceeds the\nelastic search `bulk_max_body_size` setting. (default 100MB)\nElastic will respond with an HTTP 413 Entity Too Large error.\n\nIn this case we retry the request by splitting the message batch\nin half.\n\nWhen responding with an HTTP 413 error, the server is allowed to close the connection\nimmediately. This means that our HTTP client (Jest) will simply report\nan IOException (Broken pipe) instead of the actual error.\nThis can be avoided by sending the request with an Expect-Continue\nheader, which also avoids sending data that will be discarded later on.\n\nFixes #5091"}, "afterCommit": {"oid": "7facbb2b0ebf33bc8e587f60c1ab322b865f6e83", "author": {"user": {"login": "mpfz0r", "name": "Marco Pfatschbacher"}}, "url": "https://github.com/Graylog2/graylog2-server/commit/7facbb2b0ebf33bc8e587f60c1ab322b865f6e83", "committedDate": "2020-01-03T16:24:34Z", "message": "Handle Request Entity Too Large errors in ElasticSearchOutput\n\nIf we try to bulk index a batch of messages that exceeds the\nelastic search `bulk_max_body_size` setting. (default 100MB)\nElastic will respond with an HTTP 413 Entity Too Large error.\n\nIn this case we retry the request by splitting the message batch\nin half.\n\nWhen responding with an HTTP 413 error, the server is allowed to close the connection\nimmediately. This means that our HTTP client (Jest) will simply report\nan IOException (Broken pipe) instead of the actual error.\nThis can be avoided by sending the request with an Expect-Continue\nheader, which also avoids sending data that will be discarded later on.\n\nFixes #5091"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzM4ODAzNzg3", "url": "https://github.com/Graylog2/graylog2-server/pull/7071#pullrequestreview-338803787", "createdAt": "2020-01-06T18:13:02Z", "commit": {"oid": "7facbb2b0ebf33bc8e587f60c1ab322b865f6e83"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQwMDA3NDk0", "url": "https://github.com/Graylog2/graylog2-server/pull/7071#pullrequestreview-340007494", "createdAt": "2020-01-08T17:00:36Z", "commit": {"oid": "6383ac8c537138e216ca6334b511dd127936c74a"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wOFQxNzowMDozN1rOFbdgbQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0wOFQxNzo1NDowNVrOFbe8sg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDMzOTMwOQ==", "bodyText": "I noticed the following in the documentation for RequestConfig#isExpectContinueEnabled():\n\n'Expect: 100-continue' handshake should be used with caution, as it may cause problems with HTTP servers and proxies that do not support HTTP/1.1 protocol.\n\nSo I wonder if we should make this configurable in graylog.conf? (default: enabled) Otherwise we cannot do anything if a user has a broken proxy in front of Elasticsearch.", "url": "https://github.com/Graylog2/graylog2-server/pull/7071#discussion_r364339309", "createdAt": "2020-01-08T17:00:37Z", "author": {"login": "bernd"}, "path": "graylog2-server/src/main/java/org/graylog2/indexer/messages/Messages.java", "diffHunk": "@@ -185,7 +238,9 @@ private void recordTimestamp(List<Map.Entry<IndexSet, Message>> messageList, Set\n \n     private BulkResult runBulkRequest(final Bulk request, int count) {\n         try {\n-            return BULK_REQUEST_RETRYER.call(() -> client.execute(request));\n+            // Enable Expect-Continue to catch 413 errors before we send the actual data\n+            final RequestConfig requestConfig = RequestConfig.custom().setExpectContinueEnabled(true).build();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6383ac8c537138e216ca6334b511dd127936c74a"}, "originalPosition": 146}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDM1NzA1Nw==", "bodyText": "I think this implementation assumes that the messages inside messageList are uniformly sized.\nLet's say we have a body limit of 10 MB and we have a messageList with message sizes of [1 MB, 1 MB, 1 MB, 10 MB]. If we run this, we will get a 413 for the first try and split the message list into two partitions. The first partition (two messages) will be successfully written to ES but for the second partition we will get a 413 response from ES again. Then we throw an EntityTooLargeException and start over indexing all messages again.\nThis will result in duplicated messages.\nOne possible solution could be to store the offset of the successfully written messages in the EntityTooLargeException and then use List#subList() to only pass in the remaining messages into bulkIndexChunked().\nThis would still not handle the issue that failedItems of successful bulk requests would be lost. (we could include them in the exception as well...)\nThere might be a better way.", "url": "https://github.com/Graylog2/graylog2-server/pull/7071#discussion_r364357057", "createdAt": "2020-01-08T17:40:34Z", "author": {"login": "bernd"}, "path": "graylog2-server/src/main/java/org/graylog2/indexer/messages/Messages.java", "diffHunk": "@@ -137,40 +142,88 @@ public ResultMessage get(String messageId, String index) throws DocumentNotFound\n             return Collections.emptyList();\n         }\n \n-        final Bulk.Builder bulk = new Bulk.Builder();\n-        for (Map.Entry<IndexSet, Message> entry : messageList) {\n-            final Message message = entry.getValue();\n-            if (isSystemTraffic) {\n-                systemTrafficCounter.inc(message.getSize());\n-            } else {\n-                outputByteCounter.inc(message.getSize());\n+        int chunkSize = messageList.size();\n+        List<BulkResult.BulkResultItem> failedItems = new ArrayList<>();\n+        for (;;) {\n+            try {\n+                failedItems = bulkIndexChunked(messageList, isSystemTraffic, chunkSize);\n+                break; // on success\n+            } catch (EntityTooLargeException e) {\n+                LOG.warn(\"Bulk index failed with 'Request Entity Too Large' error. Retrying by splitting up batch size <{}>.\", chunkSize);\n+                if (chunkSize == messageList.size()) {\n+                    LOG.warn(\"Consider lowering the \\\"output_batch_size\\\" setting.\");\n+                }\n+                chunkSize /= 2;\n+            }\n+            if (chunkSize == 0) {\n+                throw new ElasticsearchException(\"Bulk index cannot split output batch any further.\");\n             }\n-\n-            bulk.addAction(new Index.Builder(message.toElasticSearchObject(invalidTimestampMeter))\n-                .index(entry.getKey().getWriteIndexAlias())\n-                .type(IndexMapping.TYPE_MESSAGE)\n-                .id(message.getId())\n-                .build());\n         }\n \n-        final BulkResult result = runBulkRequest(bulk.build(), messageList.size());\n-        final List<BulkResult.BulkResultItem> failedItems = result.getFailedItems();\n-\n-        if (LOG.isDebugEnabled()) {\n-            LOG.debug(\"Index: Bulk indexed {} messages, took {} ms, failures: {}\",\n-                    result.getItems().size(), result, failedItems.size());\n-        }\n \n         if (!failedItems.isEmpty()) {\n             final Set<String> failedIds = failedItems.stream().map(item -> item.id).collect(Collectors.toSet());\n             recordTimestamp(messageList, failedIds);\n-            return propagateFailure(failedItems, messageList, result.getErrorMessage());\n+            return propagateFailure(failedItems, messageList);\n         } else {\n             recordTimestamp(messageList, Collections.emptySet());\n             return Collections.emptyList();\n         }\n     }\n \n+    private List<BulkResult.BulkResultItem> bulkIndexChunked(final List<Map.Entry<IndexSet, Message>> messageList, boolean isSystemTraffic, int chunkSize) throws EntityTooLargeException {\n+        chunkSize = Math.min(messageList.size(), chunkSize);\n+\n+        final List<BulkResult.BulkResultItem> failedItems = new ArrayList<>();\n+        final Iterable<List<Map.Entry<IndexSet, Message>>> partition = Iterables.partition(messageList, chunkSize);\n+        int partitionCount = 1;\n+        for (List<Map.Entry<IndexSet, Message>> subMessageList: partition) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6383ac8c537138e216ca6334b511dd127936c74a"}, "originalPosition": 90}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NDM2MjkzMA==", "bodyText": "I think we don't exclude the failed IDs because we don't know if we can retry the failed messages. If we have a message that couldn't be written to ES due to a data type error and we don't commit its offset, then it will be retried over and over again. Okay, in practice it will most probably not because that would require the message to be the last one.\nBut then it also doesn't make sense to exclude the offset either because if the faulty message is in the middle of a batch and we commit the last offset, it's gone anyway.", "url": "https://github.com/Graylog2/graylog2-server/pull/7071#discussion_r364362930", "createdAt": "2020-01-08T17:54:05Z", "author": {"login": "bernd"}, "path": "graylog2-server/src/main/java/org/graylog2/outputs/ElasticSearchOutput.java", "diffHunk": "@@ -112,6 +112,7 @@ public void writeMessageEntries(List<Map.Entry<IndexSet, Message>> messageList)\n         }\n         failures.mark(failedMessageIds.size());\n \n+        // TODO why doesn't this exclude the failedMessageIds?", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6383ac8c537138e216ca6334b511dd127936c74a"}, "originalPosition": 4}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e95fb74d6592e9d1cdc188e1a80ee72db52fb555", "author": {"user": {"login": "mpfz0r", "name": "Marco Pfatschbacher"}}, "url": "https://github.com/Graylog2/graylog2-server/commit/e95fb74d6592e9d1cdc188e1a80ee72db52fb555", "committedDate": "2020-01-10T12:50:29Z", "message": "Handle Request Entity Too Large errors in ElasticSearchOutput\n\nIf we try to bulk index a batch of messages that exceeds the\nelastic search `http.max_content_length` setting. (default 100MB)\nElastic will respond with an HTTP 413 Entity Too Large error.\n\nIn this case we retry the request by splitting the message batch\nin half.\n\nWhen responding with an HTTP 413 error, the server is allowed to close the connection\nimmediately. This means that our HTTP client (Jest) will simply report\nan IOException (Broken pipe) instead of the actual error.\nThis can be avoided by sending the request with an Expect-Continue\nheader, which also avoids sending data that will be discarded later on.\n\nFixes #5091"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "23bd997806c78e6a5767362989e01f57642e2f13", "author": {"user": {"login": "mpfz0r", "name": "Marco Pfatschbacher"}}, "url": "https://github.com/Graylog2/graylog2-server/commit/23bd997806c78e6a5767362989e01f57642e2f13", "committedDate": "2020-01-10T12:51:24Z", "message": "Please forbiddenapi checker"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5c358f7505b1db2f0493d533783dfd6dc5c5073a", "author": {"user": {"login": "mpfz0r", "name": "Marco Pfatschbacher"}}, "url": "https://github.com/Graylog2/graylog2-server/commit/5c358f7505b1db2f0493d533783dfd6dc5c5073a", "committedDate": "2020-01-10T12:51:24Z", "message": "Try splitting up batch until we reach size 1"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bce63d3266338e2a0f6a8c2e7cccd9fa523e3b8a", "author": {"user": {"login": "mpfz0r", "name": "Marco Pfatschbacher"}}, "url": "https://github.com/Graylog2/graylog2-server/commit/bce63d3266338e2a0f6a8c2e7cccd9fa523e3b8a", "committedDate": "2020-01-10T12:51:24Z", "message": "Move JestClient execution with RequestConfig into JestUtils"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "462e9d841d94fe542b3bf28c47460f25e914de2d", "author": {"user": {"login": "mpfz0r", "name": "Marco Pfatschbacher"}}, "url": "https://github.com/Graylog2/graylog2-server/commit/462e9d841d94fe542b3bf28c47460f25e914de2d", "committedDate": "2020-01-10T12:51:24Z", "message": "Please forbiddenapi checker"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a6bd60c395bb171f9aa283db30b2c4bcd87a8785", "author": {"user": {"login": "mpfz0r", "name": "Marco Pfatschbacher"}}, "url": "https://github.com/Graylog2/graylog2-server/commit/a6bd60c395bb171f9aa283db30b2c4bcd87a8785", "committedDate": "2020-01-10T12:51:24Z", "message": "Correctly handle batches with unevenly sized messages\n\nIf we have a batch where only the messages at the end will\nexceed the Entity Too Large limit, we could end up duplicating\nmessages.\nThus keep track of the already indexed offset and report it within the\nEntityTooLargeException."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "69edda28c43f6d3eb1e9e27da3a6ca448a34f378", "author": {"user": {"login": "mpfz0r", "name": "Marco Pfatschbacher"}}, "url": "https://github.com/Graylog2/graylog2-server/commit/69edda28c43f6d3eb1e9e27da3a6ca448a34f378", "committedDate": "2020-01-10T12:51:24Z", "message": "Make use of Expect: 100-continue header configurable"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9d4a0e115b831bfac000504f64bf93f6254a573d", "author": {"user": {"login": "mpfz0r", "name": "Marco Pfatschbacher"}}, "url": "https://github.com/Graylog2/graylog2-server/commit/9d4a0e115b831bfac000504f64bf93f6254a573d", "committedDate": "2020-01-10T10:57:04Z", "message": "Correctly handle batches with unevenly sized messages\n\nIf we have a batch where only the messages at the end will\nexceed the Entity Too Large limit, we could end up duplicating\nmessages.\nThus keep track of the already indexed offset and report it within the\nEntityTooLargeException."}, "afterCommit": {"oid": "69edda28c43f6d3eb1e9e27da3a6ca448a34f378", "author": {"user": {"login": "mpfz0r", "name": "Marco Pfatschbacher"}}, "url": "https://github.com/Graylog2/graylog2-server/commit/69edda28c43f6d3eb1e9e27da3a6ca448a34f378", "committedDate": "2020-01-10T12:51:24Z", "message": "Make use of Expect: 100-continue header configurable"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9f62a04797ba49bd13f10853be52d29efcf2d356", "author": {"user": {"login": "mpfz0r", "name": "Marco Pfatschbacher"}}, "url": "https://github.com/Graylog2/graylog2-server/commit/9f62a04797ba49bd13f10853be52d29efcf2d356", "committedDate": "2020-01-10T13:31:21Z", "message": "clarify comment"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "203cf38c26e4d621bac992f9e29bc8268e56df18", "author": {"user": {"login": "mpfz0r", "name": "Marco Pfatschbacher"}}, "url": "https://github.com/Graylog2/graylog2-server/commit/203cf38c26e4d621bac992f9e29bc8268e56df18", "committedDate": "2020-01-10T15:00:42Z", "message": "Don't loose failedItems if we hit the error path twice"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQxMzE0NTg4", "url": "https://github.com/Graylog2/graylog2-server/pull/7071#pullrequestreview-341314588", "createdAt": "2020-01-10T17:32:23Z", "commit": {"oid": "203cf38c26e4d621bac992f9e29bc8268e56df18"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2762, "cost": 1, "resetAt": "2021-10-28T18:54:27Z"}}}