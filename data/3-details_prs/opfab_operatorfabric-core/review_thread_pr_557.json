{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTEyMjg3NTc2", "number": 557, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMlQwODowNzo0M1rOE0RMYQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMlQwODoyMDo0NFrOE0Rb1g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIzMjQzMTA1OnYy", "diffSide": "RIGHT", "path": "src/docs/asciidoc/deployment/configuration/configuration.adoc", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMlQwODowNzo0M1rOHr5vSg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMlQxMToxMDo1NVrOHsAC2A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTc5NjgxMA==", "bodyText": "Er is ook een default topic naam. Het enige wat je hoeft te doen om Kafka te enabelen is de property spring.kafka.consumer.group_id een waarde te geven. Hier kan je een willekeurige naam opgeven", "url": "https://github.com/opfab/operatorfabric-core/pull/557#discussion_r515796810", "createdAt": "2020-11-02T08:07:43Z", "author": {"login": "sadema"}, "path": "src/docs/asciidoc/deployment/configuration/configuration.adoc", "diffHunk": "@@ -136,3 +141,23 @@ db.archivedCards.createIndex( { \"publishDate\": 1 }, { expireAfterSeconds: 864000\n IMPORTANT: You cannot use createIndex() to change the value of expireAfterSeconds of an existing index.\n Instead use the link:https://docs.mongodb.com/manual/reference/command/collMod/#dbcmd.collMod[collMod] database command in conjunction with the index collection flag. Otherwise, to\n change the value of the option of an existing index, you must drop the index first and recreate.\n+\n+== OperatorFabric Kafka configuration\n+\n+Next to publishing cards to OperatorFabric using the REST API, OperatorFabric also supports publishing cards via a Kafka Topic. In the default configuration Kafka is disabled.\n+To enable Kafka you need to set the topic name for which the Kafka consumer can consume messages. You can do this", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "15209c20fa12ba49e4f18d771500ed9eda1669ff"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTkwMDEyMA==", "bodyText": "Yep. Foutje..", "url": "https://github.com/opfab/operatorfabric-core/pull/557#discussion_r515900120", "createdAt": "2020-11-02T11:10:55Z", "author": {"login": "JeroenGommans"}, "path": "src/docs/asciidoc/deployment/configuration/configuration.adoc", "diffHunk": "@@ -136,3 +141,23 @@ db.archivedCards.createIndex( { \"publishDate\": 1 }, { expireAfterSeconds: 864000\n IMPORTANT: You cannot use createIndex() to change the value of expireAfterSeconds of an existing index.\n Instead use the link:https://docs.mongodb.com/manual/reference/command/collMod/#dbcmd.collMod[collMod] database command in conjunction with the index collection flag. Otherwise, to\n change the value of the option of an existing index, you must drop the index first and recreate.\n+\n+== OperatorFabric Kafka configuration\n+\n+Next to publishing cards to OperatorFabric using the REST API, OperatorFabric also supports publishing cards via a Kafka Topic. In the default configuration Kafka is disabled.\n+To enable Kafka you need to set the topic name for which the Kafka consumer can consume messages. You can do this", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTc5NjgxMA=="}, "originalCommit": {"oid": "15209c20fa12ba49e4f18d771500ed9eda1669ff"}, "originalPosition": 36}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIzMjQ2MDg2OnYy", "diffSide": "RIGHT", "path": "src/docs/asciidoc/dev_env/kafka.adoc", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMlQwODoxNzo0M1rOHr6A1A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMlQxMjo0NDo0N1rOHsC18g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTgwMTMwMA==", "bodyText": "Er wordt uitgegaan van dat de brokers draaien op PLAINTEXT://127.0.0.1:9092 en dat er een schema registry draait op http://127.0.0.1:8081", "url": "https://github.com/opfab/operatorfabric-core/pull/557#discussion_r515801300", "createdAt": "2020-11-02T08:17:43Z", "author": {"login": "sadema"}, "path": "src/docs/asciidoc/dev_env/kafka.adoc", "diffHunk": "@@ -0,0 +1,112 @@\n+// Copyright (c) 2018-2020 RTE (http://www.rte-france.com)\n+// See AUTHORS.txt\n+// This document is subject to the terms of the Creative Commons Attribution 4.0 International license.\n+// If a copy of the license was not distributed with this\n+// file, You can obtain one at https://creativecommons.org/licenses/by/4.0/.\n+// SPDX-License-Identifier: CC-BY-4.0\n+\n+:kafka_schema: https://docs.confluent.io/current/schema-registry/index.html\n+:confluent: https://www.confluent.io/\n+:spring_kafka_doc: https://docs.spring.io/spring-kafka/reference/html/\n+\n+= Kafka Implementation\n+\n+Next to publishing cards to OperatorFabric using the REST API, OperatorFabric also supports publishing cards via a Kafka Topic. In the default configuration Kafka is disabled.\n+\n+\n+== Enabling Kafka\n+\n+To enable Kafka support you need to set the `kafka.consumer.group_id property` in the cards-publication yml file:\n+[source,yaml]\n+----\n+  kafka:\n+    consumer:\n+      group-id: opfab-command\n+----\n+\n+Alternatively you can set the group id in the `config/docker/kafka-env.properties` file:\n+[source, shell]\n+----\n+SPRING_KAFKA_CONSUMER_GROUP_ID=opfab-command\n+----\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "15209c20fa12ba49e4f18d771500ed9eda1669ff"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTk0NTk3MA==", "bodyText": "Check!. Heb nu ook spring.kafka.producer.bootstrap-servers  meegenomen in de settings.", "url": "https://github.com/opfab/operatorfabric-core/pull/557#discussion_r515945970", "createdAt": "2020-11-02T12:44:47Z", "author": {"login": "JeroenGommans"}, "path": "src/docs/asciidoc/dev_env/kafka.adoc", "diffHunk": "@@ -0,0 +1,112 @@\n+// Copyright (c) 2018-2020 RTE (http://www.rte-france.com)\n+// See AUTHORS.txt\n+// This document is subject to the terms of the Creative Commons Attribution 4.0 International license.\n+// If a copy of the license was not distributed with this\n+// file, You can obtain one at https://creativecommons.org/licenses/by/4.0/.\n+// SPDX-License-Identifier: CC-BY-4.0\n+\n+:kafka_schema: https://docs.confluent.io/current/schema-registry/index.html\n+:confluent: https://www.confluent.io/\n+:spring_kafka_doc: https://docs.spring.io/spring-kafka/reference/html/\n+\n+= Kafka Implementation\n+\n+Next to publishing cards to OperatorFabric using the REST API, OperatorFabric also supports publishing cards via a Kafka Topic. In the default configuration Kafka is disabled.\n+\n+\n+== Enabling Kafka\n+\n+To enable Kafka support you need to set the `kafka.consumer.group_id property` in the cards-publication yml file:\n+[source,yaml]\n+----\n+  kafka:\n+    consumer:\n+      group-id: opfab-command\n+----\n+\n+Alternatively you can set the group id in the `config/docker/kafka-env.properties` file:\n+[source, shell]\n+----\n+SPRING_KAFKA_CONSUMER_GROUP_ID=opfab-command\n+----\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTgwMTMwMA=="}, "originalCommit": {"oid": "15209c20fa12ba49e4f18d771500ed9eda1669ff"}, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIzMjQ3MDYyOnYy", "diffSide": "RIGHT", "path": "src/docs/asciidoc/dev_env/kafka.adoc", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMlQwODoyMDo0NFrOHr6Gfw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMlQwODoyMDo0NFrOHr6Gfw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTgwMjc1MQ==", "bodyText": "Ik zou hier alleen zeggen hoe je de deserizalizer configureert wanneer je geen schemaregistry wilt gebruiken", "url": "https://github.com/opfab/operatorfabric-core/pull/557#discussion_r515802751", "createdAt": "2020-11-02T08:20:44Z", "author": {"login": "sadema"}, "path": "src/docs/asciidoc/dev_env/kafka.adoc", "diffHunk": "@@ -0,0 +1,112 @@\n+// Copyright (c) 2018-2020 RTE (http://www.rte-france.com)\n+// See AUTHORS.txt\n+// This document is subject to the terms of the Creative Commons Attribution 4.0 International license.\n+// If a copy of the license was not distributed with this\n+// file, You can obtain one at https://creativecommons.org/licenses/by/4.0/.\n+// SPDX-License-Identifier: CC-BY-4.0\n+\n+:kafka_schema: https://docs.confluent.io/current/schema-registry/index.html\n+:confluent: https://www.confluent.io/\n+:spring_kafka_doc: https://docs.spring.io/spring-kafka/reference/html/\n+\n+= Kafka Implementation\n+\n+Next to publishing cards to OperatorFabric using the REST API, OperatorFabric also supports publishing cards via a Kafka Topic. In the default configuration Kafka is disabled.\n+\n+\n+== Enabling Kafka\n+\n+To enable Kafka support you need to set the `kafka.consumer.group_id property` in the cards-publication yml file:\n+[source,yaml]\n+----\n+  kafka:\n+    consumer:\n+      group-id: opfab-command\n+----\n+\n+Alternatively you can set the group id in the `config/docker/kafka-env.properties` file:\n+[source, shell]\n+----\n+SPRING_KAFKA_CONSUMER_GROUP_ID=opfab-command\n+----\n+\n+Make sure you also set the registry to either an empty string (`\"\"`) or to the server providing the schema registry service.\n+See link:{kafka_schema}[Schema management] for detailed information on using and benefits of a schema registry.\n+\n+== OperatorFabric Kafka source code\n+== Listener / deserializer\n+Most of the OperatorFabric Kafka implementation can be found at\n+\n+`org.lfenergy.operatorfabric.cards.publication.kafka`:: for\n+the implementation of the deserializers and mapping of Kafka topics to OperatorFabric cards and\n+`org.lfenergy.operatorfabric.autoconfigure.kafka` ::\n+for the various Kafka configuration options.\n+\n+=== Kafka OperatorFabric AVRO schema\n+The AVRO schema, the byte format in which messages are transffered using Kafka topics, can be found at `client/src/main/avro`.\n+Message are wrapped in a the CardCommand object before being sent to a Kafka topic.\n+This object is an almost one-to-one mapping of the OperatorFabric card, see also <<card_structure>>. The exceptions are  `Process` and\n+`Process Instance Identifier`, which are moved to the top-level CardCommand.\n+\n+\n+== Configure Kafka\n+=== Setting a new deserializer\n+By default, OperatorFabric uses the  `io.confluent.kafka.serializers.KafkaAvroDeserializer` from link:{confluent}[Confluent]. However, you can write your own\n+deserializer. An example deserializer, which ignores the schema registry, is included.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "15209c20fa12ba49e4f18d771500ed9eda1669ff"}, "originalPosition": 55}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 926, "cost": 1, "resetAt": "2021-11-13T12:10:21Z"}}}