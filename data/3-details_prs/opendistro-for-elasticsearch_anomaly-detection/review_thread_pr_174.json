{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDM5Mjk4NDk3", "number": 174, "reviewThreads": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQxNjo1NToxM1rOEIczpw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQyMToxNzo1M1rOEIiEQg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3Mjk2MDM5OnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/indices/AnomalyDetectionIndices.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQxNjo1NToxM1rOGoa5cg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQxODoxMTo0MFrOGodieg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTAzNjkxNA==", "bodyText": "Why put into two lines? How about we use logger.error(\"Fail to roll over result index\", exception); ? So we don't need to go to two lines when check log. There are maybe other request's log between these two lines, if check log manually, we need to skip other request's log.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/174#discussion_r445036914", "createdAt": "2020-06-24T16:55:13Z", "author": {"login": "ylwu-amzn"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/indices/AnomalyDetectionIndices.java", "diffHunk": "@@ -275,15 +285,86 @@ private boolean rolloverHistoryIndex() {\n             adResultMapping = getAnomalyResultMappings();\n         } catch (IOException e) {\n             logger.error(\"Fail to roll over AD result index, as can't get AD result index mapping\");\n-            return false;\n+            return;\n         }\n         request.getCreateIndexRequest().index(AD_RESULT_HISTORY_INDEX_PATTERN).mapping(MAPPING_TYPE, adResultMapping, XContentType.JSON);\n         request.addMaxIndexDocsCondition(historyMaxDocs);\n-        request.addMaxIndexAgeCondition(historyMaxAge);\n-        RolloverResponse response = adminClient.indices().rolloverIndex(request).actionGet(requestTimeout);\n-        if (!response.isRolledOver()) {\n-            logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+        adminClient.indices().rolloverIndex(request, ActionListener.wrap(response -> {\n+            if (!response.isRolledOver()) {\n+                logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+            } else {\n+                logger.info(\"{} rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+                deleteOldHistoryIndices();\n+            }\n+        }, exception -> {\n+            logger.error(\"Fail to roll over result index\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "020f509d2f882e619ce3fff3a05be41845be2126"}, "originalPosition": 137}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTA4MDE4Ng==", "bodyText": "good catch.  Fixed.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/174#discussion_r445080186", "createdAt": "2020-06-24T18:11:40Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/indices/AnomalyDetectionIndices.java", "diffHunk": "@@ -275,15 +285,86 @@ private boolean rolloverHistoryIndex() {\n             adResultMapping = getAnomalyResultMappings();\n         } catch (IOException e) {\n             logger.error(\"Fail to roll over AD result index, as can't get AD result index mapping\");\n-            return false;\n+            return;\n         }\n         request.getCreateIndexRequest().index(AD_RESULT_HISTORY_INDEX_PATTERN).mapping(MAPPING_TYPE, adResultMapping, XContentType.JSON);\n         request.addMaxIndexDocsCondition(historyMaxDocs);\n-        request.addMaxIndexAgeCondition(historyMaxAge);\n-        RolloverResponse response = adminClient.indices().rolloverIndex(request).actionGet(requestTimeout);\n-        if (!response.isRolledOver()) {\n-            logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+        adminClient.indices().rolloverIndex(request, ActionListener.wrap(response -> {\n+            if (!response.isRolledOver()) {\n+                logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+            } else {\n+                logger.info(\"{} rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+                deleteOldHistoryIndices();\n+            }\n+        }, exception -> {\n+            logger.error(\"Fail to roll over result index\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTAzNjkxNA=="}, "originalCommit": {"oid": "020f509d2f882e619ce3fff3a05be41845be2126"}, "originalPosition": 137}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3Mjk5MDc3OnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/indices/AnomalyDetectionIndices.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQxNzowMzoxMVrOGobMZg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxNjozMzowMVrOGpnSug==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTA0MTc2Ng==", "bodyText": "How about we just don't add latestToDelete to candidates  in the for loop above?", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/174#discussion_r445041766", "createdAt": "2020-06-24T17:03:11Z", "author": {"login": "ylwu-amzn"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/indices/AnomalyDetectionIndices.java", "diffHunk": "@@ -275,15 +285,86 @@ private boolean rolloverHistoryIndex() {\n             adResultMapping = getAnomalyResultMappings();\n         } catch (IOException e) {\n             logger.error(\"Fail to roll over AD result index, as can't get AD result index mapping\");\n-            return false;\n+            return;\n         }\n         request.getCreateIndexRequest().index(AD_RESULT_HISTORY_INDEX_PATTERN).mapping(MAPPING_TYPE, adResultMapping, XContentType.JSON);\n         request.addMaxIndexDocsCondition(historyMaxDocs);\n-        request.addMaxIndexAgeCondition(historyMaxAge);\n-        RolloverResponse response = adminClient.indices().rolloverIndex(request).actionGet(requestTimeout);\n-        if (!response.isRolledOver()) {\n-            logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+        adminClient.indices().rolloverIndex(request, ActionListener.wrap(response -> {\n+            if (!response.isRolledOver()) {\n+                logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+            } else {\n+                logger.info(\"{} rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+                deleteOldHistoryIndices();\n+            }\n+        }, exception -> {\n+            logger.error(\"Fail to roll over result index\");\n+            logger.error(exception);\n+        }));\n+    }\n+\n+    private void deleteOldHistoryIndices() {\n+        Set<String> candidates = new HashSet<String>();\n+\n+        ClusterStateRequest clusterStateRequest = new ClusterStateRequest()\n+            .clear()\n+            .indices(AnomalyDetectionIndices.ALL_AD_RESULTS_INDEX_PATTERN)\n+            .metadata(true)\n+            .local(true)\n+            .indicesOptions(IndicesOptions.strictExpand());\n+\n+        adminClient.cluster().state(clusterStateRequest, ActionListener.wrap(clusterStateResponse -> {\n+            String latestToDelete = null;\n+            long latest = Long.MIN_VALUE;\n+            for (ObjectCursor<IndexMetadata> cursor : clusterStateResponse.getState().metadata().indices().values()) {\n+                IndexMetadata indexMetaData = cursor.value;\n+                long creationTime = indexMetaData.getCreationDate();\n+\n+                if ((Instant.now().toEpochMilli() - creationTime) > historyRetentionPeriod.millis()) {\n+                    String indexName = indexMetaData.getIndex().getName();\n+                    candidates.add(indexName);\n+                    if (latest < creationTime) {\n+                        latest = creationTime;\n+                        latestToDelete = indexName;\n+                    }\n+                }\n+            }\n+\n+            if (candidates.size() > 1) {\n+                // delete all indices except the last one because the last one may contain docs newer than the retention period\n+                candidates.remove(latestToDelete);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "020f509d2f882e619ce3fff3a05be41845be2126"}, "originalPosition": 171}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTA3NjQ2Mw==", "bodyText": "How do we do that?  We don't know latestToDelete before looping through all indices.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/174#discussion_r445076463", "createdAt": "2020-06-24T18:04:47Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/indices/AnomalyDetectionIndices.java", "diffHunk": "@@ -275,15 +285,86 @@ private boolean rolloverHistoryIndex() {\n             adResultMapping = getAnomalyResultMappings();\n         } catch (IOException e) {\n             logger.error(\"Fail to roll over AD result index, as can't get AD result index mapping\");\n-            return false;\n+            return;\n         }\n         request.getCreateIndexRequest().index(AD_RESULT_HISTORY_INDEX_PATTERN).mapping(MAPPING_TYPE, adResultMapping, XContentType.JSON);\n         request.addMaxIndexDocsCondition(historyMaxDocs);\n-        request.addMaxIndexAgeCondition(historyMaxAge);\n-        RolloverResponse response = adminClient.indices().rolloverIndex(request).actionGet(requestTimeout);\n-        if (!response.isRolledOver()) {\n-            logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+        adminClient.indices().rolloverIndex(request, ActionListener.wrap(response -> {\n+            if (!response.isRolledOver()) {\n+                logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+            } else {\n+                logger.info(\"{} rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+                deleteOldHistoryIndices();\n+            }\n+        }, exception -> {\n+            logger.error(\"Fail to roll over result index\");\n+            logger.error(exception);\n+        }));\n+    }\n+\n+    private void deleteOldHistoryIndices() {\n+        Set<String> candidates = new HashSet<String>();\n+\n+        ClusterStateRequest clusterStateRequest = new ClusterStateRequest()\n+            .clear()\n+            .indices(AnomalyDetectionIndices.ALL_AD_RESULTS_INDEX_PATTERN)\n+            .metadata(true)\n+            .local(true)\n+            .indicesOptions(IndicesOptions.strictExpand());\n+\n+        adminClient.cluster().state(clusterStateRequest, ActionListener.wrap(clusterStateResponse -> {\n+            String latestToDelete = null;\n+            long latest = Long.MIN_VALUE;\n+            for (ObjectCursor<IndexMetadata> cursor : clusterStateResponse.getState().metadata().indices().values()) {\n+                IndexMetadata indexMetaData = cursor.value;\n+                long creationTime = indexMetaData.getCreationDate();\n+\n+                if ((Instant.now().toEpochMilli() - creationTime) > historyRetentionPeriod.millis()) {\n+                    String indexName = indexMetaData.getIndex().getName();\n+                    candidates.add(indexName);\n+                    if (latest < creationTime) {\n+                        latest = creationTime;\n+                        latestToDelete = indexName;\n+                    }\n+                }\n+            }\n+\n+            if (candidates.size() > 1) {\n+                // delete all indices except the last one because the last one may contain docs newer than the retention period\n+                candidates.remove(latestToDelete);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTA0MTc2Ng=="}, "originalCommit": {"oid": "020f509d2f882e619ce3fff3a05be41845be2126"}, "originalPosition": 171}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTE2OTE2OQ==", "bodyText": "Can we iterate indices reversely and ignore the first index which meet this condition (Instant.now().toEpochMilli() - creationTime) > historyRetentionPeriod.millis() ?\nThis is a minor suggestion. Ignore it if it's hard/impossible to do so.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/174#discussion_r445169169", "createdAt": "2020-06-24T21:00:44Z", "author": {"login": "ylwu-amzn"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/indices/AnomalyDetectionIndices.java", "diffHunk": "@@ -275,15 +285,86 @@ private boolean rolloverHistoryIndex() {\n             adResultMapping = getAnomalyResultMappings();\n         } catch (IOException e) {\n             logger.error(\"Fail to roll over AD result index, as can't get AD result index mapping\");\n-            return false;\n+            return;\n         }\n         request.getCreateIndexRequest().index(AD_RESULT_HISTORY_INDEX_PATTERN).mapping(MAPPING_TYPE, adResultMapping, XContentType.JSON);\n         request.addMaxIndexDocsCondition(historyMaxDocs);\n-        request.addMaxIndexAgeCondition(historyMaxAge);\n-        RolloverResponse response = adminClient.indices().rolloverIndex(request).actionGet(requestTimeout);\n-        if (!response.isRolledOver()) {\n-            logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+        adminClient.indices().rolloverIndex(request, ActionListener.wrap(response -> {\n+            if (!response.isRolledOver()) {\n+                logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+            } else {\n+                logger.info(\"{} rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+                deleteOldHistoryIndices();\n+            }\n+        }, exception -> {\n+            logger.error(\"Fail to roll over result index\");\n+            logger.error(exception);\n+        }));\n+    }\n+\n+    private void deleteOldHistoryIndices() {\n+        Set<String> candidates = new HashSet<String>();\n+\n+        ClusterStateRequest clusterStateRequest = new ClusterStateRequest()\n+            .clear()\n+            .indices(AnomalyDetectionIndices.ALL_AD_RESULTS_INDEX_PATTERN)\n+            .metadata(true)\n+            .local(true)\n+            .indicesOptions(IndicesOptions.strictExpand());\n+\n+        adminClient.cluster().state(clusterStateRequest, ActionListener.wrap(clusterStateResponse -> {\n+            String latestToDelete = null;\n+            long latest = Long.MIN_VALUE;\n+            for (ObjectCursor<IndexMetadata> cursor : clusterStateResponse.getState().metadata().indices().values()) {\n+                IndexMetadata indexMetaData = cursor.value;\n+                long creationTime = indexMetaData.getCreationDate();\n+\n+                if ((Instant.now().toEpochMilli() - creationTime) > historyRetentionPeriod.millis()) {\n+                    String indexName = indexMetaData.getIndex().getName();\n+                    candidates.add(indexName);\n+                    if (latest < creationTime) {\n+                        latest = creationTime;\n+                        latestToDelete = indexName;\n+                    }\n+                }\n+            }\n+\n+            if (candidates.size() > 1) {\n+                // delete all indices except the last one because the last one may contain docs newer than the retention period\n+                candidates.remove(latestToDelete);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTA0MTc2Ng=="}, "originalCommit": {"oid": "020f509d2f882e619ce3fff3a05be41845be2126"}, "originalPosition": 171}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjI4ODU3MA==", "bodyText": "The indices has no order. So we cannot do that.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/174#discussion_r446288570", "createdAt": "2020-06-26T16:33:01Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/indices/AnomalyDetectionIndices.java", "diffHunk": "@@ -275,15 +285,86 @@ private boolean rolloverHistoryIndex() {\n             adResultMapping = getAnomalyResultMappings();\n         } catch (IOException e) {\n             logger.error(\"Fail to roll over AD result index, as can't get AD result index mapping\");\n-            return false;\n+            return;\n         }\n         request.getCreateIndexRequest().index(AD_RESULT_HISTORY_INDEX_PATTERN).mapping(MAPPING_TYPE, adResultMapping, XContentType.JSON);\n         request.addMaxIndexDocsCondition(historyMaxDocs);\n-        request.addMaxIndexAgeCondition(historyMaxAge);\n-        RolloverResponse response = adminClient.indices().rolloverIndex(request).actionGet(requestTimeout);\n-        if (!response.isRolledOver()) {\n-            logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+        adminClient.indices().rolloverIndex(request, ActionListener.wrap(response -> {\n+            if (!response.isRolledOver()) {\n+                logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+            } else {\n+                logger.info(\"{} rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+                deleteOldHistoryIndices();\n+            }\n+        }, exception -> {\n+            logger.error(\"Fail to roll over result index\");\n+            logger.error(exception);\n+        }));\n+    }\n+\n+    private void deleteOldHistoryIndices() {\n+        Set<String> candidates = new HashSet<String>();\n+\n+        ClusterStateRequest clusterStateRequest = new ClusterStateRequest()\n+            .clear()\n+            .indices(AnomalyDetectionIndices.ALL_AD_RESULTS_INDEX_PATTERN)\n+            .metadata(true)\n+            .local(true)\n+            .indicesOptions(IndicesOptions.strictExpand());\n+\n+        adminClient.cluster().state(clusterStateRequest, ActionListener.wrap(clusterStateResponse -> {\n+            String latestToDelete = null;\n+            long latest = Long.MIN_VALUE;\n+            for (ObjectCursor<IndexMetadata> cursor : clusterStateResponse.getState().metadata().indices().values()) {\n+                IndexMetadata indexMetaData = cursor.value;\n+                long creationTime = indexMetaData.getCreationDate();\n+\n+                if ((Instant.now().toEpochMilli() - creationTime) > historyRetentionPeriod.millis()) {\n+                    String indexName = indexMetaData.getIndex().getName();\n+                    candidates.add(indexName);\n+                    if (latest < creationTime) {\n+                        latest = creationTime;\n+                        latestToDelete = indexName;\n+                    }\n+                }\n+            }\n+\n+            if (candidates.size() > 1) {\n+                // delete all indices except the last one because the last one may contain docs newer than the retention period\n+                candidates.remove(latestToDelete);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTA0MTc2Ng=="}, "originalCommit": {"oid": "020f509d2f882e619ce3fff3a05be41845be2126"}, "originalPosition": 171}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3MzAwOTA0OnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/indices/AnomalyDetectionIndices.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQxNzowODozN1rOGobYnw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQxODowOToxMFrOGoddEw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTA0NDg5NQ==", "bodyText": "This exception is for catching exception of clusterStateRequest? Not quite get why log Fail to get creation dates here.  The exception only caused by get creation dates ?", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/174#discussion_r445044895", "createdAt": "2020-06-24T17:08:37Z", "author": {"login": "ylwu-amzn"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/indices/AnomalyDetectionIndices.java", "diffHunk": "@@ -275,15 +285,86 @@ private boolean rolloverHistoryIndex() {\n             adResultMapping = getAnomalyResultMappings();\n         } catch (IOException e) {\n             logger.error(\"Fail to roll over AD result index, as can't get AD result index mapping\");\n-            return false;\n+            return;\n         }\n         request.getCreateIndexRequest().index(AD_RESULT_HISTORY_INDEX_PATTERN).mapping(MAPPING_TYPE, adResultMapping, XContentType.JSON);\n         request.addMaxIndexDocsCondition(historyMaxDocs);\n-        request.addMaxIndexAgeCondition(historyMaxAge);\n-        RolloverResponse response = adminClient.indices().rolloverIndex(request).actionGet(requestTimeout);\n-        if (!response.isRolledOver()) {\n-            logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+        adminClient.indices().rolloverIndex(request, ActionListener.wrap(response -> {\n+            if (!response.isRolledOver()) {\n+                logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+            } else {\n+                logger.info(\"{} rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+                deleteOldHistoryIndices();\n+            }\n+        }, exception -> {\n+            logger.error(\"Fail to roll over result index\");\n+            logger.error(exception);\n+        }));\n+    }\n+\n+    private void deleteOldHistoryIndices() {\n+        Set<String> candidates = new HashSet<String>();\n+\n+        ClusterStateRequest clusterStateRequest = new ClusterStateRequest()\n+            .clear()\n+            .indices(AnomalyDetectionIndices.ALL_AD_RESULTS_INDEX_PATTERN)\n+            .metadata(true)\n+            .local(true)\n+            .indicesOptions(IndicesOptions.strictExpand());\n+\n+        adminClient.cluster().state(clusterStateRequest, ActionListener.wrap(clusterStateResponse -> {\n+            String latestToDelete = null;\n+            long latest = Long.MIN_VALUE;\n+            for (ObjectCursor<IndexMetadata> cursor : clusterStateResponse.getState().metadata().indices().values()) {\n+                IndexMetadata indexMetaData = cursor.value;\n+                long creationTime = indexMetaData.getCreationDate();\n+\n+                if ((Instant.now().toEpochMilli() - creationTime) > historyRetentionPeriod.millis()) {\n+                    String indexName = indexMetaData.getIndex().getName();\n+                    candidates.add(indexName);\n+                    if (latest < creationTime) {\n+                        latest = creationTime;\n+                        latestToDelete = indexName;\n+                    }\n+                }\n+            }\n+\n+            if (candidates.size() > 1) {\n+                // delete all indices except the last one because the last one may contain docs newer than the retention period\n+                candidates.remove(latestToDelete);\n+                String[] toDelete = candidates.toArray(Strings.EMPTY_ARRAY);\n+                DeleteIndexRequest deleteIndexRequest = new DeleteIndexRequest(toDelete);\n+                adminClient.indices().delete(deleteIndexRequest, ActionListener.wrap(deleteIndexResponse -> {\n+                    if (!deleteIndexResponse.isAcknowledged()) {\n+                        logger\n+                            .error(\n+                                \"Could not delete one or more Anomaly result indices: {}. Retrying one by one.\",\n+                                Arrays.toString(toDelete)\n+                            );\n+                        deleteIndexIteration(toDelete);\n+                    } else {\n+                        logger.error(\"Succeeded in deleting expired anomaly result indices: {}.\", Arrays.toString(toDelete));\n+                    }\n+                }, exception -> { deleteIndexIteration(toDelete); }));\n+            }\n+        }, exception -> { logger.error(\"Fail to get creation dates of result indices\"); }));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "020f509d2f882e619ce3fff3a05be41845be2126"}, "originalPosition": 187}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTA3ODgwMw==", "bodyText": "good catch.  Changed to more general error message.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/174#discussion_r445078803", "createdAt": "2020-06-24T18:09:10Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/indices/AnomalyDetectionIndices.java", "diffHunk": "@@ -275,15 +285,86 @@ private boolean rolloverHistoryIndex() {\n             adResultMapping = getAnomalyResultMappings();\n         } catch (IOException e) {\n             logger.error(\"Fail to roll over AD result index, as can't get AD result index mapping\");\n-            return false;\n+            return;\n         }\n         request.getCreateIndexRequest().index(AD_RESULT_HISTORY_INDEX_PATTERN).mapping(MAPPING_TYPE, adResultMapping, XContentType.JSON);\n         request.addMaxIndexDocsCondition(historyMaxDocs);\n-        request.addMaxIndexAgeCondition(historyMaxAge);\n-        RolloverResponse response = adminClient.indices().rolloverIndex(request).actionGet(requestTimeout);\n-        if (!response.isRolledOver()) {\n-            logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+        adminClient.indices().rolloverIndex(request, ActionListener.wrap(response -> {\n+            if (!response.isRolledOver()) {\n+                logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+            } else {\n+                logger.info(\"{} rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+                deleteOldHistoryIndices();\n+            }\n+        }, exception -> {\n+            logger.error(\"Fail to roll over result index\");\n+            logger.error(exception);\n+        }));\n+    }\n+\n+    private void deleteOldHistoryIndices() {\n+        Set<String> candidates = new HashSet<String>();\n+\n+        ClusterStateRequest clusterStateRequest = new ClusterStateRequest()\n+            .clear()\n+            .indices(AnomalyDetectionIndices.ALL_AD_RESULTS_INDEX_PATTERN)\n+            .metadata(true)\n+            .local(true)\n+            .indicesOptions(IndicesOptions.strictExpand());\n+\n+        adminClient.cluster().state(clusterStateRequest, ActionListener.wrap(clusterStateResponse -> {\n+            String latestToDelete = null;\n+            long latest = Long.MIN_VALUE;\n+            for (ObjectCursor<IndexMetadata> cursor : clusterStateResponse.getState().metadata().indices().values()) {\n+                IndexMetadata indexMetaData = cursor.value;\n+                long creationTime = indexMetaData.getCreationDate();\n+\n+                if ((Instant.now().toEpochMilli() - creationTime) > historyRetentionPeriod.millis()) {\n+                    String indexName = indexMetaData.getIndex().getName();\n+                    candidates.add(indexName);\n+                    if (latest < creationTime) {\n+                        latest = creationTime;\n+                        latestToDelete = indexName;\n+                    }\n+                }\n+            }\n+\n+            if (candidates.size() > 1) {\n+                // delete all indices except the last one because the last one may contain docs newer than the retention period\n+                candidates.remove(latestToDelete);\n+                String[] toDelete = candidates.toArray(Strings.EMPTY_ARRAY);\n+                DeleteIndexRequest deleteIndexRequest = new DeleteIndexRequest(toDelete);\n+                adminClient.indices().delete(deleteIndexRequest, ActionListener.wrap(deleteIndexResponse -> {\n+                    if (!deleteIndexResponse.isAcknowledged()) {\n+                        logger\n+                            .error(\n+                                \"Could not delete one or more Anomaly result indices: {}. Retrying one by one.\",\n+                                Arrays.toString(toDelete)\n+                            );\n+                        deleteIndexIteration(toDelete);\n+                    } else {\n+                        logger.error(\"Succeeded in deleting expired anomaly result indices: {}.\", Arrays.toString(toDelete));\n+                    }\n+                }, exception -> { deleteIndexIteration(toDelete); }));\n+            }\n+        }, exception -> { logger.error(\"Fail to get creation dates of result indices\"); }));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTA0NDg5NQ=="}, "originalCommit": {"oid": "020f509d2f882e619ce3fff3a05be41845be2126"}, "originalPosition": 187}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3MzAxNTkwOnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/indices/AnomalyDetectionIndices.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQxNzoxMDo0NlrOGobdUA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQxODoxNTo1NlrOGodrnA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTA0NjA5Ng==", "bodyText": "Same here, why put into two lines?", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/174#discussion_r445046096", "createdAt": "2020-06-24T17:10:46Z", "author": {"login": "ylwu-amzn"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/indices/AnomalyDetectionIndices.java", "diffHunk": "@@ -275,15 +285,86 @@ private boolean rolloverHistoryIndex() {\n             adResultMapping = getAnomalyResultMappings();\n         } catch (IOException e) {\n             logger.error(\"Fail to roll over AD result index, as can't get AD result index mapping\");\n-            return false;\n+            return;\n         }\n         request.getCreateIndexRequest().index(AD_RESULT_HISTORY_INDEX_PATTERN).mapping(MAPPING_TYPE, adResultMapping, XContentType.JSON);\n         request.addMaxIndexDocsCondition(historyMaxDocs);\n-        request.addMaxIndexAgeCondition(historyMaxAge);\n-        RolloverResponse response = adminClient.indices().rolloverIndex(request).actionGet(requestTimeout);\n-        if (!response.isRolledOver()) {\n-            logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+        adminClient.indices().rolloverIndex(request, ActionListener.wrap(response -> {\n+            if (!response.isRolledOver()) {\n+                logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+            } else {\n+                logger.info(\"{} rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+                deleteOldHistoryIndices();\n+            }\n+        }, exception -> {\n+            logger.error(\"Fail to roll over result index\");\n+            logger.error(exception);\n+        }));\n+    }\n+\n+    private void deleteOldHistoryIndices() {\n+        Set<String> candidates = new HashSet<String>();\n+\n+        ClusterStateRequest clusterStateRequest = new ClusterStateRequest()\n+            .clear()\n+            .indices(AnomalyDetectionIndices.ALL_AD_RESULTS_INDEX_PATTERN)\n+            .metadata(true)\n+            .local(true)\n+            .indicesOptions(IndicesOptions.strictExpand());\n+\n+        adminClient.cluster().state(clusterStateRequest, ActionListener.wrap(clusterStateResponse -> {\n+            String latestToDelete = null;\n+            long latest = Long.MIN_VALUE;\n+            for (ObjectCursor<IndexMetadata> cursor : clusterStateResponse.getState().metadata().indices().values()) {\n+                IndexMetadata indexMetaData = cursor.value;\n+                long creationTime = indexMetaData.getCreationDate();\n+\n+                if ((Instant.now().toEpochMilli() - creationTime) > historyRetentionPeriod.millis()) {\n+                    String indexName = indexMetaData.getIndex().getName();\n+                    candidates.add(indexName);\n+                    if (latest < creationTime) {\n+                        latest = creationTime;\n+                        latestToDelete = indexName;\n+                    }\n+                }\n+            }\n+\n+            if (candidates.size() > 1) {\n+                // delete all indices except the last one because the last one may contain docs newer than the retention period\n+                candidates.remove(latestToDelete);\n+                String[] toDelete = candidates.toArray(Strings.EMPTY_ARRAY);\n+                DeleteIndexRequest deleteIndexRequest = new DeleteIndexRequest(toDelete);\n+                adminClient.indices().delete(deleteIndexRequest, ActionListener.wrap(deleteIndexResponse -> {\n+                    if (!deleteIndexResponse.isAcknowledged()) {\n+                        logger\n+                            .error(\n+                                \"Could not delete one or more Anomaly result indices: {}. Retrying one by one.\",\n+                                Arrays.toString(toDelete)\n+                            );\n+                        deleteIndexIteration(toDelete);\n+                    } else {\n+                        logger.error(\"Succeeded in deleting expired anomaly result indices: {}.\", Arrays.toString(toDelete));\n+                    }\n+                }, exception -> { deleteIndexIteration(toDelete); }));\n+            }\n+        }, exception -> { logger.error(\"Fail to get creation dates of result indices\"); }));\n+    }\n+\n+    private void deleteIndexIteration(String[] toDelete) {\n+        for (String index : toDelete) {\n+            DeleteIndexRequest singleDeleteRequest = new DeleteIndexRequest(index);\n+            adminClient.indices().delete(singleDeleteRequest, ActionListener.wrap(singleDeleteResponse -> {\n+                if (!singleDeleteResponse.isAcknowledged()) {\n+                    logger.error(\"Retrying deleting {} does not succeed.\", index);\n+                }\n+            }, exception -> {\n+                if (exception instanceof IndexNotFoundException) {\n+                    logger.info(\"{} was already deleted.\", index);\n+                } else {\n+                    logger.error(\"Retrying deleting {} does not succeed.\", index);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "020f509d2f882e619ce3fff3a05be41845be2126"}, "originalPosition": 201}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTA4MjUyNA==", "bodyText": "Fixed", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/174#discussion_r445082524", "createdAt": "2020-06-24T18:15:56Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/indices/AnomalyDetectionIndices.java", "diffHunk": "@@ -275,15 +285,86 @@ private boolean rolloverHistoryIndex() {\n             adResultMapping = getAnomalyResultMappings();\n         } catch (IOException e) {\n             logger.error(\"Fail to roll over AD result index, as can't get AD result index mapping\");\n-            return false;\n+            return;\n         }\n         request.getCreateIndexRequest().index(AD_RESULT_HISTORY_INDEX_PATTERN).mapping(MAPPING_TYPE, adResultMapping, XContentType.JSON);\n         request.addMaxIndexDocsCondition(historyMaxDocs);\n-        request.addMaxIndexAgeCondition(historyMaxAge);\n-        RolloverResponse response = adminClient.indices().rolloverIndex(request).actionGet(requestTimeout);\n-        if (!response.isRolledOver()) {\n-            logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+        adminClient.indices().rolloverIndex(request, ActionListener.wrap(response -> {\n+            if (!response.isRolledOver()) {\n+                logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+            } else {\n+                logger.info(\"{} rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+                deleteOldHistoryIndices();\n+            }\n+        }, exception -> {\n+            logger.error(\"Fail to roll over result index\");\n+            logger.error(exception);\n+        }));\n+    }\n+\n+    private void deleteOldHistoryIndices() {\n+        Set<String> candidates = new HashSet<String>();\n+\n+        ClusterStateRequest clusterStateRequest = new ClusterStateRequest()\n+            .clear()\n+            .indices(AnomalyDetectionIndices.ALL_AD_RESULTS_INDEX_PATTERN)\n+            .metadata(true)\n+            .local(true)\n+            .indicesOptions(IndicesOptions.strictExpand());\n+\n+        adminClient.cluster().state(clusterStateRequest, ActionListener.wrap(clusterStateResponse -> {\n+            String latestToDelete = null;\n+            long latest = Long.MIN_VALUE;\n+            for (ObjectCursor<IndexMetadata> cursor : clusterStateResponse.getState().metadata().indices().values()) {\n+                IndexMetadata indexMetaData = cursor.value;\n+                long creationTime = indexMetaData.getCreationDate();\n+\n+                if ((Instant.now().toEpochMilli() - creationTime) > historyRetentionPeriod.millis()) {\n+                    String indexName = indexMetaData.getIndex().getName();\n+                    candidates.add(indexName);\n+                    if (latest < creationTime) {\n+                        latest = creationTime;\n+                        latestToDelete = indexName;\n+                    }\n+                }\n+            }\n+\n+            if (candidates.size() > 1) {\n+                // delete all indices except the last one because the last one may contain docs newer than the retention period\n+                candidates.remove(latestToDelete);\n+                String[] toDelete = candidates.toArray(Strings.EMPTY_ARRAY);\n+                DeleteIndexRequest deleteIndexRequest = new DeleteIndexRequest(toDelete);\n+                adminClient.indices().delete(deleteIndexRequest, ActionListener.wrap(deleteIndexResponse -> {\n+                    if (!deleteIndexResponse.isAcknowledged()) {\n+                        logger\n+                            .error(\n+                                \"Could not delete one or more Anomaly result indices: {}. Retrying one by one.\",\n+                                Arrays.toString(toDelete)\n+                            );\n+                        deleteIndexIteration(toDelete);\n+                    } else {\n+                        logger.error(\"Succeeded in deleting expired anomaly result indices: {}.\", Arrays.toString(toDelete));\n+                    }\n+                }, exception -> { deleteIndexIteration(toDelete); }));\n+            }\n+        }, exception -> { logger.error(\"Fail to get creation dates of result indices\"); }));\n+    }\n+\n+    private void deleteIndexIteration(String[] toDelete) {\n+        for (String index : toDelete) {\n+            DeleteIndexRequest singleDeleteRequest = new DeleteIndexRequest(index);\n+            adminClient.indices().delete(singleDeleteRequest, ActionListener.wrap(singleDeleteResponse -> {\n+                if (!singleDeleteResponse.isAcknowledged()) {\n+                    logger.error(\"Retrying deleting {} does not succeed.\", index);\n+                }\n+            }, exception -> {\n+                if (exception instanceof IndexNotFoundException) {\n+                    logger.info(\"{} was already deleted.\", index);\n+                } else {\n+                    logger.error(\"Retrying deleting {} does not succeed.\", index);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTA0NjA5Ng=="}, "originalCommit": {"oid": "020f509d2f882e619ce3fff3a05be41845be2126"}, "originalPosition": 201}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3MzA0NDcwOnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/indices/AnomalyDetectionIndices.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQxNzoxOToyOFrOGobwKw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxNjo0ODowMFrOGpnxmg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTA1MDkyMw==", "bodyText": "Is it necessary to use two rounds of deletion? Roll over will be triggered periodically, so next run can re-delete the failed indices.\nIf fail to delete all indices due to some error, will it help we re-delete them immediately? Error may be still there", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/174#discussion_r445050923", "createdAt": "2020-06-24T17:19:28Z", "author": {"login": "ylwu-amzn"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/indices/AnomalyDetectionIndices.java", "diffHunk": "@@ -275,15 +285,86 @@ private boolean rolloverHistoryIndex() {\n             adResultMapping = getAnomalyResultMappings();\n         } catch (IOException e) {\n             logger.error(\"Fail to roll over AD result index, as can't get AD result index mapping\");\n-            return false;\n+            return;\n         }\n         request.getCreateIndexRequest().index(AD_RESULT_HISTORY_INDEX_PATTERN).mapping(MAPPING_TYPE, adResultMapping, XContentType.JSON);\n         request.addMaxIndexDocsCondition(historyMaxDocs);\n-        request.addMaxIndexAgeCondition(historyMaxAge);\n-        RolloverResponse response = adminClient.indices().rolloverIndex(request).actionGet(requestTimeout);\n-        if (!response.isRolledOver()) {\n-            logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+        adminClient.indices().rolloverIndex(request, ActionListener.wrap(response -> {\n+            if (!response.isRolledOver()) {\n+                logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+            } else {\n+                logger.info(\"{} rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+                deleteOldHistoryIndices();\n+            }\n+        }, exception -> {\n+            logger.error(\"Fail to roll over result index\");\n+            logger.error(exception);\n+        }));\n+    }\n+\n+    private void deleteOldHistoryIndices() {\n+        Set<String> candidates = new HashSet<String>();\n+\n+        ClusterStateRequest clusterStateRequest = new ClusterStateRequest()\n+            .clear()\n+            .indices(AnomalyDetectionIndices.ALL_AD_RESULTS_INDEX_PATTERN)\n+            .metadata(true)\n+            .local(true)\n+            .indicesOptions(IndicesOptions.strictExpand());\n+\n+        adminClient.cluster().state(clusterStateRequest, ActionListener.wrap(clusterStateResponse -> {\n+            String latestToDelete = null;\n+            long latest = Long.MIN_VALUE;\n+            for (ObjectCursor<IndexMetadata> cursor : clusterStateResponse.getState().metadata().indices().values()) {\n+                IndexMetadata indexMetaData = cursor.value;\n+                long creationTime = indexMetaData.getCreationDate();\n+\n+                if ((Instant.now().toEpochMilli() - creationTime) > historyRetentionPeriod.millis()) {\n+                    String indexName = indexMetaData.getIndex().getName();\n+                    candidates.add(indexName);\n+                    if (latest < creationTime) {\n+                        latest = creationTime;\n+                        latestToDelete = indexName;\n+                    }\n+                }\n+            }\n+\n+            if (candidates.size() > 1) {\n+                // delete all indices except the last one because the last one may contain docs newer than the retention period\n+                candidates.remove(latestToDelete);\n+                String[] toDelete = candidates.toArray(Strings.EMPTY_ARRAY);\n+                DeleteIndexRequest deleteIndexRequest = new DeleteIndexRequest(toDelete);\n+                adminClient.indices().delete(deleteIndexRequest, ActionListener.wrap(deleteIndexResponse -> {\n+                    if (!deleteIndexResponse.isAcknowledged()) {\n+                        logger\n+                            .error(\n+                                \"Could not delete one or more Anomaly result indices: {}. Retrying one by one.\",\n+                                Arrays.toString(toDelete)\n+                            );\n+                        deleteIndexIteration(toDelete);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "020f509d2f882e619ce3fff3a05be41845be2126"}, "originalPosition": 181}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTA3NzI3MQ==", "bodyText": "By default, we need to wait for 12 hours before re-deleting.  Adding a retry can mitigate some disk/memory issue without waiting for too long.  This is best effort and we cannot guarantee this would help.  We don't retry endlessly.  Just once.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/174#discussion_r445077271", "createdAt": "2020-06-24T18:06:18Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/indices/AnomalyDetectionIndices.java", "diffHunk": "@@ -275,15 +285,86 @@ private boolean rolloverHistoryIndex() {\n             adResultMapping = getAnomalyResultMappings();\n         } catch (IOException e) {\n             logger.error(\"Fail to roll over AD result index, as can't get AD result index mapping\");\n-            return false;\n+            return;\n         }\n         request.getCreateIndexRequest().index(AD_RESULT_HISTORY_INDEX_PATTERN).mapping(MAPPING_TYPE, adResultMapping, XContentType.JSON);\n         request.addMaxIndexDocsCondition(historyMaxDocs);\n-        request.addMaxIndexAgeCondition(historyMaxAge);\n-        RolloverResponse response = adminClient.indices().rolloverIndex(request).actionGet(requestTimeout);\n-        if (!response.isRolledOver()) {\n-            logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+        adminClient.indices().rolloverIndex(request, ActionListener.wrap(response -> {\n+            if (!response.isRolledOver()) {\n+                logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+            } else {\n+                logger.info(\"{} rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+                deleteOldHistoryIndices();\n+            }\n+        }, exception -> {\n+            logger.error(\"Fail to roll over result index\");\n+            logger.error(exception);\n+        }));\n+    }\n+\n+    private void deleteOldHistoryIndices() {\n+        Set<String> candidates = new HashSet<String>();\n+\n+        ClusterStateRequest clusterStateRequest = new ClusterStateRequest()\n+            .clear()\n+            .indices(AnomalyDetectionIndices.ALL_AD_RESULTS_INDEX_PATTERN)\n+            .metadata(true)\n+            .local(true)\n+            .indicesOptions(IndicesOptions.strictExpand());\n+\n+        adminClient.cluster().state(clusterStateRequest, ActionListener.wrap(clusterStateResponse -> {\n+            String latestToDelete = null;\n+            long latest = Long.MIN_VALUE;\n+            for (ObjectCursor<IndexMetadata> cursor : clusterStateResponse.getState().metadata().indices().values()) {\n+                IndexMetadata indexMetaData = cursor.value;\n+                long creationTime = indexMetaData.getCreationDate();\n+\n+                if ((Instant.now().toEpochMilli() - creationTime) > historyRetentionPeriod.millis()) {\n+                    String indexName = indexMetaData.getIndex().getName();\n+                    candidates.add(indexName);\n+                    if (latest < creationTime) {\n+                        latest = creationTime;\n+                        latestToDelete = indexName;\n+                    }\n+                }\n+            }\n+\n+            if (candidates.size() > 1) {\n+                // delete all indices except the last one because the last one may contain docs newer than the retention period\n+                candidates.remove(latestToDelete);\n+                String[] toDelete = candidates.toArray(Strings.EMPTY_ARRAY);\n+                DeleteIndexRequest deleteIndexRequest = new DeleteIndexRequest(toDelete);\n+                adminClient.indices().delete(deleteIndexRequest, ActionListener.wrap(deleteIndexResponse -> {\n+                    if (!deleteIndexResponse.isAcknowledged()) {\n+                        logger\n+                            .error(\n+                                \"Could not delete one or more Anomaly result indices: {}. Retrying one by one.\",\n+                                Arrays.toString(toDelete)\n+                            );\n+                        deleteIndexIteration(toDelete);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTA1MDkyMw=="}, "originalCommit": {"oid": "020f509d2f882e619ce3fff3a05be41845be2126"}, "originalPosition": 181}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTE3MTE1Ng==", "bodyText": "Can we get which index failed to delete? Can we delete these failed indices in one call?", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/174#discussion_r445171156", "createdAt": "2020-06-24T21:04:47Z", "author": {"login": "ylwu-amzn"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/indices/AnomalyDetectionIndices.java", "diffHunk": "@@ -275,15 +285,86 @@ private boolean rolloverHistoryIndex() {\n             adResultMapping = getAnomalyResultMappings();\n         } catch (IOException e) {\n             logger.error(\"Fail to roll over AD result index, as can't get AD result index mapping\");\n-            return false;\n+            return;\n         }\n         request.getCreateIndexRequest().index(AD_RESULT_HISTORY_INDEX_PATTERN).mapping(MAPPING_TYPE, adResultMapping, XContentType.JSON);\n         request.addMaxIndexDocsCondition(historyMaxDocs);\n-        request.addMaxIndexAgeCondition(historyMaxAge);\n-        RolloverResponse response = adminClient.indices().rolloverIndex(request).actionGet(requestTimeout);\n-        if (!response.isRolledOver()) {\n-            logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+        adminClient.indices().rolloverIndex(request, ActionListener.wrap(response -> {\n+            if (!response.isRolledOver()) {\n+                logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+            } else {\n+                logger.info(\"{} rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+                deleteOldHistoryIndices();\n+            }\n+        }, exception -> {\n+            logger.error(\"Fail to roll over result index\");\n+            logger.error(exception);\n+        }));\n+    }\n+\n+    private void deleteOldHistoryIndices() {\n+        Set<String> candidates = new HashSet<String>();\n+\n+        ClusterStateRequest clusterStateRequest = new ClusterStateRequest()\n+            .clear()\n+            .indices(AnomalyDetectionIndices.ALL_AD_RESULTS_INDEX_PATTERN)\n+            .metadata(true)\n+            .local(true)\n+            .indicesOptions(IndicesOptions.strictExpand());\n+\n+        adminClient.cluster().state(clusterStateRequest, ActionListener.wrap(clusterStateResponse -> {\n+            String latestToDelete = null;\n+            long latest = Long.MIN_VALUE;\n+            for (ObjectCursor<IndexMetadata> cursor : clusterStateResponse.getState().metadata().indices().values()) {\n+                IndexMetadata indexMetaData = cursor.value;\n+                long creationTime = indexMetaData.getCreationDate();\n+\n+                if ((Instant.now().toEpochMilli() - creationTime) > historyRetentionPeriod.millis()) {\n+                    String indexName = indexMetaData.getIndex().getName();\n+                    candidates.add(indexName);\n+                    if (latest < creationTime) {\n+                        latest = creationTime;\n+                        latestToDelete = indexName;\n+                    }\n+                }\n+            }\n+\n+            if (candidates.size() > 1) {\n+                // delete all indices except the last one because the last one may contain docs newer than the retention period\n+                candidates.remove(latestToDelete);\n+                String[] toDelete = candidates.toArray(Strings.EMPTY_ARRAY);\n+                DeleteIndexRequest deleteIndexRequest = new DeleteIndexRequest(toDelete);\n+                adminClient.indices().delete(deleteIndexRequest, ActionListener.wrap(deleteIndexResponse -> {\n+                    if (!deleteIndexResponse.isAcknowledged()) {\n+                        logger\n+                            .error(\n+                                \"Could not delete one or more Anomaly result indices: {}. Retrying one by one.\",\n+                                Arrays.toString(toDelete)\n+                            );\n+                        deleteIndexIteration(toDelete);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTA1MDkyMw=="}, "originalCommit": {"oid": "020f509d2f882e619ce3fff3a05be41845be2126"}, "originalPosition": 181}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjI5NjQ3NA==", "bodyText": "I don't know how to.  Delete response is of AcknowledgedResponse type that contains only isAcknowledged field.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/174#discussion_r446296474", "createdAt": "2020-06-26T16:48:00Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/indices/AnomalyDetectionIndices.java", "diffHunk": "@@ -275,15 +285,86 @@ private boolean rolloverHistoryIndex() {\n             adResultMapping = getAnomalyResultMappings();\n         } catch (IOException e) {\n             logger.error(\"Fail to roll over AD result index, as can't get AD result index mapping\");\n-            return false;\n+            return;\n         }\n         request.getCreateIndexRequest().index(AD_RESULT_HISTORY_INDEX_PATTERN).mapping(MAPPING_TYPE, adResultMapping, XContentType.JSON);\n         request.addMaxIndexDocsCondition(historyMaxDocs);\n-        request.addMaxIndexAgeCondition(historyMaxAge);\n-        RolloverResponse response = adminClient.indices().rolloverIndex(request).actionGet(requestTimeout);\n-        if (!response.isRolledOver()) {\n-            logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+        adminClient.indices().rolloverIndex(request, ActionListener.wrap(response -> {\n+            if (!response.isRolledOver()) {\n+                logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+            } else {\n+                logger.info(\"{} rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+                deleteOldHistoryIndices();\n+            }\n+        }, exception -> {\n+            logger.error(\"Fail to roll over result index\");\n+            logger.error(exception);\n+        }));\n+    }\n+\n+    private void deleteOldHistoryIndices() {\n+        Set<String> candidates = new HashSet<String>();\n+\n+        ClusterStateRequest clusterStateRequest = new ClusterStateRequest()\n+            .clear()\n+            .indices(AnomalyDetectionIndices.ALL_AD_RESULTS_INDEX_PATTERN)\n+            .metadata(true)\n+            .local(true)\n+            .indicesOptions(IndicesOptions.strictExpand());\n+\n+        adminClient.cluster().state(clusterStateRequest, ActionListener.wrap(clusterStateResponse -> {\n+            String latestToDelete = null;\n+            long latest = Long.MIN_VALUE;\n+            for (ObjectCursor<IndexMetadata> cursor : clusterStateResponse.getState().metadata().indices().values()) {\n+                IndexMetadata indexMetaData = cursor.value;\n+                long creationTime = indexMetaData.getCreationDate();\n+\n+                if ((Instant.now().toEpochMilli() - creationTime) > historyRetentionPeriod.millis()) {\n+                    String indexName = indexMetaData.getIndex().getName();\n+                    candidates.add(indexName);\n+                    if (latest < creationTime) {\n+                        latest = creationTime;\n+                        latestToDelete = indexName;\n+                    }\n+                }\n+            }\n+\n+            if (candidates.size() > 1) {\n+                // delete all indices except the last one because the last one may contain docs newer than the retention period\n+                candidates.remove(latestToDelete);\n+                String[] toDelete = candidates.toArray(Strings.EMPTY_ARRAY);\n+                DeleteIndexRequest deleteIndexRequest = new DeleteIndexRequest(toDelete);\n+                adminClient.indices().delete(deleteIndexRequest, ActionListener.wrap(deleteIndexResponse -> {\n+                    if (!deleteIndexResponse.isAcknowledged()) {\n+                        logger\n+                            .error(\n+                                \"Could not delete one or more Anomaly result indices: {}. Retrying one by one.\",\n+                                Arrays.toString(toDelete)\n+                            );\n+                        deleteIndexIteration(toDelete);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTA1MDkyMw=="}, "originalCommit": {"oid": "020f509d2f882e619ce3fff3a05be41845be2126"}, "originalPosition": 181}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3MzgyMDc3OnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/indices/AnomalyDetectionIndices.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQyMToxNzoyM1rOGojcqw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxNjo0ODoyNlrOGpnylA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTE3NzAwMw==", "bodyText": "logger.info", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/174#discussion_r445177003", "createdAt": "2020-06-24T21:17:23Z", "author": {"login": "yizheliu-amazon"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/indices/AnomalyDetectionIndices.java", "diffHunk": "@@ -275,15 +286,82 @@ private boolean rolloverHistoryIndex() {\n             adResultMapping = getAnomalyResultMappings();\n         } catch (IOException e) {\n             logger.error(\"Fail to roll over AD result index, as can't get AD result index mapping\");\n-            return false;\n+            return;\n         }\n         request.getCreateIndexRequest().index(AD_RESULT_HISTORY_INDEX_PATTERN).mapping(MAPPING_TYPE, adResultMapping, XContentType.JSON);\n         request.addMaxIndexDocsCondition(historyMaxDocs);\n-        request.addMaxIndexAgeCondition(historyMaxAge);\n-        RolloverResponse response = adminClient.indices().rolloverIndex(request).actionGet(requestTimeout);\n-        if (!response.isRolledOver()) {\n-            logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+        adminClient.indices().rolloverIndex(request, ActionListener.wrap(response -> {\n+            if (!response.isRolledOver()) {\n+                logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+            } else {\n+                logger.info(\"{} rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+                deleteOldHistoryIndices();\n+            }\n+        }, exception -> { logger.error(\"Fail to roll over result index\", exception); }));\n+    }\n+\n+    private void deleteOldHistoryIndices() {\n+        Set<String> candidates = new HashSet<String>();\n+\n+        ClusterStateRequest clusterStateRequest = new ClusterStateRequest()\n+            .clear()\n+            .indices(AnomalyDetectionIndices.ALL_AD_RESULTS_INDEX_PATTERN)\n+            .metadata(true)\n+            .local(true)\n+            .indicesOptions(IndicesOptions.strictExpand());\n+\n+        adminClient.cluster().state(clusterStateRequest, ActionListener.wrap(clusterStateResponse -> {\n+            String latestToDelete = null;\n+            long latest = Long.MIN_VALUE;\n+            for (ObjectCursor<IndexMetadata> cursor : clusterStateResponse.getState().metadata().indices().values()) {\n+                IndexMetadata indexMetaData = cursor.value;\n+                long creationTime = indexMetaData.getCreationDate();\n+\n+                if ((Instant.now().toEpochMilli() - creationTime) > historyRetentionPeriod.millis()) {\n+                    String indexName = indexMetaData.getIndex().getName();\n+                    candidates.add(indexName);\n+                    if (latest < creationTime) {\n+                        latest = creationTime;\n+                        latestToDelete = indexName;\n+                    }\n+                }\n+            }\n+\n+            if (candidates.size() > 1) {\n+                // delete all indices except the last one because the last one may contain docs newer than the retention period\n+                candidates.remove(latestToDelete);\n+                String[] toDelete = candidates.toArray(Strings.EMPTY_ARRAY);\n+                DeleteIndexRequest deleteIndexRequest = new DeleteIndexRequest(toDelete);\n+                adminClient.indices().delete(deleteIndexRequest, ActionListener.wrap(deleteIndexResponse -> {\n+                    if (!deleteIndexResponse.isAcknowledged()) {\n+                        logger\n+                            .error(\n+                                \"Could not delete one or more Anomaly result indices: {}. Retrying one by one.\",\n+                                Arrays.toString(toDelete)\n+                            );\n+                        deleteIndexIteration(toDelete);\n+                    } else {\n+                        logger.error(\"Succeeded in deleting expired anomaly result indices: {}.\", Arrays.toString(toDelete));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bbf1b5466f1a2082e5da389720a51d7e684f1387"}, "originalPosition": 181}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjI5NjcyNA==", "bodyText": "good catch. Fixed.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/174#discussion_r446296724", "createdAt": "2020-06-26T16:48:26Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/indices/AnomalyDetectionIndices.java", "diffHunk": "@@ -275,15 +286,82 @@ private boolean rolloverHistoryIndex() {\n             adResultMapping = getAnomalyResultMappings();\n         } catch (IOException e) {\n             logger.error(\"Fail to roll over AD result index, as can't get AD result index mapping\");\n-            return false;\n+            return;\n         }\n         request.getCreateIndexRequest().index(AD_RESULT_HISTORY_INDEX_PATTERN).mapping(MAPPING_TYPE, adResultMapping, XContentType.JSON);\n         request.addMaxIndexDocsCondition(historyMaxDocs);\n-        request.addMaxIndexAgeCondition(historyMaxAge);\n-        RolloverResponse response = adminClient.indices().rolloverIndex(request).actionGet(requestTimeout);\n-        if (!response.isRolledOver()) {\n-            logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+        adminClient.indices().rolloverIndex(request, ActionListener.wrap(response -> {\n+            if (!response.isRolledOver()) {\n+                logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+            } else {\n+                logger.info(\"{} rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+                deleteOldHistoryIndices();\n+            }\n+        }, exception -> { logger.error(\"Fail to roll over result index\", exception); }));\n+    }\n+\n+    private void deleteOldHistoryIndices() {\n+        Set<String> candidates = new HashSet<String>();\n+\n+        ClusterStateRequest clusterStateRequest = new ClusterStateRequest()\n+            .clear()\n+            .indices(AnomalyDetectionIndices.ALL_AD_RESULTS_INDEX_PATTERN)\n+            .metadata(true)\n+            .local(true)\n+            .indicesOptions(IndicesOptions.strictExpand());\n+\n+        adminClient.cluster().state(clusterStateRequest, ActionListener.wrap(clusterStateResponse -> {\n+            String latestToDelete = null;\n+            long latest = Long.MIN_VALUE;\n+            for (ObjectCursor<IndexMetadata> cursor : clusterStateResponse.getState().metadata().indices().values()) {\n+                IndexMetadata indexMetaData = cursor.value;\n+                long creationTime = indexMetaData.getCreationDate();\n+\n+                if ((Instant.now().toEpochMilli() - creationTime) > historyRetentionPeriod.millis()) {\n+                    String indexName = indexMetaData.getIndex().getName();\n+                    candidates.add(indexName);\n+                    if (latest < creationTime) {\n+                        latest = creationTime;\n+                        latestToDelete = indexName;\n+                    }\n+                }\n+            }\n+\n+            if (candidates.size() > 1) {\n+                // delete all indices except the last one because the last one may contain docs newer than the retention period\n+                candidates.remove(latestToDelete);\n+                String[] toDelete = candidates.toArray(Strings.EMPTY_ARRAY);\n+                DeleteIndexRequest deleteIndexRequest = new DeleteIndexRequest(toDelete);\n+                adminClient.indices().delete(deleteIndexRequest, ActionListener.wrap(deleteIndexResponse -> {\n+                    if (!deleteIndexResponse.isAcknowledged()) {\n+                        logger\n+                            .error(\n+                                \"Could not delete one or more Anomaly result indices: {}. Retrying one by one.\",\n+                                Arrays.toString(toDelete)\n+                            );\n+                        deleteIndexIteration(toDelete);\n+                    } else {\n+                        logger.error(\"Succeeded in deleting expired anomaly result indices: {}.\", Arrays.toString(toDelete));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTE3NzAwMw=="}, "originalCommit": {"oid": "bbf1b5466f1a2082e5da389720a51d7e684f1387"}, "originalPosition": 181}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3MzgyMjEwOnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/indices/AnomalyDetectionIndices.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQyMToxNzo1M1rOGojdjw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxNjo1MDo0OVrOGpn36Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTE3NzIzMQ==", "bodyText": "maybe we can log the exception before retrying", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/174#discussion_r445177231", "createdAt": "2020-06-24T21:17:53Z", "author": {"login": "yizheliu-amazon"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/indices/AnomalyDetectionIndices.java", "diffHunk": "@@ -275,15 +286,82 @@ private boolean rolloverHistoryIndex() {\n             adResultMapping = getAnomalyResultMappings();\n         } catch (IOException e) {\n             logger.error(\"Fail to roll over AD result index, as can't get AD result index mapping\");\n-            return false;\n+            return;\n         }\n         request.getCreateIndexRequest().index(AD_RESULT_HISTORY_INDEX_PATTERN).mapping(MAPPING_TYPE, adResultMapping, XContentType.JSON);\n         request.addMaxIndexDocsCondition(historyMaxDocs);\n-        request.addMaxIndexAgeCondition(historyMaxAge);\n-        RolloverResponse response = adminClient.indices().rolloverIndex(request).actionGet(requestTimeout);\n-        if (!response.isRolledOver()) {\n-            logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+        adminClient.indices().rolloverIndex(request, ActionListener.wrap(response -> {\n+            if (!response.isRolledOver()) {\n+                logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+            } else {\n+                logger.info(\"{} rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+                deleteOldHistoryIndices();\n+            }\n+        }, exception -> { logger.error(\"Fail to roll over result index\", exception); }));\n+    }\n+\n+    private void deleteOldHistoryIndices() {\n+        Set<String> candidates = new HashSet<String>();\n+\n+        ClusterStateRequest clusterStateRequest = new ClusterStateRequest()\n+            .clear()\n+            .indices(AnomalyDetectionIndices.ALL_AD_RESULTS_INDEX_PATTERN)\n+            .metadata(true)\n+            .local(true)\n+            .indicesOptions(IndicesOptions.strictExpand());\n+\n+        adminClient.cluster().state(clusterStateRequest, ActionListener.wrap(clusterStateResponse -> {\n+            String latestToDelete = null;\n+            long latest = Long.MIN_VALUE;\n+            for (ObjectCursor<IndexMetadata> cursor : clusterStateResponse.getState().metadata().indices().values()) {\n+                IndexMetadata indexMetaData = cursor.value;\n+                long creationTime = indexMetaData.getCreationDate();\n+\n+                if ((Instant.now().toEpochMilli() - creationTime) > historyRetentionPeriod.millis()) {\n+                    String indexName = indexMetaData.getIndex().getName();\n+                    candidates.add(indexName);\n+                    if (latest < creationTime) {\n+                        latest = creationTime;\n+                        latestToDelete = indexName;\n+                    }\n+                }\n+            }\n+\n+            if (candidates.size() > 1) {\n+                // delete all indices except the last one because the last one may contain docs newer than the retention period\n+                candidates.remove(latestToDelete);\n+                String[] toDelete = candidates.toArray(Strings.EMPTY_ARRAY);\n+                DeleteIndexRequest deleteIndexRequest = new DeleteIndexRequest(toDelete);\n+                adminClient.indices().delete(deleteIndexRequest, ActionListener.wrap(deleteIndexResponse -> {\n+                    if (!deleteIndexResponse.isAcknowledged()) {\n+                        logger\n+                            .error(\n+                                \"Could not delete one or more Anomaly result indices: {}. Retrying one by one.\",\n+                                Arrays.toString(toDelete)\n+                            );\n+                        deleteIndexIteration(toDelete);\n+                    } else {\n+                        logger.error(\"Succeeded in deleting expired anomaly result indices: {}.\", Arrays.toString(toDelete));\n+                    }\n+                }, exception -> { deleteIndexIteration(toDelete); }));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bbf1b5466f1a2082e5da389720a51d7e684f1387"}, "originalPosition": 183}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjI5ODA4OQ==", "bodyText": "added", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/174#discussion_r446298089", "createdAt": "2020-06-26T16:50:49Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/indices/AnomalyDetectionIndices.java", "diffHunk": "@@ -275,15 +286,82 @@ private boolean rolloverHistoryIndex() {\n             adResultMapping = getAnomalyResultMappings();\n         } catch (IOException e) {\n             logger.error(\"Fail to roll over AD result index, as can't get AD result index mapping\");\n-            return false;\n+            return;\n         }\n         request.getCreateIndexRequest().index(AD_RESULT_HISTORY_INDEX_PATTERN).mapping(MAPPING_TYPE, adResultMapping, XContentType.JSON);\n         request.addMaxIndexDocsCondition(historyMaxDocs);\n-        request.addMaxIndexAgeCondition(historyMaxAge);\n-        RolloverResponse response = adminClient.indices().rolloverIndex(request).actionGet(requestTimeout);\n-        if (!response.isRolledOver()) {\n-            logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+        adminClient.indices().rolloverIndex(request, ActionListener.wrap(response -> {\n+            if (!response.isRolledOver()) {\n+                logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+            } else {\n+                logger.info(\"{} rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+                deleteOldHistoryIndices();\n+            }\n+        }, exception -> { logger.error(\"Fail to roll over result index\", exception); }));\n+    }\n+\n+    private void deleteOldHistoryIndices() {\n+        Set<String> candidates = new HashSet<String>();\n+\n+        ClusterStateRequest clusterStateRequest = new ClusterStateRequest()\n+            .clear()\n+            .indices(AnomalyDetectionIndices.ALL_AD_RESULTS_INDEX_PATTERN)\n+            .metadata(true)\n+            .local(true)\n+            .indicesOptions(IndicesOptions.strictExpand());\n+\n+        adminClient.cluster().state(clusterStateRequest, ActionListener.wrap(clusterStateResponse -> {\n+            String latestToDelete = null;\n+            long latest = Long.MIN_VALUE;\n+            for (ObjectCursor<IndexMetadata> cursor : clusterStateResponse.getState().metadata().indices().values()) {\n+                IndexMetadata indexMetaData = cursor.value;\n+                long creationTime = indexMetaData.getCreationDate();\n+\n+                if ((Instant.now().toEpochMilli() - creationTime) > historyRetentionPeriod.millis()) {\n+                    String indexName = indexMetaData.getIndex().getName();\n+                    candidates.add(indexName);\n+                    if (latest < creationTime) {\n+                        latest = creationTime;\n+                        latestToDelete = indexName;\n+                    }\n+                }\n+            }\n+\n+            if (candidates.size() > 1) {\n+                // delete all indices except the last one because the last one may contain docs newer than the retention period\n+                candidates.remove(latestToDelete);\n+                String[] toDelete = candidates.toArray(Strings.EMPTY_ARRAY);\n+                DeleteIndexRequest deleteIndexRequest = new DeleteIndexRequest(toDelete);\n+                adminClient.indices().delete(deleteIndexRequest, ActionListener.wrap(deleteIndexResponse -> {\n+                    if (!deleteIndexResponse.isAcknowledged()) {\n+                        logger\n+                            .error(\n+                                \"Could not delete one or more Anomaly result indices: {}. Retrying one by one.\",\n+                                Arrays.toString(toDelete)\n+                            );\n+                        deleteIndexIteration(toDelete);\n+                    } else {\n+                        logger.error(\"Succeeded in deleting expired anomaly result indices: {}.\", Arrays.toString(toDelete));\n+                    }\n+                }, exception -> { deleteIndexIteration(toDelete); }));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTE3NzIzMQ=="}, "originalCommit": {"oid": "bbf1b5466f1a2082e5da389720a51d7e684f1387"}, "originalPosition": 183}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2883, "cost": 1, "resetAt": "2021-11-12T20:44:06Z"}}}