{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzc3NTgxNDE0", "number": 44, "title": "add AD job on top of JobScheduler", "bodyText": "Create AD job on top of JobScheduler. User can create monitor on AD result index. So we can decouple AD and Alerting.", "createdAt": "2020-02-20T06:50:09Z", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/44", "merged": true, "mergeCommit": {"oid": "a82209f1bb193e45e93ed663a4bff9e043d46db6"}, "closed": true, "closedAt": "2020-02-27T23:47:12Z", "author": {"login": "ylwu-amzn"}, "timelineItems": {"totalCount": 16, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcGFU4vAH2gAyMzc3NTgxNDE0OjBhMDNlZWVhNDRjMzMyYzNhNTMzNzQyMDAyMmIwZjM3MmU4MGFkODA=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcIjQoPgFqTM2NjA1MjM5NA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "0a03eeea44c332c3a5337420022b0f372e80ad80", "author": {"user": {"login": "ylwu-amzn", "name": "Yaliang"}}, "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/0a03eeea44c332c3a5337420022b0f372e80ad80", "committedDate": "2020-02-20T06:41:58Z", "message": "add AD job on top of JobScheduler"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0ad539154b87212be6c64d5a9ea80f3f8d95b3ab", "author": {"user": {"login": "ylwu-amzn", "name": "Yaliang"}}, "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/0ad539154b87212be6c64d5a9ea80f3f8d95b3ab", "committedDate": "2020-02-20T20:57:44Z", "message": "release job lock when job finish or fail"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzYyMzQ2ODcz", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/44#pullrequestreview-362346873", "createdAt": "2020-02-21T01:20:22Z", "commit": {"oid": "0ad539154b87212be6c64d5a9ea80f3f8d95b3ab"}, "state": "COMMENTED", "comments": {"totalCount": 17, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yMVQwMToyMDoyM1rOFsoyOg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNFQwNToyMTo1MVrOFtV6hA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MjM0OTg4Mg==", "bodyText": "You need to send channel response", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/44#discussion_r382349882", "createdAt": "2020-02-21T01:20:23Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/rest/handler/IndexAnomalyDetectorJobActionHandler.java", "diffHunk": "@@ -0,0 +1,332 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.rest.handler;\n+\n+import com.amazon.opendistroforelasticsearch.ad.AnomalyDetectorPlugin;\n+import com.amazon.opendistroforelasticsearch.ad.indices.AnomalyDetectionIndices;\n+import com.amazon.opendistroforelasticsearch.ad.model.AnomalyDetector;\n+import com.amazon.opendistroforelasticsearch.ad.model.AnomalyDetectorJob;\n+import com.amazon.opendistroforelasticsearch.ad.model.IntervalTimeConfiguration;\n+import com.amazon.opendistroforelasticsearch.ad.transport.StopDetectorAction;\n+import com.amazon.opendistroforelasticsearch.ad.transport.StopDetectorRequest;\n+import com.amazon.opendistroforelasticsearch.ad.transport.StopDetectorResponse;\n+import com.amazon.opendistroforelasticsearch.ad.util.RestHandlerUtils;\n+import com.amazon.opendistroforelasticsearch.jobscheduler.spi.schedule.IntervalSchedule;\n+import com.amazon.opendistroforelasticsearch.jobscheduler.spi.schedule.Schedule;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.admin.indices.create.CreateIndexResponse;\n+import org.elasticsearch.action.delete.DeleteRequest;\n+import org.elasticsearch.action.get.GetRequest;\n+import org.elasticsearch.action.get.GetResponse;\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.action.index.IndexResponse;\n+import org.elasticsearch.action.support.WriteRequest;\n+import org.elasticsearch.client.node.NodeClient;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.LoggingDeprecationHandler;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.common.xcontent.XContentType;\n+import org.elasticsearch.rest.BytesRestResponse;\n+import org.elasticsearch.rest.RestChannel;\n+import org.elasticsearch.rest.RestResponse;\n+import org.elasticsearch.rest.RestStatus;\n+import org.elasticsearch.rest.action.RestResponseListener;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.Instant;\n+import java.util.Locale;\n+\n+import static com.amazon.opendistroforelasticsearch.ad.model.AnomalyDetector.ANOMALY_DETECTORS_INDEX;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.MAX_ANOMALY_DETECTORS;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.MAX_ANOMALY_FEATURES;\n+import static com.amazon.opendistroforelasticsearch.ad.util.RestHandlerUtils.XCONTENT_WITH_TYPE;\n+import static org.elasticsearch.common.xcontent.ToXContent.EMPTY_PARAMS;\n+import static org.elasticsearch.common.xcontent.XContentParserUtils.ensureExpectedToken;\n+\n+/**\n+ * Anomaly detector job REST action handler to process POST/PUT request.\n+ */\n+public class IndexAnomalyDetectorJobActionHandler extends AbstractActionHandler {\n+\n+    private final AnomalyDetectionIndices anomalyDetectionIndices;\n+    private final String detectorId;\n+    private final Long seqNo;\n+    private final Long primaryTerm;\n+    private final WriteRequest.RefreshPolicy refreshPolicy;\n+    private final ClusterService clusterService;\n+\n+    private final Logger logger = LogManager.getLogger(IndexAnomalyDetectorJobActionHandler.class);\n+    private final TimeValue requestTimeout;\n+    private volatile Integer maxAnomalyDetectors;\n+    private volatile Integer maxAnomalyFeatures;\n+    private final AnomalyDetectorActionHandler handler = new AnomalyDetectorActionHandler();\n+\n+    /**\n+     * Constructor function.\n+     *\n+     * @param settings                ES settings\n+     * @param clusterService          ClusterService\n+     * @param client                  ES node client that executes actions on the local node\n+     * @param channel                 ES channel used to construct bytes / builder based outputs, and send responses\n+     * @param anomalyDetectionIndices anomaly detector index manager\n+     * @param detectorId              detector identifier\n+     * @param seqNo                   sequence number of last modification\n+     * @param primaryTerm             primary term of last modification\n+     * @param refreshPolicy           refresh policy\n+     * @param requestTimeout          request time out configuration\n+     */\n+    public IndexAnomalyDetectorJobActionHandler(\n+        Settings settings,\n+        ClusterService clusterService,\n+        NodeClient client,\n+        RestChannel channel,\n+        AnomalyDetectionIndices anomalyDetectionIndices,\n+        String detectorId,\n+        Long seqNo,\n+        Long primaryTerm,\n+        WriteRequest.RefreshPolicy refreshPolicy,\n+        TimeValue requestTimeout\n+    ) {\n+        super(client, channel);\n+        this.clusterService = clusterService;\n+        this.anomalyDetectionIndices = anomalyDetectionIndices;\n+        this.detectorId = detectorId;\n+        this.seqNo = seqNo;\n+        this.primaryTerm = primaryTerm;\n+        this.refreshPolicy = refreshPolicy;\n+        this.requestTimeout = requestTimeout;\n+        maxAnomalyDetectors = MAX_ANOMALY_DETECTORS.get(settings);\n+        maxAnomalyFeatures = MAX_ANOMALY_FEATURES.get(settings);\n+        clusterService.getClusterSettings().addSettingsUpdateConsumer(MAX_ANOMALY_DETECTORS, it -> maxAnomalyDetectors = it);\n+        clusterService.getClusterSettings().addSettingsUpdateConsumer(MAX_ANOMALY_FEATURES, it -> maxAnomalyFeatures = it);\n+    }\n+\n+    /**\n+     * Start function to process create/update anomaly detector job request.\n+     * Check if anomaly detector job index exist first, if not, will create first.\n+     *\n+     * @throws IOException IOException from {@link AnomalyDetectionIndices#initAnomalyDetectorIndexIfAbsent(ActionListener)}\n+     */\n+    public void start() throws IOException {\n+        if (!anomalyDetectionIndices.doesAnomalyDetectorJobIndexExist()) {\n+            anomalyDetectionIndices\n+                .initAnomalyDetectorIndex(\n+                    ActionListener.wrap(response -> onCreateMappingsResponse(response), exception -> onFailure(exception))\n+                );\n+        } else {\n+            prepareAnomalyDetectorJobIndexing();\n+        }\n+    }\n+\n+    /**\n+     * Create anomaly detector job.\n+     *\n+     * @throws IOException IOException from {@link AnomalyDetectionIndices#getAnomalyDetectorJobMappings}\n+     */\n+    public void createAnomalyDetectorJob() throws IOException {\n+        if (!anomalyDetectionIndices.doesAnomalyDetectorJobIndexExist()) {\n+            anomalyDetectionIndices\n+                .initAnomalyDetectorJobIndex(\n+                    ActionListener.wrap(response -> onCreateMappingsResponse(response), exception -> onFailure(exception))\n+                );\n+        } else {\n+            prepareAnomalyDetectorJobIndexing();\n+        }\n+    }\n+\n+    private void prepareAnomalyDetectorJobIndexing() {\n+        GetRequest getRequest = new GetRequest(AnomalyDetector.ANOMALY_DETECTORS_INDEX).id(detectorId);\n+        client.get(getRequest, ActionListener.wrap(response -> onGetAnomalyDetectorResponse(response), exception -> onFailure(exception)));\n+    }\n+\n+    private void onGetAnomalyDetectorResponse(GetResponse response) throws IOException {\n+        if (!response.isExists()) {\n+            XContentBuilder builder = channel\n+                .newErrorBuilder()\n+                .startObject()\n+                .field(\"Message\", \"AnomalyDetector is not found with id: \" + detectorId)\n+                .endObject();\n+            channel.sendResponse(new BytesRestResponse(RestStatus.NOT_FOUND, response.toXContent(builder, EMPTY_PARAMS)));\n+            return;\n+        }\n+        XContentParser parser = XContentType.JSON\n+            .xContent()\n+            .createParser(\n+                channel.request().getXContentRegistry(),\n+                LoggingDeprecationHandler.INSTANCE,\n+                response.getSourceAsBytesRef().streamInput()\n+            );\n+\n+        ensureExpectedToken(XContentParser.Token.START_OBJECT, parser.nextToken(), parser::getTokenLocation);\n+        AnomalyDetector detector = AnomalyDetector.parse(parser, response.getId(), response.getVersion());\n+\n+        IntervalTimeConfiguration interval = (IntervalTimeConfiguration) detector.getDetectionInterval();\n+        Schedule schedule = new IntervalSchedule(Instant.now(), (int) interval.getInterval(), interval.getUnit());\n+        Duration duration = Duration.of(interval.getInterval(), interval.getUnit());\n+        AnomalyDetectorJob job = new AnomalyDetectorJob(\n+            detector.getDetectorId(),\n+            schedule,\n+            true,\n+            Instant.now(),\n+            Instant.now(),\n+            duration.getSeconds()\n+        );\n+\n+        getAnomalyDetectorJob(job);\n+    }\n+\n+    private void getAnomalyDetectorJob(AnomalyDetectorJob job) {\n+        GetRequest getRequest = new GetRequest(AnomalyDetectorJob.ANOMALY_DETECTOR_JOB_INDEX).id(detectorId);\n+\n+        client.get(getRequest, ActionListener.wrap(response -> onGetAnomalyDetectorJob(response, job), exception -> onFailure(exception)));\n+    }\n+\n+    private void onGetAnomalyDetectorJob(GetResponse response, AnomalyDetectorJob job) throws IOException {\n+        if (response.isExists()) {\n+            XContentBuilder builder = channel\n+                .newErrorBuilder()\n+                .startObject()\n+                .field(\"Message\", \"AnomalyDetectorJob exists: \" + detectorId)\n+                .endObject();\n+            channel.sendResponse(new BytesRestResponse(RestStatus.NOT_FOUND, response.toXContent(builder, EMPTY_PARAMS)));\n+            return;\n+        }\n+\n+        indexAnomalyDetectorJob(job);\n+    }\n+\n+    private void indexAnomalyDetectorJob(AnomalyDetectorJob job) throws IOException {\n+        IndexRequest indexRequest = new IndexRequest(AnomalyDetectorJob.ANOMALY_DETECTOR_JOB_INDEX)\n+            .setRefreshPolicy(refreshPolicy)\n+            .source(job.toXContent(channel.newBuilder(), XCONTENT_WITH_TYPE))\n+            .setIfSeqNo(seqNo)\n+            .setIfPrimaryTerm(primaryTerm)\n+            .timeout(requestTimeout);\n+        if (detectorId != null) {\n+            indexRequest.id(detectorId);\n+        }\n+        client.index(indexRequest, indexAnomalyDetectorJobResponse());\n+    }\n+\n+    private ActionListener<IndexResponse> indexAnomalyDetectorJobResponse() {\n+        return new RestResponseListener<IndexResponse>(channel) {\n+            @Override\n+            public RestResponse buildResponse(IndexResponse response) throws Exception {\n+                if (response.getShardInfo().getSuccessful() < 1) {\n+                    return new BytesRestResponse(response.status(), response.toXContent(channel.newErrorBuilder(), EMPTY_PARAMS));\n+                }\n+\n+                XContentBuilder builder = channel\n+                    .newBuilder()\n+                    .startObject()\n+                    .field(RestHandlerUtils._ID, response.getId())\n+                    .field(RestHandlerUtils._VERSION, response.getVersion())\n+                    .field(RestHandlerUtils._SEQ_NO, response.getSeqNo())\n+                    .field(RestHandlerUtils._PRIMARY_TERM, response.getPrimaryTerm())\n+                    .endObject();\n+\n+                BytesRestResponse restResponse = new BytesRestResponse(response.status(), builder);\n+                if (response.status() == RestStatus.CREATED) {\n+                    String location = String.format(Locale.ROOT, \"%s/%s\", AnomalyDetectorPlugin.AD_BASE_URI, response.getId());\n+                    restResponse.addHeader(\"Location\", location);\n+                }\n+                return restResponse;\n+            }\n+        };\n+    }\n+\n+    private void onCreateMappingsResponse(CreateIndexResponse response) throws IOException {\n+        if (response.isAcknowledged()) {\n+            logger.info(\"Created {} with mappings.\", ANOMALY_DETECTORS_INDEX);\n+            prepareAnomalyDetectorJobIndexing();\n+        } else {\n+            logger.warn(\"Created {} with mappings call not acknowledged.\", ANOMALY_DETECTORS_INDEX);\n+            channel\n+                .sendResponse(\n+                    new BytesRestResponse(RestStatus.INTERNAL_SERVER_ERROR, response.toXContent(channel.newErrorBuilder(), EMPTY_PARAMS))\n+                );\n+        }\n+    }\n+\n+    /**\n+     * Delete anomaly detector job\n+     * @param detectorId detector identifier\n+     */\n+    public void deleteAnomalyDetectorJob(String detectorId) {\n+        GetRequest getRequest = new GetRequest(AnomalyDetectorJob.ANOMALY_DETECTOR_JOB_INDEX).id(detectorId);\n+\n+        client\n+            .get(\n+                getRequest,\n+                ActionListener\n+                    .wrap(\n+                        response -> deleteAnomalyDetectorJobDoc(client, detectorId, channel, refreshPolicy),\n+                        exception -> onFailure(exception)\n+                    )\n+            );\n+    }\n+\n+    private void deleteAnomalyDetectorJobDoc(\n+        NodeClient client,\n+        String detectorId,\n+        RestChannel channel,\n+        WriteRequest.RefreshPolicy refreshPolicy\n+    ) {\n+        logger.info(\"Delete anomaly detector job {}\", detectorId);\n+        DeleteRequest deleteRequest = new DeleteRequest(AnomalyDetectorJob.ANOMALY_DETECTOR_JOB_INDEX, detectorId)\n+            .setRefreshPolicy(refreshPolicy);\n+        client.delete(deleteRequest, ActionListener.wrap(response -> {\n+            if (\"deleted\".equals(response.getResult().getLowercase())) {\n+                logger.info(\"Stop anomaly detector {}\", detectorId);\n+                StopDetectorRequest stopDetectorRequest = new StopDetectorRequest(detectorId);\n+                client.execute(StopDetectorAction.INSTANCE, stopDetectorRequest, stopAdDetectorListener(channel, detectorId));\n+            } else {\n+                channel.sendResponse(new BytesRestResponse(RestStatus.BAD_REQUEST, \"Failed to stop AD job \" + detectorId));\n+            }\n+        }, exception -> {\n+            logger.error(\"Failed to stop AD job \" + detectorId, exception);\n+            onFailure(exception);\n+        }));\n+\n+    }\n+\n+    private ActionListener<StopDetectorResponse> stopAdDetectorListener(RestChannel channel, String detectorId) {\n+        return new ActionListener<StopDetectorResponse>() {\n+            @Override\n+            public void onResponse(StopDetectorResponse stopDetectorResponse) {\n+                if (stopDetectorResponse.success()) {\n+                    logger.info(\"AD model deleted successfully for detector {}\", detectorId);\n+                    channel.sendResponse(new BytesRestResponse(RestStatus.OK, \"Stopped detector: \" + detectorId));\n+                } else {\n+                    logger.error(\"Failed to delete AD model for detector {}\", detectorId);\n+                    channel.sendResponse(new BytesRestResponse(RestStatus.INTERNAL_SERVER_ERROR, \"Failed to delete AD model\"));\n+                }\n+            }\n+\n+            @Override\n+            public void onFailure(Exception e) {\n+                logger.error(\"Failed to delete AD model for detector \" + detectorId, e);\n+            }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0ad539154b87212be6c64d5a9ea80f3f8d95b3ab"}, "originalPosition": 328}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA2NjAzMw==", "bodyText": "How about putting the zip file under src/main/resources?", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/44#discussion_r383066033", "createdAt": "2020-02-24T02:18:15Z", "author": {"login": "kaituo"}, "path": "build.gradle", "diffHunk": "@@ -212,10 +212,25 @@ integTestRunner {\n \n integTestCluster {\n     distribution = es_distribution\n+    // Temporary until job-scheduler is published to Maven\n+    setupCommand('installPlugin', 'bin/elasticsearch-plugin', 'install',\n+            \"file://${fileTree(\"src/test/resources/job-scheduler\").getSingleFile().absolutePath}\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0ad539154b87212be6c64d5a9ea80f3f8d95b3ab"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA2NzA2Nw==", "bodyText": "Can we define the path in a variable and reference this variable instead?   We have multiple places referencing this path.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/44#discussion_r383067067", "createdAt": "2020-02-24T02:26:30Z", "author": {"login": "kaituo"}, "path": "build.gradle", "diffHunk": "@@ -212,10 +212,25 @@ integTestRunner {\n \n integTestCluster {\n     distribution = es_distribution\n+    // Temporary until job-scheduler is published to Maven\n+    setupCommand('installPlugin', 'bin/elasticsearch-plugin', 'install',\n+            \"file://${fileTree(\"src/test/resources/job-scheduler\").getSingleFile().absolutePath}\")\n }\n \n run {\n     distribution = es_distribution\n+    distribution = \"oss-zip\"\n+    // Temporary until job-scheduler is published to Maven\n+    setupCommand('installPlugin', 'bin/elasticsearch-plugin', 'install',\n+            \"file://${fileTree(\"src/test/resources/job-scheduler\").getSingleFile().absolutePath}\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0ad539154b87212be6c64d5a9ea80f3f8d95b3ab"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA2NzMwNQ==", "bodyText": "We have already had a runMultiNode task.  Can you merge these two?", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/44#discussion_r383067305", "createdAt": "2020-02-24T02:28:21Z", "author": {"login": "kaituo"}, "path": "build.gradle", "diffHunk": "@@ -212,10 +212,25 @@ integTestRunner {\n \n integTestCluster {\n     distribution = es_distribution\n+    // Temporary until job-scheduler is published to Maven\n+    setupCommand('installPlugin', 'bin/elasticsearch-plugin', 'install',\n+            \"file://${fileTree(\"src/test/resources/job-scheduler\").getSingleFile().absolutePath}\")\n }\n \n run {\n     distribution = es_distribution\n+    distribution = \"oss-zip\"\n+    // Temporary until job-scheduler is published to Maven\n+    setupCommand('installPlugin', 'bin/elasticsearch-plugin', 'install',\n+            \"file://${fileTree(\"src/test/resources/job-scheduler\").getSingleFile().absolutePath}\")\n+}\n+\n+runMultiNode {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0ad539154b87212be6c64d5a9ea80f3f8d95b3ab"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA3MzM1Mw==", "bodyText": "This will conflict with existing development branch as it is based on 7.4 now.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/44#discussion_r383073353", "createdAt": "2020-02-24T03:19:00Z", "author": {"login": "kaituo"}, "path": "build.gradle", "diffHunk": "@@ -288,13 +303,15 @@ jacocoTestCoverageVerification.dependsOn jacocoTestReport\n \n dependencies {\n     compileOnly \"org.elasticsearch.plugin:elasticsearch-scripting-painless-spi:${versions.elasticsearch}\"\n+    compileOnly \"com.amazon.opendistroforelasticsearch:opendistro-job-scheduler-spi:1.2.1.1\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0ad539154b87212be6c64d5a9ea80f3f8d95b3ab"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA3Mzc5OQ==", "bodyText": "This will conflict with existing development branch as it is based on 7.4 now.\nAlso, where do we use transport client?", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/44#discussion_r383073799", "createdAt": "2020-02-24T03:22:10Z", "author": {"login": "kaituo"}, "path": "build.gradle", "diffHunk": "@@ -288,13 +303,15 @@ jacocoTestCoverageVerification.dependsOn jacocoTestReport\n \n dependencies {\n     compileOnly \"org.elasticsearch.plugin:elasticsearch-scripting-painless-spi:${versions.elasticsearch}\"\n+    compileOnly \"com.amazon.opendistroforelasticsearch:opendistro-job-scheduler-spi:1.2.1.1\"\n     compile group: 'com.google.guava', name: 'guava', version:'15.0'\n     compile group: 'org.apache.commons', name: 'commons-math3', version: '3.6.1'\n     compile group: 'com.google.code.gson', name: 'gson', version: '2.8.5'\n     compile files('lib/random-cut-forest-1.0.jar')\n     compile group: 'com.yahoo.datasketches', name: 'sketches-core', version: '0.13.4'\n     compile group: 'com.yahoo.datasketches', name: 'memory', version: '0.12.2'\n     compile group: 'commons-lang', name: 'commons-lang', version: '2.6'\n+    compile group: 'org.elasticsearch.plugin', name: 'transport-netty4-client', version: '7.2.1'", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0ad539154b87212be6c64d5a9ea80f3f8d95b3ab"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA3NDI1Ng==", "bodyText": "Why do we need these changes?", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/44#discussion_r383074256", "createdAt": "2020-02-24T03:25:44Z", "author": {"login": "kaituo"}, "path": "build.gradle", "diffHunk": "@@ -317,6 +334,29 @@ apply plugin: 'nebula.ospackage'\n \n // This is afterEvaluate because the bundlePlugin ZIP task is updated afterEvaluate and changes the ZIP name to match the plugin name\n afterEvaluate {\n+    project.tasks.getByName(\"run#installOpendistroAnomalyDetectorPlugin\").dependsOn(\"run#installPlugin\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0ad539154b87212be6c64d5a9ea80f3f8d95b3ab"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA3NDUxOQ==", "bodyText": "put releaseLock in finally clause so that you don't have to do it in all of the exits?", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/44#discussion_r383074519", "createdAt": "2020-02-24T03:27:38Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/AnomalyDetectorJobRunner.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad;\n+\n+import com.amazon.opendistroforelasticsearch.ad.model.AnomalyDetectorJob;\n+import com.amazon.opendistroforelasticsearch.ad.transport.AnomalyResultAction;\n+import com.amazon.opendistroforelasticsearch.ad.transport.AnomalyResultRequest;\n+import com.amazon.opendistroforelasticsearch.jobscheduler.spi.JobExecutionContext;\n+import com.amazon.opendistroforelasticsearch.jobscheduler.spi.LockModel;\n+import com.amazon.opendistroforelasticsearch.jobscheduler.spi.ScheduledJobParameter;\n+import com.amazon.opendistroforelasticsearch.jobscheduler.spi.ScheduledJobRunner;\n+import com.amazon.opendistroforelasticsearch.jobscheduler.spi.schedule.IntervalSchedule;\n+import com.amazon.opendistroforelasticsearch.jobscheduler.spi.utils.LockService;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.time.Duration;\n+import java.time.Instant;\n+import java.util.concurrent.ExecutorService;\n+\n+import static com.amazon.opendistroforelasticsearch.ad.AnomalyDetectorPlugin.AD_JOB_THREAD_POOL_NAME;\n+\n+/**\n+ * JobScheduler will call AD job runner to get anomaly result periodically\n+ */\n+public class AnomalyDetectorJobRunner implements ScheduledJobRunner {\n+    private static final Logger log = LogManager.getLogger(AnomalyDetectorJobRunner.class);\n+\n+    private static AnomalyDetectorJobRunner INSTANCE;\n+\n+    public static AnomalyDetectorJobRunner getJobRunnerInstance() {\n+        if (INSTANCE != null) {\n+            return INSTANCE;\n+        }\n+        synchronized (AnomalyDetectorJobRunner.class) {\n+            if (INSTANCE != null) {\n+                return INSTANCE;\n+            }\n+            INSTANCE = new AnomalyDetectorJobRunner();\n+            return INSTANCE;\n+        }\n+    }\n+\n+    private Client client;\n+    private ThreadPool threadPool;\n+\n+    private AnomalyDetectorJobRunner() {\n+        // Singleton class, use getJobRunnerInstance method instead of constructor\n+    }\n+\n+    public void setClient(Client client) {\n+        this.client = client;\n+    }\n+\n+    public void setThreadPool(ThreadPool threadPool) {\n+        this.threadPool = threadPool;\n+    }\n+\n+    @Override\n+    public void runJob(ScheduledJobParameter jobParameter, JobExecutionContext context) {\n+        log.info(\"Start to run AD job {}\", jobParameter.getName());\n+        if (!(jobParameter instanceof AnomalyDetectorJob)) {\n+            throw new IllegalStateException(\n+                \"Job parameter is not instance of AnomalyDetectorJob, type: \" + jobParameter.getClass().getCanonicalName()\n+            );\n+        }\n+\n+        final LockService lockService = context.getLockService();\n+\n+        Runnable runnable = () -> {\n+            if (jobParameter.getLockDurationSeconds() != null) {\n+                lockService\n+                    .acquireLock(\n+                        jobParameter,\n+                        context,\n+                        ActionListener\n+                            .wrap(\n+                                lock -> runAdJob(jobParameter, lockService, lock),\n+                                exception -> {\n+                                    throw new IllegalStateException(\"Failed to acquire lock for AD job: \" + jobParameter.getName());\n+                                }\n+                            )\n+                    );\n+            } else {\n+                log.warn(\"Can't get lock for AD job: \" + jobParameter.getName());\n+            }\n+        };\n+\n+        ExecutorService executor = threadPool.executor(AD_JOB_THREAD_POOL_NAME);\n+        executor.submit(runnable);\n+    }\n+\n+    protected void runAdJob(ScheduledJobParameter jobParameter, LockService lockService, LockModel lock) {\n+        if (lock == null) {\n+            return;\n+        }\n+\n+        try {\n+            IntervalSchedule schedule = (IntervalSchedule) jobParameter.getSchedule();\n+            Instant endTime = Instant.now();\n+            Duration duration = Duration.of(schedule.getInterval(), schedule.getUnit());\n+            Instant startTime = endTime.minusMillis(duration.toMillis());\n+\n+            AnomalyResultRequest request = new AnomalyResultRequest(\n+                jobParameter.getName(),\n+                startTime.toEpochMilli(),\n+                endTime.toEpochMilli()\n+            );\n+            client.execute(AnomalyResultAction.INSTANCE, request, ActionListener.wrap(response -> {\n+                log.info(\"Anomaly result action ran successfully for \" + jobParameter.getName());\n+                releaseLock(jobParameter, lockService, lock);\n+            }, exception -> {\n+                log.error(\"Failed to execute anomaly result action\", exception);\n+                releaseLock(jobParameter, lockService, lock);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0ad539154b87212be6c64d5a9ea80f3f8d95b3ab"}, "originalPosition": 130}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA3NjAyMQ==", "bodyText": "This sounds like the time with jitter.  We may need to maintain a lastEndTime.  So every time we get a signal from scheduler, we do [lastEndTime, lastEndTime+interval] and update lastEndTime.  Of course, we need to deal with the case when scheduler misses sending us signals.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/44#discussion_r383076021", "createdAt": "2020-02-24T03:39:05Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/AnomalyDetectorJobRunner.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad;\n+\n+import com.amazon.opendistroforelasticsearch.ad.model.AnomalyDetectorJob;\n+import com.amazon.opendistroforelasticsearch.ad.transport.AnomalyResultAction;\n+import com.amazon.opendistroforelasticsearch.ad.transport.AnomalyResultRequest;\n+import com.amazon.opendistroforelasticsearch.jobscheduler.spi.JobExecutionContext;\n+import com.amazon.opendistroforelasticsearch.jobscheduler.spi.LockModel;\n+import com.amazon.opendistroforelasticsearch.jobscheduler.spi.ScheduledJobParameter;\n+import com.amazon.opendistroforelasticsearch.jobscheduler.spi.ScheduledJobRunner;\n+import com.amazon.opendistroforelasticsearch.jobscheduler.spi.schedule.IntervalSchedule;\n+import com.amazon.opendistroforelasticsearch.jobscheduler.spi.utils.LockService;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.time.Duration;\n+import java.time.Instant;\n+import java.util.concurrent.ExecutorService;\n+\n+import static com.amazon.opendistroforelasticsearch.ad.AnomalyDetectorPlugin.AD_JOB_THREAD_POOL_NAME;\n+\n+/**\n+ * JobScheduler will call AD job runner to get anomaly result periodically\n+ */\n+public class AnomalyDetectorJobRunner implements ScheduledJobRunner {\n+    private static final Logger log = LogManager.getLogger(AnomalyDetectorJobRunner.class);\n+\n+    private static AnomalyDetectorJobRunner INSTANCE;\n+\n+    public static AnomalyDetectorJobRunner getJobRunnerInstance() {\n+        if (INSTANCE != null) {\n+            return INSTANCE;\n+        }\n+        synchronized (AnomalyDetectorJobRunner.class) {\n+            if (INSTANCE != null) {\n+                return INSTANCE;\n+            }\n+            INSTANCE = new AnomalyDetectorJobRunner();\n+            return INSTANCE;\n+        }\n+    }\n+\n+    private Client client;\n+    private ThreadPool threadPool;\n+\n+    private AnomalyDetectorJobRunner() {\n+        // Singleton class, use getJobRunnerInstance method instead of constructor\n+    }\n+\n+    public void setClient(Client client) {\n+        this.client = client;\n+    }\n+\n+    public void setThreadPool(ThreadPool threadPool) {\n+        this.threadPool = threadPool;\n+    }\n+\n+    @Override\n+    public void runJob(ScheduledJobParameter jobParameter, JobExecutionContext context) {\n+        log.info(\"Start to run AD job {}\", jobParameter.getName());\n+        if (!(jobParameter instanceof AnomalyDetectorJob)) {\n+            throw new IllegalStateException(\n+                \"Job parameter is not instance of AnomalyDetectorJob, type: \" + jobParameter.getClass().getCanonicalName()\n+            );\n+        }\n+\n+        final LockService lockService = context.getLockService();\n+\n+        Runnable runnable = () -> {\n+            if (jobParameter.getLockDurationSeconds() != null) {\n+                lockService\n+                    .acquireLock(\n+                        jobParameter,\n+                        context,\n+                        ActionListener\n+                            .wrap(\n+                                lock -> runAdJob(jobParameter, lockService, lock),\n+                                exception -> {\n+                                    throw new IllegalStateException(\"Failed to acquire lock for AD job: \" + jobParameter.getName());\n+                                }\n+                            )\n+                    );\n+            } else {\n+                log.warn(\"Can't get lock for AD job: \" + jobParameter.getName());\n+            }\n+        };\n+\n+        ExecutorService executor = threadPool.executor(AD_JOB_THREAD_POOL_NAME);\n+        executor.submit(runnable);\n+    }\n+\n+    protected void runAdJob(ScheduledJobParameter jobParameter, LockService lockService, LockModel lock) {\n+        if (lock == null) {\n+            return;\n+        }\n+\n+        try {\n+            IntervalSchedule schedule = (IntervalSchedule) jobParameter.getSchedule();\n+            Instant endTime = Instant.now();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0ad539154b87212be6c64d5a9ea80f3f8d95b3ab"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA3NzA1OA==", "bodyText": "Is this adding AD's own threadpool?  We are doing this for throttling and thus don't want to use all of the processors.  We can use max(1, 1/4 * number of processors).", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/44#discussion_r383077058", "createdAt": "2020-02-24T03:46:47Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/AnomalyDetectorPlugin.java", "diffHunk": "@@ -316,6 +342,20 @@ private static Void initGson() {\n             );\n     }\n \n+    @Override\n+    public List<ExecutorBuilder<?>> getExecutorBuilders(Settings settings) {\n+        return Collections\n+            .singletonList(\n+                new FixedExecutorBuilder(\n+                    settings,\n+                    AD_JOB_THREAD_POOL_NAME,\n+                    EsExecutors.numberOfProcessors(settings),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0ad539154b87212be6c64d5a9ea80f3f8d95b3ab"}, "originalPosition": 109}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA3NzQzOA==", "bodyText": "It should be 2020 now.  This applies to all of your newly added header", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/44#discussion_r383077438", "createdAt": "2020-02-24T03:49:36Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/model/AnomalyDetectorJob.java", "diffHunk": "@@ -0,0 +1,172 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0ad539154b87212be6c64d5a9ea80f3f8d95b3ab"}, "originalPosition": 2}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA3OTk3NQ==", "bodyText": "Why do we need this field?  AnomalyDetector is the definition of the detector.  Enabled or not sounds like a state and should belong to ad job index.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/44#discussion_r383079975", "createdAt": "2020-02-24T04:09:52Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/model/AnomalyDetector.java", "diffHunk": "@@ -83,6 +84,7 @@\n     private final Map<String, Object> uiMetadata;\n     private final Integer schemaVersion;\n     private final Instant lastUpdateTime;\n+    private boolean enabled = false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0ad539154b87212be6c64d5a9ea80f3f8d95b3ab"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA4MTk0Mg==", "bodyText": "How is this related to delete detector?  The method name suggests we are only getting a detector job.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/44#discussion_r383081942", "createdAt": "2020-02-24T04:26:09Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/rest/handler/AnomalyDetectorActionHandler.java", "diffHunk": "@@ -82,21 +59,12 @@ public void getMonitorUsingDetector(\n         }\n     }\n \n-    /**\n-     * Callback method for {@link AnomalyDetectorActionHandler#getMonitorUsingDetector}.\n-     * If search result contains at least one monitor, return error message;\n-     * otherwise, execute {@link AnomalyDetectorFunction}\n-     *\n-     * @param response Response of searching monitor\n-     * @param channel  ES rest channel\n-     * @param function Anomaly detector function\n-     */\n-    private void onSearchResponse(SearchResponse response, RestChannel channel, AnomalyDetectorFunction function) {\n-        if (response.getHits().getTotalHits().value > 0) {\n-            String monitorId = response.getHits().getAt(0).getId();\n-            if (monitorId != null) {\n-                // check if any monitor running on the detector, if yes, we can't delete the detector\n-                channel.sendResponse(new BytesRestResponse(RestStatus.BAD_REQUEST, \"Detector is used by monitor: \" + monitorId));\n+    private void onGetAdJobResponse(GetResponse response, RestChannel channel, AnomalyDetectorFunction function) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0ad539154b87212be6c64d5a9ea80f3f8d95b3ab"}, "originalPosition": 89}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA4NzQ1Ng==", "bodyText": "Using  deleteResponse.getResult() == DocWriteResponse.Result.DELETED is more robust than comparing string as the string can change and compiler won't detect the change.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/44#discussion_r383087456", "createdAt": "2020-02-24T05:07:30Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/rest/handler/IndexAnomalyDetectorJobActionHandler.java", "diffHunk": "@@ -0,0 +1,332 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.rest.handler;\n+\n+import com.amazon.opendistroforelasticsearch.ad.AnomalyDetectorPlugin;\n+import com.amazon.opendistroforelasticsearch.ad.indices.AnomalyDetectionIndices;\n+import com.amazon.opendistroforelasticsearch.ad.model.AnomalyDetector;\n+import com.amazon.opendistroforelasticsearch.ad.model.AnomalyDetectorJob;\n+import com.amazon.opendistroforelasticsearch.ad.model.IntervalTimeConfiguration;\n+import com.amazon.opendistroforelasticsearch.ad.transport.StopDetectorAction;\n+import com.amazon.opendistroforelasticsearch.ad.transport.StopDetectorRequest;\n+import com.amazon.opendistroforelasticsearch.ad.transport.StopDetectorResponse;\n+import com.amazon.opendistroforelasticsearch.ad.util.RestHandlerUtils;\n+import com.amazon.opendistroforelasticsearch.jobscheduler.spi.schedule.IntervalSchedule;\n+import com.amazon.opendistroforelasticsearch.jobscheduler.spi.schedule.Schedule;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.admin.indices.create.CreateIndexResponse;\n+import org.elasticsearch.action.delete.DeleteRequest;\n+import org.elasticsearch.action.get.GetRequest;\n+import org.elasticsearch.action.get.GetResponse;\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.action.index.IndexResponse;\n+import org.elasticsearch.action.support.WriteRequest;\n+import org.elasticsearch.client.node.NodeClient;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.LoggingDeprecationHandler;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.common.xcontent.XContentType;\n+import org.elasticsearch.rest.BytesRestResponse;\n+import org.elasticsearch.rest.RestChannel;\n+import org.elasticsearch.rest.RestResponse;\n+import org.elasticsearch.rest.RestStatus;\n+import org.elasticsearch.rest.action.RestResponseListener;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.Instant;\n+import java.util.Locale;\n+\n+import static com.amazon.opendistroforelasticsearch.ad.model.AnomalyDetector.ANOMALY_DETECTORS_INDEX;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.MAX_ANOMALY_DETECTORS;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.MAX_ANOMALY_FEATURES;\n+import static com.amazon.opendistroforelasticsearch.ad.util.RestHandlerUtils.XCONTENT_WITH_TYPE;\n+import static org.elasticsearch.common.xcontent.ToXContent.EMPTY_PARAMS;\n+import static org.elasticsearch.common.xcontent.XContentParserUtils.ensureExpectedToken;\n+\n+/**\n+ * Anomaly detector job REST action handler to process POST/PUT request.\n+ */\n+public class IndexAnomalyDetectorJobActionHandler extends AbstractActionHandler {\n+\n+    private final AnomalyDetectionIndices anomalyDetectionIndices;\n+    private final String detectorId;\n+    private final Long seqNo;\n+    private final Long primaryTerm;\n+    private final WriteRequest.RefreshPolicy refreshPolicy;\n+    private final ClusterService clusterService;\n+\n+    private final Logger logger = LogManager.getLogger(IndexAnomalyDetectorJobActionHandler.class);\n+    private final TimeValue requestTimeout;\n+    private volatile Integer maxAnomalyDetectors;\n+    private volatile Integer maxAnomalyFeatures;\n+    private final AnomalyDetectorActionHandler handler = new AnomalyDetectorActionHandler();\n+\n+    /**\n+     * Constructor function.\n+     *\n+     * @param settings                ES settings\n+     * @param clusterService          ClusterService\n+     * @param client                  ES node client that executes actions on the local node\n+     * @param channel                 ES channel used to construct bytes / builder based outputs, and send responses\n+     * @param anomalyDetectionIndices anomaly detector index manager\n+     * @param detectorId              detector identifier\n+     * @param seqNo                   sequence number of last modification\n+     * @param primaryTerm             primary term of last modification\n+     * @param refreshPolicy           refresh policy\n+     * @param requestTimeout          request time out configuration\n+     */\n+    public IndexAnomalyDetectorJobActionHandler(\n+        Settings settings,\n+        ClusterService clusterService,\n+        NodeClient client,\n+        RestChannel channel,\n+        AnomalyDetectionIndices anomalyDetectionIndices,\n+        String detectorId,\n+        Long seqNo,\n+        Long primaryTerm,\n+        WriteRequest.RefreshPolicy refreshPolicy,\n+        TimeValue requestTimeout\n+    ) {\n+        super(client, channel);\n+        this.clusterService = clusterService;\n+        this.anomalyDetectionIndices = anomalyDetectionIndices;\n+        this.detectorId = detectorId;\n+        this.seqNo = seqNo;\n+        this.primaryTerm = primaryTerm;\n+        this.refreshPolicy = refreshPolicy;\n+        this.requestTimeout = requestTimeout;\n+        maxAnomalyDetectors = MAX_ANOMALY_DETECTORS.get(settings);\n+        maxAnomalyFeatures = MAX_ANOMALY_FEATURES.get(settings);\n+        clusterService.getClusterSettings().addSettingsUpdateConsumer(MAX_ANOMALY_DETECTORS, it -> maxAnomalyDetectors = it);\n+        clusterService.getClusterSettings().addSettingsUpdateConsumer(MAX_ANOMALY_FEATURES, it -> maxAnomalyFeatures = it);\n+    }\n+\n+    /**\n+     * Start function to process create/update anomaly detector job request.\n+     * Check if anomaly detector job index exist first, if not, will create first.\n+     *\n+     * @throws IOException IOException from {@link AnomalyDetectionIndices#initAnomalyDetectorIndexIfAbsent(ActionListener)}\n+     */\n+    public void start() throws IOException {\n+        if (!anomalyDetectionIndices.doesAnomalyDetectorJobIndexExist()) {\n+            anomalyDetectionIndices\n+                .initAnomalyDetectorIndex(\n+                    ActionListener.wrap(response -> onCreateMappingsResponse(response), exception -> onFailure(exception))\n+                );\n+        } else {\n+            prepareAnomalyDetectorJobIndexing();\n+        }\n+    }\n+\n+    /**\n+     * Create anomaly detector job.\n+     *\n+     * @throws IOException IOException from {@link AnomalyDetectionIndices#getAnomalyDetectorJobMappings}\n+     */\n+    public void createAnomalyDetectorJob() throws IOException {\n+        if (!anomalyDetectionIndices.doesAnomalyDetectorJobIndexExist()) {\n+            anomalyDetectionIndices\n+                .initAnomalyDetectorJobIndex(\n+                    ActionListener.wrap(response -> onCreateMappingsResponse(response), exception -> onFailure(exception))\n+                );\n+        } else {\n+            prepareAnomalyDetectorJobIndexing();\n+        }\n+    }\n+\n+    private void prepareAnomalyDetectorJobIndexing() {\n+        GetRequest getRequest = new GetRequest(AnomalyDetector.ANOMALY_DETECTORS_INDEX).id(detectorId);\n+        client.get(getRequest, ActionListener.wrap(response -> onGetAnomalyDetectorResponse(response), exception -> onFailure(exception)));\n+    }\n+\n+    private void onGetAnomalyDetectorResponse(GetResponse response) throws IOException {\n+        if (!response.isExists()) {\n+            XContentBuilder builder = channel\n+                .newErrorBuilder()\n+                .startObject()\n+                .field(\"Message\", \"AnomalyDetector is not found with id: \" + detectorId)\n+                .endObject();\n+            channel.sendResponse(new BytesRestResponse(RestStatus.NOT_FOUND, response.toXContent(builder, EMPTY_PARAMS)));\n+            return;\n+        }\n+        XContentParser parser = XContentType.JSON\n+            .xContent()\n+            .createParser(\n+                channel.request().getXContentRegistry(),\n+                LoggingDeprecationHandler.INSTANCE,\n+                response.getSourceAsBytesRef().streamInput()\n+            );\n+\n+        ensureExpectedToken(XContentParser.Token.START_OBJECT, parser.nextToken(), parser::getTokenLocation);\n+        AnomalyDetector detector = AnomalyDetector.parse(parser, response.getId(), response.getVersion());\n+\n+        IntervalTimeConfiguration interval = (IntervalTimeConfiguration) detector.getDetectionInterval();\n+        Schedule schedule = new IntervalSchedule(Instant.now(), (int) interval.getInterval(), interval.getUnit());\n+        Duration duration = Duration.of(interval.getInterval(), interval.getUnit());\n+        AnomalyDetectorJob job = new AnomalyDetectorJob(\n+            detector.getDetectorId(),\n+            schedule,\n+            true,\n+            Instant.now(),\n+            Instant.now(),\n+            duration.getSeconds()\n+        );\n+\n+        getAnomalyDetectorJob(job);\n+    }\n+\n+    private void getAnomalyDetectorJob(AnomalyDetectorJob job) {\n+        GetRequest getRequest = new GetRequest(AnomalyDetectorJob.ANOMALY_DETECTOR_JOB_INDEX).id(detectorId);\n+\n+        client.get(getRequest, ActionListener.wrap(response -> onGetAnomalyDetectorJob(response, job), exception -> onFailure(exception)));\n+    }\n+\n+    private void onGetAnomalyDetectorJob(GetResponse response, AnomalyDetectorJob job) throws IOException {\n+        if (response.isExists()) {\n+            XContentBuilder builder = channel\n+                .newErrorBuilder()\n+                .startObject()\n+                .field(\"Message\", \"AnomalyDetectorJob exists: \" + detectorId)\n+                .endObject();\n+            channel.sendResponse(new BytesRestResponse(RestStatus.NOT_FOUND, response.toXContent(builder, EMPTY_PARAMS)));\n+            return;\n+        }\n+\n+        indexAnomalyDetectorJob(job);\n+    }\n+\n+    private void indexAnomalyDetectorJob(AnomalyDetectorJob job) throws IOException {\n+        IndexRequest indexRequest = new IndexRequest(AnomalyDetectorJob.ANOMALY_DETECTOR_JOB_INDEX)\n+            .setRefreshPolicy(refreshPolicy)\n+            .source(job.toXContent(channel.newBuilder(), XCONTENT_WITH_TYPE))\n+            .setIfSeqNo(seqNo)\n+            .setIfPrimaryTerm(primaryTerm)\n+            .timeout(requestTimeout);\n+        if (detectorId != null) {\n+            indexRequest.id(detectorId);\n+        }\n+        client.index(indexRequest, indexAnomalyDetectorJobResponse());\n+    }\n+\n+    private ActionListener<IndexResponse> indexAnomalyDetectorJobResponse() {\n+        return new RestResponseListener<IndexResponse>(channel) {\n+            @Override\n+            public RestResponse buildResponse(IndexResponse response) throws Exception {\n+                if (response.getShardInfo().getSuccessful() < 1) {\n+                    return new BytesRestResponse(response.status(), response.toXContent(channel.newErrorBuilder(), EMPTY_PARAMS));\n+                }\n+\n+                XContentBuilder builder = channel\n+                    .newBuilder()\n+                    .startObject()\n+                    .field(RestHandlerUtils._ID, response.getId())\n+                    .field(RestHandlerUtils._VERSION, response.getVersion())\n+                    .field(RestHandlerUtils._SEQ_NO, response.getSeqNo())\n+                    .field(RestHandlerUtils._PRIMARY_TERM, response.getPrimaryTerm())\n+                    .endObject();\n+\n+                BytesRestResponse restResponse = new BytesRestResponse(response.status(), builder);\n+                if (response.status() == RestStatus.CREATED) {\n+                    String location = String.format(Locale.ROOT, \"%s/%s\", AnomalyDetectorPlugin.AD_BASE_URI, response.getId());\n+                    restResponse.addHeader(\"Location\", location);\n+                }\n+                return restResponse;\n+            }\n+        };\n+    }\n+\n+    private void onCreateMappingsResponse(CreateIndexResponse response) throws IOException {\n+        if (response.isAcknowledged()) {\n+            logger.info(\"Created {} with mappings.\", ANOMALY_DETECTORS_INDEX);\n+            prepareAnomalyDetectorJobIndexing();\n+        } else {\n+            logger.warn(\"Created {} with mappings call not acknowledged.\", ANOMALY_DETECTORS_INDEX);\n+            channel\n+                .sendResponse(\n+                    new BytesRestResponse(RestStatus.INTERNAL_SERVER_ERROR, response.toXContent(channel.newErrorBuilder(), EMPTY_PARAMS))\n+                );\n+        }\n+    }\n+\n+    /**\n+     * Delete anomaly detector job\n+     * @param detectorId detector identifier\n+     */\n+    public void deleteAnomalyDetectorJob(String detectorId) {\n+        GetRequest getRequest = new GetRequest(AnomalyDetectorJob.ANOMALY_DETECTOR_JOB_INDEX).id(detectorId);\n+\n+        client\n+            .get(\n+                getRequest,\n+                ActionListener\n+                    .wrap(\n+                        response -> deleteAnomalyDetectorJobDoc(client, detectorId, channel, refreshPolicy),\n+                        exception -> onFailure(exception)\n+                    )\n+            );\n+    }\n+\n+    private void deleteAnomalyDetectorJobDoc(\n+        NodeClient client,\n+        String detectorId,\n+        RestChannel channel,\n+        WriteRequest.RefreshPolicy refreshPolicy\n+    ) {\n+        logger.info(\"Delete anomaly detector job {}\", detectorId);\n+        DeleteRequest deleteRequest = new DeleteRequest(AnomalyDetectorJob.ANOMALY_DETECTOR_JOB_INDEX, detectorId)\n+            .setRefreshPolicy(refreshPolicy);\n+        client.delete(deleteRequest, ActionListener.wrap(response -> {\n+            if (\"deleted\".equals(response.getResult().getLowercase())) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0ad539154b87212be6c64d5a9ea80f3f8d95b3ab"}, "originalPosition": 298}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA4Nzg5NQ==", "bodyText": "If we deleted AD job but fail to stop AD model, do you allow people to run delete AD job again?  In other words, how do you handle response.getResult() == DocWriteResponse.Result.NOT_FOUND?", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/44#discussion_r383087895", "createdAt": "2020-02-24T05:10:40Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/rest/handler/IndexAnomalyDetectorJobActionHandler.java", "diffHunk": "@@ -0,0 +1,332 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.rest.handler;\n+\n+import com.amazon.opendistroforelasticsearch.ad.AnomalyDetectorPlugin;\n+import com.amazon.opendistroforelasticsearch.ad.indices.AnomalyDetectionIndices;\n+import com.amazon.opendistroforelasticsearch.ad.model.AnomalyDetector;\n+import com.amazon.opendistroforelasticsearch.ad.model.AnomalyDetectorJob;\n+import com.amazon.opendistroforelasticsearch.ad.model.IntervalTimeConfiguration;\n+import com.amazon.opendistroforelasticsearch.ad.transport.StopDetectorAction;\n+import com.amazon.opendistroforelasticsearch.ad.transport.StopDetectorRequest;\n+import com.amazon.opendistroforelasticsearch.ad.transport.StopDetectorResponse;\n+import com.amazon.opendistroforelasticsearch.ad.util.RestHandlerUtils;\n+import com.amazon.opendistroforelasticsearch.jobscheduler.spi.schedule.IntervalSchedule;\n+import com.amazon.opendistroforelasticsearch.jobscheduler.spi.schedule.Schedule;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.admin.indices.create.CreateIndexResponse;\n+import org.elasticsearch.action.delete.DeleteRequest;\n+import org.elasticsearch.action.get.GetRequest;\n+import org.elasticsearch.action.get.GetResponse;\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.action.index.IndexResponse;\n+import org.elasticsearch.action.support.WriteRequest;\n+import org.elasticsearch.client.node.NodeClient;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.LoggingDeprecationHandler;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.common.xcontent.XContentType;\n+import org.elasticsearch.rest.BytesRestResponse;\n+import org.elasticsearch.rest.RestChannel;\n+import org.elasticsearch.rest.RestResponse;\n+import org.elasticsearch.rest.RestStatus;\n+import org.elasticsearch.rest.action.RestResponseListener;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.Instant;\n+import java.util.Locale;\n+\n+import static com.amazon.opendistroforelasticsearch.ad.model.AnomalyDetector.ANOMALY_DETECTORS_INDEX;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.MAX_ANOMALY_DETECTORS;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.MAX_ANOMALY_FEATURES;\n+import static com.amazon.opendistroforelasticsearch.ad.util.RestHandlerUtils.XCONTENT_WITH_TYPE;\n+import static org.elasticsearch.common.xcontent.ToXContent.EMPTY_PARAMS;\n+import static org.elasticsearch.common.xcontent.XContentParserUtils.ensureExpectedToken;\n+\n+/**\n+ * Anomaly detector job REST action handler to process POST/PUT request.\n+ */\n+public class IndexAnomalyDetectorJobActionHandler extends AbstractActionHandler {\n+\n+    private final AnomalyDetectionIndices anomalyDetectionIndices;\n+    private final String detectorId;\n+    private final Long seqNo;\n+    private final Long primaryTerm;\n+    private final WriteRequest.RefreshPolicy refreshPolicy;\n+    private final ClusterService clusterService;\n+\n+    private final Logger logger = LogManager.getLogger(IndexAnomalyDetectorJobActionHandler.class);\n+    private final TimeValue requestTimeout;\n+    private volatile Integer maxAnomalyDetectors;\n+    private volatile Integer maxAnomalyFeatures;\n+    private final AnomalyDetectorActionHandler handler = new AnomalyDetectorActionHandler();\n+\n+    /**\n+     * Constructor function.\n+     *\n+     * @param settings                ES settings\n+     * @param clusterService          ClusterService\n+     * @param client                  ES node client that executes actions on the local node\n+     * @param channel                 ES channel used to construct bytes / builder based outputs, and send responses\n+     * @param anomalyDetectionIndices anomaly detector index manager\n+     * @param detectorId              detector identifier\n+     * @param seqNo                   sequence number of last modification\n+     * @param primaryTerm             primary term of last modification\n+     * @param refreshPolicy           refresh policy\n+     * @param requestTimeout          request time out configuration\n+     */\n+    public IndexAnomalyDetectorJobActionHandler(\n+        Settings settings,\n+        ClusterService clusterService,\n+        NodeClient client,\n+        RestChannel channel,\n+        AnomalyDetectionIndices anomalyDetectionIndices,\n+        String detectorId,\n+        Long seqNo,\n+        Long primaryTerm,\n+        WriteRequest.RefreshPolicy refreshPolicy,\n+        TimeValue requestTimeout\n+    ) {\n+        super(client, channel);\n+        this.clusterService = clusterService;\n+        this.anomalyDetectionIndices = anomalyDetectionIndices;\n+        this.detectorId = detectorId;\n+        this.seqNo = seqNo;\n+        this.primaryTerm = primaryTerm;\n+        this.refreshPolicy = refreshPolicy;\n+        this.requestTimeout = requestTimeout;\n+        maxAnomalyDetectors = MAX_ANOMALY_DETECTORS.get(settings);\n+        maxAnomalyFeatures = MAX_ANOMALY_FEATURES.get(settings);\n+        clusterService.getClusterSettings().addSettingsUpdateConsumer(MAX_ANOMALY_DETECTORS, it -> maxAnomalyDetectors = it);\n+        clusterService.getClusterSettings().addSettingsUpdateConsumer(MAX_ANOMALY_FEATURES, it -> maxAnomalyFeatures = it);\n+    }\n+\n+    /**\n+     * Start function to process create/update anomaly detector job request.\n+     * Check if anomaly detector job index exist first, if not, will create first.\n+     *\n+     * @throws IOException IOException from {@link AnomalyDetectionIndices#initAnomalyDetectorIndexIfAbsent(ActionListener)}\n+     */\n+    public void start() throws IOException {\n+        if (!anomalyDetectionIndices.doesAnomalyDetectorJobIndexExist()) {\n+            anomalyDetectionIndices\n+                .initAnomalyDetectorIndex(\n+                    ActionListener.wrap(response -> onCreateMappingsResponse(response), exception -> onFailure(exception))\n+                );\n+        } else {\n+            prepareAnomalyDetectorJobIndexing();\n+        }\n+    }\n+\n+    /**\n+     * Create anomaly detector job.\n+     *\n+     * @throws IOException IOException from {@link AnomalyDetectionIndices#getAnomalyDetectorJobMappings}\n+     */\n+    public void createAnomalyDetectorJob() throws IOException {\n+        if (!anomalyDetectionIndices.doesAnomalyDetectorJobIndexExist()) {\n+            anomalyDetectionIndices\n+                .initAnomalyDetectorJobIndex(\n+                    ActionListener.wrap(response -> onCreateMappingsResponse(response), exception -> onFailure(exception))\n+                );\n+        } else {\n+            prepareAnomalyDetectorJobIndexing();\n+        }\n+    }\n+\n+    private void prepareAnomalyDetectorJobIndexing() {\n+        GetRequest getRequest = new GetRequest(AnomalyDetector.ANOMALY_DETECTORS_INDEX).id(detectorId);\n+        client.get(getRequest, ActionListener.wrap(response -> onGetAnomalyDetectorResponse(response), exception -> onFailure(exception)));\n+    }\n+\n+    private void onGetAnomalyDetectorResponse(GetResponse response) throws IOException {\n+        if (!response.isExists()) {\n+            XContentBuilder builder = channel\n+                .newErrorBuilder()\n+                .startObject()\n+                .field(\"Message\", \"AnomalyDetector is not found with id: \" + detectorId)\n+                .endObject();\n+            channel.sendResponse(new BytesRestResponse(RestStatus.NOT_FOUND, response.toXContent(builder, EMPTY_PARAMS)));\n+            return;\n+        }\n+        XContentParser parser = XContentType.JSON\n+            .xContent()\n+            .createParser(\n+                channel.request().getXContentRegistry(),\n+                LoggingDeprecationHandler.INSTANCE,\n+                response.getSourceAsBytesRef().streamInput()\n+            );\n+\n+        ensureExpectedToken(XContentParser.Token.START_OBJECT, parser.nextToken(), parser::getTokenLocation);\n+        AnomalyDetector detector = AnomalyDetector.parse(parser, response.getId(), response.getVersion());\n+\n+        IntervalTimeConfiguration interval = (IntervalTimeConfiguration) detector.getDetectionInterval();\n+        Schedule schedule = new IntervalSchedule(Instant.now(), (int) interval.getInterval(), interval.getUnit());\n+        Duration duration = Duration.of(interval.getInterval(), interval.getUnit());\n+        AnomalyDetectorJob job = new AnomalyDetectorJob(\n+            detector.getDetectorId(),\n+            schedule,\n+            true,\n+            Instant.now(),\n+            Instant.now(),\n+            duration.getSeconds()\n+        );\n+\n+        getAnomalyDetectorJob(job);\n+    }\n+\n+    private void getAnomalyDetectorJob(AnomalyDetectorJob job) {\n+        GetRequest getRequest = new GetRequest(AnomalyDetectorJob.ANOMALY_DETECTOR_JOB_INDEX).id(detectorId);\n+\n+        client.get(getRequest, ActionListener.wrap(response -> onGetAnomalyDetectorJob(response, job), exception -> onFailure(exception)));\n+    }\n+\n+    private void onGetAnomalyDetectorJob(GetResponse response, AnomalyDetectorJob job) throws IOException {\n+        if (response.isExists()) {\n+            XContentBuilder builder = channel\n+                .newErrorBuilder()\n+                .startObject()\n+                .field(\"Message\", \"AnomalyDetectorJob exists: \" + detectorId)\n+                .endObject();\n+            channel.sendResponse(new BytesRestResponse(RestStatus.NOT_FOUND, response.toXContent(builder, EMPTY_PARAMS)));\n+            return;\n+        }\n+\n+        indexAnomalyDetectorJob(job);\n+    }\n+\n+    private void indexAnomalyDetectorJob(AnomalyDetectorJob job) throws IOException {\n+        IndexRequest indexRequest = new IndexRequest(AnomalyDetectorJob.ANOMALY_DETECTOR_JOB_INDEX)\n+            .setRefreshPolicy(refreshPolicy)\n+            .source(job.toXContent(channel.newBuilder(), XCONTENT_WITH_TYPE))\n+            .setIfSeqNo(seqNo)\n+            .setIfPrimaryTerm(primaryTerm)\n+            .timeout(requestTimeout);\n+        if (detectorId != null) {\n+            indexRequest.id(detectorId);\n+        }\n+        client.index(indexRequest, indexAnomalyDetectorJobResponse());\n+    }\n+\n+    private ActionListener<IndexResponse> indexAnomalyDetectorJobResponse() {\n+        return new RestResponseListener<IndexResponse>(channel) {\n+            @Override\n+            public RestResponse buildResponse(IndexResponse response) throws Exception {\n+                if (response.getShardInfo().getSuccessful() < 1) {\n+                    return new BytesRestResponse(response.status(), response.toXContent(channel.newErrorBuilder(), EMPTY_PARAMS));\n+                }\n+\n+                XContentBuilder builder = channel\n+                    .newBuilder()\n+                    .startObject()\n+                    .field(RestHandlerUtils._ID, response.getId())\n+                    .field(RestHandlerUtils._VERSION, response.getVersion())\n+                    .field(RestHandlerUtils._SEQ_NO, response.getSeqNo())\n+                    .field(RestHandlerUtils._PRIMARY_TERM, response.getPrimaryTerm())\n+                    .endObject();\n+\n+                BytesRestResponse restResponse = new BytesRestResponse(response.status(), builder);\n+                if (response.status() == RestStatus.CREATED) {\n+                    String location = String.format(Locale.ROOT, \"%s/%s\", AnomalyDetectorPlugin.AD_BASE_URI, response.getId());\n+                    restResponse.addHeader(\"Location\", location);\n+                }\n+                return restResponse;\n+            }\n+        };\n+    }\n+\n+    private void onCreateMappingsResponse(CreateIndexResponse response) throws IOException {\n+        if (response.isAcknowledged()) {\n+            logger.info(\"Created {} with mappings.\", ANOMALY_DETECTORS_INDEX);\n+            prepareAnomalyDetectorJobIndexing();\n+        } else {\n+            logger.warn(\"Created {} with mappings call not acknowledged.\", ANOMALY_DETECTORS_INDEX);\n+            channel\n+                .sendResponse(\n+                    new BytesRestResponse(RestStatus.INTERNAL_SERVER_ERROR, response.toXContent(channel.newErrorBuilder(), EMPTY_PARAMS))\n+                );\n+        }\n+    }\n+\n+    /**\n+     * Delete anomaly detector job\n+     * @param detectorId detector identifier\n+     */\n+    public void deleteAnomalyDetectorJob(String detectorId) {\n+        GetRequest getRequest = new GetRequest(AnomalyDetectorJob.ANOMALY_DETECTOR_JOB_INDEX).id(detectorId);\n+\n+        client\n+            .get(\n+                getRequest,\n+                ActionListener\n+                    .wrap(\n+                        response -> deleteAnomalyDetectorJobDoc(client, detectorId, channel, refreshPolicy),\n+                        exception -> onFailure(exception)\n+                    )\n+            );\n+    }\n+\n+    private void deleteAnomalyDetectorJobDoc(\n+        NodeClient client,\n+        String detectorId,\n+        RestChannel channel,\n+        WriteRequest.RefreshPolicy refreshPolicy\n+    ) {\n+        logger.info(\"Delete anomaly detector job {}\", detectorId);\n+        DeleteRequest deleteRequest = new DeleteRequest(AnomalyDetectorJob.ANOMALY_DETECTOR_JOB_INDEX, detectorId)\n+            .setRefreshPolicy(refreshPolicy);\n+        client.delete(deleteRequest, ActionListener.wrap(response -> {\n+            if (\"deleted\".equals(response.getResult().getLowercase())) {\n+                logger.info(\"Stop anomaly detector {}\", detectorId);\n+                StopDetectorRequest stopDetectorRequest = new StopDetectorRequest(detectorId);\n+                client.execute(StopDetectorAction.INSTANCE, stopDetectorRequest, stopAdDetectorListener(channel, detectorId));\n+            } else {\n+                channel.sendResponse(new BytesRestResponse(RestStatus.BAD_REQUEST, \"Failed to stop AD job \" + detectorId));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0ad539154b87212be6c64d5a9ea80f3f8d95b3ab"}, "originalPosition": 303}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA4ODUzMw==", "bodyText": "When we delete, it should always be WriteRequest.RefreshPolicy.IMMEDIATE.  We don't need a customization.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/44#discussion_r383088533", "createdAt": "2020-02-24T05:15:56Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/rest/RestDeleteAnomalyDetectorAction.java", "diffHunk": "@@ -117,23 +97,4 @@ private void deleteAnomalyDetectorDoc(\n         client.delete(deleteRequest, new RestStatusToXContentListener<>(channel));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0ad539154b87212be6c64d5a9ea80f3f8d95b3ab"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4MzA4OTI4NA==", "bodyText": "What will happen if we delete a detector that has an ad job running?", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/44#discussion_r383089284", "createdAt": "2020-02-24T05:21:51Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/rest/RestDeleteAnomalyDetectorAction.java", "diffHunk": "@@ -117,23 +97,4 @@ private void deleteAnomalyDetectorDoc(\n         client.delete(deleteRequest, new RestStatusToXContentListener<>(channel));\n     }\n ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0ad539154b87212be6c64d5a9ea80f3f8d95b3ab"}, "originalPosition": 81}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c89f6617f26b914f00cd2f26ea130c59580a9174", "author": {"user": {"login": "ylwu-amzn", "name": "Yaliang"}}, "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/c89f6617f26b914f00cd2f26ea130c59580a9174", "committedDate": "2020-02-26T18:27:04Z", "message": "fix comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "468e337182e5e3724db87f4e95bd7936c32e66c5", "author": {"user": {"login": "ylwu-amzn", "name": "Yaliang"}}, "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/468e337182e5e3724db87f4e95bd7936c32e66c5", "committedDate": "2020-02-26T18:40:32Z", "message": "Merge remote-tracking branch 'upstream/development' into development"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "de8f27737498c215f680201a14653bfa928daff3", "author": {"user": {"login": "ylwu-amzn", "name": "Yaliang"}}, "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/de8f27737498c215f680201a14653bfa928daff3", "committedDate": "2020-02-26T19:28:48Z", "message": "upgrade jobscheduler to 1.4"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY1Mzc1ODEz", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/44#pullrequestreview-365375813", "createdAt": "2020-02-27T02:21:36Z", "commit": {"oid": "de8f27737498c215f680201a14653bfa928daff3"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QwMjoyMTozN1rOFvDMUg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QwMjoyMTozN1rOFvDMUg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDg3OTY5OA==", "bodyText": "To limit PR size. Will publish another PR to return both detector and detector job.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/44#discussion_r384879698", "createdAt": "2020-02-27T02:21:37Z", "author": {"login": "ylwu-amzn"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/rest/RestGetAnomalyDetectorAction.java", "diffHunk": "@@ -68,47 +74,62 @@ public String getName() {\n     @Override\n     protected RestChannelConsumer prepareRequest(RestRequest request, NodeClient client) throws IOException {\n         String detectorId = request.param(DETECTOR_ID);\n-        GetRequest getRequest = new GetRequest(ANOMALY_DETECTORS_INDEX, detectorId)\n-            .version(RestActions.parseVersion(request))\n-            .fetchSourceContext(RestHandlerUtils.getSourceContext(request));\n-        return channel -> client.get(getRequest, getDetectorResponse(channel));\n+        MultiGetRequest.Item adItem = new MultiGetRequest.Item(ANOMALY_DETECTORS_INDEX, detectorId)\n+            .version(RestActions.parseVersion(request));\n+        MultiGetRequest.Item adJobItem = new MultiGetRequest.Item(ANOMALY_DETECTOR_JOB_INDEX, detectorId)\n+            .version(RestActions.parseVersion(request));\n+        MultiGetRequest multiGetRequest = new MultiGetRequest().add(adItem).add(adJobItem);\n+        return channel -> client.multiGet(multiGetRequest, onMultiGetResponse(channel));\n     }\n \n-    private RestResponseListener<GetResponse> getDetectorResponse(RestChannel channel) {\n-        return new RestResponseListener<GetResponse>(channel) {\n-\n+    private ActionListener<MultiGetResponse> onMultiGetResponse(RestChannel channel) {\n+        return new RestResponseListener<MultiGetResponse>(channel) {\n             @Override\n-            public RestResponse buildResponse(GetResponse response) throws Exception {\n-                if (!response.isExists()) {\n-                    return new BytesRestResponse(RestStatus.NOT_FOUND, channel.newBuilder());\n-                }\n+            public RestResponse buildResponse(MultiGetResponse multiGetResponse) throws Exception {\n+                MultiGetItemResponse[] responses = multiGetResponse.getResponses();\n+                AnomalyDetector detector = null;\n+                XContentBuilder builder = null;\n+                Boolean adJobEnabled = false;\n+                for (MultiGetItemResponse response : responses) {\n+                    if (ANOMALY_DETECTORS_INDEX.equals(response.getIndex())) {\n+                        if (!response.getResponse().isExists()) {\n+                            return new BytesRestResponse(RestStatus.NOT_FOUND, channel.newBuilder());\n+                        }\n+                        builder = channel\n+                            .newBuilder()\n+                            .startObject()\n+                            .field(RestHandlerUtils._ID, response.getId())\n+                            .field(RestHandlerUtils._VERSION, response.getResponse().getVersion())\n+                            .field(RestHandlerUtils._PRIMARY_TERM, response.getResponse().getPrimaryTerm())\n+                            .field(RestHandlerUtils._SEQ_NO, response.getResponse().getSeqNo());\n+                        if (!response.getResponse().isSourceEmpty()) {\n+                            XContentParser parser = XContentHelper\n+                                .createParser(\n+                                    channel.request().getXContentRegistry(),\n+                                    LoggingDeprecationHandler.INSTANCE,\n+                                    response.getResponse().getSourceAsBytesRef(),\n+                                    XContentType.JSON\n+                                );\n+                            try {\n+                                ensureExpectedToken(XContentParser.Token.START_OBJECT, parser.nextToken(), parser::getTokenLocation);\n+                                detector = parser.namedObject(AnomalyDetector.class, AnomalyDetector.PARSE_FIELD_NAME, null);\n+                            } catch (Throwable t) {\n+                                logger.error(\"Fail to parse detector\", t);\n+                                throw t;\n+                            } finally {\n+                                parser.close();\n+                            }\n+                        }\n+                    }\n \n-                XContentBuilder builder = channel\n-                    .newBuilder()\n-                    .startObject()\n-                    .field(RestHandlerUtils._ID, response.getId())\n-                    .field(RestHandlerUtils._VERSION, response.getVersion())\n-                    .field(RestHandlerUtils._PRIMARY_TERM, response.getPrimaryTerm())\n-                    .field(RestHandlerUtils._SEQ_NO, response.getSeqNo());\n-                if (!response.isSourceEmpty()) {\n-                    XContentParser parser = XContentHelper\n-                        .createParser(\n-                            channel.request().getXContentRegistry(),\n-                            LoggingDeprecationHandler.INSTANCE,\n-                            response.getSourceAsBytesRef(),\n-                            XContentType.JSON\n-                        );\n-                    try {\n-                        ensureExpectedToken(XContentParser.Token.START_OBJECT, parser.nextToken(), parser::getTokenLocation);\n-                        AnomalyDetector detector = parser.namedObject(AnomalyDetector.class, AnomalyDetector.PARSE_FIELD_NAME, null);\n-                        builder.field(RestHandlerUtils.ANOMALY_DETECTOR, detector);\n-                    } catch (Throwable t) {\n-                        logger.error(\"Fail to parse detector\", t);\n-                        throw t;\n-                    } finally {\n-                        parser.close();\n+                    if (ANOMALY_DETECTOR_JOB_INDEX.equals(response.getIndex())) {\n+                        if (!response.isFailed() && response.getResponse().isExists()) {\n+                            adJobEnabled = true;\n+                        }\n                     }\n                 }\n+                ToXContent.Params params = new ToXContent.MapParams(ImmutableMap.of(ENABLED_FIELD, adJobEnabled.toString()));\n+                builder.field(RestHandlerUtils.ANOMALY_DETECTOR, detector, params);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "de8f27737498c215f680201a14653bfa928daff3"}, "originalPosition": 123}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY1NDAwNTcy", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/44#pullrequestreview-365400572", "createdAt": "2020-02-27T03:55:45Z", "commit": {"oid": "de8f27737498c215f680201a14653bfa928daff3"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY1OTE4MzU0", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/44#pullrequestreview-365918354", "createdAt": "2020-02-27T19:00:21Z", "commit": {"oid": "de8f27737498c215f680201a14653bfa928daff3"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QxOTowMDoyMVrOFvdY6g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QxOTowMDoyMVrOFvdY6g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTMwODkwNg==", "bodyText": "IllegalArgumentException?", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/44#discussion_r385308906", "createdAt": "2020-02-27T19:00:21Z", "author": {"login": "yizheliu-amazon"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/AnomalyDetectorJobRunner.java", "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad;\n+\n+import com.amazon.opendistroforelasticsearch.ad.model.AnomalyDetectorJob;\n+import com.amazon.opendistroforelasticsearch.ad.transport.AnomalyResultAction;\n+import com.amazon.opendistroforelasticsearch.ad.transport.AnomalyResultRequest;\n+import com.amazon.opendistroforelasticsearch.jobscheduler.spi.JobExecutionContext;\n+import com.amazon.opendistroforelasticsearch.jobscheduler.spi.LockModel;\n+import com.amazon.opendistroforelasticsearch.jobscheduler.spi.ScheduledJobParameter;\n+import com.amazon.opendistroforelasticsearch.jobscheduler.spi.ScheduledJobRunner;\n+import com.amazon.opendistroforelasticsearch.jobscheduler.spi.schedule.IntervalSchedule;\n+import com.amazon.opendistroforelasticsearch.jobscheduler.spi.utils.LockService;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.time.Duration;\n+import java.time.Instant;\n+import java.util.concurrent.ExecutorService;\n+\n+import static com.amazon.opendistroforelasticsearch.ad.AnomalyDetectorPlugin.AD_JOB_THREAD_POOL_NAME;\n+\n+/**\n+ * JobScheduler will call AD job runner to get anomaly result periodically\n+ */\n+public class AnomalyDetectorJobRunner implements ScheduledJobRunner {\n+    private static final Logger log = LogManager.getLogger(AnomalyDetectorJobRunner.class);\n+\n+    private static AnomalyDetectorJobRunner INSTANCE;\n+\n+    public static AnomalyDetectorJobRunner getJobRunnerInstance() {\n+        if (INSTANCE != null) {\n+            return INSTANCE;\n+        }\n+        synchronized (AnomalyDetectorJobRunner.class) {\n+            if (INSTANCE != null) {\n+                return INSTANCE;\n+            }\n+            INSTANCE = new AnomalyDetectorJobRunner();\n+            return INSTANCE;\n+        }\n+    }\n+\n+    private Client client;\n+    private ThreadPool threadPool;\n+\n+    private AnomalyDetectorJobRunner() {\n+        // Singleton class, use getJobRunnerInstance method instead of constructor\n+    }\n+\n+    public void setClient(Client client) {\n+        this.client = client;\n+    }\n+\n+    public void setThreadPool(ThreadPool threadPool) {\n+        this.threadPool = threadPool;\n+    }\n+\n+    @Override\n+    public void runJob(ScheduledJobParameter jobParameter, JobExecutionContext context) {\n+        log.info(\"Start to run AD job {}\", jobParameter.getName());\n+        if (!(jobParameter instanceof AnomalyDetectorJob)) {\n+            throw new IllegalStateException(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "de8f27737498c215f680201a14653bfa928daff3"}, "originalPosition": 79}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY1OTIxOTMx", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/44#pullrequestreview-365921931", "createdAt": "2020-02-27T19:05:37Z", "commit": {"oid": "de8f27737498c215f680201a14653bfa928daff3"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QxOTowNTozOFrOFvdjcA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QxOTowNTozOFrOFvdjcA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTMxMTYwMA==", "bodyText": "nit: group by public/private so that they are in separate group", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/44#discussion_r385311600", "createdAt": "2020-02-27T19:05:38Z", "author": {"login": "yizheliu-amazon"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/model/AnomalyDetectorJob.java", "diffHunk": "@@ -0,0 +1,172 @@\n+/*\n+ * Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.model;\n+\n+import com.amazon.opendistroforelasticsearch.ad.util.ParseUtils;\n+import com.amazon.opendistroforelasticsearch.jobscheduler.spi.ScheduledJobParameter;\n+import com.amazon.opendistroforelasticsearch.jobscheduler.spi.schedule.Schedule;\n+import com.amazon.opendistroforelasticsearch.jobscheduler.spi.schedule.ScheduleParser;\n+import com.google.common.base.Objects;\n+import org.elasticsearch.common.xcontent.ToXContentObject;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+\n+import java.io.IOException;\n+import java.time.Instant;\n+\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.DEFAULT_AD_JOB_LOC_DURATION_SECONDS;\n+import static org.elasticsearch.common.xcontent.XContentParserUtils.ensureExpectedToken;\n+\n+/**\n+ * Anomaly detector job.\n+ */\n+public class AnomalyDetectorJob implements ToXContentObject, ScheduledJobParameter {\n+\n+    public static final String ANOMALY_DETECTOR_JOB_INDEX = \".opendistro-anomaly-detector-jobs\";\n+\n+    public static final String NAME_FIELD = \"name\";\n+    private static final String SCHEDULE_FIELD = \"schedule\";\n+    private static final String IS_ENABLED_FIELD = \"enabled\";\n+    private static final String ENABLED_TIME_FIELD = \"enabled_time\";\n+    public static final String LAST_UPDATE_TIME_FIELD = \"last_update_time\";\n+    public static final String LOCK_DURATION_SECONDS = \"lock_duration_seconds\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "de8f27737498c215f680201a14653bfa928daff3"}, "originalPosition": 45}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY1OTMzMTk5", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/44#pullrequestreview-365933199", "createdAt": "2020-02-27T19:22:48Z", "commit": {"oid": "de8f27737498c215f680201a14653bfa928daff3"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QxOToyMjo0OFrOFveG8A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QxOToyMjo0OFrOFveG8A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTMyMDY4OA==", "bodyText": "nit: we may merge them together like this.\nif (response.getResult() == DocWriteResponse.Result.DELETED ||\n    response.getResult() == DocWriteResponse.Result.NOT_FOUND)", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/44#discussion_r385320688", "createdAt": "2020-02-27T19:22:48Z", "author": {"login": "yizheliu-amazon"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/rest/handler/IndexAnomalyDetectorJobActionHandler.java", "diffHunk": "@@ -0,0 +1,329 @@\n+/*\n+ * Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.rest.handler;\n+\n+import com.amazon.opendistroforelasticsearch.ad.AnomalyDetectorPlugin;\n+import com.amazon.opendistroforelasticsearch.ad.indices.AnomalyDetectionIndices;\n+import com.amazon.opendistroforelasticsearch.ad.model.AnomalyDetector;\n+import com.amazon.opendistroforelasticsearch.ad.model.AnomalyDetectorJob;\n+import com.amazon.opendistroforelasticsearch.ad.model.IntervalTimeConfiguration;\n+import com.amazon.opendistroforelasticsearch.ad.transport.StopDetectorAction;\n+import com.amazon.opendistroforelasticsearch.ad.transport.StopDetectorRequest;\n+import com.amazon.opendistroforelasticsearch.ad.transport.StopDetectorResponse;\n+import com.amazon.opendistroforelasticsearch.ad.util.RestHandlerUtils;\n+import com.amazon.opendistroforelasticsearch.jobscheduler.spi.schedule.IntervalSchedule;\n+import com.amazon.opendistroforelasticsearch.jobscheduler.spi.schedule.Schedule;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.DocWriteResponse;\n+import org.elasticsearch.action.admin.indices.create.CreateIndexResponse;\n+import org.elasticsearch.action.delete.DeleteRequest;\n+import org.elasticsearch.action.get.GetRequest;\n+import org.elasticsearch.action.get.GetResponse;\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.action.index.IndexResponse;\n+import org.elasticsearch.action.support.WriteRequest;\n+import org.elasticsearch.client.node.NodeClient;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.LoggingDeprecationHandler;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.common.xcontent.XContentType;\n+import org.elasticsearch.rest.BytesRestResponse;\n+import org.elasticsearch.rest.RestChannel;\n+import org.elasticsearch.rest.RestResponse;\n+import org.elasticsearch.rest.RestStatus;\n+import org.elasticsearch.rest.action.RestResponseListener;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.Instant;\n+import java.util.Locale;\n+\n+import static com.amazon.opendistroforelasticsearch.ad.model.AnomalyDetector.ANOMALY_DETECTORS_INDEX;\n+import static com.amazon.opendistroforelasticsearch.ad.util.RestHandlerUtils.XCONTENT_WITH_TYPE;\n+import static org.elasticsearch.common.xcontent.ToXContent.EMPTY_PARAMS;\n+import static org.elasticsearch.common.xcontent.XContentParserUtils.ensureExpectedToken;\n+\n+/**\n+ * Anomaly detector job REST action handler to process POST/PUT request.\n+ */\n+public class IndexAnomalyDetectorJobActionHandler extends AbstractActionHandler {\n+\n+    private final AnomalyDetectionIndices anomalyDetectionIndices;\n+    private final String detectorId;\n+    private final Long seqNo;\n+    private final Long primaryTerm;\n+    private final WriteRequest.RefreshPolicy refreshPolicy;\n+    private final ClusterService clusterService;\n+\n+    private final Logger logger = LogManager.getLogger(IndexAnomalyDetectorJobActionHandler.class);\n+    private final TimeValue requestTimeout;\n+    private volatile Integer maxAnomalyDetectors;\n+    private volatile Integer maxAnomalyFeatures;\n+    private final AnomalyDetectorActionHandler handler = new AnomalyDetectorActionHandler();\n+\n+    /**\n+     * Constructor function.\n+     *\n+     * @param clusterService          ClusterService\n+     * @param client                  ES node client that executes actions on the local node\n+     * @param channel                 ES channel used to construct bytes / builder based outputs, and send responses\n+     * @param anomalyDetectionIndices anomaly detector index manager\n+     * @param detectorId              detector identifier\n+     * @param seqNo                   sequence number of last modification\n+     * @param primaryTerm             primary term of last modification\n+     * @param refreshPolicy           refresh policy\n+     * @param requestTimeout          request time out configuration\n+     */\n+    public IndexAnomalyDetectorJobActionHandler(\n+        ClusterService clusterService,\n+        NodeClient client,\n+        RestChannel channel,\n+        AnomalyDetectionIndices anomalyDetectionIndices,\n+        String detectorId,\n+        Long seqNo,\n+        Long primaryTerm,\n+        WriteRequest.RefreshPolicy refreshPolicy,\n+        TimeValue requestTimeout\n+    ) {\n+        super(client, channel);\n+        this.clusterService = clusterService;\n+        this.anomalyDetectionIndices = anomalyDetectionIndices;\n+        this.detectorId = detectorId;\n+        this.seqNo = seqNo;\n+        this.primaryTerm = primaryTerm;\n+        this.refreshPolicy = refreshPolicy;\n+        this.requestTimeout = requestTimeout;\n+    }\n+\n+    /**\n+     * Start function to process create/update anomaly detector job request.\n+     * Check if anomaly detector job index exist first, if not, will create first.\n+     *\n+     * @throws IOException IOException from {@link AnomalyDetectionIndices#initAnomalyDetectorIndexIfAbsent(ActionListener)}\n+     */\n+    public void start() throws IOException {\n+        if (!anomalyDetectionIndices.doesAnomalyDetectorJobIndexExist()) {\n+            anomalyDetectionIndices\n+                .initAnomalyDetectorIndex(\n+                    ActionListener.wrap(response -> onCreateMappingsResponse(response), exception -> onFailure(exception))\n+                );\n+        } else {\n+            prepareAnomalyDetectorJobIndexing();\n+        }\n+    }\n+\n+    /**\n+     * Create anomaly detector job.\n+     *\n+     * @throws IOException IOException from {@link AnomalyDetectionIndices#getAnomalyDetectorJobMappings}\n+     */\n+    public void createAnomalyDetectorJob() throws IOException {\n+        if (!anomalyDetectionIndices.doesAnomalyDetectorJobIndexExist()) {\n+            anomalyDetectionIndices\n+                .initAnomalyDetectorJobIndex(\n+                    ActionListener.wrap(response -> onCreateMappingsResponse(response), exception -> onFailure(exception))\n+                );\n+        } else {\n+            prepareAnomalyDetectorJobIndexing();\n+        }\n+    }\n+\n+    private void prepareAnomalyDetectorJobIndexing() {\n+        GetRequest getRequest = new GetRequest(AnomalyDetector.ANOMALY_DETECTORS_INDEX).id(detectorId);\n+        client.get(getRequest, ActionListener.wrap(response -> onGetAnomalyDetectorResponse(response), exception -> onFailure(exception)));\n+    }\n+\n+    private void onGetAnomalyDetectorResponse(GetResponse response) throws IOException {\n+        if (!response.isExists()) {\n+            XContentBuilder builder = channel\n+                .newErrorBuilder()\n+                .startObject()\n+                .field(\"Message\", \"AnomalyDetector is not found with id: \" + detectorId)\n+                .endObject();\n+            channel.sendResponse(new BytesRestResponse(RestStatus.NOT_FOUND, response.toXContent(builder, EMPTY_PARAMS)));\n+            return;\n+        }\n+        XContentParser parser = XContentType.JSON\n+            .xContent()\n+            .createParser(\n+                channel.request().getXContentRegistry(),\n+                LoggingDeprecationHandler.INSTANCE,\n+                response.getSourceAsBytesRef().streamInput()\n+            );\n+\n+        ensureExpectedToken(XContentParser.Token.START_OBJECT, parser.nextToken(), parser::getTokenLocation);\n+        AnomalyDetector detector = AnomalyDetector.parse(parser, response.getId(), response.getVersion());\n+\n+        IntervalTimeConfiguration interval = (IntervalTimeConfiguration) detector.getDetectionInterval();\n+        Schedule schedule = new IntervalSchedule(Instant.now(), (int) interval.getInterval(), interval.getUnit());\n+        Duration duration = Duration.of(interval.getInterval(), interval.getUnit());\n+        AnomalyDetectorJob job = new AnomalyDetectorJob(\n+            detector.getDetectorId(),\n+            schedule,\n+            true,\n+            Instant.now(),\n+            Instant.now(),\n+            duration.getSeconds()\n+        );\n+\n+        getAnomalyDetectorJob(job);\n+    }\n+\n+    private void getAnomalyDetectorJob(AnomalyDetectorJob job) {\n+        GetRequest getRequest = new GetRequest(AnomalyDetectorJob.ANOMALY_DETECTOR_JOB_INDEX).id(detectorId);\n+\n+        client.get(getRequest, ActionListener.wrap(response -> onGetAnomalyDetectorJob(response, job), exception -> onFailure(exception)));\n+    }\n+\n+    private void onGetAnomalyDetectorJob(GetResponse response, AnomalyDetectorJob job) throws IOException {\n+        if (response.isExists()) {\n+            XContentBuilder builder = channel\n+                .newErrorBuilder()\n+                .startObject()\n+                .field(\"Message\", \"AnomalyDetectorJob exists: \" + detectorId)\n+                .endObject();\n+            channel.sendResponse(new BytesRestResponse(RestStatus.NOT_FOUND, response.toXContent(builder, EMPTY_PARAMS)));\n+            return;\n+        }\n+\n+        indexAnomalyDetectorJob(job);\n+    }\n+\n+    private void indexAnomalyDetectorJob(AnomalyDetectorJob job) throws IOException {\n+        IndexRequest indexRequest = new IndexRequest(AnomalyDetectorJob.ANOMALY_DETECTOR_JOB_INDEX)\n+            .setRefreshPolicy(refreshPolicy)\n+            .source(job.toXContent(channel.newBuilder(), XCONTENT_WITH_TYPE))\n+            .setIfSeqNo(seqNo)\n+            .setIfPrimaryTerm(primaryTerm)\n+            .timeout(requestTimeout);\n+        if (detectorId != null) {\n+            indexRequest.id(detectorId);\n+        }\n+        client.index(indexRequest, indexAnomalyDetectorJobResponse());\n+    }\n+\n+    private ActionListener<IndexResponse> indexAnomalyDetectorJobResponse() {\n+        return new RestResponseListener<IndexResponse>(channel) {\n+            @Override\n+            public RestResponse buildResponse(IndexResponse response) throws Exception {\n+                if (response.getShardInfo().getSuccessful() < 1) {\n+                    return new BytesRestResponse(response.status(), response.toXContent(channel.newErrorBuilder(), EMPTY_PARAMS));\n+                }\n+\n+                XContentBuilder builder = channel\n+                    .newBuilder()\n+                    .startObject()\n+                    .field(RestHandlerUtils._ID, response.getId())\n+                    .field(RestHandlerUtils._VERSION, response.getVersion())\n+                    .field(RestHandlerUtils._SEQ_NO, response.getSeqNo())\n+                    .field(RestHandlerUtils._PRIMARY_TERM, response.getPrimaryTerm())\n+                    .endObject();\n+\n+                BytesRestResponse restResponse = new BytesRestResponse(response.status(), builder);\n+                if (response.status() == RestStatus.CREATED) {\n+                    String location = String.format(Locale.ROOT, \"%s/%s\", AnomalyDetectorPlugin.AD_BASE_URI, response.getId());\n+                    restResponse.addHeader(\"Location\", location);\n+                }\n+                return restResponse;\n+            }\n+        };\n+    }\n+\n+    private void onCreateMappingsResponse(CreateIndexResponse response) throws IOException {\n+        if (response.isAcknowledged()) {\n+            logger.info(\"Created {} with mappings.\", ANOMALY_DETECTORS_INDEX);\n+            prepareAnomalyDetectorJobIndexing();\n+        } else {\n+            logger.warn(\"Created {} with mappings call not acknowledged.\", ANOMALY_DETECTORS_INDEX);\n+            channel\n+                .sendResponse(\n+                    new BytesRestResponse(RestStatus.INTERNAL_SERVER_ERROR, response.toXContent(channel.newErrorBuilder(), EMPTY_PARAMS))\n+                );\n+        }\n+    }\n+\n+    /**\n+     * Delete anomaly detector job\n+     * @param detectorId detector identifier\n+     */\n+    public void deleteAnomalyDetectorJob(String detectorId) {\n+        GetRequest getRequest = new GetRequest(AnomalyDetectorJob.ANOMALY_DETECTOR_JOB_INDEX).id(detectorId);\n+\n+        client\n+            .get(\n+                getRequest,\n+                ActionListener\n+                    .wrap(\n+                        response -> deleteAnomalyDetectorJobDoc(client, detectorId, channel, refreshPolicy),\n+                        exception -> onFailure(exception)\n+                    )\n+            );\n+    }\n+\n+    private void deleteAnomalyDetectorJobDoc(\n+        NodeClient client,\n+        String detectorId,\n+        RestChannel channel,\n+        WriteRequest.RefreshPolicy refreshPolicy\n+    ) {\n+        logger.info(\"Delete anomaly detector job {}\", detectorId);\n+        DeleteRequest deleteRequest = new DeleteRequest(AnomalyDetectorJob.ANOMALY_DETECTOR_JOB_INDEX, detectorId)\n+            .setRefreshPolicy(refreshPolicy);\n+        client.delete(deleteRequest, ActionListener.wrap(response -> {\n+            if (response.getResult() == DocWriteResponse.Result.DELETED) {\n+                logger.info(\"Stop anomaly detector {}\", detectorId);\n+                StopDetectorRequest stopDetectorRequest = new StopDetectorRequest(detectorId);\n+                client.execute(StopDetectorAction.INSTANCE, stopDetectorRequest, stopAdDetectorListener(channel, detectorId));\n+            } else if (response.getResult() == DocWriteResponse.Result.NOT_FOUND) {\n+                logger.info(\"Anomaly detector job not found: {}\", detectorId);\n+                StopDetectorRequest stopDetectorRequest = new StopDetectorRequest(detectorId);\n+                client.execute(StopDetectorAction.INSTANCE, stopDetectorRequest, stopAdDetectorListener(channel, detectorId));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "de8f27737498c215f680201a14653bfa928daff3"}, "originalPosition": 297}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY1OTQwODkz", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/44#pullrequestreview-365940893", "createdAt": "2020-02-27T19:34:06Z", "commit": {"oid": "de8f27737498c215f680201a14653bfa928daff3"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QxOTozNDowNlrOFveesg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QxOTozNDowNlrOFveesg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTMyNjc3MA==", "bodyText": "nit: DETECT_DATA_ACTION -> EXECUTE_AD_ACTION? EXECUTE_AD_ACTION sounds more reasonable to me.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/44#discussion_r385326770", "createdAt": "2020-02-27T19:34:06Z", "author": {"login": "yizheliu-amazon"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/rest/RestAnomalyDetectorJobAction.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.rest;\n+\n+import com.amazon.opendistroforelasticsearch.ad.AnomalyDetectorPlugin;\n+import com.amazon.opendistroforelasticsearch.ad.indices.AnomalyDetectionIndices;\n+import com.amazon.opendistroforelasticsearch.ad.rest.handler.IndexAnomalyDetectorJobActionHandler;\n+import org.elasticsearch.action.support.WriteRequest;\n+import org.elasticsearch.client.node.NodeClient;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.index.seqno.SequenceNumbers;\n+import org.elasticsearch.rest.BaseRestHandler;\n+import org.elasticsearch.rest.RestController;\n+import org.elasticsearch.rest.RestRequest;\n+\n+import java.io.IOException;\n+import java.util.Locale;\n+\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.REQUEST_TIMEOUT;\n+import static com.amazon.opendistroforelasticsearch.ad.util.RestHandlerUtils.DETECTOR_ID;\n+import static com.amazon.opendistroforelasticsearch.ad.util.RestHandlerUtils.IF_PRIMARY_TERM;\n+import static com.amazon.opendistroforelasticsearch.ad.util.RestHandlerUtils.IF_SEQ_NO;\n+import static com.amazon.opendistroforelasticsearch.ad.util.RestHandlerUtils.REFRESH;\n+import static com.amazon.opendistroforelasticsearch.ad.util.RestHandlerUtils.START_JOB;\n+import static com.amazon.opendistroforelasticsearch.ad.util.RestHandlerUtils.STOP_JOB;\n+\n+/**\n+ * This class consists of the REST handler to handle request to start/stop AD job.\n+ */\n+public class RestAnomalyDetectorJobAction extends BaseRestHandler {\n+\n+    public static final String DETECT_DATA_ACTION = \"execute_anomaly_detector\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "de8f27737498c215f680201a14653bfa928daff3"}, "originalPosition": 47}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY1OTU1NjE3", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/44#pullrequestreview-365955617", "createdAt": "2020-02-27T19:56:23Z", "commit": {"oid": "de8f27737498c215f680201a14653bfa928daff3"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QxOTo1NjoyM1rOFvfL6w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QxOTo1NjoyM1rOFvfL6w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTMzODM0Nw==", "bodyText": "Is this method used anywhere? Looks like we can remove it.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/44#discussion_r385338347", "createdAt": "2020-02-27T19:56:23Z", "author": {"login": "yizheliu-amazon"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/rest/handler/IndexAnomalyDetectorJobActionHandler.java", "diffHunk": "@@ -0,0 +1,329 @@\n+/*\n+ * Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.rest.handler;\n+\n+import com.amazon.opendistroforelasticsearch.ad.AnomalyDetectorPlugin;\n+import com.amazon.opendistroforelasticsearch.ad.indices.AnomalyDetectionIndices;\n+import com.amazon.opendistroforelasticsearch.ad.model.AnomalyDetector;\n+import com.amazon.opendistroforelasticsearch.ad.model.AnomalyDetectorJob;\n+import com.amazon.opendistroforelasticsearch.ad.model.IntervalTimeConfiguration;\n+import com.amazon.opendistroforelasticsearch.ad.transport.StopDetectorAction;\n+import com.amazon.opendistroforelasticsearch.ad.transport.StopDetectorRequest;\n+import com.amazon.opendistroforelasticsearch.ad.transport.StopDetectorResponse;\n+import com.amazon.opendistroforelasticsearch.ad.util.RestHandlerUtils;\n+import com.amazon.opendistroforelasticsearch.jobscheduler.spi.schedule.IntervalSchedule;\n+import com.amazon.opendistroforelasticsearch.jobscheduler.spi.schedule.Schedule;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.DocWriteResponse;\n+import org.elasticsearch.action.admin.indices.create.CreateIndexResponse;\n+import org.elasticsearch.action.delete.DeleteRequest;\n+import org.elasticsearch.action.get.GetRequest;\n+import org.elasticsearch.action.get.GetResponse;\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.action.index.IndexResponse;\n+import org.elasticsearch.action.support.WriteRequest;\n+import org.elasticsearch.client.node.NodeClient;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.LoggingDeprecationHandler;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.common.xcontent.XContentType;\n+import org.elasticsearch.rest.BytesRestResponse;\n+import org.elasticsearch.rest.RestChannel;\n+import org.elasticsearch.rest.RestResponse;\n+import org.elasticsearch.rest.RestStatus;\n+import org.elasticsearch.rest.action.RestResponseListener;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.Instant;\n+import java.util.Locale;\n+\n+import static com.amazon.opendistroforelasticsearch.ad.model.AnomalyDetector.ANOMALY_DETECTORS_INDEX;\n+import static com.amazon.opendistroforelasticsearch.ad.util.RestHandlerUtils.XCONTENT_WITH_TYPE;\n+import static org.elasticsearch.common.xcontent.ToXContent.EMPTY_PARAMS;\n+import static org.elasticsearch.common.xcontent.XContentParserUtils.ensureExpectedToken;\n+\n+/**\n+ * Anomaly detector job REST action handler to process POST/PUT request.\n+ */\n+public class IndexAnomalyDetectorJobActionHandler extends AbstractActionHandler {\n+\n+    private final AnomalyDetectionIndices anomalyDetectionIndices;\n+    private final String detectorId;\n+    private final Long seqNo;\n+    private final Long primaryTerm;\n+    private final WriteRequest.RefreshPolicy refreshPolicy;\n+    private final ClusterService clusterService;\n+\n+    private final Logger logger = LogManager.getLogger(IndexAnomalyDetectorJobActionHandler.class);\n+    private final TimeValue requestTimeout;\n+    private volatile Integer maxAnomalyDetectors;\n+    private volatile Integer maxAnomalyFeatures;\n+    private final AnomalyDetectorActionHandler handler = new AnomalyDetectorActionHandler();\n+\n+    /**\n+     * Constructor function.\n+     *\n+     * @param clusterService          ClusterService\n+     * @param client                  ES node client that executes actions on the local node\n+     * @param channel                 ES channel used to construct bytes / builder based outputs, and send responses\n+     * @param anomalyDetectionIndices anomaly detector index manager\n+     * @param detectorId              detector identifier\n+     * @param seqNo                   sequence number of last modification\n+     * @param primaryTerm             primary term of last modification\n+     * @param refreshPolicy           refresh policy\n+     * @param requestTimeout          request time out configuration\n+     */\n+    public IndexAnomalyDetectorJobActionHandler(\n+        ClusterService clusterService,\n+        NodeClient client,\n+        RestChannel channel,\n+        AnomalyDetectionIndices anomalyDetectionIndices,\n+        String detectorId,\n+        Long seqNo,\n+        Long primaryTerm,\n+        WriteRequest.RefreshPolicy refreshPolicy,\n+        TimeValue requestTimeout\n+    ) {\n+        super(client, channel);\n+        this.clusterService = clusterService;\n+        this.anomalyDetectionIndices = anomalyDetectionIndices;\n+        this.detectorId = detectorId;\n+        this.seqNo = seqNo;\n+        this.primaryTerm = primaryTerm;\n+        this.refreshPolicy = refreshPolicy;\n+        this.requestTimeout = requestTimeout;\n+    }\n+\n+    /**\n+     * Start function to process create/update anomaly detector job request.\n+     * Check if anomaly detector job index exist first, if not, will create first.\n+     *\n+     * @throws IOException IOException from {@link AnomalyDetectionIndices#initAnomalyDetectorIndexIfAbsent(ActionListener)}\n+     */\n+    public void start() throws IOException {\n+        if (!anomalyDetectionIndices.doesAnomalyDetectorJobIndexExist()) {\n+            anomalyDetectionIndices\n+                .initAnomalyDetectorIndex(\n+                    ActionListener.wrap(response -> onCreateMappingsResponse(response), exception -> onFailure(exception))\n+                );\n+        } else {\n+            prepareAnomalyDetectorJobIndexing();\n+        }\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "de8f27737498c215f680201a14653bfa928daff3"}, "originalPosition": 130}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY1OTYxMjE0", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/44#pullrequestreview-365961214", "createdAt": "2020-02-27T20:05:14Z", "commit": {"oid": "de8f27737498c215f680201a14653bfa928daff3"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QyMDowNToxNFrOFvfdOg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QyMDowNToxNFrOFvfdOg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTM0Mjc3OA==", "bodyText": "question: in what scenario detectoId can be null?\nAs per my understanding, I think we may not need to do this check since detectorId must already be there when we index a new AD job.\nI would suggest removing this null check, and adding detectorId null check at 1st line of prepareRequest() in RestAnomalyDetectorJobAction.java", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/44#discussion_r385342778", "createdAt": "2020-02-27T20:05:14Z", "author": {"login": "yizheliu-amazon"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/rest/handler/IndexAnomalyDetectorJobActionHandler.java", "diffHunk": "@@ -0,0 +1,329 @@\n+/*\n+ * Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.rest.handler;\n+\n+import com.amazon.opendistroforelasticsearch.ad.AnomalyDetectorPlugin;\n+import com.amazon.opendistroforelasticsearch.ad.indices.AnomalyDetectionIndices;\n+import com.amazon.opendistroforelasticsearch.ad.model.AnomalyDetector;\n+import com.amazon.opendistroforelasticsearch.ad.model.AnomalyDetectorJob;\n+import com.amazon.opendistroforelasticsearch.ad.model.IntervalTimeConfiguration;\n+import com.amazon.opendistroforelasticsearch.ad.transport.StopDetectorAction;\n+import com.amazon.opendistroforelasticsearch.ad.transport.StopDetectorRequest;\n+import com.amazon.opendistroforelasticsearch.ad.transport.StopDetectorResponse;\n+import com.amazon.opendistroforelasticsearch.ad.util.RestHandlerUtils;\n+import com.amazon.opendistroforelasticsearch.jobscheduler.spi.schedule.IntervalSchedule;\n+import com.amazon.opendistroforelasticsearch.jobscheduler.spi.schedule.Schedule;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.DocWriteResponse;\n+import org.elasticsearch.action.admin.indices.create.CreateIndexResponse;\n+import org.elasticsearch.action.delete.DeleteRequest;\n+import org.elasticsearch.action.get.GetRequest;\n+import org.elasticsearch.action.get.GetResponse;\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.action.index.IndexResponse;\n+import org.elasticsearch.action.support.WriteRequest;\n+import org.elasticsearch.client.node.NodeClient;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.xcontent.LoggingDeprecationHandler;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.common.xcontent.XContentParser;\n+import org.elasticsearch.common.xcontent.XContentType;\n+import org.elasticsearch.rest.BytesRestResponse;\n+import org.elasticsearch.rest.RestChannel;\n+import org.elasticsearch.rest.RestResponse;\n+import org.elasticsearch.rest.RestStatus;\n+import org.elasticsearch.rest.action.RestResponseListener;\n+\n+import java.io.IOException;\n+import java.time.Duration;\n+import java.time.Instant;\n+import java.util.Locale;\n+\n+import static com.amazon.opendistroforelasticsearch.ad.model.AnomalyDetector.ANOMALY_DETECTORS_INDEX;\n+import static com.amazon.opendistroforelasticsearch.ad.util.RestHandlerUtils.XCONTENT_WITH_TYPE;\n+import static org.elasticsearch.common.xcontent.ToXContent.EMPTY_PARAMS;\n+import static org.elasticsearch.common.xcontent.XContentParserUtils.ensureExpectedToken;\n+\n+/**\n+ * Anomaly detector job REST action handler to process POST/PUT request.\n+ */\n+public class IndexAnomalyDetectorJobActionHandler extends AbstractActionHandler {\n+\n+    private final AnomalyDetectionIndices anomalyDetectionIndices;\n+    private final String detectorId;\n+    private final Long seqNo;\n+    private final Long primaryTerm;\n+    private final WriteRequest.RefreshPolicy refreshPolicy;\n+    private final ClusterService clusterService;\n+\n+    private final Logger logger = LogManager.getLogger(IndexAnomalyDetectorJobActionHandler.class);\n+    private final TimeValue requestTimeout;\n+    private volatile Integer maxAnomalyDetectors;\n+    private volatile Integer maxAnomalyFeatures;\n+    private final AnomalyDetectorActionHandler handler = new AnomalyDetectorActionHandler();\n+\n+    /**\n+     * Constructor function.\n+     *\n+     * @param clusterService          ClusterService\n+     * @param client                  ES node client that executes actions on the local node\n+     * @param channel                 ES channel used to construct bytes / builder based outputs, and send responses\n+     * @param anomalyDetectionIndices anomaly detector index manager\n+     * @param detectorId              detector identifier\n+     * @param seqNo                   sequence number of last modification\n+     * @param primaryTerm             primary term of last modification\n+     * @param refreshPolicy           refresh policy\n+     * @param requestTimeout          request time out configuration\n+     */\n+    public IndexAnomalyDetectorJobActionHandler(\n+        ClusterService clusterService,\n+        NodeClient client,\n+        RestChannel channel,\n+        AnomalyDetectionIndices anomalyDetectionIndices,\n+        String detectorId,\n+        Long seqNo,\n+        Long primaryTerm,\n+        WriteRequest.RefreshPolicy refreshPolicy,\n+        TimeValue requestTimeout\n+    ) {\n+        super(client, channel);\n+        this.clusterService = clusterService;\n+        this.anomalyDetectionIndices = anomalyDetectionIndices;\n+        this.detectorId = detectorId;\n+        this.seqNo = seqNo;\n+        this.primaryTerm = primaryTerm;\n+        this.refreshPolicy = refreshPolicy;\n+        this.requestTimeout = requestTimeout;\n+    }\n+\n+    /**\n+     * Start function to process create/update anomaly detector job request.\n+     * Check if anomaly detector job index exist first, if not, will create first.\n+     *\n+     * @throws IOException IOException from {@link AnomalyDetectionIndices#initAnomalyDetectorIndexIfAbsent(ActionListener)}\n+     */\n+    public void start() throws IOException {\n+        if (!anomalyDetectionIndices.doesAnomalyDetectorJobIndexExist()) {\n+            anomalyDetectionIndices\n+                .initAnomalyDetectorIndex(\n+                    ActionListener.wrap(response -> onCreateMappingsResponse(response), exception -> onFailure(exception))\n+                );\n+        } else {\n+            prepareAnomalyDetectorJobIndexing();\n+        }\n+    }\n+\n+    /**\n+     * Create anomaly detector job.\n+     *\n+     * @throws IOException IOException from {@link AnomalyDetectionIndices#getAnomalyDetectorJobMappings}\n+     */\n+    public void createAnomalyDetectorJob() throws IOException {\n+        if (!anomalyDetectionIndices.doesAnomalyDetectorJobIndexExist()) {\n+            anomalyDetectionIndices\n+                .initAnomalyDetectorJobIndex(\n+                    ActionListener.wrap(response -> onCreateMappingsResponse(response), exception -> onFailure(exception))\n+                );\n+        } else {\n+            prepareAnomalyDetectorJobIndexing();\n+        }\n+    }\n+\n+    private void prepareAnomalyDetectorJobIndexing() {\n+        GetRequest getRequest = new GetRequest(AnomalyDetector.ANOMALY_DETECTORS_INDEX).id(detectorId);\n+        client.get(getRequest, ActionListener.wrap(response -> onGetAnomalyDetectorResponse(response), exception -> onFailure(exception)));\n+    }\n+\n+    private void onGetAnomalyDetectorResponse(GetResponse response) throws IOException {\n+        if (!response.isExists()) {\n+            XContentBuilder builder = channel\n+                .newErrorBuilder()\n+                .startObject()\n+                .field(\"Message\", \"AnomalyDetector is not found with id: \" + detectorId)\n+                .endObject();\n+            channel.sendResponse(new BytesRestResponse(RestStatus.NOT_FOUND, response.toXContent(builder, EMPTY_PARAMS)));\n+            return;\n+        }\n+        XContentParser parser = XContentType.JSON\n+            .xContent()\n+            .createParser(\n+                channel.request().getXContentRegistry(),\n+                LoggingDeprecationHandler.INSTANCE,\n+                response.getSourceAsBytesRef().streamInput()\n+            );\n+\n+        ensureExpectedToken(XContentParser.Token.START_OBJECT, parser.nextToken(), parser::getTokenLocation);\n+        AnomalyDetector detector = AnomalyDetector.parse(parser, response.getId(), response.getVersion());\n+\n+        IntervalTimeConfiguration interval = (IntervalTimeConfiguration) detector.getDetectionInterval();\n+        Schedule schedule = new IntervalSchedule(Instant.now(), (int) interval.getInterval(), interval.getUnit());\n+        Duration duration = Duration.of(interval.getInterval(), interval.getUnit());\n+        AnomalyDetectorJob job = new AnomalyDetectorJob(\n+            detector.getDetectorId(),\n+            schedule,\n+            true,\n+            Instant.now(),\n+            Instant.now(),\n+            duration.getSeconds()\n+        );\n+\n+        getAnomalyDetectorJob(job);\n+    }\n+\n+    private void getAnomalyDetectorJob(AnomalyDetectorJob job) {\n+        GetRequest getRequest = new GetRequest(AnomalyDetectorJob.ANOMALY_DETECTOR_JOB_INDEX).id(detectorId);\n+\n+        client.get(getRequest, ActionListener.wrap(response -> onGetAnomalyDetectorJob(response, job), exception -> onFailure(exception)));\n+    }\n+\n+    private void onGetAnomalyDetectorJob(GetResponse response, AnomalyDetectorJob job) throws IOException {\n+        if (response.isExists()) {\n+            XContentBuilder builder = channel\n+                .newErrorBuilder()\n+                .startObject()\n+                .field(\"Message\", \"AnomalyDetectorJob exists: \" + detectorId)\n+                .endObject();\n+            channel.sendResponse(new BytesRestResponse(RestStatus.NOT_FOUND, response.toXContent(builder, EMPTY_PARAMS)));\n+            return;\n+        }\n+\n+        indexAnomalyDetectorJob(job);\n+    }\n+\n+    private void indexAnomalyDetectorJob(AnomalyDetectorJob job) throws IOException {\n+        IndexRequest indexRequest = new IndexRequest(AnomalyDetectorJob.ANOMALY_DETECTOR_JOB_INDEX)\n+            .setRefreshPolicy(refreshPolicy)\n+            .source(job.toXContent(channel.newBuilder(), XCONTENT_WITH_TYPE))\n+            .setIfSeqNo(seqNo)\n+            .setIfPrimaryTerm(primaryTerm)\n+            .timeout(requestTimeout);\n+        if (detectorId != null) {\n+            indexRequest.id(detectorId);\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "de8f27737498c215f680201a14653bfa928daff3"}, "originalPosition": 218}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "509b65e5913f085ca422872be282274fdd3f5cf9", "author": {"user": {"login": "ylwu-amzn", "name": "Yaliang"}}, "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/509b65e5913f085ca422872be282274fdd3f5cf9", "committedDate": "2020-02-27T21:54:50Z", "message": "fix comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY2MDUyMzk0", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/44#pullrequestreview-366052394", "createdAt": "2020-02-27T22:42:19Z", "commit": {"oid": "509b65e5913f085ca422872be282274fdd3f5cf9"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1617, "cost": 1, "resetAt": "2021-11-01T16:19:10Z"}}}