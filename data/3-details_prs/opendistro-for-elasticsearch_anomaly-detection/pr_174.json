{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDM5Mjk4NDk3", "number": 174, "title": "Add result indices retention period", "bodyText": "Issue #, if available:\n#37\nDescription of changes:\nCurrently we never delete the result index, even though customers have deleted the detector.   An increasing amount of result indices can use significant disk space, as well as memory pressure due to the creation of rolled over indices. This PR adds retention period to anomaly results.  We delete result indices when they are older than a retention period, which is 90 days by default. We use 90 days because that's the maximum days we allow users to view results on Kibana.  Users can configure the retention period via the setting opendistro.anomaly_detection.ad_result_history_retention_period dynamically.\nAlso, previously we roll over empty result indices.  This PR fixes that by removing the max age condition of result indices.  So we only roll over the result index when the maximum number of documents in the index is reached.\nTesting done:\n\nmanually tested result indices would be deleted after passing retention period.\n\nBy submitting this pull request, I confirm that you can use, modify, copy, and redistribute this contribution, under the terms of your choice.", "createdAt": "2020-06-24T15:54:13Z", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/174", "merged": true, "mergeCommit": {"oid": "0f538453b1e4994b7dc525485c033f98f205113e"}, "closed": true, "closedAt": "2020-06-29T16:52:23Z", "author": {"login": "kaituo"}, "timelineItems": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcucItNgH2gAyNDM5Mjk4NDk3OjAyMGY1MDlkMmY4ODJlNjE5Y2UzZmZmM2EwNWJlNDE4NDViZTIxMjY=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcwDlinAH2gAyNDM5Mjk4NDk3OjdmZWMyNGRhMDg3ZmVkYTE1NGQxNTc1NmY1Y2VhMTdhMTRmYWE2MzA=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "020f509d2f882e619ce3fff3a05be41845be2126", "author": {"user": {"login": "kaituo", "name": "Kaituo Li"}}, "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/020f509d2f882e619ce3fff3a05be41845be2126", "committedDate": "2020-06-24T15:53:27Z", "message": "Add result indices retention period\n\nCurrently we never delete the result index, even though customers have deleted the detector.\u00a0\u00a0 An increasing amount of result indices can use significant disk space, as well as memory pressure due to the creation of rolled over indices. This PR adds retention period to anomaly results.\u00a0 We delete result indices when they are older than a retention period, which is 90 days by default. We use 90 days because that's the maximum days we allow users to view results on Kibana.\u00a0 Users can configure the retention period via the setting opendistro.anomaly_detection.ad_result_history_retention_period dynamically.\n\nAlso, previously we roll over empty result indices.\u00a0 This PR fixes that by removing the max age condition of result indices.\u00a0 So we only roll over the result index when the maximum number of documents in the index is reached.\n\nTesting done:\n*\u00a0manually tested result indices would be deleted after passing retention period."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM2ODMzODM4", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/174#pullrequestreview-436833838", "createdAt": "2020-06-24T16:55:13Z", "commit": {"oid": "020f509d2f882e619ce3fff3a05be41845be2126"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQxNjo1NToxM1rOGoa5cg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQxNjo1NToxM1rOGoa5cg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTAzNjkxNA==", "bodyText": "Why put into two lines? How about we use logger.error(\"Fail to roll over result index\", exception); ? So we don't need to go to two lines when check log. There are maybe other request's log between these two lines, if check log manually, we need to skip other request's log.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/174#discussion_r445036914", "createdAt": "2020-06-24T16:55:13Z", "author": {"login": "ylwu-amzn"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/indices/AnomalyDetectionIndices.java", "diffHunk": "@@ -275,15 +285,86 @@ private boolean rolloverHistoryIndex() {\n             adResultMapping = getAnomalyResultMappings();\n         } catch (IOException e) {\n             logger.error(\"Fail to roll over AD result index, as can't get AD result index mapping\");\n-            return false;\n+            return;\n         }\n         request.getCreateIndexRequest().index(AD_RESULT_HISTORY_INDEX_PATTERN).mapping(MAPPING_TYPE, adResultMapping, XContentType.JSON);\n         request.addMaxIndexDocsCondition(historyMaxDocs);\n-        request.addMaxIndexAgeCondition(historyMaxAge);\n-        RolloverResponse response = adminClient.indices().rolloverIndex(request).actionGet(requestTimeout);\n-        if (!response.isRolledOver()) {\n-            logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+        adminClient.indices().rolloverIndex(request, ActionListener.wrap(response -> {\n+            if (!response.isRolledOver()) {\n+                logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+            } else {\n+                logger.info(\"{} rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+                deleteOldHistoryIndices();\n+            }\n+        }, exception -> {\n+            logger.error(\"Fail to roll over result index\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "020f509d2f882e619ce3fff3a05be41845be2126"}, "originalPosition": 137}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM2ODM5OTk4", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/174#pullrequestreview-436839998", "createdAt": "2020-06-24T17:03:11Z", "commit": {"oid": "020f509d2f882e619ce3fff3a05be41845be2126"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQxNzowMzoxMVrOGobMZg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQxNzowMzoxMVrOGobMZg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTA0MTc2Ng==", "bodyText": "How about we just don't add latestToDelete to candidates  in the for loop above?", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/174#discussion_r445041766", "createdAt": "2020-06-24T17:03:11Z", "author": {"login": "ylwu-amzn"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/indices/AnomalyDetectionIndices.java", "diffHunk": "@@ -275,15 +285,86 @@ private boolean rolloverHistoryIndex() {\n             adResultMapping = getAnomalyResultMappings();\n         } catch (IOException e) {\n             logger.error(\"Fail to roll over AD result index, as can't get AD result index mapping\");\n-            return false;\n+            return;\n         }\n         request.getCreateIndexRequest().index(AD_RESULT_HISTORY_INDEX_PATTERN).mapping(MAPPING_TYPE, adResultMapping, XContentType.JSON);\n         request.addMaxIndexDocsCondition(historyMaxDocs);\n-        request.addMaxIndexAgeCondition(historyMaxAge);\n-        RolloverResponse response = adminClient.indices().rolloverIndex(request).actionGet(requestTimeout);\n-        if (!response.isRolledOver()) {\n-            logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+        adminClient.indices().rolloverIndex(request, ActionListener.wrap(response -> {\n+            if (!response.isRolledOver()) {\n+                logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+            } else {\n+                logger.info(\"{} rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+                deleteOldHistoryIndices();\n+            }\n+        }, exception -> {\n+            logger.error(\"Fail to roll over result index\");\n+            logger.error(exception);\n+        }));\n+    }\n+\n+    private void deleteOldHistoryIndices() {\n+        Set<String> candidates = new HashSet<String>();\n+\n+        ClusterStateRequest clusterStateRequest = new ClusterStateRequest()\n+            .clear()\n+            .indices(AnomalyDetectionIndices.ALL_AD_RESULTS_INDEX_PATTERN)\n+            .metadata(true)\n+            .local(true)\n+            .indicesOptions(IndicesOptions.strictExpand());\n+\n+        adminClient.cluster().state(clusterStateRequest, ActionListener.wrap(clusterStateResponse -> {\n+            String latestToDelete = null;\n+            long latest = Long.MIN_VALUE;\n+            for (ObjectCursor<IndexMetadata> cursor : clusterStateResponse.getState().metadata().indices().values()) {\n+                IndexMetadata indexMetaData = cursor.value;\n+                long creationTime = indexMetaData.getCreationDate();\n+\n+                if ((Instant.now().toEpochMilli() - creationTime) > historyRetentionPeriod.millis()) {\n+                    String indexName = indexMetaData.getIndex().getName();\n+                    candidates.add(indexName);\n+                    if (latest < creationTime) {\n+                        latest = creationTime;\n+                        latestToDelete = indexName;\n+                    }\n+                }\n+            }\n+\n+            if (candidates.size() > 1) {\n+                // delete all indices except the last one because the last one may contain docs newer than the retention period\n+                candidates.remove(latestToDelete);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "020f509d2f882e619ce3fff3a05be41845be2126"}, "originalPosition": 171}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM2ODQ0MTE3", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/174#pullrequestreview-436844117", "createdAt": "2020-06-24T17:08:37Z", "commit": {"oid": "020f509d2f882e619ce3fff3a05be41845be2126"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQxNzowODozN1rOGobYnw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQxNzowODozN1rOGobYnw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTA0NDg5NQ==", "bodyText": "This exception is for catching exception of clusterStateRequest? Not quite get why log Fail to get creation dates here.  The exception only caused by get creation dates ?", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/174#discussion_r445044895", "createdAt": "2020-06-24T17:08:37Z", "author": {"login": "ylwu-amzn"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/indices/AnomalyDetectionIndices.java", "diffHunk": "@@ -275,15 +285,86 @@ private boolean rolloverHistoryIndex() {\n             adResultMapping = getAnomalyResultMappings();\n         } catch (IOException e) {\n             logger.error(\"Fail to roll over AD result index, as can't get AD result index mapping\");\n-            return false;\n+            return;\n         }\n         request.getCreateIndexRequest().index(AD_RESULT_HISTORY_INDEX_PATTERN).mapping(MAPPING_TYPE, adResultMapping, XContentType.JSON);\n         request.addMaxIndexDocsCondition(historyMaxDocs);\n-        request.addMaxIndexAgeCondition(historyMaxAge);\n-        RolloverResponse response = adminClient.indices().rolloverIndex(request).actionGet(requestTimeout);\n-        if (!response.isRolledOver()) {\n-            logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+        adminClient.indices().rolloverIndex(request, ActionListener.wrap(response -> {\n+            if (!response.isRolledOver()) {\n+                logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+            } else {\n+                logger.info(\"{} rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+                deleteOldHistoryIndices();\n+            }\n+        }, exception -> {\n+            logger.error(\"Fail to roll over result index\");\n+            logger.error(exception);\n+        }));\n+    }\n+\n+    private void deleteOldHistoryIndices() {\n+        Set<String> candidates = new HashSet<String>();\n+\n+        ClusterStateRequest clusterStateRequest = new ClusterStateRequest()\n+            .clear()\n+            .indices(AnomalyDetectionIndices.ALL_AD_RESULTS_INDEX_PATTERN)\n+            .metadata(true)\n+            .local(true)\n+            .indicesOptions(IndicesOptions.strictExpand());\n+\n+        adminClient.cluster().state(clusterStateRequest, ActionListener.wrap(clusterStateResponse -> {\n+            String latestToDelete = null;\n+            long latest = Long.MIN_VALUE;\n+            for (ObjectCursor<IndexMetadata> cursor : clusterStateResponse.getState().metadata().indices().values()) {\n+                IndexMetadata indexMetaData = cursor.value;\n+                long creationTime = indexMetaData.getCreationDate();\n+\n+                if ((Instant.now().toEpochMilli() - creationTime) > historyRetentionPeriod.millis()) {\n+                    String indexName = indexMetaData.getIndex().getName();\n+                    candidates.add(indexName);\n+                    if (latest < creationTime) {\n+                        latest = creationTime;\n+                        latestToDelete = indexName;\n+                    }\n+                }\n+            }\n+\n+            if (candidates.size() > 1) {\n+                // delete all indices except the last one because the last one may contain docs newer than the retention period\n+                candidates.remove(latestToDelete);\n+                String[] toDelete = candidates.toArray(Strings.EMPTY_ARRAY);\n+                DeleteIndexRequest deleteIndexRequest = new DeleteIndexRequest(toDelete);\n+                adminClient.indices().delete(deleteIndexRequest, ActionListener.wrap(deleteIndexResponse -> {\n+                    if (!deleteIndexResponse.isAcknowledged()) {\n+                        logger\n+                            .error(\n+                                \"Could not delete one or more Anomaly result indices: {}. Retrying one by one.\",\n+                                Arrays.toString(toDelete)\n+                            );\n+                        deleteIndexIteration(toDelete);\n+                    } else {\n+                        logger.error(\"Succeeded in deleting expired anomaly result indices: {}.\", Arrays.toString(toDelete));\n+                    }\n+                }, exception -> { deleteIndexIteration(toDelete); }));\n+            }\n+        }, exception -> { logger.error(\"Fail to get creation dates of result indices\"); }));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "020f509d2f882e619ce3fff3a05be41845be2126"}, "originalPosition": 187}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM2ODQ1NzA0", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/174#pullrequestreview-436845704", "createdAt": "2020-06-24T17:10:46Z", "commit": {"oid": "020f509d2f882e619ce3fff3a05be41845be2126"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQxNzoxMDo0NlrOGobdUA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQxNzoxMDo0NlrOGobdUA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTA0NjA5Ng==", "bodyText": "Same here, why put into two lines?", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/174#discussion_r445046096", "createdAt": "2020-06-24T17:10:46Z", "author": {"login": "ylwu-amzn"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/indices/AnomalyDetectionIndices.java", "diffHunk": "@@ -275,15 +285,86 @@ private boolean rolloverHistoryIndex() {\n             adResultMapping = getAnomalyResultMappings();\n         } catch (IOException e) {\n             logger.error(\"Fail to roll over AD result index, as can't get AD result index mapping\");\n-            return false;\n+            return;\n         }\n         request.getCreateIndexRequest().index(AD_RESULT_HISTORY_INDEX_PATTERN).mapping(MAPPING_TYPE, adResultMapping, XContentType.JSON);\n         request.addMaxIndexDocsCondition(historyMaxDocs);\n-        request.addMaxIndexAgeCondition(historyMaxAge);\n-        RolloverResponse response = adminClient.indices().rolloverIndex(request).actionGet(requestTimeout);\n-        if (!response.isRolledOver()) {\n-            logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+        adminClient.indices().rolloverIndex(request, ActionListener.wrap(response -> {\n+            if (!response.isRolledOver()) {\n+                logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+            } else {\n+                logger.info(\"{} rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+                deleteOldHistoryIndices();\n+            }\n+        }, exception -> {\n+            logger.error(\"Fail to roll over result index\");\n+            logger.error(exception);\n+        }));\n+    }\n+\n+    private void deleteOldHistoryIndices() {\n+        Set<String> candidates = new HashSet<String>();\n+\n+        ClusterStateRequest clusterStateRequest = new ClusterStateRequest()\n+            .clear()\n+            .indices(AnomalyDetectionIndices.ALL_AD_RESULTS_INDEX_PATTERN)\n+            .metadata(true)\n+            .local(true)\n+            .indicesOptions(IndicesOptions.strictExpand());\n+\n+        adminClient.cluster().state(clusterStateRequest, ActionListener.wrap(clusterStateResponse -> {\n+            String latestToDelete = null;\n+            long latest = Long.MIN_VALUE;\n+            for (ObjectCursor<IndexMetadata> cursor : clusterStateResponse.getState().metadata().indices().values()) {\n+                IndexMetadata indexMetaData = cursor.value;\n+                long creationTime = indexMetaData.getCreationDate();\n+\n+                if ((Instant.now().toEpochMilli() - creationTime) > historyRetentionPeriod.millis()) {\n+                    String indexName = indexMetaData.getIndex().getName();\n+                    candidates.add(indexName);\n+                    if (latest < creationTime) {\n+                        latest = creationTime;\n+                        latestToDelete = indexName;\n+                    }\n+                }\n+            }\n+\n+            if (candidates.size() > 1) {\n+                // delete all indices except the last one because the last one may contain docs newer than the retention period\n+                candidates.remove(latestToDelete);\n+                String[] toDelete = candidates.toArray(Strings.EMPTY_ARRAY);\n+                DeleteIndexRequest deleteIndexRequest = new DeleteIndexRequest(toDelete);\n+                adminClient.indices().delete(deleteIndexRequest, ActionListener.wrap(deleteIndexResponse -> {\n+                    if (!deleteIndexResponse.isAcknowledged()) {\n+                        logger\n+                            .error(\n+                                \"Could not delete one or more Anomaly result indices: {}. Retrying one by one.\",\n+                                Arrays.toString(toDelete)\n+                            );\n+                        deleteIndexIteration(toDelete);\n+                    } else {\n+                        logger.error(\"Succeeded in deleting expired anomaly result indices: {}.\", Arrays.toString(toDelete));\n+                    }\n+                }, exception -> { deleteIndexIteration(toDelete); }));\n+            }\n+        }, exception -> { logger.error(\"Fail to get creation dates of result indices\"); }));\n+    }\n+\n+    private void deleteIndexIteration(String[] toDelete) {\n+        for (String index : toDelete) {\n+            DeleteIndexRequest singleDeleteRequest = new DeleteIndexRequest(index);\n+            adminClient.indices().delete(singleDeleteRequest, ActionListener.wrap(singleDeleteResponse -> {\n+                if (!singleDeleteResponse.isAcknowledged()) {\n+                    logger.error(\"Retrying deleting {} does not succeed.\", index);\n+                }\n+            }, exception -> {\n+                if (exception instanceof IndexNotFoundException) {\n+                    logger.info(\"{} was already deleted.\", index);\n+                } else {\n+                    logger.error(\"Retrying deleting {} does not succeed.\", index);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "020f509d2f882e619ce3fff3a05be41845be2126"}, "originalPosition": 201}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM2ODUyMDY0", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/174#pullrequestreview-436852064", "createdAt": "2020-06-24T17:19:28Z", "commit": {"oid": "020f509d2f882e619ce3fff3a05be41845be2126"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQxNzoxOToyOFrOGobwKw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQxNzoxOToyOFrOGobwKw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTA1MDkyMw==", "bodyText": "Is it necessary to use two rounds of deletion? Roll over will be triggered periodically, so next run can re-delete the failed indices.\nIf fail to delete all indices due to some error, will it help we re-delete them immediately? Error may be still there", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/174#discussion_r445050923", "createdAt": "2020-06-24T17:19:28Z", "author": {"login": "ylwu-amzn"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/indices/AnomalyDetectionIndices.java", "diffHunk": "@@ -275,15 +285,86 @@ private boolean rolloverHistoryIndex() {\n             adResultMapping = getAnomalyResultMappings();\n         } catch (IOException e) {\n             logger.error(\"Fail to roll over AD result index, as can't get AD result index mapping\");\n-            return false;\n+            return;\n         }\n         request.getCreateIndexRequest().index(AD_RESULT_HISTORY_INDEX_PATTERN).mapping(MAPPING_TYPE, adResultMapping, XContentType.JSON);\n         request.addMaxIndexDocsCondition(historyMaxDocs);\n-        request.addMaxIndexAgeCondition(historyMaxAge);\n-        RolloverResponse response = adminClient.indices().rolloverIndex(request).actionGet(requestTimeout);\n-        if (!response.isRolledOver()) {\n-            logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+        adminClient.indices().rolloverIndex(request, ActionListener.wrap(response -> {\n+            if (!response.isRolledOver()) {\n+                logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+            } else {\n+                logger.info(\"{} rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+                deleteOldHistoryIndices();\n+            }\n+        }, exception -> {\n+            logger.error(\"Fail to roll over result index\");\n+            logger.error(exception);\n+        }));\n+    }\n+\n+    private void deleteOldHistoryIndices() {\n+        Set<String> candidates = new HashSet<String>();\n+\n+        ClusterStateRequest clusterStateRequest = new ClusterStateRequest()\n+            .clear()\n+            .indices(AnomalyDetectionIndices.ALL_AD_RESULTS_INDEX_PATTERN)\n+            .metadata(true)\n+            .local(true)\n+            .indicesOptions(IndicesOptions.strictExpand());\n+\n+        adminClient.cluster().state(clusterStateRequest, ActionListener.wrap(clusterStateResponse -> {\n+            String latestToDelete = null;\n+            long latest = Long.MIN_VALUE;\n+            for (ObjectCursor<IndexMetadata> cursor : clusterStateResponse.getState().metadata().indices().values()) {\n+                IndexMetadata indexMetaData = cursor.value;\n+                long creationTime = indexMetaData.getCreationDate();\n+\n+                if ((Instant.now().toEpochMilli() - creationTime) > historyRetentionPeriod.millis()) {\n+                    String indexName = indexMetaData.getIndex().getName();\n+                    candidates.add(indexName);\n+                    if (latest < creationTime) {\n+                        latest = creationTime;\n+                        latestToDelete = indexName;\n+                    }\n+                }\n+            }\n+\n+            if (candidates.size() > 1) {\n+                // delete all indices except the last one because the last one may contain docs newer than the retention period\n+                candidates.remove(latestToDelete);\n+                String[] toDelete = candidates.toArray(Strings.EMPTY_ARRAY);\n+                DeleteIndexRequest deleteIndexRequest = new DeleteIndexRequest(toDelete);\n+                adminClient.indices().delete(deleteIndexRequest, ActionListener.wrap(deleteIndexResponse -> {\n+                    if (!deleteIndexResponse.isAcknowledged()) {\n+                        logger\n+                            .error(\n+                                \"Could not delete one or more Anomaly result indices: {}. Retrying one by one.\",\n+                                Arrays.toString(toDelete)\n+                            );\n+                        deleteIndexIteration(toDelete);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "020f509d2f882e619ce3fff3a05be41845be2126"}, "originalPosition": 181}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bbf1b5466f1a2082e5da389720a51d7e684f1387", "author": {"user": {"login": "kaituo", "name": "Kaituo Li"}}, "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/bbf1b5466f1a2082e5da389720a51d7e684f1387", "committedDate": "2020-06-24T18:21:29Z", "message": "refactor log lines"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM3MDEzMjgx", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/174#pullrequestreview-437013281", "createdAt": "2020-06-24T21:17:23Z", "commit": {"oid": "bbf1b5466f1a2082e5da389720a51d7e684f1387"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQyMToxNzoyM1rOGojcqw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQyMToxNzoyM1rOGojcqw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTE3NzAwMw==", "bodyText": "logger.info", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/174#discussion_r445177003", "createdAt": "2020-06-24T21:17:23Z", "author": {"login": "yizheliu-amazon"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/indices/AnomalyDetectionIndices.java", "diffHunk": "@@ -275,15 +286,82 @@ private boolean rolloverHistoryIndex() {\n             adResultMapping = getAnomalyResultMappings();\n         } catch (IOException e) {\n             logger.error(\"Fail to roll over AD result index, as can't get AD result index mapping\");\n-            return false;\n+            return;\n         }\n         request.getCreateIndexRequest().index(AD_RESULT_HISTORY_INDEX_PATTERN).mapping(MAPPING_TYPE, adResultMapping, XContentType.JSON);\n         request.addMaxIndexDocsCondition(historyMaxDocs);\n-        request.addMaxIndexAgeCondition(historyMaxAge);\n-        RolloverResponse response = adminClient.indices().rolloverIndex(request).actionGet(requestTimeout);\n-        if (!response.isRolledOver()) {\n-            logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+        adminClient.indices().rolloverIndex(request, ActionListener.wrap(response -> {\n+            if (!response.isRolledOver()) {\n+                logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+            } else {\n+                logger.info(\"{} rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+                deleteOldHistoryIndices();\n+            }\n+        }, exception -> { logger.error(\"Fail to roll over result index\", exception); }));\n+    }\n+\n+    private void deleteOldHistoryIndices() {\n+        Set<String> candidates = new HashSet<String>();\n+\n+        ClusterStateRequest clusterStateRequest = new ClusterStateRequest()\n+            .clear()\n+            .indices(AnomalyDetectionIndices.ALL_AD_RESULTS_INDEX_PATTERN)\n+            .metadata(true)\n+            .local(true)\n+            .indicesOptions(IndicesOptions.strictExpand());\n+\n+        adminClient.cluster().state(clusterStateRequest, ActionListener.wrap(clusterStateResponse -> {\n+            String latestToDelete = null;\n+            long latest = Long.MIN_VALUE;\n+            for (ObjectCursor<IndexMetadata> cursor : clusterStateResponse.getState().metadata().indices().values()) {\n+                IndexMetadata indexMetaData = cursor.value;\n+                long creationTime = indexMetaData.getCreationDate();\n+\n+                if ((Instant.now().toEpochMilli() - creationTime) > historyRetentionPeriod.millis()) {\n+                    String indexName = indexMetaData.getIndex().getName();\n+                    candidates.add(indexName);\n+                    if (latest < creationTime) {\n+                        latest = creationTime;\n+                        latestToDelete = indexName;\n+                    }\n+                }\n+            }\n+\n+            if (candidates.size() > 1) {\n+                // delete all indices except the last one because the last one may contain docs newer than the retention period\n+                candidates.remove(latestToDelete);\n+                String[] toDelete = candidates.toArray(Strings.EMPTY_ARRAY);\n+                DeleteIndexRequest deleteIndexRequest = new DeleteIndexRequest(toDelete);\n+                adminClient.indices().delete(deleteIndexRequest, ActionListener.wrap(deleteIndexResponse -> {\n+                    if (!deleteIndexResponse.isAcknowledged()) {\n+                        logger\n+                            .error(\n+                                \"Could not delete one or more Anomaly result indices: {}. Retrying one by one.\",\n+                                Arrays.toString(toDelete)\n+                            );\n+                        deleteIndexIteration(toDelete);\n+                    } else {\n+                        logger.error(\"Succeeded in deleting expired anomaly result indices: {}.\", Arrays.toString(toDelete));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bbf1b5466f1a2082e5da389720a51d7e684f1387"}, "originalPosition": 181}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM3MDEzNTUw", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/174#pullrequestreview-437013550", "createdAt": "2020-06-24T21:17:53Z", "commit": {"oid": "bbf1b5466f1a2082e5da389720a51d7e684f1387"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQyMToxNzo1M1rOGojdjw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQyMToxNzo1M1rOGojdjw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTE3NzIzMQ==", "bodyText": "maybe we can log the exception before retrying", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/174#discussion_r445177231", "createdAt": "2020-06-24T21:17:53Z", "author": {"login": "yizheliu-amazon"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/indices/AnomalyDetectionIndices.java", "diffHunk": "@@ -275,15 +286,82 @@ private boolean rolloverHistoryIndex() {\n             adResultMapping = getAnomalyResultMappings();\n         } catch (IOException e) {\n             logger.error(\"Fail to roll over AD result index, as can't get AD result index mapping\");\n-            return false;\n+            return;\n         }\n         request.getCreateIndexRequest().index(AD_RESULT_HISTORY_INDEX_PATTERN).mapping(MAPPING_TYPE, adResultMapping, XContentType.JSON);\n         request.addMaxIndexDocsCondition(historyMaxDocs);\n-        request.addMaxIndexAgeCondition(historyMaxAge);\n-        RolloverResponse response = adminClient.indices().rolloverIndex(request).actionGet(requestTimeout);\n-        if (!response.isRolledOver()) {\n-            logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+        adminClient.indices().rolloverIndex(request, ActionListener.wrap(response -> {\n+            if (!response.isRolledOver()) {\n+                logger.warn(\"{} not rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+            } else {\n+                logger.info(\"{} rolled over. Conditions were: {}\", AD_RESULT_HISTORY_WRITE_INDEX_ALIAS, response.getConditionStatus());\n+                deleteOldHistoryIndices();\n+            }\n+        }, exception -> { logger.error(\"Fail to roll over result index\", exception); }));\n+    }\n+\n+    private void deleteOldHistoryIndices() {\n+        Set<String> candidates = new HashSet<String>();\n+\n+        ClusterStateRequest clusterStateRequest = new ClusterStateRequest()\n+            .clear()\n+            .indices(AnomalyDetectionIndices.ALL_AD_RESULTS_INDEX_PATTERN)\n+            .metadata(true)\n+            .local(true)\n+            .indicesOptions(IndicesOptions.strictExpand());\n+\n+        adminClient.cluster().state(clusterStateRequest, ActionListener.wrap(clusterStateResponse -> {\n+            String latestToDelete = null;\n+            long latest = Long.MIN_VALUE;\n+            for (ObjectCursor<IndexMetadata> cursor : clusterStateResponse.getState().metadata().indices().values()) {\n+                IndexMetadata indexMetaData = cursor.value;\n+                long creationTime = indexMetaData.getCreationDate();\n+\n+                if ((Instant.now().toEpochMilli() - creationTime) > historyRetentionPeriod.millis()) {\n+                    String indexName = indexMetaData.getIndex().getName();\n+                    candidates.add(indexName);\n+                    if (latest < creationTime) {\n+                        latest = creationTime;\n+                        latestToDelete = indexName;\n+                    }\n+                }\n+            }\n+\n+            if (candidates.size() > 1) {\n+                // delete all indices except the last one because the last one may contain docs newer than the retention period\n+                candidates.remove(latestToDelete);\n+                String[] toDelete = candidates.toArray(Strings.EMPTY_ARRAY);\n+                DeleteIndexRequest deleteIndexRequest = new DeleteIndexRequest(toDelete);\n+                adminClient.indices().delete(deleteIndexRequest, ActionListener.wrap(deleteIndexResponse -> {\n+                    if (!deleteIndexResponse.isAcknowledged()) {\n+                        logger\n+                            .error(\n+                                \"Could not delete one or more Anomaly result indices: {}. Retrying one by one.\",\n+                                Arrays.toString(toDelete)\n+                            );\n+                        deleteIndexIteration(toDelete);\n+                    } else {\n+                        logger.error(\"Succeeded in deleting expired anomaly result indices: {}.\", Arrays.toString(toDelete));\n+                    }\n+                }, exception -> { deleteIndexIteration(toDelete); }));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bbf1b5466f1a2082e5da389720a51d7e684f1387"}, "originalPosition": 183}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM3MDE1NDc4", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/174#pullrequestreview-437015478", "createdAt": "2020-06-24T21:21:15Z", "commit": {"oid": "bbf1b5466f1a2082e5da389720a51d7e684f1387"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM4NDU5OTA0", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/174#pullrequestreview-438459904", "createdAt": "2020-06-26T17:08:34Z", "commit": {"oid": "bbf1b5466f1a2082e5da389720a51d7e684f1387"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7fec24da087feda154d15756f5cea17a14faa630", "author": {"user": {"login": "kaituo", "name": "Kaituo Li"}}, "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/7fec24da087feda154d15756f5cea17a14faa630", "committedDate": "2020-06-29T16:25:10Z", "message": "Add UT"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1486, "cost": 1, "resetAt": "2021-11-01T16:19:10Z"}}}