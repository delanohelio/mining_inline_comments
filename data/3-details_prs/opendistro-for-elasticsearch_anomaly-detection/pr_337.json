{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTQzMDIwMTc1", "number": 337, "title": "add AD task cache", "bodyText": "Issue #, if available:\nDescription of changes:\nAdd AD task cache. We will put RCF&threshold model, shingle data, threshold model training data in cache.\n\n\n./gradlew build\n./gradlew integTest -PnumNodes=3\n\nBy submitting this pull request, I confirm that you can use, modify, copy, and redistribute this contribution, under the terms of your choice.", "createdAt": "2020-12-20T05:26:36Z", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/337", "merged": true, "mergeCommit": {"oid": "d5683f6f66d141612068f1704997056855189494"}, "closed": true, "closedAt": "2020-12-23T19:35:10Z", "author": {"login": "ylwu-amzn"}, "timelineItems": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdn6QQgAH2gAyNTQzMDIwMTc1OjFiZjE0N2MwZDljZTczYjUxOWJjY2E1YTk3M2M3MmRiODdmOTc3MDc=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdpEHGFAFqTU1ODE4NDU1Mg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "1bf147c0d9ce73b519bcca5a973c72db87f97707", "author": {"user": {"login": "ylwu-amzn", "name": "Yaliang"}}, "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/1bf147c0d9ce73b519bcca5a973c72db87f97707", "committedDate": "2020-12-20T05:12:32Z", "message": "add AD task cache"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU2NTc2MzEw", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/337#pullrequestreview-556576310", "createdAt": "2020-12-21T18:21:21Z", "commit": {"oid": "1bf147c0d9ce73b519bcca5a973c72db87f97707"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQxODoyMToyMVrOIJhm3Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQxODozNDo0MFrOIJh-PQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njg1ODcxNw==", "bodyText": "so only one task is allowed per detector, right?", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/337#discussion_r546858717", "createdAt": "2020-12-21T18:21:21Z", "author": {"login": "weicongs-amazon"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/task/ADTaskCacheManager.java", "diffHunk": "@@ -0,0 +1,306 @@\n+/*\n+ * Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.task;\n+\n+import static com.amazon.opendistroforelasticsearch.ad.MemoryTracker.Origin.HISTORICAL_SINGLE_ENTITY_DETECTOR;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.MAX_BATCH_TASK_PER_NODE;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.NUM_TREES;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.THRESHOLD_MODEL_TRAINING_SIZE;\n+\n+import java.util.Deque;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.settings.Settings;\n+\n+import com.amazon.opendistroforelasticsearch.ad.MemoryTracker;\n+import com.amazon.opendistroforelasticsearch.ad.common.exception.LimitExceededException;\n+import com.amazon.opendistroforelasticsearch.ad.ml.ThresholdingModel;\n+import com.amazon.opendistroforelasticsearch.ad.model.ADTask;\n+import com.amazon.randomcutforest.RandomCutForest;\n+\n+public class ADTaskCacheManager {\n+\n+    private final Map<String, ADBatchTaskCache> taskCaches;\n+    private volatile Integer maxAdBatchTaskPerNode;\n+    private final MemoryTracker memoryTracker;\n+\n+    /**\n+     * Constructor to create AD task cache manager.\n+     *\n+     * @param settings ES settings\n+     * @param clusterService ES cluster service\n+     * @param memoryTracker AD memory tracker\n+     */\n+    public ADTaskCacheManager(Settings settings, ClusterService clusterService, MemoryTracker memoryTracker) {\n+        this.maxAdBatchTaskPerNode = MAX_BATCH_TASK_PER_NODE.get(settings);\n+        clusterService.getClusterSettings().addSettingsUpdateConsumer(MAX_BATCH_TASK_PER_NODE, it -> maxAdBatchTaskPerNode = it);\n+        taskCaches = new ConcurrentHashMap<>();\n+        this.memoryTracker = memoryTracker;\n+    }\n+\n+    /**\n+     * Put AD task into cache.\n+     *\n+     * @param adTask AD task\n+     */\n+    public synchronized void put(ADTask adTask) {\n+        String taskId = adTask.getTaskId();\n+        if (contains(taskId)) {\n+            throw new IllegalArgumentException(\"AD task is already running\");\n+        }\n+        if (containsTaskOfDetector(adTask.getDetectorId())) {\n+            throw new IllegalArgumentException(\"There is one task executing for detector\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1bf147c0d9ce73b519bcca5a973c72db87f97707"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njg2MTQ1NQ==", "bodyText": "do we really need this if this is a private method?", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/337#discussion_r546861455", "createdAt": "2020-12-21T18:27:20Z", "author": {"login": "weicongs-amazon"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/task/ADTaskCacheManager.java", "diffHunk": "@@ -0,0 +1,306 @@\n+/*\n+ * Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.task;\n+\n+import static com.amazon.opendistroforelasticsearch.ad.MemoryTracker.Origin.HISTORICAL_SINGLE_ENTITY_DETECTOR;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.MAX_BATCH_TASK_PER_NODE;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.NUM_TREES;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.THRESHOLD_MODEL_TRAINING_SIZE;\n+\n+import java.util.Deque;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.settings.Settings;\n+\n+import com.amazon.opendistroforelasticsearch.ad.MemoryTracker;\n+import com.amazon.opendistroforelasticsearch.ad.common.exception.LimitExceededException;\n+import com.amazon.opendistroforelasticsearch.ad.ml.ThresholdingModel;\n+import com.amazon.opendistroforelasticsearch.ad.model.ADTask;\n+import com.amazon.randomcutforest.RandomCutForest;\n+\n+public class ADTaskCacheManager {\n+\n+    private final Map<String, ADBatchTaskCache> taskCaches;\n+    private volatile Integer maxAdBatchTaskPerNode;\n+    private final MemoryTracker memoryTracker;\n+\n+    /**\n+     * Constructor to create AD task cache manager.\n+     *\n+     * @param settings ES settings\n+     * @param clusterService ES cluster service\n+     * @param memoryTracker AD memory tracker\n+     */\n+    public ADTaskCacheManager(Settings settings, ClusterService clusterService, MemoryTracker memoryTracker) {\n+        this.maxAdBatchTaskPerNode = MAX_BATCH_TASK_PER_NODE.get(settings);\n+        clusterService.getClusterSettings().addSettingsUpdateConsumer(MAX_BATCH_TASK_PER_NODE, it -> maxAdBatchTaskPerNode = it);\n+        taskCaches = new ConcurrentHashMap<>();\n+        this.memoryTracker = memoryTracker;\n+    }\n+\n+    /**\n+     * Put AD task into cache.\n+     *\n+     * @param adTask AD task\n+     */\n+    public synchronized void put(ADTask adTask) {\n+        String taskId = adTask.getTaskId();\n+        if (contains(taskId)) {\n+            throw new IllegalArgumentException(\"AD task is already running\");\n+        }\n+        if (containsTaskOfDetector(adTask.getDetectorId())) {\n+            throw new IllegalArgumentException(\"There is one task executing for detector\");\n+        }\n+        checkRunningTaskLimit();\n+        long neededCacheSize = calculateADTaskCacheSize(adTask);\n+        if (!memoryTracker.canAllocate(neededCacheSize)) {\n+            throw new LimitExceededException(\"No enough memory to run detector\");\n+        }\n+        memoryTracker.consumeMemory(neededCacheSize, false, HISTORICAL_SINGLE_ENTITY_DETECTOR);\n+        ADBatchTaskCache taskCache = new ADBatchTaskCache(adTask);\n+        taskCache.getCacheMemorySize().set(neededCacheSize);\n+        taskCaches.put(taskId, taskCache);\n+    }\n+\n+    /**\n+     * check if current running batch task on current node exceeds\n+     * max running task limitation.\n+     */\n+    public void checkRunningTaskLimit() {\n+        if (size() >= maxAdBatchTaskPerNode) {\n+            String error = \"Can't run more than \" + maxAdBatchTaskPerNode + \" historical detectors per data node\";\n+            throw new LimitExceededException(error);\n+        }\n+    }\n+\n+    /**\n+     * Get task RCF model.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return RCF model\n+     */\n+    public RandomCutForest getRcfModel(String taskId) {\n+        return getBatchTaskCache(taskId).getRcfModel();\n+    }\n+\n+    /**\n+     * Get task threshold model.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return threshold model\n+     */\n+    public ThresholdingModel getThresholdModel(String taskId) {\n+        return getBatchTaskCache(taskId).getThresholdModel();\n+    }\n+\n+    /**\n+     * Get threshold model training data.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return threshold model training data\n+     */\n+    public List<Double> getThresholdModelTrainingData(String taskId) {\n+        return getBatchTaskCache(taskId).getThresholdModelTrainingData();\n+    }\n+\n+    /**\n+     * Threshold model trained or not.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return true if threshold model trained; otherwise, return false\n+     */\n+    public boolean isThresholdModelTrained(String taskId) {\n+        return getBatchTaskCache(taskId).isThresholdModelTrained();\n+    }\n+\n+    /**\n+     * Set threshold model trained or not.\n+     *\n+     * @param taskId task id\n+     * @param trained threshold model trained or not\n+     */\n+    public void setThresholdModelTrained(String taskId, boolean trained) {\n+        ADBatchTaskCache taskCache = getBatchTaskCache(taskId);\n+        taskCache.setThresholdModelTrained(trained);\n+        if (trained) {\n+            int size = taskCache.getThresholdModelTrainingData().size();\n+            long cacheSize = trainingDataMemorySize(size);\n+            taskCache.getThresholdModelTrainingData().clear();\n+            taskCache.getCacheMemorySize().getAndAdd(-cacheSize);\n+            memoryTracker.releaseMemory(cacheSize, false, HISTORICAL_SINGLE_ENTITY_DETECTOR);\n+        }\n+    }\n+\n+    /**\n+     * Get shingle data.\n+     *\n+     * @param taskId AD task id\n+     * @return shingle data\n+     */\n+    public Deque<Map.Entry<Long, Optional<double[]>>> getShingle(String taskId) {\n+        return getBatchTaskCache(taskId).getShingle();\n+    }\n+\n+    /**\n+     * Check if task exists in cache.\n+     *\n+     * @param taskId task id\n+     * @return true if task exists in cache; otherwise, return false.\n+     */\n+    public boolean contains(String taskId) {\n+        return taskCaches.containsKey(taskId);\n+    }\n+\n+    /**\n+     * Check if there is task in cache for detector.\n+     *\n+     * @param detectorId detector id\n+     * @return true if there is task in cache; otherwise return false\n+     */\n+    public boolean containsTaskOfDetector(String detectorId) {\n+        return taskCaches.values().stream().filter(v -> Objects.equals(detectorId, v.getDetectorId())).findAny().isPresent();\n+    }\n+\n+    /**\n+     * Get batch task cache. If task doesn't exist in cache, will throw\n+     * {@link java.lang.IllegalArgumentException}\n+     *\n+     * @param taskId task id\n+     * @return AD batch task cache\n+     */\n+    private ADBatchTaskCache getBatchTaskCache(String taskId) {\n+        if (!contains(taskId)) {\n+            throw new IllegalArgumentException(\"AD task not in cache\");\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1bf147c0d9ce73b519bcca5a973c72db87f97707"}, "originalPosition": 196}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njg2MjYwNg==", "bodyText": "why do we need clear this up since it's pretty small?", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/337#discussion_r546862606", "createdAt": "2020-12-21T18:29:46Z", "author": {"login": "weicongs-amazon"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/task/ADTaskCacheManager.java", "diffHunk": "@@ -0,0 +1,306 @@\n+/*\n+ * Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.task;\n+\n+import static com.amazon.opendistroforelasticsearch.ad.MemoryTracker.Origin.HISTORICAL_SINGLE_ENTITY_DETECTOR;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.MAX_BATCH_TASK_PER_NODE;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.NUM_TREES;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.THRESHOLD_MODEL_TRAINING_SIZE;\n+\n+import java.util.Deque;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.settings.Settings;\n+\n+import com.amazon.opendistroforelasticsearch.ad.MemoryTracker;\n+import com.amazon.opendistroforelasticsearch.ad.common.exception.LimitExceededException;\n+import com.amazon.opendistroforelasticsearch.ad.ml.ThresholdingModel;\n+import com.amazon.opendistroforelasticsearch.ad.model.ADTask;\n+import com.amazon.randomcutforest.RandomCutForest;\n+\n+public class ADTaskCacheManager {\n+\n+    private final Map<String, ADBatchTaskCache> taskCaches;\n+    private volatile Integer maxAdBatchTaskPerNode;\n+    private final MemoryTracker memoryTracker;\n+\n+    /**\n+     * Constructor to create AD task cache manager.\n+     *\n+     * @param settings ES settings\n+     * @param clusterService ES cluster service\n+     * @param memoryTracker AD memory tracker\n+     */\n+    public ADTaskCacheManager(Settings settings, ClusterService clusterService, MemoryTracker memoryTracker) {\n+        this.maxAdBatchTaskPerNode = MAX_BATCH_TASK_PER_NODE.get(settings);\n+        clusterService.getClusterSettings().addSettingsUpdateConsumer(MAX_BATCH_TASK_PER_NODE, it -> maxAdBatchTaskPerNode = it);\n+        taskCaches = new ConcurrentHashMap<>();\n+        this.memoryTracker = memoryTracker;\n+    }\n+\n+    /**\n+     * Put AD task into cache.\n+     *\n+     * @param adTask AD task\n+     */\n+    public synchronized void put(ADTask adTask) {\n+        String taskId = adTask.getTaskId();\n+        if (contains(taskId)) {\n+            throw new IllegalArgumentException(\"AD task is already running\");\n+        }\n+        if (containsTaskOfDetector(adTask.getDetectorId())) {\n+            throw new IllegalArgumentException(\"There is one task executing for detector\");\n+        }\n+        checkRunningTaskLimit();\n+        long neededCacheSize = calculateADTaskCacheSize(adTask);\n+        if (!memoryTracker.canAllocate(neededCacheSize)) {\n+            throw new LimitExceededException(\"No enough memory to run detector\");\n+        }\n+        memoryTracker.consumeMemory(neededCacheSize, false, HISTORICAL_SINGLE_ENTITY_DETECTOR);\n+        ADBatchTaskCache taskCache = new ADBatchTaskCache(adTask);\n+        taskCache.getCacheMemorySize().set(neededCacheSize);\n+        taskCaches.put(taskId, taskCache);\n+    }\n+\n+    /**\n+     * check if current running batch task on current node exceeds\n+     * max running task limitation.\n+     */\n+    public void checkRunningTaskLimit() {\n+        if (size() >= maxAdBatchTaskPerNode) {\n+            String error = \"Can't run more than \" + maxAdBatchTaskPerNode + \" historical detectors per data node\";\n+            throw new LimitExceededException(error);\n+        }\n+    }\n+\n+    /**\n+     * Get task RCF model.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return RCF model\n+     */\n+    public RandomCutForest getRcfModel(String taskId) {\n+        return getBatchTaskCache(taskId).getRcfModel();\n+    }\n+\n+    /**\n+     * Get task threshold model.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return threshold model\n+     */\n+    public ThresholdingModel getThresholdModel(String taskId) {\n+        return getBatchTaskCache(taskId).getThresholdModel();\n+    }\n+\n+    /**\n+     * Get threshold model training data.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return threshold model training data\n+     */\n+    public List<Double> getThresholdModelTrainingData(String taskId) {\n+        return getBatchTaskCache(taskId).getThresholdModelTrainingData();\n+    }\n+\n+    /**\n+     * Threshold model trained or not.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return true if threshold model trained; otherwise, return false\n+     */\n+    public boolean isThresholdModelTrained(String taskId) {\n+        return getBatchTaskCache(taskId).isThresholdModelTrained();\n+    }\n+\n+    /**\n+     * Set threshold model trained or not.\n+     *\n+     * @param taskId task id\n+     * @param trained threshold model trained or not\n+     */\n+    public void setThresholdModelTrained(String taskId, boolean trained) {\n+        ADBatchTaskCache taskCache = getBatchTaskCache(taskId);\n+        taskCache.setThresholdModelTrained(trained);\n+        if (trained) {\n+            int size = taskCache.getThresholdModelTrainingData().size();\n+            long cacheSize = trainingDataMemorySize(size);\n+            taskCache.getThresholdModelTrainingData().clear();\n+            taskCache.getCacheMemorySize().getAndAdd(-cacheSize);\n+            memoryTracker.releaseMemory(cacheSize, false, HISTORICAL_SINGLE_ENTITY_DETECTOR);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1bf147c0d9ce73b519bcca5a973c72db87f97707"}, "originalPosition": 152}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njg2NDcwMQ==", "bodyText": "why do we need put rcf model here? I remember there is rcf model caching in the AD entity result execution.  Are we trying to build a new workflow for this one?", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/337#discussion_r546864701", "createdAt": "2020-12-21T18:34:40Z", "author": {"login": "weicongs-amazon"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/task/ADBatchTaskCache.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.task;\n+\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.NUM_MIN_SAMPLES;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.NUM_SAMPLES_PER_TREE;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.NUM_TREES;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.THRESHOLD_MODEL_TRAINING_SIZE;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.TIME_DECAY;\n+\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Deque;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicLong;\n+\n+import com.amazon.opendistroforelasticsearch.ad.ml.HybridThresholdingModel;\n+import com.amazon.opendistroforelasticsearch.ad.ml.ThresholdingModel;\n+import com.amazon.opendistroforelasticsearch.ad.model.ADTask;\n+import com.amazon.opendistroforelasticsearch.ad.model.AnomalyDetector;\n+import com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings;\n+import com.amazon.randomcutforest.RandomCutForest;\n+\n+/**\n+ * AD batch task cache which will hold RCF, threshold model, shingle and training data.\n+ */\n+public class ADBatchTaskCache {\n+    private final String detectorId;\n+    private RandomCutForest rcfModel;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1bf147c0d9ce73b519bcca5a973c72db87f97707"}, "originalPosition": 45}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU2NjM5MjI0", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/337#pullrequestreview-556639224", "createdAt": "2020-12-21T20:17:34Z", "commit": {"oid": "1bf147c0d9ce73b519bcca5a973c72db87f97707"}, "state": "APPROVED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQyMDoxNzozNFrOIJkwrg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQyMDoyMTo0NlrOIJk3LQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjkxMDM4Mg==", "bodyText": "my point is if this is a really useful exception. I assume this won't happen at all. If this happens, what's the logic like?  Anyway, this doesn't hurt anything.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/337#discussion_r546910382", "createdAt": "2020-12-21T20:17:34Z", "author": {"login": "weicongs-amazon"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/task/ADTaskCacheManager.java", "diffHunk": "@@ -0,0 +1,306 @@\n+/*\n+ * Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.task;\n+\n+import static com.amazon.opendistroforelasticsearch.ad.MemoryTracker.Origin.HISTORICAL_SINGLE_ENTITY_DETECTOR;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.MAX_BATCH_TASK_PER_NODE;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.NUM_TREES;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.THRESHOLD_MODEL_TRAINING_SIZE;\n+\n+import java.util.Deque;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.settings.Settings;\n+\n+import com.amazon.opendistroforelasticsearch.ad.MemoryTracker;\n+import com.amazon.opendistroforelasticsearch.ad.common.exception.LimitExceededException;\n+import com.amazon.opendistroforelasticsearch.ad.ml.ThresholdingModel;\n+import com.amazon.opendistroforelasticsearch.ad.model.ADTask;\n+import com.amazon.randomcutforest.RandomCutForest;\n+\n+public class ADTaskCacheManager {\n+\n+    private final Map<String, ADBatchTaskCache> taskCaches;\n+    private volatile Integer maxAdBatchTaskPerNode;\n+    private final MemoryTracker memoryTracker;\n+\n+    /**\n+     * Constructor to create AD task cache manager.\n+     *\n+     * @param settings ES settings\n+     * @param clusterService ES cluster service\n+     * @param memoryTracker AD memory tracker\n+     */\n+    public ADTaskCacheManager(Settings settings, ClusterService clusterService, MemoryTracker memoryTracker) {\n+        this.maxAdBatchTaskPerNode = MAX_BATCH_TASK_PER_NODE.get(settings);\n+        clusterService.getClusterSettings().addSettingsUpdateConsumer(MAX_BATCH_TASK_PER_NODE, it -> maxAdBatchTaskPerNode = it);\n+        taskCaches = new ConcurrentHashMap<>();\n+        this.memoryTracker = memoryTracker;\n+    }\n+\n+    /**\n+     * Put AD task into cache.\n+     *\n+     * @param adTask AD task\n+     */\n+    public synchronized void put(ADTask adTask) {\n+        String taskId = adTask.getTaskId();\n+        if (contains(taskId)) {\n+            throw new IllegalArgumentException(\"AD task is already running\");\n+        }\n+        if (containsTaskOfDetector(adTask.getDetectorId())) {\n+            throw new IllegalArgumentException(\"There is one task executing for detector\");\n+        }\n+        checkRunningTaskLimit();\n+        long neededCacheSize = calculateADTaskCacheSize(adTask);\n+        if (!memoryTracker.canAllocate(neededCacheSize)) {\n+            throw new LimitExceededException(\"No enough memory to run detector\");\n+        }\n+        memoryTracker.consumeMemory(neededCacheSize, false, HISTORICAL_SINGLE_ENTITY_DETECTOR);\n+        ADBatchTaskCache taskCache = new ADBatchTaskCache(adTask);\n+        taskCache.getCacheMemorySize().set(neededCacheSize);\n+        taskCaches.put(taskId, taskCache);\n+    }\n+\n+    /**\n+     * check if current running batch task on current node exceeds\n+     * max running task limitation.\n+     */\n+    public void checkRunningTaskLimit() {\n+        if (size() >= maxAdBatchTaskPerNode) {\n+            String error = \"Can't run more than \" + maxAdBatchTaskPerNode + \" historical detectors per data node\";\n+            throw new LimitExceededException(error);\n+        }\n+    }\n+\n+    /**\n+     * Get task RCF model.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return RCF model\n+     */\n+    public RandomCutForest getRcfModel(String taskId) {\n+        return getBatchTaskCache(taskId).getRcfModel();\n+    }\n+\n+    /**\n+     * Get task threshold model.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return threshold model\n+     */\n+    public ThresholdingModel getThresholdModel(String taskId) {\n+        return getBatchTaskCache(taskId).getThresholdModel();\n+    }\n+\n+    /**\n+     * Get threshold model training data.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return threshold model training data\n+     */\n+    public List<Double> getThresholdModelTrainingData(String taskId) {\n+        return getBatchTaskCache(taskId).getThresholdModelTrainingData();\n+    }\n+\n+    /**\n+     * Threshold model trained or not.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return true if threshold model trained; otherwise, return false\n+     */\n+    public boolean isThresholdModelTrained(String taskId) {\n+        return getBatchTaskCache(taskId).isThresholdModelTrained();\n+    }\n+\n+    /**\n+     * Set threshold model trained or not.\n+     *\n+     * @param taskId task id\n+     * @param trained threshold model trained or not\n+     */\n+    public void setThresholdModelTrained(String taskId, boolean trained) {\n+        ADBatchTaskCache taskCache = getBatchTaskCache(taskId);\n+        taskCache.setThresholdModelTrained(trained);\n+        if (trained) {\n+            int size = taskCache.getThresholdModelTrainingData().size();\n+            long cacheSize = trainingDataMemorySize(size);\n+            taskCache.getThresholdModelTrainingData().clear();\n+            taskCache.getCacheMemorySize().getAndAdd(-cacheSize);\n+            memoryTracker.releaseMemory(cacheSize, false, HISTORICAL_SINGLE_ENTITY_DETECTOR);\n+        }\n+    }\n+\n+    /**\n+     * Get shingle data.\n+     *\n+     * @param taskId AD task id\n+     * @return shingle data\n+     */\n+    public Deque<Map.Entry<Long, Optional<double[]>>> getShingle(String taskId) {\n+        return getBatchTaskCache(taskId).getShingle();\n+    }\n+\n+    /**\n+     * Check if task exists in cache.\n+     *\n+     * @param taskId task id\n+     * @return true if task exists in cache; otherwise, return false.\n+     */\n+    public boolean contains(String taskId) {\n+        return taskCaches.containsKey(taskId);\n+    }\n+\n+    /**\n+     * Check if there is task in cache for detector.\n+     *\n+     * @param detectorId detector id\n+     * @return true if there is task in cache; otherwise return false\n+     */\n+    public boolean containsTaskOfDetector(String detectorId) {\n+        return taskCaches.values().stream().filter(v -> Objects.equals(detectorId, v.getDetectorId())).findAny().isPresent();\n+    }\n+\n+    /**\n+     * Get batch task cache. If task doesn't exist in cache, will throw\n+     * {@link java.lang.IllegalArgumentException}\n+     *\n+     * @param taskId task id\n+     * @return AD batch task cache\n+     */\n+    private ADBatchTaskCache getBatchTaskCache(String taskId) {\n+        if (!contains(taskId)) {\n+            throw new IllegalArgumentException(\"AD task not in cache\");\n+        }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njg2MTQ1NQ=="}, "originalCommit": {"oid": "1bf147c0d9ce73b519bcca5a973c72db87f97707"}, "originalPosition": 196}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjkxMjA0NQ==", "bodyText": "thanks. It's good with the second option. btw, is this cachedTask including the requirement of realtime detector, or we just have these two now, and consolidate these later by refactoring?", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/337#discussion_r546912045", "createdAt": "2020-12-21T20:21:46Z", "author": {"login": "weicongs-amazon"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/task/ADBatchTaskCache.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.task;\n+\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.NUM_MIN_SAMPLES;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.NUM_SAMPLES_PER_TREE;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.NUM_TREES;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.THRESHOLD_MODEL_TRAINING_SIZE;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.TIME_DECAY;\n+\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Deque;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicLong;\n+\n+import com.amazon.opendistroforelasticsearch.ad.ml.HybridThresholdingModel;\n+import com.amazon.opendistroforelasticsearch.ad.ml.ThresholdingModel;\n+import com.amazon.opendistroforelasticsearch.ad.model.ADTask;\n+import com.amazon.opendistroforelasticsearch.ad.model.AnomalyDetector;\n+import com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings;\n+import com.amazon.randomcutforest.RandomCutForest;\n+\n+/**\n+ * AD batch task cache which will hold RCF, threshold model, shingle and training data.\n+ */\n+public class ADBatchTaskCache {\n+    private final String detectorId;\n+    private RandomCutForest rcfModel;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njg2NDcwMQ=="}, "originalCommit": {"oid": "1bf147c0d9ce73b519bcca5a973c72db87f97707"}, "originalPosition": 45}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU2NjI0NDc4", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/337#pullrequestreview-556624478", "createdAt": "2020-12-21T19:49:30Z", "commit": {"oid": "1bf147c0d9ce73b519bcca5a973c72db87f97707"}, "state": "COMMENTED", "comments": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQxOTo0OTozMVrOIJkCzg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQyMTozMTo1NlrOIJmiZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njg5ODYzOA==", "bodyText": "What do you mean by \"create AD tasks for all detectors\"?", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/337#discussion_r546898638", "createdAt": "2020-12-21T19:49:31Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/task/ADBatchTaskCache.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.task;\n+\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.NUM_MIN_SAMPLES;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.NUM_SAMPLES_PER_TREE;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.NUM_TREES;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.THRESHOLD_MODEL_TRAINING_SIZE;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.TIME_DECAY;\n+\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Deque;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicLong;\n+\n+import com.amazon.opendistroforelasticsearch.ad.ml.HybridThresholdingModel;\n+import com.amazon.opendistroforelasticsearch.ad.ml.ThresholdingModel;\n+import com.amazon.opendistroforelasticsearch.ad.model.ADTask;\n+import com.amazon.opendistroforelasticsearch.ad.model.AnomalyDetector;\n+import com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings;\n+import com.amazon.randomcutforest.RandomCutForest;\n+\n+/**\n+ * AD batch task cache which will hold RCF, threshold model, shingle and training data.\n+ */\n+public class ADBatchTaskCache {\n+    private final String detectorId;\n+    private RandomCutForest rcfModel;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njg2NDcwMQ=="}, "originalCommit": {"oid": "1bf147c0d9ce73b519bcca5a973c72db87f97707"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjkwMzgxMw==", "bodyText": "cancel cache does not sound correct English.  You meant invalidate cache?", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/337#discussion_r546903813", "createdAt": "2020-12-21T20:01:58Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/task/ADBatchTaskCache.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.task;\n+\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.NUM_MIN_SAMPLES;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.NUM_SAMPLES_PER_TREE;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.NUM_TREES;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.THRESHOLD_MODEL_TRAINING_SIZE;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.TIME_DECAY;\n+\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Deque;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicLong;\n+\n+import com.amazon.opendistroforelasticsearch.ad.ml.HybridThresholdingModel;\n+import com.amazon.opendistroforelasticsearch.ad.ml.ThresholdingModel;\n+import com.amazon.opendistroforelasticsearch.ad.model.ADTask;\n+import com.amazon.opendistroforelasticsearch.ad.model.AnomalyDetector;\n+import com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings;\n+import com.amazon.randomcutforest.RandomCutForest;\n+\n+/**\n+ * AD batch task cache which will hold RCF, threshold model, shingle and training data.\n+ */\n+public class ADBatchTaskCache {\n+    private final String detectorId;\n+    private RandomCutForest rcfModel;\n+    private ThresholdingModel thresholdModel;\n+    private boolean thresholdModelTrained;\n+    private Deque<Map.Entry<Long, Optional<double[]>>> shingle;\n+    private List<Double> thresholdModelTrainingData;\n+    private AtomicBoolean cancelled = new AtomicBoolean(false);\n+    private AtomicLong cacheMemorySize = new AtomicLong(0);\n+    private String cancelReason;\n+    private String cancelledBy;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1bf147c0d9ce73b519bcca5a973c72db87f97707"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjkwNjEzMg==", "bodyText": "Can you add doc describing the thrown exceptions?  The caller would need to know.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/337#discussion_r546906132", "createdAt": "2020-12-21T20:07:08Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/task/ADTaskCacheManager.java", "diffHunk": "@@ -0,0 +1,306 @@\n+/*\n+ * Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.task;\n+\n+import static com.amazon.opendistroforelasticsearch.ad.MemoryTracker.Origin.HISTORICAL_SINGLE_ENTITY_DETECTOR;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.MAX_BATCH_TASK_PER_NODE;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.NUM_TREES;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.THRESHOLD_MODEL_TRAINING_SIZE;\n+\n+import java.util.Deque;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.settings.Settings;\n+\n+import com.amazon.opendistroforelasticsearch.ad.MemoryTracker;\n+import com.amazon.opendistroforelasticsearch.ad.common.exception.LimitExceededException;\n+import com.amazon.opendistroforelasticsearch.ad.ml.ThresholdingModel;\n+import com.amazon.opendistroforelasticsearch.ad.model.ADTask;\n+import com.amazon.randomcutforest.RandomCutForest;\n+\n+public class ADTaskCacheManager {\n+\n+    private final Map<String, ADBatchTaskCache> taskCaches;\n+    private volatile Integer maxAdBatchTaskPerNode;\n+    private final MemoryTracker memoryTracker;\n+\n+    /**\n+     * Constructor to create AD task cache manager.\n+     *\n+     * @param settings ES settings\n+     * @param clusterService ES cluster service\n+     * @param memoryTracker AD memory tracker\n+     */\n+    public ADTaskCacheManager(Settings settings, ClusterService clusterService, MemoryTracker memoryTracker) {\n+        this.maxAdBatchTaskPerNode = MAX_BATCH_TASK_PER_NODE.get(settings);\n+        clusterService.getClusterSettings().addSettingsUpdateConsumer(MAX_BATCH_TASK_PER_NODE, it -> maxAdBatchTaskPerNode = it);\n+        taskCaches = new ConcurrentHashMap<>();\n+        this.memoryTracker = memoryTracker;\n+    }\n+\n+    /**\n+     * Put AD task into cache.\n+     *\n+     * @param adTask AD task\n+     */\n+    public synchronized void put(ADTask adTask) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1bf147c0d9ce73b519bcca5a973c72db87f97707"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjkwNjE2MA==", "bodyText": "Can you add doc describing the thrown exceptions?", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/337#discussion_r546906160", "createdAt": "2020-12-21T20:07:12Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/task/ADTaskCacheManager.java", "diffHunk": "@@ -0,0 +1,306 @@\n+/*\n+ * Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.task;\n+\n+import static com.amazon.opendistroforelasticsearch.ad.MemoryTracker.Origin.HISTORICAL_SINGLE_ENTITY_DETECTOR;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.MAX_BATCH_TASK_PER_NODE;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.NUM_TREES;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.THRESHOLD_MODEL_TRAINING_SIZE;\n+\n+import java.util.Deque;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.settings.Settings;\n+\n+import com.amazon.opendistroforelasticsearch.ad.MemoryTracker;\n+import com.amazon.opendistroforelasticsearch.ad.common.exception.LimitExceededException;\n+import com.amazon.opendistroforelasticsearch.ad.ml.ThresholdingModel;\n+import com.amazon.opendistroforelasticsearch.ad.model.ADTask;\n+import com.amazon.randomcutforest.RandomCutForest;\n+\n+public class ADTaskCacheManager {\n+\n+    private final Map<String, ADBatchTaskCache> taskCaches;\n+    private volatile Integer maxAdBatchTaskPerNode;\n+    private final MemoryTracker memoryTracker;\n+\n+    /**\n+     * Constructor to create AD task cache manager.\n+     *\n+     * @param settings ES settings\n+     * @param clusterService ES cluster service\n+     * @param memoryTracker AD memory tracker\n+     */\n+    public ADTaskCacheManager(Settings settings, ClusterService clusterService, MemoryTracker memoryTracker) {\n+        this.maxAdBatchTaskPerNode = MAX_BATCH_TASK_PER_NODE.get(settings);\n+        clusterService.getClusterSettings().addSettingsUpdateConsumer(MAX_BATCH_TASK_PER_NODE, it -> maxAdBatchTaskPerNode = it);\n+        taskCaches = new ConcurrentHashMap<>();\n+        this.memoryTracker = memoryTracker;\n+    }\n+\n+    /**\n+     * Put AD task into cache.\n+     *\n+     * @param adTask AD task\n+     */\n+    public synchronized void put(ADTask adTask) {\n+        String taskId = adTask.getTaskId();\n+        if (contains(taskId)) {\n+            throw new IllegalArgumentException(\"AD task is already running\");\n+        }\n+        if (containsTaskOfDetector(adTask.getDetectorId())) {\n+            throw new IllegalArgumentException(\"There is one task executing for detector\");\n+        }\n+        checkRunningTaskLimit();\n+        long neededCacheSize = calculateADTaskCacheSize(adTask);\n+        if (!memoryTracker.canAllocate(neededCacheSize)) {\n+            throw new LimitExceededException(\"No enough memory to run detector\");\n+        }\n+        memoryTracker.consumeMemory(neededCacheSize, false, HISTORICAL_SINGLE_ENTITY_DETECTOR);\n+        ADBatchTaskCache taskCache = new ADBatchTaskCache(adTask);\n+        taskCache.getCacheMemorySize().set(neededCacheSize);\n+        taskCaches.put(taskId, taskCache);\n+    }\n+\n+    /**\n+     * check if current running batch task on current node exceeds\n+     * max running task limitation.\n+     */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1bf147c0d9ce73b519bcca5a973c72db87f97707"}, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjkxMDQ3OA==", "bodyText": "how do you arrive at 24?  We are gonna change to data to float soon, whose size is of 4 bytes.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/337#discussion_r546910478", "createdAt": "2020-12-21T20:17:53Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/task/ADTaskCacheManager.java", "diffHunk": "@@ -0,0 +1,306 @@\n+/*\n+ * Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.task;\n+\n+import static com.amazon.opendistroforelasticsearch.ad.MemoryTracker.Origin.HISTORICAL_SINGLE_ENTITY_DETECTOR;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.MAX_BATCH_TASK_PER_NODE;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.NUM_TREES;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.THRESHOLD_MODEL_TRAINING_SIZE;\n+\n+import java.util.Deque;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.settings.Settings;\n+\n+import com.amazon.opendistroforelasticsearch.ad.MemoryTracker;\n+import com.amazon.opendistroforelasticsearch.ad.common.exception.LimitExceededException;\n+import com.amazon.opendistroforelasticsearch.ad.ml.ThresholdingModel;\n+import com.amazon.opendistroforelasticsearch.ad.model.ADTask;\n+import com.amazon.randomcutforest.RandomCutForest;\n+\n+public class ADTaskCacheManager {\n+\n+    private final Map<String, ADBatchTaskCache> taskCaches;\n+    private volatile Integer maxAdBatchTaskPerNode;\n+    private final MemoryTracker memoryTracker;\n+\n+    /**\n+     * Constructor to create AD task cache manager.\n+     *\n+     * @param settings ES settings\n+     * @param clusterService ES cluster service\n+     * @param memoryTracker AD memory tracker\n+     */\n+    public ADTaskCacheManager(Settings settings, ClusterService clusterService, MemoryTracker memoryTracker) {\n+        this.maxAdBatchTaskPerNode = MAX_BATCH_TASK_PER_NODE.get(settings);\n+        clusterService.getClusterSettings().addSettingsUpdateConsumer(MAX_BATCH_TASK_PER_NODE, it -> maxAdBatchTaskPerNode = it);\n+        taskCaches = new ConcurrentHashMap<>();\n+        this.memoryTracker = memoryTracker;\n+    }\n+\n+    /**\n+     * Put AD task into cache.\n+     *\n+     * @param adTask AD task\n+     */\n+    public synchronized void put(ADTask adTask) {\n+        String taskId = adTask.getTaskId();\n+        if (contains(taskId)) {\n+            throw new IllegalArgumentException(\"AD task is already running\");\n+        }\n+        if (containsTaskOfDetector(adTask.getDetectorId())) {\n+            throw new IllegalArgumentException(\"There is one task executing for detector\");\n+        }\n+        checkRunningTaskLimit();\n+        long neededCacheSize = calculateADTaskCacheSize(adTask);\n+        if (!memoryTracker.canAllocate(neededCacheSize)) {\n+            throw new LimitExceededException(\"No enough memory to run detector\");\n+        }\n+        memoryTracker.consumeMemory(neededCacheSize, false, HISTORICAL_SINGLE_ENTITY_DETECTOR);\n+        ADBatchTaskCache taskCache = new ADBatchTaskCache(adTask);\n+        taskCache.getCacheMemorySize().set(neededCacheSize);\n+        taskCaches.put(taskId, taskCache);\n+    }\n+\n+    /**\n+     * check if current running batch task on current node exceeds\n+     * max running task limitation.\n+     */\n+    public void checkRunningTaskLimit() {\n+        if (size() >= maxAdBatchTaskPerNode) {\n+            String error = \"Can't run more than \" + maxAdBatchTaskPerNode + \" historical detectors per data node\";\n+            throw new LimitExceededException(error);\n+        }\n+    }\n+\n+    /**\n+     * Get task RCF model.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return RCF model\n+     */\n+    public RandomCutForest getRcfModel(String taskId) {\n+        return getBatchTaskCache(taskId).getRcfModel();\n+    }\n+\n+    /**\n+     * Get task threshold model.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return threshold model\n+     */\n+    public ThresholdingModel getThresholdModel(String taskId) {\n+        return getBatchTaskCache(taskId).getThresholdModel();\n+    }\n+\n+    /**\n+     * Get threshold model training data.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return threshold model training data\n+     */\n+    public List<Double> getThresholdModelTrainingData(String taskId) {\n+        return getBatchTaskCache(taskId).getThresholdModelTrainingData();\n+    }\n+\n+    /**\n+     * Threshold model trained or not.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return true if threshold model trained; otherwise, return false\n+     */\n+    public boolean isThresholdModelTrained(String taskId) {\n+        return getBatchTaskCache(taskId).isThresholdModelTrained();\n+    }\n+\n+    /**\n+     * Set threshold model trained or not.\n+     *\n+     * @param taskId task id\n+     * @param trained threshold model trained or not\n+     */\n+    public void setThresholdModelTrained(String taskId, boolean trained) {\n+        ADBatchTaskCache taskCache = getBatchTaskCache(taskId);\n+        taskCache.setThresholdModelTrained(trained);\n+        if (trained) {\n+            int size = taskCache.getThresholdModelTrainingData().size();\n+            long cacheSize = trainingDataMemorySize(size);\n+            taskCache.getThresholdModelTrainingData().clear();\n+            taskCache.getCacheMemorySize().getAndAdd(-cacheSize);\n+            memoryTracker.releaseMemory(cacheSize, false, HISTORICAL_SINGLE_ENTITY_DETECTOR);\n+        }\n+    }\n+\n+    /**\n+     * Get shingle data.\n+     *\n+     * @param taskId AD task id\n+     * @return shingle data\n+     */\n+    public Deque<Map.Entry<Long, Optional<double[]>>> getShingle(String taskId) {\n+        return getBatchTaskCache(taskId).getShingle();\n+    }\n+\n+    /**\n+     * Check if task exists in cache.\n+     *\n+     * @param taskId task id\n+     * @return true if task exists in cache; otherwise, return false.\n+     */\n+    public boolean contains(String taskId) {\n+        return taskCaches.containsKey(taskId);\n+    }\n+\n+    /**\n+     * Check if there is task in cache for detector.\n+     *\n+     * @param detectorId detector id\n+     * @return true if there is task in cache; otherwise return false\n+     */\n+    public boolean containsTaskOfDetector(String detectorId) {\n+        return taskCaches.values().stream().filter(v -> Objects.equals(detectorId, v.getDetectorId())).findAny().isPresent();\n+    }\n+\n+    /**\n+     * Get batch task cache. If task doesn't exist in cache, will throw\n+     * {@link java.lang.IllegalArgumentException}\n+     *\n+     * @param taskId task id\n+     * @return AD batch task cache\n+     */\n+    private ADBatchTaskCache getBatchTaskCache(String taskId) {\n+        if (!contains(taskId)) {\n+            throw new IllegalArgumentException(\"AD task not in cache\");\n+        }\n+        return taskCaches.get(taskId);\n+    }\n+\n+    /**\n+     * Calculate AD task cache memory usage.\n+     *\n+     * @param adTask AD task\n+     * @return how many bytes will consume\n+     */\n+    private long calculateADTaskCacheSize(ADTask adTask) {\n+        return memoryTracker.estimateModelSize(adTask.getDetector(), NUM_TREES) + trainingDataMemorySize(THRESHOLD_MODEL_TRAINING_SIZE)\n+            + shingleMemorySize(adTask.getDetector().getShingleSize());\n+    }\n+\n+    /**\n+     * Remove task from cache.\n+     *\n+     * @param taskId AD task id\n+     */\n+    public void remove(String taskId) {\n+        if (contains(taskId)) {\n+            memoryTracker.releaseMemory(getBatchTaskCache(taskId).getCacheMemorySize().get(), false, HISTORICAL_SINGLE_ENTITY_DETECTOR);\n+            taskCaches.remove(taskId);\n+        }\n+    }\n+\n+    /**\n+     * Cancel AD task.\n+     *\n+     * @param taskId AD task id\n+     * @param reason why need to cancel task\n+     * @param userName user name\n+     */\n+    public void cancel(String taskId, String reason, String userName) {\n+        getBatchTaskCache(taskId).cancel(reason, userName);\n+    }\n+\n+    /**\n+     * Task is cancelled or not.\n+     *\n+     * @param taskId AD task id\n+     * @return true if task is cancelled; otherwise return false\n+     */\n+    public boolean isCancelled(String taskId) {\n+        ADBatchTaskCache taskCache = getBatchTaskCache(taskId);\n+        return taskCache.isCancelled();\n+    }\n+\n+    /**\n+     * Get why task cancelled.\n+     *\n+     * @param taskId AD task id\n+     * @return task cancellation reason\n+     */\n+    public String getCancelReason(String taskId) {\n+        return getBatchTaskCache(taskId).getCancelReason();\n+    }\n+\n+    /**\n+     * Get task cancelled by which user.\n+     *\n+     * @param taskId AD task id\n+     * @return user name\n+     */\n+    public String getCancelledBy(String taskId) {\n+        return getBatchTaskCache(taskId).getCancelledBy();\n+    }\n+\n+    /**\n+     * Get current task count in cache.\n+     *\n+     * @return task count\n+     */\n+    public int size() {\n+        return taskCaches.size();\n+    }\n+\n+    /**\n+     * Clear all tasks.\n+     */\n+    public void clear() {\n+        taskCaches.clear();\n+    }\n+\n+    /**\n+     * Estimate max memory usage of model training data.\n+     * The training data is double and will cache in {@link java.util.ArrayList}.\n+     * Check {@link ADBatchTaskCache#getThresholdModelTrainingData()}\n+     *\n+     * @param size training data point count\n+     * @return how many bytes will consume\n+     */\n+    public long trainingDataMemorySize(int size) {\n+        return 24 * size;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1bf147c0d9ce73b519bcca5a973c72db87f97707"}, "originalPosition": 290}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjkxMTEzOA==", "bodyText": "the shingle memory depends on # of features, shingle size, and the data type (float vs double).  Can we hardcode it to 96?", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/337#discussion_r546911138", "createdAt": "2020-12-21T20:19:29Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/task/ADTaskCacheManager.java", "diffHunk": "@@ -0,0 +1,306 @@\n+/*\n+ * Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.task;\n+\n+import static com.amazon.opendistroforelasticsearch.ad.MemoryTracker.Origin.HISTORICAL_SINGLE_ENTITY_DETECTOR;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.MAX_BATCH_TASK_PER_NODE;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.NUM_TREES;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.THRESHOLD_MODEL_TRAINING_SIZE;\n+\n+import java.util.Deque;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.settings.Settings;\n+\n+import com.amazon.opendistroforelasticsearch.ad.MemoryTracker;\n+import com.amazon.opendistroforelasticsearch.ad.common.exception.LimitExceededException;\n+import com.amazon.opendistroforelasticsearch.ad.ml.ThresholdingModel;\n+import com.amazon.opendistroforelasticsearch.ad.model.ADTask;\n+import com.amazon.randomcutforest.RandomCutForest;\n+\n+public class ADTaskCacheManager {\n+\n+    private final Map<String, ADBatchTaskCache> taskCaches;\n+    private volatile Integer maxAdBatchTaskPerNode;\n+    private final MemoryTracker memoryTracker;\n+\n+    /**\n+     * Constructor to create AD task cache manager.\n+     *\n+     * @param settings ES settings\n+     * @param clusterService ES cluster service\n+     * @param memoryTracker AD memory tracker\n+     */\n+    public ADTaskCacheManager(Settings settings, ClusterService clusterService, MemoryTracker memoryTracker) {\n+        this.maxAdBatchTaskPerNode = MAX_BATCH_TASK_PER_NODE.get(settings);\n+        clusterService.getClusterSettings().addSettingsUpdateConsumer(MAX_BATCH_TASK_PER_NODE, it -> maxAdBatchTaskPerNode = it);\n+        taskCaches = new ConcurrentHashMap<>();\n+        this.memoryTracker = memoryTracker;\n+    }\n+\n+    /**\n+     * Put AD task into cache.\n+     *\n+     * @param adTask AD task\n+     */\n+    public synchronized void put(ADTask adTask) {\n+        String taskId = adTask.getTaskId();\n+        if (contains(taskId)) {\n+            throw new IllegalArgumentException(\"AD task is already running\");\n+        }\n+        if (containsTaskOfDetector(adTask.getDetectorId())) {\n+            throw new IllegalArgumentException(\"There is one task executing for detector\");\n+        }\n+        checkRunningTaskLimit();\n+        long neededCacheSize = calculateADTaskCacheSize(adTask);\n+        if (!memoryTracker.canAllocate(neededCacheSize)) {\n+            throw new LimitExceededException(\"No enough memory to run detector\");\n+        }\n+        memoryTracker.consumeMemory(neededCacheSize, false, HISTORICAL_SINGLE_ENTITY_DETECTOR);\n+        ADBatchTaskCache taskCache = new ADBatchTaskCache(adTask);\n+        taskCache.getCacheMemorySize().set(neededCacheSize);\n+        taskCaches.put(taskId, taskCache);\n+    }\n+\n+    /**\n+     * check if current running batch task on current node exceeds\n+     * max running task limitation.\n+     */\n+    public void checkRunningTaskLimit() {\n+        if (size() >= maxAdBatchTaskPerNode) {\n+            String error = \"Can't run more than \" + maxAdBatchTaskPerNode + \" historical detectors per data node\";\n+            throw new LimitExceededException(error);\n+        }\n+    }\n+\n+    /**\n+     * Get task RCF model.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return RCF model\n+     */\n+    public RandomCutForest getRcfModel(String taskId) {\n+        return getBatchTaskCache(taskId).getRcfModel();\n+    }\n+\n+    /**\n+     * Get task threshold model.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return threshold model\n+     */\n+    public ThresholdingModel getThresholdModel(String taskId) {\n+        return getBatchTaskCache(taskId).getThresholdModel();\n+    }\n+\n+    /**\n+     * Get threshold model training data.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return threshold model training data\n+     */\n+    public List<Double> getThresholdModelTrainingData(String taskId) {\n+        return getBatchTaskCache(taskId).getThresholdModelTrainingData();\n+    }\n+\n+    /**\n+     * Threshold model trained or not.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return true if threshold model trained; otherwise, return false\n+     */\n+    public boolean isThresholdModelTrained(String taskId) {\n+        return getBatchTaskCache(taskId).isThresholdModelTrained();\n+    }\n+\n+    /**\n+     * Set threshold model trained or not.\n+     *\n+     * @param taskId task id\n+     * @param trained threshold model trained or not\n+     */\n+    public void setThresholdModelTrained(String taskId, boolean trained) {\n+        ADBatchTaskCache taskCache = getBatchTaskCache(taskId);\n+        taskCache.setThresholdModelTrained(trained);\n+        if (trained) {\n+            int size = taskCache.getThresholdModelTrainingData().size();\n+            long cacheSize = trainingDataMemorySize(size);\n+            taskCache.getThresholdModelTrainingData().clear();\n+            taskCache.getCacheMemorySize().getAndAdd(-cacheSize);\n+            memoryTracker.releaseMemory(cacheSize, false, HISTORICAL_SINGLE_ENTITY_DETECTOR);\n+        }\n+    }\n+\n+    /**\n+     * Get shingle data.\n+     *\n+     * @param taskId AD task id\n+     * @return shingle data\n+     */\n+    public Deque<Map.Entry<Long, Optional<double[]>>> getShingle(String taskId) {\n+        return getBatchTaskCache(taskId).getShingle();\n+    }\n+\n+    /**\n+     * Check if task exists in cache.\n+     *\n+     * @param taskId task id\n+     * @return true if task exists in cache; otherwise, return false.\n+     */\n+    public boolean contains(String taskId) {\n+        return taskCaches.containsKey(taskId);\n+    }\n+\n+    /**\n+     * Check if there is task in cache for detector.\n+     *\n+     * @param detectorId detector id\n+     * @return true if there is task in cache; otherwise return false\n+     */\n+    public boolean containsTaskOfDetector(String detectorId) {\n+        return taskCaches.values().stream().filter(v -> Objects.equals(detectorId, v.getDetectorId())).findAny().isPresent();\n+    }\n+\n+    /**\n+     * Get batch task cache. If task doesn't exist in cache, will throw\n+     * {@link java.lang.IllegalArgumentException}\n+     *\n+     * @param taskId task id\n+     * @return AD batch task cache\n+     */\n+    private ADBatchTaskCache getBatchTaskCache(String taskId) {\n+        if (!contains(taskId)) {\n+            throw new IllegalArgumentException(\"AD task not in cache\");\n+        }\n+        return taskCaches.get(taskId);\n+    }\n+\n+    /**\n+     * Calculate AD task cache memory usage.\n+     *\n+     * @param adTask AD task\n+     * @return how many bytes will consume\n+     */\n+    private long calculateADTaskCacheSize(ADTask adTask) {\n+        return memoryTracker.estimateModelSize(adTask.getDetector(), NUM_TREES) + trainingDataMemorySize(THRESHOLD_MODEL_TRAINING_SIZE)\n+            + shingleMemorySize(adTask.getDetector().getShingleSize());\n+    }\n+\n+    /**\n+     * Remove task from cache.\n+     *\n+     * @param taskId AD task id\n+     */\n+    public void remove(String taskId) {\n+        if (contains(taskId)) {\n+            memoryTracker.releaseMemory(getBatchTaskCache(taskId).getCacheMemorySize().get(), false, HISTORICAL_SINGLE_ENTITY_DETECTOR);\n+            taskCaches.remove(taskId);\n+        }\n+    }\n+\n+    /**\n+     * Cancel AD task.\n+     *\n+     * @param taskId AD task id\n+     * @param reason why need to cancel task\n+     * @param userName user name\n+     */\n+    public void cancel(String taskId, String reason, String userName) {\n+        getBatchTaskCache(taskId).cancel(reason, userName);\n+    }\n+\n+    /**\n+     * Task is cancelled or not.\n+     *\n+     * @param taskId AD task id\n+     * @return true if task is cancelled; otherwise return false\n+     */\n+    public boolean isCancelled(String taskId) {\n+        ADBatchTaskCache taskCache = getBatchTaskCache(taskId);\n+        return taskCache.isCancelled();\n+    }\n+\n+    /**\n+     * Get why task cancelled.\n+     *\n+     * @param taskId AD task id\n+     * @return task cancellation reason\n+     */\n+    public String getCancelReason(String taskId) {\n+        return getBatchTaskCache(taskId).getCancelReason();\n+    }\n+\n+    /**\n+     * Get task cancelled by which user.\n+     *\n+     * @param taskId AD task id\n+     * @return user name\n+     */\n+    public String getCancelledBy(String taskId) {\n+        return getBatchTaskCache(taskId).getCancelledBy();\n+    }\n+\n+    /**\n+     * Get current task count in cache.\n+     *\n+     * @return task count\n+     */\n+    public int size() {\n+        return taskCaches.size();\n+    }\n+\n+    /**\n+     * Clear all tasks.\n+     */\n+    public void clear() {\n+        taskCaches.clear();\n+    }\n+\n+    /**\n+     * Estimate max memory usage of model training data.\n+     * The training data is double and will cache in {@link java.util.ArrayList}.\n+     * Check {@link ADBatchTaskCache#getThresholdModelTrainingData()}\n+     *\n+     * @param size training data point count\n+     * @return how many bytes will consume\n+     */\n+    public long trainingDataMemorySize(int size) {\n+        return 24 * size;\n+    }\n+\n+    /**\n+     * Estimate max memory usage of shingle data.\n+     * Based on the test, one shingle data point consumes about 96 bytes.\n+     * The shingle data is stored in {@link java.util.Deque}\n+     * Check {@link ADBatchTaskCache#getShingle()}\n+     *\n+     * @param shingleSize shingle data point count\n+     * @return how many bytes will consume\n+     */\n+    public long shingleMemorySize(int shingleSize) {\n+        return 96 * shingleSize;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1bf147c0d9ce73b519bcca5a973c72db87f97707"}, "originalPosition": 303}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjkxMTU0OA==", "bodyText": "You don't consider threshold model size, right?", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/337#discussion_r546911548", "createdAt": "2020-12-21T20:20:25Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/task/ADTaskCacheManager.java", "diffHunk": "@@ -0,0 +1,306 @@\n+/*\n+ * Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.task;\n+\n+import static com.amazon.opendistroforelasticsearch.ad.MemoryTracker.Origin.HISTORICAL_SINGLE_ENTITY_DETECTOR;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.MAX_BATCH_TASK_PER_NODE;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.NUM_TREES;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.THRESHOLD_MODEL_TRAINING_SIZE;\n+\n+import java.util.Deque;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.settings.Settings;\n+\n+import com.amazon.opendistroforelasticsearch.ad.MemoryTracker;\n+import com.amazon.opendistroforelasticsearch.ad.common.exception.LimitExceededException;\n+import com.amazon.opendistroforelasticsearch.ad.ml.ThresholdingModel;\n+import com.amazon.opendistroforelasticsearch.ad.model.ADTask;\n+import com.amazon.randomcutforest.RandomCutForest;\n+\n+public class ADTaskCacheManager {\n+\n+    private final Map<String, ADBatchTaskCache> taskCaches;\n+    private volatile Integer maxAdBatchTaskPerNode;\n+    private final MemoryTracker memoryTracker;\n+\n+    /**\n+     * Constructor to create AD task cache manager.\n+     *\n+     * @param settings ES settings\n+     * @param clusterService ES cluster service\n+     * @param memoryTracker AD memory tracker\n+     */\n+    public ADTaskCacheManager(Settings settings, ClusterService clusterService, MemoryTracker memoryTracker) {\n+        this.maxAdBatchTaskPerNode = MAX_BATCH_TASK_PER_NODE.get(settings);\n+        clusterService.getClusterSettings().addSettingsUpdateConsumer(MAX_BATCH_TASK_PER_NODE, it -> maxAdBatchTaskPerNode = it);\n+        taskCaches = new ConcurrentHashMap<>();\n+        this.memoryTracker = memoryTracker;\n+    }\n+\n+    /**\n+     * Put AD task into cache.\n+     *\n+     * @param adTask AD task\n+     */\n+    public synchronized void put(ADTask adTask) {\n+        String taskId = adTask.getTaskId();\n+        if (contains(taskId)) {\n+            throw new IllegalArgumentException(\"AD task is already running\");\n+        }\n+        if (containsTaskOfDetector(adTask.getDetectorId())) {\n+            throw new IllegalArgumentException(\"There is one task executing for detector\");\n+        }\n+        checkRunningTaskLimit();\n+        long neededCacheSize = calculateADTaskCacheSize(adTask);\n+        if (!memoryTracker.canAllocate(neededCacheSize)) {\n+            throw new LimitExceededException(\"No enough memory to run detector\");\n+        }\n+        memoryTracker.consumeMemory(neededCacheSize, false, HISTORICAL_SINGLE_ENTITY_DETECTOR);\n+        ADBatchTaskCache taskCache = new ADBatchTaskCache(adTask);\n+        taskCache.getCacheMemorySize().set(neededCacheSize);\n+        taskCaches.put(taskId, taskCache);\n+    }\n+\n+    /**\n+     * check if current running batch task on current node exceeds\n+     * max running task limitation.\n+     */\n+    public void checkRunningTaskLimit() {\n+        if (size() >= maxAdBatchTaskPerNode) {\n+            String error = \"Can't run more than \" + maxAdBatchTaskPerNode + \" historical detectors per data node\";\n+            throw new LimitExceededException(error);\n+        }\n+    }\n+\n+    /**\n+     * Get task RCF model.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return RCF model\n+     */\n+    public RandomCutForest getRcfModel(String taskId) {\n+        return getBatchTaskCache(taskId).getRcfModel();\n+    }\n+\n+    /**\n+     * Get task threshold model.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return threshold model\n+     */\n+    public ThresholdingModel getThresholdModel(String taskId) {\n+        return getBatchTaskCache(taskId).getThresholdModel();\n+    }\n+\n+    /**\n+     * Get threshold model training data.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return threshold model training data\n+     */\n+    public List<Double> getThresholdModelTrainingData(String taskId) {\n+        return getBatchTaskCache(taskId).getThresholdModelTrainingData();\n+    }\n+\n+    /**\n+     * Threshold model trained or not.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return true if threshold model trained; otherwise, return false\n+     */\n+    public boolean isThresholdModelTrained(String taskId) {\n+        return getBatchTaskCache(taskId).isThresholdModelTrained();\n+    }\n+\n+    /**\n+     * Set threshold model trained or not.\n+     *\n+     * @param taskId task id\n+     * @param trained threshold model trained or not\n+     */\n+    public void setThresholdModelTrained(String taskId, boolean trained) {\n+        ADBatchTaskCache taskCache = getBatchTaskCache(taskId);\n+        taskCache.setThresholdModelTrained(trained);\n+        if (trained) {\n+            int size = taskCache.getThresholdModelTrainingData().size();\n+            long cacheSize = trainingDataMemorySize(size);\n+            taskCache.getThresholdModelTrainingData().clear();\n+            taskCache.getCacheMemorySize().getAndAdd(-cacheSize);\n+            memoryTracker.releaseMemory(cacheSize, false, HISTORICAL_SINGLE_ENTITY_DETECTOR);\n+        }\n+    }\n+\n+    /**\n+     * Get shingle data.\n+     *\n+     * @param taskId AD task id\n+     * @return shingle data\n+     */\n+    public Deque<Map.Entry<Long, Optional<double[]>>> getShingle(String taskId) {\n+        return getBatchTaskCache(taskId).getShingle();\n+    }\n+\n+    /**\n+     * Check if task exists in cache.\n+     *\n+     * @param taskId task id\n+     * @return true if task exists in cache; otherwise, return false.\n+     */\n+    public boolean contains(String taskId) {\n+        return taskCaches.containsKey(taskId);\n+    }\n+\n+    /**\n+     * Check if there is task in cache for detector.\n+     *\n+     * @param detectorId detector id\n+     * @return true if there is task in cache; otherwise return false\n+     */\n+    public boolean containsTaskOfDetector(String detectorId) {\n+        return taskCaches.values().stream().filter(v -> Objects.equals(detectorId, v.getDetectorId())).findAny().isPresent();\n+    }\n+\n+    /**\n+     * Get batch task cache. If task doesn't exist in cache, will throw\n+     * {@link java.lang.IllegalArgumentException}\n+     *\n+     * @param taskId task id\n+     * @return AD batch task cache\n+     */\n+    private ADBatchTaskCache getBatchTaskCache(String taskId) {\n+        if (!contains(taskId)) {\n+            throw new IllegalArgumentException(\"AD task not in cache\");\n+        }\n+        return taskCaches.get(taskId);\n+    }\n+\n+    /**\n+     * Calculate AD task cache memory usage.\n+     *\n+     * @param adTask AD task\n+     * @return how many bytes will consume\n+     */\n+    private long calculateADTaskCacheSize(ADTask adTask) {\n+        return memoryTracker.estimateModelSize(adTask.getDetector(), NUM_TREES) + trainingDataMemorySize(THRESHOLD_MODEL_TRAINING_SIZE)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1bf147c0d9ce73b519bcca5a973c72db87f97707"}, "originalPosition": 207}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjkxNTIxMg==", "bodyText": "When are you gonna release the cache memory?  Also, you need to use canAllocateReserved(..) since canAllocate will consider shared cache memory, which can be always full.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/337#discussion_r546915212", "createdAt": "2020-12-21T20:29:40Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/task/ADTaskCacheManager.java", "diffHunk": "@@ -0,0 +1,306 @@\n+/*\n+ * Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.task;\n+\n+import static com.amazon.opendistroforelasticsearch.ad.MemoryTracker.Origin.HISTORICAL_SINGLE_ENTITY_DETECTOR;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.MAX_BATCH_TASK_PER_NODE;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.NUM_TREES;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.THRESHOLD_MODEL_TRAINING_SIZE;\n+\n+import java.util.Deque;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.settings.Settings;\n+\n+import com.amazon.opendistroforelasticsearch.ad.MemoryTracker;\n+import com.amazon.opendistroforelasticsearch.ad.common.exception.LimitExceededException;\n+import com.amazon.opendistroforelasticsearch.ad.ml.ThresholdingModel;\n+import com.amazon.opendistroforelasticsearch.ad.model.ADTask;\n+import com.amazon.randomcutforest.RandomCutForest;\n+\n+public class ADTaskCacheManager {\n+\n+    private final Map<String, ADBatchTaskCache> taskCaches;\n+    private volatile Integer maxAdBatchTaskPerNode;\n+    private final MemoryTracker memoryTracker;\n+\n+    /**\n+     * Constructor to create AD task cache manager.\n+     *\n+     * @param settings ES settings\n+     * @param clusterService ES cluster service\n+     * @param memoryTracker AD memory tracker\n+     */\n+    public ADTaskCacheManager(Settings settings, ClusterService clusterService, MemoryTracker memoryTracker) {\n+        this.maxAdBatchTaskPerNode = MAX_BATCH_TASK_PER_NODE.get(settings);\n+        clusterService.getClusterSettings().addSettingsUpdateConsumer(MAX_BATCH_TASK_PER_NODE, it -> maxAdBatchTaskPerNode = it);\n+        taskCaches = new ConcurrentHashMap<>();\n+        this.memoryTracker = memoryTracker;\n+    }\n+\n+    /**\n+     * Put AD task into cache.\n+     *\n+     * @param adTask AD task\n+     */\n+    public synchronized void put(ADTask adTask) {\n+        String taskId = adTask.getTaskId();\n+        if (contains(taskId)) {\n+            throw new IllegalArgumentException(\"AD task is already running\");\n+        }\n+        if (containsTaskOfDetector(adTask.getDetectorId())) {\n+            throw new IllegalArgumentException(\"There is one task executing for detector\");\n+        }\n+        checkRunningTaskLimit();\n+        long neededCacheSize = calculateADTaskCacheSize(adTask);\n+        if (!memoryTracker.canAllocate(neededCacheSize)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1bf147c0d9ce73b519bcca5a973c72db87f97707"}, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjkxNTY5MA==", "bodyText": "This should be be memoryTracker.consumeMemory(memoryToConsume, true, HISTORICAL_SINGLE_ENTITY_DETECTOR)", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/337#discussion_r546915690", "createdAt": "2020-12-21T20:30:57Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/task/ADTaskCacheManager.java", "diffHunk": "@@ -0,0 +1,306 @@\n+/*\n+ * Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.task;\n+\n+import static com.amazon.opendistroforelasticsearch.ad.MemoryTracker.Origin.HISTORICAL_SINGLE_ENTITY_DETECTOR;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.MAX_BATCH_TASK_PER_NODE;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.NUM_TREES;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.THRESHOLD_MODEL_TRAINING_SIZE;\n+\n+import java.util.Deque;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.settings.Settings;\n+\n+import com.amazon.opendistroforelasticsearch.ad.MemoryTracker;\n+import com.amazon.opendistroforelasticsearch.ad.common.exception.LimitExceededException;\n+import com.amazon.opendistroforelasticsearch.ad.ml.ThresholdingModel;\n+import com.amazon.opendistroforelasticsearch.ad.model.ADTask;\n+import com.amazon.randomcutforest.RandomCutForest;\n+\n+public class ADTaskCacheManager {\n+\n+    private final Map<String, ADBatchTaskCache> taskCaches;\n+    private volatile Integer maxAdBatchTaskPerNode;\n+    private final MemoryTracker memoryTracker;\n+\n+    /**\n+     * Constructor to create AD task cache manager.\n+     *\n+     * @param settings ES settings\n+     * @param clusterService ES cluster service\n+     * @param memoryTracker AD memory tracker\n+     */\n+    public ADTaskCacheManager(Settings settings, ClusterService clusterService, MemoryTracker memoryTracker) {\n+        this.maxAdBatchTaskPerNode = MAX_BATCH_TASK_PER_NODE.get(settings);\n+        clusterService.getClusterSettings().addSettingsUpdateConsumer(MAX_BATCH_TASK_PER_NODE, it -> maxAdBatchTaskPerNode = it);\n+        taskCaches = new ConcurrentHashMap<>();\n+        this.memoryTracker = memoryTracker;\n+    }\n+\n+    /**\n+     * Put AD task into cache.\n+     *\n+     * @param adTask AD task\n+     */\n+    public synchronized void put(ADTask adTask) {\n+        String taskId = adTask.getTaskId();\n+        if (contains(taskId)) {\n+            throw new IllegalArgumentException(\"AD task is already running\");\n+        }\n+        if (containsTaskOfDetector(adTask.getDetectorId())) {\n+            throw new IllegalArgumentException(\"There is one task executing for detector\");\n+        }\n+        checkRunningTaskLimit();\n+        long neededCacheSize = calculateADTaskCacheSize(adTask);\n+        if (!memoryTracker.canAllocate(neededCacheSize)) {\n+            throw new LimitExceededException(\"No enough memory to run detector\");\n+        }\n+        memoryTracker.consumeMemory(neededCacheSize, false, HISTORICAL_SINGLE_ENTITY_DETECTOR);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1bf147c0d9ce73b519bcca5a973c72db87f97707"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjkxNjEwOA==", "bodyText": "2nd parameter should be true.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/337#discussion_r546916108", "createdAt": "2020-12-21T20:32:09Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/task/ADTaskCacheManager.java", "diffHunk": "@@ -0,0 +1,306 @@\n+/*\n+ * Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.task;\n+\n+import static com.amazon.opendistroforelasticsearch.ad.MemoryTracker.Origin.HISTORICAL_SINGLE_ENTITY_DETECTOR;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.MAX_BATCH_TASK_PER_NODE;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.NUM_TREES;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.THRESHOLD_MODEL_TRAINING_SIZE;\n+\n+import java.util.Deque;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.settings.Settings;\n+\n+import com.amazon.opendistroforelasticsearch.ad.MemoryTracker;\n+import com.amazon.opendistroforelasticsearch.ad.common.exception.LimitExceededException;\n+import com.amazon.opendistroforelasticsearch.ad.ml.ThresholdingModel;\n+import com.amazon.opendistroforelasticsearch.ad.model.ADTask;\n+import com.amazon.randomcutforest.RandomCutForest;\n+\n+public class ADTaskCacheManager {\n+\n+    private final Map<String, ADBatchTaskCache> taskCaches;\n+    private volatile Integer maxAdBatchTaskPerNode;\n+    private final MemoryTracker memoryTracker;\n+\n+    /**\n+     * Constructor to create AD task cache manager.\n+     *\n+     * @param settings ES settings\n+     * @param clusterService ES cluster service\n+     * @param memoryTracker AD memory tracker\n+     */\n+    public ADTaskCacheManager(Settings settings, ClusterService clusterService, MemoryTracker memoryTracker) {\n+        this.maxAdBatchTaskPerNode = MAX_BATCH_TASK_PER_NODE.get(settings);\n+        clusterService.getClusterSettings().addSettingsUpdateConsumer(MAX_BATCH_TASK_PER_NODE, it -> maxAdBatchTaskPerNode = it);\n+        taskCaches = new ConcurrentHashMap<>();\n+        this.memoryTracker = memoryTracker;\n+    }\n+\n+    /**\n+     * Put AD task into cache.\n+     *\n+     * @param adTask AD task\n+     */\n+    public synchronized void put(ADTask adTask) {\n+        String taskId = adTask.getTaskId();\n+        if (contains(taskId)) {\n+            throw new IllegalArgumentException(\"AD task is already running\");\n+        }\n+        if (containsTaskOfDetector(adTask.getDetectorId())) {\n+            throw new IllegalArgumentException(\"There is one task executing for detector\");\n+        }\n+        checkRunningTaskLimit();\n+        long neededCacheSize = calculateADTaskCacheSize(adTask);\n+        if (!memoryTracker.canAllocate(neededCacheSize)) {\n+            throw new LimitExceededException(\"No enough memory to run detector\");\n+        }\n+        memoryTracker.consumeMemory(neededCacheSize, false, HISTORICAL_SINGLE_ENTITY_DETECTOR);\n+        ADBatchTaskCache taskCache = new ADBatchTaskCache(adTask);\n+        taskCache.getCacheMemorySize().set(neededCacheSize);\n+        taskCaches.put(taskId, taskCache);\n+    }\n+\n+    /**\n+     * check if current running batch task on current node exceeds\n+     * max running task limitation.\n+     */\n+    public void checkRunningTaskLimit() {\n+        if (size() >= maxAdBatchTaskPerNode) {\n+            String error = \"Can't run more than \" + maxAdBatchTaskPerNode + \" historical detectors per data node\";\n+            throw new LimitExceededException(error);\n+        }\n+    }\n+\n+    /**\n+     * Get task RCF model.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return RCF model\n+     */\n+    public RandomCutForest getRcfModel(String taskId) {\n+        return getBatchTaskCache(taskId).getRcfModel();\n+    }\n+\n+    /**\n+     * Get task threshold model.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return threshold model\n+     */\n+    public ThresholdingModel getThresholdModel(String taskId) {\n+        return getBatchTaskCache(taskId).getThresholdModel();\n+    }\n+\n+    /**\n+     * Get threshold model training data.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return threshold model training data\n+     */\n+    public List<Double> getThresholdModelTrainingData(String taskId) {\n+        return getBatchTaskCache(taskId).getThresholdModelTrainingData();\n+    }\n+\n+    /**\n+     * Threshold model trained or not.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return true if threshold model trained; otherwise, return false\n+     */\n+    public boolean isThresholdModelTrained(String taskId) {\n+        return getBatchTaskCache(taskId).isThresholdModelTrained();\n+    }\n+\n+    /**\n+     * Set threshold model trained or not.\n+     *\n+     * @param taskId task id\n+     * @param trained threshold model trained or not\n+     */\n+    public void setThresholdModelTrained(String taskId, boolean trained) {\n+        ADBatchTaskCache taskCache = getBatchTaskCache(taskId);\n+        taskCache.setThresholdModelTrained(trained);\n+        if (trained) {\n+            int size = taskCache.getThresholdModelTrainingData().size();\n+            long cacheSize = trainingDataMemorySize(size);\n+            taskCache.getThresholdModelTrainingData().clear();\n+            taskCache.getCacheMemorySize().getAndAdd(-cacheSize);\n+            memoryTracker.releaseMemory(cacheSize, false, HISTORICAL_SINGLE_ENTITY_DETECTOR);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1bf147c0d9ce73b519bcca5a973c72db87f97707"}, "originalPosition": 152}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjkxNjY4MQ==", "bodyText": "This method assumes not no threads calling this method with the same taskId, right? Can we assume that?", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/337#discussion_r546916681", "createdAt": "2020-12-21T20:33:36Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/task/ADTaskCacheManager.java", "diffHunk": "@@ -0,0 +1,306 @@\n+/*\n+ * Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.task;\n+\n+import static com.amazon.opendistroforelasticsearch.ad.MemoryTracker.Origin.HISTORICAL_SINGLE_ENTITY_DETECTOR;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.MAX_BATCH_TASK_PER_NODE;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.NUM_TREES;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.THRESHOLD_MODEL_TRAINING_SIZE;\n+\n+import java.util.Deque;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.settings.Settings;\n+\n+import com.amazon.opendistroforelasticsearch.ad.MemoryTracker;\n+import com.amazon.opendistroforelasticsearch.ad.common.exception.LimitExceededException;\n+import com.amazon.opendistroforelasticsearch.ad.ml.ThresholdingModel;\n+import com.amazon.opendistroforelasticsearch.ad.model.ADTask;\n+import com.amazon.randomcutforest.RandomCutForest;\n+\n+public class ADTaskCacheManager {\n+\n+    private final Map<String, ADBatchTaskCache> taskCaches;\n+    private volatile Integer maxAdBatchTaskPerNode;\n+    private final MemoryTracker memoryTracker;\n+\n+    /**\n+     * Constructor to create AD task cache manager.\n+     *\n+     * @param settings ES settings\n+     * @param clusterService ES cluster service\n+     * @param memoryTracker AD memory tracker\n+     */\n+    public ADTaskCacheManager(Settings settings, ClusterService clusterService, MemoryTracker memoryTracker) {\n+        this.maxAdBatchTaskPerNode = MAX_BATCH_TASK_PER_NODE.get(settings);\n+        clusterService.getClusterSettings().addSettingsUpdateConsumer(MAX_BATCH_TASK_PER_NODE, it -> maxAdBatchTaskPerNode = it);\n+        taskCaches = new ConcurrentHashMap<>();\n+        this.memoryTracker = memoryTracker;\n+    }\n+\n+    /**\n+     * Put AD task into cache.\n+     *\n+     * @param adTask AD task\n+     */\n+    public synchronized void put(ADTask adTask) {\n+        String taskId = adTask.getTaskId();\n+        if (contains(taskId)) {\n+            throw new IllegalArgumentException(\"AD task is already running\");\n+        }\n+        if (containsTaskOfDetector(adTask.getDetectorId())) {\n+            throw new IllegalArgumentException(\"There is one task executing for detector\");\n+        }\n+        checkRunningTaskLimit();\n+        long neededCacheSize = calculateADTaskCacheSize(adTask);\n+        if (!memoryTracker.canAllocate(neededCacheSize)) {\n+            throw new LimitExceededException(\"No enough memory to run detector\");\n+        }\n+        memoryTracker.consumeMemory(neededCacheSize, false, HISTORICAL_SINGLE_ENTITY_DETECTOR);\n+        ADBatchTaskCache taskCache = new ADBatchTaskCache(adTask);\n+        taskCache.getCacheMemorySize().set(neededCacheSize);\n+        taskCaches.put(taskId, taskCache);\n+    }\n+\n+    /**\n+     * check if current running batch task on current node exceeds\n+     * max running task limitation.\n+     */\n+    public void checkRunningTaskLimit() {\n+        if (size() >= maxAdBatchTaskPerNode) {\n+            String error = \"Can't run more than \" + maxAdBatchTaskPerNode + \" historical detectors per data node\";\n+            throw new LimitExceededException(error);\n+        }\n+    }\n+\n+    /**\n+     * Get task RCF model.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return RCF model\n+     */\n+    public RandomCutForest getRcfModel(String taskId) {\n+        return getBatchTaskCache(taskId).getRcfModel();\n+    }\n+\n+    /**\n+     * Get task threshold model.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return threshold model\n+     */\n+    public ThresholdingModel getThresholdModel(String taskId) {\n+        return getBatchTaskCache(taskId).getThresholdModel();\n+    }\n+\n+    /**\n+     * Get threshold model training data.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return threshold model training data\n+     */\n+    public List<Double> getThresholdModelTrainingData(String taskId) {\n+        return getBatchTaskCache(taskId).getThresholdModelTrainingData();\n+    }\n+\n+    /**\n+     * Threshold model trained or not.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return true if threshold model trained; otherwise, return false\n+     */\n+    public boolean isThresholdModelTrained(String taskId) {\n+        return getBatchTaskCache(taskId).isThresholdModelTrained();\n+    }\n+\n+    /**\n+     * Set threshold model trained or not.\n+     *\n+     * @param taskId task id\n+     * @param trained threshold model trained or not\n+     */\n+    public void setThresholdModelTrained(String taskId, boolean trained) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1bf147c0d9ce73b519bcca5a973c72db87f97707"}, "originalPosition": 144}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjkzNDYyNA==", "bodyText": "This class is a combination of 4 functions:\n\ndata structure for models.  You can modify EntityModel to cover that.  Current EntityModel does not support shingle.  Once it supports that, it will need your Deque<Map.Entry<Long, Optional<double[]>>> shingle.\nfunctions to create empty models.  We create models during training.  Do we really need to create the empty one here?  It sounds strange that a cache is responsible for training or creating models. Can we let the caller pass in the trained objects in?\ncancel/invalidate the cache.\ntrack cache size\n\nI am thinking whether we can define the class as:\nclass ADBatchTaskCache {\nprivate EntityModel ...\nprivate String cancelReason;\nprivate AtomicLong cacheMemorySize = new AtomicLong(0);\n...\npublic ADBatchTaskCache(EntityModel..) {..}", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/337#discussion_r546934624", "createdAt": "2020-12-21T21:19:31Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/task/ADBatchTaskCache.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.task;\n+\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.NUM_MIN_SAMPLES;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.NUM_SAMPLES_PER_TREE;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.NUM_TREES;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.THRESHOLD_MODEL_TRAINING_SIZE;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.TIME_DECAY;\n+\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.Deque;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.concurrent.atomic.AtomicLong;\n+\n+import com.amazon.opendistroforelasticsearch.ad.ml.HybridThresholdingModel;\n+import com.amazon.opendistroforelasticsearch.ad.ml.ThresholdingModel;\n+import com.amazon.opendistroforelasticsearch.ad.model.ADTask;\n+import com.amazon.opendistroforelasticsearch.ad.model.AnomalyDetector;\n+import com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings;\n+import com.amazon.randomcutforest.RandomCutForest;\n+\n+/**\n+ * AD batch task cache which will hold RCF, threshold model, shingle and training data.\n+ */\n+public class ADBatchTaskCache {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1bf147c0d9ce73b519bcca5a973c72db87f97707"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjkzOTAxNw==", "bodyText": "runtime exception means sth you cannot recover.  Is getting something not existing not recoverable? Is it better to return an optional.empty when it is not there.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/337#discussion_r546939017", "createdAt": "2020-12-21T21:30:56Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/task/ADTaskCacheManager.java", "diffHunk": "@@ -0,0 +1,306 @@\n+/*\n+ * Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.task;\n+\n+import static com.amazon.opendistroforelasticsearch.ad.MemoryTracker.Origin.HISTORICAL_SINGLE_ENTITY_DETECTOR;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.MAX_BATCH_TASK_PER_NODE;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.NUM_TREES;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.THRESHOLD_MODEL_TRAINING_SIZE;\n+\n+import java.util.Deque;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.settings.Settings;\n+\n+import com.amazon.opendistroforelasticsearch.ad.MemoryTracker;\n+import com.amazon.opendistroforelasticsearch.ad.common.exception.LimitExceededException;\n+import com.amazon.opendistroforelasticsearch.ad.ml.ThresholdingModel;\n+import com.amazon.opendistroforelasticsearch.ad.model.ADTask;\n+import com.amazon.randomcutforest.RandomCutForest;\n+\n+public class ADTaskCacheManager {\n+\n+    private final Map<String, ADBatchTaskCache> taskCaches;\n+    private volatile Integer maxAdBatchTaskPerNode;\n+    private final MemoryTracker memoryTracker;\n+\n+    /**\n+     * Constructor to create AD task cache manager.\n+     *\n+     * @param settings ES settings\n+     * @param clusterService ES cluster service\n+     * @param memoryTracker AD memory tracker\n+     */\n+    public ADTaskCacheManager(Settings settings, ClusterService clusterService, MemoryTracker memoryTracker) {\n+        this.maxAdBatchTaskPerNode = MAX_BATCH_TASK_PER_NODE.get(settings);\n+        clusterService.getClusterSettings().addSettingsUpdateConsumer(MAX_BATCH_TASK_PER_NODE, it -> maxAdBatchTaskPerNode = it);\n+        taskCaches = new ConcurrentHashMap<>();\n+        this.memoryTracker = memoryTracker;\n+    }\n+\n+    /**\n+     * Put AD task into cache.\n+     *\n+     * @param adTask AD task\n+     */\n+    public synchronized void put(ADTask adTask) {\n+        String taskId = adTask.getTaskId();\n+        if (contains(taskId)) {\n+            throw new IllegalArgumentException(\"AD task is already running\");\n+        }\n+        if (containsTaskOfDetector(adTask.getDetectorId())) {\n+            throw new IllegalArgumentException(\"There is one task executing for detector\");\n+        }\n+        checkRunningTaskLimit();\n+        long neededCacheSize = calculateADTaskCacheSize(adTask);\n+        if (!memoryTracker.canAllocate(neededCacheSize)) {\n+            throw new LimitExceededException(\"No enough memory to run detector\");\n+        }\n+        memoryTracker.consumeMemory(neededCacheSize, false, HISTORICAL_SINGLE_ENTITY_DETECTOR);\n+        ADBatchTaskCache taskCache = new ADBatchTaskCache(adTask);\n+        taskCache.getCacheMemorySize().set(neededCacheSize);\n+        taskCaches.put(taskId, taskCache);\n+    }\n+\n+    /**\n+     * check if current running batch task on current node exceeds\n+     * max running task limitation.\n+     */\n+    public void checkRunningTaskLimit() {\n+        if (size() >= maxAdBatchTaskPerNode) {\n+            String error = \"Can't run more than \" + maxAdBatchTaskPerNode + \" historical detectors per data node\";\n+            throw new LimitExceededException(error);\n+        }\n+    }\n+\n+    /**\n+     * Get task RCF model.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return RCF model\n+     */\n+    public RandomCutForest getRcfModel(String taskId) {\n+        return getBatchTaskCache(taskId).getRcfModel();\n+    }\n+\n+    /**\n+     * Get task threshold model.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return threshold model\n+     */\n+    public ThresholdingModel getThresholdModel(String taskId) {\n+        return getBatchTaskCache(taskId).getThresholdModel();\n+    }\n+\n+    /**\n+     * Get threshold model training data.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return threshold model training data\n+     */\n+    public List<Double> getThresholdModelTrainingData(String taskId) {\n+        return getBatchTaskCache(taskId).getThresholdModelTrainingData();\n+    }\n+\n+    /**\n+     * Threshold model trained or not.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return true if threshold model trained; otherwise, return false\n+     */\n+    public boolean isThresholdModelTrained(String taskId) {\n+        return getBatchTaskCache(taskId).isThresholdModelTrained();\n+    }\n+\n+    /**\n+     * Set threshold model trained or not.\n+     *\n+     * @param taskId task id\n+     * @param trained threshold model trained or not\n+     */\n+    public void setThresholdModelTrained(String taskId, boolean trained) {\n+        ADBatchTaskCache taskCache = getBatchTaskCache(taskId);\n+        taskCache.setThresholdModelTrained(trained);\n+        if (trained) {\n+            int size = taskCache.getThresholdModelTrainingData().size();\n+            long cacheSize = trainingDataMemorySize(size);\n+            taskCache.getThresholdModelTrainingData().clear();\n+            taskCache.getCacheMemorySize().getAndAdd(-cacheSize);\n+            memoryTracker.releaseMemory(cacheSize, false, HISTORICAL_SINGLE_ENTITY_DETECTOR);\n+        }\n+    }\n+\n+    /**\n+     * Get shingle data.\n+     *\n+     * @param taskId AD task id\n+     * @return shingle data\n+     */\n+    public Deque<Map.Entry<Long, Optional<double[]>>> getShingle(String taskId) {\n+        return getBatchTaskCache(taskId).getShingle();\n+    }\n+\n+    /**\n+     * Check if task exists in cache.\n+     *\n+     * @param taskId task id\n+     * @return true if task exists in cache; otherwise, return false.\n+     */\n+    public boolean contains(String taskId) {\n+        return taskCaches.containsKey(taskId);\n+    }\n+\n+    /**\n+     * Check if there is task in cache for detector.\n+     *\n+     * @param detectorId detector id\n+     * @return true if there is task in cache; otherwise return false\n+     */\n+    public boolean containsTaskOfDetector(String detectorId) {\n+        return taskCaches.values().stream().filter(v -> Objects.equals(detectorId, v.getDetectorId())).findAny().isPresent();\n+    }\n+\n+    /**\n+     * Get batch task cache. If task doesn't exist in cache, will throw\n+     * {@link java.lang.IllegalArgumentException}\n+     *\n+     * @param taskId task id\n+     * @return AD batch task cache\n+     */\n+    private ADBatchTaskCache getBatchTaskCache(String taskId) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1bf147c0d9ce73b519bcca5a973c72db87f97707"}, "originalPosition": 193}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjkzOTQ5Mg==", "bodyText": "2nd parameter should be true.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/337#discussion_r546939492", "createdAt": "2020-12-21T21:31:56Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/task/ADTaskCacheManager.java", "diffHunk": "@@ -0,0 +1,306 @@\n+/*\n+ * Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.task;\n+\n+import static com.amazon.opendistroforelasticsearch.ad.MemoryTracker.Origin.HISTORICAL_SINGLE_ENTITY_DETECTOR;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.MAX_BATCH_TASK_PER_NODE;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.NUM_TREES;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.THRESHOLD_MODEL_TRAINING_SIZE;\n+\n+import java.util.Deque;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.settings.Settings;\n+\n+import com.amazon.opendistroforelasticsearch.ad.MemoryTracker;\n+import com.amazon.opendistroforelasticsearch.ad.common.exception.LimitExceededException;\n+import com.amazon.opendistroforelasticsearch.ad.ml.ThresholdingModel;\n+import com.amazon.opendistroforelasticsearch.ad.model.ADTask;\n+import com.amazon.randomcutforest.RandomCutForest;\n+\n+public class ADTaskCacheManager {\n+\n+    private final Map<String, ADBatchTaskCache> taskCaches;\n+    private volatile Integer maxAdBatchTaskPerNode;\n+    private final MemoryTracker memoryTracker;\n+\n+    /**\n+     * Constructor to create AD task cache manager.\n+     *\n+     * @param settings ES settings\n+     * @param clusterService ES cluster service\n+     * @param memoryTracker AD memory tracker\n+     */\n+    public ADTaskCacheManager(Settings settings, ClusterService clusterService, MemoryTracker memoryTracker) {\n+        this.maxAdBatchTaskPerNode = MAX_BATCH_TASK_PER_NODE.get(settings);\n+        clusterService.getClusterSettings().addSettingsUpdateConsumer(MAX_BATCH_TASK_PER_NODE, it -> maxAdBatchTaskPerNode = it);\n+        taskCaches = new ConcurrentHashMap<>();\n+        this.memoryTracker = memoryTracker;\n+    }\n+\n+    /**\n+     * Put AD task into cache.\n+     *\n+     * @param adTask AD task\n+     */\n+    public synchronized void put(ADTask adTask) {\n+        String taskId = adTask.getTaskId();\n+        if (contains(taskId)) {\n+            throw new IllegalArgumentException(\"AD task is already running\");\n+        }\n+        if (containsTaskOfDetector(adTask.getDetectorId())) {\n+            throw new IllegalArgumentException(\"There is one task executing for detector\");\n+        }\n+        checkRunningTaskLimit();\n+        long neededCacheSize = calculateADTaskCacheSize(adTask);\n+        if (!memoryTracker.canAllocate(neededCacheSize)) {\n+            throw new LimitExceededException(\"No enough memory to run detector\");\n+        }\n+        memoryTracker.consumeMemory(neededCacheSize, false, HISTORICAL_SINGLE_ENTITY_DETECTOR);\n+        ADBatchTaskCache taskCache = new ADBatchTaskCache(adTask);\n+        taskCache.getCacheMemorySize().set(neededCacheSize);\n+        taskCaches.put(taskId, taskCache);\n+    }\n+\n+    /**\n+     * check if current running batch task on current node exceeds\n+     * max running task limitation.\n+     */\n+    public void checkRunningTaskLimit() {\n+        if (size() >= maxAdBatchTaskPerNode) {\n+            String error = \"Can't run more than \" + maxAdBatchTaskPerNode + \" historical detectors per data node\";\n+            throw new LimitExceededException(error);\n+        }\n+    }\n+\n+    /**\n+     * Get task RCF model.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return RCF model\n+     */\n+    public RandomCutForest getRcfModel(String taskId) {\n+        return getBatchTaskCache(taskId).getRcfModel();\n+    }\n+\n+    /**\n+     * Get task threshold model.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return threshold model\n+     */\n+    public ThresholdingModel getThresholdModel(String taskId) {\n+        return getBatchTaskCache(taskId).getThresholdModel();\n+    }\n+\n+    /**\n+     * Get threshold model training data.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return threshold model training data\n+     */\n+    public List<Double> getThresholdModelTrainingData(String taskId) {\n+        return getBatchTaskCache(taskId).getThresholdModelTrainingData();\n+    }\n+\n+    /**\n+     * Threshold model trained or not.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return true if threshold model trained; otherwise, return false\n+     */\n+    public boolean isThresholdModelTrained(String taskId) {\n+        return getBatchTaskCache(taskId).isThresholdModelTrained();\n+    }\n+\n+    /**\n+     * Set threshold model trained or not.\n+     *\n+     * @param taskId task id\n+     * @param trained threshold model trained or not\n+     */\n+    public void setThresholdModelTrained(String taskId, boolean trained) {\n+        ADBatchTaskCache taskCache = getBatchTaskCache(taskId);\n+        taskCache.setThresholdModelTrained(trained);\n+        if (trained) {\n+            int size = taskCache.getThresholdModelTrainingData().size();\n+            long cacheSize = trainingDataMemorySize(size);\n+            taskCache.getThresholdModelTrainingData().clear();\n+            taskCache.getCacheMemorySize().getAndAdd(-cacheSize);\n+            memoryTracker.releaseMemory(cacheSize, false, HISTORICAL_SINGLE_ENTITY_DETECTOR);\n+        }\n+    }\n+\n+    /**\n+     * Get shingle data.\n+     *\n+     * @param taskId AD task id\n+     * @return shingle data\n+     */\n+    public Deque<Map.Entry<Long, Optional<double[]>>> getShingle(String taskId) {\n+        return getBatchTaskCache(taskId).getShingle();\n+    }\n+\n+    /**\n+     * Check if task exists in cache.\n+     *\n+     * @param taskId task id\n+     * @return true if task exists in cache; otherwise, return false.\n+     */\n+    public boolean contains(String taskId) {\n+        return taskCaches.containsKey(taskId);\n+    }\n+\n+    /**\n+     * Check if there is task in cache for detector.\n+     *\n+     * @param detectorId detector id\n+     * @return true if there is task in cache; otherwise return false\n+     */\n+    public boolean containsTaskOfDetector(String detectorId) {\n+        return taskCaches.values().stream().filter(v -> Objects.equals(detectorId, v.getDetectorId())).findAny().isPresent();\n+    }\n+\n+    /**\n+     * Get batch task cache. If task doesn't exist in cache, will throw\n+     * {@link java.lang.IllegalArgumentException}\n+     *\n+     * @param taskId task id\n+     * @return AD batch task cache\n+     */\n+    private ADBatchTaskCache getBatchTaskCache(String taskId) {\n+        if (!contains(taskId)) {\n+            throw new IllegalArgumentException(\"AD task not in cache\");\n+        }\n+        return taskCaches.get(taskId);\n+    }\n+\n+    /**\n+     * Calculate AD task cache memory usage.\n+     *\n+     * @param adTask AD task\n+     * @return how many bytes will consume\n+     */\n+    private long calculateADTaskCacheSize(ADTask adTask) {\n+        return memoryTracker.estimateModelSize(adTask.getDetector(), NUM_TREES) + trainingDataMemorySize(THRESHOLD_MODEL_TRAINING_SIZE)\n+            + shingleMemorySize(adTask.getDetector().getShingleSize());\n+    }\n+\n+    /**\n+     * Remove task from cache.\n+     *\n+     * @param taskId AD task id\n+     */\n+    public void remove(String taskId) {\n+        if (contains(taskId)) {\n+            memoryTracker.releaseMemory(getBatchTaskCache(taskId).getCacheMemorySize().get(), false, HISTORICAL_SINGLE_ENTITY_DETECTOR);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1bf147c0d9ce73b519bcca5a973c72db87f97707"}, "originalPosition": 218}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "aaced0b3feceec73cc6b0de316ba9c48045a8456", "author": {"user": {"login": "ylwu-amzn", "name": "Yaliang"}}, "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/aaced0b3feceec73cc6b0de316ba9c48045a8456", "committedDate": "2020-12-21T22:06:10Z", "message": "add java doc for exception"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "de29b8a937ef9125bc2c66dad02059b04622822e", "author": {"user": {"login": "ylwu-amzn", "name": "Yaliang"}}, "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/de29b8a937ef9125bc2c66dad02059b04622822e", "committedDate": "2020-12-21T22:23:26Z", "message": "change to reserved memory"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ce0654c8967bd0c9a5f715899b59bb83d05176b6", "author": {"user": {"login": "ylwu-amzn", "name": "Yaliang"}}, "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/ce0654c8967bd0c9a5f715899b59bb83d05176b6", "committedDate": "2020-12-21T22:16:04Z", "message": "change to reserved memory"}, "afterCommit": {"oid": "de29b8a937ef9125bc2c66dad02059b04622822e", "author": {"user": {"login": "ylwu-amzn", "name": "Yaliang"}}, "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/de29b8a937ef9125bc2c66dad02059b04622822e", "committedDate": "2020-12-21T22:23:26Z", "message": "change to reserved memory"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU3MjcxMjQ1", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/337#pullrequestreview-557271245", "createdAt": "2020-12-22T18:13:17Z", "commit": {"oid": "de29b8a937ef9125bc2c66dad02059b04622822e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQxODoxMzoxN1rOIKEORA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQxODoxMzoxN1rOIKEORA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzQyNTg2MA==", "bodyText": "When you cancel a task, should we release memory involved?", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/337#discussion_r547425860", "createdAt": "2020-12-22T18:13:17Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/task/ADTaskCacheManager.java", "diffHunk": "@@ -0,0 +1,311 @@\n+/*\n+ * Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.task;\n+\n+import static com.amazon.opendistroforelasticsearch.ad.MemoryTracker.Origin.HISTORICAL_SINGLE_ENTITY_DETECTOR;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.MAX_BATCH_TASK_PER_NODE;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.NUM_TREES;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.THRESHOLD_MODEL_TRAINING_SIZE;\n+\n+import java.util.Deque;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.settings.Settings;\n+\n+import com.amazon.opendistroforelasticsearch.ad.MemoryTracker;\n+import com.amazon.opendistroforelasticsearch.ad.common.exception.LimitExceededException;\n+import com.amazon.opendistroforelasticsearch.ad.ml.ThresholdingModel;\n+import com.amazon.opendistroforelasticsearch.ad.model.ADTask;\n+import com.amazon.randomcutforest.RandomCutForest;\n+\n+public class ADTaskCacheManager {\n+\n+    private final Map<String, ADBatchTaskCache> taskCaches;\n+    private volatile Integer maxAdBatchTaskPerNode;\n+    private final MemoryTracker memoryTracker;\n+\n+    /**\n+     * Constructor to create AD task cache manager.\n+     *\n+     * @param settings ES settings\n+     * @param clusterService ES cluster service\n+     * @param memoryTracker AD memory tracker\n+     */\n+    public ADTaskCacheManager(Settings settings, ClusterService clusterService, MemoryTracker memoryTracker) {\n+        this.maxAdBatchTaskPerNode = MAX_BATCH_TASK_PER_NODE.get(settings);\n+        clusterService.getClusterSettings().addSettingsUpdateConsumer(MAX_BATCH_TASK_PER_NODE, it -> maxAdBatchTaskPerNode = it);\n+        taskCaches = new ConcurrentHashMap<>();\n+        this.memoryTracker = memoryTracker;\n+    }\n+\n+    /**\n+     * Put AD task into cache.\n+     * If AD task is already in cache, will throw {@link IllegalArgumentException}\n+     * If there is one AD task in cache for detector, will throw {@link IllegalArgumentException}\n+     * If there is no enough memory for this AD task, will throw {@link LimitExceededException}\n+     *\n+     * @param adTask AD task\n+     */\n+    public synchronized void put(ADTask adTask) {\n+        String taskId = adTask.getTaskId();\n+        if (contains(taskId)) {\n+            throw new IllegalArgumentException(\"AD task is already running\");\n+        }\n+        if (containsTaskOfDetector(adTask.getDetectorId())) {\n+            throw new IllegalArgumentException(\"There is one task executing for detector\");\n+        }\n+        checkRunningTaskLimit();\n+        long neededCacheSize = calculateADTaskCacheSize(adTask);\n+        if (!memoryTracker.canAllocate(neededCacheSize)) {\n+            throw new LimitExceededException(\"No enough memory to run detector\");\n+        }\n+        memoryTracker.consumeMemory(neededCacheSize, false, HISTORICAL_SINGLE_ENTITY_DETECTOR);\n+        ADBatchTaskCache taskCache = new ADBatchTaskCache(adTask);\n+        taskCache.getCacheMemorySize().set(neededCacheSize);\n+        taskCaches.put(taskId, taskCache);\n+    }\n+\n+    /**\n+     * check if current running batch task on current node exceeds\n+     * max running task limitation.\n+     * If executing task count exceeds limitation, will throw\n+     * {@link LimitExceededException}\n+     */\n+    public void checkRunningTaskLimit() {\n+        if (size() >= maxAdBatchTaskPerNode) {\n+            String error = \"Can't run more than \" + maxAdBatchTaskPerNode + \" historical detectors per data node\";\n+            throw new LimitExceededException(error);\n+        }\n+    }\n+\n+    /**\n+     * Get task RCF model.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return RCF model\n+     */\n+    public RandomCutForest getRcfModel(String taskId) {\n+        return getBatchTaskCache(taskId).getRcfModel();\n+    }\n+\n+    /**\n+     * Get task threshold model.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return threshold model\n+     */\n+    public ThresholdingModel getThresholdModel(String taskId) {\n+        return getBatchTaskCache(taskId).getThresholdModel();\n+    }\n+\n+    /**\n+     * Get threshold model training data.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return threshold model training data\n+     */\n+    public List<Double> getThresholdModelTrainingData(String taskId) {\n+        return getBatchTaskCache(taskId).getThresholdModelTrainingData();\n+    }\n+\n+    /**\n+     * Threshold model trained or not.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return true if threshold model trained; otherwise, return false\n+     */\n+    public boolean isThresholdModelTrained(String taskId) {\n+        return getBatchTaskCache(taskId).isThresholdModelTrained();\n+    }\n+\n+    /**\n+     * Set threshold model trained or not.\n+     *\n+     * @param taskId task id\n+     * @param trained threshold model trained or not\n+     */\n+    public void setThresholdModelTrained(String taskId, boolean trained) {\n+        ADBatchTaskCache taskCache = getBatchTaskCache(taskId);\n+        taskCache.setThresholdModelTrained(trained);\n+        if (trained) {\n+            int size = taskCache.getThresholdModelTrainingData().size();\n+            long cacheSize = trainingDataMemorySize(size);\n+            taskCache.getThresholdModelTrainingData().clear();\n+            taskCache.getCacheMemorySize().getAndAdd(-cacheSize);\n+            memoryTracker.releaseMemory(cacheSize, true, HISTORICAL_SINGLE_ENTITY_DETECTOR);\n+        }\n+    }\n+\n+    /**\n+     * Get shingle data.\n+     *\n+     * @param taskId AD task id\n+     * @return shingle data\n+     */\n+    public Deque<Map.Entry<Long, Optional<double[]>>> getShingle(String taskId) {\n+        return getBatchTaskCache(taskId).getShingle();\n+    }\n+\n+    /**\n+     * Check if task exists in cache.\n+     *\n+     * @param taskId task id\n+     * @return true if task exists in cache; otherwise, return false.\n+     */\n+    public boolean contains(String taskId) {\n+        return taskCaches.containsKey(taskId);\n+    }\n+\n+    /**\n+     * Check if there is task in cache for detector.\n+     *\n+     * @param detectorId detector id\n+     * @return true if there is task in cache; otherwise return false\n+     */\n+    public boolean containsTaskOfDetector(String detectorId) {\n+        return taskCaches.values().stream().filter(v -> Objects.equals(detectorId, v.getDetectorId())).findAny().isPresent();\n+    }\n+\n+    /**\n+     * Get batch task cache. If task doesn't exist in cache, will throw\n+     * {@link java.lang.IllegalArgumentException}\n+     *\n+     * @param taskId task id\n+     * @return AD batch task cache\n+     */\n+    private ADBatchTaskCache getBatchTaskCache(String taskId) {\n+        if (!contains(taskId)) {\n+            throw new IllegalArgumentException(\"AD task not in cache\");\n+        }\n+        return taskCaches.get(taskId);\n+    }\n+\n+    /**\n+     * Calculate AD task cache memory usage.\n+     *\n+     * @param adTask AD task\n+     * @return how many bytes will consume\n+     */\n+    private long calculateADTaskCacheSize(ADTask adTask) {\n+        return memoryTracker.estimateModelSize(adTask.getDetector(), NUM_TREES) + trainingDataMemorySize(THRESHOLD_MODEL_TRAINING_SIZE)\n+            + shingleMemorySize(adTask.getDetector().getShingleSize());\n+    }\n+\n+    /**\n+     * Remove task from cache.\n+     *\n+     * @param taskId AD task id\n+     */\n+    public void remove(String taskId) {\n+        if (contains(taskId)) {\n+            memoryTracker.releaseMemory(getBatchTaskCache(taskId).getCacheMemorySize().get(), true, HISTORICAL_SINGLE_ENTITY_DETECTOR);\n+            taskCaches.remove(taskId);\n+        }\n+    }\n+\n+    /**\n+     * Cancel AD task.\n+     *\n+     * @param taskId AD task id\n+     * @param reason why need to cancel task\n+     * @param userName user name\n+     */\n+    public void cancel(String taskId, String reason, String userName) {\n+        getBatchTaskCache(taskId).cancel(reason, userName);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "de29b8a937ef9125bc2c66dad02059b04622822e"}, "originalPosition": 236}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d48182d29dee44991ba9c6a0afd3b8b3e0aa7fb9", "author": {"user": {"login": "ylwu-amzn", "name": "Yaliang"}}, "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/d48182d29dee44991ba9c6a0afd3b8b3e0aa7fb9", "committedDate": "2020-12-22T20:48:30Z", "message": "fix shingle memory calculation;store threshold model training data in double array"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "43f77d88fc2c543f94499299c2898ae0f14861d8", "author": {"user": {"login": "ylwu-amzn", "name": "Yaliang"}}, "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/43f77d88fc2c543f94499299c2898ae0f14861d8", "committedDate": "2020-12-22T20:46:09Z", "message": "store threshold model training data in double array"}, "afterCommit": {"oid": "d48182d29dee44991ba9c6a0afd3b8b3e0aa7fb9", "author": {"user": {"login": "ylwu-amzn", "name": "Yaliang"}}, "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/d48182d29dee44991ba9c6a0afd3b8b3e0aa7fb9", "committedDate": "2020-12-22T20:48:30Z", "message": "fix shingle memory calculation;store threshold model training data in double array"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU3NDc3NDk0", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/337#pullrequestreview-557477494", "createdAt": "2020-12-23T02:42:36Z", "commit": {"oid": "d48182d29dee44991ba9c6a0afd3b8b3e0aa7fb9"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QwMjo0ODo1M1rOIKPd6w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QwMzoxMDozN1rOIKPy8w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzYxMDA5MQ==", "bodyText": "when will you call this method?  Threshold model can emit results even if it has only seen 1 rcf score.  We use rcf's total updates to measure whether the models are ready or not.  Simply put, threshold model is always trained.  I wonder why we need a flag to set it trained or not.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/337#discussion_r547610091", "createdAt": "2020-12-23T02:48:53Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/task/ADTaskCacheManager.java", "diffHunk": "@@ -0,0 +1,325 @@\n+/*\n+ * Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.task;\n+\n+import static com.amazon.opendistroforelasticsearch.ad.MemoryTracker.Origin.HISTORICAL_SINGLE_ENTITY_DETECTOR;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.MAX_BATCH_TASK_PER_NODE;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.NUM_TREES;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.THRESHOLD_MODEL_TRAINING_SIZE;\n+\n+import java.util.Deque;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.settings.Settings;\n+\n+import com.amazon.opendistroforelasticsearch.ad.MemoryTracker;\n+import com.amazon.opendistroforelasticsearch.ad.common.exception.LimitExceededException;\n+import com.amazon.opendistroforelasticsearch.ad.ml.ThresholdingModel;\n+import com.amazon.opendistroforelasticsearch.ad.model.ADTask;\n+import com.amazon.opendistroforelasticsearch.ad.model.AnomalyDetector;\n+import com.amazon.randomcutforest.RandomCutForest;\n+\n+public class ADTaskCacheManager {\n+\n+    private final Map<String, ADBatchTaskCache> taskCaches;\n+    private volatile Integer maxAdBatchTaskPerNode;\n+    private final MemoryTracker memoryTracker;\n+\n+    /**\n+     * Constructor to create AD task cache manager.\n+     *\n+     * @param settings ES settings\n+     * @param clusterService ES cluster service\n+     * @param memoryTracker AD memory tracker\n+     */\n+    public ADTaskCacheManager(Settings settings, ClusterService clusterService, MemoryTracker memoryTracker) {\n+        this.maxAdBatchTaskPerNode = MAX_BATCH_TASK_PER_NODE.get(settings);\n+        clusterService.getClusterSettings().addSettingsUpdateConsumer(MAX_BATCH_TASK_PER_NODE, it -> maxAdBatchTaskPerNode = it);\n+        taskCaches = new ConcurrentHashMap<>();\n+        this.memoryTracker = memoryTracker;\n+    }\n+\n+    /**\n+     * Put AD task into cache.\n+     * If AD task is already in cache, will throw {@link IllegalArgumentException}\n+     * If there is one AD task in cache for detector, will throw {@link IllegalArgumentException}\n+     * If there is no enough memory for this AD task, will throw {@link LimitExceededException}\n+     *\n+     * @param adTask AD task\n+     */\n+    public synchronized void put(ADTask adTask) {\n+        String taskId = adTask.getTaskId();\n+        if (contains(taskId)) {\n+            throw new IllegalArgumentException(\"AD task is already running\");\n+        }\n+        if (containsTaskOfDetector(adTask.getDetectorId())) {\n+            throw new IllegalArgumentException(\"There is one task executing for detector\");\n+        }\n+        checkRunningTaskLimit();\n+        long neededCacheSize = calculateADTaskCacheSize(adTask);\n+        if (!memoryTracker.canAllocate(neededCacheSize)) {\n+            throw new LimitExceededException(\"No enough memory to run detector\");\n+        }\n+        memoryTracker.consumeMemory(neededCacheSize, false, HISTORICAL_SINGLE_ENTITY_DETECTOR);\n+        ADBatchTaskCache taskCache = new ADBatchTaskCache(adTask);\n+        taskCache.getCacheMemorySize().set(neededCacheSize);\n+        taskCaches.put(taskId, taskCache);\n+    }\n+\n+    /**\n+     * check if current running batch task on current node exceeds\n+     * max running task limitation.\n+     * If executing task count exceeds limitation, will throw\n+     * {@link LimitExceededException}\n+     */\n+    public void checkRunningTaskLimit() {\n+        if (size() >= maxAdBatchTaskPerNode) {\n+            String error = \"Can't run more than \" + maxAdBatchTaskPerNode + \" historical detectors per data node\";\n+            throw new LimitExceededException(error);\n+        }\n+    }\n+\n+    /**\n+     * Get task RCF model.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return RCF model\n+     */\n+    public RandomCutForest getRcfModel(String taskId) {\n+        return getBatchTaskCache(taskId).getRcfModel();\n+    }\n+\n+    /**\n+     * Get task threshold model.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return threshold model\n+     */\n+    public ThresholdingModel getThresholdModel(String taskId) {\n+        return getBatchTaskCache(taskId).getThresholdModel();\n+    }\n+\n+    /**\n+     * Get threshold model training data.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return threshold model training data\n+     */\n+    public double[] getThresholdModelTrainingData(String taskId) {\n+        return getBatchTaskCache(taskId).getThresholdModelTrainingData();\n+    }\n+\n+    public int addThresholdModelTrainingData(String taskId, double... data) {\n+        ADBatchTaskCache taskCache = getBatchTaskCache(taskId);\n+        double[] thresholdModelTrainingData = taskCache.getThresholdModelTrainingData();\n+        AtomicInteger size = taskCache.getThresholdModelTrainingDataSize();\n+        int dataPointsAdded = Math.min(data.length, THRESHOLD_MODEL_TRAINING_SIZE - size.get());\n+        System.arraycopy(data, 0, thresholdModelTrainingData, size.get(), dataPointsAdded);\n+        return size.addAndGet(dataPointsAdded);\n+    }\n+\n+    /**\n+     * Threshold model trained or not.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return true if threshold model trained; otherwise, return false\n+     */\n+    public boolean isThresholdModelTrained(String taskId) {\n+        return getBatchTaskCache(taskId).isThresholdModelTrained();\n+    }\n+\n+    /**\n+     * Set threshold model trained or not.\n+     *\n+     * @param taskId task id\n+     * @param trained threshold model trained or not\n+     */\n+    protected void setThresholdModelTrained(String taskId, boolean trained) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d48182d29dee44991ba9c6a0afd3b8b3e0aa7fb9"}, "originalPosition": 159}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzYxMjcxMg==", "bodyText": "Maybe you make 8 an field called it numberSize?  This would make it easier to change in the future.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/337#discussion_r547612712", "createdAt": "2020-12-23T02:59:22Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/task/ADTaskCacheManager.java", "diffHunk": "@@ -0,0 +1,325 @@\n+/*\n+ * Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.task;\n+\n+import static com.amazon.opendistroforelasticsearch.ad.MemoryTracker.Origin.HISTORICAL_SINGLE_ENTITY_DETECTOR;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.MAX_BATCH_TASK_PER_NODE;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.NUM_TREES;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.THRESHOLD_MODEL_TRAINING_SIZE;\n+\n+import java.util.Deque;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.settings.Settings;\n+\n+import com.amazon.opendistroforelasticsearch.ad.MemoryTracker;\n+import com.amazon.opendistroforelasticsearch.ad.common.exception.LimitExceededException;\n+import com.amazon.opendistroforelasticsearch.ad.ml.ThresholdingModel;\n+import com.amazon.opendistroforelasticsearch.ad.model.ADTask;\n+import com.amazon.opendistroforelasticsearch.ad.model.AnomalyDetector;\n+import com.amazon.randomcutforest.RandomCutForest;\n+\n+public class ADTaskCacheManager {\n+\n+    private final Map<String, ADBatchTaskCache> taskCaches;\n+    private volatile Integer maxAdBatchTaskPerNode;\n+    private final MemoryTracker memoryTracker;\n+\n+    /**\n+     * Constructor to create AD task cache manager.\n+     *\n+     * @param settings ES settings\n+     * @param clusterService ES cluster service\n+     * @param memoryTracker AD memory tracker\n+     */\n+    public ADTaskCacheManager(Settings settings, ClusterService clusterService, MemoryTracker memoryTracker) {\n+        this.maxAdBatchTaskPerNode = MAX_BATCH_TASK_PER_NODE.get(settings);\n+        clusterService.getClusterSettings().addSettingsUpdateConsumer(MAX_BATCH_TASK_PER_NODE, it -> maxAdBatchTaskPerNode = it);\n+        taskCaches = new ConcurrentHashMap<>();\n+        this.memoryTracker = memoryTracker;\n+    }\n+\n+    /**\n+     * Put AD task into cache.\n+     * If AD task is already in cache, will throw {@link IllegalArgumentException}\n+     * If there is one AD task in cache for detector, will throw {@link IllegalArgumentException}\n+     * If there is no enough memory for this AD task, will throw {@link LimitExceededException}\n+     *\n+     * @param adTask AD task\n+     */\n+    public synchronized void put(ADTask adTask) {\n+        String taskId = adTask.getTaskId();\n+        if (contains(taskId)) {\n+            throw new IllegalArgumentException(\"AD task is already running\");\n+        }\n+        if (containsTaskOfDetector(adTask.getDetectorId())) {\n+            throw new IllegalArgumentException(\"There is one task executing for detector\");\n+        }\n+        checkRunningTaskLimit();\n+        long neededCacheSize = calculateADTaskCacheSize(adTask);\n+        if (!memoryTracker.canAllocate(neededCacheSize)) {\n+            throw new LimitExceededException(\"No enough memory to run detector\");\n+        }\n+        memoryTracker.consumeMemory(neededCacheSize, false, HISTORICAL_SINGLE_ENTITY_DETECTOR);\n+        ADBatchTaskCache taskCache = new ADBatchTaskCache(adTask);\n+        taskCache.getCacheMemorySize().set(neededCacheSize);\n+        taskCaches.put(taskId, taskCache);\n+    }\n+\n+    /**\n+     * check if current running batch task on current node exceeds\n+     * max running task limitation.\n+     * If executing task count exceeds limitation, will throw\n+     * {@link LimitExceededException}\n+     */\n+    public void checkRunningTaskLimit() {\n+        if (size() >= maxAdBatchTaskPerNode) {\n+            String error = \"Can't run more than \" + maxAdBatchTaskPerNode + \" historical detectors per data node\";\n+            throw new LimitExceededException(error);\n+        }\n+    }\n+\n+    /**\n+     * Get task RCF model.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return RCF model\n+     */\n+    public RandomCutForest getRcfModel(String taskId) {\n+        return getBatchTaskCache(taskId).getRcfModel();\n+    }\n+\n+    /**\n+     * Get task threshold model.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return threshold model\n+     */\n+    public ThresholdingModel getThresholdModel(String taskId) {\n+        return getBatchTaskCache(taskId).getThresholdModel();\n+    }\n+\n+    /**\n+     * Get threshold model training data.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return threshold model training data\n+     */\n+    public double[] getThresholdModelTrainingData(String taskId) {\n+        return getBatchTaskCache(taskId).getThresholdModelTrainingData();\n+    }\n+\n+    public int addThresholdModelTrainingData(String taskId, double... data) {\n+        ADBatchTaskCache taskCache = getBatchTaskCache(taskId);\n+        double[] thresholdModelTrainingData = taskCache.getThresholdModelTrainingData();\n+        AtomicInteger size = taskCache.getThresholdModelTrainingDataSize();\n+        int dataPointsAdded = Math.min(data.length, THRESHOLD_MODEL_TRAINING_SIZE - size.get());\n+        System.arraycopy(data, 0, thresholdModelTrainingData, size.get(), dataPointsAdded);\n+        return size.addAndGet(dataPointsAdded);\n+    }\n+\n+    /**\n+     * Threshold model trained or not.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return true if threshold model trained; otherwise, return false\n+     */\n+    public boolean isThresholdModelTrained(String taskId) {\n+        return getBatchTaskCache(taskId).isThresholdModelTrained();\n+    }\n+\n+    /**\n+     * Set threshold model trained or not.\n+     *\n+     * @param taskId task id\n+     * @param trained threshold model trained or not\n+     */\n+    protected void setThresholdModelTrained(String taskId, boolean trained) {\n+        ADBatchTaskCache taskCache = getBatchTaskCache(taskId);\n+        taskCache.setThresholdModelTrained(trained);\n+        if (trained) {\n+            int size = taskCache.getThresholdModelTrainingDataSize().get();\n+            long cacheSize = trainingDataMemorySize(size);\n+            taskCache.clearTrainingData();\n+            taskCache.getCacheMemorySize().getAndAdd(-cacheSize);\n+            memoryTracker.releaseMemory(cacheSize, true, HISTORICAL_SINGLE_ENTITY_DETECTOR);\n+        }\n+    }\n+\n+    /**\n+     * Get shingle data.\n+     *\n+     * @param taskId AD task id\n+     * @return shingle data\n+     */\n+    public Deque<Map.Entry<Long, Optional<double[]>>> getShingle(String taskId) {\n+        return getBatchTaskCache(taskId).getShingle();\n+    }\n+\n+    /**\n+     * Check if task exists in cache.\n+     *\n+     * @param taskId task id\n+     * @return true if task exists in cache; otherwise, return false.\n+     */\n+    public boolean contains(String taskId) {\n+        return taskCaches.containsKey(taskId);\n+    }\n+\n+    /**\n+     * Check if there is task in cache for detector.\n+     *\n+     * @param detectorId detector id\n+     * @return true if there is task in cache; otherwise return false\n+     */\n+    public boolean containsTaskOfDetector(String detectorId) {\n+        return taskCaches.values().stream().filter(v -> Objects.equals(detectorId, v.getDetectorId())).findAny().isPresent();\n+    }\n+\n+    /**\n+     * Get batch task cache. If task doesn't exist in cache, will throw\n+     * {@link java.lang.IllegalArgumentException}\n+     *\n+     * @param taskId task id\n+     * @return AD batch task cache\n+     */\n+    private ADBatchTaskCache getBatchTaskCache(String taskId) {\n+        if (!contains(taskId)) {\n+            throw new IllegalArgumentException(\"AD task not in cache\");\n+        }\n+        return taskCaches.get(taskId);\n+    }\n+\n+    /**\n+     * Calculate AD task cache memory usage.\n+     *\n+     * @param adTask AD task\n+     * @return how many bytes will consume\n+     */\n+    private long calculateADTaskCacheSize(ADTask adTask) {\n+        AnomalyDetector detector = adTask.getDetector();\n+        return memoryTracker.estimateModelSize(detector, NUM_TREES) + trainingDataMemorySize(THRESHOLD_MODEL_TRAINING_SIZE)\n+            + shingleMemorySize(detector.getShingleSize(), detector.getEnabledFeatureIds().size());\n+    }\n+\n+    /**\n+     * Remove task from cache.\n+     *\n+     * @param taskId AD task id\n+     */\n+    public void remove(String taskId) {\n+        if (contains(taskId)) {\n+            memoryTracker.releaseMemory(getBatchTaskCache(taskId).getCacheMemorySize().get(), true, HISTORICAL_SINGLE_ENTITY_DETECTOR);\n+            taskCaches.remove(taskId);\n+        }\n+    }\n+\n+    /**\n+     * Cancel AD task.\n+     *\n+     * @param taskId AD task id\n+     * @param reason why need to cancel task\n+     * @param userName user name\n+     */\n+    public void cancel(String taskId, String reason, String userName) {\n+        getBatchTaskCache(taskId).cancel(reason, userName);\n+    }\n+\n+    /**\n+     * Task is cancelled or not.\n+     *\n+     * @param taskId AD task id\n+     * @return true if task is cancelled; otherwise return false\n+     */\n+    public boolean isCancelled(String taskId) {\n+        ADBatchTaskCache taskCache = getBatchTaskCache(taskId);\n+        return taskCache.isCancelled();\n+    }\n+\n+    /**\n+     * Get why task cancelled.\n+     *\n+     * @param taskId AD task id\n+     * @return task cancellation reason\n+     */\n+    public String getCancelReason(String taskId) {\n+        return getBatchTaskCache(taskId).getCancelReason();\n+    }\n+\n+    /**\n+     * Get task cancelled by which user.\n+     *\n+     * @param taskId AD task id\n+     * @return user name\n+     */\n+    public String getCancelledBy(String taskId) {\n+        return getBatchTaskCache(taskId).getCancelledBy();\n+    }\n+\n+    /**\n+     * Get current task count in cache.\n+     *\n+     * @return task count\n+     */\n+    public int size() {\n+        return taskCaches.size();\n+    }\n+\n+    /**\n+     * Clear all tasks.\n+     */\n+    public void clear() {\n+        taskCaches.clear();\n+    }\n+\n+    /**\n+     * Estimate max memory usage of model training data.\n+     * The training data is double and will cache in double array.\n+     * One double consumes 8 bytes.\n+     *\n+     * @param size training data point count\n+     * @return how many bytes will consume\n+     */\n+    public long trainingDataMemorySize(int size) {\n+        return 8 * size;\n+    }\n+\n+    /**\n+     * Estimate max memory usage of shingle data.\n+     * One feature aggregated data point(double) consumes 8 bytes.\n+     * The shingle data is stored in {@link java.util.Deque}. From testing,\n+     * other parts except feature data consume 80 bytes.\n+     *\n+     * Check {@link ADBatchTaskCache#getShingle()}\n+     *\n+     * @param shingleSize shingle data point count\n+     * @param enabledFeatureSize enabled feature count\n+     * @return how many bytes will consume\n+     */\n+    public long shingleMemorySize(int shingleSize, int enabledFeatureSize) {\n+        return (80 + 8 * enabledFeatureSize) * shingleSize;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d48182d29dee44991ba9c6a0afd3b8b3e0aa7fb9"}, "originalPosition": 322}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzYxMjczOA==", "bodyText": "Maybe you make 8 an field called it numberSize?", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/337#discussion_r547612738", "createdAt": "2020-12-23T02:59:31Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/task/ADTaskCacheManager.java", "diffHunk": "@@ -0,0 +1,325 @@\n+/*\n+ * Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.task;\n+\n+import static com.amazon.opendistroforelasticsearch.ad.MemoryTracker.Origin.HISTORICAL_SINGLE_ENTITY_DETECTOR;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.MAX_BATCH_TASK_PER_NODE;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.NUM_TREES;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.THRESHOLD_MODEL_TRAINING_SIZE;\n+\n+import java.util.Deque;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.settings.Settings;\n+\n+import com.amazon.opendistroforelasticsearch.ad.MemoryTracker;\n+import com.amazon.opendistroforelasticsearch.ad.common.exception.LimitExceededException;\n+import com.amazon.opendistroforelasticsearch.ad.ml.ThresholdingModel;\n+import com.amazon.opendistroforelasticsearch.ad.model.ADTask;\n+import com.amazon.opendistroforelasticsearch.ad.model.AnomalyDetector;\n+import com.amazon.randomcutforest.RandomCutForest;\n+\n+public class ADTaskCacheManager {\n+\n+    private final Map<String, ADBatchTaskCache> taskCaches;\n+    private volatile Integer maxAdBatchTaskPerNode;\n+    private final MemoryTracker memoryTracker;\n+\n+    /**\n+     * Constructor to create AD task cache manager.\n+     *\n+     * @param settings ES settings\n+     * @param clusterService ES cluster service\n+     * @param memoryTracker AD memory tracker\n+     */\n+    public ADTaskCacheManager(Settings settings, ClusterService clusterService, MemoryTracker memoryTracker) {\n+        this.maxAdBatchTaskPerNode = MAX_BATCH_TASK_PER_NODE.get(settings);\n+        clusterService.getClusterSettings().addSettingsUpdateConsumer(MAX_BATCH_TASK_PER_NODE, it -> maxAdBatchTaskPerNode = it);\n+        taskCaches = new ConcurrentHashMap<>();\n+        this.memoryTracker = memoryTracker;\n+    }\n+\n+    /**\n+     * Put AD task into cache.\n+     * If AD task is already in cache, will throw {@link IllegalArgumentException}\n+     * If there is one AD task in cache for detector, will throw {@link IllegalArgumentException}\n+     * If there is no enough memory for this AD task, will throw {@link LimitExceededException}\n+     *\n+     * @param adTask AD task\n+     */\n+    public synchronized void put(ADTask adTask) {\n+        String taskId = adTask.getTaskId();\n+        if (contains(taskId)) {\n+            throw new IllegalArgumentException(\"AD task is already running\");\n+        }\n+        if (containsTaskOfDetector(adTask.getDetectorId())) {\n+            throw new IllegalArgumentException(\"There is one task executing for detector\");\n+        }\n+        checkRunningTaskLimit();\n+        long neededCacheSize = calculateADTaskCacheSize(adTask);\n+        if (!memoryTracker.canAllocate(neededCacheSize)) {\n+            throw new LimitExceededException(\"No enough memory to run detector\");\n+        }\n+        memoryTracker.consumeMemory(neededCacheSize, false, HISTORICAL_SINGLE_ENTITY_DETECTOR);\n+        ADBatchTaskCache taskCache = new ADBatchTaskCache(adTask);\n+        taskCache.getCacheMemorySize().set(neededCacheSize);\n+        taskCaches.put(taskId, taskCache);\n+    }\n+\n+    /**\n+     * check if current running batch task on current node exceeds\n+     * max running task limitation.\n+     * If executing task count exceeds limitation, will throw\n+     * {@link LimitExceededException}\n+     */\n+    public void checkRunningTaskLimit() {\n+        if (size() >= maxAdBatchTaskPerNode) {\n+            String error = \"Can't run more than \" + maxAdBatchTaskPerNode + \" historical detectors per data node\";\n+            throw new LimitExceededException(error);\n+        }\n+    }\n+\n+    /**\n+     * Get task RCF model.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return RCF model\n+     */\n+    public RandomCutForest getRcfModel(String taskId) {\n+        return getBatchTaskCache(taskId).getRcfModel();\n+    }\n+\n+    /**\n+     * Get task threshold model.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return threshold model\n+     */\n+    public ThresholdingModel getThresholdModel(String taskId) {\n+        return getBatchTaskCache(taskId).getThresholdModel();\n+    }\n+\n+    /**\n+     * Get threshold model training data.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return threshold model training data\n+     */\n+    public double[] getThresholdModelTrainingData(String taskId) {\n+        return getBatchTaskCache(taskId).getThresholdModelTrainingData();\n+    }\n+\n+    public int addThresholdModelTrainingData(String taskId, double... data) {\n+        ADBatchTaskCache taskCache = getBatchTaskCache(taskId);\n+        double[] thresholdModelTrainingData = taskCache.getThresholdModelTrainingData();\n+        AtomicInteger size = taskCache.getThresholdModelTrainingDataSize();\n+        int dataPointsAdded = Math.min(data.length, THRESHOLD_MODEL_TRAINING_SIZE - size.get());\n+        System.arraycopy(data, 0, thresholdModelTrainingData, size.get(), dataPointsAdded);\n+        return size.addAndGet(dataPointsAdded);\n+    }\n+\n+    /**\n+     * Threshold model trained or not.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return true if threshold model trained; otherwise, return false\n+     */\n+    public boolean isThresholdModelTrained(String taskId) {\n+        return getBatchTaskCache(taskId).isThresholdModelTrained();\n+    }\n+\n+    /**\n+     * Set threshold model trained or not.\n+     *\n+     * @param taskId task id\n+     * @param trained threshold model trained or not\n+     */\n+    protected void setThresholdModelTrained(String taskId, boolean trained) {\n+        ADBatchTaskCache taskCache = getBatchTaskCache(taskId);\n+        taskCache.setThresholdModelTrained(trained);\n+        if (trained) {\n+            int size = taskCache.getThresholdModelTrainingDataSize().get();\n+            long cacheSize = trainingDataMemorySize(size);\n+            taskCache.clearTrainingData();\n+            taskCache.getCacheMemorySize().getAndAdd(-cacheSize);\n+            memoryTracker.releaseMemory(cacheSize, true, HISTORICAL_SINGLE_ENTITY_DETECTOR);\n+        }\n+    }\n+\n+    /**\n+     * Get shingle data.\n+     *\n+     * @param taskId AD task id\n+     * @return shingle data\n+     */\n+    public Deque<Map.Entry<Long, Optional<double[]>>> getShingle(String taskId) {\n+        return getBatchTaskCache(taskId).getShingle();\n+    }\n+\n+    /**\n+     * Check if task exists in cache.\n+     *\n+     * @param taskId task id\n+     * @return true if task exists in cache; otherwise, return false.\n+     */\n+    public boolean contains(String taskId) {\n+        return taskCaches.containsKey(taskId);\n+    }\n+\n+    /**\n+     * Check if there is task in cache for detector.\n+     *\n+     * @param detectorId detector id\n+     * @return true if there is task in cache; otherwise return false\n+     */\n+    public boolean containsTaskOfDetector(String detectorId) {\n+        return taskCaches.values().stream().filter(v -> Objects.equals(detectorId, v.getDetectorId())).findAny().isPresent();\n+    }\n+\n+    /**\n+     * Get batch task cache. If task doesn't exist in cache, will throw\n+     * {@link java.lang.IllegalArgumentException}\n+     *\n+     * @param taskId task id\n+     * @return AD batch task cache\n+     */\n+    private ADBatchTaskCache getBatchTaskCache(String taskId) {\n+        if (!contains(taskId)) {\n+            throw new IllegalArgumentException(\"AD task not in cache\");\n+        }\n+        return taskCaches.get(taskId);\n+    }\n+\n+    /**\n+     * Calculate AD task cache memory usage.\n+     *\n+     * @param adTask AD task\n+     * @return how many bytes will consume\n+     */\n+    private long calculateADTaskCacheSize(ADTask adTask) {\n+        AnomalyDetector detector = adTask.getDetector();\n+        return memoryTracker.estimateModelSize(detector, NUM_TREES) + trainingDataMemorySize(THRESHOLD_MODEL_TRAINING_SIZE)\n+            + shingleMemorySize(detector.getShingleSize(), detector.getEnabledFeatureIds().size());\n+    }\n+\n+    /**\n+     * Remove task from cache.\n+     *\n+     * @param taskId AD task id\n+     */\n+    public void remove(String taskId) {\n+        if (contains(taskId)) {\n+            memoryTracker.releaseMemory(getBatchTaskCache(taskId).getCacheMemorySize().get(), true, HISTORICAL_SINGLE_ENTITY_DETECTOR);\n+            taskCaches.remove(taskId);\n+        }\n+    }\n+\n+    /**\n+     * Cancel AD task.\n+     *\n+     * @param taskId AD task id\n+     * @param reason why need to cancel task\n+     * @param userName user name\n+     */\n+    public void cancel(String taskId, String reason, String userName) {\n+        getBatchTaskCache(taskId).cancel(reason, userName);\n+    }\n+\n+    /**\n+     * Task is cancelled or not.\n+     *\n+     * @param taskId AD task id\n+     * @return true if task is cancelled; otherwise return false\n+     */\n+    public boolean isCancelled(String taskId) {\n+        ADBatchTaskCache taskCache = getBatchTaskCache(taskId);\n+        return taskCache.isCancelled();\n+    }\n+\n+    /**\n+     * Get why task cancelled.\n+     *\n+     * @param taskId AD task id\n+     * @return task cancellation reason\n+     */\n+    public String getCancelReason(String taskId) {\n+        return getBatchTaskCache(taskId).getCancelReason();\n+    }\n+\n+    /**\n+     * Get task cancelled by which user.\n+     *\n+     * @param taskId AD task id\n+     * @return user name\n+     */\n+    public String getCancelledBy(String taskId) {\n+        return getBatchTaskCache(taskId).getCancelledBy();\n+    }\n+\n+    /**\n+     * Get current task count in cache.\n+     *\n+     * @return task count\n+     */\n+    public int size() {\n+        return taskCaches.size();\n+    }\n+\n+    /**\n+     * Clear all tasks.\n+     */\n+    public void clear() {\n+        taskCaches.clear();\n+    }\n+\n+    /**\n+     * Estimate max memory usage of model training data.\n+     * The training data is double and will cache in double array.\n+     * One double consumes 8 bytes.\n+     *\n+     * @param size training data point count\n+     * @return how many bytes will consume\n+     */\n+    public long trainingDataMemorySize(int size) {\n+        return 8 * size;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d48182d29dee44991ba9c6a0afd3b8b3e0aa7fb9"}, "originalPosition": 306}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzYxNTQyNA==", "bodyText": "you missed my comment", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/337#discussion_r547615424", "createdAt": "2020-12-23T03:10:22Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/task/ADTaskCacheManager.java", "diffHunk": "@@ -0,0 +1,306 @@\n+/*\n+ * Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.task;\n+\n+import static com.amazon.opendistroforelasticsearch.ad.MemoryTracker.Origin.HISTORICAL_SINGLE_ENTITY_DETECTOR;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.MAX_BATCH_TASK_PER_NODE;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.NUM_TREES;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.THRESHOLD_MODEL_TRAINING_SIZE;\n+\n+import java.util.Deque;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.settings.Settings;\n+\n+import com.amazon.opendistroforelasticsearch.ad.MemoryTracker;\n+import com.amazon.opendistroforelasticsearch.ad.common.exception.LimitExceededException;\n+import com.amazon.opendistroforelasticsearch.ad.ml.ThresholdingModel;\n+import com.amazon.opendistroforelasticsearch.ad.model.ADTask;\n+import com.amazon.randomcutforest.RandomCutForest;\n+\n+public class ADTaskCacheManager {\n+\n+    private final Map<String, ADBatchTaskCache> taskCaches;\n+    private volatile Integer maxAdBatchTaskPerNode;\n+    private final MemoryTracker memoryTracker;\n+\n+    /**\n+     * Constructor to create AD task cache manager.\n+     *\n+     * @param settings ES settings\n+     * @param clusterService ES cluster service\n+     * @param memoryTracker AD memory tracker\n+     */\n+    public ADTaskCacheManager(Settings settings, ClusterService clusterService, MemoryTracker memoryTracker) {\n+        this.maxAdBatchTaskPerNode = MAX_BATCH_TASK_PER_NODE.get(settings);\n+        clusterService.getClusterSettings().addSettingsUpdateConsumer(MAX_BATCH_TASK_PER_NODE, it -> maxAdBatchTaskPerNode = it);\n+        taskCaches = new ConcurrentHashMap<>();\n+        this.memoryTracker = memoryTracker;\n+    }\n+\n+    /**\n+     * Put AD task into cache.\n+     *\n+     * @param adTask AD task\n+     */\n+    public synchronized void put(ADTask adTask) {\n+        String taskId = adTask.getTaskId();\n+        if (contains(taskId)) {\n+            throw new IllegalArgumentException(\"AD task is already running\");\n+        }\n+        if (containsTaskOfDetector(adTask.getDetectorId())) {\n+            throw new IllegalArgumentException(\"There is one task executing for detector\");\n+        }\n+        checkRunningTaskLimit();\n+        long neededCacheSize = calculateADTaskCacheSize(adTask);\n+        if (!memoryTracker.canAllocate(neededCacheSize)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjkxNTIxMg=="}, "originalCommit": {"oid": "1bf147c0d9ce73b519bcca5a973c72db87f97707"}, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzYxNTQ3NQ==", "bodyText": "you missed my comment", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/337#discussion_r547615475", "createdAt": "2020-12-23T03:10:37Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/task/ADTaskCacheManager.java", "diffHunk": "@@ -0,0 +1,306 @@\n+/*\n+ * Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.task;\n+\n+import static com.amazon.opendistroforelasticsearch.ad.MemoryTracker.Origin.HISTORICAL_SINGLE_ENTITY_DETECTOR;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.MAX_BATCH_TASK_PER_NODE;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.NUM_TREES;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.THRESHOLD_MODEL_TRAINING_SIZE;\n+\n+import java.util.Deque;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.settings.Settings;\n+\n+import com.amazon.opendistroforelasticsearch.ad.MemoryTracker;\n+import com.amazon.opendistroforelasticsearch.ad.common.exception.LimitExceededException;\n+import com.amazon.opendistroforelasticsearch.ad.ml.ThresholdingModel;\n+import com.amazon.opendistroforelasticsearch.ad.model.ADTask;\n+import com.amazon.randomcutforest.RandomCutForest;\n+\n+public class ADTaskCacheManager {\n+\n+    private final Map<String, ADBatchTaskCache> taskCaches;\n+    private volatile Integer maxAdBatchTaskPerNode;\n+    private final MemoryTracker memoryTracker;\n+\n+    /**\n+     * Constructor to create AD task cache manager.\n+     *\n+     * @param settings ES settings\n+     * @param clusterService ES cluster service\n+     * @param memoryTracker AD memory tracker\n+     */\n+    public ADTaskCacheManager(Settings settings, ClusterService clusterService, MemoryTracker memoryTracker) {\n+        this.maxAdBatchTaskPerNode = MAX_BATCH_TASK_PER_NODE.get(settings);\n+        clusterService.getClusterSettings().addSettingsUpdateConsumer(MAX_BATCH_TASK_PER_NODE, it -> maxAdBatchTaskPerNode = it);\n+        taskCaches = new ConcurrentHashMap<>();\n+        this.memoryTracker = memoryTracker;\n+    }\n+\n+    /**\n+     * Put AD task into cache.\n+     *\n+     * @param adTask AD task\n+     */\n+    public synchronized void put(ADTask adTask) {\n+        String taskId = adTask.getTaskId();\n+        if (contains(taskId)) {\n+            throw new IllegalArgumentException(\"AD task is already running\");\n+        }\n+        if (containsTaskOfDetector(adTask.getDetectorId())) {\n+            throw new IllegalArgumentException(\"There is one task executing for detector\");\n+        }\n+        checkRunningTaskLimit();\n+        long neededCacheSize = calculateADTaskCacheSize(adTask);\n+        if (!memoryTracker.canAllocate(neededCacheSize)) {\n+            throw new LimitExceededException(\"No enough memory to run detector\");\n+        }\n+        memoryTracker.consumeMemory(neededCacheSize, false, HISTORICAL_SINGLE_ENTITY_DETECTOR);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjkxNTY5MA=="}, "originalCommit": {"oid": "1bf147c0d9ce73b519bcca5a973c72db87f97707"}, "originalPosition": 77}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9088012ca0e00fad15a5fb48b15080395720290b", "author": {"user": {"login": "ylwu-amzn", "name": "Yaliang"}}, "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/9088012ca0e00fad15a5fb48b15080395720290b", "committedDate": "2020-12-23T05:41:55Z", "message": "address comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU4MTgwMDk1", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/337#pullrequestreview-558180095", "createdAt": "2020-12-23T19:05:07Z", "commit": {"oid": "9088012ca0e00fad15a5fb48b15080395720290b"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxOTowNTowN1rOIKwTOg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxOToxMzoxMlrOIKwqpQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODE0ODAyNg==", "bodyText": "I still suggest we remove the exceptions and use Optional or null. In Java, the convention is to always check conditions whenever possible and not to use exceptions for flow control.  Conditional check is a jump in the byte code while the exception handling is much more complex.  When an exception occurs inside a Java method, the method creates an Exception object and passes the Exception object to the JVM (in Java term, the method \"throw\" an Exception). The Exception object contains the type of the exception, and the state of the program when the exception occurs. The JVM is responsible for finding an exception handler to process the Exception object. It searches backward through the call stack until it finds a matching exception handler for that particular class of Exception object (in Java term, it is called \"catch\" the Exception). If the JVM cannot find a matching exception handler in all the methods in the call stack, it terminates the program.\nIf you don't want to do it, I am fine as well.  Just a note this is not a good practice.\nRef: https://stackoverflow.com/questions/8161042/why-use-an-exception-instead-of-if-else", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/337#discussion_r548148026", "createdAt": "2020-12-23T19:05:07Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/task/ADTaskCacheManager.java", "diffHunk": "@@ -0,0 +1,329 @@\n+/*\n+ * Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.task;\n+\n+import static com.amazon.opendistroforelasticsearch.ad.MemoryTracker.Origin.HISTORICAL_SINGLE_ENTITY_DETECTOR;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.MAX_BATCH_TASK_PER_NODE;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.NUM_TREES;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.THRESHOLD_MODEL_TRAINING_SIZE;\n+\n+import java.util.Deque;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.settings.Settings;\n+\n+import com.amazon.opendistroforelasticsearch.ad.MemoryTracker;\n+import com.amazon.opendistroforelasticsearch.ad.common.exception.LimitExceededException;\n+import com.amazon.opendistroforelasticsearch.ad.ml.ThresholdingModel;\n+import com.amazon.opendistroforelasticsearch.ad.model.ADTask;\n+import com.amazon.opendistroforelasticsearch.ad.model.AnomalyDetector;\n+import com.amazon.randomcutforest.RandomCutForest;\n+\n+public class ADTaskCacheManager {\n+\n+    private final Map<String, ADBatchTaskCache> taskCaches;\n+    private volatile Integer maxAdBatchTaskPerNode;\n+    private final MemoryTracker memoryTracker;\n+    private final int numberSize = 8;\n+\n+    /**\n+     * Constructor to create AD task cache manager.\n+     *\n+     * @param settings ES settings\n+     * @param clusterService ES cluster service\n+     * @param memoryTracker AD memory tracker\n+     */\n+    public ADTaskCacheManager(Settings settings, ClusterService clusterService, MemoryTracker memoryTracker) {\n+        this.maxAdBatchTaskPerNode = MAX_BATCH_TASK_PER_NODE.get(settings);\n+        clusterService.getClusterSettings().addSettingsUpdateConsumer(MAX_BATCH_TASK_PER_NODE, it -> maxAdBatchTaskPerNode = it);\n+        taskCaches = new ConcurrentHashMap<>();\n+        this.memoryTracker = memoryTracker;\n+    }\n+\n+    /**\n+     * Put AD task into cache.\n+     * If AD task is already in cache, will throw {@link IllegalArgumentException}\n+     * If there is one AD task in cache for detector, will throw {@link IllegalArgumentException}\n+     * If there is no enough memory for this AD task, will throw {@link LimitExceededException}\n+     *\n+     * @param adTask AD task\n+     */\n+    public synchronized void put(ADTask adTask) {\n+        String taskId = adTask.getTaskId();\n+        if (contains(taskId)) {\n+            throw new IllegalArgumentException(\"AD task is already running\");\n+        }\n+        if (containsTaskOfDetector(adTask.getDetectorId())) {\n+            throw new IllegalArgumentException(\"There is one task executing for detector\");\n+        }\n+        checkRunningTaskLimit();\n+        long neededCacheSize = calculateADTaskCacheSize(adTask);\n+        if (!memoryTracker.canAllocateReserved(adTask.getDetectorId(), neededCacheSize)) {\n+            throw new LimitExceededException(\"No enough memory to run detector\");\n+        }\n+        memoryTracker.consumeMemory(neededCacheSize, true, HISTORICAL_SINGLE_ENTITY_DETECTOR);\n+        ADBatchTaskCache taskCache = new ADBatchTaskCache(adTask);\n+        taskCache.getCacheMemorySize().set(neededCacheSize);\n+        taskCaches.put(taskId, taskCache);\n+    }\n+\n+    /**\n+     * check if current running batch task on current node exceeds\n+     * max running task limitation.\n+     * If executing task count exceeds limitation, will throw\n+     * {@link LimitExceededException}\n+     */\n+    public void checkRunningTaskLimit() {\n+        if (size() >= maxAdBatchTaskPerNode) {\n+            String error = \"Can't run more than \" + maxAdBatchTaskPerNode + \" historical detectors per data node\";\n+            throw new LimitExceededException(error);\n+        }\n+    }\n+\n+    /**\n+     * Get task RCF model.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return RCF model\n+     */\n+    public RandomCutForest getRcfModel(String taskId) {\n+        return getBatchTaskCache(taskId).getRcfModel();\n+    }\n+\n+    /**\n+     * Get task threshold model.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return threshold model\n+     */\n+    public ThresholdingModel getThresholdModel(String taskId) {\n+        return getBatchTaskCache(taskId).getThresholdModel();\n+    }\n+\n+    /**\n+     * Get threshold model training data.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return threshold model training data\n+     */\n+    public double[] getThresholdModelTrainingData(String taskId) {\n+        return getBatchTaskCache(taskId).getThresholdModelTrainingData();\n+    }\n+\n+    public int addThresholdModelTrainingData(String taskId, double... data) {\n+        ADBatchTaskCache taskCache = getBatchTaskCache(taskId);\n+        double[] thresholdModelTrainingData = taskCache.getThresholdModelTrainingData();\n+        AtomicInteger size = taskCache.getThresholdModelTrainingDataSize();\n+        int dataPointsAdded = Math.min(data.length, THRESHOLD_MODEL_TRAINING_SIZE - size.get());\n+        System.arraycopy(data, 0, thresholdModelTrainingData, size.get(), dataPointsAdded);\n+        return size.addAndGet(dataPointsAdded);\n+    }\n+\n+    /**\n+     * Threshold model trained or not.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return true if threshold model trained; otherwise, return false\n+     */\n+    public boolean isThresholdModelTrained(String taskId) {\n+        return getBatchTaskCache(taskId).isThresholdModelTrained();\n+    }\n+\n+    /**\n+     * Set threshold model trained or not.\n+     *\n+     * @param taskId task id\n+     * @param trained threshold model trained or not\n+     */\n+    protected void setThresholdModelTrained(String taskId, boolean trained) {\n+        ADBatchTaskCache taskCache = getBatchTaskCache(taskId);\n+        taskCache.setThresholdModelTrained(trained);\n+        if (trained) {\n+            int size = taskCache.getThresholdModelTrainingDataSize().get();\n+            long cacheSize = trainingDataMemorySize(size);\n+            taskCache.clearTrainingData();\n+            taskCache.getCacheMemorySize().getAndAdd(-cacheSize);\n+            memoryTracker.releaseMemory(cacheSize, true, HISTORICAL_SINGLE_ENTITY_DETECTOR);\n+        }\n+    }\n+\n+    /**\n+     * Get shingle data.\n+     *\n+     * @param taskId AD task id\n+     * @return shingle data\n+     */\n+    public Deque<Map.Entry<Long, Optional<double[]>>> getShingle(String taskId) {\n+        return getBatchTaskCache(taskId).getShingle();\n+    }\n+\n+    /**\n+     * Check if task exists in cache.\n+     *\n+     * @param taskId task id\n+     * @return true if task exists in cache; otherwise, return false.\n+     */\n+    public boolean contains(String taskId) {\n+        return taskCaches.containsKey(taskId);\n+    }\n+\n+    /**\n+     * Check if there is task in cache for detector.\n+     *\n+     * @param detectorId detector id\n+     * @return true if there is task in cache; otherwise return false\n+     */\n+    public boolean containsTaskOfDetector(String detectorId) {\n+        return taskCaches.values().stream().filter(v -> Objects.equals(detectorId, v.getDetectorId())).findAny().isPresent();\n+    }\n+\n+    /**\n+     * Get batch task cache. If task doesn't exist in cache, will throw\n+     * {@link java.lang.IllegalArgumentException}\n+     * We throw exception rather than return {@code Optional.empty} or null\n+     * here, so don't need to check task existence by writing duplicate null\n+     * checking code. All AD task exceptions will be handled in AD task manager.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9088012ca0e00fad15a5fb48b15080395720290b"}, "originalPosition": 207}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0ODE1NDAyMQ==", "bodyText": "Understood.  1000 is a trade-off between accuracy and usability. In real time, 128 is the threshold to emit results.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/337#discussion_r548154021", "createdAt": "2020-12-23T19:13:12Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/task/ADTaskCacheManager.java", "diffHunk": "@@ -0,0 +1,325 @@\n+/*\n+ * Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.task;\n+\n+import static com.amazon.opendistroforelasticsearch.ad.MemoryTracker.Origin.HISTORICAL_SINGLE_ENTITY_DETECTOR;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.MAX_BATCH_TASK_PER_NODE;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.NUM_TREES;\n+import static com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings.THRESHOLD_MODEL_TRAINING_SIZE;\n+\n+import java.util.Deque;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Optional;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.settings.Settings;\n+\n+import com.amazon.opendistroforelasticsearch.ad.MemoryTracker;\n+import com.amazon.opendistroforelasticsearch.ad.common.exception.LimitExceededException;\n+import com.amazon.opendistroforelasticsearch.ad.ml.ThresholdingModel;\n+import com.amazon.opendistroforelasticsearch.ad.model.ADTask;\n+import com.amazon.opendistroforelasticsearch.ad.model.AnomalyDetector;\n+import com.amazon.randomcutforest.RandomCutForest;\n+\n+public class ADTaskCacheManager {\n+\n+    private final Map<String, ADBatchTaskCache> taskCaches;\n+    private volatile Integer maxAdBatchTaskPerNode;\n+    private final MemoryTracker memoryTracker;\n+\n+    /**\n+     * Constructor to create AD task cache manager.\n+     *\n+     * @param settings ES settings\n+     * @param clusterService ES cluster service\n+     * @param memoryTracker AD memory tracker\n+     */\n+    public ADTaskCacheManager(Settings settings, ClusterService clusterService, MemoryTracker memoryTracker) {\n+        this.maxAdBatchTaskPerNode = MAX_BATCH_TASK_PER_NODE.get(settings);\n+        clusterService.getClusterSettings().addSettingsUpdateConsumer(MAX_BATCH_TASK_PER_NODE, it -> maxAdBatchTaskPerNode = it);\n+        taskCaches = new ConcurrentHashMap<>();\n+        this.memoryTracker = memoryTracker;\n+    }\n+\n+    /**\n+     * Put AD task into cache.\n+     * If AD task is already in cache, will throw {@link IllegalArgumentException}\n+     * If there is one AD task in cache for detector, will throw {@link IllegalArgumentException}\n+     * If there is no enough memory for this AD task, will throw {@link LimitExceededException}\n+     *\n+     * @param adTask AD task\n+     */\n+    public synchronized void put(ADTask adTask) {\n+        String taskId = adTask.getTaskId();\n+        if (contains(taskId)) {\n+            throw new IllegalArgumentException(\"AD task is already running\");\n+        }\n+        if (containsTaskOfDetector(adTask.getDetectorId())) {\n+            throw new IllegalArgumentException(\"There is one task executing for detector\");\n+        }\n+        checkRunningTaskLimit();\n+        long neededCacheSize = calculateADTaskCacheSize(adTask);\n+        if (!memoryTracker.canAllocate(neededCacheSize)) {\n+            throw new LimitExceededException(\"No enough memory to run detector\");\n+        }\n+        memoryTracker.consumeMemory(neededCacheSize, false, HISTORICAL_SINGLE_ENTITY_DETECTOR);\n+        ADBatchTaskCache taskCache = new ADBatchTaskCache(adTask);\n+        taskCache.getCacheMemorySize().set(neededCacheSize);\n+        taskCaches.put(taskId, taskCache);\n+    }\n+\n+    /**\n+     * check if current running batch task on current node exceeds\n+     * max running task limitation.\n+     * If executing task count exceeds limitation, will throw\n+     * {@link LimitExceededException}\n+     */\n+    public void checkRunningTaskLimit() {\n+        if (size() >= maxAdBatchTaskPerNode) {\n+            String error = \"Can't run more than \" + maxAdBatchTaskPerNode + \" historical detectors per data node\";\n+            throw new LimitExceededException(error);\n+        }\n+    }\n+\n+    /**\n+     * Get task RCF model.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return RCF model\n+     */\n+    public RandomCutForest getRcfModel(String taskId) {\n+        return getBatchTaskCache(taskId).getRcfModel();\n+    }\n+\n+    /**\n+     * Get task threshold model.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return threshold model\n+     */\n+    public ThresholdingModel getThresholdModel(String taskId) {\n+        return getBatchTaskCache(taskId).getThresholdModel();\n+    }\n+\n+    /**\n+     * Get threshold model training data.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return threshold model training data\n+     */\n+    public double[] getThresholdModelTrainingData(String taskId) {\n+        return getBatchTaskCache(taskId).getThresholdModelTrainingData();\n+    }\n+\n+    public int addThresholdModelTrainingData(String taskId, double... data) {\n+        ADBatchTaskCache taskCache = getBatchTaskCache(taskId);\n+        double[] thresholdModelTrainingData = taskCache.getThresholdModelTrainingData();\n+        AtomicInteger size = taskCache.getThresholdModelTrainingDataSize();\n+        int dataPointsAdded = Math.min(data.length, THRESHOLD_MODEL_TRAINING_SIZE - size.get());\n+        System.arraycopy(data, 0, thresholdModelTrainingData, size.get(), dataPointsAdded);\n+        return size.addAndGet(dataPointsAdded);\n+    }\n+\n+    /**\n+     * Threshold model trained or not.\n+     * If task doesn't exist in cache, will throw {@link java.lang.IllegalArgumentException}.\n+     *\n+     * @param taskId AD task id\n+     * @return true if threshold model trained; otherwise, return false\n+     */\n+    public boolean isThresholdModelTrained(String taskId) {\n+        return getBatchTaskCache(taskId).isThresholdModelTrained();\n+    }\n+\n+    /**\n+     * Set threshold model trained or not.\n+     *\n+     * @param taskId task id\n+     * @param trained threshold model trained or not\n+     */\n+    protected void setThresholdModelTrained(String taskId, boolean trained) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzYxMDA5MQ=="}, "originalCommit": {"oid": "d48182d29dee44991ba9c6a0afd3b8b3e0aa7fb9"}, "originalPosition": 159}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU4MTg0NTUy", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/337#pullrequestreview-558184552", "createdAt": "2020-12-23T19:15:30Z", "commit": {"oid": "9088012ca0e00fad15a5fb48b15080395720290b"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1448, "cost": 1, "resetAt": "2021-11-01T16:19:10Z"}}}