{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg2MjMyNTA5", "number": 59, "title": "record error and execution start/end time in AD result; handle except\u2026", "bodyText": "Issue #47\n\nDescription of changes:\n\nrecord error and execution start/end time in AD result\nhandle exception from AD result action.\nIf exception is EndRunException: 1).if endNow=true, will stop AD job run; otherwise; 2). if endNow=false, will retry AD job, if all retries failed or have no enough time to retry, will stop AD job.\n\nBy submitting this pull request, I confirm that you can use, modify, copy, and redistribute this contribution, under the terms of your choice.", "createdAt": "2020-03-10T16:19:08Z", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59", "merged": true, "mergeCommit": {"oid": "b4a8decd1a59085dd9ac176c8a70864e6956ae5b"}, "closed": true, "closedAt": "2020-03-17T02:20:53Z", "author": {"login": "ylwu-amzn"}, "timelineItems": {"totalCount": 16, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcMU34rgH2gAyMzg2MjMyNTA5OjYzOGFmNWQ2ODQ5NWRlYjlkMTJmODk2Y2FiZGVmMWQxMmY3MGU1MWI=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcOZEcRAH2gAyMzg2MjMyNTA5OmY5NjU3MTcyMWY4OTUyZjE3Y2VjZWEyZjQ0ZDcxZWE3ZDdmOGU2NTc=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "638af5d68495deb9d12f896cabdef1d12f70e51b", "author": {"user": {"login": "ylwu-amzn", "name": "Yaliang"}}, "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/638af5d68495deb9d12f896cabdef1d12f70e51b", "committedDate": "2020-03-10T16:12:19Z", "message": "record error and execution start/end time in AD result; handle exception from AD result action"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzczMjQ5MjI0", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#pullrequestreview-373249224", "createdAt": "2020-03-12T02:57:15Z", "commit": {"oid": "638af5d68495deb9d12f896cabdef1d12f70e51b"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMlQwMjo1NzoxNVrOF1PvVA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMlQwMzo1ODozN1rOF1QicQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTM3NjcyNA==", "bodyText": "executionStartTime and endTime are almost the same, we can just keep one.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r391376724", "createdAt": "2020-03-12T02:57:15Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/AnomalyDetectorJobRunner.java", "diffHunk": "@@ -81,6 +130,11 @@ public void runJob(ScheduledJobParameter jobParameter, JobExecutionContext conte\n             );\n         }\n \n+        Instant executionStartTime = Instant.now();\n+        IntervalSchedule schedule = (IntervalSchedule) jobParameter.getSchedule();\n+        Instant endTime = Instant.now();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "638af5d68495deb9d12f896cabdef1d12f70e51b"}, "originalPosition": 104}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTM3OTE4MQ==", "bodyText": "put releaseLock in a finally clause so you don't have to remember to write it in every branch?", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r391379181", "createdAt": "2020-03-12T03:07:39Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/AnomalyDetectorJobRunner.java", "diffHunk": "@@ -106,36 +169,301 @@ public void runJob(ScheduledJobParameter jobParameter, JobExecutionContext conte\n         executor.submit(runnable);\n     }\n \n-    protected void runAdJob(ScheduledJobParameter jobParameter, LockService lockService, LockModel lock) {\n+    protected void runAdJob(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant startTime,\n+        Instant endTime,\n+        Instant executionStartTime,\n+        Iterator<TimeValue> backoff\n+    ) {\n+\n         if (lock == null) {\n+            indexAnomalyResultExceptionSilently(\n+                jobParameter,\n+                startTime,\n+                endTime,\n+                executionStartTime,\n+                new AnomalyDetectionException(jobParameter.getName(), \"Can't run AD job due to null lock\")\n+            );\n             return;\n         }\n \n         try {\n-            IntervalSchedule schedule = (IntervalSchedule) jobParameter.getSchedule();\n-            // TODO: handle jitter of job scheduler\n-            Instant endTime = Instant.now();\n-            Duration duration = Duration.of(schedule.getInterval(), schedule.getUnit());\n-            Instant startTime = endTime.minusMillis(duration.toMillis());\n-\n             AnomalyResultRequest request = new AnomalyResultRequest(\n                 jobParameter.getName(),\n                 startTime.toEpochMilli(),\n                 endTime.toEpochMilli()\n             );\n-            client.execute(AnomalyResultAction.INSTANCE, request, ActionListener.wrap(response -> {\n-                log.info(\"Anomaly result action ran successfully for \" + jobParameter.getName());\n-                releaseLock(jobParameter, lockService, lock);\n-            }, exception -> {\n-                log.error(\"Failed to execute anomaly result action\", exception);\n+            client\n+                .execute(\n+                    AnomalyResultAction.INSTANCE,\n+                    request,\n+                    ActionListener\n+                        .wrap(\n+                            response -> {\n+                                indexAnomalyResultSilently(\n+                                    jobParameter,\n+                                    lockService,\n+                                    lock,\n+                                    startTime,\n+                                    endTime,\n+                                    executionStartTime,\n+                                    response\n+                                );\n+                            },\n+                            exception -> {\n+                                handleAdException(\n+                                    jobParameter,\n+                                    lockService,\n+                                    lock,\n+                                    startTime,\n+                                    endTime,\n+                                    executionStartTime,\n+                                    backoff,\n+                                    exception\n+                                );\n+                            }\n+                        )\n+                );\n+        } catch (Exception e) {\n+            indexAnomalyResultExceptionSilently(jobParameter, startTime, endTime, executionStartTime, e);\n+            log.error(\"Failed to execute AD job \" + jobParameter.getName(), e);\n+            releaseLock(jobParameter, lockService, lock);\n+        }\n+    }\n+\n+    protected void handleAdException(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant startTime,\n+        Instant endTime,\n+        Instant executionStartTime,\n+        Iterator<TimeValue> backoff,\n+        Exception exception\n+    ) {\n+        if (exception instanceof EndRunException) {\n+            log.error(\"EndRunException happened when executed anomaly result action for \" + jobParameter.getName(), exception);\n+\n+            if (((EndRunException) exception).isEndNow()) {\n+                // Stop AD job if EndRunException shows we should end job now.\n+                stopAdJobSilently(jobParameter.getName());\n+                indexAnomalyResultExceptionSilently(\n+                    jobParameter,\n+                    startTime,\n+                    endTime,\n+                    executionStartTime,\n+                    \"Stopped detector: \" + exception.getMessage()\n+                );\n                 releaseLock(jobParameter, lockService, lock);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "638af5d68495deb9d12f896cabdef1d12f70e51b"}, "originalPosition": 233}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTM4MjEzMA==", "bodyText": "For retryable EndRunException, I didn't mean to retry right away.  I meant to let AD job trigger the retry in the new few runs.  After that, if things do not improve, stop AD job.\nThe backoff setting for EndRunException retry here is too fast.  The formula of backoff delay is:\nstart + 10 * ((int) Math.exp(0.8d * (currentlyConsumed)) - 1)\nIn your current setting,\nstart = 1 sec\ncurrentlyConsumed is between [0, 2] since we are gonna retry 3 times.\nThen we are gonna retry in 1 sec, 11 sec, 31 sec.\nSee the definition of ExponentialBackoffIterator in Elasticsearch for further details.\nSome issue like training data not available cannot be fixed right away.  We need to wait a few more retries * AD job interval.\nAlso, would AD job run and the backoff retry happen at the same time?  If yes, would there be any problem?", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r391382130", "createdAt": "2020-03-12T03:22:04Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/AnomalyDetectorJobRunner.java", "diffHunk": "@@ -106,36 +169,301 @@ public void runJob(ScheduledJobParameter jobParameter, JobExecutionContext conte\n         executor.submit(runnable);\n     }\n \n-    protected void runAdJob(ScheduledJobParameter jobParameter, LockService lockService, LockModel lock) {\n+    protected void runAdJob(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant startTime,\n+        Instant endTime,\n+        Instant executionStartTime,\n+        Iterator<TimeValue> backoff\n+    ) {\n+\n         if (lock == null) {\n+            indexAnomalyResultExceptionSilently(\n+                jobParameter,\n+                startTime,\n+                endTime,\n+                executionStartTime,\n+                new AnomalyDetectionException(jobParameter.getName(), \"Can't run AD job due to null lock\")\n+            );\n             return;\n         }\n \n         try {\n-            IntervalSchedule schedule = (IntervalSchedule) jobParameter.getSchedule();\n-            // TODO: handle jitter of job scheduler\n-            Instant endTime = Instant.now();\n-            Duration duration = Duration.of(schedule.getInterval(), schedule.getUnit());\n-            Instant startTime = endTime.minusMillis(duration.toMillis());\n-\n             AnomalyResultRequest request = new AnomalyResultRequest(\n                 jobParameter.getName(),\n                 startTime.toEpochMilli(),\n                 endTime.toEpochMilli()\n             );\n-            client.execute(AnomalyResultAction.INSTANCE, request, ActionListener.wrap(response -> {\n-                log.info(\"Anomaly result action ran successfully for \" + jobParameter.getName());\n-                releaseLock(jobParameter, lockService, lock);\n-            }, exception -> {\n-                log.error(\"Failed to execute anomaly result action\", exception);\n+            client\n+                .execute(\n+                    AnomalyResultAction.INSTANCE,\n+                    request,\n+                    ActionListener\n+                        .wrap(\n+                            response -> {\n+                                indexAnomalyResultSilently(\n+                                    jobParameter,\n+                                    lockService,\n+                                    lock,\n+                                    startTime,\n+                                    endTime,\n+                                    executionStartTime,\n+                                    response\n+                                );\n+                            },\n+                            exception -> {\n+                                handleAdException(\n+                                    jobParameter,\n+                                    lockService,\n+                                    lock,\n+                                    startTime,\n+                                    endTime,\n+                                    executionStartTime,\n+                                    backoff,\n+                                    exception\n+                                );\n+                            }\n+                        )\n+                );\n+        } catch (Exception e) {\n+            indexAnomalyResultExceptionSilently(jobParameter, startTime, endTime, executionStartTime, e);\n+            log.error(\"Failed to execute AD job \" + jobParameter.getName(), e);\n+            releaseLock(jobParameter, lockService, lock);\n+        }\n+    }\n+\n+    protected void handleAdException(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant startTime,\n+        Instant endTime,\n+        Instant executionStartTime,\n+        Iterator<TimeValue> backoff,\n+        Exception exception\n+    ) {\n+        if (exception instanceof EndRunException) {\n+            log.error(\"EndRunException happened when executed anomaly result action for \" + jobParameter.getName(), exception);\n+\n+            if (((EndRunException) exception).isEndNow()) {\n+                // Stop AD job if EndRunException shows we should end job now.\n+                stopAdJobSilently(jobParameter.getName());\n+                indexAnomalyResultExceptionSilently(\n+                    jobParameter,\n+                    startTime,\n+                    endTime,\n+                    executionStartTime,\n+                    \"Stopped detector: \" + exception.getMessage()\n+                );\n                 releaseLock(jobParameter, lockService, lock);\n-            }));\n+            } else {\n+                // retry AD job, if all retries failed or have no enough time to retry, will stop AD job.\n+                Schedule schedule = jobParameter.getSchedule();\n+                long nextExecutionTime = jobParameter.getSchedule().getNextExecutionTime(executionStartTime).toEpochMilli();\n+                long now = Instant.now().toEpochMilli();\n+                long leftTime = nextExecutionTime - now - JOB_RUN_BUFFER_IN_MILLISECONDS;\n+                long usedTime = now - executionStartTime.toEpochMilli();\n+\n+                if (!backoff.hasNext()) {\n+                    stopAdJobForEndRunException(\n+                        jobParameter,\n+                        lockService,\n+                        lock,\n+                        startTime,\n+                        endTime,\n+                        executionStartTime,\n+                        (EndRunException) exception\n+                    );\n+                } else {\n+                    if (backoff.hasNext()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "638af5d68495deb9d12f896cabdef1d12f70e51b"}, "originalPosition": 254}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTM4NTE1MQ==", "bodyText": "Are line 252~260 same with stopAdJobForEndRunException?", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r391385151", "createdAt": "2020-03-12T03:36:13Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/AnomalyDetectorJobRunner.java", "diffHunk": "@@ -106,36 +169,301 @@ public void runJob(ScheduledJobParameter jobParameter, JobExecutionContext conte\n         executor.submit(runnable);\n     }\n \n-    protected void runAdJob(ScheduledJobParameter jobParameter, LockService lockService, LockModel lock) {\n+    protected void runAdJob(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant startTime,\n+        Instant endTime,\n+        Instant executionStartTime,\n+        Iterator<TimeValue> backoff\n+    ) {\n+\n         if (lock == null) {\n+            indexAnomalyResultExceptionSilently(\n+                jobParameter,\n+                startTime,\n+                endTime,\n+                executionStartTime,\n+                new AnomalyDetectionException(jobParameter.getName(), \"Can't run AD job due to null lock\")\n+            );\n             return;\n         }\n \n         try {\n-            IntervalSchedule schedule = (IntervalSchedule) jobParameter.getSchedule();\n-            // TODO: handle jitter of job scheduler\n-            Instant endTime = Instant.now();\n-            Duration duration = Duration.of(schedule.getInterval(), schedule.getUnit());\n-            Instant startTime = endTime.minusMillis(duration.toMillis());\n-\n             AnomalyResultRequest request = new AnomalyResultRequest(\n                 jobParameter.getName(),\n                 startTime.toEpochMilli(),\n                 endTime.toEpochMilli()\n             );\n-            client.execute(AnomalyResultAction.INSTANCE, request, ActionListener.wrap(response -> {\n-                log.info(\"Anomaly result action ran successfully for \" + jobParameter.getName());\n-                releaseLock(jobParameter, lockService, lock);\n-            }, exception -> {\n-                log.error(\"Failed to execute anomaly result action\", exception);\n+            client\n+                .execute(\n+                    AnomalyResultAction.INSTANCE,\n+                    request,\n+                    ActionListener\n+                        .wrap(\n+                            response -> {\n+                                indexAnomalyResultSilently(\n+                                    jobParameter,\n+                                    lockService,\n+                                    lock,\n+                                    startTime,\n+                                    endTime,\n+                                    executionStartTime,\n+                                    response\n+                                );\n+                            },\n+                            exception -> {\n+                                handleAdException(\n+                                    jobParameter,\n+                                    lockService,\n+                                    lock,\n+                                    startTime,\n+                                    endTime,\n+                                    executionStartTime,\n+                                    backoff,\n+                                    exception\n+                                );\n+                            }\n+                        )\n+                );\n+        } catch (Exception e) {\n+            indexAnomalyResultExceptionSilently(jobParameter, startTime, endTime, executionStartTime, e);\n+            log.error(\"Failed to execute AD job \" + jobParameter.getName(), e);\n+            releaseLock(jobParameter, lockService, lock);\n+        }\n+    }\n+\n+    protected void handleAdException(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant startTime,\n+        Instant endTime,\n+        Instant executionStartTime,\n+        Iterator<TimeValue> backoff,\n+        Exception exception\n+    ) {\n+        if (exception instanceof EndRunException) {\n+            log.error(\"EndRunException happened when executed anomaly result action for \" + jobParameter.getName(), exception);\n+\n+            if (((EndRunException) exception).isEndNow()) {\n+                // Stop AD job if EndRunException shows we should end job now.\n+                stopAdJobSilently(jobParameter.getName());\n+                indexAnomalyResultExceptionSilently(\n+                    jobParameter,\n+                    startTime,\n+                    endTime,\n+                    executionStartTime,\n+                    \"Stopped detector: \" + exception.getMessage()\n+                );\n                 releaseLock(jobParameter, lockService, lock);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTM3OTE4MQ=="}, "originalCommit": {"oid": "638af5d68495deb9d12f896cabdef1d12f70e51b"}, "originalPosition": 233}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTM4NTczNQ==", "bodyText": "How about rename to stopAdJob?  I know you want to differentiate stopADJob only and stopAdJob + index + release lock.  Silently gives me a fear that this is a serial killer without leaving any trace.  But you do have a lot of logs and exception handling.\nAlso, we don't usually use adverb as method names.  We usually use verbs or verb phrases.  See https://google.github.io/styleguide/javaguide.html\nThis applies to your other *Silently methods as well.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r391385735", "createdAt": "2020-03-12T03:38:47Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/AnomalyDetectorJobRunner.java", "diffHunk": "@@ -106,36 +169,301 @@ public void runJob(ScheduledJobParameter jobParameter, JobExecutionContext conte\n         executor.submit(runnable);\n     }\n \n-    protected void runAdJob(ScheduledJobParameter jobParameter, LockService lockService, LockModel lock) {\n+    protected void runAdJob(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant startTime,\n+        Instant endTime,\n+        Instant executionStartTime,\n+        Iterator<TimeValue> backoff\n+    ) {\n+\n         if (lock == null) {\n+            indexAnomalyResultExceptionSilently(\n+                jobParameter,\n+                startTime,\n+                endTime,\n+                executionStartTime,\n+                new AnomalyDetectionException(jobParameter.getName(), \"Can't run AD job due to null lock\")\n+            );\n             return;\n         }\n \n         try {\n-            IntervalSchedule schedule = (IntervalSchedule) jobParameter.getSchedule();\n-            // TODO: handle jitter of job scheduler\n-            Instant endTime = Instant.now();\n-            Duration duration = Duration.of(schedule.getInterval(), schedule.getUnit());\n-            Instant startTime = endTime.minusMillis(duration.toMillis());\n-\n             AnomalyResultRequest request = new AnomalyResultRequest(\n                 jobParameter.getName(),\n                 startTime.toEpochMilli(),\n                 endTime.toEpochMilli()\n             );\n-            client.execute(AnomalyResultAction.INSTANCE, request, ActionListener.wrap(response -> {\n-                log.info(\"Anomaly result action ran successfully for \" + jobParameter.getName());\n-                releaseLock(jobParameter, lockService, lock);\n-            }, exception -> {\n-                log.error(\"Failed to execute anomaly result action\", exception);\n+            client\n+                .execute(\n+                    AnomalyResultAction.INSTANCE,\n+                    request,\n+                    ActionListener\n+                        .wrap(\n+                            response -> {\n+                                indexAnomalyResultSilently(\n+                                    jobParameter,\n+                                    lockService,\n+                                    lock,\n+                                    startTime,\n+                                    endTime,\n+                                    executionStartTime,\n+                                    response\n+                                );\n+                            },\n+                            exception -> {\n+                                handleAdException(\n+                                    jobParameter,\n+                                    lockService,\n+                                    lock,\n+                                    startTime,\n+                                    endTime,\n+                                    executionStartTime,\n+                                    backoff,\n+                                    exception\n+                                );\n+                            }\n+                        )\n+                );\n+        } catch (Exception e) {\n+            indexAnomalyResultExceptionSilently(jobParameter, startTime, endTime, executionStartTime, e);\n+            log.error(\"Failed to execute AD job \" + jobParameter.getName(), e);\n+            releaseLock(jobParameter, lockService, lock);\n+        }\n+    }\n+\n+    protected void handleAdException(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant startTime,\n+        Instant endTime,\n+        Instant executionStartTime,\n+        Iterator<TimeValue> backoff,\n+        Exception exception\n+    ) {\n+        if (exception instanceof EndRunException) {\n+            log.error(\"EndRunException happened when executed anomaly result action for \" + jobParameter.getName(), exception);\n+\n+            if (((EndRunException) exception).isEndNow()) {\n+                // Stop AD job if EndRunException shows we should end job now.\n+                stopAdJobSilently(jobParameter.getName());\n+                indexAnomalyResultExceptionSilently(\n+                    jobParameter,\n+                    startTime,\n+                    endTime,\n+                    executionStartTime,\n+                    \"Stopped detector: \" + exception.getMessage()\n+                );\n                 releaseLock(jobParameter, lockService, lock);\n-            }));\n+            } else {\n+                // retry AD job, if all retries failed or have no enough time to retry, will stop AD job.\n+                Schedule schedule = jobParameter.getSchedule();\n+                long nextExecutionTime = jobParameter.getSchedule().getNextExecutionTime(executionStartTime).toEpochMilli();\n+                long now = Instant.now().toEpochMilli();\n+                long leftTime = nextExecutionTime - now - JOB_RUN_BUFFER_IN_MILLISECONDS;\n+                long usedTime = now - executionStartTime.toEpochMilli();\n+\n+                if (!backoff.hasNext()) {\n+                    stopAdJobForEndRunException(\n+                        jobParameter,\n+                        lockService,\n+                        lock,\n+                        startTime,\n+                        endTime,\n+                        executionStartTime,\n+                        (EndRunException) exception\n+                    );\n+                } else {\n+                    if (backoff.hasNext()) {\n+                        TimeValue nextRunDelay = backoff.next();\n+                        if (leftTime > (usedTime + nextRunDelay.getMillis())) {\n+                            threadPool\n+                                .schedule(\n+                                    () -> runAdJob(jobParameter, lockService, lock, startTime, endTime, executionStartTime, backoff),\n+                                    nextRunDelay,\n+                                    ThreadPool.Names.SAME\n+                                );\n+                        } else {\n+                            stopAdJobForEndRunException(\n+                                jobParameter,\n+                                lockService,\n+                                lock,\n+                                startTime,\n+                                endTime,\n+                                executionStartTime,\n+                                (EndRunException) exception\n+                            );\n+                        }\n+                    }\n+                }\n+            }\n+        } else {\n+            if (exception instanceof InternalFailure) {\n+                // AnomalyResultTransportAction already prints exception stack trace\n+                log.error(\"InternalFailure happened when executed anomaly result action for \" + jobParameter.getName());\n+            } else {\n+                log.error(\"Failed to execute anomaly result action for \" + jobParameter.getName(), exception);\n+            }\n+            indexAnomalyResultExceptionSilently(jobParameter, startTime, endTime, executionStartTime, exception);\n+            releaseLock(jobParameter, lockService, lock);\n+        }\n+    }\n+\n+    private void stopAdJobForEndRunException(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant startTime,\n+        Instant endTime,\n+        Instant executionStartTime,\n+        EndRunException exception\n+    ) {\n+        stopAdJobSilently(jobParameter.getName());\n+        indexAnomalyResultExceptionSilently(\n+            jobParameter,\n+            startTime,\n+            endTime,\n+            executionStartTime,\n+            \"Stopped detector: \" + exception.getMessage()\n+        );\n+        releaseLock(jobParameter, lockService, lock);\n+    }\n+\n+    private void stopAdJobSilently(String detectorId) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "638af5d68495deb9d12f896cabdef1d12f70e51b"}, "originalPosition": 309}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTM4OTgwOQ==", "bodyText": "typo: responses", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r391389809", "createdAt": "2020-03-12T03:58:37Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/rest/handler/AnomalyDetectorFunction.java", "diffHunk": "@@ -21,7 +21,7 @@\n     /**\n      * Performs this operation.\n      *\n-     * Notes: don't forget to send back response via channel if you process response with this method.\n+     * Notes: don't forget to send back responds via channel if you process response with this method.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "638af5d68495deb9d12f896cabdef1d12f70e51b"}, "originalPosition": 5}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fcb22229ed6c0e18919d3b9c6ad24299b2bb8ed8", "author": {"user": {"login": "ylwu-amzn", "name": "Yaliang"}}, "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/fcb22229ed6c0e18919d3b9c6ad24299b2bb8ed8", "committedDate": "2020-03-12T16:06:34Z", "message": "fail AD job if fail consecutively more than limit times"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f15696cf35e0c7497679bd41332962b18917f519", "author": {"user": {"login": "ylwu-amzn", "name": "Yaliang"}}, "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/f15696cf35e0c7497679bd41332962b18917f519", "committedDate": "2020-03-12T16:32:56Z", "message": "fix typo"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc0MDMxOTI2", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#pullrequestreview-374031926", "createdAt": "2020-03-13T03:32:53Z", "commit": {"oid": "f15696cf35e0c7497679bd41332962b18917f519"}, "state": "COMMENTED", "comments": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xM1QwMzozMjo1NFrOF12rWQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xM1QwNTo1MzozNFrOF14V7g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjAxNDY4MQ==", "bodyText": "Since detectorEndRunExceptionCount does not depend on anything else to be initialized, you can put the initialization to your constructor and remove this method. I cannot think of a use case where we need to call this method after AnomalyDetectorRunner is initialized.  Also, it is easy for other people unfamiliar with the code to forget to call this method when initializing AnomalyDetectorRunner.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r392014681", "createdAt": "2020-03-13T03:32:54Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/AnomalyDetectorJobRunner.java", "diffHunk": "@@ -108,13 +109,18 @@ public void setAnomalyResultHandler(AnomalyResultHandler anomalyResultHandler) {\n         this.anomalyResultHandler = anomalyResultHandler;\n     }\n \n+    public void setDetectorEndRunExceptionCount(ConcurrentHashMap<String, Integer> detectorEndRunExceptionCount) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f15696cf35e0c7497679bd41332962b18917f519"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjAxNTYyOQ==", "bodyText": "We also need to remove a detector id from detectorEndRunExceptionCount if we get non-EndRunException.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r392015629", "createdAt": "2020-03-13T03:37:02Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/AnomalyDetectorJobRunner.java", "diffHunk": "@@ -194,43 +198,19 @@ protected void runAdJob(\n             AnomalyResultRequest request = new AnomalyResultRequest(\n                 jobParameter.getName(),\n                 startTime.toEpochMilli(),\n-                endTime.toEpochMilli()\n+                executionStartTime.toEpochMilli()\n             );\n-            client\n-                .execute(\n-                    AnomalyResultAction.INSTANCE,\n-                    request,\n-                    ActionListener\n-                        .wrap(\n-                            response -> {\n-                                indexAnomalyResultSilently(\n-                                    jobParameter,\n-                                    lockService,\n-                                    lock,\n-                                    startTime,\n-                                    endTime,\n-                                    executionStartTime,\n-                                    response\n-                                );\n-                            },\n-                            exception -> {\n-                                handleAdException(\n-                                    jobParameter,\n-                                    lockService,\n-                                    lock,\n-                                    startTime,\n-                                    endTime,\n-                                    executionStartTime,\n-                                    backoff,\n-                                    exception\n-                                );\n-                            }\n-                        )\n-                );\n+            client.execute(AnomalyResultAction.INSTANCE, request, ActionListener.wrap(response -> {\n+                indexAnomalyResult(jobParameter, lockService, lock, startTime, executionStartTime, response);\n+                detectorEndRunExceptionCount.remove(jobParameter.getName());\n+            },\n+                exception -> {\n+                    handleAdException(jobParameter, lockService, lock, startTime, executionStartTime, backoff, retryTimes, exception);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f15696cf35e0c7497679bd41332962b18917f519"}, "originalPosition": 145}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjAxNTY4OA==", "bodyText": "the key is detector id.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r392015688", "createdAt": "2020-03-13T03:37:27Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/AnomalyDetectorJobRunner.java", "diffHunk": "@@ -194,43 +198,19 @@ protected void runAdJob(\n             AnomalyResultRequest request = new AnomalyResultRequest(\n                 jobParameter.getName(),\n                 startTime.toEpochMilli(),\n-                endTime.toEpochMilli()\n+                executionStartTime.toEpochMilli()\n             );\n-            client\n-                .execute(\n-                    AnomalyResultAction.INSTANCE,\n-                    request,\n-                    ActionListener\n-                        .wrap(\n-                            response -> {\n-                                indexAnomalyResultSilently(\n-                                    jobParameter,\n-                                    lockService,\n-                                    lock,\n-                                    startTime,\n-                                    endTime,\n-                                    executionStartTime,\n-                                    response\n-                                );\n-                            },\n-                            exception -> {\n-                                handleAdException(\n-                                    jobParameter,\n-                                    lockService,\n-                                    lock,\n-                                    startTime,\n-                                    endTime,\n-                                    executionStartTime,\n-                                    backoff,\n-                                    exception\n-                                );\n-                            }\n-                        )\n-                );\n+            client.execute(AnomalyResultAction.INSTANCE, request, ActionListener.wrap(response -> {\n+                indexAnomalyResult(jobParameter, lockService, lock, startTime, executionStartTime, response);\n+                detectorEndRunExceptionCount.remove(jobParameter.getName());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f15696cf35e0c7497679bd41332962b18917f519"}, "originalPosition": 142}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjAxNTcyMQ==", "bodyText": "the key is detector id.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r392015721", "createdAt": "2020-03-13T03:37:37Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/AnomalyDetectorJobRunner.java", "diffHunk": "@@ -317,22 +307,23 @@ private void stopAdJobForEndRunException(\n         LockService lockService,\n         LockModel lock,\n         Instant startTime,\n-        Instant endTime,\n         Instant executionStartTime,\n         EndRunException exception\n     ) {\n-        stopAdJobSilently(jobParameter.getName());\n-        indexAnomalyResultExceptionSilently(\n+        detectorEndRunExceptionCount.remove(jobParameter.getName());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f15696cf35e0c7497679bd41332962b18917f519"}, "originalPosition": 287}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjAyNjAyOA==", "bodyText": "After much thought, I am still inclined to remove the backoff retry because we don't have a clear use case a quick retry is needed and there are complications for the backoff retry.  This is the 3 cases where EndRunException is thrown with endNow being false:\n\ntraining data for cold start not available\ncold start cannot succeed\nunknown prediction error\n\nTwo of the causes are related to cold start. Let's discuss it one by one:\n\ntraining data for cold start not available: the situation won't improve within seconds.\ncold start cannot succeed and unknown prediction error: this indicates some bugs of our side and  system heavy load.  Quick retry does not help.\n\nSome complications of retry quickly:\n\nCold start is expensive as it runs 24 queries, initializing models, and saving checkpoints. Retry cold start quickly can impose performance pressure.\n10 seconds buffer might not be enough to prevent multiple cold starts (started by backoff retry and AD job) at the same time as cold start cannot finish within a few seconds.  Lai once said it takes about 20~30 seconds.  The process can take longer if customers' feature queries are  complex and we have more features.  Hanguang's cancel would only apply if there are prediction queries for current window running.  Cancel won't happen when current window queries finish, but we are running 24 queries for cold start, initializing models and saving checkpoints.\nWe are using our own threadpool and it is limited by 1/4 cores.  Retry uses threadpool and may slow down other jobs' running.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r392026028", "createdAt": "2020-03-13T04:33:01Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/AnomalyDetectorJobRunner.java", "diffHunk": "@@ -106,36 +174,303 @@ public void runJob(ScheduledJobParameter jobParameter, JobExecutionContext conte\n         executor.submit(runnable);\n     }\n \n-    protected void runAdJob(ScheduledJobParameter jobParameter, LockService lockService, LockModel lock) {\n+    protected void runAdJob(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant startTime,\n+        Instant executionStartTime,\n+        Iterator<TimeValue> backoff,\n+        int retryTimes\n+    ) {\n+\n         if (lock == null) {\n+            indexAnomalyResultException(\n+                jobParameter,\n+                startTime,\n+                executionStartTime,\n+                new AnomalyDetectionException(jobParameter.getName(), \"Can't run AD job due to null lock\")\n+            );\n             return;\n         }\n \n         try {\n-            IntervalSchedule schedule = (IntervalSchedule) jobParameter.getSchedule();\n-            // TODO: handle jitter of job scheduler\n-            Instant endTime = Instant.now();\n-            Duration duration = Duration.of(schedule.getInterval(), schedule.getUnit());\n-            Instant startTime = endTime.minusMillis(duration.toMillis());\n-\n             AnomalyResultRequest request = new AnomalyResultRequest(\n                 jobParameter.getName(),\n                 startTime.toEpochMilli(),\n-                endTime.toEpochMilli()\n+                executionStartTime.toEpochMilli()\n             );\n             client.execute(AnomalyResultAction.INSTANCE, request, ActionListener.wrap(response -> {\n-                log.info(\"Anomaly result action ran successfully for \" + jobParameter.getName());\n-                releaseLock(jobParameter, lockService, lock);\n-            }, exception -> {\n-                log.error(\"Failed to execute anomaly result action\", exception);\n-                releaseLock(jobParameter, lockService, lock);\n-            }));\n+                indexAnomalyResult(jobParameter, lockService, lock, startTime, executionStartTime, response);\n+                detectorEndRunExceptionCount.remove(jobParameter.getName());\n+            },\n+                exception -> {\n+                    handleAdException(jobParameter, lockService, lock, startTime, executionStartTime, backoff, retryTimes, exception);\n+                }\n+            ));\n+        } catch (Exception e) {\n+            indexAnomalyResultException(jobParameter, lockService, lock, startTime, executionStartTime, e, true);\n+            log.error(\"Failed to execute AD job \" + jobParameter.getName(), e);\n+        }\n+    }\n+\n+    protected void handleAdException(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant startTime,\n+        Instant executionStartTime,\n+        Iterator<TimeValue> backoff,\n+        int retryTimes,\n+        Exception exception\n+    ) {\n+        String detectorId = jobParameter.getName();\n+        if (exception instanceof EndRunException) {\n+            log.error(\"EndRunException happened when executed anomaly result action for \" + detectorId, exception);\n+\n+            if (((EndRunException) exception).isEndNow()) {\n+                detectorEndRunExceptionCount.remove(detectorId);\n+                // Stop AD job if EndRunException shows we should end job now.\n+                stopAdJob(detectorId);\n+                indexAnomalyResultException(\n+                    jobParameter,\n+                    lockService,\n+                    lock,\n+                    startTime,\n+                    executionStartTime,\n+                    \"Stopped detector: \" + exception.getMessage(),\n+                    true\n+                );\n+            } else {\n+                detectorEndRunExceptionCount.compute(detectorId, (k, v) -> {\n+                    if (v == null) {\n+                        return 1;\n+                    } else if (retryTimes == 0) {\n+                        return v + 1;\n+                    } else {\n+                        return v;\n+                    }\n+                });\n+                // if AD job failed consecutively due to EndRunException and failed times exceeds upper limit, will stop AD job\n+                if (detectorEndRunExceptionCount.get(detectorId) > maxRetryForEndRunException) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f15696cf35e0c7497679bd41332962b18917f519"}, "originalPosition": 238}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjAyODIwNQ==", "bodyText": "I was confused at the beginning when looking at this line.  Wondering when retryTimes is 0.  Then I realized every time a new AD job run would set retryTimes to 0.  retryTimes is more of a signal to increment the count by 1 instead of the real retry times of the detector.  Is my understanding correct?\nI suggest the following to simplify:\nFirst, detectorEndRunExceptionCount for a detector id is removed from the map whenever we have a successful run or an exception that is not EndRunException.\nSecond, every time an EndRunException exception is caught, add count.  Insert the mapping if the detector id is not present. Then check if the count has reached the threshold, and stop if it is.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r392028205", "createdAt": "2020-03-13T04:45:26Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/AnomalyDetectorJobRunner.java", "diffHunk": "@@ -106,36 +174,303 @@ public void runJob(ScheduledJobParameter jobParameter, JobExecutionContext conte\n         executor.submit(runnable);\n     }\n \n-    protected void runAdJob(ScheduledJobParameter jobParameter, LockService lockService, LockModel lock) {\n+    protected void runAdJob(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant startTime,\n+        Instant executionStartTime,\n+        Iterator<TimeValue> backoff,\n+        int retryTimes\n+    ) {\n+\n         if (lock == null) {\n+            indexAnomalyResultException(\n+                jobParameter,\n+                startTime,\n+                executionStartTime,\n+                new AnomalyDetectionException(jobParameter.getName(), \"Can't run AD job due to null lock\")\n+            );\n             return;\n         }\n \n         try {\n-            IntervalSchedule schedule = (IntervalSchedule) jobParameter.getSchedule();\n-            // TODO: handle jitter of job scheduler\n-            Instant endTime = Instant.now();\n-            Duration duration = Duration.of(schedule.getInterval(), schedule.getUnit());\n-            Instant startTime = endTime.minusMillis(duration.toMillis());\n-\n             AnomalyResultRequest request = new AnomalyResultRequest(\n                 jobParameter.getName(),\n                 startTime.toEpochMilli(),\n-                endTime.toEpochMilli()\n+                executionStartTime.toEpochMilli()\n             );\n             client.execute(AnomalyResultAction.INSTANCE, request, ActionListener.wrap(response -> {\n-                log.info(\"Anomaly result action ran successfully for \" + jobParameter.getName());\n-                releaseLock(jobParameter, lockService, lock);\n-            }, exception -> {\n-                log.error(\"Failed to execute anomaly result action\", exception);\n-                releaseLock(jobParameter, lockService, lock);\n-            }));\n+                indexAnomalyResult(jobParameter, lockService, lock, startTime, executionStartTime, response);\n+                detectorEndRunExceptionCount.remove(jobParameter.getName());\n+            },\n+                exception -> {\n+                    handleAdException(jobParameter, lockService, lock, startTime, executionStartTime, backoff, retryTimes, exception);\n+                }\n+            ));\n+        } catch (Exception e) {\n+            indexAnomalyResultException(jobParameter, lockService, lock, startTime, executionStartTime, e, true);\n+            log.error(\"Failed to execute AD job \" + jobParameter.getName(), e);\n+        }\n+    }\n+\n+    protected void handleAdException(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant startTime,\n+        Instant executionStartTime,\n+        Iterator<TimeValue> backoff,\n+        int retryTimes,\n+        Exception exception\n+    ) {\n+        String detectorId = jobParameter.getName();\n+        if (exception instanceof EndRunException) {\n+            log.error(\"EndRunException happened when executed anomaly result action for \" + detectorId, exception);\n+\n+            if (((EndRunException) exception).isEndNow()) {\n+                detectorEndRunExceptionCount.remove(detectorId);\n+                // Stop AD job if EndRunException shows we should end job now.\n+                stopAdJob(detectorId);\n+                indexAnomalyResultException(\n+                    jobParameter,\n+                    lockService,\n+                    lock,\n+                    startTime,\n+                    executionStartTime,\n+                    \"Stopped detector: \" + exception.getMessage(),\n+                    true\n+                );\n+            } else {\n+                detectorEndRunExceptionCount.compute(detectorId, (k, v) -> {\n+                    if (v == null) {\n+                        return 1;\n+                    } else if (retryTimes == 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f15696cf35e0c7497679bd41332962b18917f519"}, "originalPosition": 231}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjAzMDcxMA==", "bodyText": "rename to currentJobStartTime and lastJobStartTime as it is not clear what is the difference between startTime and executionStartTime?  If you agree, please change related code.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r392030710", "createdAt": "2020-03-13T04:58:38Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/AnomalyDetectorJobRunner.java", "diffHunk": "@@ -132,8 +138,7 @@ public void runJob(ScheduledJobParameter jobParameter, JobExecutionContext conte\n \n         Instant executionStartTime = Instant.now();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f15696cf35e0c7497679bd41332962b18917f519"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjAzNDY1NQ==", "bodyText": "would we have double lock release since your code in the try block can release the lock?  How about adding a isLockReleasedOrExpired before release?", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r392034655", "createdAt": "2020-03-13T05:18:32Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/AnomalyDetectorJobRunner.java", "diffHunk": "@@ -106,36 +174,303 @@ public void runJob(ScheduledJobParameter jobParameter, JobExecutionContext conte\n         executor.submit(runnable);\n     }\n \n-    protected void runAdJob(ScheduledJobParameter jobParameter, LockService lockService, LockModel lock) {\n+    protected void runAdJob(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant startTime,\n+        Instant executionStartTime,\n+        Iterator<TimeValue> backoff,\n+        int retryTimes\n+    ) {\n+\n         if (lock == null) {\n+            indexAnomalyResultException(\n+                jobParameter,\n+                startTime,\n+                executionStartTime,\n+                new AnomalyDetectionException(jobParameter.getName(), \"Can't run AD job due to null lock\")\n+            );\n             return;\n         }\n \n         try {\n-            IntervalSchedule schedule = (IntervalSchedule) jobParameter.getSchedule();\n-            // TODO: handle jitter of job scheduler\n-            Instant endTime = Instant.now();\n-            Duration duration = Duration.of(schedule.getInterval(), schedule.getUnit());\n-            Instant startTime = endTime.minusMillis(duration.toMillis());\n-\n             AnomalyResultRequest request = new AnomalyResultRequest(\n                 jobParameter.getName(),\n                 startTime.toEpochMilli(),\n-                endTime.toEpochMilli()\n+                executionStartTime.toEpochMilli()\n             );\n             client.execute(AnomalyResultAction.INSTANCE, request, ActionListener.wrap(response -> {\n-                log.info(\"Anomaly result action ran successfully for \" + jobParameter.getName());\n-                releaseLock(jobParameter, lockService, lock);\n-            }, exception -> {\n-                log.error(\"Failed to execute anomaly result action\", exception);\n-                releaseLock(jobParameter, lockService, lock);\n-            }));\n+                indexAnomalyResult(jobParameter, lockService, lock, startTime, executionStartTime, response);\n+                detectorEndRunExceptionCount.remove(jobParameter.getName());\n+            },\n+                exception -> {\n+                    handleAdException(jobParameter, lockService, lock, startTime, executionStartTime, backoff, retryTimes, exception);\n+                }\n+            ));\n+        } catch (Exception e) {\n+            indexAnomalyResultException(jobParameter, lockService, lock, startTime, executionStartTime, e, true);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f15696cf35e0c7497679bd41332962b18917f519"}, "originalPosition": 195}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjAzODM0Mw==", "bodyText": "Are line 232~243 the same thing as stopAdJobForEndRunException ?", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r392038343", "createdAt": "2020-03-13T05:37:15Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/AnomalyDetectorJobRunner.java", "diffHunk": "@@ -106,36 +174,303 @@ public void runJob(ScheduledJobParameter jobParameter, JobExecutionContext conte\n         executor.submit(runnable);\n     }\n \n-    protected void runAdJob(ScheduledJobParameter jobParameter, LockService lockService, LockModel lock) {\n+    protected void runAdJob(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant startTime,\n+        Instant executionStartTime,\n+        Iterator<TimeValue> backoff,\n+        int retryTimes\n+    ) {\n+\n         if (lock == null) {\n+            indexAnomalyResultException(\n+                jobParameter,\n+                startTime,\n+                executionStartTime,\n+                new AnomalyDetectionException(jobParameter.getName(), \"Can't run AD job due to null lock\")\n+            );\n             return;\n         }\n \n         try {\n-            IntervalSchedule schedule = (IntervalSchedule) jobParameter.getSchedule();\n-            // TODO: handle jitter of job scheduler\n-            Instant endTime = Instant.now();\n-            Duration duration = Duration.of(schedule.getInterval(), schedule.getUnit());\n-            Instant startTime = endTime.minusMillis(duration.toMillis());\n-\n             AnomalyResultRequest request = new AnomalyResultRequest(\n                 jobParameter.getName(),\n                 startTime.toEpochMilli(),\n-                endTime.toEpochMilli()\n+                executionStartTime.toEpochMilli()\n             );\n             client.execute(AnomalyResultAction.INSTANCE, request, ActionListener.wrap(response -> {\n-                log.info(\"Anomaly result action ran successfully for \" + jobParameter.getName());\n-                releaseLock(jobParameter, lockService, lock);\n-            }, exception -> {\n-                log.error(\"Failed to execute anomaly result action\", exception);\n-                releaseLock(jobParameter, lockService, lock);\n-            }));\n+                indexAnomalyResult(jobParameter, lockService, lock, startTime, executionStartTime, response);\n+                detectorEndRunExceptionCount.remove(jobParameter.getName());\n+            },\n+                exception -> {\n+                    handleAdException(jobParameter, lockService, lock, startTime, executionStartTime, backoff, retryTimes, exception);\n+                }\n+            ));\n+        } catch (Exception e) {\n+            indexAnomalyResultException(jobParameter, lockService, lock, startTime, executionStartTime, e, true);\n+            log.error(\"Failed to execute AD job \" + jobParameter.getName(), e);\n+        }\n+    }\n+\n+    protected void handleAdException(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant startTime,\n+        Instant executionStartTime,\n+        Iterator<TimeValue> backoff,\n+        int retryTimes,\n+        Exception exception\n+    ) {\n+        String detectorId = jobParameter.getName();\n+        if (exception instanceof EndRunException) {\n+            log.error(\"EndRunException happened when executed anomaly result action for \" + detectorId, exception);\n+\n+            if (((EndRunException) exception).isEndNow()) {\n+                detectorEndRunExceptionCount.remove(detectorId);\n+                // Stop AD job if EndRunException shows we should end job now.\n+                stopAdJob(detectorId);\n+                indexAnomalyResultException(\n+                    jobParameter,\n+                    lockService,\n+                    lock,\n+                    startTime,\n+                    executionStartTime,\n+                    \"Stopped detector: \" + exception.getMessage(),\n+                    true", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f15696cf35e0c7497679bd41332962b18917f519"}, "originalPosition": 225}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjAzODQzMw==", "bodyText": "the key is detector id.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r392038433", "createdAt": "2020-03-13T05:37:42Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/AnomalyDetectorJobRunner.java", "diffHunk": "@@ -106,36 +174,303 @@ public void runJob(ScheduledJobParameter jobParameter, JobExecutionContext conte\n         executor.submit(runnable);\n     }\n \n-    protected void runAdJob(ScheduledJobParameter jobParameter, LockService lockService, LockModel lock) {\n+    protected void runAdJob(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant startTime,\n+        Instant executionStartTime,\n+        Iterator<TimeValue> backoff,\n+        int retryTimes\n+    ) {\n+\n         if (lock == null) {\n+            indexAnomalyResultException(\n+                jobParameter,\n+                startTime,\n+                executionStartTime,\n+                new AnomalyDetectionException(jobParameter.getName(), \"Can't run AD job due to null lock\")\n+            );\n             return;\n         }\n \n         try {\n-            IntervalSchedule schedule = (IntervalSchedule) jobParameter.getSchedule();\n-            // TODO: handle jitter of job scheduler\n-            Instant endTime = Instant.now();\n-            Duration duration = Duration.of(schedule.getInterval(), schedule.getUnit());\n-            Instant startTime = endTime.minusMillis(duration.toMillis());\n-\n             AnomalyResultRequest request = new AnomalyResultRequest(\n                 jobParameter.getName(),\n                 startTime.toEpochMilli(),\n-                endTime.toEpochMilli()\n+                executionStartTime.toEpochMilli()\n             );\n             client.execute(AnomalyResultAction.INSTANCE, request, ActionListener.wrap(response -> {\n-                log.info(\"Anomaly result action ran successfully for \" + jobParameter.getName());\n-                releaseLock(jobParameter, lockService, lock);\n-            }, exception -> {\n-                log.error(\"Failed to execute anomaly result action\", exception);\n-                releaseLock(jobParameter, lockService, lock);\n-            }));\n+                indexAnomalyResult(jobParameter, lockService, lock, startTime, executionStartTime, response);\n+                detectorEndRunExceptionCount.remove(jobParameter.getName());\n+            },\n+                exception -> {\n+                    handleAdException(jobParameter, lockService, lock, startTime, executionStartTime, backoff, retryTimes, exception);\n+                }\n+            ));\n+        } catch (Exception e) {\n+            indexAnomalyResultException(jobParameter, lockService, lock, startTime, executionStartTime, e, true);\n+            log.error(\"Failed to execute AD job \" + jobParameter.getName(), e);\n+        }\n+    }\n+\n+    protected void handleAdException(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant startTime,\n+        Instant executionStartTime,\n+        Iterator<TimeValue> backoff,\n+        int retryTimes,\n+        Exception exception\n+    ) {\n+        String detectorId = jobParameter.getName();\n+        if (exception instanceof EndRunException) {\n+            log.error(\"EndRunException happened when executed anomaly result action for \" + detectorId, exception);\n+\n+            if (((EndRunException) exception).isEndNow()) {\n+                detectorEndRunExceptionCount.remove(detectorId);\n+                // Stop AD job if EndRunException shows we should end job now.\n+                stopAdJob(detectorId);\n+                indexAnomalyResultException(\n+                    jobParameter,\n+                    lockService,\n+                    lock,\n+                    startTime,\n+                    executionStartTime,\n+                    \"Stopped detector: \" + exception.getMessage(),\n+                    true\n+                );\n+            } else {\n+                detectorEndRunExceptionCount.compute(detectorId, (k, v) -> {\n+                    if (v == null) {\n+                        return 1;\n+                    } else if (retryTimes == 0) {\n+                        return v + 1;\n+                    } else {\n+                        return v;\n+                    }\n+                });\n+                // if AD job failed consecutively due to EndRunException and failed times exceeds upper limit, will stop AD job\n+                if (detectorEndRunExceptionCount.get(detectorId) > maxRetryForEndRunException) {\n+                    stopAdJobForEndRunException(\n+                        jobParameter,\n+                        lockService,\n+                        lock,\n+                        startTime,\n+                        executionStartTime,\n+                        (EndRunException) exception\n+                    );\n+                    return;\n+                }\n+                // retry AD job, if all retries failed or have no enough time to retry, will record exception in AD result.\n+                Schedule schedule = jobParameter.getSchedule();\n+                long nextExecutionTime = jobParameter.getSchedule().getNextExecutionTime(executionStartTime).toEpochMilli();\n+                long now = Instant.now().toEpochMilli();\n+                long leftTime = nextExecutionTime - now - JOB_RUN_BUFFER_IN_MILLISECONDS;\n+                long usedTime = now - executionStartTime.toEpochMilli();\n+\n+                TimeValue nextRunDelay = backoff.hasNext() ? backoff.next() : null;\n+\n+                if (nextRunDelay != null && leftTime > (usedTime + nextRunDelay.getMillis())) {\n+                    threadPool\n+                        .schedule(\n+                            () -> runAdJob(jobParameter, lockService, lock, startTime, executionStartTime, backoff, retryTimes + 1),\n+                            nextRunDelay,\n+                            ThreadPool.Names.SAME\n+                        );\n+                } else {\n+                    indexAnomalyResultException(\n+                        jobParameter,\n+                        lockService,\n+                        lock,\n+                        startTime,\n+                        executionStartTime,\n+                        exception.getMessage(),\n+                        true\n+                    );\n+                }\n+            }\n+        } else {\n+            if (exception instanceof InternalFailure) {\n+                // AnomalyResultTransportAction already prints exception stack trace\n+                log.error(\"InternalFailure happened when executed anomaly result action for \" + jobParameter.getName());\n+            } else {\n+                log.error(\"Failed to execute anomaly result action for \" + jobParameter.getName(), exception);\n+            }\n+            indexAnomalyResultException(jobParameter, lockService, lock, startTime, executionStartTime, exception, true);\n+        }\n+    }\n+\n+    private void stopAdJobForEndRunException(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant startTime,\n+        Instant executionStartTime,\n+        EndRunException exception\n+    ) {\n+        detectorEndRunExceptionCount.remove(jobParameter.getName());\n+        stopAdJob(jobParameter.getName());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f15696cf35e0c7497679bd41332962b18917f519"}, "originalPosition": 297}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjA0MTk2Ng==", "bodyText": "So as long as we have 10 secs (JOB_RUN_BUFFER_IN_MILLISECONDS), and backoff has available retries, we would retry?", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r392041966", "createdAt": "2020-03-13T05:53:34Z", "author": {"login": "kaituo"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/AnomalyDetectorJobRunner.java", "diffHunk": "@@ -106,36 +174,303 @@ public void runJob(ScheduledJobParameter jobParameter, JobExecutionContext conte\n         executor.submit(runnable);\n     }\n \n-    protected void runAdJob(ScheduledJobParameter jobParameter, LockService lockService, LockModel lock) {\n+    protected void runAdJob(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant startTime,\n+        Instant executionStartTime,\n+        Iterator<TimeValue> backoff,\n+        int retryTimes\n+    ) {\n+\n         if (lock == null) {\n+            indexAnomalyResultException(\n+                jobParameter,\n+                startTime,\n+                executionStartTime,\n+                new AnomalyDetectionException(jobParameter.getName(), \"Can't run AD job due to null lock\")\n+            );\n             return;\n         }\n \n         try {\n-            IntervalSchedule schedule = (IntervalSchedule) jobParameter.getSchedule();\n-            // TODO: handle jitter of job scheduler\n-            Instant endTime = Instant.now();\n-            Duration duration = Duration.of(schedule.getInterval(), schedule.getUnit());\n-            Instant startTime = endTime.minusMillis(duration.toMillis());\n-\n             AnomalyResultRequest request = new AnomalyResultRequest(\n                 jobParameter.getName(),\n                 startTime.toEpochMilli(),\n-                endTime.toEpochMilli()\n+                executionStartTime.toEpochMilli()\n             );\n             client.execute(AnomalyResultAction.INSTANCE, request, ActionListener.wrap(response -> {\n-                log.info(\"Anomaly result action ran successfully for \" + jobParameter.getName());\n-                releaseLock(jobParameter, lockService, lock);\n-            }, exception -> {\n-                log.error(\"Failed to execute anomaly result action\", exception);\n-                releaseLock(jobParameter, lockService, lock);\n-            }));\n+                indexAnomalyResult(jobParameter, lockService, lock, startTime, executionStartTime, response);\n+                detectorEndRunExceptionCount.remove(jobParameter.getName());\n+            },\n+                exception -> {\n+                    handleAdException(jobParameter, lockService, lock, startTime, executionStartTime, backoff, retryTimes, exception);\n+                }\n+            ));\n+        } catch (Exception e) {\n+            indexAnomalyResultException(jobParameter, lockService, lock, startTime, executionStartTime, e, true);\n+            log.error(\"Failed to execute AD job \" + jobParameter.getName(), e);\n+        }\n+    }\n+\n+    protected void handleAdException(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant startTime,\n+        Instant executionStartTime,\n+        Iterator<TimeValue> backoff,\n+        int retryTimes,\n+        Exception exception\n+    ) {\n+        String detectorId = jobParameter.getName();\n+        if (exception instanceof EndRunException) {\n+            log.error(\"EndRunException happened when executed anomaly result action for \" + detectorId, exception);\n+\n+            if (((EndRunException) exception).isEndNow()) {\n+                detectorEndRunExceptionCount.remove(detectorId);\n+                // Stop AD job if EndRunException shows we should end job now.\n+                stopAdJob(detectorId);\n+                indexAnomalyResultException(\n+                    jobParameter,\n+                    lockService,\n+                    lock,\n+                    startTime,\n+                    executionStartTime,\n+                    \"Stopped detector: \" + exception.getMessage(),\n+                    true\n+                );\n+            } else {\n+                detectorEndRunExceptionCount.compute(detectorId, (k, v) -> {\n+                    if (v == null) {\n+                        return 1;\n+                    } else if (retryTimes == 0) {\n+                        return v + 1;\n+                    } else {\n+                        return v;\n+                    }\n+                });\n+                // if AD job failed consecutively due to EndRunException and failed times exceeds upper limit, will stop AD job\n+                if (detectorEndRunExceptionCount.get(detectorId) > maxRetryForEndRunException) {\n+                    stopAdJobForEndRunException(\n+                        jobParameter,\n+                        lockService,\n+                        lock,\n+                        startTime,\n+                        executionStartTime,\n+                        (EndRunException) exception\n+                    );\n+                    return;\n+                }\n+                // retry AD job, if all retries failed or have no enough time to retry, will record exception in AD result.\n+                Schedule schedule = jobParameter.getSchedule();\n+                long nextExecutionTime = jobParameter.getSchedule().getNextExecutionTime(executionStartTime).toEpochMilli();\n+                long now = Instant.now().toEpochMilli();\n+                long leftTime = nextExecutionTime - now - JOB_RUN_BUFFER_IN_MILLISECONDS;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f15696cf35e0c7497679bd41332962b18917f519"}, "originalPosition": 253}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "84ea1c1960c2fd7690872ea3372d73050faa48a1", "author": {"user": {"login": "ylwu-amzn", "name": "Yaliang"}}, "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/84ea1c1960c2fd7690872ea3372d73050faa48a1", "committedDate": "2020-03-13T22:35:41Z", "message": "tune variable name"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3ab3c170d40fd58f11e517fdd25e6256df2cef53", "author": {"user": {"login": "ylwu-amzn", "name": "Yaliang"}}, "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/3ab3c170d40fd58f11e517fdd25e6256df2cef53", "committedDate": "2020-03-14T03:11:47Z", "message": "remove backoff retry"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc0OTgzNjk4", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#pullrequestreview-374983698", "createdAt": "2020-03-16T08:03:36Z", "commit": {"oid": "3ab3c170d40fd58f11e517fdd25e6256df2cef53"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9fcfd11b7c8dd0a018e0ac2bdd22711827cb348c", "author": {"user": {"login": "ylwu-amzn", "name": "Yaliang"}}, "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/9fcfd11b7c8dd0a018e0ac2bdd22711827cb348c", "committedDate": "2020-03-16T17:13:01Z", "message": "Merge branch 'development' into development"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc1NDcxMDE4", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#pullrequestreview-375471018", "createdAt": "2020-03-16T18:13:49Z", "commit": {"oid": "9fcfd11b7c8dd0a018e0ac2bdd22711827cb348c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQxODoxMzo1MFrOF3AYtw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQxODoxMzo1MFrOF3AYtw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzIyMjMyNw==", "bodyText": "Do we have issue for such TODO? Just don't want to lose track of such improvement idea in the future.", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r393222327", "createdAt": "2020-03-16T18:13:50Z", "author": {"login": "yizheliu-amazon"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/AnomalyDetectorJobRunner.java", "diffHunk": "@@ -90,60 +133,368 @@ public void runJob(ScheduledJobParameter jobParameter, JobExecutionContext conte\n                         jobParameter,\n                         context,\n                         ActionListener\n-                            .wrap(\n-                                lock -> runAdJob(jobParameter, lockService, lock),\n-                                exception -> {\n-                                    throw new IllegalStateException(\"Failed to acquire lock for AD job: \" + jobParameter.getName());\n-                                }\n-                            )\n+                            .wrap(lock -> runAdJob(jobParameter, lockService, lock, detectionStartTime, executionStartTime), exception -> {\n+                                indexAnomalyResultException(\n+                                    jobParameter,\n+                                    lockService,\n+                                    null,\n+                                    detectionStartTime,\n+                                    executionStartTime,\n+                                    exception,\n+                                    false\n+                                );\n+                                throw new IllegalStateException(\"Failed to acquire lock for AD job: \" + detectorId);\n+                            })\n                     );\n             } else {\n-                log.warn(\"Can't get lock for AD job: \" + jobParameter.getName());\n+                log.warn(\"Can't get lock for AD job: \" + detectorId);\n             }\n         };\n \n         ExecutorService executor = threadPool.executor(AD_THREAD_POOL_NAME);\n         executor.submit(runnable);\n     }\n \n-    protected void runAdJob(ScheduledJobParameter jobParameter, LockService lockService, LockModel lock) {\n+    /**\n+     * Get anomaly result, index result or handle exception if failed.\n+     *\n+     * @param jobParameter scheduled job parameter\n+     * @param lockService lock service\n+     * @param lock lock to run job\n+     * @param detectionStartTime detection start time\n+     * @param executionStartTime detection end time\n+     */\n+    protected void runAdJob(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant detectionStartTime,\n+        Instant executionStartTime\n+    ) {\n+        String detectorId = jobParameter.getName();\n         if (lock == null) {\n+            indexAnomalyResultException(\n+                jobParameter,\n+                lockService,\n+                lock,\n+                detectionStartTime,\n+                executionStartTime,\n+                \"Can't run AD job due to null lock\",\n+                false\n+            );\n             return;\n         }\n \n         try {\n-            IntervalSchedule schedule = (IntervalSchedule) jobParameter.getSchedule();\n-            // TODO: handle jitter of job scheduler\n-            Instant endTime = Instant.now();\n-            Duration duration = Duration.of(schedule.getInterval(), schedule.getUnit());\n-            Instant startTime = endTime.minusMillis(duration.toMillis());\n-\n             AnomalyResultRequest request = new AnomalyResultRequest(\n-                jobParameter.getName(),\n-                startTime.toEpochMilli(),\n-                endTime.toEpochMilli()\n+                detectorId,\n+                detectionStartTime.toEpochMilli(),\n+                executionStartTime.toEpochMilli()\n             );\n-            client.execute(AnomalyResultAction.INSTANCE, request, ActionListener.wrap(response -> {\n-                log.info(\"Anomaly result action ran successfully for \" + jobParameter.getName());\n-                releaseLock(jobParameter, lockService, lock);\n-            }, exception -> {\n-                log.error(\"Failed to execute anomaly result action\", exception);\n-                releaseLock(jobParameter, lockService, lock);\n-            }));\n+            client\n+                .execute(\n+                    AnomalyResultAction.INSTANCE,\n+                    request,\n+                    ActionListener\n+                        .wrap(\n+                            response -> {\n+                                indexAnomalyResult(jobParameter, lockService, lock, detectionStartTime, executionStartTime, response);\n+                            },\n+                            exception -> {\n+                                handleAdException(jobParameter, lockService, lock, detectionStartTime, executionStartTime, exception);\n+                            }\n+                        )\n+                );\n+        } catch (Exception e) {\n+            indexAnomalyResultException(jobParameter, lockService, lock, detectionStartTime, executionStartTime, e, true);\n+            log.error(\"Failed to execute AD job \" + detectorId, e);\n+        }\n+    }\n+\n+    /**\n+     * Handle exception from anomaly result action.\n+     *\n+     * 1. If exception is {@link EndRunException}\n+     *   a). if isEndNow == true, stop AD job and store exception in anomaly result\n+     *   b). if isEndNow == false, record count of {@link EndRunException} for this\n+     *       detector. If count of {@link EndRunException} exceeds upper limit, will\n+     *       stop AD job and store exception in anomaly result; otherwise, just\n+     *       store exception in anomaly result, not stop AD job for the detector.\n+     *\n+     * 2. If exception is not {@link EndRunException}, decrease count of\n+     *    {@link EndRunException} for the detector and index eception in Anomaly\n+     *    result. If exception is {@link InternalFailure}, will not log exception\n+     *    stack trace as already logged in {@link AnomalyResultTransportAction}.\n+     *\n+     * TODO: Handle finer granularity exception such as some exception may be", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9fcfd11b7c8dd0a018e0ac2bdd22711827cb348c"}, "originalPosition": 233}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc1NDcxMjM3", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#pullrequestreview-375471237", "createdAt": "2020-03-16T18:14:07Z", "commit": {"oid": "9fcfd11b7c8dd0a018e0ac2bdd22711827cb348c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQxODoxNDowOFrOF3AZZw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQxODoxNDowOFrOF3AZZw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzIyMjUwMw==", "bodyText": "nit: typo: heavy", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r393222503", "createdAt": "2020-03-16T18:14:08Z", "author": {"login": "yizheliu-amazon"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/AnomalyDetectorJobRunner.java", "diffHunk": "@@ -90,60 +133,368 @@ public void runJob(ScheduledJobParameter jobParameter, JobExecutionContext conte\n                         jobParameter,\n                         context,\n                         ActionListener\n-                            .wrap(\n-                                lock -> runAdJob(jobParameter, lockService, lock),\n-                                exception -> {\n-                                    throw new IllegalStateException(\"Failed to acquire lock for AD job: \" + jobParameter.getName());\n-                                }\n-                            )\n+                            .wrap(lock -> runAdJob(jobParameter, lockService, lock, detectionStartTime, executionStartTime), exception -> {\n+                                indexAnomalyResultException(\n+                                    jobParameter,\n+                                    lockService,\n+                                    null,\n+                                    detectionStartTime,\n+                                    executionStartTime,\n+                                    exception,\n+                                    false\n+                                );\n+                                throw new IllegalStateException(\"Failed to acquire lock for AD job: \" + detectorId);\n+                            })\n                     );\n             } else {\n-                log.warn(\"Can't get lock for AD job: \" + jobParameter.getName());\n+                log.warn(\"Can't get lock for AD job: \" + detectorId);\n             }\n         };\n \n         ExecutorService executor = threadPool.executor(AD_THREAD_POOL_NAME);\n         executor.submit(runnable);\n     }\n \n-    protected void runAdJob(ScheduledJobParameter jobParameter, LockService lockService, LockModel lock) {\n+    /**\n+     * Get anomaly result, index result or handle exception if failed.\n+     *\n+     * @param jobParameter scheduled job parameter\n+     * @param lockService lock service\n+     * @param lock lock to run job\n+     * @param detectionStartTime detection start time\n+     * @param executionStartTime detection end time\n+     */\n+    protected void runAdJob(\n+        ScheduledJobParameter jobParameter,\n+        LockService lockService,\n+        LockModel lock,\n+        Instant detectionStartTime,\n+        Instant executionStartTime\n+    ) {\n+        String detectorId = jobParameter.getName();\n         if (lock == null) {\n+            indexAnomalyResultException(\n+                jobParameter,\n+                lockService,\n+                lock,\n+                detectionStartTime,\n+                executionStartTime,\n+                \"Can't run AD job due to null lock\",\n+                false\n+            );\n             return;\n         }\n \n         try {\n-            IntervalSchedule schedule = (IntervalSchedule) jobParameter.getSchedule();\n-            // TODO: handle jitter of job scheduler\n-            Instant endTime = Instant.now();\n-            Duration duration = Duration.of(schedule.getInterval(), schedule.getUnit());\n-            Instant startTime = endTime.minusMillis(duration.toMillis());\n-\n             AnomalyResultRequest request = new AnomalyResultRequest(\n-                jobParameter.getName(),\n-                startTime.toEpochMilli(),\n-                endTime.toEpochMilli()\n+                detectorId,\n+                detectionStartTime.toEpochMilli(),\n+                executionStartTime.toEpochMilli()\n             );\n-            client.execute(AnomalyResultAction.INSTANCE, request, ActionListener.wrap(response -> {\n-                log.info(\"Anomaly result action ran successfully for \" + jobParameter.getName());\n-                releaseLock(jobParameter, lockService, lock);\n-            }, exception -> {\n-                log.error(\"Failed to execute anomaly result action\", exception);\n-                releaseLock(jobParameter, lockService, lock);\n-            }));\n+            client\n+                .execute(\n+                    AnomalyResultAction.INSTANCE,\n+                    request,\n+                    ActionListener\n+                        .wrap(\n+                            response -> {\n+                                indexAnomalyResult(jobParameter, lockService, lock, detectionStartTime, executionStartTime, response);\n+                            },\n+                            exception -> {\n+                                handleAdException(jobParameter, lockService, lock, detectionStartTime, executionStartTime, exception);\n+                            }\n+                        )\n+                );\n+        } catch (Exception e) {\n+            indexAnomalyResultException(jobParameter, lockService, lock, detectionStartTime, executionStartTime, e, true);\n+            log.error(\"Failed to execute AD job \" + detectorId, e);\n+        }\n+    }\n+\n+    /**\n+     * Handle exception from anomaly result action.\n+     *\n+     * 1. If exception is {@link EndRunException}\n+     *   a). if isEndNow == true, stop AD job and store exception in anomaly result\n+     *   b). if isEndNow == false, record count of {@link EndRunException} for this\n+     *       detector. If count of {@link EndRunException} exceeds upper limit, will\n+     *       stop AD job and store exception in anomaly result; otherwise, just\n+     *       store exception in anomaly result, not stop AD job for the detector.\n+     *\n+     * 2. If exception is not {@link EndRunException}, decrease count of\n+     *    {@link EndRunException} for the detector and index eception in Anomaly\n+     *    result. If exception is {@link InternalFailure}, will not log exception\n+     *    stack trace as already logged in {@link AnomalyResultTransportAction}.\n+     *\n+     * TODO: Handle finer granularity exception such as some exception may be\n+     *       transient and retry in current job may succeed. Currently, we don't\n+     *       know which exception is transient and retryable in\n+     *       {@link AnomalyResultTransportAction}. So we don't add backoff retry\n+     *       now to avoid bring extra load to cluster, expecially the code start\n+     *       process is relatively heavey by sending out 24 queries, initializing", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9fcfd11b7c8dd0a018e0ac2bdd22711827cb348c"}, "originalPosition": 238}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc1NjEzMTI5", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#pullrequestreview-375613129", "createdAt": "2020-03-16T22:04:33Z", "commit": {"oid": "9fcfd11b7c8dd0a018e0ac2bdd22711827cb348c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQyMjowNDozM1rOF3HRwQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQyMjowNDozM1rOF3HRwQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMzNTIzMw==", "bodyText": "Can you log the exception here so that it might be easier for us to troubleshoot in case of any issue?", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r393335233", "createdAt": "2020-03-16T22:04:33Z", "author": {"login": "yizheliu-amazon"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/transport/handler/AnomalyResultHandler.java", "diffHunk": "@@ -0,0 +1,205 @@\n+/*\n+ * Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.transport.handler;\n+\n+import com.amazon.opendistroforelasticsearch.ad.common.exception.AnomalyDetectionException;\n+import com.amazon.opendistroforelasticsearch.ad.indices.AnomalyDetectionIndices;\n+import com.amazon.opendistroforelasticsearch.ad.model.AnomalyResult;\n+import com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings;\n+import com.amazon.opendistroforelasticsearch.ad.util.RestHandlerUtils;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.ExceptionsHelper;\n+import org.elasticsearch.ResourceAlreadyExistsException;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.admin.indices.create.CreateIndexResponse;\n+import org.elasticsearch.action.bulk.BackoffPolicy;\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.action.index.IndexResponse;\n+import org.elasticsearch.action.support.IndicesOptions;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.block.ClusterBlockLevel;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.util.concurrent.EsRejectedExecutionException;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.Iterator;\n+import java.util.Locale;\n+\n+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n+\n+public class AnomalyResultHandler {\n+    private static final Logger LOG = LogManager.getLogger(AnomalyResultHandler.class);\n+\n+    static final String CANNOT_SAVE_ERR_MSG = \"Cannot save anomaly result due to write block.\";\n+    static final String FAIL_TO_SAVE_ERR_MSG = \"Fail to save anomaly index: \";\n+    static final String RETRY_SAVING_ERR_MSG = \"Retry in saving anomaly index: \";\n+    static final String SUCCESS_SAVING_MSG = \"SSUCCESS_SAVING_MSGuccess in saving anomaly index: \";\n+\n+    private final Client client;\n+    private final ClusterService clusterService;\n+    private final IndexNameExpressionResolver indexNameExpressionResolver;\n+    private final AnomalyDetectionIndices anomalyDetectionIndices;\n+    private final ThreadPool threadPool;\n+    private final BackoffPolicy resultSavingBackoffPolicy;\n+\n+    public AnomalyResultHandler(\n+        Client client,\n+        Settings settings,\n+        ClusterService clusterService,\n+        IndexNameExpressionResolver indexNameExpressionResolver,\n+        AnomalyDetectionIndices anomalyDetectionIndices,\n+        ThreadPool threadPool\n+    ) {\n+        this.client = client;\n+        this.clusterService = clusterService;\n+        this.indexNameExpressionResolver = indexNameExpressionResolver;\n+        this.anomalyDetectionIndices = anomalyDetectionIndices;\n+        this.threadPool = threadPool;\n+        this.resultSavingBackoffPolicy = BackoffPolicy\n+            .exponentialBackoff(\n+                AnomalyDetectorSettings.BACKOFF_INITIAL_DELAY.get(settings),\n+                AnomalyDetectorSettings.MAX_RETRY_FOR_BACKOFF.get(settings)\n+            );\n+    }\n+\n+    public void indexAnomalyResult(AnomalyResult anomalyResult) {\n+        try {\n+            if (checkIndicesBlocked(clusterService.state(), ClusterBlockLevel.WRITE, AnomalyResult.ANOMALY_RESULT_INDEX)) {\n+                LOG.warn(CANNOT_SAVE_ERR_MSG);\n+                return;\n+            }\n+            if (!anomalyDetectionIndices.doesAnomalyResultIndexExist()) {\n+                anomalyDetectionIndices\n+                    .initAnomalyResultIndexDirectly(\n+                        ActionListener.wrap(initResponse -> onCreateAnomalyResultIndexResponse(initResponse, anomalyResult), exception -> {\n+                            if (ExceptionsHelper.unwrapCause(exception) instanceof ResourceAlreadyExistsException) {\n+                                // It is possible the index has been created while we sending the create request\n+                                saveDetectorResult(anomalyResult);\n+                            } else {\n+                                throw new AnomalyDetectionException(\n+                                    anomalyResult.getDetectorId(),\n+                                    \"Unexpected error creating anomaly result index\",\n+                                    exception\n+                                );\n+                            }\n+                        })\n+                    );\n+            } else {\n+                saveDetectorResult(anomalyResult);\n+            }\n+        } catch (Exception e) {\n+            throw new AnomalyDetectionException(\n+                anomalyResult.getDetectorId(),\n+                String\n+                    .format(\n+                        Locale.ROOT,\n+                        \"Error in saving anomaly index for ID %s from %s to %s\",\n+                        anomalyResult.getDetectorId(),\n+                        anomalyResult.getDataStartTime(),\n+                        anomalyResult.getDataEndTime()\n+                    )\n+            );\n+        }\n+    }\n+\n+    /**\n+     * Similar to checkGlobalBlock, we check block on the indices level.\n+     *\n+     * @param state   Cluster state\n+     * @param level   block level\n+     * @param indices the indices on which to check block\n+     * @return whether any of the index has block on the level.\n+     */\n+    private boolean checkIndicesBlocked(ClusterState state, ClusterBlockLevel level, String... indices) {\n+        // the original index might be an index expression with wildcards like \"log*\",\n+        // so we need to expand the expression to concrete index name\n+        String[] concreteIndices = indexNameExpressionResolver.concreteIndexNames(state, IndicesOptions.lenientExpandOpen(), indices);\n+\n+        return state.blocks().indicesBlockedException(level, concreteIndices) != null;\n+    }\n+\n+    private void onCreateAnomalyResultIndexResponse(CreateIndexResponse response, AnomalyResult anomalyResult) {\n+        if (response.isAcknowledged()) {\n+            saveDetectorResult(anomalyResult);\n+        } else {\n+            throw new AnomalyDetectionException(\n+                anomalyResult.getDetectorId(),\n+                \"Creating anomaly result index with mappings call not acknowledged.\"\n+            );\n+        }\n+    }\n+\n+    private void saveDetectorResult(AnomalyResult anomalyResult) {\n+        try (XContentBuilder builder = jsonBuilder()) {\n+            IndexRequest indexRequest = new IndexRequest(AnomalyResult.ANOMALY_RESULT_INDEX)\n+                .source(anomalyResult.toXContent(builder, RestHandlerUtils.XCONTENT_WITH_TYPE));\n+            saveDetectorResult(\n+                indexRequest,\n+                String\n+                    .format(\n+                        Locale.ROOT,\n+                        \"ID %s from %s to %s\",\n+                        anomalyResult.getDetectorId(),\n+                        anomalyResult.getDataStartTime(),\n+                        anomalyResult.getDataEndTime()\n+                    ),\n+                resultSavingBackoffPolicy.iterator()\n+            );\n+        } catch (Exception e) {\n+            e.printStackTrace();\n+            throw new AnomalyDetectionException(anomalyResult.getDetectorId(), \"Cannot save result\");\n+        }\n+    }\n+\n+    void saveDetectorResult(IndexRequest indexRequest, String context, Iterator<TimeValue> backoff) {\n+        client\n+            .index(\n+                indexRequest,\n+                ActionListener\n+                    .<IndexResponse>wrap(\n+                        response -> LOG.debug(SUCCESS_SAVING_MSG + context),\n+                        exception -> {\n+                            // Elasticsearch has a thread pool and a queue for write per node. A thread\n+                            // pool will have N number of workers ready to handle the requests. When a\n+                            // request comes and if a worker is free , this is handled by the worker. Now by\n+                            // default the number of workers is equal to the number of cores on that CPU.\n+                            // When the workers are full and there are more write requests, the request\n+                            // will go to queue. The size of queue is also limited. If by default size is,\n+                            // say, 200 and if there happens more parallel requests than this, then those\n+                            // requests would be rejected as you can see EsRejectedExecutionException.\n+                            // So EsRejectedExecutionException is the way that Elasticsearch tells us that\n+                            // it cannot keep up with the current indexing rate.\n+                            // When it happens, we should pause indexing a bit before trying again, ideally\n+                            // with randomized exponential backoff.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9fcfd11b7c8dd0a018e0ac2bdd22711827cb348c"}, "originalPosition": 192}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc1NjEzNTMw", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#pullrequestreview-375613530", "createdAt": "2020-03-16T22:05:29Z", "commit": {"oid": "9fcfd11b7c8dd0a018e0ac2bdd22711827cb348c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQyMjowNToyOVrOF3HS_Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQyMjowNToyOVrOF3HS_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMzNTU0OQ==", "bodyText": "why use printStackTrace instead of log.error?", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r393335549", "createdAt": "2020-03-16T22:05:29Z", "author": {"login": "yizheliu-amazon"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/transport/handler/AnomalyResultHandler.java", "diffHunk": "@@ -0,0 +1,205 @@\n+/*\n+ * Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.transport.handler;\n+\n+import com.amazon.opendistroforelasticsearch.ad.common.exception.AnomalyDetectionException;\n+import com.amazon.opendistroforelasticsearch.ad.indices.AnomalyDetectionIndices;\n+import com.amazon.opendistroforelasticsearch.ad.model.AnomalyResult;\n+import com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings;\n+import com.amazon.opendistroforelasticsearch.ad.util.RestHandlerUtils;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.ExceptionsHelper;\n+import org.elasticsearch.ResourceAlreadyExistsException;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.admin.indices.create.CreateIndexResponse;\n+import org.elasticsearch.action.bulk.BackoffPolicy;\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.action.index.IndexResponse;\n+import org.elasticsearch.action.support.IndicesOptions;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.block.ClusterBlockLevel;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.util.concurrent.EsRejectedExecutionException;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.Iterator;\n+import java.util.Locale;\n+\n+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n+\n+public class AnomalyResultHandler {\n+    private static final Logger LOG = LogManager.getLogger(AnomalyResultHandler.class);\n+\n+    static final String CANNOT_SAVE_ERR_MSG = \"Cannot save anomaly result due to write block.\";\n+    static final String FAIL_TO_SAVE_ERR_MSG = \"Fail to save anomaly index: \";\n+    static final String RETRY_SAVING_ERR_MSG = \"Retry in saving anomaly index: \";\n+    static final String SUCCESS_SAVING_MSG = \"SSUCCESS_SAVING_MSGuccess in saving anomaly index: \";\n+\n+    private final Client client;\n+    private final ClusterService clusterService;\n+    private final IndexNameExpressionResolver indexNameExpressionResolver;\n+    private final AnomalyDetectionIndices anomalyDetectionIndices;\n+    private final ThreadPool threadPool;\n+    private final BackoffPolicy resultSavingBackoffPolicy;\n+\n+    public AnomalyResultHandler(\n+        Client client,\n+        Settings settings,\n+        ClusterService clusterService,\n+        IndexNameExpressionResolver indexNameExpressionResolver,\n+        AnomalyDetectionIndices anomalyDetectionIndices,\n+        ThreadPool threadPool\n+    ) {\n+        this.client = client;\n+        this.clusterService = clusterService;\n+        this.indexNameExpressionResolver = indexNameExpressionResolver;\n+        this.anomalyDetectionIndices = anomalyDetectionIndices;\n+        this.threadPool = threadPool;\n+        this.resultSavingBackoffPolicy = BackoffPolicy\n+            .exponentialBackoff(\n+                AnomalyDetectorSettings.BACKOFF_INITIAL_DELAY.get(settings),\n+                AnomalyDetectorSettings.MAX_RETRY_FOR_BACKOFF.get(settings)\n+            );\n+    }\n+\n+    public void indexAnomalyResult(AnomalyResult anomalyResult) {\n+        try {\n+            if (checkIndicesBlocked(clusterService.state(), ClusterBlockLevel.WRITE, AnomalyResult.ANOMALY_RESULT_INDEX)) {\n+                LOG.warn(CANNOT_SAVE_ERR_MSG);\n+                return;\n+            }\n+            if (!anomalyDetectionIndices.doesAnomalyResultIndexExist()) {\n+                anomalyDetectionIndices\n+                    .initAnomalyResultIndexDirectly(\n+                        ActionListener.wrap(initResponse -> onCreateAnomalyResultIndexResponse(initResponse, anomalyResult), exception -> {\n+                            if (ExceptionsHelper.unwrapCause(exception) instanceof ResourceAlreadyExistsException) {\n+                                // It is possible the index has been created while we sending the create request\n+                                saveDetectorResult(anomalyResult);\n+                            } else {\n+                                throw new AnomalyDetectionException(\n+                                    anomalyResult.getDetectorId(),\n+                                    \"Unexpected error creating anomaly result index\",\n+                                    exception\n+                                );\n+                            }\n+                        })\n+                    );\n+            } else {\n+                saveDetectorResult(anomalyResult);\n+            }\n+        } catch (Exception e) {\n+            throw new AnomalyDetectionException(\n+                anomalyResult.getDetectorId(),\n+                String\n+                    .format(\n+                        Locale.ROOT,\n+                        \"Error in saving anomaly index for ID %s from %s to %s\",\n+                        anomalyResult.getDetectorId(),\n+                        anomalyResult.getDataStartTime(),\n+                        anomalyResult.getDataEndTime()\n+                    )\n+            );\n+        }\n+    }\n+\n+    /**\n+     * Similar to checkGlobalBlock, we check block on the indices level.\n+     *\n+     * @param state   Cluster state\n+     * @param level   block level\n+     * @param indices the indices on which to check block\n+     * @return whether any of the index has block on the level.\n+     */\n+    private boolean checkIndicesBlocked(ClusterState state, ClusterBlockLevel level, String... indices) {\n+        // the original index might be an index expression with wildcards like \"log*\",\n+        // so we need to expand the expression to concrete index name\n+        String[] concreteIndices = indexNameExpressionResolver.concreteIndexNames(state, IndicesOptions.lenientExpandOpen(), indices);\n+\n+        return state.blocks().indicesBlockedException(level, concreteIndices) != null;\n+    }\n+\n+    private void onCreateAnomalyResultIndexResponse(CreateIndexResponse response, AnomalyResult anomalyResult) {\n+        if (response.isAcknowledged()) {\n+            saveDetectorResult(anomalyResult);\n+        } else {\n+            throw new AnomalyDetectionException(\n+                anomalyResult.getDetectorId(),\n+                \"Creating anomaly result index with mappings call not acknowledged.\"\n+            );\n+        }\n+    }\n+\n+    private void saveDetectorResult(AnomalyResult anomalyResult) {\n+        try (XContentBuilder builder = jsonBuilder()) {\n+            IndexRequest indexRequest = new IndexRequest(AnomalyResult.ANOMALY_RESULT_INDEX)\n+                .source(anomalyResult.toXContent(builder, RestHandlerUtils.XCONTENT_WITH_TYPE));\n+            saveDetectorResult(\n+                indexRequest,\n+                String\n+                    .format(\n+                        Locale.ROOT,\n+                        \"ID %s from %s to %s\",\n+                        anomalyResult.getDetectorId(),\n+                        anomalyResult.getDataStartTime(),\n+                        anomalyResult.getDataEndTime()\n+                    ),\n+                resultSavingBackoffPolicy.iterator()\n+            );\n+        } catch (Exception e) {\n+            e.printStackTrace();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9fcfd11b7c8dd0a018e0ac2bdd22711827cb348c"}, "originalPosition": 168}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc1NjE0NjAz", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#pullrequestreview-375614603", "createdAt": "2020-03-16T22:07:57Z", "commit": {"oid": "9fcfd11b7c8dd0a018e0ac2bdd22711827cb348c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQyMjowNzo1N1rOF3HWVA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQyMjowNzo1N1rOF3HWVA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMzNjQwNA==", "bodyText": "Can you either log the Exception or use it to initialize AnomalyDetectionException, so that we don't loose track of the original exception info?", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#discussion_r393336404", "createdAt": "2020-03-16T22:07:57Z", "author": {"login": "yizheliu-amazon"}, "path": "src/main/java/com/amazon/opendistroforelasticsearch/ad/transport/handler/AnomalyResultHandler.java", "diffHunk": "@@ -0,0 +1,205 @@\n+/*\n+ * Copyright 2020 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistroforelasticsearch.ad.transport.handler;\n+\n+import com.amazon.opendistroforelasticsearch.ad.common.exception.AnomalyDetectionException;\n+import com.amazon.opendistroforelasticsearch.ad.indices.AnomalyDetectionIndices;\n+import com.amazon.opendistroforelasticsearch.ad.model.AnomalyResult;\n+import com.amazon.opendistroforelasticsearch.ad.settings.AnomalyDetectorSettings;\n+import com.amazon.opendistroforelasticsearch.ad.util.RestHandlerUtils;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.elasticsearch.ExceptionsHelper;\n+import org.elasticsearch.ResourceAlreadyExistsException;\n+import org.elasticsearch.action.ActionListener;\n+import org.elasticsearch.action.admin.indices.create.CreateIndexResponse;\n+import org.elasticsearch.action.bulk.BackoffPolicy;\n+import org.elasticsearch.action.index.IndexRequest;\n+import org.elasticsearch.action.index.IndexResponse;\n+import org.elasticsearch.action.support.IndicesOptions;\n+import org.elasticsearch.client.Client;\n+import org.elasticsearch.cluster.ClusterState;\n+import org.elasticsearch.cluster.block.ClusterBlockLevel;\n+import org.elasticsearch.cluster.metadata.IndexNameExpressionResolver;\n+import org.elasticsearch.cluster.service.ClusterService;\n+import org.elasticsearch.common.settings.Settings;\n+import org.elasticsearch.common.unit.TimeValue;\n+import org.elasticsearch.common.util.concurrent.EsRejectedExecutionException;\n+import org.elasticsearch.common.xcontent.XContentBuilder;\n+import org.elasticsearch.threadpool.ThreadPool;\n+\n+import java.util.Iterator;\n+import java.util.Locale;\n+\n+import static org.elasticsearch.common.xcontent.XContentFactory.jsonBuilder;\n+\n+public class AnomalyResultHandler {\n+    private static final Logger LOG = LogManager.getLogger(AnomalyResultHandler.class);\n+\n+    static final String CANNOT_SAVE_ERR_MSG = \"Cannot save anomaly result due to write block.\";\n+    static final String FAIL_TO_SAVE_ERR_MSG = \"Fail to save anomaly index: \";\n+    static final String RETRY_SAVING_ERR_MSG = \"Retry in saving anomaly index: \";\n+    static final String SUCCESS_SAVING_MSG = \"SSUCCESS_SAVING_MSGuccess in saving anomaly index: \";\n+\n+    private final Client client;\n+    private final ClusterService clusterService;\n+    private final IndexNameExpressionResolver indexNameExpressionResolver;\n+    private final AnomalyDetectionIndices anomalyDetectionIndices;\n+    private final ThreadPool threadPool;\n+    private final BackoffPolicy resultSavingBackoffPolicy;\n+\n+    public AnomalyResultHandler(\n+        Client client,\n+        Settings settings,\n+        ClusterService clusterService,\n+        IndexNameExpressionResolver indexNameExpressionResolver,\n+        AnomalyDetectionIndices anomalyDetectionIndices,\n+        ThreadPool threadPool\n+    ) {\n+        this.client = client;\n+        this.clusterService = clusterService;\n+        this.indexNameExpressionResolver = indexNameExpressionResolver;\n+        this.anomalyDetectionIndices = anomalyDetectionIndices;\n+        this.threadPool = threadPool;\n+        this.resultSavingBackoffPolicy = BackoffPolicy\n+            .exponentialBackoff(\n+                AnomalyDetectorSettings.BACKOFF_INITIAL_DELAY.get(settings),\n+                AnomalyDetectorSettings.MAX_RETRY_FOR_BACKOFF.get(settings)\n+            );\n+    }\n+\n+    public void indexAnomalyResult(AnomalyResult anomalyResult) {\n+        try {\n+            if (checkIndicesBlocked(clusterService.state(), ClusterBlockLevel.WRITE, AnomalyResult.ANOMALY_RESULT_INDEX)) {\n+                LOG.warn(CANNOT_SAVE_ERR_MSG);\n+                return;\n+            }\n+            if (!anomalyDetectionIndices.doesAnomalyResultIndexExist()) {\n+                anomalyDetectionIndices\n+                    .initAnomalyResultIndexDirectly(\n+                        ActionListener.wrap(initResponse -> onCreateAnomalyResultIndexResponse(initResponse, anomalyResult), exception -> {\n+                            if (ExceptionsHelper.unwrapCause(exception) instanceof ResourceAlreadyExistsException) {\n+                                // It is possible the index has been created while we sending the create request\n+                                saveDetectorResult(anomalyResult);\n+                            } else {\n+                                throw new AnomalyDetectionException(\n+                                    anomalyResult.getDetectorId(),\n+                                    \"Unexpected error creating anomaly result index\",\n+                                    exception\n+                                );\n+                            }\n+                        })\n+                    );\n+            } else {\n+                saveDetectorResult(anomalyResult);\n+            }\n+        } catch (Exception e) {\n+            throw new AnomalyDetectionException(\n+                anomalyResult.getDetectorId(),\n+                String\n+                    .format(\n+                        Locale.ROOT,\n+                        \"Error in saving anomaly index for ID %s from %s to %s\",\n+                        anomalyResult.getDetectorId(),\n+                        anomalyResult.getDataStartTime(),\n+                        anomalyResult.getDataEndTime()\n+                    )\n+            );", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9fcfd11b7c8dd0a018e0ac2bdd22711827cb348c"}, "originalPosition": 120}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc1NjE2NTQz", "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/pull/59#pullrequestreview-375616543", "createdAt": "2020-03-16T22:12:08Z", "commit": {"oid": "9fcfd11b7c8dd0a018e0ac2bdd22711827cb348c"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f96571721f8952f17cecea2f44d71ea7d7f8e657", "author": {"user": {"login": "ylwu-amzn", "name": "Yaliang"}}, "url": "https://github.com/opendistro-for-elasticsearch/anomaly-detection/commit/f96571721f8952f17cecea2f44d71ea7d7f8e657", "committedDate": "2020-03-17T02:13:30Z", "message": "fix typo;add more log"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1634, "cost": 1, "resetAt": "2021-11-01T16:19:10Z"}}}