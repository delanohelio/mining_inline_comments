{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQzNDQxODg4", "number": 10125, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQxODowNjoyMlrOELAYBw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQxODowNjoyMlrOELAYBw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5OTc1OTQzOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/druid/client/CachingClusteredClient.java", "isResolved": false, "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQxODowNjoyMlrOGsYOGw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QwMDo0Mzo1NlrOGsgmAQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE4NzM1NQ==", "bodyText": "This still isn't right. It will get all segments for the time chunk. We should use timeline.findEntry when the incoming QSS calls for specific segments, like ServerManager.getQueryRunnerForSegments does.", "url": "https://github.com/apache/druid/pull/10125#discussion_r449187355", "createdAt": "2020-07-02T18:06:22Z", "author": {"login": "gianm"}, "path": "server/src/main/java/org/apache/druid/client/CachingClusteredClient.java", "diffHunk": "@@ -401,11 +407,16 @@ private ClusterQueryResult(Sequence<T> sequence, int numQueryServers)\n       }\n     }\n \n-    private Set<SegmentServerSelector> computeSegmentsToQuery(TimelineLookup<String, ServerSelector> timeline)\n+    private Set<SegmentServerSelector> computeSegmentsToQuery(\n+        TimelineLookup<String, ServerSelector> timeline,\n+        boolean specificSegments\n+    )\n     {\n+      final java.util.function.Function<Interval, List<TimelineObjectHolder<String, ServerSelector>>> lookupFn\n+          = specificSegments ? timeline::lookupWithIncompletePartitions : timeline::lookup;\n       final List<TimelineObjectHolder<String, ServerSelector>> serversLookup = toolChest.filterSegments(\n           query,\n-          intervals.stream().flatMap(i -> timeline.lookup(i).stream()).collect(Collectors.toList())\n+          intervals.stream().flatMap(i -> lookupFn.apply(i).stream()).collect(Collectors.toList())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4f90aa8c94363d493b12594a0914518c52b392cf"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTIyNjg5NA==", "bodyText": "Hmm, although, getQueryRunnerForSegments does create a modified timeline that only has the relevant segments, so this might be okay as long as we can assume none of them overshadow the others. Which should be a fair assumption for a query that originally started out as being by intervals. It seems a bit sketchy, though, and would be nice if we could avoid the unnecessary creation of this timeline.\nBut if we stick with this approach \u2014\u00a0will this properly retain information about the relevant SegmentDescriptors' intervals, though? These could be narrower than the segments' full intervals.", "url": "https://github.com/apache/druid/pull/10125#discussion_r449226894", "createdAt": "2020-07-02T19:32:09Z", "author": {"login": "gianm"}, "path": "server/src/main/java/org/apache/druid/client/CachingClusteredClient.java", "diffHunk": "@@ -401,11 +407,16 @@ private ClusterQueryResult(Sequence<T> sequence, int numQueryServers)\n       }\n     }\n \n-    private Set<SegmentServerSelector> computeSegmentsToQuery(TimelineLookup<String, ServerSelector> timeline)\n+    private Set<SegmentServerSelector> computeSegmentsToQuery(\n+        TimelineLookup<String, ServerSelector> timeline,\n+        boolean specificSegments\n+    )\n     {\n+      final java.util.function.Function<Interval, List<TimelineObjectHolder<String, ServerSelector>>> lookupFn\n+          = specificSegments ? timeline::lookupWithIncompletePartitions : timeline::lookup;\n       final List<TimelineObjectHolder<String, ServerSelector>> serversLookup = toolChest.filterSegments(\n           query,\n-          intervals.stream().flatMap(i -> timeline.lookup(i).stream()).collect(Collectors.toList())\n+          intervals.stream().flatMap(i -> lookupFn.apply(i).stream()).collect(Collectors.toList())", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE4NzM1NQ=="}, "originalCommit": {"oid": "4f90aa8c94363d493b12594a0914518c52b392cf"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTI1NDMzMw==", "bodyText": "Hmm, although, getQueryRunnerForSegments does create a modified timeline that only has the relevant segments, so this might be okay as long as we can assume none of them overshadow the others. Which should be a fair assumption for a query that originally started out as being by intervals. It seems a bit sketchy, though, and would be nice if we could avoid the unnecessary creation of this timeline.\n\nI agree. That would be cleaner and even more efficient since we can avoid unnecessary timeline build and lookup on it. However, since we are about to release our next version, I would like to avoid such big refactoring for now. It will be more risky and potentially delay the release.\n\nBut if we stick with this approach \u2014\u00a0will this properly retain information about the relevant SegmentDescriptors' intervals, though? These could be narrower than the segments' full intervals.\n\nIt does truncate the interval, but the query server can handle it. The query runner for specific segments in ServerManager or AppenderatorImpl uses TimelineLookup.findEntry() to find the PartitionHolder containing the segments to query. In this findEntry(), an entry matches if its interval contains the given interval.\n  public @Nullable PartitionHolder<ObjectType> findEntry(Interval interval, VersionType version)\n  {\n    lock.readLock().lock();\n    try {\n      for (Entry<Interval, TreeMap<VersionType, TimelineEntry>> entry : allTimelineEntries.entrySet()) {\n        if (entry.getKey().equals(interval) || entry.getKey().contains(interval)) {\n          TimelineEntry foundEntry = entry.getValue().get(version);\n          if (foundEntry != null) {\n            return foundEntry.getPartitionHolder().asImmutable();\n          }\n        }\n      }\n\n      return null;\n    }\n    finally {\n      lock.readLock().unlock();\n    }\n  }", "url": "https://github.com/apache/druid/pull/10125#discussion_r449254333", "createdAt": "2020-07-02T20:37:10Z", "author": {"login": "jihoonson"}, "path": "server/src/main/java/org/apache/druid/client/CachingClusteredClient.java", "diffHunk": "@@ -401,11 +407,16 @@ private ClusterQueryResult(Sequence<T> sequence, int numQueryServers)\n       }\n     }\n \n-    private Set<SegmentServerSelector> computeSegmentsToQuery(TimelineLookup<String, ServerSelector> timeline)\n+    private Set<SegmentServerSelector> computeSegmentsToQuery(\n+        TimelineLookup<String, ServerSelector> timeline,\n+        boolean specificSegments\n+    )\n     {\n+      final java.util.function.Function<Interval, List<TimelineObjectHolder<String, ServerSelector>>> lookupFn\n+          = specificSegments ? timeline::lookupWithIncompletePartitions : timeline::lookup;\n       final List<TimelineObjectHolder<String, ServerSelector>> serversLookup = toolChest.filterSegments(\n           query,\n-          intervals.stream().flatMap(i -> timeline.lookup(i).stream()).collect(Collectors.toList())\n+          intervals.stream().flatMap(i -> lookupFn.apply(i).stream()).collect(Collectors.toList())", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE4NzM1NQ=="}, "originalCommit": {"oid": "4f90aa8c94363d493b12594a0914518c52b392cf"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTMwNTY3NA==", "bodyText": "It does truncate the interval, but the query server can handle it. The query runner for specific segments in ServerManager or AppenderatorImpl uses TimelineLookup.findEntry() to find the PartitionHolder containing the segments to query. In this findEntry(), an entry matches if its interval contains the given interval.\n\nThis isn't what I'm worried about \u2014\u00a0I'm worried that the SegmentDescriptor with the shorter interval might not get properly retained in the retry. Will it? If so, I think it's ok, if a bit sketchy. It would be good to have tests for it since it's so sketchy.", "url": "https://github.com/apache/druid/pull/10125#discussion_r449305674", "createdAt": "2020-07-02T23:17:08Z", "author": {"login": "gianm"}, "path": "server/src/main/java/org/apache/druid/client/CachingClusteredClient.java", "diffHunk": "@@ -401,11 +407,16 @@ private ClusterQueryResult(Sequence<T> sequence, int numQueryServers)\n       }\n     }\n \n-    private Set<SegmentServerSelector> computeSegmentsToQuery(TimelineLookup<String, ServerSelector> timeline)\n+    private Set<SegmentServerSelector> computeSegmentsToQuery(\n+        TimelineLookup<String, ServerSelector> timeline,\n+        boolean specificSegments\n+    )\n     {\n+      final java.util.function.Function<Interval, List<TimelineObjectHolder<String, ServerSelector>>> lookupFn\n+          = specificSegments ? timeline::lookupWithIncompletePartitions : timeline::lookup;\n       final List<TimelineObjectHolder<String, ServerSelector>> serversLookup = toolChest.filterSegments(\n           query,\n-          intervals.stream().flatMap(i -> timeline.lookup(i).stream()).collect(Collectors.toList())\n+          intervals.stream().flatMap(i -> lookupFn.apply(i).stream()).collect(Collectors.toList())", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE4NzM1NQ=="}, "originalCommit": {"oid": "4f90aa8c94363d493b12594a0914518c52b392cf"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTMwNjE2OQ==", "bodyText": "Ah yeah, it does that now. I can add some comments and update tests to verify that behavior.", "url": "https://github.com/apache/druid/pull/10125#discussion_r449306169", "createdAt": "2020-07-02T23:19:22Z", "author": {"login": "jihoonson"}, "path": "server/src/main/java/org/apache/druid/client/CachingClusteredClient.java", "diffHunk": "@@ -401,11 +407,16 @@ private ClusterQueryResult(Sequence<T> sequence, int numQueryServers)\n       }\n     }\n \n-    private Set<SegmentServerSelector> computeSegmentsToQuery(TimelineLookup<String, ServerSelector> timeline)\n+    private Set<SegmentServerSelector> computeSegmentsToQuery(\n+        TimelineLookup<String, ServerSelector> timeline,\n+        boolean specificSegments\n+    )\n     {\n+      final java.util.function.Function<Interval, List<TimelineObjectHolder<String, ServerSelector>>> lookupFn\n+          = specificSegments ? timeline::lookupWithIncompletePartitions : timeline::lookup;\n       final List<TimelineObjectHolder<String, ServerSelector>> serversLookup = toolChest.filterSegments(\n           query,\n-          intervals.stream().flatMap(i -> timeline.lookup(i).stream()).collect(Collectors.toList())\n+          intervals.stream().flatMap(i -> lookupFn.apply(i).stream()).collect(Collectors.toList())", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE4NzM1NQ=="}, "originalCommit": {"oid": "4f90aa8c94363d493b12594a0914518c52b392cf"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTMxMjEzNA==", "bodyText": "I think the test to verify this behavior should be an integration test rather than unit test. I will add some with doc/comments in a follow-up for integration tests.", "url": "https://github.com/apache/druid/pull/10125#discussion_r449312134", "createdAt": "2020-07-02T23:45:27Z", "author": {"login": "jihoonson"}, "path": "server/src/main/java/org/apache/druid/client/CachingClusteredClient.java", "diffHunk": "@@ -401,11 +407,16 @@ private ClusterQueryResult(Sequence<T> sequence, int numQueryServers)\n       }\n     }\n \n-    private Set<SegmentServerSelector> computeSegmentsToQuery(TimelineLookup<String, ServerSelector> timeline)\n+    private Set<SegmentServerSelector> computeSegmentsToQuery(\n+        TimelineLookup<String, ServerSelector> timeline,\n+        boolean specificSegments\n+    )\n     {\n+      final java.util.function.Function<Interval, List<TimelineObjectHolder<String, ServerSelector>>> lookupFn\n+          = specificSegments ? timeline::lookupWithIncompletePartitions : timeline::lookup;\n       final List<TimelineObjectHolder<String, ServerSelector>> serversLookup = toolChest.filterSegments(\n           query,\n-          intervals.stream().flatMap(i -> timeline.lookup(i).stream()).collect(Collectors.toList())\n+          intervals.stream().flatMap(i -> lookupFn.apply(i).stream()).collect(Collectors.toList())", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE4NzM1NQ=="}, "originalCommit": {"oid": "4f90aa8c94363d493b12594a0914518c52b392cf"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTMyNDU0NQ==", "bodyText": "OK, thanks, if you make sure the integration tests cover this case then that works for me.", "url": "https://github.com/apache/druid/pull/10125#discussion_r449324545", "createdAt": "2020-07-03T00:43:56Z", "author": {"login": "gianm"}, "path": "server/src/main/java/org/apache/druid/client/CachingClusteredClient.java", "diffHunk": "@@ -401,11 +407,16 @@ private ClusterQueryResult(Sequence<T> sequence, int numQueryServers)\n       }\n     }\n \n-    private Set<SegmentServerSelector> computeSegmentsToQuery(TimelineLookup<String, ServerSelector> timeline)\n+    private Set<SegmentServerSelector> computeSegmentsToQuery(\n+        TimelineLookup<String, ServerSelector> timeline,\n+        boolean specificSegments\n+    )\n     {\n+      final java.util.function.Function<Interval, List<TimelineObjectHolder<String, ServerSelector>>> lookupFn\n+          = specificSegments ? timeline::lookupWithIncompletePartitions : timeline::lookup;\n       final List<TimelineObjectHolder<String, ServerSelector>> serversLookup = toolChest.filterSegments(\n           query,\n-          intervals.stream().flatMap(i -> timeline.lookup(i).stream()).collect(Collectors.toList())\n+          intervals.stream().flatMap(i -> lookupFn.apply(i).stream()).collect(Collectors.toList())", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE4NzM1NQ=="}, "originalCommit": {"oid": "4f90aa8c94363d493b12594a0914518c52b392cf"}, "originalPosition": 70}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2201, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}