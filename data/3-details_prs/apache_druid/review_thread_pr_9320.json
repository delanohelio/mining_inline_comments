{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzcxODAyOTc3", "number": 9320, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxOToyMzozOFrODdzUaA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxOToyMzozOFrODdzUaA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyNTc2MTA0OnYy", "diffSide": "RIGHT", "path": "docs/development/extensions-core/protobuf.md", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxOToyMzozOFrOFmnRTA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQyMToyMTowOFrOFmqnXg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjAzMzYxMg==", "bodyText": "Keeping the shebang line that was present before is convenient if this code snippet is copy/pasted into its own script file.", "url": "https://github.com/apache/druid/pull/9320#discussion_r376033612", "createdAt": "2020-02-06T19:23:38Z", "author": {"login": "ccaominh"}, "path": "docs/development/extensions-core/protobuf.md", "diffHunk": "@@ -165,54 +164,74 @@ Please make sure these keys are properly configured for successful ingestion.\n }\n ```\n \n-## Kafka Producer\n+## Adding Protobuf messages to Kafka\n \n-Here is the sample script that publishes the metrics to Kafka in Protobuf format.\n+If necessary, from your Kafka installation directory run the following command to create the Kafka topic\n \n-1. Run `protoc` again with the Python binding option.  This command generates `metrics_pb2.py` file.\n- ```\n-  protoc -o metrics.desc metrics.proto --python_out=.\n- ```\n+```\n+./bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic metrics_pb\n+```\n \n-2. Create Kafka producer script.\n+This example script requires `protobuf` and `kafka-python` modules. With the topic in place, messages can be inserted running the following command from your Druid installation directory\n \n-This script requires `protobuf` and `kafka-python` modules.\n+```\n+./bin/generate-example-metrics | ./quickstart/protobuf/pb_publisher.py\n+```\n \n-```python\n-#!/usr/bin/env python\n+You can confirm that data has been inserted to your Kafka topic using the following command from your Kafka installation directory\n+\n+```\n+./bin/kafka-console-consumer --zookeeper localhost --topic metrics_pb\n+```\n+\n+which should print messages like this\n+\n+```\n+millisecondsGETR\"2017-04-06T03:23:56Z*2002/list:request/latencyBwww1.example.com\n+```\n+\n+If your supervisor created in the previous step is running, the indexing tasks should begin producing the messages and the data will soon be available for querying in Druid.\n+\n+## Generating the example files\n+\n+The files provided in the example quickstart can be generated in the following manner starting with only `metrics.proto`.\n+\n+### `metrics.desc`\n+\n+The descriptor file is generated using `protoc` Protobuf compiler. Given a `.proto` file, a `.desc` file can be generated like so.\n+\n+```\n+protoc -o metrics.desc metrics.proto\n+```\n+\n+### `metrics_pb2.py`\n+`metrics_pb2.py` is also generated with `protoc`\n+\n+```\n+ protoc -o metrics.desc metrics.proto --python_out=.\n+```\n \n+### `pb_publisher.py`\n+After `metrics_pb2.py` is generated, another script can be constructed to parse JSON data, convert it to Protobuf, and produce to a Kafka topic\n+\n+```python", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "96e6dcc618d86463c8a285902c45e286dfa1ce89"}, "originalPosition": 135}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjA4ODQxNA==", "bodyText": "Oops, accidentally left that off when i moved stuff around \ud83d\udc4d", "url": "https://github.com/apache/druid/pull/9320#discussion_r376088414", "createdAt": "2020-02-06T21:21:08Z", "author": {"login": "clintropolis"}, "path": "docs/development/extensions-core/protobuf.md", "diffHunk": "@@ -165,54 +164,74 @@ Please make sure these keys are properly configured for successful ingestion.\n }\n ```\n \n-## Kafka Producer\n+## Adding Protobuf messages to Kafka\n \n-Here is the sample script that publishes the metrics to Kafka in Protobuf format.\n+If necessary, from your Kafka installation directory run the following command to create the Kafka topic\n \n-1. Run `protoc` again with the Python binding option.  This command generates `metrics_pb2.py` file.\n- ```\n-  protoc -o metrics.desc metrics.proto --python_out=.\n- ```\n+```\n+./bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic metrics_pb\n+```\n \n-2. Create Kafka producer script.\n+This example script requires `protobuf` and `kafka-python` modules. With the topic in place, messages can be inserted running the following command from your Druid installation directory\n \n-This script requires `protobuf` and `kafka-python` modules.\n+```\n+./bin/generate-example-metrics | ./quickstart/protobuf/pb_publisher.py\n+```\n \n-```python\n-#!/usr/bin/env python\n+You can confirm that data has been inserted to your Kafka topic using the following command from your Kafka installation directory\n+\n+```\n+./bin/kafka-console-consumer --zookeeper localhost --topic metrics_pb\n+```\n+\n+which should print messages like this\n+\n+```\n+millisecondsGETR\"2017-04-06T03:23:56Z*2002/list:request/latencyBwww1.example.com\n+```\n+\n+If your supervisor created in the previous step is running, the indexing tasks should begin producing the messages and the data will soon be available for querying in Druid.\n+\n+## Generating the example files\n+\n+The files provided in the example quickstart can be generated in the following manner starting with only `metrics.proto`.\n+\n+### `metrics.desc`\n+\n+The descriptor file is generated using `protoc` Protobuf compiler. Given a `.proto` file, a `.desc` file can be generated like so.\n+\n+```\n+protoc -o metrics.desc metrics.proto\n+```\n+\n+### `metrics_pb2.py`\n+`metrics_pb2.py` is also generated with `protoc`\n+\n+```\n+ protoc -o metrics.desc metrics.proto --python_out=.\n+```\n \n+### `pb_publisher.py`\n+After `metrics_pb2.py` is generated, another script can be constructed to parse JSON data, convert it to Protobuf, and produce to a Kafka topic\n+\n+```python", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjAzMzYxMg=="}, "originalCommit": {"oid": "96e6dcc618d86463c8a285902c45e286dfa1ce89"}, "originalPosition": 135}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2744, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}