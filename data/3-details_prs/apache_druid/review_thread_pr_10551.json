{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTE0NjA3ODY0", "number": 10551, "reviewThreads": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNlQxMDoxOToyOFrOE2BuvQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQwMTowNzo1M1rOE_Z8Qg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1MDg2OTA5OnYy", "diffSide": "LEFT", "path": "extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/indexing/kafka/KafkaConsumerConfigs.java", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNlQxMDoxOToyOFrOHuoLFQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQwODoyNDo0MlrOHxC-zg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODY1NDc0MQ==", "bodyText": "I think to remove isolation.level here and leaves the configuration to users changes the current behavior.\nCurrently users care nothing about this kafka configuration when using a higher version of kafka such as 0.11. By removing it, they need to set this property in supervisor spec,  or the default value, which is read_uncommitted, will be applied, which may be not what they expect.\nIf this is the root cause that limits the Druid to use Kafka lower than 0.11, I think maybe we can introduce another property, as the same way as pollTimeout property does, then we can unset isolation.level property according to the value of this new property. Only those who want to use Druid with older kafka  need to set this new property.", "url": "https://github.com/apache/druid/pull/10551#discussion_r518654741", "createdAt": "2020-11-06T10:19:28Z", "author": {"login": "FrankChen021"}, "path": "extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/indexing/kafka/KafkaConsumerConfigs.java", "diffHunk": "@@ -38,7 +38,6 @@\n     props.put(\"group.id\", StringUtils.format(\"kafka-supervisor-%s\", IdUtils.getRandomId()));\n     props.put(\"auto.offset.reset\", \"none\");\n     props.put(\"enable.auto.commit\", \"false\");\n-    props.put(\"isolation.level\", \"read_committed\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ac6dd037a910461462ee9c1e9994176c4c7aab4c"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODc4MDg5Mw==", "bodyText": "Yes,  It will change the current behavior.\nYou are right, most people really don't care this Kafka configuration(Let it be default behavior). As I know the default logic of the Kafka Producer is not to enable transactions feature and the same as Kafka Consumer. So that maybe Druid Kafka indexing service keep the same default logic is more reasonable.\nFurthermore, if a Druid user want Druid to consume transactional Kafka topics, I think it is more reasonable to let users set this parameter in consumerProperties like 'bootstrap.servers' because he knows what he is going to do and why.\nBy the way, Druid from 0.15 to better can't consume old version Kafka is really confused me(I believe it's not just me). Generally speaking, higher Kafka consumer client is able to consume old version Kafka cluster unless it involves high-version-specific api. And this hard limitation block us to upgrade Druid cluster from 0.14.2 for a long time. If we don't remove this config, we have to upgrade PRD Kafka cluster, which is a much more heavy work to do because there are too many consumers of Kafka such as Spark and Flink. Orz...\nThanks for reviewing!", "url": "https://github.com/apache/druid/pull/10551#discussion_r518780893", "createdAt": "2020-11-06T14:20:30Z", "author": {"login": "zhangyue19921010"}, "path": "extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/indexing/kafka/KafkaConsumerConfigs.java", "diffHunk": "@@ -38,7 +38,6 @@\n     props.put(\"group.id\", StringUtils.format(\"kafka-supervisor-%s\", IdUtils.getRandomId()));\n     props.put(\"auto.offset.reset\", \"none\");\n     props.put(\"enable.auto.commit\", \"false\");\n-    props.put(\"isolation.level\", \"read_committed\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODY1NDc0MQ=="}, "originalCommit": {"oid": "ac6dd037a910461462ee9c1e9994176c4c7aab4c"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTUxOTYyOQ==", "bodyText": "We don't know whether or not the users have enabled transactional message in their clusters, so changing the current behavior may cause backward compatibility problem.", "url": "https://github.com/apache/druid/pull/10551#discussion_r519519629", "createdAt": "2020-11-09T02:19:21Z", "author": {"login": "FrankChen021"}, "path": "extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/indexing/kafka/KafkaConsumerConfigs.java", "diffHunk": "@@ -38,7 +38,6 @@\n     props.put(\"group.id\", StringUtils.format(\"kafka-supervisor-%s\", IdUtils.getRandomId()));\n     props.put(\"auto.offset.reset\", \"none\");\n     props.put(\"enable.auto.commit\", \"false\");\n-    props.put(\"isolation.level\", \"read_committed\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODY1NDc0MQ=="}, "originalCommit": {"oid": "ac6dd037a910461462ee9c1e9994176c4c7aab4c"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTYwMzM2Mg==", "bodyText": "Make sense! I add a new property named consumeTransactionally in consumerProperties, which is a Kafka consumer level property to control isolation.level.\nIf users don't set consumeTransactionally or set consumeTransactionally true, druid will consume Kafka Transactionally by default.\nSet consumeTransactionally false here can disable druid to consume Kafka Transactionally through unset isolation.level property, which means druid can consume lower version of Kafka now like 0.10.x\nIn this way, we don't change current Druid default behavior and provide a way to let druid consume lower version Kafka.", "url": "https://github.com/apache/druid/pull/10551#discussion_r519603362", "createdAt": "2020-11-09T07:36:37Z", "author": {"login": "zhangyue19921010"}, "path": "extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/indexing/kafka/KafkaConsumerConfigs.java", "diffHunk": "@@ -38,7 +38,6 @@\n     props.put(\"group.id\", StringUtils.format(\"kafka-supervisor-%s\", IdUtils.getRandomId()));\n     props.put(\"auto.offset.reset\", \"none\");\n     props.put(\"enable.auto.commit\", \"false\");\n-    props.put(\"isolation.level\", \"read_committed\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODY1NDc0MQ=="}, "originalCommit": {"oid": "ac6dd037a910461462ee9c1e9994176c4c7aab4c"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTE5MTExOA==", "bodyText": "@FrankChen021  Hi Frank, sorry to bother you. I have tested this change in our Druid cluster recently. What should I do next ?", "url": "https://github.com/apache/druid/pull/10551#discussion_r521191118", "createdAt": "2020-11-11T08:24:42Z", "author": {"login": "zhangyue19921010"}, "path": "extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/indexing/kafka/KafkaConsumerConfigs.java", "diffHunk": "@@ -38,7 +38,6 @@\n     props.put(\"group.id\", StringUtils.format(\"kafka-supervisor-%s\", IdUtils.getRandomId()));\n     props.put(\"auto.offset.reset\", \"none\");\n     props.put(\"enable.auto.commit\", \"false\");\n-    props.put(\"isolation.level\", \"read_committed\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxODY1NDc0MQ=="}, "originalCommit": {"oid": "ac6dd037a910461462ee9c1e9994176c4c7aab4c"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI2NzgyMDE1OnYy", "diffSide": "RIGHT", "path": "extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/indexing/kafka/KafkaConsumerConfigs.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQxMDoyMjo0NFrOHxHFYA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQwNjoxMjoxMlrOHxr4nQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTI1ODMzNg==", "bodyText": "Putting this property in KafkaIndexTaskIOConfig.consumerProperties might cause some confusion. consumerProperties is designed to store kafka official properties. It's better to put the new property in KafkaIndexTaskIOConfig directly and put the code related to this property in KafkaRecordSupplier.addConsumerPropertiesFromConfig", "url": "https://github.com/apache/druid/pull/10551#discussion_r521258336", "createdAt": "2020-11-11T10:22:44Z", "author": {"login": "FrankChen021"}, "path": "extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/indexing/kafka/KafkaConsumerConfigs.java", "diffHunk": "@@ -30,15 +30,23 @@\n  */\n public class KafkaConsumerConfigs\n {\n-\n-  public static Map<String, Object> getConsumerProperties()\n+  public static Map<String, Object> getConsumerProperties(Map<String, Object> customerConsumerProperties)\n   {\n+    final Object value = customerConsumerProperties.remove(\"consumeTransactionally\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": null, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTg2MTI3Nw==", "bodyText": "Hi FrankChen021, I have put the new property consumeTransactionally in the KafkaSupervisorIOConfig directly. If users ignore this config or set this config true, Druid would consume Kafka transactionally same as current Druid behavior.\nSet consumeTransactionally false here can disable Druid to consume Kafka transactionally through unset isolation.level property, meanwhile Druid could consume lower version of Kafka now like 0.10.2.1 .\nIn this way, we don't change current Druid default behavior and provide a way to a way to make Druid have the ability to consume different versions of Kafka and remove the hard limitation that Druid(after 0.15.0) only can consume Kafka version 0.11.x or better.\nI have tested this PR in our Dev Druid cluster.  Please take a look.", "url": "https://github.com/apache/druid/pull/10551#discussion_r521861277", "createdAt": "2020-11-12T06:12:12Z", "author": {"login": "zhangyue19921010"}, "path": "extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/indexing/kafka/KafkaConsumerConfigs.java", "diffHunk": "@@ -30,15 +30,23 @@\n  */\n public class KafkaConsumerConfigs\n {\n-\n-  public static Map<String, Object> getConsumerProperties()\n+  public static Map<String, Object> getConsumerProperties(Map<String, Object> customerConsumerProperties)\n   {\n+    final Object value = customerConsumerProperties.remove(\"consumeTransactionally\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTI1ODMzNg=="}, "originalCommit": null, "originalPosition": 8}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI5MTQ2NDE5OnYy", "diffSide": "RIGHT", "path": "docs/development/extensions-core/kafka-ingestion.md", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QwODoxNjo0OVrOH0pD-g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QwOToyMTozN1rOH0riLw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDk2MDc2Mg==", "bodyText": "At the beginning of this doc, there's paragraph that describes the version of kafka that are supported. Since this PR\nprovides a way to support those kafka clusters lower than 0.11, we should also make some changes to the doc\n\nThe Kafka indexing service supports transactional topics which were introduced in Kafka 0.11.x. These changes make the\nKafka consumer that Druid uses incompatible with older brokers. Ensure that your Kafka brokers are version 0.11.x or\t> Kafka consumer that Druid uses incompatible with older brokers. Ensure that your Kafka brokers are version 0.11.x or\nbetter before using this functionality. Refer Kafka upgrade guide\t> better before using this functionality. Refer Kafka upgrade guide\nif you are using older version of Kafka brokers.\t> if you are using older version of Kafka brokers.", "url": "https://github.com/apache/druid/pull/10551#discussion_r524960762", "createdAt": "2020-11-17T08:16:49Z", "author": {"login": "FrankChen021"}, "path": "docs/development/extensions-core/kafka-ingestion.md", "diffHunk": "@@ -144,6 +144,7 @@ A sample supervisor spec is shown below:\n |`lateMessageRejectionStartDateTime`|ISO8601 DateTime|Configure tasks to reject messages with timestamps earlier than this date time; for example if this is set to `2016-01-01T11:00Z` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps earlier than *2016-01-01T11:00Z* will be dropped. This may help prevent concurrency issues if your data stream has late messages and you have multiple pipelines that need to operate on the same segments (e.g. a realtime and a nightly batch ingestion pipeline).|no (default == none)|\n |`lateMessageRejectionPeriod`|ISO8601 Period|Configure tasks to reject messages with timestamps earlier than this period before the task was created; for example if this is set to `PT1H` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps earlier than *2016-01-01T11:00Z* will be dropped. This may help prevent concurrency issues if your data stream has late messages and you have multiple pipelines that need to operate on the same segments (e.g. a realtime and a nightly batch ingestion pipeline). Please note that only one of `lateMessageRejectionPeriod` or `lateMessageRejectionStartDateTime` can be specified.|no (default == none)|\n |`earlyMessageRejectionPeriod`|ISO8601 Period|Configure tasks to reject messages with timestamps later than this period after the task reached its taskDuration; for example if this is set to `PT1H`, the taskDuration is set to `PT1H` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps later than *2016-01-01T14:00Z* will be dropped. **Note:** Tasks sometimes run past their task duration, for example, in cases of supervisor failover. Setting earlyMessageRejectionPeriod too low may cause messages to be dropped unexpectedly whenever a task runs past its originally configured task duration.|no (default == none)|\n+|`consumeTransactionally`|Boolean|Set `consumeTransactionally` false here can disable druid to consume Kafka in a transactional way. And druid could consume lower version of Kafka now, such as 0.10.2.1 |no (default == true)|\n ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1b4d4d86ff3833058c2609b2f767e6facf1480e0"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTAwMTI2Mw==", "bodyText": "@FrankChen021 Done  :)", "url": "https://github.com/apache/druid/pull/10551#discussion_r525001263", "createdAt": "2020-11-17T09:21:37Z", "author": {"login": "zhangyue19921010"}, "path": "docs/development/extensions-core/kafka-ingestion.md", "diffHunk": "@@ -144,6 +144,7 @@ A sample supervisor spec is shown below:\n |`lateMessageRejectionStartDateTime`|ISO8601 DateTime|Configure tasks to reject messages with timestamps earlier than this date time; for example if this is set to `2016-01-01T11:00Z` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps earlier than *2016-01-01T11:00Z* will be dropped. This may help prevent concurrency issues if your data stream has late messages and you have multiple pipelines that need to operate on the same segments (e.g. a realtime and a nightly batch ingestion pipeline).|no (default == none)|\n |`lateMessageRejectionPeriod`|ISO8601 Period|Configure tasks to reject messages with timestamps earlier than this period before the task was created; for example if this is set to `PT1H` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps earlier than *2016-01-01T11:00Z* will be dropped. This may help prevent concurrency issues if your data stream has late messages and you have multiple pipelines that need to operate on the same segments (e.g. a realtime and a nightly batch ingestion pipeline). Please note that only one of `lateMessageRejectionPeriod` or `lateMessageRejectionStartDateTime` can be specified.|no (default == none)|\n |`earlyMessageRejectionPeriod`|ISO8601 Period|Configure tasks to reject messages with timestamps later than this period after the task reached its taskDuration; for example if this is set to `PT1H`, the taskDuration is set to `PT1H` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps later than *2016-01-01T14:00Z* will be dropped. **Note:** Tasks sometimes run past their task duration, for example, in cases of supervisor failover. Setting earlyMessageRejectionPeriod too low may cause messages to be dropped unexpectedly whenever a task runs past its originally configured task duration.|no (default == none)|\n+|`consumeTransactionally`|Boolean|Set `consumeTransactionally` false here can disable druid to consume Kafka in a transactional way. And druid could consume lower version of Kafka now, such as 0.10.2.1 |no (default == true)|\n ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDk2MDc2Mg=="}, "originalCommit": {"oid": "1b4d4d86ff3833058c2609b2f767e6facf1480e0"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwMTQwNDg4OnYy", "diffSide": "RIGHT", "path": "extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/indexing/kafka/KafkaRecordSupplier.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMjoyMzoxNVrOH2KDCA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwODo0OTowN1rOH2Sdcg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0OTc2OA==", "bodyText": "please revert this unnecessary change", "url": "https://github.com/apache/druid/pull/10551#discussion_r526549768", "createdAt": "2020-11-19T02:23:15Z", "author": {"login": "FrankChen021"}, "path": "extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/indexing/kafka/KafkaRecordSupplier.java", "diffHunk": "@@ -37,6 +37,7 @@\n import org.apache.kafka.common.serialization.Deserializer;\n \n import javax.annotation.Nonnull;\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8ed2ef72b460e215d7ce710aac829e5e97e87a9c"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjY4NzYwMg==", "bodyText": "Done.", "url": "https://github.com/apache/druid/pull/10551#discussion_r526687602", "createdAt": "2020-11-19T08:49:07Z", "author": {"login": "zhangyue19921010"}, "path": "extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/indexing/kafka/KafkaRecordSupplier.java", "diffHunk": "@@ -37,6 +37,7 @@\n import org.apache.kafka.common.serialization.Deserializer;\n \n import javax.annotation.Nonnull;\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0OTc2OA=="}, "originalCommit": {"oid": "8ed2ef72b460e215d7ce710aac829e5e97e87a9c"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwMTQwNjQ0OnYy", "diffSide": "RIGHT", "path": "extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/supervisor/KafkaSupervisorTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMjoyMzo1OFrOH2KD9w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwODo0OToxM1rOH2SdtQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU1MDAwNw==", "bodyText": "please revert this unnecessary change", "url": "https://github.com/apache/druid/pull/10551#discussion_r526550007", "createdAt": "2020-11-19T02:23:58Z", "author": {"login": "FrankChen021"}, "path": "extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/supervisor/KafkaSupervisorTest.java", "diffHunk": "@@ -2445,7 +2446,9 @@ public void testCheckpointForInactiveTaskGroup()\n     final TaskLocation location2 = new TaskLocation(\"testHost2\", 145, -1);\n     Collection workItems = new ArrayList<>();\n     workItems.add(new TestTaskRunnerWorkItem(id1, null, location1));\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8ed2ef72b460e215d7ce710aac829e5e97e87a9c"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjY4NzY2OQ==", "bodyText": "Done.", "url": "https://github.com/apache/druid/pull/10551#discussion_r526687669", "createdAt": "2020-11-19T08:49:13Z", "author": {"login": "zhangyue19921010"}, "path": "extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/supervisor/KafkaSupervisorTest.java", "diffHunk": "@@ -2445,7 +2446,9 @@ public void testCheckpointForInactiveTaskGroup()\n     final TaskLocation location2 = new TaskLocation(\"testHost2\", 145, -1);\n     Collection workItems = new ArrayList<>();\n     workItems.add(new TestTaskRunnerWorkItem(id1, null, location1));\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU1MDAwNw=="}, "originalCommit": {"oid": "8ed2ef72b460e215d7ce710aac829e5e97e87a9c"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwMTQwNjU0OnYy", "diffSide": "RIGHT", "path": "extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/supervisor/KafkaSupervisorTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMjoyNDowMVrOH2KECg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwODo0OToxOFrOH2Sd6Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU1MDAyNg==", "bodyText": "please revert this unnecessary change", "url": "https://github.com/apache/druid/pull/10551#discussion_r526550026", "createdAt": "2020-11-19T02:24:01Z", "author": {"login": "FrankChen021"}, "path": "extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/supervisor/KafkaSupervisorTest.java", "diffHunk": "@@ -2445,7 +2446,9 @@ public void testCheckpointForInactiveTaskGroup()\n     final TaskLocation location2 = new TaskLocation(\"testHost2\", 145, -1);\n     Collection workItems = new ArrayList<>();\n     workItems.add(new TestTaskRunnerWorkItem(id1, null, location1));\n+\n     workItems.add(new TestTaskRunnerWorkItem(id2, null, location2));\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8ed2ef72b460e215d7ce710aac829e5e97e87a9c"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjY4NzcyMQ==", "bodyText": "Done.", "url": "https://github.com/apache/druid/pull/10551#discussion_r526687721", "createdAt": "2020-11-19T08:49:18Z", "author": {"login": "zhangyue19921010"}, "path": "extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/supervisor/KafkaSupervisorTest.java", "diffHunk": "@@ -2445,7 +2446,9 @@ public void testCheckpointForInactiveTaskGroup()\n     final TaskLocation location2 = new TaskLocation(\"testHost2\", 145, -1);\n     Collection workItems = new ArrayList<>();\n     workItems.add(new TestTaskRunnerWorkItem(id1, null, location1));\n+\n     workItems.add(new TestTaskRunnerWorkItem(id2, null, location2));\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU1MDAyNg=="}, "originalCommit": {"oid": "8ed2ef72b460e215d7ce710aac829e5e97e87a9c"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0OTIwNzcwOnYy", "diffSide": "RIGHT", "path": "extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/indexing/kafka/KafkaConsumerConfigs.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQwMTowNzo1M1rOH9GPig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQwMTowMzo1N1rOH-8J_w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzgyNzQ2Ng==", "bodyText": "it would likely be simpler to leave this alone, remove the line props.put(\"isolation.level\".. altogether\nand put something like  props.put(\"isolation.level\", customerConsumerProperties.getOrDefault(\"isolation.level\", \"read_committed\"));  right after https://github.com/apache/druid/blob/master/extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/indexing/kafka/supervisor/KafkaSupervisorIOConfig.java#L78", "url": "https://github.com/apache/druid/pull/10551#discussion_r533827466", "createdAt": "2020-12-02T01:07:53Z", "author": {"login": "himanshug"}, "path": "extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/indexing/kafka/KafkaConsumerConfigs.java", "diffHunk": "@@ -31,14 +31,14 @@\n public class KafkaConsumerConfigs\n {\n \n-  public static Map<String, Object> getConsumerProperties()\n+  public static Map<String, Object> getConsumerProperties(Map<String, Object> customerConsumerProperties)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8201b0b2ca8b74d2a209186708a9b55aa5cfcc57"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTI5NzUxOA==", "bodyText": "Hi @himanshug Thanks for your review!\nI agree with it would likely be simpler to leave this alone, remove the line props.put(\"isolation.level\".. altogether.  But I think maybe it is not very appropriate to modify https://github.com/apache/druid/blob/master/extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/indexing/kafka/supervisor/KafkaSupervisorIOConfig.java#L78\nI have tried to do changes in  KafkaSupervisorIOConfig.java as you said (cc59d8b)\n    this.consumerProperties = Preconditions.checkNotNull(consumerProperties, \"consumerProperties\");\n    consumerProperties.putIfAbsent(\"isolation.level\", \"read_committed\");\n    Preconditions.checkNotNull(\n\nand functional testing is fine while UT is failed at \n  \n    \n      druid/extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/KafkaIOConfigTest.java\n    \n    \n         Line 363\n      in\n      ac6d703\n    \n    \n    \n    \n\n        \n          \n           Assert.assertEquals(oldConfig.getConsumerProperties(), currentConfig.getConsumerProperties()); \n        \n    \n  \n\n and \n  \n    \n      druid/extensions-core/kafka-indexing-service/src/test/java/org/apache/druid/indexing/kafka/KafkaIOConfigTest.java\n    \n    \n         Line 332\n      in\n      ac6d703\n    \n    \n    \n    \n\n        \n          \n           Assert.assertEquals(currentConfig.getConsumerProperties(), oldConfig.getConsumerProperties()); \n        \n    \n  \n\n\nThese failure means changes in KafkaSupervisorIOConfig may cause compatibility issues when deserialize from old IoConfig to new IoConfig or deserialize from new IoConfig to old IoConfig. In other words, we need to ensure that the deserialize between new IoConfig and old IoConfig is completely consistent and smooth.\nSo I switched to a safer way in the latest commit.\nAll the changes is tested on Dev cluster.\nPTAL :)", "url": "https://github.com/apache/druid/pull/10551#discussion_r535297518", "createdAt": "2020-12-03T14:51:12Z", "author": {"login": "zhangyue19921010"}, "path": "extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/indexing/kafka/KafkaConsumerConfigs.java", "diffHunk": "@@ -31,14 +31,14 @@\n public class KafkaConsumerConfigs\n {\n \n-  public static Map<String, Object> getConsumerProperties()\n+  public static Map<String, Object> getConsumerProperties(Map<String, Object> customerConsumerProperties)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzgyNzQ2Ng=="}, "originalCommit": {"oid": "8201b0b2ca8b74d2a209186708a9b55aa5cfcc57"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTc1OTM1OQ==", "bodyText": "we need to ensure that the deserialize between new IoConfig and old IoConfig is completely consistent and smooth\n\nwell, my main concern was the consumeTransactionally param which has been removed . Though I fail to see why simply adding the default to KafkaSupervisorIOConfig.java would not have same behavior functionally (or for backward compatibility as well)... but I am not so worried about the specifics at this point as it is easy to change later if needed.", "url": "https://github.com/apache/druid/pull/10551#discussion_r535759359", "createdAt": "2020-12-04T01:03:57Z", "author": {"login": "himanshug"}, "path": "extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/indexing/kafka/KafkaConsumerConfigs.java", "diffHunk": "@@ -31,14 +31,14 @@\n public class KafkaConsumerConfigs\n {\n \n-  public static Map<String, Object> getConsumerProperties()\n+  public static Map<String, Object> getConsumerProperties(Map<String, Object> customerConsumerProperties)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzgyNzQ2Ng=="}, "originalCommit": {"oid": "8201b0b2ca8b74d2a209186708a9b55aa5cfcc57"}, "originalPosition": 5}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3086, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}