{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQ1NTk5ODU5", "number": 10149, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QyMDoxNzoyNFrOEMOkAw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QyMDoxNzoyNFrOEMOkAw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgxMjU2OTYzOnYy", "diffSide": "RIGHT", "path": "docs/design/architecture.md", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QyMDoxNzoyNFrOGuOEeg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QyMTozMDowOFrOGuQTgg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTExODIwMg==", "bodyText": "partially-ingested data discarded -> partially-ingested data \"is\" discarded", "url": "https://github.com/apache/druid/pull/10149#discussion_r451118202", "createdAt": "2020-07-07T20:17:24Z", "author": {"login": "surekhasaharan"}, "path": "docs/design/architecture.md", "diffHunk": "@@ -213,6 +213,75 @@ this will generally start off `true` and then become `false` as the segment is p\n published segments. Generally this is a transient state, and segments in this state will soon have their `used` flag\n automatically set to false.\n \n+### Availability and consistency\n+\n+Druid has an architectural separation between ingestion and querying, as described above in\n+[Indexing and handoff](#indexing-and-handoff). This means that when understanding Druid's availability and\n+consistency properties, we must look at each function separately.\n+\n+On the **ingestion side**, Druid's primary [ingestion methods](../ingestion/index.md#ingestion-methods) are all\n+pull-based and offer transactional guarantees. This means that you are guaranteed that ingestion using these will\n+publish in an all-or-nothing manner:\n+\n+- Supervised \"seekable-stream\" ingestion methods like [Kafka](../development/extensions-core/kafka-ingestion.md) and\n+[Kinesis](../development/extensions-core/kinesis-ingestion.md). With these methods, Druid commits stream offsets to its\n+[metadata store](#metadata-storage) alongside segment metadata, in the same transaction. Note that ingestion of data\n+that has not yet been published can be rolled back if ingestion tasks fail. In this case, partially-ingested data\n+discarded, and Druid will resume ingestion from the last committed set of stream offsets. This ensures exactly-once", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "321345a8cb80d9962efd1743734f7485d3bd89d9"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTE1NDgxOA==", "bodyText": "Thanks, fixed.", "url": "https://github.com/apache/druid/pull/10149#discussion_r451154818", "createdAt": "2020-07-07T21:30:08Z", "author": {"login": "gianm"}, "path": "docs/design/architecture.md", "diffHunk": "@@ -213,6 +213,75 @@ this will generally start off `true` and then become `false` as the segment is p\n published segments. Generally this is a transient state, and segments in this state will soon have their `used` flag\n automatically set to false.\n \n+### Availability and consistency\n+\n+Druid has an architectural separation between ingestion and querying, as described above in\n+[Indexing and handoff](#indexing-and-handoff). This means that when understanding Druid's availability and\n+consistency properties, we must look at each function separately.\n+\n+On the **ingestion side**, Druid's primary [ingestion methods](../ingestion/index.md#ingestion-methods) are all\n+pull-based and offer transactional guarantees. This means that you are guaranteed that ingestion using these will\n+publish in an all-or-nothing manner:\n+\n+- Supervised \"seekable-stream\" ingestion methods like [Kafka](../development/extensions-core/kafka-ingestion.md) and\n+[Kinesis](../development/extensions-core/kinesis-ingestion.md). With these methods, Druid commits stream offsets to its\n+[metadata store](#metadata-storage) alongside segment metadata, in the same transaction. Note that ingestion of data\n+that has not yet been published can be rolled back if ingestion tasks fail. In this case, partially-ingested data\n+discarded, and Druid will resume ingestion from the last committed set of stream offsets. This ensures exactly-once", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTExODIwMg=="}, "originalCommit": {"oid": "321345a8cb80d9962efd1743734f7485d3bd89d9"}, "originalPosition": 18}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2214, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}