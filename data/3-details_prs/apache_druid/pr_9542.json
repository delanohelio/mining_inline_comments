{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzkxMjA4NTM3", "number": 9542, "title": "Add integration tests for HDFS", "bodyText": "Adding HDFS deep storage and HDFS inputSource integration tests\nIn particular this covers: (left side is the inputSource type and right side is the deep storage type)\nHDFS - HDFS\nHDFS - S3\nHDFS - Azure\nHDFS - GCS\nS3 - HDFS\nAzure - HDFS\nGCS - HDFS\nThis PR has:\n\n been self-reviewed.\n added documentation for new or modified features or behaviors.\n added Javadocs for most classes and all non-trivial methods. Linked related entities via Javadoc links.\n added or updated version, license, or notice information in licenses.yaml\n added comments explaining the \"why\" and the intent of the code wherever would not be obvious for an unfamiliar reader.\n added unit tests or modified existing tests to cover new code paths.\n added integration tests.\n been tested in a test Druid cluster.", "createdAt": "2020-03-19T20:00:09Z", "url": "https://github.com/apache/druid/pull/9542", "merged": true, "mergeCommit": {"oid": "5f127a1829839c402f16c7e6aab95be445d12216"}, "closed": true, "closedAt": "2020-03-20T22:46:08Z", "author": {"login": "maytasm"}, "timelineItems": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcPG6XwAH2gAyMzkxMjA4NTM3OmJiYjM4NjQ3NzVhYzk4NDE5NmYzY2IwNzE5ZDRmNzI1MzBhYTZjNjQ=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcPoe9hAFqTM3ODg1MDEzMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "bbb3864775ac984196f3cb0719d4f72530aa6c64", "author": {"user": {"login": "maytasm", "name": "Maytas Monsereenusorn"}}, "url": "https://github.com/apache/druid/commit/bbb3864775ac984196f3cb0719d4f72530aa6c64", "committedDate": "2020-03-19T07:38:08Z", "message": "HDFS IT"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ca910bcfd19a603120b8b9a7ad809088680b9e18", "author": {"user": {"login": "maytasm", "name": "Maytas Monsereenusorn"}}, "url": "https://github.com/apache/druid/commit/ca910bcfd19a603120b8b9a7ad809088680b9e18", "committedDate": "2020-03-19T07:44:03Z", "message": "HDFS IT"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "920cb96ee6830250bb5ec9e12e41fc10dd497410", "author": {"user": {"login": "maytasm", "name": "Maytas Monsereenusorn"}}, "url": "https://github.com/apache/druid/commit/920cb96ee6830250bb5ec9e12e41fc10dd497410", "committedDate": "2020-03-20T06:54:11Z", "message": "HDFS IT"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fcf697dc224b4b51b7024f258da366e609b866d3", "author": {"user": {"login": "maytasm", "name": "Maytas Monsereenusorn"}}, "url": "https://github.com/apache/druid/commit/fcf697dc224b4b51b7024f258da366e609b866d3", "committedDate": "2020-03-20T07:05:22Z", "message": "fix checkstyle"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc4MjYxOTEx", "url": "https://github.com/apache/druid/pull/9542#pullrequestreview-378261911", "createdAt": "2020-03-20T06:59:51Z", "commit": {"oid": "920cb96ee6830250bb5ec9e12e41fc10dd497410"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQwNjo1OTo1MlrOF5JJMQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQwNzowMzoxOVrOF5JMlg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQ2Mjk2MQ==", "bodyText": "Mounting RESOURCEDIR which has some additional test data files", "url": "https://github.com/apache/druid/pull/9542#discussion_r395462961", "createdAt": "2020-03-20T06:59:52Z", "author": {"login": "maytasm"}, "path": "integration-tests/run_cluster.sh", "diffHunk": "@@ -157,44 +160,11 @@ fi\n \n # Start docker containers for all Druid processes and dependencies\n {\n-  # Start zookeeper and kafka\n-  docker run -d --privileged --net druid-it-net --ip 172.172.172.2 ${COMMON_ENV} --name druid-zookeeper-kafka -p 2181:2181 -p 9092:9092 -p 9093:9093 -v $SHARED_DIR:/shared -v $SERVICE_SUPERVISORDS_DIR/zookeeper.conf:$SUPERVISORDIR/zookeeper.conf -v $SERVICE_SUPERVISORDS_DIR/kafka.conf:$SUPERVISORDIR/kafka.conf druid/cluster\n-\n-  # Start MYSQL\n-  docker run -d --privileged --net druid-it-net --ip 172.172.172.3 ${COMMON_ENV} --name druid-metadata-storage -v $SHARED_DIR:/shared -v $SERVICE_SUPERVISORDS_DIR/metadata-storage.conf:$SUPERVISORDIR/metadata-storage.conf druid/cluster\n-\n-  # Start Overlord\n-  docker run -d --privileged --net druid-it-net --ip 172.172.172.4 ${COMMON_ENV} ${OVERLORD_ENV} ${OVERRIDE_ENV} --name druid-overlord -p 8090:8090 -p 8290:8290 -v $SHARED_DIR:/shared -v $SERVICE_SUPERVISORDS_DIR/druid.conf:$SUPERVISORDIR/druid.conf --link druid-metadata-storage:druid-metadata-storage --link druid-zookeeper-kafka:druid-zookeeper-kafka druid/cluster\n-\n-  # Start Coordinator\n-  docker run -d --privileged --net druid-it-net --ip 172.172.172.5 ${COMMON_ENV} ${COORDINATOR_ENV} ${OVERRIDE_ENV} --name druid-coordinator -p 8081:8081 -p 8281:8281 -v $SHARED_DIR:/shared -v $SERVICE_SUPERVISORDS_DIR/druid.conf:$SUPERVISORDIR/druid.conf --link druid-overlord:druid-overlord --link druid-metadata-storage:druid-metadata-storage --link druid-zookeeper-kafka:druid-zookeeper-kafka druid/cluster\n-\n-  # Start Historical\n-  docker run -d --privileged --net druid-it-net --ip 172.172.172.6 ${COMMON_ENV} ${HISTORICAL_ENV} ${OVERRIDE_ENV} --name druid-historical -p 8083:8083 -p 8283:8283 -v $SHARED_DIR:/shared -v $SERVICE_SUPERVISORDS_DIR/druid.conf:$SUPERVISORDIR/druid.conf --link druid-zookeeper-kafka:druid-zookeeper-kafka druid/cluster\n-\n-  # Start Middlemanger\n-  docker run -d --privileged --net druid-it-net --ip 172.172.172.7 ${COMMON_ENV} ${MIDDLEMANAGER_ENV} ${OVERRIDE_ENV} --name druid-middlemanager -p 8091:8091 -p 8291:8291 -p 8100:8100 -p 8101:8101 -p 8102:8102 -p 8103:8103 -p 8104:8104 -p 8105:8105 -p 8300:8300 -p 8301:8301 -p 8302:8302 -p 8303:8303 -p 8304:8304 -p 8305:8305 -v $RESOURCEDIR:/resources -v $SHARED_DIR:/shared -v $SERVICE_SUPERVISORDS_DIR/druid.conf:$SUPERVISORDIR/druid.conf --link druid-zookeeper-kafka:druid-zookeeper-kafka --link druid-overlord:druid-overlord druid/cluster\n-\n-  # Start Broker\n-  docker run -d --privileged --net druid-it-net --ip 172.172.172.8 ${COMMON_ENV} ${BROKER_ENV} ${OVERRIDE_ENV} --name druid-broker -p 8082:8082 -p 8282:8282 -v $SHARED_DIR:/shared -v $SERVICE_SUPERVISORDS_DIR/druid.conf:$SUPERVISORDIR/druid.conf --link druid-zookeeper-kafka:druid-zookeeper-kafka --link druid-middlemanager:druid-middlemanager --link druid-historical:druid-historical druid/cluster\n-\n-  # Start Router\n-  docker run -d --privileged --net druid-it-net --ip 172.172.172.9 ${COMMON_ENV} ${ROUTER_ENV} ${OVERRIDE_ENV} --name druid-router -p 8888:8888 -p 9088:9088 -v $SHARED_DIR:/shared -v $SERVICE_SUPERVISORDS_DIR/druid.conf:$SUPERVISORDIR/druid.conf --link druid-zookeeper-kafka:druid-zookeeper-kafka --link druid-coordinator:druid-coordinator --link druid-broker:druid-broker druid/cluster\n-\n-  # Start Router with permissive TLS settings (client auth enabled, no hostname verification, no revocation check)\n-  docker run -d --privileged --net druid-it-net --ip 172.172.172.10 ${COMMON_ENV} ${ROUTER_PERMISSIVE_TLS_ENV} ${OVERRIDE_ENV} --name druid-router-permissive-tls -p 8889:8889 -p 9089:9089 -v $SHARED_DIR:/shared -v $SERVICE_SUPERVISORDS_DIR/druid.conf:$SUPERVISORDIR/druid.conf --link druid-zookeeper-kafka:druid-zookeeper-kafka --link druid-coordinator:druid-coordinator --link druid-broker:druid-broker druid/cluster\n-\n-  # Start Router with TLS but no client auth\n-  docker run -d --privileged --net druid-it-net --ip 172.172.172.11 ${COMMON_ENV} ${ROUTER_NO_CLIENT_AUTH_TLS_ENV} ${OVERRIDE_ENV} --name druid-router-no-client-auth-tls -p 8890:8890 -p 9090:9090 -v $SHARED_DIR:/shared -v $SERVICE_SUPERVISORDS_DIR/druid.conf:$SUPERVISORDIR/druid.conf --link druid-zookeeper-kafka:druid-zookeeper-kafka --link druid-coordinator:druid-coordinator --link druid-broker:druid-broker druid/cluster\n-\n-  # Start Router with custom TLS cert checkers\n-  docker run -d --privileged --net druid-it-net --ip 172.172.172.12 ${COMMON_ENV} ${ROUTER_CUSTOM_CHECK_TLS_ENV} ${OVERRIDE_ENV} --hostname druid-router-custom-check-tls --name druid-router-custom-check-tls -p 8891:8891 -p 9091:9091 -v $SHARED_DIR:/shared -v $SERVICE_SUPERVISORDS_DIR/druid.conf:$SUPERVISORDIR/druid.conf --link druid-zookeeper-kafka:druid-zookeeper-kafka --link druid-coordinator:druid-coordinator --link druid-broker:druid-broker druid/cluster\n-\n   # Start Hadoop docker if needed\n   if [ -n \"$DRUID_INTEGRATION_TEST_START_HADOOP_DOCKER\" ] && [ \"$DRUID_INTEGRATION_TEST_START_HADOOP_DOCKER\" == true ]\n   then\n     # Start Hadoop docker container\n-    docker run -d --privileged --net druid-it-net --ip 172.172.172.13 -h druid-it-hadoop --name druid-it-hadoop -p 2049:2049 -p 2122:2122 -p 8020:8020 -p 8021:8021 -p 8030:8030 -p 8031:8031 -p 8032:8032 -p 8033:8033 -p 8040:8040 -p 8042:8042 -p 8088:8088 -p 8443:8443 -p 9000:9000 -p 10020:10020 -p 19888:19888 -p 34455:34455 -p 49707:49707 -p 50010:50010 -p 50020:50020 -p 50030:50030 -p 50060:50060 -p 50070:50070 -p 50075:50075 -p 50090:50090 -p 51111:51111 -v $SHARED_DIR:/shared druid-it/hadoop:2.8.5 sh -c \"/etc/bootstrap.sh && tail -f /dev/null\"\n+    docker run -d --privileged --net druid-it-net --ip 172.172.172.13 -h druid-it-hadoop --name druid-it-hadoop -p 2049:2049 -p 2122:2122 -p 8020:8020 -p 8021:8021 -p 8030:8030 -p 8031:8031 -p 8032:8032 -p 8033:8033 -p 8040:8040 -p 8042:8042 -p 8088:8088 -p 8443:8443 -p 9000:9000 -p 10020:10020 -p 19888:19888 -p 34455:34455 -p 49707:49707 -p 50010:50010 -p 50020:50020 -p 50030:50030 -p 50060:50060 -p 50070:50070 -p 50075:50075 -p 50090:50090 -p 51111:51111 -v $RESOURCEDIR:/resources -v $SHARED_DIR:/shared druid-it/hadoop:2.8.5 sh -c \"/etc/bootstrap.sh && tail -f /dev/null\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "920cb96ee6830250bb5ec9e12e41fc10dd497410"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQ2MzExMQ==", "bodyText": "Moved all these to after starting Hadoop since we need Hadoop XML files to be copied to shared before starting Druid", "url": "https://github.com/apache/druid/pull/9542#discussion_r395463111", "createdAt": "2020-03-20T07:00:27Z", "author": {"login": "maytasm"}, "path": "integration-tests/run_cluster.sh", "diffHunk": "@@ -218,10 +188,44 @@ fi\n     docker exec -t druid-it-hadoop sh -c \"./usr/local/hadoop/bin/hdfs dfs -chmod -R 777 /user\"\n     # Copy data files to Hadoop container\n     docker exec -t druid-it-hadoop sh -c \"./usr/local/hadoop/bin/hdfs dfs -put /shared/wikiticker-it/wikiticker-2015-09-12-sampled.json.gz /quickstart/wikiticker-2015-09-12-sampled.json.gz\"\n+    docker exec -t druid-it-hadoop sh -c \"./usr/local/hadoop/bin/hdfs dfs -put /resources/data/batch_index /batch_index\"\n     echo \"Finished setting up druid hadoop dirs\"\n \n     echo \"Copying Hadoop XML files to shared\"\n     docker exec -t druid-it-hadoop sh -c \"cp /usr/local/hadoop/etc/hadoop/*.xml /shared/hadoop_xml\"\n     echo \"Copied Hadoop XML files to shared\"\n   fi\n+\n+  # Start zookeeper and kafka", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "920cb96ee6830250bb5ec9e12e41fc10dd497410"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQ2MzgzMA==", "bodyText": "Hadoop InputSource has a bug with batch parallel so using this non parallel for now.", "url": "https://github.com/apache/druid/pull/9542#discussion_r395463830", "createdAt": "2020-03-20T07:03:19Z", "author": {"login": "maytasm"}, "path": "integration-tests/src/test/resources/indexer/wikipedia_cloud_simple_index_task.json", "diffHunk": "@@ -0,0 +1,81 @@\n+{", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "920cb96ee6830250bb5ec9e12e41fc10dd497410"}, "originalPosition": 1}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc4ODQ1NTU4", "url": "https://github.com/apache/druid/pull/9542#pullrequestreview-378845558", "createdAt": "2020-03-20T22:30:07Z", "commit": {"oid": "fcf697dc224b4b51b7024f258da366e609b866d3"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc4ODUwMTMx", "url": "https://github.com/apache/druid/pull/9542#pullrequestreview-378850131", "createdAt": "2020-03-20T22:44:58Z", "commit": {"oid": "fcf697dc224b4b51b7024f258da366e609b866d3"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2691, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}