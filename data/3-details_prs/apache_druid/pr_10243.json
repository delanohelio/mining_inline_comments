{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDYzNTY3Mjk1", "number": 10243, "title": "Add maxNumFiles to splitHintSpec", "bodyText": "Description\nThis PR adds maxNumFiles to maxSize splitHintSpec which is a new limit on the max number of files in a split. Also, the human readable format is now supported for maxSplitSize.\n\nThis PR has:\n\n been self-reviewed.\n\n using the concurrency checklist (Remove this item if the PR doesn't have any relation to concurrency.)\n\n\n added documentation for new or modified features or behaviors.\n added Javadocs for most classes and all non-trivial methods. Linked related entities via Javadoc links.\n added or updated version, license, or notice information in licenses.yaml\n added comments explaining the \"why\" and the intent of the code wherever would not be obvious for an unfamiliar reader.\n added unit tests or modified existing tests to cover new code paths, ensuring the threshold for code coverage is met.\n added integration tests.\n been tested in a test Druid cluster.", "createdAt": "2020-08-05T18:29:58Z", "url": "https://github.com/apache/druid/pull/10243", "merged": true, "mergeCommit": {"oid": "b5b3e6ecce6f5346c4a1ed440b27656dd3b130a5"}, "closed": true, "closedAt": "2020-08-21T16:43:58Z", "author": {"login": "jihoonson"}, "timelineItems": {"totalCount": 20, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc7_ePkAH2gAyNDYzNTY3Mjk1OmVkMDFkYzE2YWVjOWI1MGQ5NTRlNmFlZjg0NjI3YmNkNjE0YWExOTA=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdA3I6egFqTQ3MjAwMDU1MQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "ed01dc16aec9b50d954e6aef84627bcd614aa190", "author": {"user": {"login": "jihoonson", "name": "Jihoon Son"}}, "url": "https://github.com/apache/druid/commit/ed01dc16aec9b50d954e6aef84627bcd614aa190", "committedDate": "2020-08-05T18:24:40Z", "message": "Add maxNumFiles to splitHintSpec"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d8477cf9c28d56ca876d81fcc4d1014e185f9cb3", "author": {"user": {"login": "jihoonson", "name": "Jihoon Son"}}, "url": "https://github.com/apache/druid/commit/d8477cf9c28d56ca876d81fcc4d1014e185f9cb3", "committedDate": "2020-08-05T18:27:47Z", "message": "missing link"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a69fe7c33cfa29ae746ba3ba688a1b97f40799c6", "author": {"user": {"login": "jihoonson", "name": "Jihoon Son"}}, "url": "https://github.com/apache/druid/commit/a69fe7c33cfa29ae746ba3ba688a1b97f40799c6", "committedDate": "2020-08-05T21:46:26Z", "message": "fix build failure; use maxNumFiles for integration tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "34c620e5d1ce50f66e0e4676a3c6904ed25bf03f", "author": {"user": {"login": "jihoonson", "name": "Jihoon Son"}}, "url": "https://github.com/apache/druid/commit/34c620e5d1ce50f66e0e4676a3c6904ed25bf03f", "committedDate": "2020-08-05T22:47:46Z", "message": "spelling"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "93a6f45cf0b64d8e0ab6eca097a4e9bccaab65e9", "author": {"user": {"login": "jihoonson", "name": "Jihoon Son"}}, "url": "https://github.com/apache/druid/commit/93a6f45cf0b64d8e0ab6eca097a4e9bccaab65e9", "committedDate": "2020-08-13T18:30:30Z", "message": "lower default"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY3NzE3Nzg3", "url": "https://github.com/apache/druid/pull/10243#pullrequestreview-467717787", "createdAt": "2020-08-14T16:39:52Z", "commit": {"oid": "93a6f45cf0b64d8e0ab6eca097a4e9bccaab65e9"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQxNjozOTo1MlrOHA7VJg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQxNjozOTo1MlrOHA7VJg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDczNDExOA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            |maxNumFiles|Maximum number of input files to process in a single task. This limit is to avoid task failures when the ingestion spec is too long. There are two known limits on the max size of serialized ingestion spec, i.e., the max ZNode size in ZooKeeper (`jute.maxbuffer`) and the max packet size in MySQL (`max_allowed_packet`). These can make ingestion tasks fail if the serialized ingestion spec size hits one of them.|5000|no|\n          \n          \n            \n            |maxNumFiles|Maximum number of input files to process in a single task. This limit is to avoid task failures when the ingestion spec is too long. There are two known limits on the max size of serialized ingestion spec, i.e., the max ZNode size in ZooKeeper (`jute.maxbuffer`) and the max packet size in MySQL (`max_allowed_packet`). These can make ingestion tasks fail if the serialized ingestion spec size hits one of them.|1000|no|", "url": "https://github.com/apache/druid/pull/10243#discussion_r470734118", "createdAt": "2020-08-14T16:39:52Z", "author": {"login": "abhishekagarwal87"}, "path": "docs/ingestion/native-batch.md", "diffHunk": "@@ -232,7 +232,8 @@ The size-based split hint spec is respected by all splittable input sources exce\n |property|description|default|required?|\n |--------|-----------|-------|---------|\n |type|This should always be `maxSize`.|none|yes|\n-|maxSplitSize|Maximum number of bytes of input files to process in a single task. If a single file is larger than this number, it will be processed by itself in a single task (Files are never split across tasks yet).|500MB|no|\n+|maxSplitSize|Maximum number of bytes of input files to process in a single task. If a single file is larger than this number, it will be processed by itself in a single task (Files are never split across tasks yet). [Human-readable format](../configuration/human-readable-byte.md) is supported.|500MiB|no|\n+|maxNumFiles|Maximum number of input files to process in a single task. This limit is to avoid task failures when the ingestion spec is too long. There are two known limits on the max size of serialized ingestion spec, i.e., the max ZNode size in ZooKeeper (`jute.maxbuffer`) and the max packet size in MySQL (`max_allowed_packet`). These can make ingestion tasks fail if the serialized ingestion spec size hits one of them.|5000|no|", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "93a6f45cf0b64d8e0ab6eca097a4e9bccaab65e9"}, "originalPosition": 6}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "65657f6eec028817ce32f90dcea15e382e3ed3ef", "author": {"user": {"login": "jihoonson", "name": "Jihoon Son"}}, "url": "https://github.com/apache/druid/commit/65657f6eec028817ce32f90dcea15e382e3ed3ef", "committedDate": "2020-08-14T18:01:31Z", "message": "Update docs/ingestion/native-batch.md\n\nCo-authored-by: Abhishek Agarwal <1477457+abhishekagarwal87@users.noreply.github.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY3OTA0MDgw", "url": "https://github.com/apache/druid/pull/10243#pullrequestreview-467904080", "createdAt": "2020-08-14T22:22:23Z", "commit": {"oid": "65657f6eec028817ce32f90dcea15e382e3ed3ef"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQyMjoyMjoyM1rOHBEy7g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQyMjo0Mzo0OFrOHBFHSw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg4OTE5OA==", "bodyText": "Should we keep one of these tests to use maxSplitSize so that we know that the old specs continue to work", "url": "https://github.com/apache/druid/pull/10243#discussion_r470889198", "createdAt": "2020-08-14T22:22:23Z", "author": {"login": "suneet-s"}, "path": "integration-tests/src/test/resources/indexer/wikipedia_parallel_ingest_segment_index_task.json", "diffHunk": "@@ -61,7 +61,7 @@\n       \"forceGuaranteedRollup\": \"%%FORCE_GUARANTEED_ROLLUP%%\",\n       \"splitHintSpec\": {\n         \"type\": \"maxSize\",\n-        \"maxSplitSize\": 1", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "65657f6eec028817ce32f90dcea15e382e3ed3ef"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg5MDYzNg==", "bodyText": "This is a great comment! Thank you!", "url": "https://github.com/apache/druid/pull/10243#discussion_r470890636", "createdAt": "2020-08-14T22:28:16Z", "author": {"login": "suneet-s"}, "path": "core/src/main/java/org/apache/druid/data/input/MaxSizeSplitHintSpec.java", "diffHunk": "@@ -43,22 +44,53 @@\n   public static final String TYPE = \"maxSize\";\n \n   @VisibleForTesting\n-  static final long DEFAULT_MAX_SPLIT_SIZE = 512 * 1024 * 1024;\n+  static final HumanReadableBytes DEFAULT_MAX_SPLIT_SIZE = new HumanReadableBytes(\"512MiB\");\n \n-  private final long maxSplitSize;\n+  /**\n+   * There are two known issues when a split contains a large list of files.\n+   *\n+   * - 'jute.maxbuffer' in ZooKeeper. This system property controls the max size of ZNode. As its default is 500KB,\n+   *   task allocation can fail if the serialized ingestion spec is larger than this limit.\n+   * - 'max_allowed_packet' in MySQL. This is the max size of a communication packet sent to a MySQL server.\n+   *   The default is either 64MB or 4MB depending on MySQL version. Updating metadata store can fail if the serialized\n+   *   ingestion spec is larger than this limit.\n+   *\n+   * The default is consertively chosen as 1000.\n+   */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "65657f6eec028817ce32f90dcea15e382e3ed3ef"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg5MzA5MQ==", "bodyText": "Should we add a preconditionCheck on maxNumFiles? If the user has entered maxNumFiles, it should be a positive number >= 1\nI think what you've implemented works even with negative numbers, but maybe it's better to tell the user they're doing something strange.", "url": "https://github.com/apache/druid/pull/10243#discussion_r470893091", "createdAt": "2020-08-14T22:37:46Z", "author": {"login": "suneet-s"}, "path": "core/src/main/java/org/apache/druid/data/input/MaxSizeSplitHintSpec.java", "diffHunk": "@@ -43,22 +44,53 @@\n   public static final String TYPE = \"maxSize\";\n \n   @VisibleForTesting\n-  static final long DEFAULT_MAX_SPLIT_SIZE = 512 * 1024 * 1024;\n+  static final HumanReadableBytes DEFAULT_MAX_SPLIT_SIZE = new HumanReadableBytes(\"512MiB\");\n \n-  private final long maxSplitSize;\n+  /**\n+   * There are two known issues when a split contains a large list of files.\n+   *\n+   * - 'jute.maxbuffer' in ZooKeeper. This system property controls the max size of ZNode. As its default is 500KB,\n+   *   task allocation can fail if the serialized ingestion spec is larger than this limit.\n+   * - 'max_allowed_packet' in MySQL. This is the max size of a communication packet sent to a MySQL server.\n+   *   The default is either 64MB or 4MB depending on MySQL version. Updating metadata store can fail if the serialized\n+   *   ingestion spec is larger than this limit.\n+   *\n+   * The default is consertively chosen as 1000.\n+   */\n+  @VisibleForTesting\n+  static final int DEFAULT_MAX_NUM_FILES = 1000;\n+\n+  private final HumanReadableBytes maxSplitSize;\n+  private final int maxNumFiles;\n \n   @JsonCreator\n-  public MaxSizeSplitHintSpec(@JsonProperty(\"maxSplitSize\") @Nullable Long maxSplitSize)\n+  public MaxSizeSplitHintSpec(\n+      @JsonProperty(\"maxSplitSize\") @Nullable HumanReadableBytes maxSplitSize,\n+      @JsonProperty(\"maxNumFiles\") @Nullable Integer maxNumFiles\n+  )\n   {\n     this.maxSplitSize = maxSplitSize == null ? DEFAULT_MAX_SPLIT_SIZE : maxSplitSize;\n+    this.maxNumFiles = maxNumFiles == null ? DEFAULT_MAX_NUM_FILES : maxNumFiles;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "65657f6eec028817ce32f90dcea15e382e3ed3ef"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg5NDQxMQ==", "bodyText": "Is there a pattern to document the relationship between these 2 configs.\nReading these docs I'm not sure if I need to consider one when setting the other or which one takes precedence.", "url": "https://github.com/apache/druid/pull/10243#discussion_r470894411", "createdAt": "2020-08-14T22:43:48Z", "author": {"login": "suneet-s"}, "path": "docs/ingestion/native-batch.md", "diffHunk": "@@ -232,7 +232,8 @@ The size-based split hint spec is respected by all splittable input sources exce\n |property|description|default|required?|\n |--------|-----------|-------|---------|\n |type|This should always be `maxSize`.|none|yes|\n-|maxSplitSize|Maximum number of bytes of input files to process in a single task. If a single file is larger than this number, it will be processed by itself in a single task (Files are never split across tasks yet).|500MB|no|\n+|maxSplitSize|Maximum number of bytes of input files to process in a single task. If a single file is larger than this number, it will be processed by itself in a single task (Files are never split across tasks yet). [Human-readable format](../configuration/human-readable-byte.md) is supported.|500MiB|no|\n+|maxNumFiles|Maximum number of input files to process in a single task. This limit is to avoid task failures when the ingestion spec is too long. There are two known limits on the max size of serialized ingestion spec, i.e., the max ZNode size in ZooKeeper (`jute.maxbuffer`) and the max packet size in MySQL (`max_allowed_packet`). These can make ingestion tasks fail if the serialized ingestion spec size hits one of them.|1000|no|", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "65657f6eec028817ce32f90dcea15e382e3ed3ef"}, "originalPosition": 6}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9b62a55e97ed62a00fc24196090f84b8d5b36b82", "author": {"user": {"login": "jihoonson", "name": "Jihoon Son"}}, "url": "https://github.com/apache/druid/commit/9b62a55e97ed62a00fc24196090f84b8d5b36b82", "committedDate": "2020-08-18T01:34:41Z", "message": "address comments; change default maxSplitSize"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c0ab886fe77729b4b5e3626e03779edea40f79b8", "author": {"user": {"login": "jihoonson", "name": "Jihoon Son"}}, "url": "https://github.com/apache/druid/commit/c0ab886fe77729b4b5e3626e03779edea40f79b8", "committedDate": "2020-08-18T03:39:15Z", "message": "spelling"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY5MDI3MTcx", "url": "https://github.com/apache/druid/pull/10243#pullrequestreview-469027171", "createdAt": "2020-08-18T06:32:44Z", "commit": {"oid": "c0ab886fe77729b4b5e3626e03779edea40f79b8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQwNjozMjo0NFrOHCFNAA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQwNjozMjo0NFrOHCFNAA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTk0NDQ0OA==", "bodyText": "This change seems reasonable to me, but since we're changing the default behavior from 512 MiB to 1GiB, can we add a system property to override this default value. In case users are doing an upgrade to 0.20 and want the old behavior, the system property would give them a way. to have the previous default.", "url": "https://github.com/apache/druid/pull/10243#discussion_r471944448", "createdAt": "2020-08-18T06:32:44Z", "author": {"login": "suneet-s"}, "path": "core/src/main/java/org/apache/druid/data/input/MaxSizeSplitHintSpec.java", "diffHunk": "@@ -44,7 +45,7 @@\n   public static final String TYPE = \"maxSize\";\n \n   @VisibleForTesting\n-  static final HumanReadableBytes DEFAULT_MAX_SPLIT_SIZE = new HumanReadableBytes(\"512MiB\");\n+  static final HumanReadableBytes DEFAULT_MAX_SPLIT_SIZE = new HumanReadableBytes(\"1GiB\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0ab886fe77729b4b5e3626e03779edea40f79b8"}, "originalPosition": 13}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcwMTIxMjIy", "url": "https://github.com/apache/druid/pull/10243#pullrequestreview-470121222", "createdAt": "2020-08-19T04:46:27Z", "commit": {"oid": "c0ab886fe77729b4b5e3626e03779edea40f79b8"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcwOTM5NTQy", "url": "https://github.com/apache/druid/pull/10243#pullrequestreview-470939542", "createdAt": "2020-08-19T20:52:57Z", "commit": {"oid": "c0ab886fe77729b4b5e3626e03779edea40f79b8"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQyMDo1Mjo1OFrOHDYqlw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQyMTowMDowMlrOHDY40g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzMxMTg5NQ==", "bodyText": "is this a typo: 'consertively' -> 'conservatively'?", "url": "https://github.com/apache/druid/pull/10243#discussion_r473311895", "createdAt": "2020-08-19T20:52:58Z", "author": {"login": "clintropolis"}, "path": "core/src/main/java/org/apache/druid/data/input/MaxSizeSplitHintSpec.java", "diffHunk": "@@ -43,22 +45,55 @@\n   public static final String TYPE = \"maxSize\";\n \n   @VisibleForTesting\n-  static final long DEFAULT_MAX_SPLIT_SIZE = 512 * 1024 * 1024;\n+  static final HumanReadableBytes DEFAULT_MAX_SPLIT_SIZE = new HumanReadableBytes(\"1GiB\");\n \n-  private final long maxSplitSize;\n+  /**\n+   * There are two known issues when a split contains a large list of files.\n+   *\n+   * - 'jute.maxbuffer' in ZooKeeper. This system property controls the max size of ZNode. As its default is 500KB,\n+   *   task allocation can fail if the serialized ingestion spec is larger than this limit.\n+   * - 'max_allowed_packet' in MySQL. This is the max size of a communication packet sent to a MySQL server.\n+   *   The default is either 64MB or 4MB depending on MySQL version. Updating metadata store can fail if the serialized\n+   *   ingestion spec is larger than this limit.\n+   *\n+   * The default is consertively chosen as 1000.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0ab886fe77729b4b5e3626e03779edea40f79b8"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzMxMzI0Mw==", "bodyText": "typo: 'Noe' -> 'Note'", "url": "https://github.com/apache/druid/pull/10243#discussion_r473313243", "createdAt": "2020-08-19T20:55:28Z", "author": {"login": "clintropolis"}, "path": "docs/ingestion/native-batch.md", "diffHunk": "@@ -232,7 +232,8 @@ The size-based split hint spec is respected by all splittable input sources exce\n |property|description|default|required?|\n |--------|-----------|-------|---------|\n |type|This should always be `maxSize`.|none|yes|\n-|maxSplitSize|Maximum number of bytes of input files to process in a single task. If a single file is larger than this number, it will be processed by itself in a single task (Files are never split across tasks yet).|500MB|no|\n+|maxSplitSize|Maximum number of bytes of input files to process in a single task. If a single file is larger than this number, it will be processed by itself in a single task (Files are never split across tasks yet). Noe that one subtask will not process more files than `maxNumFiles` even if their total size is smaller than `maxSplitSize`. [Human-readable format](../configuration/human-readable-byte.md) is supported.|1GiB|no|", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0ab886fe77729b4b5e3626e03779edea40f79b8"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzMxNTUzOA==", "bodyText": "Does this limit apply to the entire parallel task, just the subtasks, or both? It isn't super clear from the docs here, though from my interpretation of the code it looks like this applies to subtasks?", "url": "https://github.com/apache/druid/pull/10243#discussion_r473315538", "createdAt": "2020-08-19T21:00:02Z", "author": {"login": "clintropolis"}, "path": "docs/ingestion/native-batch.md", "diffHunk": "@@ -232,7 +232,8 @@ The size-based split hint spec is respected by all splittable input sources exce\n |property|description|default|required?|\n |--------|-----------|-------|---------|\n |type|This should always be `maxSize`.|none|yes|\n-|maxSplitSize|Maximum number of bytes of input files to process in a single task. If a single file is larger than this number, it will be processed by itself in a single task (Files are never split across tasks yet).|500MB|no|\n+|maxSplitSize|Maximum number of bytes of input files to process in a single task. If a single file is larger than this number, it will be processed by itself in a single task (Files are never split across tasks yet). Noe that one subtask will not process more files than `maxNumFiles` even if their total size is smaller than `maxSplitSize`. [Human-readable format](../configuration/human-readable-byte.md) is supported.|1GiB|no|\n+|maxNumFiles|Maximum number of input files to process in a single task. This limit is to avoid task failures when the ingestion spec is too long. There are two known limits on the max size of serialized ingestion spec, i.e., the max ZNode size in ZooKeeper (`jute.maxbuffer`) and the max packet size in MySQL (`max_allowed_packet`). These can make ingestion tasks fail if the serialized ingestion spec size hits one of them. Note that one subtask will not process more data than `maxSplitSize` even if the total number of files is smaller than `maxNumFiles`.|1000|no|", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c0ab886fe77729b4b5e3626e03779edea40f79b8"}, "originalPosition": 6}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c363df0e175fdce431e9d1f7581453aff851a8c9", "author": {"user": {"login": "jihoonson", "name": "Jihoon Son"}}, "url": "https://github.com/apache/druid/commit/c363df0e175fdce431e9d1f7581453aff851a8c9", "committedDate": "2020-08-20T07:26:26Z", "message": "typos and doc"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcxNDA3MTMy", "url": "https://github.com/apache/druid/pull/10243#pullrequestreview-471407132", "createdAt": "2020-08-20T09:11:36Z", "commit": {"oid": "c363df0e175fdce431e9d1f7581453aff851a8c9"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQwOToxMTozNlrOHD2R3Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQwOToxMTozNlrOHD2R3Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Mzc5NzA4NQ==", "bodyText": "Should SegmentsSplitHintSpec be updated to accept HumanReadableBytes for maxInputSegmentBytesPerTask as well?", "url": "https://github.com/apache/druid/pull/10243#discussion_r473797085", "createdAt": "2020-08-20T09:11:36Z", "author": {"login": "clintropolis"}, "path": "core/src/main/java/org/apache/druid/data/input/MaxSizeSplitHintSpec.java", "diffHunk": "@@ -43,22 +45,55 @@\n   public static final String TYPE = \"maxSize\";\n \n   @VisibleForTesting\n-  static final long DEFAULT_MAX_SPLIT_SIZE = 512 * 1024 * 1024;\n+  static final HumanReadableBytes DEFAULT_MAX_SPLIT_SIZE = new HumanReadableBytes(\"1GiB\");\n \n-  private final long maxSplitSize;\n+  /**\n+   * There are two known issues when a split contains a large list of files.\n+   *\n+   * - 'jute.maxbuffer' in ZooKeeper. This system property controls the max size of ZNode. As its default is 500KB,\n+   *   task allocation can fail if the serialized ingestion spec is larger than this limit.\n+   * - 'max_allowed_packet' in MySQL. This is the max size of a communication packet sent to a MySQL server.\n+   *   The default is either 64MB or 4MB depending on MySQL version. Updating metadata store can fail if the serialized\n+   *   ingestion spec is larger than this limit.\n+   *\n+   * The default is conservatively chosen as 1000.\n+   */\n+  @VisibleForTesting\n+  static final int DEFAULT_MAX_NUM_FILES = 1000;\n+\n+  private final HumanReadableBytes maxSplitSize;\n+  private final int maxNumFiles;\n \n   @JsonCreator\n-  public MaxSizeSplitHintSpec(@JsonProperty(\"maxSplitSize\") @Nullable Long maxSplitSize)\n+  public MaxSizeSplitHintSpec(\n+      @JsonProperty(\"maxSplitSize\") @Nullable HumanReadableBytes maxSplitSize,\n+      @JsonProperty(\"maxNumFiles\") @Nullable Integer maxNumFiles\n+  )\n   {\n     this.maxSplitSize = maxSplitSize == null ? DEFAULT_MAX_SPLIT_SIZE : maxSplitSize;\n+    this.maxNumFiles = maxNumFiles == null ? DEFAULT_MAX_NUM_FILES : maxNumFiles;\n+    Preconditions.checkArgument(this.maxSplitSize.getBytes() > 0, \"maxSplitSize should be larger than 0\");\n+    Preconditions.checkArgument(this.maxNumFiles > 0, \"maxNumFiles should be larger than 0\");\n+  }\n+\n+  @VisibleForTesting\n+  public MaxSizeSplitHintSpec(long maxSplitSize, @Nullable Integer maxNumFiles)\n+  {\n+    this(new HumanReadableBytes(maxSplitSize), maxNumFiles);\n   }\n \n   @JsonProperty\n-  public long getMaxSplitSize()\n+  public HumanReadableBytes getMaxSplitSize()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c363df0e175fdce431e9d1f7581453aff851a8c9"}, "originalPosition": 56}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fbcb142303ff1e57f0e55d045e96fb7b2c6fbeb7", "author": {"user": {"login": "jihoonson", "name": "Jihoon Son"}}, "url": "https://github.com/apache/druid/commit/fbcb142303ff1e57f0e55d045e96fb7b2c6fbeb7", "committedDate": "2020-08-20T17:56:16Z", "message": "same change for segments splitHintSpec"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "da709d0c369ab73a0617b639fae79b27bcf41dc4", "author": {"user": {"login": "jihoonson", "name": "Jihoon Son"}}, "url": "https://github.com/apache/druid/commit/da709d0c369ab73a0617b639fae79b27bcf41dc4", "committedDate": "2020-08-20T20:26:01Z", "message": "fix build"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8742c30ec0c1aa871afa54d1907ba5ce8ad30d10", "author": {"user": {"login": "jihoonson", "name": "Jihoon Son"}}, "url": "https://github.com/apache/druid/commit/8742c30ec0c1aa871afa54d1907ba5ce8ad30d10", "committedDate": "2020-08-20T20:31:43Z", "message": "Merge branch 'master' of github.com:apache/druid into max-num-files-split"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ea184a565914ef7523f8d9aac932cafad078f92d", "author": {"user": {"login": "jihoonson", "name": "Jihoon Son"}}, "url": "https://github.com/apache/druid/commit/ea184a565914ef7523f8d9aac932cafad078f92d", "committedDate": "2020-08-20T20:36:21Z", "message": "fix build"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcyMDAwNTUx", "url": "https://github.com/apache/druid/pull/10243#pullrequestreview-472000551", "createdAt": "2020-08-20T21:31:45Z", "commit": {"oid": "ea184a565914ef7523f8d9aac932cafad078f92d"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1918, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}