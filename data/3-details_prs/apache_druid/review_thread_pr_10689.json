{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTQyMTEzOTYz", "number": 10689, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQyMjowNzo0OVrOFH8tTg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQyMjo0Mjo1MFrOFH9NIQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQzODc4OTkwOnYy", "diffSide": "RIGHT", "path": "processing/src/main/java/org/apache/druid/segment/IndexMergerV9.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQyMjowNzo0OVrOIJnaVg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQyMjowNzo0OVrOIJnaVg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njk1MzgxNA==", "bodyText": "Should this be a warn since we expected to always merge at least two segments regardless of column limit? The warning may be misleading as there is nothing to fix / change", "url": "https://github.com/apache/druid/pull/10689#discussion_r546953814", "createdAt": "2020-12-21T22:07:49Z", "author": {"login": "maytasm"}, "path": "processing/src/main/java/org/apache/druid/segment/IndexMergerV9.java", "diffHunk": "@@ -931,25 +936,158 @@ public File merge(\n       boolean rollup,\n       final AggregatorFactory[] metricAggs,\n       File outDir,\n-      IndexSpec indexSpec\n+      IndexSpec indexSpec,\n+      int maxColumnsToMerge\n   ) throws IOException\n   {\n-    return merge(indexes, rollup, metricAggs, outDir, indexSpec, new BaseProgressIndicator(), null);\n+    return multiphaseMerge(indexes, rollup, metricAggs, outDir, indexSpec, new BaseProgressIndicator(), null, maxColumnsToMerge);\n   }\n \n-  private File merge(\n+  private File multiphaseMerge(\n       List<IndexableAdapter> indexes,\n       final boolean rollup,\n       final AggregatorFactory[] metricAggs,\n       File outDir,\n       IndexSpec indexSpec,\n       ProgressIndicator progress,\n-      @Nullable SegmentWriteOutMediumFactory segmentWriteOutMediumFactory\n+      @Nullable SegmentWriteOutMediumFactory segmentWriteOutMediumFactory,\n+      int maxColumnsToMerge\n   ) throws IOException\n   {\n     FileUtils.deleteDirectory(outDir);\n     org.apache.commons.io.FileUtils.forceMkdir(outDir);\n \n+    List<File> tempDirs = new ArrayList<>();\n+\n+    if (maxColumnsToMerge == IndexMerger.UNLIMITED_MAX_COLUMNS_TO_MERGE) {\n+      return merge(\n+          indexes,\n+          rollup,\n+          metricAggs,\n+          outDir,\n+          indexSpec,\n+          progress,\n+          segmentWriteOutMediumFactory\n+      );\n+    }\n+\n+    List<List<IndexableAdapter>> currentPhases = getMergePhases(indexes, maxColumnsToMerge);\n+    List<File> currentOutputs = new ArrayList<>();\n+\n+    log.debug(\"base outDir: \" + outDir);\n+\n+    try {\n+      while (true) {\n+        for (List<IndexableAdapter> phase : currentPhases) {\n+          File phaseOutDir;\n+          if (currentPhases.size() == 1) {\n+            // use the given outDir on the final merge phase\n+            phaseOutDir = outDir;\n+          } else {\n+            phaseOutDir = FileUtils.createTempDir();\n+            tempDirs.add(phaseOutDir);\n+          }\n+          log.debug(\"phase outDir: \" + phaseOutDir);\n+\n+          File phaseOutput = merge(\n+              phase,\n+              rollup,\n+              metricAggs,\n+              phaseOutDir,\n+              indexSpec,\n+              progress,\n+              segmentWriteOutMediumFactory\n+          );\n+          currentOutputs.add(phaseOutput);\n+        }\n+        if (currentOutputs.size() == 1) {\n+          // we're done, we made a single File output\n+          return currentOutputs.get(0);\n+        } else {\n+          // convert Files to QueryableIndexIndexableAdapter and do another merge phase\n+          List<IndexableAdapter> qIndexAdapters = new ArrayList<>();\n+          for (File outputFile : currentOutputs) {\n+            QueryableIndex qIndex = indexIO.loadIndex(outputFile, true);\n+            qIndexAdapters.add(new QueryableIndexIndexableAdapter(qIndex));\n+          }\n+          currentPhases = getMergePhases(qIndexAdapters, maxColumnsToMerge);\n+          currentOutputs = new ArrayList<>();\n+        }\n+      }\n+    }\n+    finally {\n+      for (File tempDir : tempDirs) {\n+        if (tempDir.exists()) {\n+          try {\n+            FileUtils.deleteDirectory(tempDir);\n+          }\n+          catch (Exception e) {\n+            log.warn(e, \"Failed to remove directory[%s]\", tempDir);\n+          }\n+        }\n+      }\n+    }\n+  }\n+\n+  private List<List<IndexableAdapter>> getMergePhases(List<IndexableAdapter> indexes, int maxColumnsToMerge)\n+  {\n+    List<List<IndexableAdapter>> toMerge = new ArrayList<>();\n+    // always merge at least two segments regardless of column limit\n+    if (indexes.size() <= 2) {\n+      if (getIndexColumnCount(indexes) > maxColumnsToMerge) {\n+        log.warn(\"index pair has more columns than maxColumnsToMerge [%d].\", maxColumnsToMerge);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "76458ecb77b0b18bb0fc0a36e4bf6c389abce3ca"}, "originalPosition": 169}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQzODg2NzQwOnYy", "diffSide": "RIGHT", "path": "processing/src/main/java/org/apache/druid/segment/IndexMergerV9.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQyMjo0MDo0OFrOIJoG1w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQyMjo0MDo0OFrOIJoG1w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njk2NTIwNw==", "bodyText": "Is it useful to log the iteration number of this loop?\nlike how many times have we done a pass so far?", "url": "https://github.com/apache/druid/pull/10689#discussion_r546965207", "createdAt": "2020-12-21T22:40:48Z", "author": {"login": "maytasm"}, "path": "processing/src/main/java/org/apache/druid/segment/IndexMergerV9.java", "diffHunk": "@@ -931,25 +936,158 @@ public File merge(\n       boolean rollup,\n       final AggregatorFactory[] metricAggs,\n       File outDir,\n-      IndexSpec indexSpec\n+      IndexSpec indexSpec,\n+      int maxColumnsToMerge\n   ) throws IOException\n   {\n-    return merge(indexes, rollup, metricAggs, outDir, indexSpec, new BaseProgressIndicator(), null);\n+    return multiphaseMerge(indexes, rollup, metricAggs, outDir, indexSpec, new BaseProgressIndicator(), null, maxColumnsToMerge);\n   }\n \n-  private File merge(\n+  private File multiphaseMerge(\n       List<IndexableAdapter> indexes,\n       final boolean rollup,\n       final AggregatorFactory[] metricAggs,\n       File outDir,\n       IndexSpec indexSpec,\n       ProgressIndicator progress,\n-      @Nullable SegmentWriteOutMediumFactory segmentWriteOutMediumFactory\n+      @Nullable SegmentWriteOutMediumFactory segmentWriteOutMediumFactory,\n+      int maxColumnsToMerge\n   ) throws IOException\n   {\n     FileUtils.deleteDirectory(outDir);\n     org.apache.commons.io.FileUtils.forceMkdir(outDir);\n \n+    List<File> tempDirs = new ArrayList<>();\n+\n+    if (maxColumnsToMerge == IndexMerger.UNLIMITED_MAX_COLUMNS_TO_MERGE) {\n+      return merge(\n+          indexes,\n+          rollup,\n+          metricAggs,\n+          outDir,\n+          indexSpec,\n+          progress,\n+          segmentWriteOutMediumFactory\n+      );\n+    }\n+\n+    List<List<IndexableAdapter>> currentPhases = getMergePhases(indexes, maxColumnsToMerge);\n+    List<File> currentOutputs = new ArrayList<>();\n+\n+    log.debug(\"base outDir: \" + outDir);\n+\n+    try {\n+      while (true) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "76458ecb77b0b18bb0fc0a36e4bf6c389abce3ca"}, "originalPosition": 111}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQzODg2ODQwOnYy", "diffSide": "RIGHT", "path": "processing/src/main/java/org/apache/druid/segment/IndexMergerV9.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQyMjo0MToxOVrOIJoHag==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQyMjo0MToxOVrOIJoHag==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njk2NTM1NA==", "bodyText": "is it useful to log the size of currentPhases? It might help to see the progress as the number should decrease after each pass", "url": "https://github.com/apache/druid/pull/10689#discussion_r546965354", "createdAt": "2020-12-21T22:41:19Z", "author": {"login": "maytasm"}, "path": "processing/src/main/java/org/apache/druid/segment/IndexMergerV9.java", "diffHunk": "@@ -931,25 +936,158 @@ public File merge(\n       boolean rollup,\n       final AggregatorFactory[] metricAggs,\n       File outDir,\n-      IndexSpec indexSpec\n+      IndexSpec indexSpec,\n+      int maxColumnsToMerge\n   ) throws IOException\n   {\n-    return merge(indexes, rollup, metricAggs, outDir, indexSpec, new BaseProgressIndicator(), null);\n+    return multiphaseMerge(indexes, rollup, metricAggs, outDir, indexSpec, new BaseProgressIndicator(), null, maxColumnsToMerge);\n   }\n \n-  private File merge(\n+  private File multiphaseMerge(\n       List<IndexableAdapter> indexes,\n       final boolean rollup,\n       final AggregatorFactory[] metricAggs,\n       File outDir,\n       IndexSpec indexSpec,\n       ProgressIndicator progress,\n-      @Nullable SegmentWriteOutMediumFactory segmentWriteOutMediumFactory\n+      @Nullable SegmentWriteOutMediumFactory segmentWriteOutMediumFactory,\n+      int maxColumnsToMerge\n   ) throws IOException\n   {\n     FileUtils.deleteDirectory(outDir);\n     org.apache.commons.io.FileUtils.forceMkdir(outDir);\n \n+    List<File> tempDirs = new ArrayList<>();\n+\n+    if (maxColumnsToMerge == IndexMerger.UNLIMITED_MAX_COLUMNS_TO_MERGE) {\n+      return merge(\n+          indexes,\n+          rollup,\n+          metricAggs,\n+          outDir,\n+          indexSpec,\n+          progress,\n+          segmentWriteOutMediumFactory\n+      );\n+    }\n+\n+    List<List<IndexableAdapter>> currentPhases = getMergePhases(indexes, maxColumnsToMerge);\n+    List<File> currentOutputs = new ArrayList<>();\n+\n+    log.debug(\"base outDir: \" + outDir);\n+\n+    try {\n+      while (true) {\n+        for (List<IndexableAdapter> phase : currentPhases) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "76458ecb77b0b18bb0fc0a36e4bf6c389abce3ca"}, "originalPosition": 112}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQzODg3MTM3OnYy", "diffSide": "RIGHT", "path": "processing/src/main/java/org/apache/druid/segment/IndexMergerV9.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQyMjo0Mjo1MFrOIJoJOQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQyMjo0Mjo1MFrOIJoJOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njk2NTgxNw==", "bodyText": "Should this be a warn since this can happen and is a expected / ok thing? The warning may be misleading as there is nothing to fix / change", "url": "https://github.com/apache/druid/pull/10689#discussion_r546965817", "createdAt": "2020-12-21T22:42:50Z", "author": {"login": "maytasm"}, "path": "processing/src/main/java/org/apache/druid/segment/IndexMergerV9.java", "diffHunk": "@@ -931,25 +936,158 @@ public File merge(\n       boolean rollup,\n       final AggregatorFactory[] metricAggs,\n       File outDir,\n-      IndexSpec indexSpec\n+      IndexSpec indexSpec,\n+      int maxColumnsToMerge\n   ) throws IOException\n   {\n-    return merge(indexes, rollup, metricAggs, outDir, indexSpec, new BaseProgressIndicator(), null);\n+    return multiphaseMerge(indexes, rollup, metricAggs, outDir, indexSpec, new BaseProgressIndicator(), null, maxColumnsToMerge);\n   }\n \n-  private File merge(\n+  private File multiphaseMerge(\n       List<IndexableAdapter> indexes,\n       final boolean rollup,\n       final AggregatorFactory[] metricAggs,\n       File outDir,\n       IndexSpec indexSpec,\n       ProgressIndicator progress,\n-      @Nullable SegmentWriteOutMediumFactory segmentWriteOutMediumFactory\n+      @Nullable SegmentWriteOutMediumFactory segmentWriteOutMediumFactory,\n+      int maxColumnsToMerge\n   ) throws IOException\n   {\n     FileUtils.deleteDirectory(outDir);\n     org.apache.commons.io.FileUtils.forceMkdir(outDir);\n \n+    List<File> tempDirs = new ArrayList<>();\n+\n+    if (maxColumnsToMerge == IndexMerger.UNLIMITED_MAX_COLUMNS_TO_MERGE) {\n+      return merge(\n+          indexes,\n+          rollup,\n+          metricAggs,\n+          outDir,\n+          indexSpec,\n+          progress,\n+          segmentWriteOutMediumFactory\n+      );\n+    }\n+\n+    List<List<IndexableAdapter>> currentPhases = getMergePhases(indexes, maxColumnsToMerge);\n+    List<File> currentOutputs = new ArrayList<>();\n+\n+    log.debug(\"base outDir: \" + outDir);\n+\n+    try {\n+      while (true) {\n+        for (List<IndexableAdapter> phase : currentPhases) {\n+          File phaseOutDir;\n+          if (currentPhases.size() == 1) {\n+            // use the given outDir on the final merge phase\n+            phaseOutDir = outDir;\n+          } else {\n+            phaseOutDir = FileUtils.createTempDir();\n+            tempDirs.add(phaseOutDir);\n+          }\n+          log.debug(\"phase outDir: \" + phaseOutDir);\n+\n+          File phaseOutput = merge(\n+              phase,\n+              rollup,\n+              metricAggs,\n+              phaseOutDir,\n+              indexSpec,\n+              progress,\n+              segmentWriteOutMediumFactory\n+          );\n+          currentOutputs.add(phaseOutput);\n+        }\n+        if (currentOutputs.size() == 1) {\n+          // we're done, we made a single File output\n+          return currentOutputs.get(0);\n+        } else {\n+          // convert Files to QueryableIndexIndexableAdapter and do another merge phase\n+          List<IndexableAdapter> qIndexAdapters = new ArrayList<>();\n+          for (File outputFile : currentOutputs) {\n+            QueryableIndex qIndex = indexIO.loadIndex(outputFile, true);\n+            qIndexAdapters.add(new QueryableIndexIndexableAdapter(qIndex));\n+          }\n+          currentPhases = getMergePhases(qIndexAdapters, maxColumnsToMerge);\n+          currentOutputs = new ArrayList<>();\n+        }\n+      }\n+    }\n+    finally {\n+      for (File tempDir : tempDirs) {\n+        if (tempDir.exists()) {\n+          try {\n+            FileUtils.deleteDirectory(tempDir);\n+          }\n+          catch (Exception e) {\n+            log.warn(e, \"Failed to remove directory[%s]\", tempDir);\n+          }\n+        }\n+      }\n+    }\n+  }\n+\n+  private List<List<IndexableAdapter>> getMergePhases(List<IndexableAdapter> indexes, int maxColumnsToMerge)\n+  {\n+    List<List<IndexableAdapter>> toMerge = new ArrayList<>();\n+    // always merge at least two segments regardless of column limit\n+    if (indexes.size() <= 2) {\n+      if (getIndexColumnCount(indexes) > maxColumnsToMerge) {\n+        log.warn(\"index pair has more columns than maxColumnsToMerge [%d].\", maxColumnsToMerge);\n+      }\n+      toMerge.add(indexes);\n+    } else {\n+      List<IndexableAdapter> currentPhase = new ArrayList<>();\n+      int currentColumnCount = 0;\n+      for (IndexableAdapter index : indexes) {\n+        int indexColumnCount = getIndexColumnCount(index);\n+        if (indexColumnCount > maxColumnsToMerge) {\n+          log.warn(\"index has more columns [%d] than maxColumnsToMerge [%d]!\", indexColumnCount, maxColumnsToMerge);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "76458ecb77b0b18bb0fc0a36e4bf6c389abce3ca"}, "originalPosition": 178}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2931, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}