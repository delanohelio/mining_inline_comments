{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTA3Mjg5ODg5", "number": 10524, "title": "Dynamic auto scale Kafka-Stream ingest tasks", "bodyText": "Description\n\n\n\n\nIn druid, users need to set 'taskCount' when submit Kafka ingestion supervisor. It has a few\u00a0limitations :\n\nWhen supervisor is running, we can't modify the task count number. We may meet data lag during sudden peak traffic period. Users have to re-submit the supervisor with a larger task number, aiming to catch up Kafka delay. But if there are too many supervisors, this re-submit operation is very complicated. In addition do scale in action manually after sudden traffic peak.\nIn order to avoid Kafka lag during regular traffic peak, users have to set a large task count in supervisors. So that it will cause the waste of resource during regular traffic off-peak.\nFor example,\n\n\nHere is our traffic pattern. I have to set taskCount to 8, avoiding Kafka lag during traffic peak. At other times, 4 tasks are enough.\nThis PR provides the ability of auto scaling the number of Kafka ingest tasks based on Lag metrics when supervisors are running. Enable this feature and ingest tasks will auto scale out during traffic peak and scale in during traffic off-peak.\nDesign\nHere are the designs of this PR:\nThe work flow of supervisor controller based on druid source code\n\nAs the picture shows, SupervisorManger controls all the supervisors in OverLord Service. Each Kafka Supervisor serially consume notices in LinkedBlockingQueue. Notice is an interface. RunNotice, ShutdownNotice and RestNotice are implementations of this interface. I design a new implementation named DynamicAllocationTasksNotice. I create a new Timer(lagComputationExec) to collect Kafka lags at fix rate and create a new Timer(allocationExec) to check and do scale action at fix rate, as shown below\n\nFor allocationExec details ,\n\nFurthermore, I expand the ioConfig spec and add new parameters to control the scale behave, for example\n\"ioConfig\": {\n      \"topic\": \"dummy_topic\",\n      \"inputFormat\": null,\n      \"replicas\": 1,\n      \"taskCount\": 1,\n      \"taskDuration\": \"PT3600S\",\n      \"consumerProperties\": {\n        \"bootstrap.servers\": \"xxx,xxx,xxx\"\n      },\n      \"autoScalerConfig\": {\n        \"enableTaskAutoScaler\": true,\n        \"lagCollectionIntervalMillis\": 30000,\n        \"lagCollectionRangeMillis\": 600000,\n        \"scaleOutThreshold\": 6000000,\n        \"triggerScaleOutThresholdFrequency\": 0.3,\n        \"scaleInThreshold\": 1000000,\n        \"triggerScaleInThresholdFrequency\": 0.9,\n        \"scaleActionStartDelayMillis\": 300000,\n        \"scaleActionPeriodMillis\": 60000,\n        \"taskCountMax\": 6,\n        \"taskCountMin\": 2,\n        \"scaleInStep\": 1,\n        \"scaleOutStep\": 2,\n        \"minTriggerScaleActionFrequencyMillis\": 600000\n      },\n      \"pollTimeout\": 100,\n      \"startDelay\": \"PT5S\",\n      \"period\": \"PT30S\",\n      \"useEarliestOffset\": false,\n      \"completionTimeout\": \"PT1800S\",\n      \"lateMessageRejectionPeriod\": null,\n      \"earlyMessageRejectionPeriod\": null,\n      \"lateMessageRejectionStartDateTime\": null,\n      \"stream\": \"dummy_topic\",\n      \"useEarliestSequenceNumber\": false\n    }\n\n\n\nProperty\nDescription\nRequired\n\n\n\n\nenableTaskAutoScaler\nWhether enable this feature or not. Set false or ignored here will disable autoScaler even though autoScalerConfig is not null\nno (default == false)\n\n\nlagCollectionIntervalMillis\nDefine the frequency of lag points collection.\nno (default == 30000)\n\n\nlagCollectionRangeMillis\nThe total time window of lag collection, Use with lagCollectionIntervalMillis\uff0cit means that in the recent lagCollectionRangeMillis, collect lag metric points every lagCollectionIntervalMillis.\nno (default == 600000)\n\n\nscaleOutThreshold\nThe Threshold of scale out action\nno (default == 6000000)\n\n\ntriggerScaleOutThresholdFrequency\nIf triggerScaleOutThresholdFrequency percent of lag points are higher than scaleOutThreshold, then do scale out action.\nno (default == 0.3)\n\n\nscaleInThreshold\nThe Threshold of scale in action\nno (default == 1000000)\n\n\ntriggerScaleInThresholdFrequency\nIf triggerScaleInThresholdFrequency percent of lag points are lower than scaleOutThreshold, then do scale in action.\nno (default == 0.9)\n\n\nscaleActionStartDelayMillis\nNumber of milliseconds after supervisor starts when first check scale logic.\nno (default == 300000)\n\n\nscaleActionPeriodMillis\nThe frequency of checking whether to do scale action in millis\nno (default == 60000)\n\n\ntaskCountMax\nMaximum value of task count. Make Sure taskCountMax >= taskCountMin\nyes\n\n\ntaskCountMin\nMinimum value of task count. When enable autoscaler, the value of taskCount in IOConfig will be ignored, and taskCountMin will be the number of tasks that ingestion starts going up to taskCountMax\nyes\n\n\nscaleInStep\nHow many tasks to reduce at a time\nno (default == 1)\n\n\nscaleOutStep\nHow many tasks to add at a time\nno (default == 2)\n\n\nminTriggerScaleActionFrequencyMillis\nMinimum time interval between two scale actions\nno (default == 600000)\n\n\nautoScalerStrategy\nThe algorithm of autoScaler. ONLY lagBased is supported for now.\nno (default == lagBased)\n\n\n\nEffect evaluation :\nI have deployed this feature in our Production Environment\nFigure 1 : Kafka ingestion lag\n\nFigure 2 : Task count\n\nFigure 3 : Ingest speed total\n\nDruid ingestion task is divided into two states: reading and writing, When druid scales out at 10:38, druid will launch 3 new tasks in reading state, and change the old one's state from reading to writing which will finish writing in few minutes. This is why the figure2 shows a peak of 4 from 10:38 to 10:42(3 new reading tasks and one writing task) and a peak of 5 from 11:06 to 11:08. In fact, what we really care about is the tasks in reading state. In other words, the real peak of task number is 3 all the time, which scale out at 10:39 due to Kafka lag and there is no gap between the traffic peak and task peak.\nConclusion\nHere are the benefits of Druid Auto Scale :\n\nHelp improve data SLA: whenever there is heavy traffic, Druid can scale out automatically and\u00a0sensitively \u00a0to provide stronger consuming power so that there is no delay for downstream.\nResource Saving :\n\nCost Saving, because the task number of each datasource is reduced, so that there\u00a0is no need for as many task solts as before.\nSupport Resource Saving, the entire process from scale out action to scale in action does not require human intervention.\n\n\n\n\nThis PR has:\n\n been self-reviewed.\n\n using the concurrency checklist (Remove this item if the PR doesn't have any relation to concurrency.)\n\n\n added documentation for new or modified features or behaviors.\n added Javadocs for most classes and all non-trivial methods. Linked related entities via Javadoc links.\n added or updated version, license, or notice information in licenses.yaml\n added comments explaining the \"why\" and the intent of the code wherever would not be obvious for an unfamiliar reader.\n added unit tests or modified existing tests to cover new code paths, ensuring the threshold for code coverage is met.\n added integration tests.\n been tested in a test Druid cluster.\n\n\n\nKey changed/added classes in this PR\n\nSeekableStreamSupervisor.java \nKafkaSupervisor.java\nKafkaSupervisorIOConfig.java", "createdAt": "2020-10-21T06:30:01Z", "url": "https://github.com/apache/druid/pull/10524", "merged": true, "mergeCommit": {"oid": "bddacbb1c3abccf6ad035a4756a6960761fd43a2"}, "closed": true, "closedAt": "2021-03-06T09:06:52Z", "author": {"login": "zhangyue19921010"}, "timelineItems": {"totalCount": 78, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdUS9ZAAH2gAyNTA3Mjg5ODg5OmYzZDY0MjJhZTI4OWZjMzgyMWUwN2M0ZWY5ZWQ1ODEwZDY3YzlmNjQ=", "endCursor": "Y3Vyc29yOnYyOpPPAAABeANG-DAFqTYwNTQwOTE3MA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "f3d6422ae289fc3821e07c4ef9ed5810d67c9f64", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/f3d6422ae289fc3821e07c4ef9ed5810d67c9f64", "committedDate": "2020-10-20T06:41:04Z", "message": "druid task auto scale based on kafka lag"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5c1c21c44c2737fe0e55405f863cfd8c93329213", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/5c1c21c44c2737fe0e55405f863cfd8c93329213", "committedDate": "2020-10-21T03:25:00Z", "message": "fix kafkaSupervisorIOConfig and KinesisSupervisorIOConfig"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6d7582be1e9c423a50085b57a3a163a5166316f4", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/6d7582be1e9c423a50085b57a3a163a5166316f4", "committedDate": "2020-10-21T03:27:47Z", "message": "druid task auto scale based on kafka lag"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "16b07446ad051fd8277bdba14b9b3bde4bab247b", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/16b07446ad051fd8277bdba14b9b3bde4bab247b", "committedDate": "2020-10-21T03:27:47Z", "message": "fix kafkaSupervisorIOConfig and KinesisSupervisorIOConfig"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "07eb9c089b9ba751dcb4c3b55728c3486406b278", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/07eb9c089b9ba751dcb4c3b55728c3486406b278", "committedDate": "2020-10-21T03:28:36Z", "message": "test dynamic auto scale done"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a041b44ec5d39aca60bb319b681d9c5edea7a455", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/a041b44ec5d39aca60bb319b681d9c5edea7a455", "committedDate": "2020-10-21T03:30:26Z", "message": "auto scale tasks tested on prd cluster"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "746b033327ef51dd74c811c369444e51bac785ca", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/746b033327ef51dd74c811c369444e51bac785ca", "committedDate": "2020-10-21T03:32:06Z", "message": "auto scale tasks tested on prd cluster"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d25f94a593a7b47207db44a8df838bbea46d0793", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/d25f94a593a7b47207db44a8df838bbea46d0793", "committedDate": "2020-10-21T03:33:04Z", "message": "auto scale tasks tested on prd cluster"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e7a1af1e97a8f693b8f43ef6a20cda5a735e7fa4", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/e7a1af1e97a8f693b8f43ef6a20cda5a735e7fa4", "committedDate": "2020-10-22T10:56:00Z", "message": "modify code style to solve 29055.10 29055.9 29055.17 29055.18 29055.19 29055.20"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d53ea7680fc8137e7197b8d7fa7fd887c633d566", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/d53ea7680fc8137e7197b8d7fa7fd887c633d566", "committedDate": "2020-10-22T11:04:43Z", "message": "Merge branch 'master' into kafka-dynamic-scale-ingest-tasks"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "78cbd45577dccc3abd39fb03db6d2a9298e6c252", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/78cbd45577dccc3abd39fb03db6d2a9298e6c252", "committedDate": "2020-10-23T04:54:40Z", "message": "rename test fiel function"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM4MDM5MzQx", "url": "https://github.com/apache/druid/pull/10524#pullrequestreview-538039341", "createdAt": "2020-11-24T23:07:42Z", "commit": {"oid": "78cbd45577dccc3abd39fb03db6d2a9298e6c252"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 30, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQyMzowNzo0MlrOH5bmBQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxNzowNjoyMVrOH58tfg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTk4Mjk4MQ==", "bodyText": "add comment stating why this is not implemented", "url": "https://github.com/apache/druid/pull/10524#discussion_r529982981", "createdAt": "2020-11-24T23:07:42Z", "author": {"login": "capistrant"}, "path": "extensions-core/kinesis-indexing-service/src/main/java/org/apache/druid/indexing/kinesis/supervisor/KinesisSupervisor.java", "diffHunk": "@@ -377,6 +377,11 @@ protected boolean useExclusiveStartSequenceNumberForNonFirstSequence()\n     return true;\n   }\n \n+  @Override\n+  protected void collectLag(ArrayList<Long> lags)\n+  {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78cbd45577dccc3abd39fb03db6d2a9298e6c252"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTk4MzM3OA==", "bodyText": "nit: remove empty line", "url": "https://github.com/apache/druid/pull/10524#discussion_r529983378", "createdAt": "2020-11-24T23:08:10Z", "author": {"login": "capistrant"}, "path": "extensions-core/kinesis-indexing-service/src/main/java/org/apache/druid/indexing/kinesis/supervisor/KinesisSupervisorIOConfig.java", "diffHunk": "@@ -85,7 +88,9 @@ public KinesisSupervisorIOConfig(\n         completionTimeout,\n         lateMessageRejectionPeriod,\n         earlyMessageRejectionPeriod,\n+        dynamicAllocationTasksProperties,\n         lateMessageRejectionStartDateTime\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78cbd45577dccc3abd39fb03db6d2a9298e6c252"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTk4NDU1Ng==", "bodyText": "javadoc would be helpful as this is important/complex method", "url": "https://github.com/apache/druid/pull/10524#discussion_r529984556", "createdAt": "2020-11-24T23:09:29Z", "author": {"login": "capistrant"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -317,6 +322,157 @@ public void handle()\n     }\n   }\n \n+  // same as submit supervisor logic\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    @Override\n+    public void handle()\n+    {\n+      lock.lock();\n+      try {\n+        long nowTime = System.currentTimeMillis();\n+        long minTriggerDynamicFrequency = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"minTriggerDynamicFrequencyMillis\", 1200000)));\n+        // Only queue is full and over minTriggerDynamicFrequency can trigger scale out/in\n+        // max(minTriggerDynamicFrequency, metricsCollectionRangeMillis)\n+        if (spec.isSuspended()) {\n+          log.info(\"[%s] supervisor is suspended, skip to check dynamic allocate task logic\", dataSource);\n+          return;\n+        }\n+        log.info(\"PendingCompletionTaskGroups is : \" + pendingCompletionTaskGroups);\n+        for (CopyOnWriteArrayList list : pendingCompletionTaskGroups.values()) {\n+          if (!list.isEmpty()) {\n+            log.info(\"Still hand off tasks unfinished, skip to do scale action [\" + pendingCompletionTaskGroups + \"]\");\n+            return;\n+          }\n+        }\n+        if (nowTime - dynamicTriggerLastRunTime < minTriggerDynamicFrequency) {\n+          log.info(\"NowTime - dynamicTriggerLastRunTime is [\" + (nowTime - dynamicTriggerLastRunTime) + \"]. Defined minTriggerDynamicFrequency is [\" + minTriggerDynamicFrequency + \"] , CLAM DOWN NOW !\");\n+          return;\n+        }\n+        if (!queue.isAtFullCapacity()) {\n+          log.info(\"Metrics collection is not at full capacity, skip to check dynamic allocate task : [\" + queue.size() + \" vs \" + queue.maxSize() + \"]\");\n+          return;\n+        }\n+        List<Long> lags = collectTotalLags();\n+        boolean allocationSuccess = dynamicAllocate(lags);\n+        if (allocationSuccess) {\n+          dynamicTriggerLastRunTime = nowTime;\n+          queue.clear();\n+        }\n+      }\n+      catch (Exception e) {\n+        log.error(e, \"Error, when parse DynamicAllocationTasksNotice\");\n+      }\n+      finally {\n+        lock.unlock();\n+      }\n+    }\n+  }\n+\n+  private boolean dynamicAllocate(List<Long> lags) throws InterruptedException, ExecutionException, TimeoutException", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78cbd45577dccc3abd39fb03db6d2a9298e6c252"}, "originalPosition": 90}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTk4NDk2Ng==", "bodyText": "javadoc would be helpful as this is complex/important method override", "url": "https://github.com/apache/druid/pull/10524#discussion_r529984966", "createdAt": "2020-11-24T23:09:57Z", "author": {"login": "capistrant"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -317,6 +322,157 @@ public void handle()\n     }\n   }\n \n+  // same as submit supervisor logic\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    @Override\n+    public void handle()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78cbd45577dccc3abd39fb03db6d2a9298e6c252"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTk4NjE2NQ==", "bodyText": "javadoc please", "url": "https://github.com/apache/druid/pull/10524#discussion_r529986165", "createdAt": "2020-11-24T23:11:10Z", "author": {"login": "capistrant"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -3561,4 +3843,6 @@ protected void emitLag()\n    * sequences. In Kafka, start offsets are always inclusive.\n    */\n   protected abstract boolean useExclusiveStartSequenceNumberForNonFirstSequence();\n+\n+  protected abstract void collectLag(ArrayList<Long> lags);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78cbd45577dccc3abd39fb03db6d2a9298e6c252"}, "originalPosition": 479}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTk4Nzk2MA==", "bodyText": "we need to document all of these new configs in kafka-ingestion.md in the KafkaSupervisorIOConfig section", "url": "https://github.com/apache/druid/pull/10524#discussion_r529987960", "createdAt": "2020-11-24T23:12:59Z", "author": {"login": "capistrant"}, "path": "indexing-service/src/test/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisorStateTest.java", "diffHunk": "@@ -824,12 +827,32 @@ private static SeekableStreamSupervisorIOConfig getIOConfig()\n         false,\n         new Period(\"PT30M\"),\n         null,\n-        null, null\n+        null, getProperties(), null\n     )\n     {\n     };\n   }\n \n+  private static Map<String, Object> getProperties()\n+  {\n+    HashMap<String, Object> dynamicAllocationTasksProperties = new HashMap<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78cbd45577dccc3abd39fb03db6d2a9298e6c252"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDAwNTM0MA==", "bodyText": "what is the reasoning behind this default of 8?", "url": "https://github.com/apache/druid/pull/10524#discussion_r530005340", "createdAt": "2020-11-24T23:31:01Z", "author": {"login": "capistrant"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -518,20 +684,52 @@ public SeekableStreamSupervisor(\n     this.useExclusiveStartingSequence = useExclusiveStartingSequence;\n     this.dataSource = spec.getDataSchema().getDataSource();\n     this.ioConfig = spec.getIoConfig();\n+    this.dynamicAllocationTasksProperties = ioConfig.getDynamicAllocationTasksProperties();\n+    log.info(\"Get dynamicAllocationTasksProperties from IOConfig : \" + dynamicAllocationTasksProperties);\n+\n+    if (dynamicAllocationTasksProperties != null && !dynamicAllocationTasksProperties.isEmpty() && Boolean.parseBoolean(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"enableDynamicAllocationTasks\", false)))) {\n+      log.info(\"EnableDynamicAllocationTasks for datasource \" + dataSource);\n+      this.enableDynamicAllocationTasks = true;\n+    } else {\n+      log.info(\"Disable Dynamic Allocate Tasks\");\n+      this.enableDynamicAllocationTasks = false;\n+    }\n+    int taskCountMax = 0;\n+    if (enableDynamicAllocationTasks) {\n+      this.metricsCollectionIntervalMillis = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"metricsCollectionIntervalMillis\", 10000)));\n+      this.metricsCollectionRangeMillis = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"metricsCollectionRangeMillis\", 6 * 10 * 1000)));\n+      int slots = (int) (metricsCollectionRangeMillis / metricsCollectionIntervalMillis) + 1;\n+      log.info(\" The interval of metrics collection is \" + metricsCollectionIntervalMillis + \", \" + metricsCollectionRangeMillis + \" timeRange will collect \" + slots + \" data points at most.\");\n+      this.queue = new CircularFifoQueue<>(slots);\n+      taskCountMax = Integer.parseInt(String.valueOf(this.dynamicAllocationTasksProperties.getOrDefault(\"taskCountMax\", 8)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78cbd45577dccc3abd39fb03db6d2a9298e6c252"}, "originalPosition": 256}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDAwNzEzMw==", "bodyText": "I don't think this log or the one below is needed since there aren't logs for the other Execs", "url": "https://github.com/apache/druid/pull/10524#discussion_r530007133", "createdAt": "2020-11-24T23:32:56Z", "author": {"login": "capistrant"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -652,6 +857,11 @@ public void stop(boolean stopGracefully)\n       try {\n         scheduledExec.shutdownNow(); // stop recurring executions\n         reportingExec.shutdownNow();\n+        log.info(\"Shut Down allocationExec now\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78cbd45577dccc3abd39fb03db6d2a9298e6c252"}, "originalPosition": 316}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDAwOTU5Nw==", "bodyText": "is this supposed to be collectAndComputeLags()? As far as I can tell, the log on line 982 seems to suggest that is the name you may have meant to use", "url": "https://github.com/apache/druid/pull/10524#discussion_r530009597", "createdAt": "2020-11-24T23:35:38Z", "author": {"login": "capistrant"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -791,6 +1016,38 @@ public void tryInit()\n     }\n   }\n \n+  private Runnable collectAndcollectLags()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78cbd45577dccc3abd39fb03db6d2a9298e6c252"}, "originalPosition": 352}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDAxOTc4Ng==", "bodyText": "as your comment says below, this could be null. Should we annotate as nullable?", "url": "https://github.com/apache/druid/pull/10524#discussion_r530019786", "createdAt": "2020-11-24T23:55:28Z", "author": {"login": "capistrant"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisorIOConfig.java", "diffHunk": "@@ -46,6 +48,7 @@\n   private final Optional<Duration> lateMessageRejectionPeriod;\n   private final Optional<Duration> earlyMessageRejectionPeriod;\n   private final Optional<DateTime> lateMessageRejectionStartDateTime;\n+  private final Map<String, Object> dynamicAllocationTasksProperties;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78cbd45577dccc3abd39fb03db6d2a9298e6c252"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDAyMDE0Nw==", "bodyText": "should this be annotated as nullable if the instance can be null as your comment in the constructor suggests?", "url": "https://github.com/apache/druid/pull/10524#discussion_r530020147", "createdAt": "2020-11-24T23:56:34Z", "author": {"login": "capistrant"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisorIOConfig.java", "diffHunk": "@@ -113,12 +119,23 @@ public Integer getReplicas()\n     return replicas;\n   }\n \n+  @JsonProperty", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78cbd45577dccc3abd39fb03db6d2a9298e6c252"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDAyMTA5OA==", "bodyText": "pretty straightforward method, but a short javadoc would be nice since we are updating an important lag related object", "url": "https://github.com/apache/druid/pull/10524#discussion_r530021098", "createdAt": "2020-11-24T23:59:29Z", "author": {"login": "capistrant"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -3526,6 +3789,25 @@ protected void emitLag()\n     }\n   }\n \n+\n+  protected void computeLags(Map<PartitionIdType, Long> partitionLags, ArrayList<Long> lags)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78cbd45577dccc3abd39fb03db6d2a9298e6c252"}, "originalPosition": 453}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDAyMjAwNQ==", "bodyText": "what are the implications of this failing? we are catching and carrying on. Can anything negative come from that?", "url": "https://github.com/apache/druid/pull/10524#discussion_r530022005", "createdAt": "2020-11-25T00:02:23Z", "author": {"login": "capistrant"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -1137,6 +1394,20 @@ public void gracefulShutdownInternal() throws ExecutionException, InterruptedExc\n   @VisibleForTesting\n   public void resetInternal(DataSourceMetadata dataSourceMetadata)\n   {\n+    // clear queue for kafka lags\n+    if (enableDynamicAllocationTasks && queue != null) {\n+      try {\n+        lock.lock();\n+        queue.clear();\n+      }\n+      catch (Exception e) {\n+        log.warn(e, \"Error,when clear queue in rest action\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78cbd45577dccc3abd39fb03db6d2a9298e6c252"}, "originalPosition": 398}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDAyMjIyMA==", "bodyText": "I think refactoring with a more descriptive name would be beneficial for readability", "url": "https://github.com/apache/druid/pull/10524#discussion_r530022220", "createdAt": "2020-11-25T00:03:05Z", "author": {"login": "capistrant"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -495,6 +655,12 @@ boolean isValidTaskGroup(int taskGroupId, @Nullable TaskGroup taskGroup)\n   private volatile boolean stopped = false;\n   private volatile boolean lifecycleStarted = false;\n   private final ServiceEmitter emitter;\n+  private final boolean enableDynamicAllocationTasks;\n+  private volatile long metricsCollectionIntervalMillis;\n+  private volatile long metricsCollectionRangeMillis;\n+  private volatile long dynamicCheckStartDelayMillis;\n+  private volatile long dynamicCheckPeriod;\n+  private volatile CircularFifoQueue<Long> queue;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78cbd45577dccc3abd39fb03db6d2a9298e6c252"}, "originalPosition": 231}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDA2MDY2MQ==", "bodyText": "also, a javadoc would be helpful too if you don't mind", "url": "https://github.com/apache/druid/pull/10524#discussion_r530060661", "createdAt": "2020-11-25T02:05:37Z", "author": {"login": "capistrant"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -791,6 +1016,38 @@ public void tryInit()\n     }\n   }\n \n+  private Runnable collectAndcollectLags()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDAwOTU5Nw=="}, "originalCommit": {"oid": "78cbd45577dccc3abd39fb03db6d2a9298e6c252"}, "originalPosition": 352}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDA2NjEzNA==", "bodyText": "I think this method deserves a more specific name as it is actually re-submitting the supervisor. Perhaps submitSupervisorWithTaskCount or something of that sort?", "url": "https://github.com/apache/druid/pull/10524#discussion_r530066134", "createdAt": "2020-11-25T02:23:59Z", "author": {"login": "capistrant"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -317,6 +322,157 @@ public void handle()\n     }\n   }\n \n+  // same as submit supervisor logic\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    @Override\n+    public void handle()\n+    {\n+      lock.lock();\n+      try {\n+        long nowTime = System.currentTimeMillis();\n+        long minTriggerDynamicFrequency = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"minTriggerDynamicFrequencyMillis\", 1200000)));\n+        // Only queue is full and over minTriggerDynamicFrequency can trigger scale out/in\n+        // max(minTriggerDynamicFrequency, metricsCollectionRangeMillis)\n+        if (spec.isSuspended()) {\n+          log.info(\"[%s] supervisor is suspended, skip to check dynamic allocate task logic\", dataSource);\n+          return;\n+        }\n+        log.info(\"PendingCompletionTaskGroups is : \" + pendingCompletionTaskGroups);\n+        for (CopyOnWriteArrayList list : pendingCompletionTaskGroups.values()) {\n+          if (!list.isEmpty()) {\n+            log.info(\"Still hand off tasks unfinished, skip to do scale action [\" + pendingCompletionTaskGroups + \"]\");\n+            return;\n+          }\n+        }\n+        if (nowTime - dynamicTriggerLastRunTime < minTriggerDynamicFrequency) {\n+          log.info(\"NowTime - dynamicTriggerLastRunTime is [\" + (nowTime - dynamicTriggerLastRunTime) + \"]. Defined minTriggerDynamicFrequency is [\" + minTriggerDynamicFrequency + \"] , CLAM DOWN NOW !\");\n+          return;\n+        }\n+        if (!queue.isAtFullCapacity()) {\n+          log.info(\"Metrics collection is not at full capacity, skip to check dynamic allocate task : [\" + queue.size() + \" vs \" + queue.maxSize() + \"]\");\n+          return;\n+        }\n+        List<Long> lags = collectTotalLags();\n+        boolean allocationSuccess = dynamicAllocate(lags);\n+        if (allocationSuccess) {\n+          dynamicTriggerLastRunTime = nowTime;\n+          queue.clear();\n+        }\n+      }\n+      catch (Exception e) {\n+        log.error(e, \"Error, when parse DynamicAllocationTasksNotice\");\n+      }\n+      finally {\n+        lock.unlock();\n+      }\n+    }\n+  }\n+\n+  private boolean dynamicAllocate(List<Long> lags) throws InterruptedException, ExecutionException, TimeoutException\n+  {\n+    // if supervisor is not suspended, ensure required tasks are running\n+    // if suspended, ensure tasks have been requested to gracefully stop\n+    log.info(\"[%s] supervisor is running, start to check dynamic allocate task logic\", dataSource);\n+    long scaleOutThreshold = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"scaleOutThreshold\", 5000000)));\n+    long scaleInThreshold = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"scaleInThreshold\", 1000000)));\n+    double triggerSaleOutThresholdFrequency = Double.parseDouble(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"triggerSaleOutThresholdFrequency\", 0.3)));\n+    double triggerSaleInThresholdFrequency = Double.parseDouble(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"triggerSaleInThresholdFrequency\", 0.8)));\n+    int taskCountMax = Integer.parseInt(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"taskCountMax\", 8)));\n+    int taskCountMin = Integer.parseInt(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"taskCountMin\", 1)));\n+    int scaleInStep = Integer.parseInt(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"scaleInStep\", 1)));\n+    int scaleOutStep = Integer.parseInt(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"scaleOutStep\", 2)));\n+    int beyond = 0;\n+    int within = 0;\n+    int metricsCount = lags.size();\n+    for (Long lag : lags) {\n+      if (lag >= scaleOutThreshold) {\n+        beyond++;\n+      }\n+      if (lag <= scaleInThreshold) {\n+        within++;\n+      }\n+    }\n+    double beyondProportion = beyond * 1.0 / metricsCount;\n+    double withinProportion = within * 1.0 / metricsCount;\n+    log.info(\"triggerSaleOutThresholdFrequency is [ \" + triggerSaleOutThresholdFrequency + \" ] and triggerSaleInThresholdFrequency is [ \" + triggerSaleInThresholdFrequency + \" ]\");\n+    log.info(\"beyondProportion is [ \" + beyondProportion + \" ] and withinProportion is [ \" + withinProportion + \" ]\");\n+\n+    int currentActiveTaskCount;\n+    int desireActiveTaskCount;\n+    Collection<TaskGroup> activeTaskGroups = activelyReadingTaskGroups.values();\n+    currentActiveTaskCount = activeTaskGroups.size();\n+\n+    if (beyondProportion >= triggerSaleOutThresholdFrequency) {\n+      // Do Scale out\n+      int taskCount = currentActiveTaskCount + scaleOutStep;\n+      if (currentActiveTaskCount == taskCountMax) {\n+        log.info(\"CurrentActiveTaskCount reach task count Max limit, skip to scale out tasks\");\n+        return false;\n+      } else {\n+        desireActiveTaskCount = Math.min(taskCount, taskCountMax);\n+      }\n+      log.info(\"Start to scale out tasks , current active task number [ \" + currentActiveTaskCount + \" ] and desire task number is [ \" + desireActiveTaskCount + \" ] \");\n+      gracefulShutdownInternal();\n+      // clear everything\n+      clearAllocationInfos();\n+      log.info(\"Set Task Count : \" + desireActiveTaskCount);\n+      setTaskCount(desireActiveTaskCount);\n+      return true;\n+    }\n+\n+    if (withinProportion >= triggerSaleInThresholdFrequency) {\n+      // Do Scale in\n+      int taskCount = currentActiveTaskCount - scaleInStep;\n+      if (currentActiveTaskCount == taskCountMin) {\n+        log.info(\"CurrentActiveTaskCount reach task count Min limit, skip to scale in tasks\");\n+        return false;\n+      } else {\n+        desireActiveTaskCount = Math.max(taskCount, taskCountMin);\n+      }\n+      log.info(\"Start to scale in tasks , current active task number [ \" + currentActiveTaskCount + \" ] and desire task number is [ \" + desireActiveTaskCount + \" ] \");\n+      gracefulShutdownInternal();\n+      // clear everything\n+      clearAllocationInfos();\n+      log.info(\"Set Task Count : \" + desireActiveTaskCount);\n+      setTaskCount(desireActiveTaskCount);\n+      return true;\n+    }\n+    return false;\n+  }\n+\n+  private void setTaskCount(int desireActiveTaskCount)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78cbd45577dccc3abd39fb03db6d2a9298e6c252"}, "originalPosition": 162}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDQ5NjU5Mw==", "bodyText": "same thought about debug level and context about the supervisor it is referring to", "url": "https://github.com/apache/druid/pull/10524#discussion_r530496593", "createdAt": "2020-11-25T16:22:16Z", "author": {"login": "capistrant"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -518,20 +684,52 @@ public SeekableStreamSupervisor(\n     this.useExclusiveStartingSequence = useExclusiveStartingSequence;\n     this.dataSource = spec.getDataSchema().getDataSource();\n     this.ioConfig = spec.getIoConfig();\n+    this.dynamicAllocationTasksProperties = ioConfig.getDynamicAllocationTasksProperties();\n+    log.info(\"Get dynamicAllocationTasksProperties from IOConfig : \" + dynamicAllocationTasksProperties);\n+\n+    if (dynamicAllocationTasksProperties != null && !dynamicAllocationTasksProperties.isEmpty() && Boolean.parseBoolean(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"enableDynamicAllocationTasks\", false)))) {\n+      log.info(\"EnableDynamicAllocationTasks for datasource \" + dataSource);\n+      this.enableDynamicAllocationTasks = true;\n+    } else {\n+      log.info(\"Disable Dynamic Allocate Tasks\");\n+      this.enableDynamicAllocationTasks = false;\n+    }\n+    int taskCountMax = 0;\n+    if (enableDynamicAllocationTasks) {\n+      this.metricsCollectionIntervalMillis = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"metricsCollectionIntervalMillis\", 10000)));\n+      this.metricsCollectionRangeMillis = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"metricsCollectionRangeMillis\", 6 * 10 * 1000)));\n+      int slots = (int) (metricsCollectionRangeMillis / metricsCollectionIntervalMillis) + 1;\n+      log.info(\" The interval of metrics collection is \" + metricsCollectionIntervalMillis + \", \" + metricsCollectionRangeMillis + \" timeRange will collect \" + slots + \" data points at most.\");\n+      this.queue = new CircularFifoQueue<>(slots);\n+      taskCountMax = Integer.parseInt(String.valueOf(this.dynamicAllocationTasksProperties.getOrDefault(\"taskCountMax\", 8)));\n+      this.dynamicCheckStartDelayMillis = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"dynamicCheckStartDelayMillis\", 300000)));\n+      this.dynamicCheckPeriod = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"dynamicCheckPeriod\", 600000)));\n+      this.metricsCollectionRangeMillis = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"metricsCollectionRangeMillis\", 600000)));\n+    }\n+\n     this.tuningConfig = spec.getTuningConfig();\n     this.taskTuningConfig = this.tuningConfig.convertToTaskTuningConfig();\n     this.supervisorId = supervisorId;\n     this.exec = Execs.singleThreaded(supervisorId);\n     this.scheduledExec = Execs.scheduledSingleThreaded(supervisorId + \"-Scheduler-%d\");\n     this.reportingExec = Execs.scheduledSingleThreaded(supervisorId + \"-Reporting-%d\");\n+    this.allocationExec = Execs.scheduledSingleThreaded(supervisorId + \"-Allocation-%d\");\n+    this.lagComputationExec = Execs.scheduledSingleThreaded(supervisorId + \"-Computation-%d\");\n     this.stateManager = new SeekableStreamSupervisorStateManager(\n         spec.getSupervisorStateManagerConfig(),\n         spec.isSuspended()\n     );\n \n-    int workerThreads = (this.tuningConfig.getWorkerThreads() != null\n-                         ? this.tuningConfig.getWorkerThreads()\n-                         : Math.min(10, this.ioConfig.getTaskCount()));\n+    int workerThreads;\n+    if (enableDynamicAllocationTasks) {\n+      workerThreads = (this.tuningConfig.getWorkerThreads() != null\n+              ? this.tuningConfig.getWorkerThreads()\n+              : Math.min(10, taskCountMax));\n+    } else {\n+      workerThreads = (this.tuningConfig.getWorkerThreads() != null\n+              ? this.tuningConfig.getWorkerThreads()\n+              : Math.min(10, this.ioConfig.getTaskCount()));\n+    }\n \n     this.workerExec = MoreExecutors.listeningDecorator(Execs.multiThreaded(workerThreads, supervisorId + \"-Worker-%d\"));\n     log.info(\"Created worker pool with [%d] threads for dataSource [%s]\", workerThreads, this.dataSource);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78cbd45577dccc3abd39fb03db6d2a9298e6c252"}, "originalPosition": 290}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDQ5ODUwMg==", "bodyText": "wondering if it would be better to have all these defaults be final constants instantiated at top of class for easy reference?", "url": "https://github.com/apache/druid/pull/10524#discussion_r530498502", "createdAt": "2020-11-25T16:25:06Z", "author": {"login": "capistrant"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -518,20 +684,52 @@ public SeekableStreamSupervisor(\n     this.useExclusiveStartingSequence = useExclusiveStartingSequence;\n     this.dataSource = spec.getDataSchema().getDataSource();\n     this.ioConfig = spec.getIoConfig();\n+    this.dynamicAllocationTasksProperties = ioConfig.getDynamicAllocationTasksProperties();\n+    log.info(\"Get dynamicAllocationTasksProperties from IOConfig : \" + dynamicAllocationTasksProperties);\n+\n+    if (dynamicAllocationTasksProperties != null && !dynamicAllocationTasksProperties.isEmpty() && Boolean.parseBoolean(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"enableDynamicAllocationTasks\", false)))) {\n+      log.info(\"EnableDynamicAllocationTasks for datasource \" + dataSource);\n+      this.enableDynamicAllocationTasks = true;\n+    } else {\n+      log.info(\"Disable Dynamic Allocate Tasks\");\n+      this.enableDynamicAllocationTasks = false;\n+    }\n+    int taskCountMax = 0;\n+    if (enableDynamicAllocationTasks) {\n+      this.metricsCollectionIntervalMillis = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"metricsCollectionIntervalMillis\", 10000)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78cbd45577dccc3abd39fb03db6d2a9298e6c252"}, "originalPosition": 251}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDQ5OTQ2Nw==", "bodyText": "wondering if this default value should be final constant instantiated at top of class?", "url": "https://github.com/apache/druid/pull/10524#discussion_r530499467", "createdAt": "2020-11-25T16:26:24Z", "author": {"login": "capistrant"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -317,6 +322,157 @@ public void handle()\n     }\n   }\n \n+  // same as submit supervisor logic\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    @Override\n+    public void handle()\n+    {\n+      lock.lock();\n+      try {\n+        long nowTime = System.currentTimeMillis();\n+        long minTriggerDynamicFrequency = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"minTriggerDynamicFrequencyMillis\", 1200000)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78cbd45577dccc3abd39fb03db6d2a9298e6c252"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDUwMDM1OQ==", "bodyText": "also the logs added should add context about what supervisor is being logged. I think we should evaluate what logs should be changed to debug too so limit the chattiness of info level", "url": "https://github.com/apache/druid/pull/10524#discussion_r530500359", "createdAt": "2020-11-25T16:27:40Z", "author": {"login": "capistrant"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -317,6 +322,157 @@ public void handle()\n     }\n   }\n \n+  // same as submit supervisor logic\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    @Override\n+    public void handle()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTk4NDk2Ng=="}, "originalCommit": {"oid": "78cbd45577dccc3abd39fb03db6d2a9298e6c252"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDUwMTk5Mg==", "bodyText": "logs added in this method should provide context about what supervisor they refer to. I also think we should evaluate what logs should be changed to debug too so limit the chattiness of info level", "url": "https://github.com/apache/druid/pull/10524#discussion_r530501992", "createdAt": "2020-11-25T16:30:04Z", "author": {"login": "capistrant"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -317,6 +322,157 @@ public void handle()\n     }\n   }\n \n+  // same as submit supervisor logic\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    @Override\n+    public void handle()\n+    {\n+      lock.lock();\n+      try {\n+        long nowTime = System.currentTimeMillis();\n+        long minTriggerDynamicFrequency = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"minTriggerDynamicFrequencyMillis\", 1200000)));\n+        // Only queue is full and over minTriggerDynamicFrequency can trigger scale out/in\n+        // max(minTriggerDynamicFrequency, metricsCollectionRangeMillis)\n+        if (spec.isSuspended()) {\n+          log.info(\"[%s] supervisor is suspended, skip to check dynamic allocate task logic\", dataSource);\n+          return;\n+        }\n+        log.info(\"PendingCompletionTaskGroups is : \" + pendingCompletionTaskGroups);\n+        for (CopyOnWriteArrayList list : pendingCompletionTaskGroups.values()) {\n+          if (!list.isEmpty()) {\n+            log.info(\"Still hand off tasks unfinished, skip to do scale action [\" + pendingCompletionTaskGroups + \"]\");\n+            return;\n+          }\n+        }\n+        if (nowTime - dynamicTriggerLastRunTime < minTriggerDynamicFrequency) {\n+          log.info(\"NowTime - dynamicTriggerLastRunTime is [\" + (nowTime - dynamicTriggerLastRunTime) + \"]. Defined minTriggerDynamicFrequency is [\" + minTriggerDynamicFrequency + \"] , CLAM DOWN NOW !\");\n+          return;\n+        }\n+        if (!queue.isAtFullCapacity()) {\n+          log.info(\"Metrics collection is not at full capacity, skip to check dynamic allocate task : [\" + queue.size() + \" vs \" + queue.maxSize() + \"]\");\n+          return;\n+        }\n+        List<Long> lags = collectTotalLags();\n+        boolean allocationSuccess = dynamicAllocate(lags);\n+        if (allocationSuccess) {\n+          dynamicTriggerLastRunTime = nowTime;\n+          queue.clear();\n+        }\n+      }\n+      catch (Exception e) {\n+        log.error(e, \"Error, when parse DynamicAllocationTasksNotice\");\n+      }\n+      finally {\n+        lock.unlock();\n+      }\n+    }\n+  }\n+\n+  private boolean dynamicAllocate(List<Long> lags) throws InterruptedException, ExecutionException, TimeoutException", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTk4NDU1Ng=="}, "originalCommit": {"oid": "78cbd45577dccc3abd39fb03db6d2a9298e6c252"}, "originalPosition": 90}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDUwMjI3NA==", "bodyText": "should the config defaults be instantiated as final constants at top of class?", "url": "https://github.com/apache/druid/pull/10524#discussion_r530502274", "createdAt": "2020-11-25T16:30:31Z", "author": {"login": "capistrant"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -317,6 +322,157 @@ public void handle()\n     }\n   }\n \n+  // same as submit supervisor logic\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    @Override\n+    public void handle()\n+    {\n+      lock.lock();\n+      try {\n+        long nowTime = System.currentTimeMillis();\n+        long minTriggerDynamicFrequency = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"minTriggerDynamicFrequencyMillis\", 1200000)));\n+        // Only queue is full and over minTriggerDynamicFrequency can trigger scale out/in\n+        // max(minTriggerDynamicFrequency, metricsCollectionRangeMillis)\n+        if (spec.isSuspended()) {\n+          log.info(\"[%s] supervisor is suspended, skip to check dynamic allocate task logic\", dataSource);\n+          return;\n+        }\n+        log.info(\"PendingCompletionTaskGroups is : \" + pendingCompletionTaskGroups);\n+        for (CopyOnWriteArrayList list : pendingCompletionTaskGroups.values()) {\n+          if (!list.isEmpty()) {\n+            log.info(\"Still hand off tasks unfinished, skip to do scale action [\" + pendingCompletionTaskGroups + \"]\");\n+            return;\n+          }\n+        }\n+        if (nowTime - dynamicTriggerLastRunTime < minTriggerDynamicFrequency) {\n+          log.info(\"NowTime - dynamicTriggerLastRunTime is [\" + (nowTime - dynamicTriggerLastRunTime) + \"]. Defined minTriggerDynamicFrequency is [\" + minTriggerDynamicFrequency + \"] , CLAM DOWN NOW !\");\n+          return;\n+        }\n+        if (!queue.isAtFullCapacity()) {\n+          log.info(\"Metrics collection is not at full capacity, skip to check dynamic allocate task : [\" + queue.size() + \" vs \" + queue.maxSize() + \"]\");\n+          return;\n+        }\n+        List<Long> lags = collectTotalLags();\n+        boolean allocationSuccess = dynamicAllocate(lags);\n+        if (allocationSuccess) {\n+          dynamicTriggerLastRunTime = nowTime;\n+          queue.clear();\n+        }\n+      }\n+      catch (Exception e) {\n+        log.error(e, \"Error, when parse DynamicAllocationTasksNotice\");\n+      }\n+      finally {\n+        lock.unlock();\n+      }\n+    }\n+  }\n+\n+  private boolean dynamicAllocate(List<Long> lags) throws InterruptedException, ExecutionException, TimeoutException", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTk4NDU1Ng=="}, "originalCommit": {"oid": "78cbd45577dccc3abd39fb03db6d2a9298e6c252"}, "originalPosition": 90}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDUwOTQyMg==", "bodyText": "what are the consequences of failure at this point? we have called gracefulShutdownInternal so I assume we will be left with no active supervisor for the datasource?", "url": "https://github.com/apache/druid/pull/10524#discussion_r530509422", "createdAt": "2020-11-25T16:41:41Z", "author": {"login": "capistrant"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -317,6 +322,157 @@ public void handle()\n     }\n   }\n \n+  // same as submit supervisor logic\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    @Override\n+    public void handle()\n+    {\n+      lock.lock();\n+      try {\n+        long nowTime = System.currentTimeMillis();\n+        long minTriggerDynamicFrequency = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"minTriggerDynamicFrequencyMillis\", 1200000)));\n+        // Only queue is full and over minTriggerDynamicFrequency can trigger scale out/in\n+        // max(minTriggerDynamicFrequency, metricsCollectionRangeMillis)\n+        if (spec.isSuspended()) {\n+          log.info(\"[%s] supervisor is suspended, skip to check dynamic allocate task logic\", dataSource);\n+          return;\n+        }\n+        log.info(\"PendingCompletionTaskGroups is : \" + pendingCompletionTaskGroups);\n+        for (CopyOnWriteArrayList list : pendingCompletionTaskGroups.values()) {\n+          if (!list.isEmpty()) {\n+            log.info(\"Still hand off tasks unfinished, skip to do scale action [\" + pendingCompletionTaskGroups + \"]\");\n+            return;\n+          }\n+        }\n+        if (nowTime - dynamicTriggerLastRunTime < minTriggerDynamicFrequency) {\n+          log.info(\"NowTime - dynamicTriggerLastRunTime is [\" + (nowTime - dynamicTriggerLastRunTime) + \"]. Defined minTriggerDynamicFrequency is [\" + minTriggerDynamicFrequency + \"] , CLAM DOWN NOW !\");\n+          return;\n+        }\n+        if (!queue.isAtFullCapacity()) {\n+          log.info(\"Metrics collection is not at full capacity, skip to check dynamic allocate task : [\" + queue.size() + \" vs \" + queue.maxSize() + \"]\");\n+          return;\n+        }\n+        List<Long> lags = collectTotalLags();\n+        boolean allocationSuccess = dynamicAllocate(lags);\n+        if (allocationSuccess) {\n+          dynamicTriggerLastRunTime = nowTime;\n+          queue.clear();\n+        }\n+      }\n+      catch (Exception e) {\n+        log.error(e, \"Error, when parse DynamicAllocationTasksNotice\");\n+      }\n+      finally {\n+        lock.unlock();\n+      }\n+    }\n+  }\n+\n+  private boolean dynamicAllocate(List<Long> lags) throws InterruptedException, ExecutionException, TimeoutException\n+  {\n+    // if supervisor is not suspended, ensure required tasks are running\n+    // if suspended, ensure tasks have been requested to gracefully stop\n+    log.info(\"[%s] supervisor is running, start to check dynamic allocate task logic\", dataSource);\n+    long scaleOutThreshold = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"scaleOutThreshold\", 5000000)));\n+    long scaleInThreshold = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"scaleInThreshold\", 1000000)));\n+    double triggerSaleOutThresholdFrequency = Double.parseDouble(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"triggerSaleOutThresholdFrequency\", 0.3)));\n+    double triggerSaleInThresholdFrequency = Double.parseDouble(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"triggerSaleInThresholdFrequency\", 0.8)));\n+    int taskCountMax = Integer.parseInt(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"taskCountMax\", 8)));\n+    int taskCountMin = Integer.parseInt(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"taskCountMin\", 1)));\n+    int scaleInStep = Integer.parseInt(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"scaleInStep\", 1)));\n+    int scaleOutStep = Integer.parseInt(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"scaleOutStep\", 2)));\n+    int beyond = 0;\n+    int within = 0;\n+    int metricsCount = lags.size();\n+    for (Long lag : lags) {\n+      if (lag >= scaleOutThreshold) {\n+        beyond++;\n+      }\n+      if (lag <= scaleInThreshold) {\n+        within++;\n+      }\n+    }\n+    double beyondProportion = beyond * 1.0 / metricsCount;\n+    double withinProportion = within * 1.0 / metricsCount;\n+    log.info(\"triggerSaleOutThresholdFrequency is [ \" + triggerSaleOutThresholdFrequency + \" ] and triggerSaleInThresholdFrequency is [ \" + triggerSaleInThresholdFrequency + \" ]\");\n+    log.info(\"beyondProportion is [ \" + beyondProportion + \" ] and withinProportion is [ \" + withinProportion + \" ]\");\n+\n+    int currentActiveTaskCount;\n+    int desireActiveTaskCount;\n+    Collection<TaskGroup> activeTaskGroups = activelyReadingTaskGroups.values();\n+    currentActiveTaskCount = activeTaskGroups.size();\n+\n+    if (beyondProportion >= triggerSaleOutThresholdFrequency) {\n+      // Do Scale out\n+      int taskCount = currentActiveTaskCount + scaleOutStep;\n+      if (currentActiveTaskCount == taskCountMax) {\n+        log.info(\"CurrentActiveTaskCount reach task count Max limit, skip to scale out tasks\");\n+        return false;\n+      } else {\n+        desireActiveTaskCount = Math.min(taskCount, taskCountMax);\n+      }\n+      log.info(\"Start to scale out tasks , current active task number [ \" + currentActiveTaskCount + \" ] and desire task number is [ \" + desireActiveTaskCount + \" ] \");\n+      gracefulShutdownInternal();\n+      // clear everything\n+      clearAllocationInfos();\n+      log.info(\"Set Task Count : \" + desireActiveTaskCount);\n+      setTaskCount(desireActiveTaskCount);\n+      return true;\n+    }\n+\n+    if (withinProportion >= triggerSaleInThresholdFrequency) {\n+      // Do Scale in\n+      int taskCount = currentActiveTaskCount - scaleInStep;\n+      if (currentActiveTaskCount == taskCountMin) {\n+        log.info(\"CurrentActiveTaskCount reach task count Min limit, skip to scale in tasks\");\n+        return false;\n+      } else {\n+        desireActiveTaskCount = Math.max(taskCount, taskCountMin);\n+      }\n+      log.info(\"Start to scale in tasks , current active task number [ \" + currentActiveTaskCount + \" ] and desire task number is [ \" + desireActiveTaskCount + \" ] \");\n+      gracefulShutdownInternal();\n+      // clear everything\n+      clearAllocationInfos();\n+      log.info(\"Set Task Count : \" + desireActiveTaskCount);\n+      setTaskCount(desireActiveTaskCount);\n+      return true;\n+    }\n+    return false;\n+  }\n+\n+  private void setTaskCount(int desireActiveTaskCount)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDA2NjEzNA=="}, "originalCommit": {"oid": "78cbd45577dccc3abd39fb03db6d2a9298e6c252"}, "originalPosition": 162}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDUxMTMzMA==", "bodyText": "logs in this constructor should include info on the supervisor being referred to. I think we should also evaluate what can be debug to reduce chattiness in info level logging.", "url": "https://github.com/apache/druid/pull/10524#discussion_r530511330", "createdAt": "2020-11-25T16:44:17Z", "author": {"login": "capistrant"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -495,6 +655,12 @@ boolean isValidTaskGroup(int taskGroupId, @Nullable TaskGroup taskGroup)\n   private volatile boolean stopped = false;\n   private volatile boolean lifecycleStarted = false;\n   private final ServiceEmitter emitter;\n+  private final boolean enableDynamicAllocationTasks;\n+  private volatile long metricsCollectionIntervalMillis;\n+  private volatile long metricsCollectionRangeMillis;\n+  private volatile long dynamicCheckStartDelayMillis;\n+  private volatile long dynamicCheckPeriod;\n+  private volatile CircularFifoQueue<Long> queue;\n \n   public SeekableStreamSupervisor(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78cbd45577dccc3abd39fb03db6d2a9298e6c252"}, "originalPosition": 233}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDUxMjY4OA==", "bodyText": "include reference to the datasource in this log and the one for the lag computation executor below. Should they be debug to reduce info level chattiness?", "url": "https://github.com/apache/druid/pull/10524#discussion_r530512688", "createdAt": "2020-11-25T16:46:16Z", "author": {"login": "capistrant"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -768,7 +978,22 @@ public void tryInit()\n         );\n \n         scheduleReporting(reportingExec);\n-\n+        if (enableDynamicAllocationTasks) {\n+          log.info(\"Collect and compute lags at fixed rate of \" + metricsCollectionIntervalMillis);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78cbd45577dccc3abd39fb03db6d2a9298e6c252"}, "originalPosition": 330}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDUxODQ0Mg==", "bodyText": "logs should provide context about what supervisor they are referring. As in other places, lets assess what can be changed to debug to reduce chattiness", "url": "https://github.com/apache/druid/pull/10524#discussion_r530518442", "createdAt": "2020-11-25T16:55:02Z", "author": {"login": "capistrant"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -791,6 +1016,38 @@ public void tryInit()\n     }\n   }\n \n+  private Runnable collectAndcollectLags()\n+  {\n+    return new Runnable() {\n+      @Override\n+      public void run()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78cbd45577dccc3abd39fb03db6d2a9298e6c252"}, "originalPosition": 356}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDUxODgwNQ==", "bodyText": "should this be warn if we catch and move on?", "url": "https://github.com/apache/druid/pull/10524#discussion_r530518805", "createdAt": "2020-11-25T16:55:30Z", "author": {"login": "capistrant"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -791,6 +1016,38 @@ public void tryInit()\n     }\n   }\n \n+  private Runnable collectAndcollectLags()\n+  {\n+    return new Runnable() {\n+      @Override\n+      public void run()\n+      {\n+        lock.lock();\n+        try {\n+          if (!spec.isSuspended()) {\n+            ArrayList<Long> metricsInfo = new ArrayList<>(3);\n+            collectLag(metricsInfo);\n+            long totalLags = metricsInfo.size() < 3 ? 0 : metricsInfo.get(1);\n+            queue.offer(totalLags > 0 ? totalLags : 0);\n+            log.info(\"Current lag metric points : \" + new ArrayList<>(queue));\n+          } else {\n+            log.info(\"[%s] supervisor is suspended, skip to collect kafka lags\", dataSource);\n+          }\n+        }\n+        catch (Exception e) {\n+          log.error(e, \"Error, When collect kafka lags\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78cbd45577dccc3abd39fb03db6d2a9298e6c252"}, "originalPosition": 371}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDUyMjU5Nw==", "bodyText": "does this mean we have not collected enough historical lag data to decide on scale in/scale out? I think the log can be updated to be more descriptive since it may not be obvious to log reader why it matters that queue is not full", "url": "https://github.com/apache/druid/pull/10524#discussion_r530522597", "createdAt": "2020-11-25T17:01:27Z", "author": {"login": "capistrant"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -317,6 +322,157 @@ public void handle()\n     }\n   }\n \n+  // same as submit supervisor logic\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    @Override\n+    public void handle()\n+    {\n+      lock.lock();\n+      try {\n+        long nowTime = System.currentTimeMillis();\n+        long minTriggerDynamicFrequency = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"minTriggerDynamicFrequencyMillis\", 1200000)));\n+        // Only queue is full and over minTriggerDynamicFrequency can trigger scale out/in\n+        // max(minTriggerDynamicFrequency, metricsCollectionRangeMillis)\n+        if (spec.isSuspended()) {\n+          log.info(\"[%s] supervisor is suspended, skip to check dynamic allocate task logic\", dataSource);\n+          return;\n+        }\n+        log.info(\"PendingCompletionTaskGroups is : \" + pendingCompletionTaskGroups);\n+        for (CopyOnWriteArrayList list : pendingCompletionTaskGroups.values()) {\n+          if (!list.isEmpty()) {\n+            log.info(\"Still hand off tasks unfinished, skip to do scale action [\" + pendingCompletionTaskGroups + \"]\");\n+            return;\n+          }\n+        }\n+        if (nowTime - dynamicTriggerLastRunTime < minTriggerDynamicFrequency) {\n+          log.info(\"NowTime - dynamicTriggerLastRunTime is [\" + (nowTime - dynamicTriggerLastRunTime) + \"]. Defined minTriggerDynamicFrequency is [\" + minTriggerDynamicFrequency + \"] , CLAM DOWN NOW !\");\n+          return;\n+        }\n+        if (!queue.isAtFullCapacity()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78cbd45577dccc3abd39fb03db6d2a9298e6c252"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDUyNDA3OA==", "bodyText": "I think these may be spelling mistakes in variable name and config value for this and next config. triggerSale* --> triggerScale* ?", "url": "https://github.com/apache/druid/pull/10524#discussion_r530524078", "createdAt": "2020-11-25T17:03:57Z", "author": {"login": "capistrant"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -317,6 +322,157 @@ public void handle()\n     }\n   }\n \n+  // same as submit supervisor logic\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    @Override\n+    public void handle()\n+    {\n+      lock.lock();\n+      try {\n+        long nowTime = System.currentTimeMillis();\n+        long minTriggerDynamicFrequency = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"minTriggerDynamicFrequencyMillis\", 1200000)));\n+        // Only queue is full and over minTriggerDynamicFrequency can trigger scale out/in\n+        // max(minTriggerDynamicFrequency, metricsCollectionRangeMillis)\n+        if (spec.isSuspended()) {\n+          log.info(\"[%s] supervisor is suspended, skip to check dynamic allocate task logic\", dataSource);\n+          return;\n+        }\n+        log.info(\"PendingCompletionTaskGroups is : \" + pendingCompletionTaskGroups);\n+        for (CopyOnWriteArrayList list : pendingCompletionTaskGroups.values()) {\n+          if (!list.isEmpty()) {\n+            log.info(\"Still hand off tasks unfinished, skip to do scale action [\" + pendingCompletionTaskGroups + \"]\");\n+            return;\n+          }\n+        }\n+        if (nowTime - dynamicTriggerLastRunTime < minTriggerDynamicFrequency) {\n+          log.info(\"NowTime - dynamicTriggerLastRunTime is [\" + (nowTime - dynamicTriggerLastRunTime) + \"]. Defined minTriggerDynamicFrequency is [\" + minTriggerDynamicFrequency + \"] , CLAM DOWN NOW !\");\n+          return;\n+        }\n+        if (!queue.isAtFullCapacity()) {\n+          log.info(\"Metrics collection is not at full capacity, skip to check dynamic allocate task : [\" + queue.size() + \" vs \" + queue.maxSize() + \"]\");\n+          return;\n+        }\n+        List<Long> lags = collectTotalLags();\n+        boolean allocationSuccess = dynamicAllocate(lags);\n+        if (allocationSuccess) {\n+          dynamicTriggerLastRunTime = nowTime;\n+          queue.clear();\n+        }\n+      }\n+      catch (Exception e) {\n+        log.error(e, \"Error, when parse DynamicAllocationTasksNotice\");\n+      }\n+      finally {\n+        lock.unlock();\n+      }\n+    }\n+  }\n+\n+  private boolean dynamicAllocate(List<Long> lags) throws InterruptedException, ExecutionException, TimeoutException\n+  {\n+    // if supervisor is not suspended, ensure required tasks are running\n+    // if suspended, ensure tasks have been requested to gracefully stop\n+    log.info(\"[%s] supervisor is running, start to check dynamic allocate task logic\", dataSource);\n+    long scaleOutThreshold = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"scaleOutThreshold\", 5000000)));\n+    long scaleInThreshold = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"scaleInThreshold\", 1000000)));\n+    double triggerSaleOutThresholdFrequency = Double.parseDouble(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"triggerSaleOutThresholdFrequency\", 0.3)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78cbd45577dccc3abd39fb03db6d2a9298e6c252"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDUyNTU2Ng==", "bodyText": "same spelling callout as above", "url": "https://github.com/apache/druid/pull/10524#discussion_r530525566", "createdAt": "2020-11-25T17:06:21Z", "author": {"login": "capistrant"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -317,6 +322,157 @@ public void handle()\n     }\n   }\n \n+  // same as submit supervisor logic\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    @Override\n+    public void handle()\n+    {\n+      lock.lock();\n+      try {\n+        long nowTime = System.currentTimeMillis();\n+        long minTriggerDynamicFrequency = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"minTriggerDynamicFrequencyMillis\", 1200000)));\n+        // Only queue is full and over minTriggerDynamicFrequency can trigger scale out/in\n+        // max(minTriggerDynamicFrequency, metricsCollectionRangeMillis)\n+        if (spec.isSuspended()) {\n+          log.info(\"[%s] supervisor is suspended, skip to check dynamic allocate task logic\", dataSource);\n+          return;\n+        }\n+        log.info(\"PendingCompletionTaskGroups is : \" + pendingCompletionTaskGroups);\n+        for (CopyOnWriteArrayList list : pendingCompletionTaskGroups.values()) {\n+          if (!list.isEmpty()) {\n+            log.info(\"Still hand off tasks unfinished, skip to do scale action [\" + pendingCompletionTaskGroups + \"]\");\n+            return;\n+          }\n+        }\n+        if (nowTime - dynamicTriggerLastRunTime < minTriggerDynamicFrequency) {\n+          log.info(\"NowTime - dynamicTriggerLastRunTime is [\" + (nowTime - dynamicTriggerLastRunTime) + \"]. Defined minTriggerDynamicFrequency is [\" + minTriggerDynamicFrequency + \"] , CLAM DOWN NOW !\");\n+          return;\n+        }\n+        if (!queue.isAtFullCapacity()) {\n+          log.info(\"Metrics collection is not at full capacity, skip to check dynamic allocate task : [\" + queue.size() + \" vs \" + queue.maxSize() + \"]\");\n+          return;\n+        }\n+        List<Long> lags = collectTotalLags();\n+        boolean allocationSuccess = dynamicAllocate(lags);\n+        if (allocationSuccess) {\n+          dynamicTriggerLastRunTime = nowTime;\n+          queue.clear();\n+        }\n+      }\n+      catch (Exception e) {\n+        log.error(e, \"Error, when parse DynamicAllocationTasksNotice\");\n+      }\n+      finally {\n+        lock.unlock();\n+      }\n+    }\n+  }\n+\n+  private boolean dynamicAllocate(List<Long> lags) throws InterruptedException, ExecutionException, TimeoutException\n+  {\n+    // if supervisor is not suspended, ensure required tasks are running\n+    // if suspended, ensure tasks have been requested to gracefully stop\n+    log.info(\"[%s] supervisor is running, start to check dynamic allocate task logic\", dataSource);\n+    long scaleOutThreshold = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"scaleOutThreshold\", 5000000)));\n+    long scaleInThreshold = Long.parseLong(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"scaleInThreshold\", 1000000)));\n+    double triggerSaleOutThresholdFrequency = Double.parseDouble(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"triggerSaleOutThresholdFrequency\", 0.3)));\n+    double triggerSaleInThresholdFrequency = Double.parseDouble(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"triggerSaleInThresholdFrequency\", 0.8)));\n+    int taskCountMax = Integer.parseInt(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"taskCountMax\", 8)));\n+    int taskCountMin = Integer.parseInt(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"taskCountMin\", 1)));\n+    int scaleInStep = Integer.parseInt(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"scaleInStep\", 1)));\n+    int scaleOutStep = Integer.parseInt(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"scaleOutStep\", 2)));\n+    int beyond = 0;\n+    int within = 0;\n+    int metricsCount = lags.size();\n+    for (Long lag : lags) {\n+      if (lag >= scaleOutThreshold) {\n+        beyond++;\n+      }\n+      if (lag <= scaleInThreshold) {\n+        within++;\n+      }\n+    }\n+    double beyondProportion = beyond * 1.0 / metricsCount;\n+    double withinProportion = within * 1.0 / metricsCount;\n+    log.info(\"triggerSaleOutThresholdFrequency is [ \" + triggerSaleOutThresholdFrequency + \" ] and triggerSaleInThresholdFrequency is [ \" + triggerSaleInThresholdFrequency + \" ]\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "78cbd45577dccc3abd39fb03db6d2a9298e6c252"}, "originalPosition": 116}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e8b7e09333f086603c824c7983b2eee8b8ef7d21", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/e8b7e09333f086603c824c7983b2eee8b8ef7d21", "committedDate": "2020-11-27T02:12:39Z", "message": "Merge branch 'master' into kafka-dynamic-scale-ingest-tasks"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "215844e6162e7095450b04aa6218989da939f37a", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/215844e6162e7095450b04aa6218989da939f37a", "committedDate": "2020-11-27T12:07:24Z", "message": "change codes and add docs based on capistrant reviewed"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b3b75b20992d6a31e6c4012b6408eeaf03192c5b", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/b3b75b20992d6a31e6c4012b6408eeaf03192c5b", "committedDate": "2020-11-27T12:10:24Z", "message": "midify test docs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "18375474208f172c5728a60f3935f4cc023ac981", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/18375474208f172c5728a60f3935f4cc023ac981", "committedDate": "2020-11-27T15:37:50Z", "message": "modify docs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "50a94cadb70d153e5afc675e19ecf1b08654a8c1", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/50a94cadb70d153e5afc675e19ecf1b08654a8c1", "committedDate": "2020-11-27T16:25:40Z", "message": "modify docs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4a0d706626ab82ac438cb4c7c3ba89b4b94e653b", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/4a0d706626ab82ac438cb4c7c3ba89b4b94e653b", "committedDate": "2020-11-28T04:49:59Z", "message": "modify docs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "aa70a5c33c6e1b50739a1b6f15ab3eb67586fb90", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/aa70a5c33c6e1b50739a1b6f15ab3eb67586fb90", "committedDate": "2021-01-15T00:11:13Z", "message": "merge from master"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fb70688fa646c0d4826f1a8e224a76cf6a640427", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/fb70688fa646c0d4826f1a8e224a76cf6a640427", "committedDate": "2021-01-15T00:15:20Z", "message": "merge from master"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c0b3ff258020bd17c1e370ac2b71b872b27f25a8", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/c0b3ff258020bd17c1e370ac2b71b872b27f25a8", "committedDate": "2021-01-15T10:57:51Z", "message": "Extract the autoScale logic out of SeekableStreamSupervisor to minimize putting more stuff inside there &&  Make autoscaling algorithm configurable and scalable."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "76db5ba009fbd54d5b45ffcc3193d3c05373fbe0", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/76db5ba009fbd54d5b45ffcc3193d3c05373fbe0", "committedDate": "2021-01-16T07:52:06Z", "message": "fix ci failed"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "751175fc7cf449fe4adf533c3245878e483a70e6", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/751175fc7cf449fe4adf533c3245878e483a70e6", "committedDate": "2021-01-16T07:53:16Z", "message": "revert msic.xml"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f8a67072ad8deeab6e1035589e568552cd5eec0c", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/f8a67072ad8deeab6e1035589e568552cd5eec0c", "committedDate": "2021-01-16T22:33:41Z", "message": "add uts to test autoscaler create && scale out/in and kafka ingest with scale enable"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "172cff7904038e2b700ca427cad490ea7751cf74", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/172cff7904038e2b700ca427cad490ea7751cf74", "committedDate": "2021-01-17T05:39:56Z", "message": "add more uts"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "57811be4b6fb66a4cfe7e32267a5730bb7e57e48", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/57811be4b6fb66a4cfe7e32267a5730bb7e57e48", "committedDate": "2021-01-17T06:49:13Z", "message": "fix inner class check"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ff8105c173082116a9d346c6cd3caae44fda42d0", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/ff8105c173082116a9d346c6cd3caae44fda42d0", "committedDate": "2021-01-26T02:39:38Z", "message": "add IT for kafka ingestion with autoscaler"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "05571f7e0a124f3971ecc0716d85d3fb30581d5b", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/05571f7e0a124f3971ecc0716d85d3fb30581d5b", "committedDate": "2021-01-26T06:11:02Z", "message": "add new IT in groups=kafka-index named testKafkaIndexDataWithWithAutoscaler"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f09d3d5d4f8374f29288994c955945cb1e33199e", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/f09d3d5d4f8374f29288994c955945cb1e33199e", "committedDate": "2021-01-26T06:16:31Z", "message": "Merge branch 'master' into kafka-dynamic-scale-ingest-tasks"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY3NzgzNTY0", "url": "https://github.com/apache/druid/pull/10524#pullrequestreview-567783564", "createdAt": "2021-01-14T01:16:30Z", "commit": {"oid": "4a0d706626ab82ac438cb4c7c3ba89b4b94e653b"}, "state": "COMMENTED", "comments": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQwMToxNjozMFrOITLdkQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wMlQwMTowMzoyMFrOId7QHQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Njk4MTY0OQ==", "bodyText": "nit: I see that concept of storing lag stats in ArrayList<Long> predates your PR, it might be simpler to define a new class like and change to..... and make related changes in other places where this ArrayList is used\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              protected abstract void collectLag(ArrayList<Long> lags);\n          \n          \n            \n              protected abstract LagStats computeLagStats();\n          \n          \n            \n              \n          \n          \n            \n              static class LagStats\n          \n          \n            \n              {\n          \n          \n            \n                private final long maxLag;\n          \n          \n            \n                private final long totalLag;\n          \n          \n            \n                private final long avgLag;\n          \n          \n            \n            \n          \n          \n            \n                public LagStats(long maxLag, long totalLag, long avgLag)\n          \n          \n            \n                {\n          \n          \n            \n                  this.maxLag = maxLag;\n          \n          \n            \n                  this.totalLag = totalLag;\n          \n          \n            \n                  this.avgLag = avgLag;\n          \n          \n            \n                }\n          \n          \n            \n            \n          \n          \n            \n                public long getMaxLag()\n          \n          \n            \n                {\n          \n          \n            \n                  return maxLag;\n          \n          \n            \n                }\n          \n          \n            \n            \n          \n          \n            \n                public long getTotalLag()\n          \n          \n            \n                {\n          \n          \n            \n                  return totalLag;\n          \n          \n            \n                }\n          \n          \n            \n            \n          \n          \n            \n                public long getAvgLag()\n          \n          \n            \n                {\n          \n          \n            \n                  return avgLag;\n          \n          \n            \n                }\n          \n          \n            \n              }", "url": "https://github.com/apache/druid/pull/10524#discussion_r556981649", "createdAt": "2021-01-14T01:16:30Z", "author": {"login": "himanshug"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -3561,4 +3874,11 @@ protected void emitLag()\n    * sequences. In Kafka, start offsets are always inclusive.\n    */\n   protected abstract boolean useExclusiveStartSequenceNumberForNonFirstSequence();\n+\n+  /**\n+   * Collect maxLag, totalLag, avgLag into ArrayList<Long> lags\n+   * Only support Kafka ingestion so far.\n+   * @param lags , Notice : The order of values is maxLag, totalLag and avgLag.\n+   */\n+  protected abstract void collectLag(ArrayList<Long> lags);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4a0d706626ab82ac438cb4c7c3ba89b4b94e653b"}, "originalPosition": 511}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MTQ2NzQzNg==", "bodyText": "can this be added as default impl in SupervisorSpec interface?", "url": "https://github.com/apache/druid/pull/10524#discussion_r561467436", "createdAt": "2021-01-21T02:01:04Z", "author": {"login": "himanshug"}, "path": "extensions-contrib/materialized-view-maintenance/src/main/java/org/apache/druid/indexing/materializedview/MaterializedViewSupervisorSpec.java", "diffHunk": "@@ -361,6 +362,12 @@ public Supervisor createSupervisor()\n     );\n   }\n \n+  @Override\n+  public SupervisorTaskAutoscaler createAutoscaler(Supervisor supervisor)\n+  {\n+    return null;\n+  }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "57811be4b6fb66a4cfe7e32267a5730bb7e57e48"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODIzNTc5OA==", "bodyText": "At this time, I think this is very specific to KafkaSupervisor and it seems that currently we only want to support autoscaling for kafka indexing , so I would say in this PR, we rename DefaultAutoScaler to KafkaIndexingDefaultAutoScaler and let KafkaIndexingDefaultAutoScaler cast Supervisor to KafkaSupervisor so as to use KafkaSupervisor.collectLag(..) directly and not have it in the interface.\nIf, at a later time, Kinesis starts using it in some form, then Supervisor interface can be modified at that time.", "url": "https://github.com/apache/druid/pull/10524#discussion_r568235798", "createdAt": "2021-02-02T00:25:16Z", "author": {"login": "himanshug"}, "path": "server/src/main/java/org/apache/druid/indexing/overlord/supervisor/Supervisor.java", "diffHunk": "@@ -64,4 +66,18 @@ default Boolean isHealthy()\n    * @param checkpointMetadata metadata for the sequence to currently checkpoint\n    */\n   void checkpoint(int taskGroupId, DataSourceMetadata checkpointMetadata);\n+\n+  /**\n+   * Collect maxLag, totalLag, avgLag into ArrayList<Long> lags\n+   * Only support Kafka ingestion so far.\n+   * @param lags , Notice : The order of values is maxLag, totalLag and avgLag.\n+   */\n+  void collectLag(ArrayList<Long> lags);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f09d3d5d4f8374f29288994c955945cb1e33199e"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODIzNjUyNA==", "bodyText": "can we instead have void reconcileTaskCount() which looks at current task count in the io config, and does things to match that many number of active tasks.\nautoscale impl would be responsible for updating the task count in task io config and then calling this method.", "url": "https://github.com/apache/druid/pull/10524#discussion_r568236524", "createdAt": "2021-02-02T00:27:10Z", "author": {"login": "himanshug"}, "path": "server/src/main/java/org/apache/druid/indexing/overlord/supervisor/Supervisor.java", "diffHunk": "@@ -64,4 +66,18 @@ default Boolean isHealthy()\n    * @param checkpointMetadata metadata for the sequence to currently checkpoint\n    */\n   void checkpoint(int taskGroupId, DataSourceMetadata checkpointMetadata);\n+\n+  /**\n+   * Collect maxLag, totalLag, avgLag into ArrayList<Long> lags\n+   * Only support Kafka ingestion so far.\n+   * @param lags , Notice : The order of values is maxLag, totalLag and avgLag.\n+   */\n+  void collectLag(ArrayList<Long> lags);\n+\n+  /**\n+   * use for autoscaler\n+   */\n+  Runnable buildDynamicAllocationTask(Callable<Integer> scaleAction);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f09d3d5d4f8374f29288994c955945cb1e33199e"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODIzNzE4Mw==", "bodyText": "seems we only really need the active task group count, so, can we have int getActiveTaskGroupsCount() instead ?", "url": "https://github.com/apache/druid/pull/10524#discussion_r568237183", "createdAt": "2021-02-02T00:28:07Z", "author": {"login": "himanshug"}, "path": "server/src/main/java/org/apache/druid/indexing/overlord/supervisor/Supervisor.java", "diffHunk": "@@ -64,4 +66,18 @@ default Boolean isHealthy()\n    * @param checkpointMetadata metadata for the sequence to currently checkpoint\n    */\n   void checkpoint(int taskGroupId, DataSourceMetadata checkpointMetadata);\n+\n+  /**\n+   * Collect maxLag, totalLag, avgLag into ArrayList<Long> lags\n+   * Only support Kafka ingestion so far.\n+   * @param lags , Notice : The order of values is maxLag, totalLag and avgLag.\n+   */\n+  void collectLag(ArrayList<Long> lags);\n+\n+  /**\n+   * use for autoscaler\n+   */\n+  Runnable buildDynamicAllocationTask(Callable<Integer> scaleAction);\n+\n+  Map getSupervisorTaskInfos();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f09d3d5d4f8374f29288994c955945cb1e33199e"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODIzODE0Mw==", "bodyText": "these should throw UnSupportedOperationException instead as they are not supposed to be called", "url": "https://github.com/apache/druid/pull/10524#discussion_r568238143", "createdAt": "2021-02-02T00:30:43Z", "author": {"login": "himanshug"}, "path": "extensions-contrib/materialized-view-maintenance/src/main/java/org/apache/druid/indexing/materializedview/MaterializedViewSupervisor.java", "diffHunk": "@@ -282,6 +283,23 @@ public void checkpoint(int taskGroupId, DataSourceMetadata checkpointMetadata)\n     // do nothing\n   }\n \n+  @Override\n+  public void collectLag(ArrayList<Long> lags)\n+  {\n+  }\n+\n+  @Override\n+  public Runnable buildDynamicAllocationTask(Callable<Integer> scaleAction)\n+  {\n+    return null;\n+  }\n+\n+  @Override\n+  public Map getSupervisorTaskInfos()\n+  {\n+    return null;\n+  }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f09d3d5d4f8374f29288994c955945cb1e33199e"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODIzODcxMA==", "bodyText": "we should actually throw exception if someone sets this on a kinesis supervisor spec ... as that is not expected.", "url": "https://github.com/apache/druid/pull/10524#discussion_r568238710", "createdAt": "2021-02-02T00:32:31Z", "author": {"login": "himanshug"}, "path": "extensions-core/kinesis-indexing-service/src/main/java/org/apache/druid/indexing/kinesis/supervisor/KinesisSupervisorIOConfig.java", "diffHunk": "@@ -70,6 +72,7 @@ public KinesisSupervisorIOConfig(\n       @JsonProperty(\"fetchDelayMillis\") Integer fetchDelayMillis,\n       @JsonProperty(\"awsAssumedRoleArn\") String awsAssumedRoleArn,\n       @JsonProperty(\"awsExternalId\") String awsExternalId,\n+      @JsonProperty(\"dynamicAllocationTasksProperties\") Map<String, Object> dynamicAllocationTasksProperties,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f09d3d5d4f8374f29288994c955945cb1e33199e"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODI0NTY1MQ==", "bodyText": "could we instead get a handle to SupervisorTaskAutoscaler and have SupervisorTaskAutoscaler.getMaxTaskCount() provide maximum task count ?", "url": "https://github.com/apache/druid/pull/10524#discussion_r568245651", "createdAt": "2021-02-02T00:49:30Z", "author": {"login": "himanshug"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -519,20 +636,40 @@ public SeekableStreamSupervisor(\n     this.useExclusiveStartingSequence = useExclusiveStartingSequence;\n     this.dataSource = spec.getDataSchema().getDataSource();\n     this.ioConfig = spec.getIoConfig();\n+    this.dynamicAllocationTasksProperties = ioConfig.getDynamicAllocationTasksProperties();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f09d3d5d4f8374f29288994c955945cb1e33199e"}, "originalPosition": 176}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODI0Nzk0NA==", "bodyText": "this type of logic should live inside the autoscaler impl I think which should decide when to trigger the autoscaling", "url": "https://github.com/apache/druid/pull/10524#discussion_r568247944", "createdAt": "2021-02-02T00:56:01Z", "author": {"login": "himanshug"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -318,6 +322,114 @@ public void handle()\n     }\n   }\n \n+  // change taskCount without resubmitting.\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    Callable<Integer> scaleAction;\n+\n+    DynamicAllocationTasksNotice(Callable<Integer> scaleAction)\n+    {\n+      this.scaleAction = scaleAction;\n+    }\n+\n+    /**\n+     * This method will do lags points collection and check dynamic scale action is necessary or not.\n+     */\n+    @Override\n+    public void handle()\n+    {\n+      try {\n+        long nowTime = System.currentTimeMillis();\n+        // Only queue is full and over minTriggerDynamicFrequency can trigger scale out/in\n+        if (spec.isSuspended()) {\n+          log.info(\"[%s] supervisor is suspended, skip to check dynamic allocate task logic\", dataSource);\n+          return;\n+        }\n+        log.debug(\"PendingCompletionTaskGroups is [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+        for (CopyOnWriteArrayList list : pendingCompletionTaskGroups.values()) {\n+          if (!list.isEmpty()) {\n+            log.info(\"Still hand off tasks unfinished, skip to do scale action [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+            return;\n+          }\n+        }\n+        if (nowTime - dynamicTriggerLastRunTime < minTriggerDynamicFrequency) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f09d3d5d4f8374f29288994c955945cb1e33199e"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODI0OTE2Ng==", "bodyText": "I am not sure why we need extra property enableDynamicAllocationTasks, if user added a non-null dynamicAllocationTasksProperties that alone should mean that user wanted to enable autoscaling.", "url": "https://github.com/apache/druid/pull/10524#discussion_r568249166", "createdAt": "2021-02-02T00:59:31Z", "author": {"login": "himanshug"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisorSpec.java", "diffHunk": "@@ -151,6 +156,29 @@ public DruidMonitorSchedulerConfig getMonitorSchedulerConfig()\n   @Override\n   public abstract Supervisor createSupervisor();\n \n+  /**\n+   * need to notice that autoScaler would be null which means autoscale is dissable.\n+   * @param supervisor\n+   * @return autoScaler, disable autoscale will return dummyAutoScaler and enable autoscale wiil return defaultAutoScaler by default.\n+   */\n+  @Override\n+  @SuppressFBWarnings(value = \"RV_RETURN_VALUE_IGNORED\", justification = \"using siwtch(String)\")\n+  public SupervisorTaskAutoscaler createAutoscaler(Supervisor supervisor)\n+  {\n+    String dataSource = getId();\n+    SupervisorTaskAutoscaler autoScaler = new DummyAutoScaler(supervisor, dataSource);\n+    Map<String, Object> dynamicAllocationTasksProperties = ingestionSchema.getIOConfig().getDynamicAllocationTasksProperties();\n+    if (dynamicAllocationTasksProperties != null && !dynamicAllocationTasksProperties.isEmpty() && Boolean.parseBoolean(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"enableDynamicAllocationTasks\", false)))) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f09d3d5d4f8374f29288994c955945cb1e33199e"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODI0OTUyOQ==", "bodyText": "can we create the autoscaler instance using jackson ... i.e. something like jsonMapper.readValueFrom...()", "url": "https://github.com/apache/druid/pull/10524#discussion_r568249529", "createdAt": "2021-02-02T01:00:29Z", "author": {"login": "himanshug"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisorSpec.java", "diffHunk": "@@ -151,6 +156,29 @@ public DruidMonitorSchedulerConfig getMonitorSchedulerConfig()\n   @Override\n   public abstract Supervisor createSupervisor();\n \n+  /**\n+   * need to notice that autoScaler would be null which means autoscale is dissable.\n+   * @param supervisor\n+   * @return autoScaler, disable autoscale will return dummyAutoScaler and enable autoscale wiil return defaultAutoScaler by default.\n+   */\n+  @Override\n+  @SuppressFBWarnings(value = \"RV_RETURN_VALUE_IGNORED\", justification = \"using siwtch(String)\")\n+  public SupervisorTaskAutoscaler createAutoscaler(Supervisor supervisor)\n+  {\n+    String dataSource = getId();\n+    SupervisorTaskAutoscaler autoScaler = new DummyAutoScaler(supervisor, dataSource);\n+    Map<String, Object> dynamicAllocationTasksProperties = ingestionSchema.getIOConfig().getDynamicAllocationTasksProperties();\n+    if (dynamicAllocationTasksProperties != null && !dynamicAllocationTasksProperties.isEmpty() && Boolean.parseBoolean(String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"enableDynamicAllocationTasks\", false)))) {\n+      String autoScalerStrategy = String.valueOf(dynamicAllocationTasksProperties.getOrDefault(\"autoScalerStrategy\", \"default\"));\n+\n+      // will thorw 'Return value of String.hashCode() ignored : RV_RETURN_VALUE_IGNORED' just Suppress it.\n+      switch (StringUtils.toLowerCase(autoScalerStrategy)) {\n+        default: autoScaler = new DefaultAutoScaler(supervisor, dataSource, dynamicAllocationTasksProperties, this);\n+      }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f09d3d5d4f8374f29288994c955945cb1e33199e"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODI0OTgwMA==", "bodyText": "not sure if we need this, if user added dynamicAllocationTasksProperties  section in the supervisor spec, that alone should be enough to enable autoscaling?", "url": "https://github.com/apache/druid/pull/10524#discussion_r568249800", "createdAt": "2021-02-02T01:01:26Z", "author": {"login": "himanshug"}, "path": "docs/development/extensions-core/kafka-ingestion.md", "diffHunk": "@@ -146,6 +146,26 @@ A sample supervisor spec is shown below:\n |`lateMessageRejectionStartDateTime`|ISO8601 DateTime|Configure tasks to reject messages with timestamps earlier than this date time; for example if this is set to `2016-01-01T11:00Z` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps earlier than *2016-01-01T11:00Z* will be dropped. This may help prevent concurrency issues if your data stream has late messages and you have multiple pipelines that need to operate on the same segments (e.g. a realtime and a nightly batch ingestion pipeline).|no (default == none)|\n |`lateMessageRejectionPeriod`|ISO8601 Period|Configure tasks to reject messages with timestamps earlier than this period before the task was created; for example if this is set to `PT1H` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps earlier than *2016-01-01T11:00Z* will be dropped. This may help prevent concurrency issues if your data stream has late messages and you have multiple pipelines that need to operate on the same segments (e.g. a realtime and a nightly batch ingestion pipeline). Please note that only one of `lateMessageRejectionPeriod` or `lateMessageRejectionStartDateTime` can be specified.|no (default == none)|\n |`earlyMessageRejectionPeriod`|ISO8601 Period|Configure tasks to reject messages with timestamps later than this period after the task reached its taskDuration; for example if this is set to `PT1H`, the taskDuration is set to `PT1H` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps later than *2016-01-01T14:00Z* will be dropped. **Note:** Tasks sometimes run past their task duration, for example, in cases of supervisor failover. Setting earlyMessageRejectionPeriod too low may cause messages to be dropped unexpectedly whenever a task runs past its originally configured task duration.|no (default == none)|\n+|`dynamicAllocationTasksProperties`|Object|`dynamicAllocationTasksProperties` to specify how to auto scale the number of Kafka ingest tasks based on Lag metrics. See [Dynamic Allocation Tasks Properties](#Dynamic Allocation Tasks Properties) for details.|no (default == null)|\n+\n+#### Dynamic Allocation Tasks Properties\n+\n+| Property | Description | Default |\n+| ------------- | ------------- | ------------- |\n+| `enableDynamicAllocationTasks` | whether enable this feature or not | false |", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f09d3d5d4f8374f29288994c955945cb1e33199e"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODI1MDE2Mw==", "bodyText": "I think autoscaling better describes this feature , so maybe call it autoscalerConfig", "url": "https://github.com/apache/druid/pull/10524#discussion_r568250163", "createdAt": "2021-02-02T01:02:33Z", "author": {"login": "himanshug"}, "path": "docs/development/extensions-core/kafka-ingestion.md", "diffHunk": "@@ -146,6 +146,26 @@ A sample supervisor spec is shown below:\n |`lateMessageRejectionStartDateTime`|ISO8601 DateTime|Configure tasks to reject messages with timestamps earlier than this date time; for example if this is set to `2016-01-01T11:00Z` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps earlier than *2016-01-01T11:00Z* will be dropped. This may help prevent concurrency issues if your data stream has late messages and you have multiple pipelines that need to operate on the same segments (e.g. a realtime and a nightly batch ingestion pipeline).|no (default == none)|\n |`lateMessageRejectionPeriod`|ISO8601 Period|Configure tasks to reject messages with timestamps earlier than this period before the task was created; for example if this is set to `PT1H` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps earlier than *2016-01-01T11:00Z* will be dropped. This may help prevent concurrency issues if your data stream has late messages and you have multiple pipelines that need to operate on the same segments (e.g. a realtime and a nightly batch ingestion pipeline). Please note that only one of `lateMessageRejectionPeriod` or `lateMessageRejectionStartDateTime` can be specified.|no (default == none)|\n |`earlyMessageRejectionPeriod`|ISO8601 Period|Configure tasks to reject messages with timestamps later than this period after the task reached its taskDuration; for example if this is set to `PT1H`, the taskDuration is set to `PT1H` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps later than *2016-01-01T14:00Z* will be dropped. **Note:** Tasks sometimes run past their task duration, for example, in cases of supervisor failover. Setting earlyMessageRejectionPeriod too low may cause messages to be dropped unexpectedly whenever a task runs past its originally configured task duration.|no (default == none)|\n+|`dynamicAllocationTasksProperties`|Object|`dynamicAllocationTasksProperties` to specify how to auto scale the number of Kafka ingest tasks based on Lag metrics. See [Dynamic Allocation Tasks Properties](#Dynamic Allocation Tasks Properties) for details.|no (default == null)|", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f09d3d5d4f8374f29288994c955945cb1e33199e"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODI1MDM5Nw==", "bodyText": "be very specific that this is  ONLY supported for kafka indexing as of now.", "url": "https://github.com/apache/druid/pull/10524#discussion_r568250397", "createdAt": "2021-02-02T01:03:20Z", "author": {"login": "himanshug"}, "path": "docs/development/extensions-core/kafka-ingestion.md", "diffHunk": "@@ -146,6 +146,26 @@ A sample supervisor spec is shown below:\n |`lateMessageRejectionStartDateTime`|ISO8601 DateTime|Configure tasks to reject messages with timestamps earlier than this date time; for example if this is set to `2016-01-01T11:00Z` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps earlier than *2016-01-01T11:00Z* will be dropped. This may help prevent concurrency issues if your data stream has late messages and you have multiple pipelines that need to operate on the same segments (e.g. a realtime and a nightly batch ingestion pipeline).|no (default == none)|\n |`lateMessageRejectionPeriod`|ISO8601 Period|Configure tasks to reject messages with timestamps earlier than this period before the task was created; for example if this is set to `PT1H` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps earlier than *2016-01-01T11:00Z* will be dropped. This may help prevent concurrency issues if your data stream has late messages and you have multiple pipelines that need to operate on the same segments (e.g. a realtime and a nightly batch ingestion pipeline). Please note that only one of `lateMessageRejectionPeriod` or `lateMessageRejectionStartDateTime` can be specified.|no (default == none)|\n |`earlyMessageRejectionPeriod`|ISO8601 Period|Configure tasks to reject messages with timestamps later than this period after the task reached its taskDuration; for example if this is set to `PT1H`, the taskDuration is set to `PT1H` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps later than *2016-01-01T14:00Z* will be dropped. **Note:** Tasks sometimes run past their task duration, for example, in cases of supervisor failover. Setting earlyMessageRejectionPeriod too low may cause messages to be dropped unexpectedly whenever a task runs past its originally configured task duration.|no (default == none)|\n+|`dynamicAllocationTasksProperties`|Object|`dynamicAllocationTasksProperties` to specify how to auto scale the number of Kafka ingest tasks based on Lag metrics. See [Dynamic Allocation Tasks Properties](#Dynamic Allocation Tasks Properties) for details.|no (default == null)|", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2ODI1MDE2Mw=="}, "originalCommit": {"oid": "f09d3d5d4f8374f29288994c955945cb1e33199e"}, "originalPosition": 4}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e66d5d20428d39e0d71ae68a41c668d7e2d508a2", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/e66d5d20428d39e0d71ae68a41c668d7e2d508a2", "committedDate": "2021-02-02T05:05:10Z", "message": "Merge branch 'master' into kafka-dynamic-scale-ingest-tasks"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "87a694ad10daa29b8934599a05e35bdbfea14059", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/87a694ad10daa29b8934599a05e35bdbfea14059", "committedDate": "2021-02-02T07:28:01Z", "message": "review change"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "71bdfbbad7c8ff87de78d388dd65c2a25903ca3e", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/71bdfbbad7c8ff87de78d388dd65c2a25903ca3e", "committedDate": "2021-02-02T07:49:58Z", "message": "code review"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "96025755975a2de106d7a9aa1930d48b17bc25b6", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/96025755975a2de106d7a9aa1930d48b17bc25b6", "committedDate": "2021-02-02T09:10:02Z", "message": "remove unused imports"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6bbbf297d1ab84b675d07108f554bd765206ff08", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/6bbbf297d1ab84b675d07108f554bd765206ff08", "committedDate": "2021-02-02T10:23:52Z", "message": "fix NLP"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0ae6a34821939049e6cae6312c6f8b796eb4af11", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/0ae6a34821939049e6cae6312c6f8b796eb4af11", "committedDate": "2021-02-03T02:20:38Z", "message": "fix docs and UTs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "16e4f47421c442851a84c50326d39b3283234094", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/16e4f47421c442851a84c50326d39b3283234094", "committedDate": "2021-02-03T02:24:43Z", "message": "revert misc.xml"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "25fec0ff18d0acb79734dd93bedccff3ab43308a", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/25fec0ff18d0acb79734dd93bedccff3ab43308a", "committedDate": "2021-02-03T11:06:24Z", "message": "use jackson to build autoScaleConfig with default values"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f0c8d7877590876ac9e1e2277eea7b0cb810ec06", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/f0c8d7877590876ac9e1e2277eea7b0cb810ec06", "committedDate": "2021-02-03T14:27:30Z", "message": "add uts"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0733590862fa43068e19b15d85dc5507732f7620", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/0733590862fa43068e19b15d85dc5507732f7620", "committedDate": "2021-02-03T17:22:19Z", "message": "use jackson to init AutoScalerConfig in IOConfig instead of Map<>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "972690294bf199ec0b93d01d5f44e3d9c008720c", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/972690294bf199ec0b93d01d5f44e3d9c008720c", "committedDate": "2021-02-04T04:21:32Z", "message": " autoscalerConfig interface and provide a defaultAutoScalerConfig"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "32fffa955c9ab06ed0a57378e95371e517794f4f", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/32fffa955c9ab06ed0a57378e95371e517794f4f", "committedDate": "2021-02-04T05:22:00Z", "message": "modify uts"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "34c2785dd4973dc1fd34b6739464e228654f4d9f", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/34c2785dd4973dc1fd34b6739464e228654f4d9f", "committedDate": "2021-02-04T06:18:57Z", "message": "modify docs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "eb95830fe960ab0d28d22103b1d115a874fa04c7", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/eb95830fe960ab0d28d22103b1d115a874fa04c7", "committedDate": "2021-02-04T10:56:42Z", "message": "fix checkstyle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7de0f10e7b7a6f802d66983fed928dcf19233049", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/7de0f10e7b7a6f802d66983fed928dcf19233049", "committedDate": "2021-02-04T10:57:48Z", "message": "revert misc.xml"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ce5945b18155d058f6899ea68db26147c3e03015", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/ce5945b18155d058f6899ea68db26147c3e03015", "committedDate": "2021-02-05T02:56:22Z", "message": "modify uts"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTg0MjM5Nzg0", "url": "https://github.com/apache/druid/pull/10524#pullrequestreview-584239784", "createdAt": "2021-02-05T11:10:17Z", "commit": {"oid": "ce5945b18155d058f6899ea68db26147c3e03015"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wNVQxMToxMDoxN1rOIgcj3w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wNVQxMTo0MzozNVrOIgdoHQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDg5MzI3OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n               * @return Boolean flag, do scale action successfully or not. If true , it will take at least 'minTriggerDynamicFrequency' before next 'dynamicAllocatie'.\n          \n          \n            \n               * @return Boolean flag, do scale action successfully or not. If true, it will take at least 'minTriggerDynamicFrequency' before next 'dynamicAllocate'.", "url": "https://github.com/apache/druid/pull/10524#discussion_r570893279", "createdAt": "2021-02-05T11:10:17Z", "author": {"login": "pjain1"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -318,6 +324,114 @@ public void handle()\n     }\n   }\n \n+  // change taskCount without resubmitting.\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    Callable<Integer> scaleAction;\n+\n+    DynamicAllocationTasksNotice(Callable<Integer> scaleAction)\n+    {\n+      this.scaleAction = scaleAction;\n+    }\n+\n+    /**\n+     * This method will do lags points collection and check dynamic scale action is necessary or not.\n+     */\n+    @Override\n+    public void handle()\n+    {\n+      try {\n+        long nowTime = System.currentTimeMillis();\n+        // Only queue is full and over minTriggerDynamicFrequency can trigger scale out/in\n+        if (spec.isSuspended()) {\n+          log.info(\"[%s] supervisor is suspended, skip to check dynamic allocate task logic\", dataSource);\n+          return;\n+        }\n+        log.debug(\"PendingCompletionTaskGroups is [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+        for (CopyOnWriteArrayList list : pendingCompletionTaskGroups.values()) {\n+          if (!list.isEmpty()) {\n+            log.info(\"Still hand off tasks unfinished, skip to do scale action [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+            return;\n+          }\n+        }\n+        if (autoScalerConfig != null && nowTime - dynamicTriggerLastRunTime < autoScalerConfig.getMinTriggerDynamicFrequencyMillis()) {\n+          log.info(\"NowTime - dynamicTriggerLastRunTime is [%s]. Defined minTriggerDynamicFrequency is [%s] for dataSource [%s], CLAM DOWN NOW !\", nowTime - dynamicTriggerLastRunTime, autoScalerConfig.getMinTriggerDynamicFrequencyMillis(), dataSource);\n+          return;\n+        }\n+\n+        Integer desriedTaskCount = scaleAction.call();\n+        boolean allocationSuccess = dynamicAllocate(desriedTaskCount);\n+\n+        if (allocationSuccess) {\n+          dynamicTriggerLastRunTime = nowTime;\n+        }\n+      }\n+      catch (Exception ex) {\n+        log.warn(ex, \"Error, when parse DynamicAllocationTasksNotice\");\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method determines how to do scale actions based on collected lag points.\n+   * If scale action is triggered :\n+   *    First of all, call gracefulShutdownInternal() which will change the state of  current datasource ingest tasks from reading to publishing.\n+   *    Secondly, clear all the stateful data structures: activelyReadingTaskGroups, partitionGroups, partitionOffsets, pendingCompletionTaskGroups, partitionIds. These structures will be rebuiled next 'RunNotice'.\n+   *    Finally, change taskCount in SeekableStreamSupervisorIOConfig and sync it to MetaStorage.\n+   * After changed taskCount in SeekableStreamSupervisorIOConfig, next RunNotice will ceate scaled number of ingest tasks without resubmitting supervisors.\n+   * @param desireActiveTaskCount desire taskCount compute from autoscaler\n+   * @return Boolean flag, do scale action successfully or not. If true , it will take at least 'minTriggerDynamicFrequency' before next 'dynamicAllocatie'.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ce5945b18155d058f6899ea68db26147c3e03015"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDg5MzY2Mg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                      log.info(\"NowTime - dynamicTriggerLastRunTime is [%s]. Defined minTriggerDynamicFrequency is [%s] for dataSource [%s], CLAM DOWN NOW !\", nowTime - dynamicTriggerLastRunTime, autoScalerConfig.getMinTriggerDynamicFrequencyMillis(), dataSource);\n          \n          \n            \n                      log.info(\"NowTime - dynamicTriggerLastRunTime is [%s]. Defined minTriggerDynamicFrequency is [%s] for dataSource [%s], CALM DOWN NOW !\", nowTime - dynamicTriggerLastRunTime, autoScalerConfig.getMinTriggerDynamicFrequencyMillis(), dataSource);", "url": "https://github.com/apache/druid/pull/10524#discussion_r570893662", "createdAt": "2021-02-05T11:11:03Z", "author": {"login": "pjain1"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -318,6 +324,114 @@ public void handle()\n     }\n   }\n \n+  // change taskCount without resubmitting.\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    Callable<Integer> scaleAction;\n+\n+    DynamicAllocationTasksNotice(Callable<Integer> scaleAction)\n+    {\n+      this.scaleAction = scaleAction;\n+    }\n+\n+    /**\n+     * This method will do lags points collection and check dynamic scale action is necessary or not.\n+     */\n+    @Override\n+    public void handle()\n+    {\n+      try {\n+        long nowTime = System.currentTimeMillis();\n+        // Only queue is full and over minTriggerDynamicFrequency can trigger scale out/in\n+        if (spec.isSuspended()) {\n+          log.info(\"[%s] supervisor is suspended, skip to check dynamic allocate task logic\", dataSource);\n+          return;\n+        }\n+        log.debug(\"PendingCompletionTaskGroups is [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+        for (CopyOnWriteArrayList list : pendingCompletionTaskGroups.values()) {\n+          if (!list.isEmpty()) {\n+            log.info(\"Still hand off tasks unfinished, skip to do scale action [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+            return;\n+          }\n+        }\n+        if (autoScalerConfig != null && nowTime - dynamicTriggerLastRunTime < autoScalerConfig.getMinTriggerDynamicFrequencyMillis()) {\n+          log.info(\"NowTime - dynamicTriggerLastRunTime is [%s]. Defined minTriggerDynamicFrequency is [%s] for dataSource [%s], CLAM DOWN NOW !\", nowTime - dynamicTriggerLastRunTime, autoScalerConfig.getMinTriggerDynamicFrequencyMillis(), dataSource);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ce5945b18155d058f6899ea68db26147c3e03015"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDg5NDExMQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    log.warn(ex, \"Error, when parse DynamicAllocationTasksNotice\");\n          \n          \n            \n                    log.warn(ex, \"Error parsing DynamicAllocationTasksNotice\");", "url": "https://github.com/apache/druid/pull/10524#discussion_r570894111", "createdAt": "2021-02-05T11:12:00Z", "author": {"login": "pjain1"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -318,6 +324,114 @@ public void handle()\n     }\n   }\n \n+  // change taskCount without resubmitting.\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    Callable<Integer> scaleAction;\n+\n+    DynamicAllocationTasksNotice(Callable<Integer> scaleAction)\n+    {\n+      this.scaleAction = scaleAction;\n+    }\n+\n+    /**\n+     * This method will do lags points collection and check dynamic scale action is necessary or not.\n+     */\n+    @Override\n+    public void handle()\n+    {\n+      try {\n+        long nowTime = System.currentTimeMillis();\n+        // Only queue is full and over minTriggerDynamicFrequency can trigger scale out/in\n+        if (spec.isSuspended()) {\n+          log.info(\"[%s] supervisor is suspended, skip to check dynamic allocate task logic\", dataSource);\n+          return;\n+        }\n+        log.debug(\"PendingCompletionTaskGroups is [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+        for (CopyOnWriteArrayList list : pendingCompletionTaskGroups.values()) {\n+          if (!list.isEmpty()) {\n+            log.info(\"Still hand off tasks unfinished, skip to do scale action [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+            return;\n+          }\n+        }\n+        if (autoScalerConfig != null && nowTime - dynamicTriggerLastRunTime < autoScalerConfig.getMinTriggerDynamicFrequencyMillis()) {\n+          log.info(\"NowTime - dynamicTriggerLastRunTime is [%s]. Defined minTriggerDynamicFrequency is [%s] for dataSource [%s], CLAM DOWN NOW !\", nowTime - dynamicTriggerLastRunTime, autoScalerConfig.getMinTriggerDynamicFrequencyMillis(), dataSource);\n+          return;\n+        }\n+\n+        Integer desriedTaskCount = scaleAction.call();\n+        boolean allocationSuccess = dynamicAllocate(desriedTaskCount);\n+\n+        if (allocationSuccess) {\n+          dynamicTriggerLastRunTime = nowTime;\n+        }\n+      }\n+      catch (Exception ex) {\n+        log.warn(ex, \"Error, when parse DynamicAllocationTasksNotice\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ce5945b18155d058f6899ea68db26147c3e03015"}, "originalPosition": 89}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDg5NDg1OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n               * After changed taskCount in SeekableStreamSupervisorIOConfig, next RunNotice will ceate scaled number of ingest tasks without resubmitting supervisors.\n          \n          \n            \n               * After changed taskCount in SeekableStreamSupervisorIOConfig, next RunNotice will create scaled number of ingest tasks without resubmitting supervisors.", "url": "https://github.com/apache/druid/pull/10524#discussion_r570894859", "createdAt": "2021-02-05T11:13:35Z", "author": {"login": "pjain1"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -318,6 +324,114 @@ public void handle()\n     }\n   }\n \n+  // change taskCount without resubmitting.\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    Callable<Integer> scaleAction;\n+\n+    DynamicAllocationTasksNotice(Callable<Integer> scaleAction)\n+    {\n+      this.scaleAction = scaleAction;\n+    }\n+\n+    /**\n+     * This method will do lags points collection and check dynamic scale action is necessary or not.\n+     */\n+    @Override\n+    public void handle()\n+    {\n+      try {\n+        long nowTime = System.currentTimeMillis();\n+        // Only queue is full and over minTriggerDynamicFrequency can trigger scale out/in\n+        if (spec.isSuspended()) {\n+          log.info(\"[%s] supervisor is suspended, skip to check dynamic allocate task logic\", dataSource);\n+          return;\n+        }\n+        log.debug(\"PendingCompletionTaskGroups is [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+        for (CopyOnWriteArrayList list : pendingCompletionTaskGroups.values()) {\n+          if (!list.isEmpty()) {\n+            log.info(\"Still hand off tasks unfinished, skip to do scale action [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+            return;\n+          }\n+        }\n+        if (autoScalerConfig != null && nowTime - dynamicTriggerLastRunTime < autoScalerConfig.getMinTriggerDynamicFrequencyMillis()) {\n+          log.info(\"NowTime - dynamicTriggerLastRunTime is [%s]. Defined minTriggerDynamicFrequency is [%s] for dataSource [%s], CLAM DOWN NOW !\", nowTime - dynamicTriggerLastRunTime, autoScalerConfig.getMinTriggerDynamicFrequencyMillis(), dataSource);\n+          return;\n+        }\n+\n+        Integer desriedTaskCount = scaleAction.call();\n+        boolean allocationSuccess = dynamicAllocate(desriedTaskCount);\n+\n+        if (allocationSuccess) {\n+          dynamicTriggerLastRunTime = nowTime;\n+        }\n+      }\n+      catch (Exception ex) {\n+        log.warn(ex, \"Error, when parse DynamicAllocationTasksNotice\");\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method determines how to do scale actions based on collected lag points.\n+   * If scale action is triggered :\n+   *    First of all, call gracefulShutdownInternal() which will change the state of  current datasource ingest tasks from reading to publishing.\n+   *    Secondly, clear all the stateful data structures: activelyReadingTaskGroups, partitionGroups, partitionOffsets, pendingCompletionTaskGroups, partitionIds. These structures will be rebuiled next 'RunNotice'.\n+   *    Finally, change taskCount in SeekableStreamSupervisorIOConfig and sync it to MetaStorage.\n+   * After changed taskCount in SeekableStreamSupervisorIOConfig, next RunNotice will ceate scaled number of ingest tasks without resubmitting supervisors.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ce5945b18155d058f6899ea68db26147c3e03015"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDg5NjAyNQ==", "bodyText": "We are not checking if desireActiveTaskCount is already equal to currentActiveTaskCount. If they are equal there is nothing to be done.", "url": "https://github.com/apache/druid/pull/10524#discussion_r570896025", "createdAt": "2021-02-05T11:15:49Z", "author": {"login": "pjain1"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -318,6 +324,114 @@ public void handle()\n     }\n   }\n \n+  // change taskCount without resubmitting.\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    Callable<Integer> scaleAction;\n+\n+    DynamicAllocationTasksNotice(Callable<Integer> scaleAction)\n+    {\n+      this.scaleAction = scaleAction;\n+    }\n+\n+    /**\n+     * This method will do lags points collection and check dynamic scale action is necessary or not.\n+     */\n+    @Override\n+    public void handle()\n+    {\n+      try {\n+        long nowTime = System.currentTimeMillis();\n+        // Only queue is full and over minTriggerDynamicFrequency can trigger scale out/in\n+        if (spec.isSuspended()) {\n+          log.info(\"[%s] supervisor is suspended, skip to check dynamic allocate task logic\", dataSource);\n+          return;\n+        }\n+        log.debug(\"PendingCompletionTaskGroups is [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+        for (CopyOnWriteArrayList list : pendingCompletionTaskGroups.values()) {\n+          if (!list.isEmpty()) {\n+            log.info(\"Still hand off tasks unfinished, skip to do scale action [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+            return;\n+          }\n+        }\n+        if (autoScalerConfig != null && nowTime - dynamicTriggerLastRunTime < autoScalerConfig.getMinTriggerDynamicFrequencyMillis()) {\n+          log.info(\"NowTime - dynamicTriggerLastRunTime is [%s]. Defined minTriggerDynamicFrequency is [%s] for dataSource [%s], CLAM DOWN NOW !\", nowTime - dynamicTriggerLastRunTime, autoScalerConfig.getMinTriggerDynamicFrequencyMillis(), dataSource);\n+          return;\n+        }\n+\n+        Integer desriedTaskCount = scaleAction.call();\n+        boolean allocationSuccess = dynamicAllocate(desriedTaskCount);\n+\n+        if (allocationSuccess) {\n+          dynamicTriggerLastRunTime = nowTime;\n+        }\n+      }\n+      catch (Exception ex) {\n+        log.warn(ex, \"Error, when parse DynamicAllocationTasksNotice\");\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method determines how to do scale actions based on collected lag points.\n+   * If scale action is triggered :\n+   *    First of all, call gracefulShutdownInternal() which will change the state of  current datasource ingest tasks from reading to publishing.\n+   *    Secondly, clear all the stateful data structures: activelyReadingTaskGroups, partitionGroups, partitionOffsets, pendingCompletionTaskGroups, partitionIds. These structures will be rebuiled next 'RunNotice'.\n+   *    Finally, change taskCount in SeekableStreamSupervisorIOConfig and sync it to MetaStorage.\n+   * After changed taskCount in SeekableStreamSupervisorIOConfig, next RunNotice will ceate scaled number of ingest tasks without resubmitting supervisors.\n+   * @param desireActiveTaskCount desire taskCount compute from autoscaler\n+   * @return Boolean flag, do scale action successfully or not. If true , it will take at least 'minTriggerDynamicFrequency' before next 'dynamicAllocatie'.\n+   *         If false, it will do 'dynamicAllocate' again after 'dynamicCheckPeriod'.\n+   * @throws InterruptedException\n+   * @throws ExecutionException\n+   * @throws TimeoutException\n+   */\n+  private boolean dynamicAllocate(Integer desireActiveTaskCount) throws InterruptedException, ExecutionException, TimeoutException\n+  {\n+    int currentActiveTaskCount;\n+    Collection<TaskGroup> activeTaskGroups = activelyReadingTaskGroups.values();\n+    currentActiveTaskCount = activeTaskGroups.size();\n+\n+    if (desireActiveTaskCount == -1) {\n+      return false;\n+    } else {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ce5945b18155d058f6899ea68db26147c3e03015"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDkxMDc0OQ==", "bodyText": "I think we should first update the count in metadata and then clear the allocation info. What if the database update fails then its not good to clear the allocation info.", "url": "https://github.com/apache/druid/pull/10524#discussion_r570910749", "createdAt": "2021-02-05T11:43:35Z", "author": {"login": "pjain1"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -318,6 +324,114 @@ public void handle()\n     }\n   }\n \n+  // change taskCount without resubmitting.\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    Callable<Integer> scaleAction;\n+\n+    DynamicAllocationTasksNotice(Callable<Integer> scaleAction)\n+    {\n+      this.scaleAction = scaleAction;\n+    }\n+\n+    /**\n+     * This method will do lags points collection and check dynamic scale action is necessary or not.\n+     */\n+    @Override\n+    public void handle()\n+    {\n+      try {\n+        long nowTime = System.currentTimeMillis();\n+        // Only queue is full and over minTriggerDynamicFrequency can trigger scale out/in\n+        if (spec.isSuspended()) {\n+          log.info(\"[%s] supervisor is suspended, skip to check dynamic allocate task logic\", dataSource);\n+          return;\n+        }\n+        log.debug(\"PendingCompletionTaskGroups is [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+        for (CopyOnWriteArrayList list : pendingCompletionTaskGroups.values()) {\n+          if (!list.isEmpty()) {\n+            log.info(\"Still hand off tasks unfinished, skip to do scale action [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+            return;\n+          }\n+        }\n+        if (autoScalerConfig != null && nowTime - dynamicTriggerLastRunTime < autoScalerConfig.getMinTriggerDynamicFrequencyMillis()) {\n+          log.info(\"NowTime - dynamicTriggerLastRunTime is [%s]. Defined minTriggerDynamicFrequency is [%s] for dataSource [%s], CLAM DOWN NOW !\", nowTime - dynamicTriggerLastRunTime, autoScalerConfig.getMinTriggerDynamicFrequencyMillis(), dataSource);\n+          return;\n+        }\n+\n+        Integer desriedTaskCount = scaleAction.call();\n+        boolean allocationSuccess = dynamicAllocate(desriedTaskCount);\n+\n+        if (allocationSuccess) {\n+          dynamicTriggerLastRunTime = nowTime;\n+        }\n+      }\n+      catch (Exception ex) {\n+        log.warn(ex, \"Error, when parse DynamicAllocationTasksNotice\");\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method determines how to do scale actions based on collected lag points.\n+   * If scale action is triggered :\n+   *    First of all, call gracefulShutdownInternal() which will change the state of  current datasource ingest tasks from reading to publishing.\n+   *    Secondly, clear all the stateful data structures: activelyReadingTaskGroups, partitionGroups, partitionOffsets, pendingCompletionTaskGroups, partitionIds. These structures will be rebuiled next 'RunNotice'.\n+   *    Finally, change taskCount in SeekableStreamSupervisorIOConfig and sync it to MetaStorage.\n+   * After changed taskCount in SeekableStreamSupervisorIOConfig, next RunNotice will ceate scaled number of ingest tasks without resubmitting supervisors.\n+   * @param desireActiveTaskCount desire taskCount compute from autoscaler\n+   * @return Boolean flag, do scale action successfully or not. If true , it will take at least 'minTriggerDynamicFrequency' before next 'dynamicAllocatie'.\n+   *         If false, it will do 'dynamicAllocate' again after 'dynamicCheckPeriod'.\n+   * @throws InterruptedException\n+   * @throws ExecutionException\n+   * @throws TimeoutException\n+   */\n+  private boolean dynamicAllocate(Integer desireActiveTaskCount) throws InterruptedException, ExecutionException, TimeoutException\n+  {\n+    int currentActiveTaskCount;\n+    Collection<TaskGroup> activeTaskGroups = activelyReadingTaskGroups.values();\n+    currentActiveTaskCount = activeTaskGroups.size();\n+\n+    if (desireActiveTaskCount == -1) {\n+      return false;\n+    } else {\n+      log.debug(\"Start to scale action tasks, current active task number [%s] and desire task number is [%s] for dataSource [%s].\", currentActiveTaskCount, desireActiveTaskCount, dataSource);\n+      gracefulShutdownInternal();\n+      // clear everything\n+      clearAllocationInfos();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ce5945b18155d058f6899ea68db26147c3e03015"}, "originalPosition": 120}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTg0Mzg4MTQ5", "url": "https://github.com/apache/druid/pull/10524#pullrequestreview-584388149", "createdAt": "2021-02-05T14:29:46Z", "commit": {"oid": "ce5945b18155d058f6899ea68db26147c3e03015"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wNVQxNDoyOTo0NlrOIgjbEA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wNVQxNDoyOTo0NlrOIgjbEA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MTAwNTcxMg==", "bodyText": "desireActiveTaskCount -> desiredActiveTaskCount", "url": "https://github.com/apache/druid/pull/10524#discussion_r571005712", "createdAt": "2021-02-05T14:29:46Z", "author": {"login": "pjain1"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -318,6 +324,114 @@ public void handle()\n     }\n   }\n \n+  // change taskCount without resubmitting.\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    Callable<Integer> scaleAction;\n+\n+    DynamicAllocationTasksNotice(Callable<Integer> scaleAction)\n+    {\n+      this.scaleAction = scaleAction;\n+    }\n+\n+    /**\n+     * This method will do lags points collection and check dynamic scale action is necessary or not.\n+     */\n+    @Override\n+    public void handle()\n+    {\n+      try {\n+        long nowTime = System.currentTimeMillis();\n+        // Only queue is full and over minTriggerDynamicFrequency can trigger scale out/in\n+        if (spec.isSuspended()) {\n+          log.info(\"[%s] supervisor is suspended, skip to check dynamic allocate task logic\", dataSource);\n+          return;\n+        }\n+        log.debug(\"PendingCompletionTaskGroups is [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+        for (CopyOnWriteArrayList list : pendingCompletionTaskGroups.values()) {\n+          if (!list.isEmpty()) {\n+            log.info(\"Still hand off tasks unfinished, skip to do scale action [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+            return;\n+          }\n+        }\n+        if (autoScalerConfig != null && nowTime - dynamicTriggerLastRunTime < autoScalerConfig.getMinTriggerDynamicFrequencyMillis()) {\n+          log.info(\"NowTime - dynamicTriggerLastRunTime is [%s]. Defined minTriggerDynamicFrequency is [%s] for dataSource [%s], CLAM DOWN NOW !\", nowTime - dynamicTriggerLastRunTime, autoScalerConfig.getMinTriggerDynamicFrequencyMillis(), dataSource);\n+          return;\n+        }\n+\n+        Integer desriedTaskCount = scaleAction.call();\n+        boolean allocationSuccess = dynamicAllocate(desriedTaskCount);\n+\n+        if (allocationSuccess) {\n+          dynamicTriggerLastRunTime = nowTime;\n+        }\n+      }\n+      catch (Exception ex) {\n+        log.warn(ex, \"Error, when parse DynamicAllocationTasksNotice\");\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method determines how to do scale actions based on collected lag points.\n+   * If scale action is triggered :\n+   *    First of all, call gracefulShutdownInternal() which will change the state of  current datasource ingest tasks from reading to publishing.\n+   *    Secondly, clear all the stateful data structures: activelyReadingTaskGroups, partitionGroups, partitionOffsets, pendingCompletionTaskGroups, partitionIds. These structures will be rebuiled next 'RunNotice'.\n+   *    Finally, change taskCount in SeekableStreamSupervisorIOConfig and sync it to MetaStorage.\n+   * After changed taskCount in SeekableStreamSupervisorIOConfig, next RunNotice will ceate scaled number of ingest tasks without resubmitting supervisors.\n+   * @param desireActiveTaskCount desire taskCount compute from autoscaler\n+   * @return Boolean flag, do scale action successfully or not. If true , it will take at least 'minTriggerDynamicFrequency' before next 'dynamicAllocatie'.\n+   *         If false, it will do 'dynamicAllocate' again after 'dynamicCheckPeriod'.\n+   * @throws InterruptedException\n+   * @throws ExecutionException\n+   * @throws TimeoutException\n+   */\n+  private boolean dynamicAllocate(Integer desireActiveTaskCount) throws InterruptedException, ExecutionException, TimeoutException", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ce5945b18155d058f6899ea68db26147c3e03015"}, "originalPosition": 108}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "85660b7614a43de30b1859f0e275213b7e1e2343", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/85660b7614a43de30b1859f0e275213b7e1e2343", "committedDate": "2021-02-05T15:23:49Z", "message": "reviewed code change"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "feb3e1e88f68aed4f3ce8a3459d14caf85b663d6", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/feb3e1e88f68aed4f3ce8a3459d14caf85b663d6", "committedDate": "2021-02-05T15:30:09Z", "message": "reviewed code change"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTk1MTU2NDE3", "url": "https://github.com/apache/druid/pull/10524#pullrequestreview-595156417", "createdAt": "2021-02-22T09:33:09Z", "commit": {"oid": "feb3e1e88f68aed4f3ce8a3459d14caf85b663d6"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yMlQwOTozMzowOVrOIpOi5g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yMlQwOTozMzowOVrOIpOi5g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDEwMDgzOA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            |`autoscalerConfig`|Object|`autoscalerConfig` to specify how to auto scale the number of Kafka ingest tasks based on Lag metrics. ONLY supported for Kafka indexing as of now. See [Tasks Autoscaler Properties](#Tasks Autoscaler Properties) for details.|no (default == null)|\n          \n          \n            \n            \n          \n          \n            \n            #### Tasks Autoscaler Properties\n          \n          \n            \n            \n          \n          \n            \n            | Property | Description | Default |\n          \n          \n            \n            | ------------- | ------------- | ------------- |\n          \n          \n            \n            | `enableTaskAutoscaler` | whether enable this feature or not. Set false or ignored here will disable `autoscaler` even though `autoscalerConfig` is not null| false |\n          \n          \n            \n            | `metricsCollectionIntervalMillis` | Define the frequency of lag points collection.  | 30000 |\n          \n          \n            \n            | `metricsCollectionRangeMillis` | The total time window of lag collection, Use with `metricsCollectionIntervalMillis`\uff0cit means that in the recent `metricsCollectionRangeMill`, collect lag metric points every `metricsCollectionIntervalMillis`. | 600000 |\n          \n          \n            \n            | `scaleOutThreshold` | The Threshold of scale out action | 6000000 |\n          \n          \n            \n            | `triggerScaleOutThresholdFrequency` | If `triggerScaleOutThresholdFrequency` percent of lag points are higher than `scaleOutThreshold`, then do scale out action. | 0.3 |\n          \n          \n            \n            | `scaleInThreshold` | The Threshold of scale in action | 1000000 |\n          \n          \n            \n            | `triggerScaleInThresholdFrequency` | If `triggerScaleInThresholdFrequency` percent of lag points are lower than `scaleOutThreshold`, then do scale in action. | 0.9 |\n          \n          \n            \n            | `dynamicCheckStartDelayMillis` | Number of milliseconds after supervisor starts when first check scale logic. | 300000 |\n          \n          \n            \n            | `dynamicCheckPeriod` | the frequency of checking whether to do scale action | 60000 |\n          \n          \n            \n            |`autoscalerConfig`|Object|`autoscalerConfig` to specify how to auto scale the number of Kafka ingest tasks based on Lag metrics. ONLY supported for Kafka indexing as of now. See [Tasks Autoscaler Properties](#task-autoscaler-properties) for details.|no (default == null)|\n          \n          \n            \n            \n          \n          \n            \n            ### Task Autoscaler Properties\n          \n          \n            \n            \n          \n          \n            \n            | Property | Description | Default |\n          \n          \n            \n            | ------------- | ------------- | ------------- |\n          \n          \n            \n            | `enableTaskAutoscaler` | Whether enable this feature or not. Not setting ot setting to false will disable `autoscaler` even though `autoscalerConfig` is not null| false |\n          \n          \n            \n            | `metricsCollectionIntervalMillis` | Define the frequency of lag points collection.  | 30000 |\n          \n          \n            \n            | `metricsCollectionRangeMillis` | The total time window of lag collection, Use with `metricsCollectionIntervalMillis`\uff0cit means that in the recent `metricsCollectionRangeMillis`, collect lag metric points every `metricsCollectionIntervalMillis`. | 600000 |\n          \n          \n            \n            | `scaleOutThreshold` | The Threshold of scale out action | 6000000 |\n          \n          \n            \n            | `triggerScaleOutThresholdFrequency` | If `triggerScaleOutThresholdFrequency` percent of lag points are higher than `scaleOutThreshold`, then do scale out action. | 0.3 |\n          \n          \n            \n            | `scaleInThreshold` | The Threshold of scale in action | 1000000 |\n          \n          \n            \n            | `triggerScaleInThresholdFrequency` | If `triggerScaleInThresholdFrequency` percent of lag points are lower than `scaleOutThreshold`, then do scale in action. | 0.9 |\n          \n          \n            \n            | `dynamicCheckStartDelayMillis` | Number of milliseconds after supervisor starts when first check scale logic. | 300000 |\n          \n          \n            \n            | `dynamicCheckPeriod` | The frequency of checking whether to do scale action in millis | 60000 |", "url": "https://github.com/apache/druid/pull/10524#discussion_r580100838", "createdAt": "2021-02-22T09:33:09Z", "author": {"login": "pjain1"}, "path": "docs/development/extensions-core/kafka-ingestion.md", "diffHunk": "@@ -146,6 +146,26 @@ A sample supervisor spec is shown below:\n |`lateMessageRejectionStartDateTime`|ISO8601 DateTime|Configure tasks to reject messages with timestamps earlier than this date time; for example if this is set to `2016-01-01T11:00Z` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps earlier than *2016-01-01T11:00Z* will be dropped. This may help prevent concurrency issues if your data stream has late messages and you have multiple pipelines that need to operate on the same segments (e.g. a realtime and a nightly batch ingestion pipeline).|no (default == none)|\n |`lateMessageRejectionPeriod`|ISO8601 Period|Configure tasks to reject messages with timestamps earlier than this period before the task was created; for example if this is set to `PT1H` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps earlier than *2016-01-01T11:00Z* will be dropped. This may help prevent concurrency issues if your data stream has late messages and you have multiple pipelines that need to operate on the same segments (e.g. a realtime and a nightly batch ingestion pipeline). Please note that only one of `lateMessageRejectionPeriod` or `lateMessageRejectionStartDateTime` can be specified.|no (default == none)|\n |`earlyMessageRejectionPeriod`|ISO8601 Period|Configure tasks to reject messages with timestamps later than this period after the task reached its taskDuration; for example if this is set to `PT1H`, the taskDuration is set to `PT1H` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps later than *2016-01-01T14:00Z* will be dropped. **Note:** Tasks sometimes run past their task duration, for example, in cases of supervisor failover. Setting earlyMessageRejectionPeriod too low may cause messages to be dropped unexpectedly whenever a task runs past its originally configured task duration.|no (default == none)|\n+|`autoscalerConfig`|Object|`autoscalerConfig` to specify how to auto scale the number of Kafka ingest tasks based on Lag metrics. ONLY supported for Kafka indexing as of now. See [Tasks Autoscaler Properties](#Tasks Autoscaler Properties) for details.|no (default == null)|\n+\n+#### Tasks Autoscaler Properties\n+\n+| Property | Description | Default |\n+| ------------- | ------------- | ------------- |\n+| `enableTaskAutoscaler` | whether enable this feature or not. Set false or ignored here will disable `autoscaler` even though `autoscalerConfig` is not null| false |\n+| `metricsCollectionIntervalMillis` | Define the frequency of lag points collection.  | 30000 |\n+| `metricsCollectionRangeMillis` | The total time window of lag collection, Use with `metricsCollectionIntervalMillis`\uff0cit means that in the recent `metricsCollectionRangeMill`, collect lag metric points every `metricsCollectionIntervalMillis`. | 600000 |\n+| `scaleOutThreshold` | The Threshold of scale out action | 6000000 |\n+| `triggerScaleOutThresholdFrequency` | If `triggerScaleOutThresholdFrequency` percent of lag points are higher than `scaleOutThreshold`, then do scale out action. | 0.3 |\n+| `scaleInThreshold` | The Threshold of scale in action | 1000000 |\n+| `triggerScaleInThresholdFrequency` | If `triggerScaleInThresholdFrequency` percent of lag points are lower than `scaleOutThreshold`, then do scale in action. | 0.9 |\n+| `dynamicCheckStartDelayMillis` | Number of milliseconds after supervisor starts when first check scale logic. | 300000 |\n+| `dynamicCheckPeriod` | the frequency of checking whether to do scale action | 60000 |", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "feb3e1e88f68aed4f3ce8a3459d14caf85b663d6"}, "originalPosition": 18}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTk1MTYyMDAx", "url": "https://github.com/apache/druid/pull/10524#pullrequestreview-595162001", "createdAt": "2021-02-22T09:39:37Z", "commit": {"oid": "feb3e1e88f68aed4f3ce8a3459d14caf85b663d6"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yMlQwOTozOTozN1rOIpO0fw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yMlQwOTozOTozN1rOIpO0fw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDEwNTM0Mw==", "bodyText": "what is this used for ? lets move this to parent pom as done for other dependencies and just declare it here.", "url": "https://github.com/apache/druid/pull/10524#discussion_r580105343", "createdAt": "2021-02-22T09:39:37Z", "author": {"login": "pjain1"}, "path": "indexing-service/pom.xml", "diffHunk": "@@ -62,7 +62,11 @@\n             <artifactId>druid-hll</artifactId>\n             <version>${project.parent.version}</version>\n         </dependency>\n-\n+        <dependency>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "feb3e1e88f68aed4f3ce8a3459d14caf85b663d6"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTk1Mjc1NDc2", "url": "https://github.com/apache/druid/pull/10524#pullrequestreview-595275476", "createdAt": "2021-02-22T11:58:34Z", "commit": {"oid": "feb3e1e88f68aed4f3ce8a3459d14caf85b663d6"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yMlQxMTo1ODozNFrOIpUQGw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yMlQxMTo1ODozNFrOIpUQGw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDE5NDMzMQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  log.info(\"enableTaskAutoscaler for datasource [%s]\", dataSource);\n          \n          \n            \n                  log.info(\"Running Task autoscaler for datasource [%s]\", dataSource);", "url": "https://github.com/apache/druid/pull/10524#discussion_r580194331", "createdAt": "2021-02-22T11:58:34Z", "author": {"login": "pjain1"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -519,20 +635,42 @@ public SeekableStreamSupervisor(\n     this.useExclusiveStartingSequence = useExclusiveStartingSequence;\n     this.dataSource = spec.getDataSchema().getDataSource();\n     this.ioConfig = spec.getIoConfig();\n+    this.autoScalerConfig = ioConfig.getAutoscalerConfig();\n     this.tuningConfig = spec.getTuningConfig();\n     this.taskTuningConfig = this.tuningConfig.convertToTaskTuningConfig();\n     this.supervisorId = supervisorId;\n     this.exec = Execs.singleThreaded(StringUtils.encodeForFormat(supervisorId));\n     this.scheduledExec = Execs.scheduledSingleThreaded(StringUtils.encodeForFormat(supervisorId) + \"-Scheduler-%d\");\n     this.reportingExec = Execs.scheduledSingleThreaded(StringUtils.encodeForFormat(supervisorId) + \"-Reporting-%d\");\n+\n     this.stateManager = new SeekableStreamSupervisorStateManager(\n         spec.getSupervisorStateManagerConfig(),\n         spec.isSuspended()\n     );\n \n-    int workerThreads = (this.tuningConfig.getWorkerThreads() != null\n-                         ? this.tuningConfig.getWorkerThreads()\n-                         : Math.min(10, this.ioConfig.getTaskCount()));\n+    int workerThreads;\n+    int chatThreads;\n+    if (autoScalerConfig != null && autoScalerConfig.getEnableTaskAutoscaler()) {\n+      log.info(\"enableTaskAutoscaler for datasource [%s]\", dataSource);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "feb3e1e88f68aed4f3ce8a3459d14caf85b663d6"}, "originalPosition": 196}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTk1Mjc1ODU5", "url": "https://github.com/apache/druid/pull/10524#pullrequestreview-595275859", "createdAt": "2021-02-22T11:59:06Z", "commit": {"oid": "feb3e1e88f68aed4f3ce8a3459d14caf85b663d6"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yMlQxMTo1OTowN1rOIpURcQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yMlQxMTo1OTowN1rOIpURcQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDE5NDY3Mw==", "bodyText": "IMO this log is not required as this is the default behaviour", "url": "https://github.com/apache/druid/pull/10524#discussion_r580194673", "createdAt": "2021-02-22T11:59:07Z", "author": {"login": "pjain1"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -519,20 +635,42 @@ public SeekableStreamSupervisor(\n     this.useExclusiveStartingSequence = useExclusiveStartingSequence;\n     this.dataSource = spec.getDataSchema().getDataSource();\n     this.ioConfig = spec.getIoConfig();\n+    this.autoScalerConfig = ioConfig.getAutoscalerConfig();\n     this.tuningConfig = spec.getTuningConfig();\n     this.taskTuningConfig = this.tuningConfig.convertToTaskTuningConfig();\n     this.supervisorId = supervisorId;\n     this.exec = Execs.singleThreaded(StringUtils.encodeForFormat(supervisorId));\n     this.scheduledExec = Execs.scheduledSingleThreaded(StringUtils.encodeForFormat(supervisorId) + \"-Scheduler-%d\");\n     this.reportingExec = Execs.scheduledSingleThreaded(StringUtils.encodeForFormat(supervisorId) + \"-Reporting-%d\");\n+\n     this.stateManager = new SeekableStreamSupervisorStateManager(\n         spec.getSupervisorStateManagerConfig(),\n         spec.isSuspended()\n     );\n \n-    int workerThreads = (this.tuningConfig.getWorkerThreads() != null\n-                         ? this.tuningConfig.getWorkerThreads()\n-                         : Math.min(10, this.ioConfig.getTaskCount()));\n+    int workerThreads;\n+    int chatThreads;\n+    if (autoScalerConfig != null && autoScalerConfig.getEnableTaskAutoscaler()) {\n+      log.info(\"enableTaskAutoscaler for datasource [%s]\", dataSource);\n+\n+      workerThreads = (this.tuningConfig.getWorkerThreads() != null\n+              ? this.tuningConfig.getWorkerThreads()\n+              : Math.min(10, autoScalerConfig.getTaskCountMax()));\n+\n+      chatThreads = (this.tuningConfig.getChatThreads() != null\n+              ? this.tuningConfig.getChatThreads()\n+              : Math.min(10, autoScalerConfig.getTaskCountMax() * this.ioConfig.getReplicas()));\n+    } else {\n+      log.info(\"Disable dynamic allocate tasks for [%s]\", dataSource);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "feb3e1e88f68aed4f3ce8a3459d14caf85b663d6"}, "originalPosition": 206}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTk1Mjg1NDU1", "url": "https://github.com/apache/druid/pull/10524#pullrequestreview-595285455", "createdAt": "2021-02-22T12:11:55Z", "commit": {"oid": "feb3e1e88f68aed4f3ce8a3459d14caf85b663d6"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yMlQxMjoxMTo1NVrOIpUugg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yMlQxMjoxMTo1NVrOIpUugg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDIwMjExNA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  try {\n          \n          \n            \n                    long nowTime = System.currentTimeMillis();\n          \n          \n            \n                    // Only queue is full and over minTriggerDynamicFrequency can trigger scale out/in\n          \n          \n            \n                    if (spec.isSuspended()) {\n          \n          \n            \n                      log.info(\"[%s] supervisor is suspended, skip to check dynamic allocate task logic\", dataSource);\n          \n          \n            \n                      return;\n          \n          \n            \n                    }\n          \n          \n            \n                    log.debug(\"PendingCompletionTaskGroups is [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n          \n          \n            \n                    for (CopyOnWriteArrayList list : pendingCompletionTaskGroups.values()) {\n          \n          \n            \n                      if (!list.isEmpty()) {\n          \n          \n            \n                        log.info(\"Still hand off tasks unfinished, skip to do scale action [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n          \n          \n            \n                        return;\n          \n          \n            \n                      }\n          \n          \n            \n                    }\n          \n          \n            \n                    if (autoScalerConfig != null && nowTime - dynamicTriggerLastRunTime < autoScalerConfig.getMinTriggerDynamicFrequencyMillis()) {\n          \n          \n            \n                      log.info(\"NowTime - dynamicTriggerLastRunTime is [%s]. Defined minTriggerDynamicFrequency is [%s] for dataSource [%s], CALM DOWN NOW !\", nowTime - dynamicTriggerLastRunTime, autoScalerConfig.getMinTriggerDynamicFrequencyMillis(), dataSource);\n          \n          \n            \n                      return;\n          \n          \n            \n                    }\n          \n          \n            \n            \n          \n          \n            \n                    Integer desriedTaskCount = scaleAction.call();\n          \n          \n            \n                    boolean allocationSuccess = dynamicAllocate(desriedTaskCount);\n          \n          \n            \n            \n          \n          \n            \n                    if (allocationSuccess) {\n          \n          \n            \n                      dynamicTriggerLastRunTime = nowTime;\n          \n          \n            \n                    }\n          \n          \n            \n                  }\n          \n          \n            \n                  catch (Exception ex) {\n          \n          \n            \n                    log.warn(ex, \"Error parsing DynamicAllocationTasksNotice\");\n          \n          \n            \n                  }\n          \n          \n            \n                }\n          \n          \n            \n                  if (autoScalerConfig == null) {\n          \n          \n            \n                    log.warn(\"autoScalerConfig is null but dynamic allocation notice is submitted, how can it be ?\");\n          \n          \n            \n                  } else {\n          \n          \n            \n                    try {\n          \n          \n            \n                      long nowTime = System.currentTimeMillis();\n          \n          \n            \n                      if (spec.isSuspended()) {\n          \n          \n            \n                        log.info(\"Skipping DynamicAllocationTasksNotice execution because [%s] supervisor is suspended\",\n          \n          \n            \n                            dataSource\n          \n          \n            \n                        );\n          \n          \n            \n                        return;\n          \n          \n            \n                      }\n          \n          \n            \n                      log.debug(\"PendingCompletionTaskGroups is [%s] for dataSource [%s]\", pendingCompletionTaskGroups,\n          \n          \n            \n                          dataSource\n          \n          \n            \n                      );\n          \n          \n            \n                      for (CopyOnWriteArrayList<TaskGroup> list : pendingCompletionTaskGroups.values()) {\n          \n          \n            \n                        if (!list.isEmpty()) {\n          \n          \n            \n                          log.info(\n          \n          \n            \n                              \"Skipping DynamicAllocationTasksNotice execution for datasource [%s] because following tasks are pending [%s]\",\n          \n          \n            \n                              dataSource, pendingCompletionTaskGroups\n          \n          \n            \n                          );\n          \n          \n            \n                          return;\n          \n          \n            \n                        }\n          \n          \n            \n                      }\n          \n          \n            \n                      if (nowTime - dynamicTriggerLastRunTime < autoScalerConfig.getMinTriggerDynamicFrequencyMillis()) {\n          \n          \n            \n                        log.info(\n          \n          \n            \n                            \"DynamicAllocationTasksNotice submitted again in [%d] millis, minTriggerDynamicFrequency is [%s] for dataSource [%s], skipping it!\",\n          \n          \n            \n                            nowTime - dynamicTriggerLastRunTime, autoScalerConfig.getMinTriggerDynamicFrequencyMillis(), dataSource\n          \n          \n            \n                        );\n          \n          \n            \n                        return;\n          \n          \n            \n                      }\n          \n          \n            \n            \n          \n          \n            \n                      Integer desriedTaskCount = scaleAction.call();\n          \n          \n            \n                      boolean allocationSuccess = dynamicAllocate(desriedTaskCount);\n          \n          \n            \n            \n          \n          \n            \n                      if (allocationSuccess) {\n          \n          \n            \n                        dynamicTriggerLastRunTime = nowTime;\n          \n          \n            \n                      }\n          \n          \n            \n                    } catch (Exception ex) {\n          \n          \n            \n                      log.warn(ex, \"Error parsing DynamicAllocationTasksNotice\");\n          \n          \n            \n                    }\n          \n          \n            \n                  }", "url": "https://github.com/apache/druid/pull/10524#discussion_r580202114", "createdAt": "2021-02-22T12:11:55Z", "author": {"login": "pjain1"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -318,6 +324,114 @@ public void handle()\n     }\n   }\n \n+  // change taskCount without resubmitting.\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    Callable<Integer> scaleAction;\n+\n+    DynamicAllocationTasksNotice(Callable<Integer> scaleAction)\n+    {\n+      this.scaleAction = scaleAction;\n+    }\n+\n+    /**\n+     * This method will do lags points collection and check dynamic scale action is necessary or not.\n+     */\n+    @Override\n+    public void handle()\n+    {\n+      try {\n+        long nowTime = System.currentTimeMillis();\n+        // Only queue is full and over minTriggerDynamicFrequency can trigger scale out/in\n+        if (spec.isSuspended()) {\n+          log.info(\"[%s] supervisor is suspended, skip to check dynamic allocate task logic\", dataSource);\n+          return;\n+        }\n+        log.debug(\"PendingCompletionTaskGroups is [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+        for (CopyOnWriteArrayList list : pendingCompletionTaskGroups.values()) {\n+          if (!list.isEmpty()) {\n+            log.info(\"Still hand off tasks unfinished, skip to do scale action [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+            return;\n+          }\n+        }\n+        if (autoScalerConfig != null && nowTime - dynamicTriggerLastRunTime < autoScalerConfig.getMinTriggerDynamicFrequencyMillis()) {\n+          log.info(\"NowTime - dynamicTriggerLastRunTime is [%s]. Defined minTriggerDynamicFrequency is [%s] for dataSource [%s], CALM DOWN NOW !\", nowTime - dynamicTriggerLastRunTime, autoScalerConfig.getMinTriggerDynamicFrequencyMillis(), dataSource);\n+          return;\n+        }\n+\n+        Integer desriedTaskCount = scaleAction.call();\n+        boolean allocationSuccess = dynamicAllocate(desriedTaskCount);\n+\n+        if (allocationSuccess) {\n+          dynamicTriggerLastRunTime = nowTime;\n+        }\n+      }\n+      catch (Exception ex) {\n+        log.warn(ex, \"Error parsing DynamicAllocationTasksNotice\");\n+      }\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "feb3e1e88f68aed4f3ce8a3459d14caf85b663d6"}, "originalPosition": 91}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTk1MjkxNzYw", "url": "https://github.com/apache/druid/pull/10524#pullrequestreview-595291760", "createdAt": "2021-02-22T12:20:26Z", "commit": {"oid": "feb3e1e88f68aed4f3ce8a3459d14caf85b663d6"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yMlQxMjoyMDoyN1rOIpVCBg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yMlQxMjoyMDoyN1rOIpVCBg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDIwNzExMA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n               *    First of all, call gracefulShutdownInternal() which will change the state of  current datasource ingest tasks from reading to publishing.\n          \n          \n            \n               *    Secondly, clear all the stateful data structures: activelyReadingTaskGroups, partitionGroups, partitionOffsets, pendingCompletionTaskGroups, partitionIds. These structures will be rebuiled next 'RunNotice'.\n          \n          \n            \n               *    Finally, change taskCount in SeekableStreamSupervisorIOConfig and sync it to MetaStorage.\n          \n          \n            \n               * After changed taskCount in SeekableStreamSupervisorIOConfig, next RunNotice will create scaled number of ingest tasks without resubmitting supervisors.\n          \n          \n            \n               * @param desiredActiveTaskCount desired taskCount compute from autoscaler\n          \n          \n            \n               * @return Boolean flag, do scale action successfully or not. If true , it will take at least 'minTriggerDynamicFrequency' before next 'dynamicAllocate'.\n          \n          \n            \n               *         If false, it will do 'dynamicAllocate' again after 'dynamicCheckPeriod'.\n          \n          \n            \n               *    First of all, call gracefulShutdownInternal() which will change the state of current datasource ingest tasks from reading to publishing.\n          \n          \n            \n               *    Secondly, clear all the stateful data structures: activelyReadingTaskGroups, partitionGroups, partitionOffsets, pendingCompletionTaskGroups, partitionIds. These structures will be rebuild in the next 'RunNotice'.\n          \n          \n            \n               *    Finally, change the taskCount in SeekableStreamSupervisorIOConfig and sync it to MetadataStorage.\n          \n          \n            \n               * After the taskCount is changed in SeekableStreamSupervisorIOConfig, next RunNotice will create scaled number of ingest tasks without resubmitting the supervisor.\n          \n          \n            \n               * @param desiredActiveTaskCount desired taskCount compute from autoscaler\n          \n          \n            \n               * @return Boolean flag indicating if scale action was executed or not. If true, it will wait at least 'minTriggerDynamicFrequency' before next 'dynamicAllocate'.\n          \n          \n            \n               *         If false, it will do 'dynamicAllocate' again after 'dynamicCheckPeriod' millis.", "url": "https://github.com/apache/druid/pull/10524#discussion_r580207110", "createdAt": "2021-02-22T12:20:27Z", "author": {"login": "pjain1"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -318,6 +324,114 @@ public void handle()\n     }\n   }\n \n+  // change taskCount without resubmitting.\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    Callable<Integer> scaleAction;\n+\n+    DynamicAllocationTasksNotice(Callable<Integer> scaleAction)\n+    {\n+      this.scaleAction = scaleAction;\n+    }\n+\n+    /**\n+     * This method will do lags points collection and check dynamic scale action is necessary or not.\n+     */\n+    @Override\n+    public void handle()\n+    {\n+      try {\n+        long nowTime = System.currentTimeMillis();\n+        // Only queue is full and over minTriggerDynamicFrequency can trigger scale out/in\n+        if (spec.isSuspended()) {\n+          log.info(\"[%s] supervisor is suspended, skip to check dynamic allocate task logic\", dataSource);\n+          return;\n+        }\n+        log.debug(\"PendingCompletionTaskGroups is [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+        for (CopyOnWriteArrayList list : pendingCompletionTaskGroups.values()) {\n+          if (!list.isEmpty()) {\n+            log.info(\"Still hand off tasks unfinished, skip to do scale action [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+            return;\n+          }\n+        }\n+        if (autoScalerConfig != null && nowTime - dynamicTriggerLastRunTime < autoScalerConfig.getMinTriggerDynamicFrequencyMillis()) {\n+          log.info(\"NowTime - dynamicTriggerLastRunTime is [%s]. Defined minTriggerDynamicFrequency is [%s] for dataSource [%s], CALM DOWN NOW !\", nowTime - dynamicTriggerLastRunTime, autoScalerConfig.getMinTriggerDynamicFrequencyMillis(), dataSource);\n+          return;\n+        }\n+\n+        Integer desriedTaskCount = scaleAction.call();\n+        boolean allocationSuccess = dynamicAllocate(desriedTaskCount);\n+\n+        if (allocationSuccess) {\n+          dynamicTriggerLastRunTime = nowTime;\n+        }\n+      }\n+      catch (Exception ex) {\n+        log.warn(ex, \"Error parsing DynamicAllocationTasksNotice\");\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method determines how to do scale actions based on collected lag points.\n+   * If scale action is triggered :\n+   *    First of all, call gracefulShutdownInternal() which will change the state of  current datasource ingest tasks from reading to publishing.\n+   *    Secondly, clear all the stateful data structures: activelyReadingTaskGroups, partitionGroups, partitionOffsets, pendingCompletionTaskGroups, partitionIds. These structures will be rebuiled next 'RunNotice'.\n+   *    Finally, change taskCount in SeekableStreamSupervisorIOConfig and sync it to MetaStorage.\n+   * After changed taskCount in SeekableStreamSupervisorIOConfig, next RunNotice will create scaled number of ingest tasks without resubmitting supervisors.\n+   * @param desiredActiveTaskCount desired taskCount compute from autoscaler\n+   * @return Boolean flag, do scale action successfully or not. If true , it will take at least 'minTriggerDynamicFrequency' before next 'dynamicAllocate'.\n+   *         If false, it will do 'dynamicAllocate' again after 'dynamicCheckPeriod'.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "feb3e1e88f68aed4f3ce8a3459d14caf85b663d6"}, "originalPosition": 103}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTk1MjkyNDY2", "url": "https://github.com/apache/druid/pull/10524#pullrequestreview-595292466", "createdAt": "2021-02-22T12:21:22Z", "commit": {"oid": "feb3e1e88f68aed4f3ce8a3459d14caf85b663d6"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yMlQxMjoyMToyMlrOIpVEIQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yMlQxMjoyMToyMlrOIpVEIQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDIwNzY0OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  log.debug(\"Start to scale action tasks, current active task number [%s] and desired task number is [%s] for dataSource [%s].\", currentActiveTaskCount, desiredActiveTaskCount, dataSource);\n          \n          \n            \n                  log.debug(\n          \n          \n            \n                      \"Starting scale action, current active task count is [%d] and desired task count is [%d] for dataSource [%s].\",\n          \n          \n            \n                      currentActiveTaskCount, desiredActiveTaskCount, dataSource\n          \n          \n            \n                  );", "url": "https://github.com/apache/druid/pull/10524#discussion_r580207649", "createdAt": "2021-02-22T12:21:22Z", "author": {"login": "pjain1"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -318,6 +324,114 @@ public void handle()\n     }\n   }\n \n+  // change taskCount without resubmitting.\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    Callable<Integer> scaleAction;\n+\n+    DynamicAllocationTasksNotice(Callable<Integer> scaleAction)\n+    {\n+      this.scaleAction = scaleAction;\n+    }\n+\n+    /**\n+     * This method will do lags points collection and check dynamic scale action is necessary or not.\n+     */\n+    @Override\n+    public void handle()\n+    {\n+      try {\n+        long nowTime = System.currentTimeMillis();\n+        // Only queue is full and over minTriggerDynamicFrequency can trigger scale out/in\n+        if (spec.isSuspended()) {\n+          log.info(\"[%s] supervisor is suspended, skip to check dynamic allocate task logic\", dataSource);\n+          return;\n+        }\n+        log.debug(\"PendingCompletionTaskGroups is [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+        for (CopyOnWriteArrayList list : pendingCompletionTaskGroups.values()) {\n+          if (!list.isEmpty()) {\n+            log.info(\"Still hand off tasks unfinished, skip to do scale action [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+            return;\n+          }\n+        }\n+        if (autoScalerConfig != null && nowTime - dynamicTriggerLastRunTime < autoScalerConfig.getMinTriggerDynamicFrequencyMillis()) {\n+          log.info(\"NowTime - dynamicTriggerLastRunTime is [%s]. Defined minTriggerDynamicFrequency is [%s] for dataSource [%s], CALM DOWN NOW !\", nowTime - dynamicTriggerLastRunTime, autoScalerConfig.getMinTriggerDynamicFrequencyMillis(), dataSource);\n+          return;\n+        }\n+\n+        Integer desriedTaskCount = scaleAction.call();\n+        boolean allocationSuccess = dynamicAllocate(desriedTaskCount);\n+\n+        if (allocationSuccess) {\n+          dynamicTriggerLastRunTime = nowTime;\n+        }\n+      }\n+      catch (Exception ex) {\n+        log.warn(ex, \"Error parsing DynamicAllocationTasksNotice\");\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method determines how to do scale actions based on collected lag points.\n+   * If scale action is triggered :\n+   *    First of all, call gracefulShutdownInternal() which will change the state of  current datasource ingest tasks from reading to publishing.\n+   *    Secondly, clear all the stateful data structures: activelyReadingTaskGroups, partitionGroups, partitionOffsets, pendingCompletionTaskGroups, partitionIds. These structures will be rebuiled next 'RunNotice'.\n+   *    Finally, change taskCount in SeekableStreamSupervisorIOConfig and sync it to MetaStorage.\n+   * After changed taskCount in SeekableStreamSupervisorIOConfig, next RunNotice will create scaled number of ingest tasks without resubmitting supervisors.\n+   * @param desiredActiveTaskCount desired taskCount compute from autoscaler\n+   * @return Boolean flag, do scale action successfully or not. If true , it will take at least 'minTriggerDynamicFrequency' before next 'dynamicAllocate'.\n+   *         If false, it will do 'dynamicAllocate' again after 'dynamicCheckPeriod'.\n+   * @throws InterruptedException\n+   * @throws ExecutionException\n+   * @throws TimeoutException\n+   */\n+  private boolean dynamicAllocate(Integer desiredActiveTaskCount) throws InterruptedException, ExecutionException, TimeoutException\n+  {\n+    int currentActiveTaskCount;\n+    Collection<TaskGroup> activeTaskGroups = activelyReadingTaskGroups.values();\n+    currentActiveTaskCount = activeTaskGroups.size();\n+\n+    if (desiredActiveTaskCount == -1 || desiredActiveTaskCount == currentActiveTaskCount) {\n+      return false;\n+    } else {\n+      log.debug(\"Start to scale action tasks, current active task number [%s] and desired task number is [%s] for dataSource [%s].\", currentActiveTaskCount, desiredActiveTaskCount, dataSource);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "feb3e1e88f68aed4f3ce8a3459d14caf85b663d6"}, "originalPosition": 117}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTk1MjkzMjQ2", "url": "https://github.com/apache/druid/pull/10524#pullrequestreview-595293246", "createdAt": "2021-02-22T12:22:23Z", "commit": {"oid": "feb3e1e88f68aed4f3ce8a3459d14caf85b663d6"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yMlQxMjoyMjoyM1rOIpVGnw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yMlQxMjoyMjoyM1rOIpVGnw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDIwODI4Nw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    log.warn(\"supervisorManager is null in taskMaster, skip to do scale action for dataSource [%s].\", dataSource);\n          \n          \n            \n                    log.warn(\"supervisorManager is null in taskMaster, skipping scale action for dataSource [%s].\", dataSource);", "url": "https://github.com/apache/druid/pull/10524#discussion_r580208287", "createdAt": "2021-02-22T12:22:23Z", "author": {"login": "pjain1"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -318,6 +324,114 @@ public void handle()\n     }\n   }\n \n+  // change taskCount without resubmitting.\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    Callable<Integer> scaleAction;\n+\n+    DynamicAllocationTasksNotice(Callable<Integer> scaleAction)\n+    {\n+      this.scaleAction = scaleAction;\n+    }\n+\n+    /**\n+     * This method will do lags points collection and check dynamic scale action is necessary or not.\n+     */\n+    @Override\n+    public void handle()\n+    {\n+      try {\n+        long nowTime = System.currentTimeMillis();\n+        // Only queue is full and over minTriggerDynamicFrequency can trigger scale out/in\n+        if (spec.isSuspended()) {\n+          log.info(\"[%s] supervisor is suspended, skip to check dynamic allocate task logic\", dataSource);\n+          return;\n+        }\n+        log.debug(\"PendingCompletionTaskGroups is [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+        for (CopyOnWriteArrayList list : pendingCompletionTaskGroups.values()) {\n+          if (!list.isEmpty()) {\n+            log.info(\"Still hand off tasks unfinished, skip to do scale action [%s] for dataSource [%s].\", pendingCompletionTaskGroups, dataSource);\n+            return;\n+          }\n+        }\n+        if (autoScalerConfig != null && nowTime - dynamicTriggerLastRunTime < autoScalerConfig.getMinTriggerDynamicFrequencyMillis()) {\n+          log.info(\"NowTime - dynamicTriggerLastRunTime is [%s]. Defined minTriggerDynamicFrequency is [%s] for dataSource [%s], CALM DOWN NOW !\", nowTime - dynamicTriggerLastRunTime, autoScalerConfig.getMinTriggerDynamicFrequencyMillis(), dataSource);\n+          return;\n+        }\n+\n+        Integer desriedTaskCount = scaleAction.call();\n+        boolean allocationSuccess = dynamicAllocate(desriedTaskCount);\n+\n+        if (allocationSuccess) {\n+          dynamicTriggerLastRunTime = nowTime;\n+        }\n+      }\n+      catch (Exception ex) {\n+        log.warn(ex, \"Error parsing DynamicAllocationTasksNotice\");\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method determines how to do scale actions based on collected lag points.\n+   * If scale action is triggered :\n+   *    First of all, call gracefulShutdownInternal() which will change the state of  current datasource ingest tasks from reading to publishing.\n+   *    Secondly, clear all the stateful data structures: activelyReadingTaskGroups, partitionGroups, partitionOffsets, pendingCompletionTaskGroups, partitionIds. These structures will be rebuiled next 'RunNotice'.\n+   *    Finally, change taskCount in SeekableStreamSupervisorIOConfig and sync it to MetaStorage.\n+   * After changed taskCount in SeekableStreamSupervisorIOConfig, next RunNotice will create scaled number of ingest tasks without resubmitting supervisors.\n+   * @param desiredActiveTaskCount desired taskCount compute from autoscaler\n+   * @return Boolean flag, do scale action successfully or not. If true , it will take at least 'minTriggerDynamicFrequency' before next 'dynamicAllocate'.\n+   *         If false, it will do 'dynamicAllocate' again after 'dynamicCheckPeriod'.\n+   * @throws InterruptedException\n+   * @throws ExecutionException\n+   * @throws TimeoutException\n+   */\n+  private boolean dynamicAllocate(Integer desiredActiveTaskCount) throws InterruptedException, ExecutionException, TimeoutException\n+  {\n+    int currentActiveTaskCount;\n+    Collection<TaskGroup> activeTaskGroups = activelyReadingTaskGroups.values();\n+    currentActiveTaskCount = activeTaskGroups.size();\n+\n+    if (desiredActiveTaskCount == -1 || desiredActiveTaskCount == currentActiveTaskCount) {\n+      return false;\n+    } else {\n+      log.debug(\"Start to scale action tasks, current active task number [%s] and desired task number is [%s] for dataSource [%s].\", currentActiveTaskCount, desiredActiveTaskCount, dataSource);\n+      gracefulShutdownInternal();\n+      changeTaskCountInIOConfig(desiredActiveTaskCount);\n+      // clear everything\n+      clearAllocationInfos();\n+      log.info(\"Changed taskCount to [%s] for dataSource [%s].\", desiredActiveTaskCount, dataSource);\n+      return true;\n+    }\n+  }\n+\n+  private void changeTaskCountInIOConfig(int desiredActiveTaskCount)\n+  {\n+    ioConfig.setTaskCount(desiredActiveTaskCount);\n+    try {\n+      Optional<SupervisorManager> supervisorManager = taskMaster.getSupervisorManager();\n+      if (supervisorManager.isPresent()) {\n+        MetadataSupervisorManager metadataSupervisorManager = supervisorManager.get().getMetadataSupervisorManager();\n+        metadataSupervisorManager.insert(dataSource, spec);\n+      } else {\n+        log.warn(\"supervisorManager is null in taskMaster, skip to do scale action for dataSource [%s].\", dataSource);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "feb3e1e88f68aed4f3ce8a3459d14caf85b663d6"}, "originalPosition": 136}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTk1Mjk2NzM4", "url": "https://github.com/apache/druid/pull/10524#pullrequestreview-595296738", "createdAt": "2021-02-22T12:27:03Z", "commit": {"oid": "feb3e1e88f68aed4f3ce8a3459d14caf85b663d6"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yMlQxMjoyNzowM1rOIpVQvw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yMlQxMjoyNzowM1rOIpVQvw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDIxMDg3OQ==", "bodyText": "Not sure what you mean by fill in 'lags'\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n               * This method compute maxLag, totalLag and avgLag then fill in 'lags'\n          \n          \n            \n               * This method computes maxLag, totalLag and avgLag", "url": "https://github.com/apache/druid/pull/10524#discussion_r580210879", "createdAt": "2021-02-22T12:27:03Z", "author": {"login": "pjain1"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -3543,6 +3682,24 @@ protected void emitLag()\n     }\n   }\n \n+\n+  /**\n+   * This method compute maxLag, totalLag and avgLag then fill in 'lags'", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "feb3e1e88f68aed4f3ce8a3459d14caf85b663d6"}, "originalPosition": 311}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTk1MzIzNjUx", "url": "https://github.com/apache/druid/pull/10524#pullrequestreview-595323651", "createdAt": "2021-02-22T13:01:05Z", "commit": {"oid": "feb3e1e88f68aed4f3ce8a3459d14caf85b663d6"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yMlQxMzowMTowNVrOIpWheA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yMlQxMzowMTowNVrOIpWheA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MDIzMTU0NA==", "bodyText": "if by mistake one submits autoScalerConfig for kinesis supervisor then seems like DefaultAutoScaler  is created for kinesis also ?", "url": "https://github.com/apache/druid/pull/10524#discussion_r580231544", "createdAt": "2021-02-22T13:01:05Z", "author": {"login": "pjain1"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisorSpec.java", "diffHunk": "@@ -151,6 +157,37 @@ public DruidMonitorSchedulerConfig getMonitorSchedulerConfig()\n   @Override\n   public abstract Supervisor createSupervisor();\n \n+  /**\n+   * need to notice that autoScaler would be null which means autoscale is dissable.\n+   * @param supervisor\n+   * @return autoScaler, disable autoscale will return dummyAutoScaler and enable autoscale wiil return defaultAutoScaler by default.\n+   */\n+  @Override\n+  @SuppressFBWarnings(value = \"RV_RETURN_VALUE_IGNORED\", justification = \"using siwtch(String)\")\n+  public SupervisorTaskAutoscaler createAutoscaler(Supervisor supervisor)\n+  {\n+    String dataSource = getId();\n+    SupervisorTaskAutoscaler autoScaler = new DummyAutoScaler(supervisor, dataSource);\n+    AutoScalerConfig autoScalerConfig = ingestionSchema.getIOConfig().getAutoscalerConfig();\n+\n+    // kinesis'autoscalerConfig is always null for now, So that kinesis will hold a DummyAutoScaler.\n+    // only SeekableStreamSupervisor is supported here.\n+    if (autoScalerConfig != null", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "feb3e1e88f68aed4f3ce8a3459d14caf85b663d6"}, "originalPosition": 40}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b6632d6c713f2bf87905de0ebb83756d3716edeb", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/b6632d6c713f2bf87905de0ebb83756d3716edeb", "committedDate": "2021-02-23T06:07:26Z", "message": "code reviewed"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "688b9c4b4ff1841477d8139a7c83e54d36ccb986", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/688b9c4b4ff1841477d8139a7c83e54d36ccb986", "committedDate": "2021-02-23T06:09:05Z", "message": "Merge branch 'master' into kafka-dynamic-scale-ingest-tasks"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTk3NDE4MTQ4", "url": "https://github.com/apache/druid/pull/10524#pullrequestreview-597418148", "createdAt": "2021-02-24T12:21:35Z", "commit": {"oid": "688b9c4b4ff1841477d8139a7c83e54d36ccb986"}, "state": "COMMENTED", "comments": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yNFQxMjoyMTozNVrOIq9LiQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yNFQxMjozMjowN1rOIq9lPQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTkxMzQ4MQ==", "bodyText": "The way autoScaler instance is created here does not support custom autoScaler implementation in extensions as switch statement is used to create the instance. If a new strategy is implemented for autoScaler in an extension, this class needs to be changed to support it which is not ideal as its a change in core Druid. I have raised a PR on your branch on how we can fix this - zhangyue19921010#1\nThe changes are -\n\nAdd SupervisorTaskAutoScaler createAutoScaler(Supervisor supervisor, SupervisorSpec spec); method in AutoScalerConfig that will be called from SeekableStreamSupervisorSpec to create autoScaler.\nI don't think getAutoScalerStrategy method is needed in AutoScalerConfig as implementation of AutoScalerConfig can return instance of AutoScaler directly on call to createAutoScaler.", "url": "https://github.com/apache/druid/pull/10524#discussion_r581913481", "createdAt": "2021-02-24T12:21:35Z", "author": {"login": "pjain1"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisorSpec.java", "diffHunk": "@@ -151,6 +157,37 @@ public DruidMonitorSchedulerConfig getMonitorSchedulerConfig()\n   @Override\n   public abstract Supervisor createSupervisor();\n \n+  /**\n+   * need to notice that autoScaler would be null which means autoscale is dissable.\n+   * @param supervisor\n+   * @return autoScaler, disable autoscale will return dummyAutoScaler and enable autoscale wiil return defaultAutoScaler by default.\n+   */\n+  @Override\n+  @SuppressFBWarnings(value = \"RV_RETURN_VALUE_IGNORED\", justification = \"using siwtch(String)\")\n+  public SupervisorTaskAutoscaler createAutoscaler(Supervisor supervisor)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "688b9c4b4ff1841477d8139a7c83e54d36ccb986"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTkxMzkxMg==", "bodyText": "This is not required as mentioned above and add another method to create auto scaler as mentioned in above comment.", "url": "https://github.com/apache/druid/pull/10524#discussion_r581913912", "createdAt": "2021-02-24T12:22:15Z", "author": {"login": "pjain1"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/autoscaler/AutoScalerConfig.java", "diffHunk": "@@ -0,0 +1,40 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.seekablestream.supervisor.autoscaler;\n+\n+import com.fasterxml.jackson.annotation.JsonSubTypes;\n+import com.fasterxml.jackson.annotation.JsonSubTypes.Type;\n+import com.fasterxml.jackson.annotation.JsonTypeInfo;\n+import org.apache.druid.guice.annotations.UnstableApi;\n+\n+@UnstableApi\n+@JsonTypeInfo(use = JsonTypeInfo.Id.NAME, property = \"autoScalerStrategy\", defaultImpl = DefaultAutoScalerConfig.class)\n+@JsonSubTypes(value = {\n+        @Type(name = \"default\", value = DefaultAutoScalerConfig.class)\n+})\n+public interface AutoScalerConfig\n+{\n+  boolean getEnableTaskAutoscaler();\n+  long getMinTriggerDynamicFrequencyMillis();\n+  String getAutoScalerStrategy();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "688b9c4b4ff1841477d8139a7c83e54d36ccb986"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTkxNDc2Nw==", "bodyText": "I think we should change the name of this to LagBasedAutoScalerConfig as it is using lag to make decisions about auto scaling. Also we should not use default as type names as it is confusing. See zhangyue19921010#1", "url": "https://github.com/apache/druid/pull/10524#discussion_r581914767", "createdAt": "2021-02-24T12:23:42Z", "author": {"login": "pjain1"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/autoscaler/AutoScalerConfig.java", "diffHunk": "@@ -0,0 +1,40 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.seekablestream.supervisor.autoscaler;\n+\n+import com.fasterxml.jackson.annotation.JsonSubTypes;\n+import com.fasterxml.jackson.annotation.JsonSubTypes.Type;\n+import com.fasterxml.jackson.annotation.JsonTypeInfo;\n+import org.apache.druid.guice.annotations.UnstableApi;\n+\n+@UnstableApi\n+@JsonTypeInfo(use = JsonTypeInfo.Id.NAME, property = \"autoScalerStrategy\", defaultImpl = DefaultAutoScalerConfig.class)\n+@JsonSubTypes(value = {\n+        @Type(name = \"default\", value = DefaultAutoScalerConfig.class)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "688b9c4b4ff1841477d8139a7c83e54d36ccb986"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTkxNTkwNA==", "bodyText": "See https://github.com/zhangyue19921010/druid/pull/1/files#diff-f1b33808bb841d1e71e1f5ec3fbaeb3f94899066277b75e192942b66371667ce for suggestions on log lines, method and variable names.", "url": "https://github.com/apache/druid/pull/10524#discussion_r581915904", "createdAt": "2021-02-24T12:25:31Z", "author": {"login": "pjain1"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/autoscaler/DefaultAutoScaler.java", "diffHunk": "@@ -0,0 +1,244 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.seekablestream.supervisor.autoscaler;\n+\n+import org.apache.commons.collections4.queue.CircularFifoQueue;\n+import org.apache.druid.indexing.overlord.supervisor.Supervisor;\n+import org.apache.druid.indexing.overlord.supervisor.SupervisorSpec;\n+import org.apache.druid.indexing.overlord.supervisor.autoscaler.LagStats;\n+import org.apache.druid.indexing.overlord.supervisor.autoscaler.SupervisorTaskAutoscaler;\n+import org.apache.druid.indexing.seekablestream.supervisor.SeekableStreamSupervisor;\n+import org.apache.druid.java.util.common.StringUtils;\n+import org.apache.druid.java.util.common.concurrent.Execs;\n+import org.apache.druid.java.util.emitter.EmittingLogger;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.ReentrantLock;\n+\n+public class DefaultAutoScaler implements SupervisorTaskAutoscaler", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "688b9c4b4ff1841477d8139a7c83e54d36ccb986"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTkxNjQ3OA==", "bodyText": "not sure why we are encoding supervisorId, its already a constant string from line 56. Not sure why this is needed.", "url": "https://github.com/apache/druid/pull/10524#discussion_r581916478", "createdAt": "2021-02-24T12:26:31Z", "author": {"login": "pjain1"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/autoscaler/DefaultAutoScaler.java", "diffHunk": "@@ -0,0 +1,244 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.seekablestream.supervisor.autoscaler;\n+\n+import org.apache.commons.collections4.queue.CircularFifoQueue;\n+import org.apache.druid.indexing.overlord.supervisor.Supervisor;\n+import org.apache.druid.indexing.overlord.supervisor.SupervisorSpec;\n+import org.apache.druid.indexing.overlord.supervisor.autoscaler.LagStats;\n+import org.apache.druid.indexing.overlord.supervisor.autoscaler.SupervisorTaskAutoscaler;\n+import org.apache.druid.indexing.seekablestream.supervisor.SeekableStreamSupervisor;\n+import org.apache.druid.java.util.common.StringUtils;\n+import org.apache.druid.java.util.common.concurrent.Execs;\n+import org.apache.druid.java.util.emitter.EmittingLogger;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.ReentrantLock;\n+\n+public class DefaultAutoScaler implements SupervisorTaskAutoscaler\n+{\n+  private static final EmittingLogger log = new EmittingLogger(DefaultAutoScaler.class);\n+  private final String dataSource;\n+  private final CircularFifoQueue<Long> lagMetricsQueue;\n+  private final ScheduledExecutorService lagComputationExec;\n+  private final ScheduledExecutorService allocationExec;\n+  private final SupervisorSpec spec;\n+  private final SeekableStreamSupervisor supervisor;\n+  private final DefaultAutoScalerConfig defaultAutoScalerConfig;\n+\n+  private static ReentrantLock lock = new ReentrantLock(true);\n+\n+\n+  public DefaultAutoScaler(Supervisor supervisor, String dataSource, AutoScalerConfig autoScalerConfig, SupervisorSpec spec)\n+  {\n+    this.defaultAutoScalerConfig = (DefaultAutoScalerConfig) autoScalerConfig;\n+    String supervisorId = StringUtils.format(\"KafkaSupervisor-%s\", dataSource);\n+    this.dataSource = dataSource;\n+    int slots = (int) (defaultAutoScalerConfig.getMetricsCollectionRangeMillis() / defaultAutoScalerConfig.getMetricsCollectionIntervalMillis()) + 1;\n+    log.debug(\" The interval of metrics collection is [%s], [%s] timeRange will collect [%s] data points for dataSource [%s].\", defaultAutoScalerConfig.getMetricsCollectionIntervalMillis(), defaultAutoScalerConfig.getMetricsCollectionRangeMillis(), slots, dataSource);\n+    this.lagMetricsQueue = new CircularFifoQueue<>(slots);\n+    this.allocationExec = Execs.scheduledSingleThreaded(StringUtils.encodeForFormat(supervisorId) + \"-Allocation-%d\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "688b9c4b4ff1841477d8139a7c83e54d36ccb986"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTkxNzYzOA==", "bodyText": "See https://github.com/zhangyue19921010/druid/pull/1/files#diff-943c4b0695e902cb2a3465b69f593a584dac7308037288db0f9fd97054efb12b for suggestions on log lines, method and variable names.", "url": "https://github.com/apache/druid/pull/10524#discussion_r581917638", "createdAt": "2021-02-24T12:28:14Z", "author": {"login": "pjain1"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/autoscaler/DefaultAutoScalerConfig.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.seekablestream.supervisor.autoscaler;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+\n+import javax.annotation.Nullable;\n+\n+public class DefaultAutoScalerConfig implements AutoScalerConfig", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "688b9c4b4ff1841477d8139a7c83e54d36ccb986"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTkxODAzOQ==", "bodyText": "I think we can call this NoopAutoScaler.", "url": "https://github.com/apache/druid/pull/10524#discussion_r581918039", "createdAt": "2021-02-24T12:28:53Z", "author": {"login": "pjain1"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/autoscaler/DummyAutoScaler.java", "diffHunk": "@@ -0,0 +1,48 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.seekablestream.supervisor.autoscaler;\n+\n+import org.apache.druid.indexing.overlord.supervisor.Supervisor;\n+import org.apache.druid.indexing.overlord.supervisor.autoscaler.SupervisorTaskAutoscaler;\n+\n+public class DummyAutoScaler implements SupervisorTaskAutoscaler", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "688b9c4b4ff1841477d8139a7c83e54d36ccb986"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTkxODE4MQ==", "bodyText": "This can be no-arg constructor.", "url": "https://github.com/apache/druid/pull/10524#discussion_r581918181", "createdAt": "2021-02-24T12:29:03Z", "author": {"login": "pjain1"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/autoscaler/DummyAutoScaler.java", "diffHunk": "@@ -0,0 +1,48 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.seekablestream.supervisor.autoscaler;\n+\n+import org.apache.druid.indexing.overlord.supervisor.Supervisor;\n+import org.apache.druid.indexing.overlord.supervisor.autoscaler.SupervisorTaskAutoscaler;\n+\n+public class DummyAutoScaler implements SupervisorTaskAutoscaler\n+{\n+  public DummyAutoScaler(Supervisor supervisor, String dataSource)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "688b9c4b4ff1841477d8139a7c83e54d36ccb986"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTkxODQzNw==", "bodyText": "https://github.com/zhangyue19921010/druid/pull/1/files#diff-0621db18fa2257d0cd499178c842d96ae73df2264038ccc7de23d7a7ed5235a5", "url": "https://github.com/apache/druid/pull/10524#discussion_r581918437", "createdAt": "2021-02-24T12:29:26Z", "author": {"login": "pjain1"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/autoscaler/DummyAutoScaler.java", "diffHunk": "@@ -0,0 +1,48 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.seekablestream.supervisor.autoscaler;\n+\n+import org.apache.druid.indexing.overlord.supervisor.Supervisor;\n+import org.apache.druid.indexing.overlord.supervisor.autoscaler.SupervisorTaskAutoscaler;\n+\n+public class DummyAutoScaler implements SupervisorTaskAutoscaler", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTkxODAzOQ=="}, "originalCommit": {"oid": "688b9c4b4ff1841477d8139a7c83e54d36ccb986"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTkxOTUyNA==", "bodyText": "Variable names will need to be changed here, if these suggestions are implemented -https://github.com/zhangyue19921010/druid/pull/1/files#diff-943c4b0695e902cb2a3465b69f593a584dac7308037288db0f9fd97054efb12b", "url": "https://github.com/apache/druid/pull/10524#discussion_r581919524", "createdAt": "2021-02-24T12:31:10Z", "author": {"login": "pjain1"}, "path": "integration-tests/src/test/resources/stream/data/supervisor_with_autoscaler_spec_template.json", "diffHunk": "@@ -0,0 +1,73 @@\n+{\n+  \"type\": \"%%STREAM_TYPE%%\",\n+  \"dataSchema\": {\n+    \"dataSource\": \"%%DATASOURCE%%\",\n+    \"parser\": %%PARSER%%,\n+    \"timestampSpec\": {\n+      \"column\": \"timestamp\",\n+      \"format\": \"auto\"\n+    },\n+    \"dimensionsSpec\": {\n+      \"dimensions\": [\"page\", \"language\", \"user\", \"unpatrolled\", \"newPage\", \"robot\", \"anonymous\", \"namespace\", \"continent\", \"country\", \"region\", \"city\"],\n+      \"dimensionExclusions\": [],\n+      \"spatialDimensions\": []\n+    },\n+    \"metricsSpec\": [\n+      {\n+        \"type\": \"count\",\n+        \"name\": \"count\"\n+      },\n+      {\n+        \"type\": \"doubleSum\",\n+        \"name\": \"added\",\n+        \"fieldName\": \"added\"\n+      },\n+      {\n+        \"type\": \"doubleSum\",\n+        \"name\": \"deleted\",\n+        \"fieldName\": \"deleted\"\n+      },\n+      {\n+        \"type\": \"doubleSum\",\n+        \"name\": \"delta\",\n+        \"fieldName\": \"delta\"\n+      }\n+    ],\n+    \"granularitySpec\": {\n+      \"type\": \"uniform\",\n+      \"segmentGranularity\": \"MINUTE\",\n+      \"queryGranularity\": \"NONE\"\n+    }\n+  },\n+  \"tuningConfig\": {\n+    \"type\": \"%%STREAM_TYPE%%\",\n+    \"intermediatePersistPeriod\": \"PT30S\",\n+    \"maxRowsPerSegment\": 5000000,\n+    \"maxRowsInMemory\": 500000\n+  },\n+  \"ioConfig\": {\n+    \"%%TOPIC_KEY%%\": \"%%TOPIC_VALUE%%\",\n+    \"%%STREAM_PROPERTIES_KEY%%\": %%STREAM_PROPERTIES_VALUE%%,\n+    \"autoscalerConfig\": {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "688b9c4b4ff1841477d8139a7c83e54d36ccb986"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTkyMDA2MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              /**\n          \n          \n            \n               * Collect maxLag, totalLag, avgLag\n          \n          \n            \n               * Only support Kafka ingestion so far.\n          \n          \n            \n               */\n          \n          \n            \n              /**\n          \n          \n            \n               * Computes maxLag, totalLag and avgLag\n          \n          \n            \n               * Only supports Kafka ingestion so far.\n          \n          \n            \n               */", "url": "https://github.com/apache/druid/pull/10524#discussion_r581920061", "createdAt": "2021-02-24T12:32:07Z", "author": {"login": "pjain1"}, "path": "server/src/main/java/org/apache/druid/indexing/overlord/supervisor/Supervisor.java", "diffHunk": "@@ -64,4 +65,12 @@ default Boolean isHealthy()\n    * @param checkpointMetadata metadata for the sequence to currently checkpoint\n    */\n   void checkpoint(int taskGroupId, DataSourceMetadata checkpointMetadata);\n+\n+  /**\n+   * Collect maxLag, totalLag, avgLag\n+   * Only support Kafka ingestion so far.\n+   */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "688b9c4b4ff1841477d8139a7c83e54d36ccb986"}, "originalPosition": 16}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTk3NDM1OTY1", "url": "https://github.com/apache/druid/pull/10524#pullrequestreview-597435965", "createdAt": "2021-02-24T12:43:34Z", "commit": {"oid": "688b9c4b4ff1841477d8139a7c83e54d36ccb986"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yNFQxMjo0MzozNFrOIq-BKg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yNFQxMjo0MzozNFrOIq-BKg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MTkyNzIxMA==", "bodyText": "We can just pass autoscalerConfig here and it will be null because if its not null then exception will be thrown at line 96.", "url": "https://github.com/apache/druid/pull/10524#discussion_r581927210", "createdAt": "2021-02-24T12:43:34Z", "author": {"login": "pjain1"}, "path": "extensions-core/kinesis-indexing-service/src/main/java/org/apache/druid/indexing/kinesis/supervisor/KinesisSupervisorIOConfig.java", "diffHunk": "@@ -85,8 +87,16 @@ public KinesisSupervisorIOConfig(\n         completionTimeout,\n         lateMessageRejectionPeriod,\n         earlyMessageRejectionPeriod,\n+        null,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "688b9c4b4ff1841477d8139a7c83e54d36ccb986"}, "originalPosition": 20}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "00758e647c7137166b3e149607305a54db284dfb", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/00758e647c7137166b3e149607305a54db284dfb", "committedDate": "2021-02-25T09:10:26Z", "message": "code review"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTk4MzUxMTcy", "url": "https://github.com/apache/druid/pull/10524#pullrequestreview-598351172", "createdAt": "2021-02-25T09:21:19Z", "commit": {"oid": "00758e647c7137166b3e149607305a54db284dfb"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yNVQwOToyMToxOVrOIrrWJg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yNVQwOToyMToxOVrOIrrWJg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MjY2OTg2Mg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  log.error(\"supervisorManager is null in taskMaster, skipping scale action for dataSource [%s].\", dataSource);\n          \n          \n            \n                  log.error(e, \"Failed to sync taskCount to MetaStorage for dataSource [%s].\", dataSource);\n          \n      \n    \n    \n  \n\nprobably you copied the above one by mistake", "url": "https://github.com/apache/druid/pull/10524#discussion_r582669862", "createdAt": "2021-02-25T09:21:19Z", "author": {"login": "pjain1"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -318,6 +323,127 @@ public void handle()\n     }\n   }\n \n+  // change taskCount without resubmitting.\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    Callable<Integer> scaleAction;\n+\n+    DynamicAllocationTasksNotice(Callable<Integer> scaleAction)\n+    {\n+      this.scaleAction = scaleAction;\n+    }\n+\n+    /**\n+     * This method will do lag points collection and check dynamic scale action is necessary or not.\n+     */\n+    @Override\n+    public void handle()\n+    {\n+      if (autoScalerConfig == null) {\n+        log.warn(\"autoScalerConfig is null but dynamic allocation notice is submitted, how can it be ?\");\n+      } else {\n+        try {\n+          long nowTime = System.currentTimeMillis();\n+          if (spec.isSuspended()) {\n+            log.info(\"Skipping DynamicAllocationTasksNotice execution because [%s] supervisor is suspended\",\n+                    dataSource\n+            );\n+            return;\n+          }\n+          log.debug(\"PendingCompletionTaskGroups is [%s] for dataSource [%s]\", pendingCompletionTaskGroups,\n+                  dataSource\n+          );\n+          for (CopyOnWriteArrayList<TaskGroup> list : pendingCompletionTaskGroups.values()) {\n+            if (!list.isEmpty()) {\n+              log.info(\n+                      \"Skipping DynamicAllocationTasksNotice execution for datasource [%s] because following tasks are pending [%s]\",\n+                      dataSource, pendingCompletionTaskGroups\n+              );\n+              return;\n+            }\n+          }\n+          if (nowTime - dynamicTriggerLastRunTime < autoScalerConfig.getMinTriggerScaleActionFrequencyMillis()) {\n+            log.info(\n+                    \"DynamicAllocationTasksNotice submitted again in [%d] millis, minTriggerDynamicFrequency is [%s] for dataSource [%s], skipping it!\",\n+                    nowTime - dynamicTriggerLastRunTime, autoScalerConfig.getMinTriggerScaleActionFrequencyMillis(), dataSource\n+            );\n+            return;\n+          }\n+          final Integer desriedTaskCount = scaleAction.call();\n+          boolean allocationSuccess = changeTaskCount(desriedTaskCount);\n+          if (allocationSuccess) {\n+            dynamicTriggerLastRunTime = nowTime;\n+          }\n+        }\n+        catch (Exception ex) {\n+          log.warn(ex, \"Error parsing DynamicAllocationTasksNotice\");\n+        }\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method determines how to do scale actions based on collected lag points.\n+   * If scale action is triggered :\n+   *    First of all, call gracefulShutdownInternal() which will change the state of current datasource ingest tasks from reading to publishing.\n+   *    Secondly, clear all the stateful data structures: activelyReadingTaskGroups, partitionGroups, partitionOffsets, pendingCompletionTaskGroups, partitionIds. These structures will be rebuiled in the next 'RunNotice'.\n+   *    Finally, change the taskCount in SeekableStreamSupervisorIOConfig and sync it to MetadataStorage.\n+   * After the taskCount is changed in SeekableStreamSupervisorIOConfig, next RunNotice will create scaled number of ingest tasks without resubmitting the supervisor.\n+   * @param desiredActiveTaskCount desired taskCount computed from AutoScaler\n+   * @return Boolean flag indicating if scale action was executed or not. If true, it will wait at least 'minTriggerScaleActionFrequencyMillis' before next 'changeTaskCount'.\n+   *         If false, it will do 'changeTaskCount' again after 'scaleActionPeriodMillis' millis.\n+   * @throws InterruptedException\n+   * @throws ExecutionException\n+   * @throws TimeoutException\n+   */\n+  private boolean changeTaskCount(Integer desiredActiveTaskCount) throws InterruptedException, ExecutionException, TimeoutException\n+  {\n+    int currentActiveTaskCount;\n+    Collection<TaskGroup> activeTaskGroups = activelyReadingTaskGroups.values();\n+    currentActiveTaskCount = activeTaskGroups.size();\n+\n+    if (desiredActiveTaskCount == -1 || desiredActiveTaskCount == currentActiveTaskCount) {\n+      return false;\n+    } else {\n+      log.info(\n+              \"Starting scale action, current active task count is [%d] and desired task count is [%d] for dataSource [%s].\",\n+              currentActiveTaskCount, desiredActiveTaskCount, dataSource\n+      );\n+      gracefulShutdownInternal();\n+      changeTaskCountInIOConfig(desiredActiveTaskCount);\n+      clearAllocationInfo();\n+      log.info(\"Changed taskCount to [%s] for dataSource [%s].\", desiredActiveTaskCount, dataSource);\n+      return true;\n+    }\n+  }\n+\n+  private void changeTaskCountInIOConfig(int desiredActiveTaskCount)\n+  {\n+    ioConfig.setTaskCount(desiredActiveTaskCount);\n+    try {\n+      Optional<SupervisorManager> supervisorManager = taskMaster.getSupervisorManager();\n+      if (supervisorManager.isPresent()) {\n+        MetadataSupervisorManager metadataSupervisorManager = supervisorManager.get().getMetadataSupervisorManager();\n+        metadataSupervisorManager.insert(dataSource, spec);\n+      } else {\n+        log.error(\"supervisorManager is null in taskMaster, skipping scale action for dataSource [%s].\", dataSource);\n+      }\n+    }\n+    catch (Exception e) {\n+      log.error(\"supervisorManager is null in taskMaster, skipping scale action for dataSource [%s].\", dataSource);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "00758e647c7137166b3e149607305a54db284dfb"}, "originalPosition": 146}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTk4MzU4NDcw", "url": "https://github.com/apache/druid/pull/10524#pullrequestreview-598358470", "createdAt": "2021-02-25T09:29:05Z", "commit": {"oid": "00758e647c7137166b3e149607305a54db284dfb"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yNVQwOToyOTowNVrOIrrslw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0yNVQwOToyOTowNVrOIrrslw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4MjY3NTYwNw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              /**\n          \n          \n            \n               * need to notice that autoScaler would be null which means autoscale is dissable.\n          \n          \n            \n               * @param supervisor\n          \n          \n            \n               * @return autoScaler, disable autoscale will return dummyAutoScaler and enable autoscale wiil return defaultAutoScaler by default.\n          \n          \n            \n               */\n          \n          \n            \n              /**\n          \n          \n            \n               * An autoScaler instance will be returned depending on the autoScalerConfig. In case autoScalerConfig is null or autoScaler is disabled then NoopTaskAutoScaler will be returned.\n          \n          \n            \n               * @param supervisor\n          \n          \n            \n               * @return autoScaler\n          \n          \n            \n               */", "url": "https://github.com/apache/druid/pull/10524#discussion_r582675607", "createdAt": "2021-02-25T09:29:05Z", "author": {"login": "pjain1"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisorSpec.java", "diffHunk": "@@ -151,6 +154,21 @@ public DruidMonitorSchedulerConfig getMonitorSchedulerConfig()\n   @Override\n   public abstract Supervisor createSupervisor();\n \n+  /**\n+   * need to notice that autoScaler would be null which means autoscale is dissable.\n+   * @param supervisor\n+   * @return autoScaler, disable autoscale will return dummyAutoScaler and enable autoscale wiil return defaultAutoScaler by default.\n+   */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "00758e647c7137166b3e149607305a54db284dfb"}, "originalPosition": 19}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1f1008266a0040a74f9bd8c0deffddf923d67d9e", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/1f1008266a0040a74f9bd8c0deffddf923d67d9e", "committedDate": "2021-02-25T11:21:37Z", "message": "log changed"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6334e2ba0ddf48ddfd884fcdfe9361cee1431e6b", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/6334e2ba0ddf48ddfd884fcdfe9361cee1431e6b", "committedDate": "2021-02-25T13:13:20Z", "message": "do StringUtils.encodeForFormat when create allocationExec"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTk4Njc0NjA1", "url": "https://github.com/apache/druid/pull/10524#pullrequestreview-598674605", "createdAt": "2021-02-25T15:13:39Z", "commit": {"oid": "6334e2ba0ddf48ddfd884fcdfe9361cee1431e6b"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjAxMzAwNDYy", "url": "https://github.com/apache/druid/pull/10524#pullrequestreview-601300462", "createdAt": "2021-03-02T00:31:39Z", "commit": {"oid": "6334e2ba0ddf48ddfd884fcdfe9361cee1431e6b"}, "state": "COMMENTED", "comments": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0wMlQwMDozMTo0MFrOIuDHgw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0wMlQwMToxMTo0MVrOIuEF7g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTE1NjQ4Mw==", "bodyText": "Can we make the distinction that, following properties are common to any autoscaler and rest are specific to lagBased autoscaler , maybe have two tables.\nautoScalerStrategy\nenableTaskAutoScaler\ntaskCountMin\ntaskCountMax\nminTriggerScaleActionFrequencyMillis", "url": "https://github.com/apache/druid/pull/10524#discussion_r585156483", "createdAt": "2021-03-02T00:31:40Z", "author": {"login": "himanshug"}, "path": "docs/development/extensions-core/kafka-ingestion.md", "diffHunk": "@@ -146,6 +146,26 @@ A sample supervisor spec is shown below:\n |`lateMessageRejectionStartDateTime`|ISO8601 DateTime|Configure tasks to reject messages with timestamps earlier than this date time; for example if this is set to `2016-01-01T11:00Z` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps earlier than *2016-01-01T11:00Z* will be dropped. This may help prevent concurrency issues if your data stream has late messages and you have multiple pipelines that need to operate on the same segments (e.g. a realtime and a nightly batch ingestion pipeline).|no (default == none)|\n |`lateMessageRejectionPeriod`|ISO8601 Period|Configure tasks to reject messages with timestamps earlier than this period before the task was created; for example if this is set to `PT1H` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps earlier than *2016-01-01T11:00Z* will be dropped. This may help prevent concurrency issues if your data stream has late messages and you have multiple pipelines that need to operate on the same segments (e.g. a realtime and a nightly batch ingestion pipeline). Please note that only one of `lateMessageRejectionPeriod` or `lateMessageRejectionStartDateTime` can be specified.|no (default == none)|\n |`earlyMessageRejectionPeriod`|ISO8601 Period|Configure tasks to reject messages with timestamps later than this period after the task reached its taskDuration; for example if this is set to `PT1H`, the taskDuration is set to `PT1H` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps later than *2016-01-01T14:00Z* will be dropped. **Note:** Tasks sometimes run past their task duration, for example, in cases of supervisor failover. Setting earlyMessageRejectionPeriod too low may cause messages to be dropped unexpectedly whenever a task runs past its originally configured task duration.|no (default == none)|\n+|`autoScalerConfig`|Object|`autoScalerConfig` to specify how to auto scale the number of Kafka ingest tasks based on Lag metrics. ONLY supported for Kafka indexing as of now. See [Tasks Autoscaler Properties](#Task Autoscaler Properties) for details.|no (default == null)|\n+\n+### Task Autoscaler Properties\n+| Property | Description | Required |\n+| ------------- | ------------- | ------------- |\n+| `enableTaskAutoScaler` | Whether enable this feature or not. Set false or ignored here will disable `autoScaler` even though `autoScalerConfig` is not null| no (default == false) |\n+| `lagCollectionIntervalMillis` | Define the frequency of lag points collection.  | no (default == 30000) |\n+| `lagCollectionRangeMillis` | The total time window of lag collection, Use with `lagCollectionIntervalMillis`\uff0cit means that in the recent `lagCollectionRangeMillis`, collect lag metric points every `lagCollectionIntervalMillis`. | no (default == 600000) |\n+| `scaleOutThreshold` | The Threshold of scale out action | no (default == 6000000) |\n+| `triggerScaleOutThresholdFrequency` | If `triggerScaleOutThresholdFrequency` percent of lag points are higher than `scaleOutThreshold`, then do scale out action. | no (default == 0.3) |\n+| `scaleInThreshold` | The Threshold of scale in action | no (default == 1000000) |\n+| `triggerScaleInThresholdFrequency` | If `triggerScaleInThresholdFrequency` percent of lag points are lower than `scaleOutThreshold`, then do scale in action. | no (default == 0.9) |\n+| `scaleActionStartDelayMillis` | Number of milliseconds after supervisor starts when first check scale logic. | no (default == 300000) |\n+| `scaleActionPeriodMillis` | The frequency of checking whether to do scale action in millis | no (default == 60000) |\n+| `taskCountMax` | Maximum value of task count. Make Sure `taskCountMax >= taskCountMin` | yes |\n+| `taskCountMin` | Minimum value of task count. When enable autoscaler, the value of taskCount in `IOConfig` will be ignored, and `taskCountMin` will be the number of tasks that ingestion starts going up to `taskCountMax`| yes |\n+| `scaleInStep` | How many tasks to reduce at a time | no (default == 1) |\n+| `scaleOutStep` | How many tasks to add at a time | no (default == 2) |\n+| `minTriggerScaleActionFrequencyMillis` | Minimum time interval between two scale actions | no (default == 600000) |\n+| `autoScalerStrategy` | The algorithm of `autoScaler`. ONLY `lagBased` is supported for now. | no (default == `lagBased`) |", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6334e2ba0ddf48ddfd884fcdfe9361cee1431e6b"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTE1NzAwMg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            | `lagCollectionIntervalMillis` | Define the frequency of lag points collection.  | no (default == 30000) |\n          \n          \n            \n            | `lagCollectionIntervalMillis` | Period of lag points collection.  | no (default == 30000) |", "url": "https://github.com/apache/druid/pull/10524#discussion_r585157002", "createdAt": "2021-03-02T00:33:09Z", "author": {"login": "himanshug"}, "path": "docs/development/extensions-core/kafka-ingestion.md", "diffHunk": "@@ -146,6 +146,26 @@ A sample supervisor spec is shown below:\n |`lateMessageRejectionStartDateTime`|ISO8601 DateTime|Configure tasks to reject messages with timestamps earlier than this date time; for example if this is set to `2016-01-01T11:00Z` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps earlier than *2016-01-01T11:00Z* will be dropped. This may help prevent concurrency issues if your data stream has late messages and you have multiple pipelines that need to operate on the same segments (e.g. a realtime and a nightly batch ingestion pipeline).|no (default == none)|\n |`lateMessageRejectionPeriod`|ISO8601 Period|Configure tasks to reject messages with timestamps earlier than this period before the task was created; for example if this is set to `PT1H` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps earlier than *2016-01-01T11:00Z* will be dropped. This may help prevent concurrency issues if your data stream has late messages and you have multiple pipelines that need to operate on the same segments (e.g. a realtime and a nightly batch ingestion pipeline). Please note that only one of `lateMessageRejectionPeriod` or `lateMessageRejectionStartDateTime` can be specified.|no (default == none)|\n |`earlyMessageRejectionPeriod`|ISO8601 Period|Configure tasks to reject messages with timestamps later than this period after the task reached its taskDuration; for example if this is set to `PT1H`, the taskDuration is set to `PT1H` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps later than *2016-01-01T14:00Z* will be dropped. **Note:** Tasks sometimes run past their task duration, for example, in cases of supervisor failover. Setting earlyMessageRejectionPeriod too low may cause messages to be dropped unexpectedly whenever a task runs past its originally configured task duration.|no (default == none)|\n+|`autoScalerConfig`|Object|`autoScalerConfig` to specify how to auto scale the number of Kafka ingest tasks based on Lag metrics. ONLY supported for Kafka indexing as of now. See [Tasks Autoscaler Properties](#Task Autoscaler Properties) for details.|no (default == null)|\n+\n+### Task Autoscaler Properties\n+| Property | Description | Required |\n+| ------------- | ------------- | ------------- |\n+| `enableTaskAutoScaler` | Whether enable this feature or not. Set false or ignored here will disable `autoScaler` even though `autoScalerConfig` is not null| no (default == false) |\n+| `lagCollectionIntervalMillis` | Define the frequency of lag points collection.  | no (default == 30000) |", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6334e2ba0ddf48ddfd884fcdfe9361cee1431e6b"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTE2MDcxMQ==", "bodyText": "why shouldn't we expect lagStats.getTotalLag() to return a value >= 0 ?", "url": "https://github.com/apache/druid/pull/10524#discussion_r585160711", "createdAt": "2021-03-02T00:43:00Z", "author": {"login": "himanshug"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/autoscaler/LagBasedAutoScaler.java", "diffHunk": "@@ -0,0 +1,242 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.seekablestream.supervisor.autoscaler;\n+\n+import org.apache.commons.collections4.queue.CircularFifoQueue;\n+import org.apache.druid.indexing.overlord.supervisor.SupervisorSpec;\n+import org.apache.druid.indexing.overlord.supervisor.autoscaler.LagStats;\n+import org.apache.druid.indexing.overlord.supervisor.autoscaler.SupervisorTaskAutoScaler;\n+import org.apache.druid.indexing.seekablestream.supervisor.SeekableStreamSupervisor;\n+import org.apache.druid.java.util.common.StringUtils;\n+import org.apache.druid.java.util.common.concurrent.Execs;\n+import org.apache.druid.java.util.emitter.EmittingLogger;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.ReentrantLock;\n+\n+public class LagBasedAutoScaler implements SupervisorTaskAutoScaler\n+{\n+  private static final EmittingLogger log = new EmittingLogger(LagBasedAutoScaler.class);\n+  private final String dataSource;\n+  private final CircularFifoQueue<Long> lagMetricsQueue;\n+  private final ScheduledExecutorService lagComputationExec;\n+  private final ScheduledExecutorService allocationExec;\n+  private final SupervisorSpec spec;\n+  private final SeekableStreamSupervisor supervisor;\n+  private final LagBasedAutoScalerConfig lagBasedAutoScalerConfig;\n+\n+  private static final ReentrantLock LOCK = new ReentrantLock(true);\n+\n+  public LagBasedAutoScaler(SeekableStreamSupervisor supervisor, String dataSource,\n+      LagBasedAutoScalerConfig autoScalerConfig, SupervisorSpec spec\n+  )\n+  {\n+    this.lagBasedAutoScalerConfig = autoScalerConfig;\n+    final String supervisorId = StringUtils.format(\"Supervisor-%s\", dataSource);\n+    this.dataSource = dataSource;\n+    final int slots = (int) (lagBasedAutoScalerConfig.getLagCollectionRangeMillis() / lagBasedAutoScalerConfig\n+        .getLagCollectionIntervalMillis()) + 1;\n+    this.lagMetricsQueue = new CircularFifoQueue<>(slots);\n+    this.allocationExec = Execs.scheduledSingleThreaded(StringUtils.encodeForFormat(supervisorId) + \"-Allocation-%d\");\n+    this.lagComputationExec = Execs.scheduledSingleThreaded(StringUtils.encodeForFormat(supervisorId) + \"-Computation-%d\");\n+    this.spec = spec;\n+    this.supervisor = supervisor;\n+  }\n+\n+  @Override\n+  public void start()\n+  {\n+    Callable<Integer> scaleAction = () -> {\n+      LOCK.lock();\n+      int desiredTaskCount = -1;\n+      try {\n+        desiredTaskCount = computeDesiredTaskCount(new ArrayList<>(lagMetricsQueue));\n+\n+        if (desiredTaskCount != -1) {\n+          lagMetricsQueue.clear();\n+        }\n+      }\n+      catch (Exception ex) {\n+        log.warn(ex, \"Exception while computing desired task count for [%s]\", dataSource);\n+      }\n+      finally {\n+        LOCK.unlock();\n+      }\n+      return desiredTaskCount;\n+    };\n+\n+    lagComputationExec.scheduleAtFixedRate(\n+        computeAndCollectLag(),\n+        lagBasedAutoScalerConfig.getScaleActionStartDelayMillis(), // wait for tasks to start up\n+        lagBasedAutoScalerConfig.getLagCollectionIntervalMillis(),\n+        TimeUnit.MILLISECONDS\n+    );\n+    allocationExec.scheduleAtFixedRate(\n+        supervisor.buildDynamicAllocationTask(scaleAction),\n+        lagBasedAutoScalerConfig.getScaleActionStartDelayMillis() + lagBasedAutoScalerConfig\n+            .getLagCollectionRangeMillis(),\n+        lagBasedAutoScalerConfig.getScaleActionPeriodMillis(),\n+        TimeUnit.MILLISECONDS\n+    );\n+    log.info(\n+        \"LagBasedAutoScaler will collect lag every [%d] millis and will keep [%d] data points for the last [%d] millis for dataSource [%s]\",\n+        lagBasedAutoScalerConfig.getLagCollectionIntervalMillis(), lagMetricsQueue.size(),\n+        lagBasedAutoScalerConfig.getLagCollectionRangeMillis(), dataSource\n+    );\n+  }\n+\n+  @Override\n+  public void stop()\n+  {\n+    allocationExec.shutdownNow();\n+    lagComputationExec.shutdownNow();\n+  }\n+\n+  @Override\n+  public void reset()\n+  {\n+    // clear queue for kafka lags\n+    if (lagMetricsQueue != null) {\n+      try {\n+        LOCK.lock();\n+        lagMetricsQueue.clear();\n+      }\n+      catch (Exception e) {\n+        log.warn(e, \"Error,when clear queue in rest action\");\n+      }\n+      finally {\n+        LOCK.unlock();\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method computes current consumer lag. Gets the total lag of all partitions and fill in the lagMetricsQueue\n+   *\n+   * @return a Runnbale object to compute and collect lag.\n+   */\n+  private Runnable computeAndCollectLag()\n+  {\n+    return () -> {\n+      LOCK.lock();\n+      try {\n+        if (!spec.isSuspended()) {\n+          LagStats lagStats = supervisor.computeLagStats();\n+          if (lagStats == null) {\n+            lagMetricsQueue.offer(0L);\n+          } else {\n+            long totalLags = lagStats.getTotalLag();\n+            lagMetricsQueue.offer(totalLags > 0 ? totalLags : 0L);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6334e2ba0ddf48ddfd884fcdfe9361cee1431e6b"}, "originalPosition": 150}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTE2MjI3NA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              private Integer computeDesiredTaskCount(List<Long> lags)\n          \n          \n            \n              private int computeDesiredTaskCount(List<Long> lags)", "url": "https://github.com/apache/druid/pull/10524#discussion_r585162274", "createdAt": "2021-03-02T00:47:07Z", "author": {"login": "himanshug"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/autoscaler/LagBasedAutoScaler.java", "diffHunk": "@@ -0,0 +1,242 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.seekablestream.supervisor.autoscaler;\n+\n+import org.apache.commons.collections4.queue.CircularFifoQueue;\n+import org.apache.druid.indexing.overlord.supervisor.SupervisorSpec;\n+import org.apache.druid.indexing.overlord.supervisor.autoscaler.LagStats;\n+import org.apache.druid.indexing.overlord.supervisor.autoscaler.SupervisorTaskAutoScaler;\n+import org.apache.druid.indexing.seekablestream.supervisor.SeekableStreamSupervisor;\n+import org.apache.druid.java.util.common.StringUtils;\n+import org.apache.druid.java.util.common.concurrent.Execs;\n+import org.apache.druid.java.util.emitter.EmittingLogger;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.ReentrantLock;\n+\n+public class LagBasedAutoScaler implements SupervisorTaskAutoScaler\n+{\n+  private static final EmittingLogger log = new EmittingLogger(LagBasedAutoScaler.class);\n+  private final String dataSource;\n+  private final CircularFifoQueue<Long> lagMetricsQueue;\n+  private final ScheduledExecutorService lagComputationExec;\n+  private final ScheduledExecutorService allocationExec;\n+  private final SupervisorSpec spec;\n+  private final SeekableStreamSupervisor supervisor;\n+  private final LagBasedAutoScalerConfig lagBasedAutoScalerConfig;\n+\n+  private static final ReentrantLock LOCK = new ReentrantLock(true);\n+\n+  public LagBasedAutoScaler(SeekableStreamSupervisor supervisor, String dataSource,\n+      LagBasedAutoScalerConfig autoScalerConfig, SupervisorSpec spec\n+  )\n+  {\n+    this.lagBasedAutoScalerConfig = autoScalerConfig;\n+    final String supervisorId = StringUtils.format(\"Supervisor-%s\", dataSource);\n+    this.dataSource = dataSource;\n+    final int slots = (int) (lagBasedAutoScalerConfig.getLagCollectionRangeMillis() / lagBasedAutoScalerConfig\n+        .getLagCollectionIntervalMillis()) + 1;\n+    this.lagMetricsQueue = new CircularFifoQueue<>(slots);\n+    this.allocationExec = Execs.scheduledSingleThreaded(StringUtils.encodeForFormat(supervisorId) + \"-Allocation-%d\");\n+    this.lagComputationExec = Execs.scheduledSingleThreaded(StringUtils.encodeForFormat(supervisorId) + \"-Computation-%d\");\n+    this.spec = spec;\n+    this.supervisor = supervisor;\n+  }\n+\n+  @Override\n+  public void start()\n+  {\n+    Callable<Integer> scaleAction = () -> {\n+      LOCK.lock();\n+      int desiredTaskCount = -1;\n+      try {\n+        desiredTaskCount = computeDesiredTaskCount(new ArrayList<>(lagMetricsQueue));\n+\n+        if (desiredTaskCount != -1) {\n+          lagMetricsQueue.clear();\n+        }\n+      }\n+      catch (Exception ex) {\n+        log.warn(ex, \"Exception while computing desired task count for [%s]\", dataSource);\n+      }\n+      finally {\n+        LOCK.unlock();\n+      }\n+      return desiredTaskCount;\n+    };\n+\n+    lagComputationExec.scheduleAtFixedRate(\n+        computeAndCollectLag(),\n+        lagBasedAutoScalerConfig.getScaleActionStartDelayMillis(), // wait for tasks to start up\n+        lagBasedAutoScalerConfig.getLagCollectionIntervalMillis(),\n+        TimeUnit.MILLISECONDS\n+    );\n+    allocationExec.scheduleAtFixedRate(\n+        supervisor.buildDynamicAllocationTask(scaleAction),\n+        lagBasedAutoScalerConfig.getScaleActionStartDelayMillis() + lagBasedAutoScalerConfig\n+            .getLagCollectionRangeMillis(),\n+        lagBasedAutoScalerConfig.getScaleActionPeriodMillis(),\n+        TimeUnit.MILLISECONDS\n+    );\n+    log.info(\n+        \"LagBasedAutoScaler will collect lag every [%d] millis and will keep [%d] data points for the last [%d] millis for dataSource [%s]\",\n+        lagBasedAutoScalerConfig.getLagCollectionIntervalMillis(), lagMetricsQueue.size(),\n+        lagBasedAutoScalerConfig.getLagCollectionRangeMillis(), dataSource\n+    );\n+  }\n+\n+  @Override\n+  public void stop()\n+  {\n+    allocationExec.shutdownNow();\n+    lagComputationExec.shutdownNow();\n+  }\n+\n+  @Override\n+  public void reset()\n+  {\n+    // clear queue for kafka lags\n+    if (lagMetricsQueue != null) {\n+      try {\n+        LOCK.lock();\n+        lagMetricsQueue.clear();\n+      }\n+      catch (Exception e) {\n+        log.warn(e, \"Error,when clear queue in rest action\");\n+      }\n+      finally {\n+        LOCK.unlock();\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method computes current consumer lag. Gets the total lag of all partitions and fill in the lagMetricsQueue\n+   *\n+   * @return a Runnbale object to compute and collect lag.\n+   */\n+  private Runnable computeAndCollectLag()\n+  {\n+    return () -> {\n+      LOCK.lock();\n+      try {\n+        if (!spec.isSuspended()) {\n+          LagStats lagStats = supervisor.computeLagStats();\n+          if (lagStats == null) {\n+            lagMetricsQueue.offer(0L);\n+          } else {\n+            long totalLags = lagStats.getTotalLag();\n+            lagMetricsQueue.offer(totalLags > 0 ? totalLags : 0L);\n+          }\n+          log.debug(\"Current lags [%s] for dataSource [%s].\", new ArrayList<>(lagMetricsQueue), dataSource);\n+        } else {\n+          log.warn(\"[%s] supervisor is suspended, skipping lag collection\", dataSource);\n+        }\n+      }\n+      catch (Exception e) {\n+        log.error(e, \"Error while collecting lags\");\n+      }\n+      finally {\n+        LOCK.unlock();\n+      }\n+    };\n+  }\n+\n+  /**\n+   * This method determines whether to do scale actions based on collected lag points.\n+   * Current algorithm of scale is simple:\n+   * First of all, compute the proportion of lag points higher/lower than scaleOutThreshold/scaleInThreshold, getting scaleOutThreshold/scaleInThreshold.\n+   * Secondly, compare scaleOutThreshold/scaleInThreshold with triggerScaleOutThresholdFrequency/triggerScaleInThresholdFrequency. P.S. Scale out action has higher priority than scale in action.\n+   * Finaly, if scaleOutThreshold/scaleInThreshold is higher than triggerScaleOutThresholdFrequency/triggerScaleInThresholdFrequency, scale out/in action would be triggered.\n+   *\n+   * @param lags the lag metrics of Stream(Kafka/Kinesis)\n+   * @return Integer. target number of tasksCount, -1 means skip scale action.\n+   */\n+  private Integer computeDesiredTaskCount(List<Long> lags)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6334e2ba0ddf48ddfd884fcdfe9361cee1431e6b"}, "originalPosition": 176}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTE2MzU3MA==", "bodyText": "is it legitimate for supervisor.getActiveTaskGroupsCount() to return a negative value? if not, then supervisor.getActiveTaskGroupsCount() should always return a value >= 0 and this check shouldn't be needed.", "url": "https://github.com/apache/druid/pull/10524#discussion_r585163570", "createdAt": "2021-03-02T00:50:15Z", "author": {"login": "himanshug"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/autoscaler/LagBasedAutoScaler.java", "diffHunk": "@@ -0,0 +1,242 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.seekablestream.supervisor.autoscaler;\n+\n+import org.apache.commons.collections4.queue.CircularFifoQueue;\n+import org.apache.druid.indexing.overlord.supervisor.SupervisorSpec;\n+import org.apache.druid.indexing.overlord.supervisor.autoscaler.LagStats;\n+import org.apache.druid.indexing.overlord.supervisor.autoscaler.SupervisorTaskAutoScaler;\n+import org.apache.druid.indexing.seekablestream.supervisor.SeekableStreamSupervisor;\n+import org.apache.druid.java.util.common.StringUtils;\n+import org.apache.druid.java.util.common.concurrent.Execs;\n+import org.apache.druid.java.util.emitter.EmittingLogger;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.ReentrantLock;\n+\n+public class LagBasedAutoScaler implements SupervisorTaskAutoScaler\n+{\n+  private static final EmittingLogger log = new EmittingLogger(LagBasedAutoScaler.class);\n+  private final String dataSource;\n+  private final CircularFifoQueue<Long> lagMetricsQueue;\n+  private final ScheduledExecutorService lagComputationExec;\n+  private final ScheduledExecutorService allocationExec;\n+  private final SupervisorSpec spec;\n+  private final SeekableStreamSupervisor supervisor;\n+  private final LagBasedAutoScalerConfig lagBasedAutoScalerConfig;\n+\n+  private static final ReentrantLock LOCK = new ReentrantLock(true);\n+\n+  public LagBasedAutoScaler(SeekableStreamSupervisor supervisor, String dataSource,\n+      LagBasedAutoScalerConfig autoScalerConfig, SupervisorSpec spec\n+  )\n+  {\n+    this.lagBasedAutoScalerConfig = autoScalerConfig;\n+    final String supervisorId = StringUtils.format(\"Supervisor-%s\", dataSource);\n+    this.dataSource = dataSource;\n+    final int slots = (int) (lagBasedAutoScalerConfig.getLagCollectionRangeMillis() / lagBasedAutoScalerConfig\n+        .getLagCollectionIntervalMillis()) + 1;\n+    this.lagMetricsQueue = new CircularFifoQueue<>(slots);\n+    this.allocationExec = Execs.scheduledSingleThreaded(StringUtils.encodeForFormat(supervisorId) + \"-Allocation-%d\");\n+    this.lagComputationExec = Execs.scheduledSingleThreaded(StringUtils.encodeForFormat(supervisorId) + \"-Computation-%d\");\n+    this.spec = spec;\n+    this.supervisor = supervisor;\n+  }\n+\n+  @Override\n+  public void start()\n+  {\n+    Callable<Integer> scaleAction = () -> {\n+      LOCK.lock();\n+      int desiredTaskCount = -1;\n+      try {\n+        desiredTaskCount = computeDesiredTaskCount(new ArrayList<>(lagMetricsQueue));\n+\n+        if (desiredTaskCount != -1) {\n+          lagMetricsQueue.clear();\n+        }\n+      }\n+      catch (Exception ex) {\n+        log.warn(ex, \"Exception while computing desired task count for [%s]\", dataSource);\n+      }\n+      finally {\n+        LOCK.unlock();\n+      }\n+      return desiredTaskCount;\n+    };\n+\n+    lagComputationExec.scheduleAtFixedRate(\n+        computeAndCollectLag(),\n+        lagBasedAutoScalerConfig.getScaleActionStartDelayMillis(), // wait for tasks to start up\n+        lagBasedAutoScalerConfig.getLagCollectionIntervalMillis(),\n+        TimeUnit.MILLISECONDS\n+    );\n+    allocationExec.scheduleAtFixedRate(\n+        supervisor.buildDynamicAllocationTask(scaleAction),\n+        lagBasedAutoScalerConfig.getScaleActionStartDelayMillis() + lagBasedAutoScalerConfig\n+            .getLagCollectionRangeMillis(),\n+        lagBasedAutoScalerConfig.getScaleActionPeriodMillis(),\n+        TimeUnit.MILLISECONDS\n+    );\n+    log.info(\n+        \"LagBasedAutoScaler will collect lag every [%d] millis and will keep [%d] data points for the last [%d] millis for dataSource [%s]\",\n+        lagBasedAutoScalerConfig.getLagCollectionIntervalMillis(), lagMetricsQueue.size(),\n+        lagBasedAutoScalerConfig.getLagCollectionRangeMillis(), dataSource\n+    );\n+  }\n+\n+  @Override\n+  public void stop()\n+  {\n+    allocationExec.shutdownNow();\n+    lagComputationExec.shutdownNow();\n+  }\n+\n+  @Override\n+  public void reset()\n+  {\n+    // clear queue for kafka lags\n+    if (lagMetricsQueue != null) {\n+      try {\n+        LOCK.lock();\n+        lagMetricsQueue.clear();\n+      }\n+      catch (Exception e) {\n+        log.warn(e, \"Error,when clear queue in rest action\");\n+      }\n+      finally {\n+        LOCK.unlock();\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method computes current consumer lag. Gets the total lag of all partitions and fill in the lagMetricsQueue\n+   *\n+   * @return a Runnbale object to compute and collect lag.\n+   */\n+  private Runnable computeAndCollectLag()\n+  {\n+    return () -> {\n+      LOCK.lock();\n+      try {\n+        if (!spec.isSuspended()) {\n+          LagStats lagStats = supervisor.computeLagStats();\n+          if (lagStats == null) {\n+            lagMetricsQueue.offer(0L);\n+          } else {\n+            long totalLags = lagStats.getTotalLag();\n+            lagMetricsQueue.offer(totalLags > 0 ? totalLags : 0L);\n+          }\n+          log.debug(\"Current lags [%s] for dataSource [%s].\", new ArrayList<>(lagMetricsQueue), dataSource);\n+        } else {\n+          log.warn(\"[%s] supervisor is suspended, skipping lag collection\", dataSource);\n+        }\n+      }\n+      catch (Exception e) {\n+        log.error(e, \"Error while collecting lags\");\n+      }\n+      finally {\n+        LOCK.unlock();\n+      }\n+    };\n+  }\n+\n+  /**\n+   * This method determines whether to do scale actions based on collected lag points.\n+   * Current algorithm of scale is simple:\n+   * First of all, compute the proportion of lag points higher/lower than scaleOutThreshold/scaleInThreshold, getting scaleOutThreshold/scaleInThreshold.\n+   * Secondly, compare scaleOutThreshold/scaleInThreshold with triggerScaleOutThresholdFrequency/triggerScaleInThresholdFrequency. P.S. Scale out action has higher priority than scale in action.\n+   * Finaly, if scaleOutThreshold/scaleInThreshold is higher than triggerScaleOutThresholdFrequency/triggerScaleInThresholdFrequency, scale out/in action would be triggered.\n+   *\n+   * @param lags the lag metrics of Stream(Kafka/Kinesis)\n+   * @return Integer. target number of tasksCount, -1 means skip scale action.\n+   */\n+  private Integer computeDesiredTaskCount(List<Long> lags)\n+  {\n+    // if supervisor is not suspended, ensure required tasks are running\n+    // if suspended, ensure tasks have been requested to gracefully stop\n+    log.debug(\"Computing desired task count for [%s], based on following lags : [%s]\", dataSource, lags);\n+    int beyond = 0;\n+    int within = 0;\n+    int metricsCount = lags.size();\n+    for (Long lag : lags) {\n+      if (lag >= lagBasedAutoScalerConfig.getScaleOutThreshold()) {\n+        beyond++;\n+      }\n+      if (lag <= lagBasedAutoScalerConfig.getScaleInThreshold()) {\n+        within++;\n+      }\n+    }\n+    double beyondProportion = beyond * 1.0 / metricsCount;\n+    double withinProportion = within * 1.0 / metricsCount;\n+\n+    log.debug(\"Calculated beyondProportion is [%s] and withinProportion is [%s] for dataSource [%s].\", beyondProportion,\n+        withinProportion, dataSource\n+    );\n+\n+    int currentActiveTaskCount = supervisor.getActiveTaskGroupsCount();\n+    if (currentActiveTaskCount < 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6334e2ba0ddf48ddfd884fcdfe9361cee1431e6b"}, "originalPosition": 200}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTE2NzA3OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              private boolean changeTaskCount(Integer desiredActiveTaskCount) throws InterruptedException, ExecutionException, TimeoutException\n          \n          \n            \n              private boolean changeTaskCount(int desiredActiveTaskCount) throws InterruptedException, ExecutionException, TimeoutException", "url": "https://github.com/apache/druid/pull/10524#discussion_r585167079", "createdAt": "2021-03-02T00:59:17Z", "author": {"login": "himanshug"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -318,6 +323,127 @@ public void handle()\n     }\n   }\n \n+  // change taskCount without resubmitting.\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    Callable<Integer> scaleAction;\n+\n+    DynamicAllocationTasksNotice(Callable<Integer> scaleAction)\n+    {\n+      this.scaleAction = scaleAction;\n+    }\n+\n+    /**\n+     * This method will do lag points collection and check dynamic scale action is necessary or not.\n+     */\n+    @Override\n+    public void handle()\n+    {\n+      if (autoScalerConfig == null) {\n+        log.warn(\"autoScalerConfig is null but dynamic allocation notice is submitted, how can it be ?\");\n+      } else {\n+        try {\n+          long nowTime = System.currentTimeMillis();\n+          if (spec.isSuspended()) {\n+            log.info(\"Skipping DynamicAllocationTasksNotice execution because [%s] supervisor is suspended\",\n+                    dataSource\n+            );\n+            return;\n+          }\n+          log.debug(\"PendingCompletionTaskGroups is [%s] for dataSource [%s]\", pendingCompletionTaskGroups,\n+                  dataSource\n+          );\n+          for (CopyOnWriteArrayList<TaskGroup> list : pendingCompletionTaskGroups.values()) {\n+            if (!list.isEmpty()) {\n+              log.info(\n+                      \"Skipping DynamicAllocationTasksNotice execution for datasource [%s] because following tasks are pending [%s]\",\n+                      dataSource, pendingCompletionTaskGroups\n+              );\n+              return;\n+            }\n+          }\n+          if (nowTime - dynamicTriggerLastRunTime < autoScalerConfig.getMinTriggerScaleActionFrequencyMillis()) {\n+            log.info(\n+                    \"DynamicAllocationTasksNotice submitted again in [%d] millis, minTriggerDynamicFrequency is [%s] for dataSource [%s], skipping it!\",\n+                    nowTime - dynamicTriggerLastRunTime, autoScalerConfig.getMinTriggerScaleActionFrequencyMillis(), dataSource\n+            );\n+            return;\n+          }\n+          final Integer desriedTaskCount = scaleAction.call();\n+          boolean allocationSuccess = changeTaskCount(desriedTaskCount);\n+          if (allocationSuccess) {\n+            dynamicTriggerLastRunTime = nowTime;\n+          }\n+        }\n+        catch (Exception ex) {\n+          log.warn(ex, \"Error parsing DynamicAllocationTasksNotice\");\n+        }\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method determines how to do scale actions based on collected lag points.\n+   * If scale action is triggered :\n+   *    First of all, call gracefulShutdownInternal() which will change the state of current datasource ingest tasks from reading to publishing.\n+   *    Secondly, clear all the stateful data structures: activelyReadingTaskGroups, partitionGroups, partitionOffsets, pendingCompletionTaskGroups, partitionIds. These structures will be rebuiled in the next 'RunNotice'.\n+   *    Finally, change the taskCount in SeekableStreamSupervisorIOConfig and sync it to MetadataStorage.\n+   * After the taskCount is changed in SeekableStreamSupervisorIOConfig, next RunNotice will create scaled number of ingest tasks without resubmitting the supervisor.\n+   * @param desiredActiveTaskCount desired taskCount computed from AutoScaler\n+   * @return Boolean flag indicating if scale action was executed or not. If true, it will wait at least 'minTriggerScaleActionFrequencyMillis' before next 'changeTaskCount'.\n+   *         If false, it will do 'changeTaskCount' again after 'scaleActionPeriodMillis' millis.\n+   * @throws InterruptedException\n+   * @throws ExecutionException\n+   * @throws TimeoutException\n+   */\n+  private boolean changeTaskCount(Integer desiredActiveTaskCount) throws InterruptedException, ExecutionException, TimeoutException", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6334e2ba0ddf48ddfd884fcdfe9361cee1431e6b"}, "originalPosition": 112}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTE2NzI3MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                if (desiredActiveTaskCount == -1 || desiredActiveTaskCount == currentActiveTaskCount) {\n          \n          \n            \n                if (desiredActiveTaskCount < 0 || desiredActiveTaskCount == currentActiveTaskCount) {", "url": "https://github.com/apache/druid/pull/10524#discussion_r585167271", "createdAt": "2021-03-02T00:59:40Z", "author": {"login": "himanshug"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -318,6 +323,127 @@ public void handle()\n     }\n   }\n \n+  // change taskCount without resubmitting.\n+  private class DynamicAllocationTasksNotice implements Notice\n+  {\n+    Callable<Integer> scaleAction;\n+\n+    DynamicAllocationTasksNotice(Callable<Integer> scaleAction)\n+    {\n+      this.scaleAction = scaleAction;\n+    }\n+\n+    /**\n+     * This method will do lag points collection and check dynamic scale action is necessary or not.\n+     */\n+    @Override\n+    public void handle()\n+    {\n+      if (autoScalerConfig == null) {\n+        log.warn(\"autoScalerConfig is null but dynamic allocation notice is submitted, how can it be ?\");\n+      } else {\n+        try {\n+          long nowTime = System.currentTimeMillis();\n+          if (spec.isSuspended()) {\n+            log.info(\"Skipping DynamicAllocationTasksNotice execution because [%s] supervisor is suspended\",\n+                    dataSource\n+            );\n+            return;\n+          }\n+          log.debug(\"PendingCompletionTaskGroups is [%s] for dataSource [%s]\", pendingCompletionTaskGroups,\n+                  dataSource\n+          );\n+          for (CopyOnWriteArrayList<TaskGroup> list : pendingCompletionTaskGroups.values()) {\n+            if (!list.isEmpty()) {\n+              log.info(\n+                      \"Skipping DynamicAllocationTasksNotice execution for datasource [%s] because following tasks are pending [%s]\",\n+                      dataSource, pendingCompletionTaskGroups\n+              );\n+              return;\n+            }\n+          }\n+          if (nowTime - dynamicTriggerLastRunTime < autoScalerConfig.getMinTriggerScaleActionFrequencyMillis()) {\n+            log.info(\n+                    \"DynamicAllocationTasksNotice submitted again in [%d] millis, minTriggerDynamicFrequency is [%s] for dataSource [%s], skipping it!\",\n+                    nowTime - dynamicTriggerLastRunTime, autoScalerConfig.getMinTriggerScaleActionFrequencyMillis(), dataSource\n+            );\n+            return;\n+          }\n+          final Integer desriedTaskCount = scaleAction.call();\n+          boolean allocationSuccess = changeTaskCount(desriedTaskCount);\n+          if (allocationSuccess) {\n+            dynamicTriggerLastRunTime = nowTime;\n+          }\n+        }\n+        catch (Exception ex) {\n+          log.warn(ex, \"Error parsing DynamicAllocationTasksNotice\");\n+        }\n+      }\n+    }\n+  }\n+\n+  /**\n+   * This method determines how to do scale actions based on collected lag points.\n+   * If scale action is triggered :\n+   *    First of all, call gracefulShutdownInternal() which will change the state of current datasource ingest tasks from reading to publishing.\n+   *    Secondly, clear all the stateful data structures: activelyReadingTaskGroups, partitionGroups, partitionOffsets, pendingCompletionTaskGroups, partitionIds. These structures will be rebuiled in the next 'RunNotice'.\n+   *    Finally, change the taskCount in SeekableStreamSupervisorIOConfig and sync it to MetadataStorage.\n+   * After the taskCount is changed in SeekableStreamSupervisorIOConfig, next RunNotice will create scaled number of ingest tasks without resubmitting the supervisor.\n+   * @param desiredActiveTaskCount desired taskCount computed from AutoScaler\n+   * @return Boolean flag indicating if scale action was executed or not. If true, it will wait at least 'minTriggerScaleActionFrequencyMillis' before next 'changeTaskCount'.\n+   *         If false, it will do 'changeTaskCount' again after 'scaleActionPeriodMillis' millis.\n+   * @throws InterruptedException\n+   * @throws ExecutionException\n+   * @throws TimeoutException\n+   */\n+  private boolean changeTaskCount(Integer desiredActiveTaskCount) throws InterruptedException, ExecutionException, TimeoutException\n+  {\n+    int currentActiveTaskCount;\n+    Collection<TaskGroup> activeTaskGroups = activelyReadingTaskGroups.values();\n+    currentActiveTaskCount = activeTaskGroups.size();\n+\n+    if (desiredActiveTaskCount == -1 || desiredActiveTaskCount == currentActiveTaskCount) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6334e2ba0ddf48ddfd884fcdfe9361cee1431e6b"}, "originalPosition": 118}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTE2ODk0Ng==", "bodyText": "not sure why lagCollectionRangeMillis was added to scaleActionStartDelayMillis .", "url": "https://github.com/apache/druid/pull/10524#discussion_r585168946", "createdAt": "2021-03-02T01:03:50Z", "author": {"login": "himanshug"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/autoscaler/LagBasedAutoScaler.java", "diffHunk": "@@ -0,0 +1,242 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.seekablestream.supervisor.autoscaler;\n+\n+import org.apache.commons.collections4.queue.CircularFifoQueue;\n+import org.apache.druid.indexing.overlord.supervisor.SupervisorSpec;\n+import org.apache.druid.indexing.overlord.supervisor.autoscaler.LagStats;\n+import org.apache.druid.indexing.overlord.supervisor.autoscaler.SupervisorTaskAutoScaler;\n+import org.apache.druid.indexing.seekablestream.supervisor.SeekableStreamSupervisor;\n+import org.apache.druid.java.util.common.StringUtils;\n+import org.apache.druid.java.util.common.concurrent.Execs;\n+import org.apache.druid.java.util.emitter.EmittingLogger;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.ReentrantLock;\n+\n+public class LagBasedAutoScaler implements SupervisorTaskAutoScaler\n+{\n+  private static final EmittingLogger log = new EmittingLogger(LagBasedAutoScaler.class);\n+  private final String dataSource;\n+  private final CircularFifoQueue<Long> lagMetricsQueue;\n+  private final ScheduledExecutorService lagComputationExec;\n+  private final ScheduledExecutorService allocationExec;\n+  private final SupervisorSpec spec;\n+  private final SeekableStreamSupervisor supervisor;\n+  private final LagBasedAutoScalerConfig lagBasedAutoScalerConfig;\n+\n+  private static final ReentrantLock LOCK = new ReentrantLock(true);\n+\n+  public LagBasedAutoScaler(SeekableStreamSupervisor supervisor, String dataSource,\n+      LagBasedAutoScalerConfig autoScalerConfig, SupervisorSpec spec\n+  )\n+  {\n+    this.lagBasedAutoScalerConfig = autoScalerConfig;\n+    final String supervisorId = StringUtils.format(\"Supervisor-%s\", dataSource);\n+    this.dataSource = dataSource;\n+    final int slots = (int) (lagBasedAutoScalerConfig.getLagCollectionRangeMillis() / lagBasedAutoScalerConfig\n+        .getLagCollectionIntervalMillis()) + 1;\n+    this.lagMetricsQueue = new CircularFifoQueue<>(slots);\n+    this.allocationExec = Execs.scheduledSingleThreaded(StringUtils.encodeForFormat(supervisorId) + \"-Allocation-%d\");\n+    this.lagComputationExec = Execs.scheduledSingleThreaded(StringUtils.encodeForFormat(supervisorId) + \"-Computation-%d\");\n+    this.spec = spec;\n+    this.supervisor = supervisor;\n+  }\n+\n+  @Override\n+  public void start()\n+  {\n+    Callable<Integer> scaleAction = () -> {\n+      LOCK.lock();\n+      int desiredTaskCount = -1;\n+      try {\n+        desiredTaskCount = computeDesiredTaskCount(new ArrayList<>(lagMetricsQueue));\n+\n+        if (desiredTaskCount != -1) {\n+          lagMetricsQueue.clear();\n+        }\n+      }\n+      catch (Exception ex) {\n+        log.warn(ex, \"Exception while computing desired task count for [%s]\", dataSource);\n+      }\n+      finally {\n+        LOCK.unlock();\n+      }\n+      return desiredTaskCount;\n+    };\n+\n+    lagComputationExec.scheduleAtFixedRate(\n+        computeAndCollectLag(),\n+        lagBasedAutoScalerConfig.getScaleActionStartDelayMillis(), // wait for tasks to start up\n+        lagBasedAutoScalerConfig.getLagCollectionIntervalMillis(),\n+        TimeUnit.MILLISECONDS\n+    );\n+    allocationExec.scheduleAtFixedRate(\n+        supervisor.buildDynamicAllocationTask(scaleAction),\n+        lagBasedAutoScalerConfig.getScaleActionStartDelayMillis() + lagBasedAutoScalerConfig\n+            .getLagCollectionRangeMillis(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6334e2ba0ddf48ddfd884fcdfe9361cee1431e6b"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTE3MTkwNA==", "bodyText": "wouldn't time interval between two scale actions be always greater/equal to scaleActionPeriodMillis ?", "url": "https://github.com/apache/druid/pull/10524#discussion_r585171904", "createdAt": "2021-03-02T01:10:06Z", "author": {"login": "himanshug"}, "path": "docs/development/extensions-core/kafka-ingestion.md", "diffHunk": "@@ -146,6 +146,26 @@ A sample supervisor spec is shown below:\n |`lateMessageRejectionStartDateTime`|ISO8601 DateTime|Configure tasks to reject messages with timestamps earlier than this date time; for example if this is set to `2016-01-01T11:00Z` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps earlier than *2016-01-01T11:00Z* will be dropped. This may help prevent concurrency issues if your data stream has late messages and you have multiple pipelines that need to operate on the same segments (e.g. a realtime and a nightly batch ingestion pipeline).|no (default == none)|\n |`lateMessageRejectionPeriod`|ISO8601 Period|Configure tasks to reject messages with timestamps earlier than this period before the task was created; for example if this is set to `PT1H` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps earlier than *2016-01-01T11:00Z* will be dropped. This may help prevent concurrency issues if your data stream has late messages and you have multiple pipelines that need to operate on the same segments (e.g. a realtime and a nightly batch ingestion pipeline). Please note that only one of `lateMessageRejectionPeriod` or `lateMessageRejectionStartDateTime` can be specified.|no (default == none)|\n |`earlyMessageRejectionPeriod`|ISO8601 Period|Configure tasks to reject messages with timestamps later than this period after the task reached its taskDuration; for example if this is set to `PT1H`, the taskDuration is set to `PT1H` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps later than *2016-01-01T14:00Z* will be dropped. **Note:** Tasks sometimes run past their task duration, for example, in cases of supervisor failover. Setting earlyMessageRejectionPeriod too low may cause messages to be dropped unexpectedly whenever a task runs past its originally configured task duration.|no (default == none)|\n+|`autoScalerConfig`|Object|`autoScalerConfig` to specify how to auto scale the number of Kafka ingest tasks based on Lag metrics. ONLY supported for Kafka indexing as of now. See [Tasks Autoscaler Properties](#Task Autoscaler Properties) for details.|no (default == null)|\n+\n+### Task Autoscaler Properties\n+| Property | Description | Required |\n+| ------------- | ------------- | ------------- |\n+| `enableTaskAutoScaler` | Whether enable this feature or not. Set false or ignored here will disable `autoScaler` even though `autoScalerConfig` is not null| no (default == false) |\n+| `lagCollectionIntervalMillis` | Define the frequency of lag points collection.  | no (default == 30000) |\n+| `lagCollectionRangeMillis` | The total time window of lag collection, Use with `lagCollectionIntervalMillis`\uff0cit means that in the recent `lagCollectionRangeMillis`, collect lag metric points every `lagCollectionIntervalMillis`. | no (default == 600000) |\n+| `scaleOutThreshold` | The Threshold of scale out action | no (default == 6000000) |\n+| `triggerScaleOutThresholdFrequency` | If `triggerScaleOutThresholdFrequency` percent of lag points are higher than `scaleOutThreshold`, then do scale out action. | no (default == 0.3) |\n+| `scaleInThreshold` | The Threshold of scale in action | no (default == 1000000) |\n+| `triggerScaleInThresholdFrequency` | If `triggerScaleInThresholdFrequency` percent of lag points are lower than `scaleOutThreshold`, then do scale in action. | no (default == 0.9) |\n+| `scaleActionStartDelayMillis` | Number of milliseconds after supervisor starts when first check scale logic. | no (default == 300000) |\n+| `scaleActionPeriodMillis` | The frequency of checking whether to do scale action in millis | no (default == 60000) |\n+| `taskCountMax` | Maximum value of task count. Make Sure `taskCountMax >= taskCountMin` | yes |\n+| `taskCountMin` | Minimum value of task count. When enable autoscaler, the value of taskCount in `IOConfig` will be ignored, and `taskCountMin` will be the number of tasks that ingestion starts going up to `taskCountMax`| yes |\n+| `scaleInStep` | How many tasks to reduce at a time | no (default == 1) |\n+| `scaleOutStep` | How many tasks to add at a time | no (default == 2) |\n+| `minTriggerScaleActionFrequencyMillis` | Minimum time interval between two scale actions | no (default == 600000) |", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6334e2ba0ddf48ddfd884fcdfe9361cee1431e6b"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTE3MjMyNQ==", "bodyText": "not sure if it is a \"frequency\". maybe triggerScaleOutFractionThreshold", "url": "https://github.com/apache/druid/pull/10524#discussion_r585172325", "createdAt": "2021-03-02T01:11:21Z", "author": {"login": "himanshug"}, "path": "docs/development/extensions-core/kafka-ingestion.md", "diffHunk": "@@ -146,6 +146,26 @@ A sample supervisor spec is shown below:\n |`lateMessageRejectionStartDateTime`|ISO8601 DateTime|Configure tasks to reject messages with timestamps earlier than this date time; for example if this is set to `2016-01-01T11:00Z` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps earlier than *2016-01-01T11:00Z* will be dropped. This may help prevent concurrency issues if your data stream has late messages and you have multiple pipelines that need to operate on the same segments (e.g. a realtime and a nightly batch ingestion pipeline).|no (default == none)|\n |`lateMessageRejectionPeriod`|ISO8601 Period|Configure tasks to reject messages with timestamps earlier than this period before the task was created; for example if this is set to `PT1H` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps earlier than *2016-01-01T11:00Z* will be dropped. This may help prevent concurrency issues if your data stream has late messages and you have multiple pipelines that need to operate on the same segments (e.g. a realtime and a nightly batch ingestion pipeline). Please note that only one of `lateMessageRejectionPeriod` or `lateMessageRejectionStartDateTime` can be specified.|no (default == none)|\n |`earlyMessageRejectionPeriod`|ISO8601 Period|Configure tasks to reject messages with timestamps later than this period after the task reached its taskDuration; for example if this is set to `PT1H`, the taskDuration is set to `PT1H` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps later than *2016-01-01T14:00Z* will be dropped. **Note:** Tasks sometimes run past their task duration, for example, in cases of supervisor failover. Setting earlyMessageRejectionPeriod too low may cause messages to be dropped unexpectedly whenever a task runs past its originally configured task duration.|no (default == none)|\n+|`autoScalerConfig`|Object|`autoScalerConfig` to specify how to auto scale the number of Kafka ingest tasks based on Lag metrics. ONLY supported for Kafka indexing as of now. See [Tasks Autoscaler Properties](#Task Autoscaler Properties) for details.|no (default == null)|\n+\n+### Task Autoscaler Properties\n+| Property | Description | Required |\n+| ------------- | ------------- | ------------- |\n+| `enableTaskAutoScaler` | Whether enable this feature or not. Set false or ignored here will disable `autoScaler` even though `autoScalerConfig` is not null| no (default == false) |\n+| `lagCollectionIntervalMillis` | Define the frequency of lag points collection.  | no (default == 30000) |\n+| `lagCollectionRangeMillis` | The total time window of lag collection, Use with `lagCollectionIntervalMillis`\uff0cit means that in the recent `lagCollectionRangeMillis`, collect lag metric points every `lagCollectionIntervalMillis`. | no (default == 600000) |\n+| `scaleOutThreshold` | The Threshold of scale out action | no (default == 6000000) |\n+| `triggerScaleOutThresholdFrequency` | If `triggerScaleOutThresholdFrequency` percent of lag points are higher than `scaleOutThreshold`, then do scale out action. | no (default == 0.3) |", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6334e2ba0ddf48ddfd884fcdfe9361cee1431e6b"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NTE3MjQ2Mg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            | `triggerScaleInThresholdFrequency` | If `triggerScaleInThresholdFrequency` percent of lag points are lower than `scaleOutThreshold`, then do scale in action. | no (default == 0.9) |\n          \n          \n            \n            | `triggerScaleInFractionThreshold` | If `triggerScaleInThresholdFrequency` percent of lag points are lower than `scaleOutThreshold`, then do scale in action. | no (default == 0.9) |", "url": "https://github.com/apache/druid/pull/10524#discussion_r585172462", "createdAt": "2021-03-02T01:11:41Z", "author": {"login": "himanshug"}, "path": "docs/development/extensions-core/kafka-ingestion.md", "diffHunk": "@@ -146,6 +146,26 @@ A sample supervisor spec is shown below:\n |`lateMessageRejectionStartDateTime`|ISO8601 DateTime|Configure tasks to reject messages with timestamps earlier than this date time; for example if this is set to `2016-01-01T11:00Z` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps earlier than *2016-01-01T11:00Z* will be dropped. This may help prevent concurrency issues if your data stream has late messages and you have multiple pipelines that need to operate on the same segments (e.g. a realtime and a nightly batch ingestion pipeline).|no (default == none)|\n |`lateMessageRejectionPeriod`|ISO8601 Period|Configure tasks to reject messages with timestamps earlier than this period before the task was created; for example if this is set to `PT1H` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps earlier than *2016-01-01T11:00Z* will be dropped. This may help prevent concurrency issues if your data stream has late messages and you have multiple pipelines that need to operate on the same segments (e.g. a realtime and a nightly batch ingestion pipeline). Please note that only one of `lateMessageRejectionPeriod` or `lateMessageRejectionStartDateTime` can be specified.|no (default == none)|\n |`earlyMessageRejectionPeriod`|ISO8601 Period|Configure tasks to reject messages with timestamps later than this period after the task reached its taskDuration; for example if this is set to `PT1H`, the taskDuration is set to `PT1H` and the supervisor creates a task at *2016-01-01T12:00Z*, messages with timestamps later than *2016-01-01T14:00Z* will be dropped. **Note:** Tasks sometimes run past their task duration, for example, in cases of supervisor failover. Setting earlyMessageRejectionPeriod too low may cause messages to be dropped unexpectedly whenever a task runs past its originally configured task duration.|no (default == none)|\n+|`autoScalerConfig`|Object|`autoScalerConfig` to specify how to auto scale the number of Kafka ingest tasks based on Lag metrics. ONLY supported for Kafka indexing as of now. See [Tasks Autoscaler Properties](#Task Autoscaler Properties) for details.|no (default == null)|\n+\n+### Task Autoscaler Properties\n+| Property | Description | Required |\n+| ------------- | ------------- | ------------- |\n+| `enableTaskAutoScaler` | Whether enable this feature or not. Set false or ignored here will disable `autoScaler` even though `autoScalerConfig` is not null| no (default == false) |\n+| `lagCollectionIntervalMillis` | Define the frequency of lag points collection.  | no (default == 30000) |\n+| `lagCollectionRangeMillis` | The total time window of lag collection, Use with `lagCollectionIntervalMillis`\uff0cit means that in the recent `lagCollectionRangeMillis`, collect lag metric points every `lagCollectionIntervalMillis`. | no (default == 600000) |\n+| `scaleOutThreshold` | The Threshold of scale out action | no (default == 6000000) |\n+| `triggerScaleOutThresholdFrequency` | If `triggerScaleOutThresholdFrequency` percent of lag points are higher than `scaleOutThreshold`, then do scale out action. | no (default == 0.3) |\n+| `scaleInThreshold` | The Threshold of scale in action | no (default == 1000000) |\n+| `triggerScaleInThresholdFrequency` | If `triggerScaleInThresholdFrequency` percent of lag points are lower than `scaleOutThreshold`, then do scale in action. | no (default == 0.9) |", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6334e2ba0ddf48ddfd884fcdfe9361cee1431e6b"}, "originalPosition": 15}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "22339ddc83976758809570dd1c92d7506c26fcfa", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/22339ddc83976758809570dd1c92d7506c26fcfa", "committedDate": "2021-03-02T06:06:57Z", "message": "code review && limit taskCountMax to partitionNumbers"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "644e7320ce2f51521b470b022f3406395054bd60", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/644e7320ce2f51521b470b022f3406395054bd60", "committedDate": "2021-03-02T07:33:18Z", "message": "modify docs"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjA0NTE3MTM0", "url": "https://github.com/apache/druid/pull/10524#pullrequestreview-604517134", "createdAt": "2021-03-04T20:10:52Z", "commit": {"oid": "644e7320ce2f51521b470b022f3406395054bd60"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0wNFQyMDoxMDo1MlrOIwkA5Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0wNFQyMDoxMDo1MlrOIwkA5Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4Nzc5MjYxMw==", "bodyText": "nit:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              public int getPartitionNumbers()\n          \n          \n            \n              public int getPartitionsCount()", "url": "https://github.com/apache/druid/pull/10524#discussion_r587792613", "createdAt": "2021-03-04T20:10:52Z", "author": {"login": "himanshug"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/seekablestream/supervisor/SeekableStreamSupervisor.java", "diffHunk": "@@ -1901,6 +2058,11 @@ protected boolean supportsPartitionExpiration()\n     return false;\n   }\n \n+  public int getPartitionNumbers()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "644e7320ce2f51521b470b022f3406395054bd60"}, "originalPosition": 279}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjA0NjU3MDcx", "url": "https://github.com/apache/druid/pull/10524#pullrequestreview-604657071", "createdAt": "2021-03-04T23:20:56Z", "commit": {"oid": "644e7320ce2f51521b470b022f3406395054bd60"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0wNFQyMzoyMDo1NlrOIwqyzg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMy0wNFQyMzozMzozOFrOIwrG3A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzkwMzY5NA==", "bodyText": "Should this be included in toString below?", "url": "https://github.com/apache/druid/pull/10524#discussion_r587903694", "createdAt": "2021-03-04T23:20:56Z", "author": {"login": "capistrant"}, "path": "extensions-core/kafka-indexing-service/src/main/java/org/apache/druid/indexing/kafka/supervisor/KafkaSupervisorIOConfig.java", "diffHunk": "@@ -51,6 +53,7 @@ public KafkaSupervisorIOConfig(\n       @JsonProperty(\"taskCount\") Integer taskCount,\n       @JsonProperty(\"taskDuration\") Period taskDuration,\n       @JsonProperty(\"consumerProperties\") Map<String, Object> consumerProperties,\n+      @Nullable @JsonProperty(\"autoScalerConfig\") AutoScalerConfig autoScalerConfig,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "644e7320ce2f51521b470b022f3406395054bd60"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzkwNDIwNA==", "bodyText": "Not sure if UnsupportedOperationException would be better here or if null is fine.", "url": "https://github.com/apache/druid/pull/10524#discussion_r587904204", "createdAt": "2021-03-04T23:22:21Z", "author": {"login": "capistrant"}, "path": "extensions-core/kinesis-indexing-service/src/main/java/org/apache/druid/indexing/kinesis/supervisor/KinesisSupervisor.java", "diffHunk": "@@ -378,6 +379,13 @@ protected boolean useExclusiveStartSequenceNumberForNonFirstSequence()\n     return true;\n   }\n \n+  // not yet supported, will be implemented in the future maybe? need to find a proper way to measure kinesis lag.\n+  @Override\n+  public LagStats computeLagStats()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "644e7320ce2f51521b470b022f3406395054bd60"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU4NzkwODgyOA==", "bodyText": "does this need to be added added to licesnses.yaml? https://github.com/apache/druid/blob/master/dev/license.md#when-you-add-a-new-library-dependency-into-druid", "url": "https://github.com/apache/druid/pull/10524#discussion_r587908828", "createdAt": "2021-03-04T23:33:38Z", "author": {"login": "capistrant"}, "path": "pom.xml", "diffHunk": "@@ -957,6 +957,11 @@\n                 <artifactId>jna</artifactId>\n                 <version>4.5.1</version>\n             </dependency>\n+            <dependency>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "644e7320ce2f51521b470b022f3406395054bd60"}, "originalPosition": 4}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1a9a09d05411476a27de69b0e22e8ddebe0d5f90", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/1a9a09d05411476a27de69b0e22e8ddebe0d5f90", "committedDate": "2021-03-05T02:40:11Z", "message": "code review"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjA1NDA4MTIx", "url": "https://github.com/apache/druid/pull/10524#pullrequestreview-605408121", "createdAt": "2021-03-05T16:43:30Z", "commit": {"oid": "1a9a09d05411476a27de69b0e22e8ddebe0d5f90"}, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NjA1NDA5MTcw", "url": "https://github.com/apache/druid/pull/10524#pullrequestreview-605409170", "createdAt": "2021-03-05T16:44:46Z", "commit": {"oid": "1a9a09d05411476a27de69b0e22e8ddebe0d5f90"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3394, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}