{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzY4MjUxODgz", "number": 9274, "title": "Refactoring some codes around ingestion", "bodyText": "Part of #9241.\nDescription\nThis PR is mainly about\n\nParallel index task and simple task now use the same segment allocator implementation. This is reusable for the future implementation as well.\nAdded PartitionAnalysis to store the analysis of the partitioning\nMove some util methods to SegmentLockHelper and rename it to TaskLockHelper\nRenamed ShardSpecFactory to ShardSpecBuilder. Added SingleDimensionShardSpecBuilder.\n\n\nThis PR has:\n\n been self-reviewed.\n\n using the concurrency checklist (Remove this item if the PR doesn't have any relation to concurrency.)\n\n\n added documentation for new or modified features or behaviors.\n added Javadocs for most classes and all non-trivial methods. Linked related entities via Javadoc links.\n added or updated version, license, or notice information in licenses.yaml\n added comments explaining the \"why\" and the intent of the code wherever would not be obvious for an unfamiliar reader.\n added unit tests or modified existing tests to cover new code paths.\n added integration tests.\n been tested in a test Druid cluster.", "createdAt": "2020-01-28T21:57:39Z", "url": "https://github.com/apache/druid/pull/9274", "merged": true, "mergeCommit": {"oid": "e81230f9abd092b2ac742258abf534f6e17f35e8"}, "closed": true, "closedAt": "2020-02-08T00:23:07Z", "author": {"login": "jihoonson"}, "timelineItems": {"totalCount": 18, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABb-4lqHgH2gAyMzY4MjUxODgzOjgxYjI4ODQyMDhhYmQxNjkyNTczYzgzOGUyZGQ3MDIzYjg5MmNmNjg=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcCG-gVAFqTM1NTQ3MjAzOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "81b2884208abd1692573c838e2dd7023b892cf68", "author": {"user": {"login": "jihoonson", "name": "Jihoon Son"}}, "url": "https://github.com/apache/druid/commit/81b2884208abd1692573c838e2dd7023b892cf68", "committedDate": "2020-01-28T21:54:03Z", "message": "Refactoring codes around ingestion:\n\n- Parallel index task and simple task now use the same segment allocator implementation. This is reusable for the future implementation as well.\n- Added PartitionAnalysis to store the analysis of the partitioning\n- Move some util methods to SegmentLockHelper and rename it to TaskLockHelper"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9a230a398d7ac88f7d2932495a3b1c0a389b0e2a", "author": {"user": {"login": "jihoonson", "name": "Jihoon Son"}}, "url": "https://github.com/apache/druid/commit/9a230a398d7ac88f7d2932495a3b1c0a389b0e2a", "committedDate": "2020-01-28T22:21:32Z", "message": "fix build"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "407c40273cdaa29a8af60fbf68f009710897c138", "author": {"user": {"login": "jihoonson", "name": "Jihoon Son"}}, "url": "https://github.com/apache/druid/commit/407c40273cdaa29a8af60fbf68f009710897c138", "committedDate": "2020-01-28T23:13:31Z", "message": "fix SingleDimensionShardSpecFactory"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1713e791a4dfa3ae5bea40095e7bc4a35cf3cd47", "author": {"user": {"login": "jihoonson", "name": "Jihoon Son"}}, "url": "https://github.com/apache/druid/commit/1713e791a4dfa3ae5bea40095e7bc4a35cf3cd47", "committedDate": "2020-01-28T23:17:28Z", "message": "optimize SingledimensionShardSpecFactory"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6", "author": {"user": {"login": "jihoonson", "name": "Jihoon Son"}}, "url": "https://github.com/apache/druid/commit/b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6", "committedDate": "2020-01-28T23:37:43Z", "message": "fix test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bf54438f363d097f685744463e63f663327053f0", "author": {"user": {"login": "jihoonson", "name": "Jihoon Son"}}, "url": "https://github.com/apache/druid/commit/bf54438f363d097f685744463e63f663327053f0", "committedDate": "2020-01-29T03:21:32Z", "message": "shard spec builder"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "afc16f14650bb6f335b4d2fecd1b44534a8e9172", "author": {"user": {"login": "jihoonson", "name": "Jihoon Son"}}, "url": "https://github.com/apache/druid/commit/afc16f14650bb6f335b4d2fecd1b44534a8e9172", "committedDate": "2020-01-29T16:22:17Z", "message": "import order"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9062b6952f4ab156dddc7a033b6f3945df412067", "author": {"user": {"login": "jihoonson", "name": "Jihoon Son"}}, "url": "https://github.com/apache/druid/commit/9062b6952f4ab156dddc7a033b6f3945df412067", "committedDate": "2020-01-30T08:12:24Z", "message": "shardSpecBuilder -> partialShardSpec"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "58998ac74be63ce92e375d8d605daf35e69da637", "author": {"user": {"login": "jihoonson", "name": "Jihoon Son"}}, "url": "https://github.com/apache/druid/commit/58998ac74be63ce92e375d8d605daf35e69da637", "committedDate": "2020-01-30T20:17:28Z", "message": "build -> complete"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ5ODAwNzAz", "url": "https://github.com/apache/druid/pull/9274#pullrequestreview-349800703", "createdAt": "2020-01-29T00:40:37Z", "commit": {"oid": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6"}, "state": "COMMENTED", "comments": {"totalCount": 24, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOVQwMDo0MDozN1rOFi5Z8A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wMVQxODo0NjoyM1rOFkeqcw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjEzNjQzMg==", "bodyText": "Maybe change to {@link GranularitySpec#getSegmentGranularity}", "url": "https://github.com/apache/druid/pull/9274#discussion_r372136432", "createdAt": "2020-01-29T00:40:37Z", "author": {"login": "ccaominh"}, "path": "core/src/main/java/org/apache/druid/indexer/partitions/SecondaryPartitionType.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexer.partitions;\n+\n+/**\n+ * In Druid, ingested data are primarily partitioned based on time range (GranularitySpec#getSegmentGranularity),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjEzNzIzMA==", "bodyText": "Perhaps rename to getNumBuckets()", "url": "https://github.com/apache/druid/pull/9274#discussion_r372137230", "createdAt": "2020-01-29T00:43:54Z", "author": {"login": "ccaominh"}, "path": "core/src/main/java/org/apache/druid/timeline/partition/PartitionBoundaries.java", "diffHunk": "@@ -74,4 +74,9 @@ public PartitionBoundaries(String... partitions)\n   {\n     return delegate;\n   }\n+\n+  public int numBuckets()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjEzNzgyMA==", "bodyText": "Update the error message to say \"taskLockHelper\" instead of \"segmentLockHelper\"", "url": "https://github.com/apache/druid/pull/9274#discussion_r372137820", "createdAt": "2020-01-29T00:46:19Z", "author": {"login": "ccaominh"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/AbstractBatchIndexTask.java", "diffHunk": "@@ -194,14 +179,9 @@ public int getPriority()\n     return getContextValue(Tasks.PRIORITY_KEY, Tasks.DEFAULT_BATCH_INDEX_TASK_PRIORITY);\n   }\n \n-  public boolean isUseSegmentLock()\n-  {\n-    return useSegmentLock;\n-  }\n-\n-  public SegmentLockHelper getSegmentLockHelper()\n+  public TaskLockHelper getTaskLockHelper()\n   {\n-    return segmentLockHelper;\n+    return Preconditions.checkNotNull(taskLockHelper, \"segmentLockHelper is not initialized yet\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6"}, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE0MjQ5Mw==", "bodyText": "Can also add the respective unit test to PartitionBoundariesTest", "url": "https://github.com/apache/druid/pull/9274#discussion_r372142493", "createdAt": "2020-01-29T01:04:48Z", "author": {"login": "ccaominh"}, "path": "core/src/main/java/org/apache/druid/timeline/partition/PartitionBoundaries.java", "diffHunk": "@@ -74,4 +74,9 @@ public PartitionBoundaries(String... partitions)\n   {\n     return delegate;\n   }\n+\n+  public int numBuckets()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjEzNzIzMA=="}, "originalCommit": {"oid": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE0NTIyNw==", "bodyText": "PartitionBoundaries should probably override equals for this. Can use EqualsVerifier to add a unit test.", "url": "https://github.com/apache/druid/pull/9274#discussion_r372145227", "createdAt": "2020-01-29T01:15:49Z", "author": {"login": "ccaominh"}, "path": "core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionShardSpecFactory.java", "diffHunk": "@@ -0,0 +1,107 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.timeline.partition;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+import javax.annotation.Nullable;\n+import java.util.Objects;\n+\n+public class SingleDimensionShardSpecFactory implements ShardSpecFactory\n+{\n+  private final String partitionDimension;\n+  private final PartitionBoundaries partitionBoundaries;\n+\n+  @JsonCreator\n+  public SingleDimensionShardSpecFactory(\n+      @JsonProperty(\"partitionDimension\") String partitionDimension,\n+      @JsonProperty(\"partitionBoundaries\") PartitionBoundaries partitionBoundaries\n+  )\n+  {\n+    this.partitionDimension = partitionDimension;\n+    this.partitionBoundaries = partitionBoundaries;\n+  }\n+\n+  @JsonProperty\n+  public String getPartitionDimension()\n+  {\n+    return partitionDimension;\n+  }\n+\n+  @JsonProperty\n+  public PartitionBoundaries getPartitionBoundaries()\n+  {\n+    return partitionBoundaries;\n+  }\n+\n+  @Override\n+  public ShardSpec create(ObjectMapper objectMapper, @Nullable ShardSpec specOfPreviousMaxPartitionId)\n+  {\n+    final int partitionId;\n+    if (specOfPreviousMaxPartitionId != null) {\n+      assert specOfPreviousMaxPartitionId instanceof SingleDimensionShardSpec;\n+      final SingleDimensionShardSpec prevSpec = (SingleDimensionShardSpec) specOfPreviousMaxPartitionId;\n+      partitionId = prevSpec.getPartitionNum() + 1;\n+    } else {\n+      partitionId = 0;\n+    }\n+    return create(objectMapper, partitionId);\n+  }\n+\n+  @Override\n+  public ShardSpec create(ObjectMapper objectMapper, int partitionId)\n+  {\n+    // TODO: numBuckets should be added to SingleDimensionShardSpec in a follow-up PR.\n+    return new SingleDimensionShardSpec(\n+        partitionDimension,\n+        partitionBoundaries.get(partitionId),\n+        partitionBoundaries.get(partitionId + 1),\n+        partitionId\n+    );\n+  }\n+\n+  @Override\n+  public Class<? extends ShardSpec> getShardSpecClass()\n+  {\n+    return SingleDimensionShardSpec.class;\n+  }\n+\n+  @Override\n+  public boolean equals(Object o)\n+  {\n+    if (this == o) {\n+      return true;\n+    }\n+    if (o == null || getClass() != o.getClass()) {\n+      return false;\n+    }\n+    SingleDimensionShardSpecFactory that = (SingleDimensionShardSpecFactory) o;\n+    return Objects.equals(partitionDimension, that.partitionDimension) &&\n+           Objects.equals(partitionBoundaries, that.partitionBoundaries);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6"}, "originalPosition": 99}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE0NTQyNg==", "bodyText": "Please add unit tests for the two create methods", "url": "https://github.com/apache/druid/pull/9274#discussion_r372145426", "createdAt": "2020-01-29T01:16:37Z", "author": {"login": "ccaominh"}, "path": "core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionShardSpecFactory.java", "diffHunk": "@@ -0,0 +1,107 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.timeline.partition;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+import javax.annotation.Nullable;\n+import java.util.Objects;\n+\n+public class SingleDimensionShardSpecFactory implements ShardSpecFactory\n+{\n+  private final String partitionDimension;\n+  private final PartitionBoundaries partitionBoundaries;\n+\n+  @JsonCreator\n+  public SingleDimensionShardSpecFactory(\n+      @JsonProperty(\"partitionDimension\") String partitionDimension,\n+      @JsonProperty(\"partitionBoundaries\") PartitionBoundaries partitionBoundaries\n+  )\n+  {\n+    this.partitionDimension = partitionDimension;\n+    this.partitionBoundaries = partitionBoundaries;\n+  }\n+\n+  @JsonProperty\n+  public String getPartitionDimension()\n+  {\n+    return partitionDimension;\n+  }\n+\n+  @JsonProperty\n+  public PartitionBoundaries getPartitionBoundaries()\n+  {\n+    return partitionBoundaries;\n+  }\n+\n+  @Override\n+  public ShardSpec create(ObjectMapper objectMapper, @Nullable ShardSpec specOfPreviousMaxPartitionId)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE0ODIxNw==", "bodyText": "What do you think about adding a method to the partition spec interface so that future addition of partition specs do not potentially require modification to this code?", "url": "https://github.com/apache/druid/pull/9274#discussion_r372148217", "createdAt": "2020-01-29T01:28:23Z", "author": {"login": "ccaominh"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/IndexTask.java", "diffHunk": "@@ -598,59 +612,74 @@ public TaskStatus runTask(final TaskToolbox toolbox)\n    *\n    * @return a map indicating how many shardSpecs need to be created per interval.\n    */\n-  private Map<Interval, Pair<ShardSpecFactory, Integer>> determineShardSpecs(\n+  private PartitionAnalysis determineShardSpecs(\n       final TaskToolbox toolbox,\n       final InputSource inputSource,\n       final File tmpDir,\n-      final PartitionsSpec nonNullPartitionsSpec\n+      @Nonnull final PartitionsSpec partitionsSpec\n   ) throws IOException\n   {\n     final ObjectMapper jsonMapper = toolbox.getJsonMapper();\n-    final IndexTuningConfig tuningConfig = ingestionSchema.getTuningConfig();\n-    final IndexIOConfig ioConfig = ingestionSchema.getIOConfig();\n \n     final GranularitySpec granularitySpec = ingestionSchema.getDataSchema().getGranularitySpec();\n \n     // Must determine intervals if unknown, since we acquire all locks before processing any data.\n     final boolean determineIntervals = !granularitySpec.bucketIntervals().isPresent();\n \n     // Must determine partitions if rollup is guaranteed and the user didn't provide a specific value.\n-    final boolean determineNumPartitions = nonNullPartitionsSpec.needsDeterminePartitions(false);\n+    final boolean determineNumPartitions = partitionsSpec.needsDeterminePartitions(false);\n \n     // if we were given number of shards per interval and the intervals, we don't need to scan the data\n     if (!determineNumPartitions && !determineIntervals) {\n       log.info(\"Skipping determine partition scan\");\n-      return createShardSpecWithoutInputScan(\n-          granularitySpec,\n-          ioConfig,\n-          tuningConfig,\n-          nonNullPartitionsSpec\n-      );\n+      if (partitionsSpec.getType() == SecondaryPartitionType.HASH) {\n+        return PartialHashSegmentGenerateTask.createHashPartitionAnalysisFromPartitionsSpec(\n+            granularitySpec,\n+            (HashedPartitionsSpec) partitionsSpec\n+        );\n+      } else if (partitionsSpec.getType() == SecondaryPartitionType.LINEAR) {\n+        return createLinearPartitionAnalysis(granularitySpec, (DynamicPartitionsSpec) partitionsSpec);\n+      } else {\n+        throw new UOE(\"%s\", partitionsSpec.getClass().getName());\n+      }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6"}, "originalPosition": 153}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE0ODk2OA==", "bodyText": "What do you think about adding a method to the partition spec interface so that future addition of partition specs do not potentially require modification to this code?", "url": "https://github.com/apache/druid/pull/9274#discussion_r372148968", "createdAt": "2020-01-29T01:31:28Z", "author": {"login": "ccaominh"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/IndexTask.java", "diffHunk": "@@ -659,50 +688,49 @@ public TaskStatus runTask(final TaskToolbox toolbox)\n         inputSource,\n         tmpDir,\n         granularitySpec,\n-        nonNullPartitionsSpec,\n+        partitionsSpec,\n         determineIntervals\n     );\n-\n-    final Map<Interval, Pair<ShardSpecFactory, Integer>> allocateSpecs = new HashMap<>();\n+    final PartitionAnalysis<Integer, ?> partitionAnalysis;\n+    if (partitionsSpec.getType() == SecondaryPartitionType.LINEAR) {\n+      partitionAnalysis = new LinearPartitionAnalysis((DynamicPartitionsSpec) partitionsSpec);\n+    } else if (partitionsSpec.getType() == SecondaryPartitionType.HASH) {\n+      partitionAnalysis = new HashPartitionAnalysis((HashedPartitionsSpec) partitionsSpec);\n+    } else {\n+      throw new UOE(\"%s\", partitionsSpec.getClass().getName());\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6"}, "originalPosition": 216}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE0OTY5OQ==", "bodyText": "May be useful add some unit tests to IndexTaskTest to cover the new code you've added", "url": "https://github.com/apache/druid/pull/9274#discussion_r372149699", "createdAt": "2020-01-29T01:34:47Z", "author": {"login": "ccaominh"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/IndexTask.java", "diffHunk": "@@ -264,6 +271,13 @@ public String getType()\n   @Override\n   public boolean isReady(TaskActionClient taskActionClient) throws Exception\n   {\n+    final IndexTuningConfig tuningConfig = getIngestionSchema().getTuningConfig();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE1MjE1NA==", "bodyText": "Is it worth adding unit test for this class now?", "url": "https://github.com/apache/druid/pull/9274#discussion_r372152154", "createdAt": "2020-01-29T01:44:59Z", "author": {"login": "ccaominh"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/OverlordCoordinatingSegmentAllocator.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.common.task;\n+\n+import org.apache.druid.data.input.InputRow;\n+import org.apache.druid.indexer.partitions.PartitionsSpec;\n+import org.apache.druid.indexer.partitions.SecondaryPartitionType;\n+import org.apache.druid.indexing.appenderator.ActionBasedSegmentAllocator;\n+import org.apache.druid.indexing.common.TaskToolbox;\n+import org.apache.druid.indexing.common.actions.SegmentAllocateAction;\n+import org.apache.druid.indexing.common.actions.SurrogateAction;\n+import org.apache.druid.indexing.common.task.TaskLockHelper.OverwritingRootGenerationPartitions;\n+import org.apache.druid.indexing.common.task.batch.parallel.SupervisorTaskAccess;\n+import org.apache.druid.java.util.common.ISE;\n+import org.apache.druid.segment.indexing.DataSchema;\n+import org.apache.druid.segment.indexing.granularity.GranularitySpec;\n+import org.apache.druid.segment.realtime.appenderator.SegmentAllocator;\n+import org.apache.druid.segment.realtime.appenderator.SegmentIdWithShardSpec;\n+import org.apache.druid.timeline.partition.NumberedOverwriteShardSpecFactory;\n+import org.apache.druid.timeline.partition.NumberedShardSpecFactory;\n+import org.apache.druid.timeline.partition.ShardSpecFactory;\n+import org.joda.time.Interval;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+\n+/**\n+ * Segment allocator which allocates new segments using the overlord per request.\n+ */\n+public class OverlordCoordinatingSegmentAllocator implements SegmentAllocator", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE1MjgzNg==", "bodyText": "Do you want to add unit tests for this class?", "url": "https://github.com/apache/druid/pull/9274#discussion_r372152836", "createdAt": "2020-01-29T01:47:56Z", "author": {"login": "ccaominh"}, "path": "indexing-service/src/test/java/org/apache/druid/indexing/common/task/CountingLocalTaskActionClient.java", "diffHunk": "@@ -0,0 +1,68 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.common.task;\n+\n+import org.apache.druid.indexing.common.actions.LocalTaskActionClient;\n+import org.apache.druid.indexing.common.actions.SurrogateAction;\n+import org.apache.druid.indexing.common.actions.TaskAction;\n+import org.apache.druid.indexing.common.actions.TaskActionClient;\n+import org.apache.druid.indexing.common.actions.TaskActionToolbox;\n+import org.apache.druid.indexing.common.actions.TaskAuditLogConfig;\n+import org.apache.druid.indexing.overlord.TaskStorage;\n+\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+public class CountingLocalTaskActionClient implements TaskActionClient", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE1MzYxNg==", "bodyText": "Thanks for the additional helpful comments!", "url": "https://github.com/apache/druid/pull/9274#discussion_r372153616", "createdAt": "2020-01-29T01:51:16Z", "author": {"login": "ccaominh"}, "path": "server/src/main/java/org/apache/druid/segment/realtime/appenderator/SegmentAllocator.java", "diffHunk": "@@ -21,25 +21,32 @@\n \n import org.apache.druid.data.input.InputRow;\n \n+import javax.annotation.Nullable;\n import java.io.IOException;\n \n public interface SegmentAllocator\n {\n   /**\n-   * Allocates a new segment for a given timestamp.\n+   * Allocates a new segment for a given timestamp. Even though its name is \"allocate\", this method is actually", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5MzY2NA==", "bodyText": "Maybe revise the javadoc wording to match the method rename better (similar comment for the method below)", "url": "https://github.com/apache/druid/pull/9274#discussion_r373793664", "createdAt": "2020-02-01T18:11:53Z", "author": {"login": "ccaominh"}, "path": "core/src/main/java/org/apache/druid/timeline/partition/PartialShardSpec.java", "diffHunk": "@@ -20,34 +20,37 @@\n package org.apache.druid.timeline.partition;\n \n import com.fasterxml.jackson.annotation.JsonSubTypes;\n+import com.fasterxml.jackson.annotation.JsonSubTypes.Type;\n import com.fasterxml.jackson.annotation.JsonTypeInfo;\n import com.fasterxml.jackson.databind.ObjectMapper;\n \n import javax.annotation.Nullable;\n \n /**\n- * Factory to be used to allocate segments remotely in the overlord.\n+ * Class to contain all information of a {@link ShardSpec} except for the partition ID.\n+ * This class is mainly used by the indexing tasks to allocate new segments using the Overlord.\n  */\n @JsonTypeInfo(use = JsonTypeInfo.Id.NAME, property = \"type\")\n @JsonSubTypes({\n-    @JsonSubTypes.Type(name = \"numbered\", value = NumberedShardSpecFactory.class),\n-    @JsonSubTypes.Type(name = \"hashed\", value = HashBasedNumberedShardSpecFactory.class),\n-    @JsonSubTypes.Type(name = \"numbered_overwrite\", value = NumberedOverwritingShardSpecFactory.class),\n+    @Type(name = \"numbered\", value = NumberedPartialShardSpec.class),\n+    @Type(name = \"hashed\", value = HashBasedNumberedPartialShardSpec.class),\n+    @Type(name = \"single_dim\", value = SingleDimensionPartialShardSpec.class),\n+    @Type(name = \"numbered_overwrite\", value = NumberedOverwritePartialShardSpec.class),\n })\n-public interface ShardSpecFactory\n+public interface PartialShardSpec\n {\n   /**\n    * Create a new shardSpec based on {@code specOfPreviousMaxPartitionId}. If it's null, it assumes that this is the\n    * first call for the timeChunk where the new segment is created.\n    * Note that {@code specOfPreviousMaxPartitionId} can also be null for {@link OverwriteShardSpec} if all segments\n    * in the timeChunk are first-generation segments.\n    */\n-  ShardSpec create(ObjectMapper objectMapper, @Nullable ShardSpec specOfPreviousMaxPartitionId);\n+  ShardSpec complete(ObjectMapper objectMapper, @Nullable ShardSpec specOfPreviousMaxPartitionId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "58998ac74be63ce92e375d8d605daf35e69da637"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5MzcyOA==", "bodyText": "Do you want to add a serde unit test?", "url": "https://github.com/apache/druid/pull/9274#discussion_r373793728", "createdAt": "2020-02-01T18:13:27Z", "author": {"login": "ccaominh"}, "path": "core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionPartialShardSpec.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.timeline.partition;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+import javax.annotation.Nullable;\n+\n+public class SingleDimensionPartialShardSpec implements PartialShardSpec\n+{\n+  private final String partitionDimension;\n+  private final int bucketId;\n+  @Nullable\n+  private final String start;\n+  @Nullable\n+  private final String end;\n+  private final int numBuckets;\n+\n+  @JsonCreator\n+  public SingleDimensionPartialShardSpec(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "58998ac74be63ce92e375d8d605daf35e69da637"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5Mzg4MA==", "bodyText": "This method name can be updated to match the rename to \"PartialShardSpec\"", "url": "https://github.com/apache/druid/pull/9274#discussion_r373793880", "createdAt": "2020-02-01T18:15:44Z", "author": {"login": "ccaominh"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/OverlordCoordinatingSegmentAllocator.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.common.task;\n+\n+import org.apache.druid.data.input.InputRow;\n+import org.apache.druid.indexer.partitions.PartitionsSpec;\n+import org.apache.druid.indexer.partitions.SecondaryPartitionType;\n+import org.apache.druid.indexing.appenderator.ActionBasedSegmentAllocator;\n+import org.apache.druid.indexing.common.TaskToolbox;\n+import org.apache.druid.indexing.common.actions.SegmentAllocateAction;\n+import org.apache.druid.indexing.common.actions.SurrogateAction;\n+import org.apache.druid.indexing.common.task.TaskLockHelper.OverwritingRootGenerationPartitions;\n+import org.apache.druid.indexing.common.task.batch.parallel.SupervisorTaskAccess;\n+import org.apache.druid.java.util.common.ISE;\n+import org.apache.druid.segment.indexing.DataSchema;\n+import org.apache.druid.segment.indexing.granularity.GranularitySpec;\n+import org.apache.druid.segment.realtime.appenderator.SegmentAllocator;\n+import org.apache.druid.segment.realtime.appenderator.SegmentIdWithShardSpec;\n+import org.apache.druid.timeline.partition.NumberedOverwritePartialShardSpec;\n+import org.apache.druid.timeline.partition.NumberedPartialShardSpec;\n+import org.apache.druid.timeline.partition.PartialShardSpec;\n+import org.joda.time.Interval;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+\n+/**\n+ * Segment allocator which allocates new segments using the overlord per request.\n+ */\n+public class OverlordCoordinatingSegmentAllocator implements SegmentAllocator\n+{\n+  private final ActionBasedSegmentAllocator internalAllocator;\n+\n+  OverlordCoordinatingSegmentAllocator(\n+      final TaskToolbox toolbox,\n+      final @Nullable SupervisorTaskAccess supervisorTaskAccess,\n+      final DataSchema dataSchema,\n+      final TaskLockHelper taskLockHelper,\n+      final boolean appendToExisting,\n+      final PartitionsSpec partitionsSpec\n+  )\n+  {\n+    this.internalAllocator = new ActionBasedSegmentAllocator(\n+        toolbox.getTaskActionClient(),\n+        dataSchema,\n+        (schema, row, sequenceName, previousSegmentId, skipSegmentLineageCheck) -> {\n+          final GranularitySpec granularitySpec = schema.getGranularitySpec();\n+          final Interval interval = granularitySpec\n+              .bucketInterval(row.getTimestamp())\n+              .or(granularitySpec.getSegmentGranularity().bucket(row.getTimestamp()));\n+          final PartialShardSpec partialShardSpec = createShardSpecFactory(\n+              appendToExisting,\n+              partitionsSpec,\n+              taskLockHelper,\n+              interval\n+          );\n+          if (supervisorTaskAccess != null) {\n+            return new SurrogateAction<>(\n+                supervisorTaskAccess.getSupervisorTaskId(),\n+                new SegmentAllocateAction(\n+                    schema.getDataSource(),\n+                    row.getTimestamp(),\n+                    schema.getGranularitySpec().getQueryGranularity(),\n+                    schema.getGranularitySpec().getSegmentGranularity(),\n+                    sequenceName,\n+                    previousSegmentId,\n+                    skipSegmentLineageCheck,\n+                    partialShardSpec,\n+                    taskLockHelper.getLockGranularityToUse()\n+                )\n+            );\n+          } else {\n+            return new SegmentAllocateAction(\n+                schema.getDataSource(),\n+                row.getTimestamp(),\n+                schema.getGranularitySpec().getQueryGranularity(),\n+                schema.getGranularitySpec().getSegmentGranularity(),\n+                sequenceName,\n+                previousSegmentId,\n+                skipSegmentLineageCheck,\n+                partialShardSpec,\n+                taskLockHelper.getLockGranularityToUse()\n+            );\n+          }\n+        }\n+    );\n+  }\n+\n+  @Nullable\n+  @Override\n+  public SegmentIdWithShardSpec allocate(\n+      InputRow row,\n+      String sequenceName,\n+      String previousSegmentId,\n+      boolean skipSegmentLineageCheck\n+  ) throws IOException\n+  {\n+    return internalAllocator.allocate(row, sequenceName, previousSegmentId, skipSegmentLineageCheck);\n+  }\n+\n+  private static PartialShardSpec createShardSpecFactory(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "58998ac74be63ce92e375d8d605daf35e69da637"}, "originalPosition": 118}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NDIxMA==", "bodyText": "Is it worth adding a unit test for this method now?", "url": "https://github.com/apache/druid/pull/9274#discussion_r373794210", "createdAt": "2020-02-01T18:21:57Z", "author": {"login": "ccaominh"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/PartialHashSegmentGenerateTask.java", "diffHunk": "@@ -125,14 +127,18 @@ public boolean isReady(TaskActionClient taskActionClient) throws Exception\n   }\n \n   @Override\n-  IndexTaskSegmentAllocator createSegmentAllocator(TaskToolbox toolbox) throws IOException\n+  CachingSegmentAllocator createSegmentAllocator(TaskToolbox toolbox, ParallelIndexSupervisorTaskClient taskClient)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "58998ac74be63ce92e375d8d605daf35e69da637"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NDIzNg==", "bodyText": "Is it worth adding a unit test for this method now?", "url": "https://github.com/apache/druid/pull/9274#discussion_r373794236", "createdAt": "2020-02-01T18:22:51Z", "author": {"login": "ccaominh"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/PartialHashSegmentGenerateTask.java", "diffHunk": "@@ -158,17 +164,24 @@ private HashPartitionStat createPartitionStat(TaskToolbox toolbox, DataSegment s\n     );\n   }\n \n-  private Map<Interval, Pair<ShardSpecFactory, Integer>> createShardSpecs()\n+  /**\n+   * Creates shard specs based on the given configurations. The return value is a map between intervals created\n+   * based on the segment granularity and the shard specs to be created.\n+   * Note that the shard specs to be created is a pair of {@link PartialShardSpec} and number of segments per interval\n+   * and filled only when {@link #isGuaranteedRollup} = true. Otherwise, the return value contains only the set of\n+   * intervals generated based on the segment granularity.\n+   */\n+  public static HashPartitionAnalysis createHashPartitionAnalysisFromPartitionsSpec(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "58998ac74be63ce92e375d8d605daf35e69da637"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NDI1MA==", "bodyText": "Is it worth adding a unit test for this method now?", "url": "https://github.com/apache/druid/pull/9274#discussion_r373794250", "createdAt": "2020-02-01T18:23:06Z", "author": {"login": "ccaominh"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/PartialRangeSegmentGenerateTask.java", "diffHunk": "@@ -149,15 +150,19 @@ public boolean isReady(TaskActionClient taskActionClient)\n   }\n \n   @Override\n-  IndexTaskSegmentAllocator createSegmentAllocator(TaskToolbox toolbox) throws IOException\n+  CachingSegmentAllocator createSegmentAllocator(TaskToolbox toolbox, ParallelIndexSupervisorTaskClient taskClient)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "58998ac74be63ce92e375d8d605daf35e69da637"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NDU0NA==", "bodyText": "Is it worth adding a unit test for this method?", "url": "https://github.com/apache/druid/pull/9274#discussion_r373794544", "createdAt": "2020-02-01T18:29:10Z", "author": {"login": "ccaominh"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/partition/HashPartitionAnalysis.java", "diffHunk": "@@ -0,0 +1,127 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.common.task.batch.partition;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Maps;\n+import org.apache.druid.indexer.partitions.HashedPartitionsSpec;\n+import org.apache.druid.indexing.common.TaskToolbox;\n+import org.apache.druid.segment.realtime.appenderator.SegmentIdWithShardSpec;\n+import org.apache.druid.timeline.partition.HashBasedNumberedShardSpec;\n+import org.joda.time.Interval;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.BiConsumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n+\n+public class HashPartitionAnalysis implements CompletePartitionAnalysis<Integer, HashedPartitionsSpec>\n+{\n+  /**\n+   * Key is the time ranges for the primary partitioning.\n+   * Value is the number of partitions per time range for the secondary partitioning\n+   */\n+  private final Map<Interval, Integer> intervalToNumBuckets = new HashMap<>();\n+  private final HashedPartitionsSpec partitionsSpec;\n+\n+  public HashPartitionAnalysis(HashedPartitionsSpec partitionsSpec)\n+  {\n+    this.partitionsSpec = partitionsSpec;\n+  }\n+\n+  @Override\n+  public HashedPartitionsSpec getPartitionsSpec()\n+  {\n+    return partitionsSpec;\n+  }\n+\n+  @Override\n+  public void updateBucket(Interval interval, Integer bucketAnalysis)\n+  {\n+    intervalToNumBuckets.put(interval, bucketAnalysis);\n+  }\n+\n+  @Override\n+  public Integer getBucketAnalysis(Interval interval)\n+  {\n+    return Preconditions.checkNotNull(\n+        intervalToNumBuckets.get(interval),\n+        \"Missing numBuckets for interval[%s]\",\n+        interval\n+    );\n+  }\n+\n+  @Override\n+  public Set<Interval> getAllIntervalsToIndex()\n+  {\n+    return Collections.unmodifiableSet(intervalToNumBuckets.keySet());\n+  }\n+\n+  @Override\n+  public int numTimePartitions()\n+  {\n+    return intervalToNumBuckets.size();\n+  }\n+\n+  public void forEach(BiConsumer<Interval, Integer> consumer)\n+  {\n+    intervalToNumBuckets.forEach(consumer);\n+  }\n+\n+  @Override\n+  public Map<Interval, List<SegmentIdWithShardSpec>> convertToIntervalToSegmentIds(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "58998ac74be63ce92e375d8d605daf35e69da637"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NDcwOA==", "bodyText": "Do you want to add javadocs (especially for these methods)", "url": "https://github.com/apache/druid/pull/9274#discussion_r373794708", "createdAt": "2020-02-01T18:32:08Z", "author": {"login": "ccaominh"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/partition/PartitionAnalysis.java", "diffHunk": "@@ -0,0 +1,45 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.common.task.batch.partition;\n+\n+import org.apache.druid.indexer.partitions.PartitionsSpec;\n+import org.joda.time.Interval;\n+\n+import java.util.Set;\n+\n+/**\n+ * Analysis of the partitions to create. The implementation is mutable and updated by the indexing\n+ * {@link org.apache.druid.indexing.common.task.Task}.\n+ *\n+ * This interface provides all time chunks for the primary partitioning and the bucket information per time chunk\n+ * for the secondary partitioning.\n+ */\n+public interface PartitionAnalysis<T, P extends PartitionsSpec>\n+{\n+  P getPartitionsSpec();\n+\n+  void updateBucket(Interval interval, T bucketAnalysis);\n+\n+  T getBucketAnalysis(Interval interval);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "58998ac74be63ce92e375d8d605daf35e69da637"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NDc0Mw==", "bodyText": "I assume getBucketAnalysis is used by a follow up PR?", "url": "https://github.com/apache/druid/pull/9274#discussion_r373794743", "createdAt": "2020-02-01T18:32:52Z", "author": {"login": "ccaominh"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/partition/PartitionAnalysis.java", "diffHunk": "@@ -0,0 +1,45 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.common.task.batch.partition;\n+\n+import org.apache.druid.indexer.partitions.PartitionsSpec;\n+import org.joda.time.Interval;\n+\n+import java.util.Set;\n+\n+/**\n+ * Analysis of the partitions to create. The implementation is mutable and updated by the indexing\n+ * {@link org.apache.druid.indexing.common.task.Task}.\n+ *\n+ * This interface provides all time chunks for the primary partitioning and the bucket information per time chunk\n+ * for the secondary partitioning.\n+ */\n+public interface PartitionAnalysis<T, P extends PartitionsSpec>\n+{\n+  P getPartitionsSpec();\n+\n+  void updateBucket(Interval interval, T bucketAnalysis);\n+\n+  T getBucketAnalysis(Interval interval);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NDcwOA=="}, "originalCommit": {"oid": "58998ac74be63ce92e375d8d605daf35e69da637"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NTAwOA==", "bodyText": "Can this be private?", "url": "https://github.com/apache/druid/pull/9274#discussion_r373795008", "createdAt": "2020-02-01T18:38:18Z", "author": {"login": "ccaominh"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/partition/RangePartitionAnalysis.java", "diffHunk": "@@ -17,80 +17,109 @@\n  * under the License.\n  */\n \n-package org.apache.druid.indexing.common.task;\n+package org.apache.druid.indexing.common.task.batch.partition;\n \n import com.google.common.collect.Maps;\n-import org.apache.druid.data.input.InputRow;\n+import org.apache.druid.indexer.partitions.SingleDimensionPartitionsSpec;\n import org.apache.druid.indexing.common.TaskToolbox;\n-import org.apache.druid.indexing.common.task.batch.parallel.distribution.PartitionBoundaries;\n import org.apache.druid.segment.realtime.appenderator.SegmentIdWithShardSpec;\n+import org.apache.druid.timeline.partition.PartitionBoundaries;\n import org.apache.druid.timeline.partition.SingleDimensionShardSpec;\n import org.joda.time.Interval;\n \n import javax.annotation.Nullable;\n-import java.io.IOException;\n import java.util.Collections;\n+import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n+import java.util.Set;\n+import java.util.function.BiConsumer;\n import java.util.function.Function;\n import java.util.stream.Collectors;\n import java.util.stream.IntStream;\n \n-/**\n- * Allocates all necessary range-partitioned segments locally at the beginning and reuses them.\n- *\n- * @see CachingLocalSegmentAllocatorHelper\n- */\n-public class RangePartitionCachingLocalSegmentAllocator implements IndexTaskSegmentAllocator\n+public class RangePartitionAnalysis\n+    implements CompletePartitionAnalysis<PartitionBoundaries, SingleDimensionPartitionsSpec>\n {\n-  private final String dataSource;\n-  private final String partitionDimension;\n-  private final Map<Interval, PartitionBoundaries> intervalsToPartitions;\n-  private final IndexTaskSegmentAllocator delegate;\n+  private final Map<Interval, PartitionBoundaries> intervalToPartitionBoundaries = new HashMap<>();\n+  private final SingleDimensionPartitionsSpec partitionsSpec;\n+\n+  public RangePartitionAnalysis(SingleDimensionPartitionsSpec partitionsSpec)\n+  {\n+    this.partitionsSpec = partitionsSpec;\n+  }\n+\n+  @Override\n+  public SingleDimensionPartitionsSpec getPartitionsSpec()\n+  {\n+    return partitionsSpec;\n+  }\n+\n+  @Override\n+  public void updateBucket(Interval interval, PartitionBoundaries bucketAnalysis)\n+  {\n+    intervalToPartitionBoundaries.put(interval, bucketAnalysis);\n+  }\n+\n+  @Override\n+  public PartitionBoundaries getBucketAnalysis(Interval interval)\n+  {\n+    return intervalToPartitionBoundaries.get(interval);\n+  }\n+\n+  @Override\n+  public Set<Interval> getAllIntervalsToIndex()\n+  {\n+    return Collections.unmodifiableSet(intervalToPartitionBoundaries.keySet());\n+  }\n+\n+  public void forEach(BiConsumer<Interval, PartitionBoundaries> consumer)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "58998ac74be63ce92e375d8d605daf35e69da637"}, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NTI0OA==", "bodyText": "Is this only needed for tests? If so, maybe add @VisibleForTesting", "url": "https://github.com/apache/druid/pull/9274#discussion_r373795248", "createdAt": "2020-02-01T18:42:32Z", "author": {"login": "ccaominh"}, "path": "indexing-service/src/test/java/org/apache/druid/indexing/common/task/CountingLocalTaskActionClient.java", "diffHunk": "@@ -0,0 +1,68 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.common.task;\n+\n+import org.apache.druid.indexing.common.actions.LocalTaskActionClient;\n+import org.apache.druid.indexing.common.actions.SurrogateAction;\n+import org.apache.druid.indexing.common.actions.TaskAction;\n+import org.apache.druid.indexing.common.actions.TaskActionClient;\n+import org.apache.druid.indexing.common.actions.TaskActionToolbox;\n+import org.apache.druid.indexing.common.actions.TaskAuditLogConfig;\n+import org.apache.druid.indexing.overlord.TaskStorage;\n+\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+public class CountingLocalTaskActionClient implements TaskActionClient\n+{\n+  private final ConcurrentHashMap<Class<? extends TaskAction>, AtomicInteger> actionCountMap =\n+      new ConcurrentHashMap<>();\n+  private final LocalTaskActionClient delegate;\n+\n+  public CountingLocalTaskActionClient(\n+      Task task,\n+      TaskStorage storage,\n+      TaskActionToolbox toolbox\n+  )\n+  {\n+    delegate = new LocalTaskActionClient(task, storage, toolbox, new TaskAuditLogConfig(false));\n+  }\n+\n+  @Override\n+  public <RetType> RetType submit(TaskAction<RetType> taskAction)\n+  {\n+    final RetType result = delegate.submit(taskAction);\n+    final TaskAction actionKey;\n+    if (taskAction instanceof SurrogateAction) {\n+      actionKey = ((SurrogateAction) taskAction).getTaskAction();\n+    } else {\n+      actionKey = taskAction;\n+    }\n+    actionCountMap.computeIfAbsent(actionKey.getClass(), k -> new AtomicInteger()).incrementAndGet();\n+    return result;\n+  }\n+\n+  public int getActionCount(Class<? extends TaskAction> actionClass)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "58998ac74be63ce92e375d8d605daf35e69da637"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NTQ0Mw==", "bodyText": "Do you want to update the parameter description to match the rename?", "url": "https://github.com/apache/druid/pull/9274#discussion_r373795443", "createdAt": "2020-02-01T18:46:23Z", "author": {"login": "ccaominh"}, "path": "server/src/main/java/org/apache/druid/indexing/overlord/IndexerMetadataStorageCoordinator.java", "diffHunk": "@@ -157,7 +157,7 @@\n    * @param previousSegmentId       previous segment in the series; may be null or empty, meaning this is the first\n    *                                segment\n    * @param interval                interval for which to allocate a segment\n-   * @param shardSpecFactory        shardSpecFactory containing all necessary information to create a shardSpec for the\n+   * @param partialShardSpec        shardSpecFactory containing all necessary information to create a shardSpec for the", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "58998ac74be63ce92e375d8d605daf35e69da637"}, "originalPosition": 14}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "09f1776133ef6f437bb809a15e75b7bf0449aaef", "author": {"user": {"login": "jihoonson", "name": "Jihoon Son"}}, "url": "https://github.com/apache/druid/commit/09f1776133ef6f437bb809a15e75b7bf0449aaef", "committedDate": "2020-02-03T04:03:48Z", "message": "fix comment; add unit tests for partitionBoundaries"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936", "author": {"user": {"login": "jihoonson", "name": "Jihoon Son"}}, "url": "https://github.com/apache/druid/commit/b8962a37f884f3ca3cad3abb20eb801b13783936", "committedDate": "2020-02-03T05:15:37Z", "message": "add more tests and fix javadoc"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUyMzg4MzE3", "url": "https://github.com/apache/druid/pull/9274#pullrequestreview-352388317", "createdAt": "2020-02-03T16:30:00Z", "commit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "state": "COMMENTED", "comments": {"totalCount": 15, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QxNjozMDowMFrOFk3onw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QxNzo0ODo1OFrOFk6MEA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIwNDU3NQ==", "bodyText": "javadocs please - what is this used for?", "url": "https://github.com/apache/druid/pull/9274#discussion_r374204575", "createdAt": "2020-02-03T16:30:00Z", "author": {"login": "suneet-s"}, "path": "core/src/main/java/org/apache/druid/indexer/partitions/PartitionsSpec.java", "diffHunk": "@@ -41,6 +41,9 @@\n   String MAX_ROWS_PER_SEGMENT = \"maxRowsPerSegment\";\n   int HISTORICAL_NULL = -1;\n \n+  @JsonIgnore\n+  SecondaryPartitionType getType();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIwNjE4Nw==", "bodyText": "Is there a test that fails if we change the property name here?\nIf there isn't, let's at least leave a comment here saying numPartitions is for backward compatibility.", "url": "https://github.com/apache/druid/pull/9274#discussion_r374206187", "createdAt": "2020-02-03T16:32:43Z", "author": {"login": "suneet-s"}, "path": "core/src/main/java/org/apache/druid/timeline/partition/HashBasedNumberedPartialShardSpec.java", "diffHunk": "@@ -27,20 +27,20 @@\n import java.util.List;\n import java.util.Objects;\n \n-public class HashBasedNumberedShardSpecFactory implements ShardSpecFactory\n+public class HashBasedNumberedPartialShardSpec implements PartialShardSpec\n {\n   @Nullable\n   private final List<String> partitionDimensions;\n-  private final int numPartitions;\n+  private final int numBuckets;\n \n   @JsonCreator\n-  public HashBasedNumberedShardSpecFactory(\n+  public HashBasedNumberedPartialShardSpec(\n       @JsonProperty(\"partitionDimensions\") @Nullable List<String> partitionDimensions,\n-      @JsonProperty(\"numPartitions\") int numPartitions\n+      @JsonProperty(\"numPartitions\") int numBuckets", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIyMzUzMg==", "bodyText": "do we need a unit test for this?", "url": "https://github.com/apache/druid/pull/9274#discussion_r374223532", "createdAt": "2020-02-03T17:03:19Z", "author": {"login": "suneet-s"}, "path": "core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionPartialShardSpec.java", "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.timeline.partition;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+import javax.annotation.Nullable;\n+import java.util.Objects;\n+\n+public class SingleDimensionPartialShardSpec implements PartialShardSpec\n+{\n+  private final String partitionDimension;\n+  private final int bucketId;\n+  @Nullable\n+  private final String start;\n+  @Nullable\n+  private final String end;\n+  private final int numBuckets;\n+\n+  @JsonCreator\n+  public SingleDimensionPartialShardSpec(\n+      @JsonProperty(\"partitionDimension\") String partitionDimension,\n+      @JsonProperty(\"bucketId\") int bucketId,\n+      @JsonProperty(\"start\") @Nullable String start,\n+      @JsonProperty(\"end\") @Nullable String end,\n+      @JsonProperty(\"numBuckets\") int numBuckets\n+  )\n+  {\n+    this.partitionDimension = partitionDimension;\n+    this.bucketId = bucketId;\n+    this.start = start;\n+    this.end = end;\n+    this.numBuckets = numBuckets;\n+  }\n+\n+  @JsonProperty\n+  public String getPartitionDimension()\n+  {\n+    return partitionDimension;\n+  }\n+\n+  @JsonProperty\n+  public int getBucketId()\n+  {\n+    return bucketId;\n+  }\n+\n+  @JsonProperty\n+  @Nullable\n+  public String getStart()\n+  {\n+    return start;\n+  }\n+\n+  @JsonProperty\n+  @Nullable\n+  public String getEnd()\n+  {\n+    return end;\n+  }\n+\n+  @JsonProperty\n+  public int getNumBuckets()\n+  {\n+    return numBuckets;\n+  }\n+\n+  @Override\n+  public ShardSpec complete(ObjectMapper objectMapper, @Nullable ShardSpec specOfPreviousMaxPartitionId)\n+  {\n+    final int partitionId;\n+    if (specOfPreviousMaxPartitionId != null) {\n+      assert specOfPreviousMaxPartitionId instanceof SingleDimensionShardSpec;\n+      final SingleDimensionShardSpec prevSpec = (SingleDimensionShardSpec) specOfPreviousMaxPartitionId;\n+      partitionId = prevSpec.getPartitionNum() + 1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIyNDU1NQ==", "bodyText": "Why is this cast needed?", "url": "https://github.com/apache/druid/pull/9274#discussion_r374224555", "createdAt": "2020-02-03T17:05:15Z", "author": {"login": "suneet-s"}, "path": "core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionPartialShardSpec.java", "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.timeline.partition;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+import javax.annotation.Nullable;\n+import java.util.Objects;\n+\n+public class SingleDimensionPartialShardSpec implements PartialShardSpec\n+{\n+  private final String partitionDimension;\n+  private final int bucketId;\n+  @Nullable\n+  private final String start;\n+  @Nullable\n+  private final String end;\n+  private final int numBuckets;\n+\n+  @JsonCreator\n+  public SingleDimensionPartialShardSpec(\n+      @JsonProperty(\"partitionDimension\") String partitionDimension,\n+      @JsonProperty(\"bucketId\") int bucketId,\n+      @JsonProperty(\"start\") @Nullable String start,\n+      @JsonProperty(\"end\") @Nullable String end,\n+      @JsonProperty(\"numBuckets\") int numBuckets\n+  )\n+  {\n+    this.partitionDimension = partitionDimension;\n+    this.bucketId = bucketId;\n+    this.start = start;\n+    this.end = end;\n+    this.numBuckets = numBuckets;\n+  }\n+\n+  @JsonProperty\n+  public String getPartitionDimension()\n+  {\n+    return partitionDimension;\n+  }\n+\n+  @JsonProperty\n+  public int getBucketId()\n+  {\n+    return bucketId;\n+  }\n+\n+  @JsonProperty\n+  @Nullable\n+  public String getStart()\n+  {\n+    return start;\n+  }\n+\n+  @JsonProperty\n+  @Nullable\n+  public String getEnd()\n+  {\n+    return end;\n+  }\n+\n+  @JsonProperty\n+  public int getNumBuckets()\n+  {\n+    return numBuckets;\n+  }\n+\n+  @Override\n+  public ShardSpec complete(ObjectMapper objectMapper, @Nullable ShardSpec specOfPreviousMaxPartitionId)\n+  {\n+    final int partitionId;\n+    if (specOfPreviousMaxPartitionId != null) {\n+      assert specOfPreviousMaxPartitionId instanceof SingleDimensionShardSpec;\n+      final SingleDimensionShardSpec prevSpec = (SingleDimensionShardSpec) specOfPreviousMaxPartitionId;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIyNjM0Ng==", "bodyText": "why public?", "url": "https://github.com/apache/druid/pull/9274#discussion_r374226346", "createdAt": "2020-02-03T17:08:52Z", "author": {"login": "suneet-s"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/CachingLocalSegmentAllocator.java", "diffHunk": "@@ -41,11 +45,8 @@\n \n /**\n  * Allocates all necessary segments locally at the beginning and reuses them.\n- *\n- * @see HashPartitionCachingLocalSegmentAllocator\n- * @see RangePartitionCachingLocalSegmentAllocator\n  */\n-class CachingLocalSegmentAllocatorHelper implements IndexTaskSegmentAllocator\n+public class CachingLocalSegmentAllocator implements CachingSegmentAllocator", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIyNzIwOQ==", "bodyText": "I don't see a unit test class for this. Do we want to write a test that makes sure we set the action correctly based on the passed in supervisorTaskAccess", "url": "https://github.com/apache/druid/pull/9274#discussion_r374227209", "createdAt": "2020-02-03T17:10:47Z", "author": {"login": "suneet-s"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/CachingLocalSegmentAllocator.java", "diffHunk": "@@ -59,30 +60,46 @@\n      *\n      * @return Information for segment preallocation\n      */\n-    Map<Interval, List<SegmentIdWithShardSpec>> create(Function<Interval, String> versionFinder);\n+    Map<Interval, List<SegmentIdWithShardSpec>> create(\n+        TaskToolbox toolbox,\n+        String dataSource,\n+        Function<Interval, String> versionFinder\n+    );\n   }\n \n-  CachingLocalSegmentAllocatorHelper(\n+  CachingLocalSegmentAllocator(\n       TaskToolbox toolbox,\n+      String dataSource,\n       String taskId,\n-      String supervisorTaskId,\n+      @Nullable SupervisorTaskAccess supervisorTaskAccess,\n       IntervalToSegmentIdsCreator intervalToSegmentIdsCreator\n   ) throws IOException\n   {\n     this.taskId = taskId;\n     this.sequenceNameToSegmentId = new HashMap<>();\n \n+    final TaskAction<List<TaskLock>> action;\n+    if (supervisorTaskAccess == null) {\n+      action = new LockListAction();\n+    } else {\n+      action = new SurrogateAction<>(supervisorTaskAccess.getSupervisorTaskId(), new LockListAction());\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIyNzk4MA==", "bodyText": "Why must this be NotNull? The javadocs say this function is nullable", "url": "https://github.com/apache/druid/pull/9274#discussion_r374227980", "createdAt": "2020-02-03T17:12:11Z", "author": {"login": "suneet-s"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/CachingLocalSegmentAllocator.java", "diffHunk": "@@ -115,14 +132,11 @@ public SegmentIdWithShardSpec allocate(\n       boolean skipSegmentLineageCheck\n   )\n   {\n-    return sequenceNameToSegmentId.get(sequenceName);\n-  }\n-\n-  @Override\n-  public String getSequenceName(Interval interval, InputRow inputRow)\n-  {\n-    // Sequence name is based solely on the shardSpec, and there will only be one segment per sequence.\n-    return getSequenceName(interval, shardSpecs.getShardSpec(interval, inputRow));\n+    return Preconditions.checkNotNull(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 99}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIzMjEyMQ==", "bodyText": "I think it's better to be explicit here about which types we expect to be non linear and throw a UOE exception if there another type is added. This forces the dev who adds a new type to think about which category it should fall in to.", "url": "https://github.com/apache/druid/pull/9274#discussion_r374232121", "createdAt": "2020-02-03T17:20:09Z", "author": {"login": "suneet-s"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/IndexTask.java", "diffHunk": "@@ -875,14 +876,36 @@ private TaskStatus generateAndPublishSegments(\n       toolbox.getMonitorScheduler().addMonitor(metricsMonitor);\n     }\n \n+    final PartitionsSpec partitionsSpec = partitionAnalysis.getPartitionsSpec();\n     final IndexTuningConfig tuningConfig = ingestionSchema.getTuningConfig();\n     final long pushTimeout = tuningConfig.getPushTimeout();\n \n-    final IndexTaskSegmentAllocator segmentAllocator = createSegmentAllocator(\n-        toolbox,\n-        dataSchema,\n-        allocateSpec\n-    );\n+    final SegmentAllocator segmentAllocator;\n+    final SequenceNameFunction sequenceNameFunction;\n+    if (partitionsSpec.getType() == SecondaryPartitionType.LINEAR) {\n+      segmentAllocator = SegmentAllocators.forLinearPartitioning(\n+          toolbox,\n+          null,\n+          dataSchema,\n+          getTaskLockHelper(),\n+          ingestionSchema.getIOConfig().isAppendToExisting(),\n+          partitionAnalysis.getPartitionsSpec()\n+      );\n+      sequenceNameFunction = new LinearlyPartitionedSequenceNameFunction(getId());\n+    } else {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 358}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIzMzc3MA==", "bodyText": "Does this need to be public", "url": "https://github.com/apache/druid/pull/9274#discussion_r374233770", "createdAt": "2020-02-03T17:23:25Z", "author": {"login": "suneet-s"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/LinearlyPartitionedSequenceNameFunction.java", "diffHunk": "@@ -0,0 +1,45 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.common.task;\n+\n+import org.apache.druid.data.input.InputRow;\n+import org.joda.time.Interval;\n+\n+/**\n+ * This sequence name function should be used for the linear partitioning. Since the segments are created as needed,\n+ * this function uses a single sequence name.\n+ *\n+ * @see org.apache.druid.indexer.partitions.SecondaryPartitionType\n+ */\n+public class LinearlyPartitionedSequenceNameFunction implements SequenceNameFunction", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIzNDA0Ng==", "bodyText": "does this need to be public?", "url": "https://github.com/apache/druid/pull/9274#discussion_r374234046", "createdAt": "2020-02-03T17:23:58Z", "author": {"login": "suneet-s"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/LocalSegmentAllocator.java", "diffHunk": "@@ -32,32 +34,27 @@\n import org.joda.time.DateTime;\n import org.joda.time.Interval;\n \n+import javax.annotation.Nullable;\n import java.io.IOException;\n-import java.util.HashMap;\n import java.util.Map;\n import java.util.Map.Entry;\n-import java.util.concurrent.atomic.AtomicInteger;\n import java.util.stream.Collectors;\n \n /**\n  * Segment allocator which allocates new segments locally per request.\n  */\n-class LocalSegmentAllocator implements IndexTaskSegmentAllocator\n+public class LocalSegmentAllocator implements SegmentAllocator", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIzNDk4NQ==", "bodyText": "For my understanding - why did we need to change this to MutableInt", "url": "https://github.com/apache/druid/pull/9274#discussion_r374234985", "createdAt": "2020-02-03T17:25:54Z", "author": {"login": "suneet-s"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/LocalSegmentAllocator.java", "diffHunk": "@@ -67,30 +64,25 @@\n       }\n \n       final Interval interval = maybeInterval.get();\n-      final String version = intervalToVersion.entrySet().stream()\n-                                              .filter(entry -> entry.getKey().contains(interval))\n-                                              .map(Entry::getValue)\n-                                              .findFirst()\n-                                              .orElseThrow(() -> new ISE(\"Cannot find a version for interval[%s]\", interval));\n+      final String version = intervalToVersion\n+          .entrySet()\n+          .stream()\n+          .filter(entry -> entry.getKey().contains(interval))\n+          .map(Entry::getValue)\n+          .findFirst()\n+          .orElseThrow(() -> new ISE(\"Cannot find a version for interval[%s]\", interval));\n \n-      final int partitionNum = counters.computeIfAbsent(interval, x -> new AtomicInteger()).getAndIncrement();\n+      final int partitionId = counters.computeIfAbsent(interval, x -> new MutableInt()).getAndIncrement();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI0MDYxMQ==", "bodyText": "Why is this always NonLinearlyPartitionedSequenceNameFunction shouldn't we check the partitionsSpec type to determine the  sequenceNameFunction here?\nIf it is, I think we should , make the constructors package private and expose the function name creation through a factory that accepts a PartitionsSpec", "url": "https://github.com/apache/druid/pull/9274#discussion_r374240611", "createdAt": "2020-02-03T17:37:09Z", "author": {"login": "suneet-s"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/PartialSegmentGenerateTask.java", "diffHunk": "@@ -164,7 +171,11 @@ abstract T createGeneratedPartitionsReport(\n     final PartitionsSpec partitionsSpec = tuningConfig.getGivenOrDefaultPartitionsSpec();\n     final long pushTimeout = tuningConfig.getPushTimeout();\n \n-    final IndexTaskSegmentAllocator segmentAllocator = createSegmentAllocator(toolbox);\n+    final CachingSegmentAllocator segmentAllocator = createSegmentAllocator(toolbox, taskClient);\n+    final SequenceNameFunction sequenceNameFunction = new NonLinearlyPartitionedSequenceNameFunction(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI0MjIzNg==", "bodyText": "This should look at partitionsSpec.getType() otherwise if that implementation changes to return a non linear type this will break", "url": "https://github.com/apache/druid/pull/9274#discussion_r374242236", "createdAt": "2020-02-03T17:40:39Z", "author": {"login": "suneet-s"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/SinglePhaseSubTask.java", "diffHunk": "@@ -410,7 +313,14 @@ private SegmentAllocator createSegmentAllocator()\n     final DynamicPartitionsSpec partitionsSpec = (DynamicPartitionsSpec) tuningConfig.getGivenOrDefaultPartitionsSpec();\n     final long pushTimeout = tuningConfig.getPushTimeout();\n     final boolean explicitIntervals = granularitySpec.bucketIntervals().isPresent();\n-    final SegmentAllocator segmentAllocator = createSegmentAllocator(toolbox, taskClient);\n+    final SegmentAllocator segmentAllocator = SegmentAllocators.forLinearPartitioning(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 152}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI0NTExOQ==", "bodyText": "Other implementations of ParitionAnalysis throw an exception if the interval is not found. This returns null. I think we should consolidate the behavior and document it in the interface to make it easy for consumers of the interface to interact with this function", "url": "https://github.com/apache/druid/pull/9274#discussion_r374245119", "createdAt": "2020-02-03T17:46:22Z", "author": {"login": "suneet-s"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/partition/RangePartitionAnalysis.java", "diffHunk": "@@ -17,80 +17,109 @@\n  * under the License.\n  */\n \n-package org.apache.druid.indexing.common.task;\n+package org.apache.druid.indexing.common.task.batch.partition;\n \n import com.google.common.collect.Maps;\n-import org.apache.druid.data.input.InputRow;\n+import org.apache.druid.indexer.partitions.SingleDimensionPartitionsSpec;\n import org.apache.druid.indexing.common.TaskToolbox;\n-import org.apache.druid.indexing.common.task.batch.parallel.distribution.PartitionBoundaries;\n import org.apache.druid.segment.realtime.appenderator.SegmentIdWithShardSpec;\n+import org.apache.druid.timeline.partition.PartitionBoundaries;\n import org.apache.druid.timeline.partition.SingleDimensionShardSpec;\n import org.joda.time.Interval;\n \n import javax.annotation.Nullable;\n-import java.io.IOException;\n import java.util.Collections;\n+import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n+import java.util.Set;\n+import java.util.function.BiConsumer;\n import java.util.function.Function;\n import java.util.stream.Collectors;\n import java.util.stream.IntStream;\n \n-/**\n- * Allocates all necessary range-partitioned segments locally at the beginning and reuses them.\n- *\n- * @see CachingLocalSegmentAllocatorHelper\n- */\n-public class RangePartitionCachingLocalSegmentAllocator implements IndexTaskSegmentAllocator\n+public class RangePartitionAnalysis\n+    implements CompletePartitionAnalysis<PartitionBoundaries, SingleDimensionPartitionsSpec>\n {\n-  private final String dataSource;\n-  private final String partitionDimension;\n-  private final Map<Interval, PartitionBoundaries> intervalsToPartitions;\n-  private final IndexTaskSegmentAllocator delegate;\n+  private final Map<Interval, PartitionBoundaries> intervalToPartitionBoundaries = new HashMap<>();\n+  private final SingleDimensionPartitionsSpec partitionsSpec;\n+\n+  public RangePartitionAnalysis(SingleDimensionPartitionsSpec partitionsSpec)\n+  {\n+    this.partitionsSpec = partitionsSpec;\n+  }\n+\n+  @Override\n+  public SingleDimensionPartitionsSpec getPartitionsSpec()\n+  {\n+    return partitionsSpec;\n+  }\n+\n+  @Override\n+  public void updateBucket(Interval interval, PartitionBoundaries bucketAnalysis)\n+  {\n+    intervalToPartitionBoundaries.put(interval, bucketAnalysis);\n+  }\n+\n+  @Override\n+  public PartitionBoundaries getBucketAnalysis(Interval interval)\n+  {\n+    return intervalToPartitionBoundaries.get(interval);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI0NjQxNg==", "bodyText": "shardSpecFactory -> partialShardSpec. Lombok would be nice and hide all of this away :)", "url": "https://github.com/apache/druid/pull/9274#discussion_r374246416", "createdAt": "2020-02-03T17:48:58Z", "author": {"login": "suneet-s"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/overlord/LockRequestForNewSegment.java", "diffHunk": "@@ -187,7 +187,7 @@ public String toString()\n            \", groupId='\" + groupId + '\\'' +\n            \", dataSource='\" + dataSource + '\\'' +\n            \", interval=\" + interval +\n-           \", shardSpecFactory=\" + shardSpecFactory +\n+           \", shardSpecFactory=\" + partialShardSpec +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 71}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7ac416095ec5b6ccf4b58265cb04c2ca3da33ebd", "author": {"user": {"login": "jihoonson", "name": "Jihoon Son"}}, "url": "https://github.com/apache/druid/commit/7ac416095ec5b6ccf4b58265cb04c2ca3da33ebd", "committedDate": "2020-02-04T01:57:31Z", "message": "fix toString(); add serde tests for HashBasedNumberedPartialShardSpec and SegmentAllocateAction"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "02bea97c3c04911d6b71a788ed743b7bbdd4530c", "author": {"user": {"login": "jihoonson", "name": "Jihoon Son"}}, "url": "https://github.com/apache/druid/commit/02bea97c3c04911d6b71a788ed743b7bbdd4530c", "committedDate": "2020-02-04T05:22:30Z", "message": "fix test"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU0MDg2NzU5", "url": "https://github.com/apache/druid/pull/9274#pullrequestreview-354086759", "createdAt": "2020-02-05T22:29:33Z", "commit": {"oid": "02bea97c3c04911d6b71a788ed743b7bbdd4530c"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQyMjoyOTozM1rOFmJang==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQyMjo0Mjo0MFrOFmJuZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU0NDQ3OA==", "bodyText": "Was there an issue with using TestHelper?", "url": "https://github.com/apache/druid/pull/9274#discussion_r375544478", "createdAt": "2020-02-05T22:29:33Z", "author": {"login": "ccaominh"}, "path": "core/src/test/java/org/apache/druid/timeline/partition/PartitionBoundariesTest.java", "diffHunk": "@@ -75,8 +76,23 @@ public void handlesRepeatedValue()\n   }\n \n   @Test\n-  public void serializesDeserializes()\n+  public void serializesDeserializes() throws JsonProcessingException\n   {\n-    TestHelper.testSerializesDeserializes(TestHelper.JSON_MAPPER, target);\n+    final ObjectMapper objectMapper = new ObjectMapper();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "02bea97c3c04911d6b71a788ed743b7bbdd4530c"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU0NzkzOA==", "bodyText": "May be useful to add an EqualsVerifier test for this.", "url": "https://github.com/apache/druid/pull/9274#discussion_r375547938", "createdAt": "2020-02-05T22:38:34Z", "author": {"login": "ccaominh"}, "path": "core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionPartialShardSpec.java", "diffHunk": "@@ -94,14 +125,17 @@ public boolean equals(Object o)\n     if (o == null || getClass() != o.getClass()) {\n       return false;\n     }\n-    SingleDimensionShardSpecFactory that = (SingleDimensionShardSpecFactory) o;\n-    return Objects.equals(partitionDimension, that.partitionDimension) &&\n-           Objects.equals(partitionBoundaries, that.partitionBoundaries);\n+    SingleDimensionPartialShardSpec that = (SingleDimensionPartialShardSpec) o;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "02bea97c3c04911d6b71a788ed743b7bbdd4530c"}, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU0ODU3MA==", "bodyText": "How about adding an EqualsVerifier test to this class?", "url": "https://github.com/apache/druid/pull/9274#discussion_r375548570", "createdAt": "2020-02-05T22:40:11Z", "author": {"login": "ccaominh"}, "path": "core/src/test/java/org/apache/druid/timeline/partition/HashBasedNumberedPartialShardSpecTest.java", "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.timeline.partition;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.google.common.collect.ImmutableList;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.Map;\n+\n+public class HashBasedNumberedPartialShardSpecTest\n+{\n+  private static final ObjectMapper MAPPER = new ObjectMapper();\n+\n+  @Test\n+  public void testSerde() throws IOException\n+  {\n+    final HashBasedNumberedPartialShardSpec expected = new HashBasedNumberedPartialShardSpec(\n+        ImmutableList.of(\"dim1\", \"dim2\"),\n+        3\n+    );\n+    final byte[] json = MAPPER.writeValueAsBytes(expected);\n+    final HashBasedNumberedPartialShardSpec fromJson = (HashBasedNumberedPartialShardSpec) MAPPER.readValue(\n+        json,\n+        PartialShardSpec.class\n+    );\n+    Assert.assertEquals(expected, fromJson);\n+  }\n+\n+  @Test\n+  public void testJsonPropertyNames() throws IOException\n+  {\n+    final HashBasedNumberedPartialShardSpec expected = new HashBasedNumberedPartialShardSpec(\n+        ImmutableList.of(\"dim1\", \"dim2\"),\n+        3\n+    );\n+    final byte[] json = MAPPER.writeValueAsBytes(expected);\n+    //noinspection unchecked\n+    final Map<String, Object> map = MAPPER.readValue(json, Map.class);\n+    Assert.assertEquals(3, map.size());\n+    Assert.assertEquals(HashBasedNumberedPartialShardSpec.TYPE, map.get(\"type\"));\n+    Assert.assertEquals(expected.getPartitionDimensions(), map.get(\"partitionDimensions\"));\n+    Assert.assertEquals(expected.getNumBuckets(), map.get(\"numPartitions\"));\n+  }\n+}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "02bea97c3c04911d6b71a788ed743b7bbdd4530c"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU0OTU0MA==", "bodyText": "May be useful to add an EqualsVerifier test to this class.", "url": "https://github.com/apache/druid/pull/9274#discussion_r375549540", "createdAt": "2020-02-05T22:42:40Z", "author": {"login": "ccaominh"}, "path": "core/src/test/java/org/apache/druid/timeline/partition/SingleDimensionPartialShardSpecTest.java", "diffHunk": "@@ -0,0 +1,48 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.timeline.partition;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+\n+public class SingleDimensionPartialShardSpecTest\n+{\n+  @Test\n+  public void testSerde() throws IOException\n+  {\n+    final SingleDimensionPartialShardSpec expected = new SingleDimensionPartialShardSpec(\n+        \"partitionKey\",\n+        3,\n+        \"start\",\n+        \"end\",\n+        10\n+    );\n+    final ObjectMapper mapper = new ObjectMapper();\n+    final byte[] json = mapper.writeValueAsBytes(expected);\n+    final SingleDimensionPartialShardSpec fromJson = (SingleDimensionPartialShardSpec) mapper.readValue(\n+        json,\n+        PartialShardSpec.class\n+    );\n+    Assert.assertEquals(expected, fromJson);\n+  }\n+}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "02bea97c3c04911d6b71a788ed743b7bbdd4530c"}, "originalPosition": 48}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e7c9cecd63922226d4399313874c6971e7e55938", "author": {"user": {"login": "jihoonson", "name": "Jihoon Son"}}, "url": "https://github.com/apache/druid/commit/e7c9cecd63922226d4399313874c6971e7e55938", "committedDate": "2020-02-07T22:14:28Z", "message": "add equality test for hash and range partial shard specs"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU1NDcyMDM5", "url": "https://github.com/apache/druid/pull/9274#pullrequestreview-355472039", "createdAt": "2020-02-07T22:21:38Z", "commit": {"oid": "e7c9cecd63922226d4399313874c6971e7e55938"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3826, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}