{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDM0MjA4MDcw", "number": 10033, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQwNzoyNTowOVrOEIP8ZA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQyMjowMDowNFrOEIiy6g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3MDg1Mjg0OnYy", "diffSide": "RIGHT", "path": "core/src/test/java/org/apache/druid/timeline/partition/HashBasedNumberedPartialShardSpecTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQwNzoyNTowOVrOGoGGgA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNVQwNToxMDoxNFrOGorksA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDY5NjE5Mg==", "bodyText": "just curious, this doesn't need to change, why does this test use new ObjectMapper() instead of MAPPER?", "url": "https://github.com/apache/druid/pull/10033#discussion_r444696192", "createdAt": "2020-06-24T07:25:09Z", "author": {"login": "clintropolis"}, "path": "core/src/test/java/org/apache/druid/timeline/partition/HashBasedNumberedPartialShardSpecTest.java", "diffHunk": "@@ -73,5 +73,21 @@ public void testJsonPropertyNames() throws IOException\n     Assert.assertEquals(expected.getPartitionDimensions(), map.get(\"partitionDimensions\"));\n     Assert.assertEquals(expected.getBucketId(), map.get(\"bucketId\"));\n     Assert.assertEquals(expected.getNumBuckets(), map.get(\"numPartitions\"));\n+    Assert.assertEquals(expected.getBucketId(), map.get(\"bucketId\"));\n+  }\n+\n+  @Test\n+  public void testComplete()\n+  {\n+    final HashBasedNumberedPartialShardSpec partialShardSpec = new HashBasedNumberedPartialShardSpec(\n+        ImmutableList.of(\"dim\"),\n+        2,\n+        4\n+    );\n+    final ShardSpec shardSpec = partialShardSpec.complete(new ObjectMapper(), 1, 3);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b423e964d258d2ba2f9760fa3224026157e98d0d"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTMxMDEyOA==", "bodyText": "Ah, I didn't notice it while copying these tests \ud83d\ude05", "url": "https://github.com/apache/druid/pull/10033#discussion_r445310128", "createdAt": "2020-06-25T05:10:14Z", "author": {"login": "jihoonson"}, "path": "core/src/test/java/org/apache/druid/timeline/partition/HashBasedNumberedPartialShardSpecTest.java", "diffHunk": "@@ -73,5 +73,21 @@ public void testJsonPropertyNames() throws IOException\n     Assert.assertEquals(expected.getPartitionDimensions(), map.get(\"partitionDimensions\"));\n     Assert.assertEquals(expected.getBucketId(), map.get(\"bucketId\"));\n     Assert.assertEquals(expected.getNumBuckets(), map.get(\"numPartitions\"));\n+    Assert.assertEquals(expected.getBucketId(), map.get(\"bucketId\"));\n+  }\n+\n+  @Test\n+  public void testComplete()\n+  {\n+    final HashBasedNumberedPartialShardSpec partialShardSpec = new HashBasedNumberedPartialShardSpec(\n+        ImmutableList.of(\"dim\"),\n+        2,\n+        4\n+    );\n+    final ShardSpec shardSpec = partialShardSpec.complete(new ObjectMapper(), 1, 3);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDY5NjE5Mg=="}, "originalCommit": {"oid": "b423e964d258d2ba2f9760fa3224026157e98d0d"}, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3MTAyNDM0OnYy", "diffSide": "RIGHT", "path": "indexing-service/src/test/java/org/apache/druid/indexing/common/task/batch/parallel/RangePartitionMultiPhaseParallelIndexingTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQwODoxNzo0MlrOGoHzFg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNVQwNToxMDoxOVrOGorkzA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDcyMzk5MA==", "bodyText": "nit, typo: Segmens\n\"testAppendLinearlyPartitionedSegmentsToHashPartitionedDatasourceSuccessfullyAppend\"", "url": "https://github.com/apache/druid/pull/10033#discussion_r444723990", "createdAt": "2020-06-24T08:17:42Z", "author": {"login": "clintropolis"}, "path": "indexing-service/src/test/java/org/apache/druid/indexing/common/task/batch/parallel/RangePartitionMultiPhaseParallelIndexingTest.java", "diffHunk": "@@ -201,48 +208,122 @@ private static void writeRow(\n   public void createsCorrectRangePartitions() throws Exception\n   {\n     int targetRowsPerSegment = NUM_ROW / DIM_FILE_CARDINALITY / NUM_PARTITION;\n-    final Set<DataSegment> publishedSegments;\n+    final Set<DataSegment> publishedSegments = runTestTask(\n+        new SingleDimensionPartitionsSpec(\n+            targetRowsPerSegment,\n+            null,\n+            DIM1,\n+            false\n+        ),\n+        useMultivalueDim ? TaskState.FAILED : TaskState.SUCCESS,\n+        false\n+    );\n+\n+    if (!useMultivalueDim) {\n+      assertRangePartitions(publishedSegments);\n+    }\n+  }\n+\n+  @Test\n+  public void testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b423e964d258d2ba2f9760fa3224026157e98d0d"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTMxMDE1Ng==", "bodyText": "Thanks \ud83d\udc4d", "url": "https://github.com/apache/druid/pull/10033#discussion_r445310156", "createdAt": "2020-06-25T05:10:19Z", "author": {"login": "jihoonson"}, "path": "indexing-service/src/test/java/org/apache/druid/indexing/common/task/batch/parallel/RangePartitionMultiPhaseParallelIndexingTest.java", "diffHunk": "@@ -201,48 +208,122 @@ private static void writeRow(\n   public void createsCorrectRangePartitions() throws Exception\n   {\n     int targetRowsPerSegment = NUM_ROW / DIM_FILE_CARDINALITY / NUM_PARTITION;\n-    final Set<DataSegment> publishedSegments;\n+    final Set<DataSegment> publishedSegments = runTestTask(\n+        new SingleDimensionPartitionsSpec(\n+            targetRowsPerSegment,\n+            null,\n+            DIM1,\n+            false\n+        ),\n+        useMultivalueDim ? TaskState.FAILED : TaskState.SUCCESS,\n+        false\n+    );\n+\n+    if (!useMultivalueDim) {\n+      assertRangePartitions(publishedSegments);\n+    }\n+  }\n+\n+  @Test\n+  public void testAppendLinearlyPartitionedSegmensToHashPartitionedDatasourceSuccessfullyAppend()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDcyMzk5MA=="}, "originalCommit": {"oid": "b423e964d258d2ba2f9760fa3224026157e98d0d"}, "originalPosition": 51}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3MTA0NzM0OnYy", "diffSide": "RIGHT", "path": "server/src/test/java/org/apache/druid/server/shard/SingleDimensionShardSpecTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQwODoyNDoyMVrOGoIB_Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNVQwNToxMDoyMlrOGork2g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDcyNzgwNQ==", "bodyText": "How do we end up with these mixed shard spec situations, minor compaction? Like I understand why these evaluate to true given how the checks work, just trying to understand how it happens since afaict only dynamic can be appended.", "url": "https://github.com/apache/druid/pull/10033#discussion_r444727805", "createdAt": "2020-06-24T08:24:21Z", "author": {"login": "clintropolis"}, "path": "server/src/test/java/org/apache/druid/server/shard/SingleDimensionShardSpecTest.java", "diffHunk": "@@ -142,6 +146,16 @@ public void testPossibleInDomain()\n     Assert.assertTrue(shard7.possibleInDomain(domain2));\n   }\n \n+  @Test\n+  public void testSharePartitionSpace()\n+  {\n+    final SingleDimensionShardSpec shardSpec = makeSpec(\"start\", \"end\");\n+    Assert.assertTrue(shardSpec.sharePartitionSpace(NumberedPartialShardSpec.instance()));\n+    Assert.assertTrue(shardSpec.sharePartitionSpace(new HashBasedNumberedPartialShardSpec(null, 0, 1)));\n+    Assert.assertTrue(shardSpec.sharePartitionSpace(new SingleDimensionPartialShardSpec(\"dim\", 0, null, null, 1)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b423e964d258d2ba2f9760fa3224026157e98d0d"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTMxMDE3MA==", "bodyText": "Your understanding is correct. I added HashBasedNumberedPartialShardSpec and SingleDimensionPartialShardSpec in #7547 but they are not in use yet. They will be used once we support append with non-dynamic or non-dynamic with segment locking.", "url": "https://github.com/apache/druid/pull/10033#discussion_r445310170", "createdAt": "2020-06-25T05:10:22Z", "author": {"login": "jihoonson"}, "path": "server/src/test/java/org/apache/druid/server/shard/SingleDimensionShardSpecTest.java", "diffHunk": "@@ -142,6 +146,16 @@ public void testPossibleInDomain()\n     Assert.assertTrue(shard7.possibleInDomain(domain2));\n   }\n \n+  @Test\n+  public void testSharePartitionSpace()\n+  {\n+    final SingleDimensionShardSpec shardSpec = makeSpec(\"start\", \"end\");\n+    Assert.assertTrue(shardSpec.sharePartitionSpace(NumberedPartialShardSpec.instance()));\n+    Assert.assertTrue(shardSpec.sharePartitionSpace(new HashBasedNumberedPartialShardSpec(null, 0, 1)));\n+    Assert.assertTrue(shardSpec.sharePartitionSpace(new SingleDimensionPartialShardSpec(\"dim\", 0, null, null, 1)));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDcyNzgwNQ=="}, "originalCommit": {"oid": "b423e964d258d2ba2f9760fa3224026157e98d0d"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc3Mzk0MTU0OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/org/apache/druid/timeline/partition/ShardSpec.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQyMjowMDowNFrOGoknBw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNVQwNToxMDoyNVrOGork5w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTE5NjAzOQ==", "bodyText": "Should this be partialShardSpec.useNonRootGenerationPartitionSpace(); instead of !partialShardSpec.useNonRootGenerationPartitionSpace(); ?", "url": "https://github.com/apache/druid/pull/10033#discussion_r445196039", "createdAt": "2020-06-24T22:00:04Z", "author": {"login": "maytasm"}, "path": "core/src/main/java/org/apache/druid/timeline/partition/ShardSpec.java", "diffHunk": "@@ -125,8 +125,13 @@ default short getAtomicUpdateGroupSize()\n   boolean possibleInDomain(Map<String, RangeSet<String>> domain);\n \n   /**\n-   * Returns true if two segments of this and other shardSpecs can exist in the same time chunk.\n+   * Returns true if this shardSpec and the given {@link PartialShardSpec} share the same partition space.\n+   * Any implementation of {@link OverwriteShardSpec} should return true.\n+   *\n+   * @see PartitionIds\n    */\n-  @JsonIgnore\n-  boolean isCompatible(Class<? extends ShardSpec> other);\n+  default boolean sharePartitionSpace(PartialShardSpec partialShardSpec)\n+  {\n+    return !partialShardSpec.useNonRootGenerationPartitionSpace();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b423e964d258d2ba2f9760fa3224026157e98d0d"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTIxODkwNQ==", "bodyText": "Seems like the java doc for ShardSpec#sharePartitionSpace and OverwriteShardSpec#sharePartitionSpace should be updated", "url": "https://github.com/apache/druid/pull/10033#discussion_r445218905", "createdAt": "2020-06-24T23:05:46Z", "author": {"login": "maytasm"}, "path": "core/src/main/java/org/apache/druid/timeline/partition/ShardSpec.java", "diffHunk": "@@ -125,8 +125,13 @@ default short getAtomicUpdateGroupSize()\n   boolean possibleInDomain(Map<String, RangeSet<String>> domain);\n \n   /**\n-   * Returns true if two segments of this and other shardSpecs can exist in the same time chunk.\n+   * Returns true if this shardSpec and the given {@link PartialShardSpec} share the same partition space.\n+   * Any implementation of {@link OverwriteShardSpec} should return true.\n+   *\n+   * @see PartitionIds\n    */\n-  @JsonIgnore\n-  boolean isCompatible(Class<? extends ShardSpec> other);\n+  default boolean sharePartitionSpace(PartialShardSpec partialShardSpec)\n+  {\n+    return !partialShardSpec.useNonRootGenerationPartitionSpace();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTE5NjAzOQ=="}, "originalCommit": {"oid": "b423e964d258d2ba2f9760fa3224026157e98d0d"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTMxMDE4Mw==", "bodyText": "Ah, all ShardSpecs share the same root-generation partition space except OverwriteShardSpec. So, the current code is correct. I updated the javadoc to make it more clear.", "url": "https://github.com/apache/druid/pull/10033#discussion_r445310183", "createdAt": "2020-06-25T05:10:25Z", "author": {"login": "jihoonson"}, "path": "core/src/main/java/org/apache/druid/timeline/partition/ShardSpec.java", "diffHunk": "@@ -125,8 +125,13 @@ default short getAtomicUpdateGroupSize()\n   boolean possibleInDomain(Map<String, RangeSet<String>> domain);\n \n   /**\n-   * Returns true if two segments of this and other shardSpecs can exist in the same time chunk.\n+   * Returns true if this shardSpec and the given {@link PartialShardSpec} share the same partition space.\n+   * Any implementation of {@link OverwriteShardSpec} should return true.\n+   *\n+   * @see PartitionIds\n    */\n-  @JsonIgnore\n-  boolean isCompatible(Class<? extends ShardSpec> other);\n+  default boolean sharePartitionSpace(PartialShardSpec partialShardSpec)\n+  {\n+    return !partialShardSpec.useNonRootGenerationPartitionSpace();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTE5NjAzOQ=="}, "originalCommit": {"oid": "b423e964d258d2ba2f9760fa3224026157e98d0d"}, "originalPosition": 14}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2332, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}