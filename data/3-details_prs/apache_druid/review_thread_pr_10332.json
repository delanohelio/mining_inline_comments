{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDc1NjYxNzg0", "number": 10332, "reviewThreads": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQyMjozNzo1M1rOEfuxEw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQyMzoyNjo0NFrOEfwX8Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAxNzA3NTM5OnYy", "diffSide": "RIGHT", "path": "integration-tests/src/test/resources/indexer/wikipedia_merge_index_task.json", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQyMjozNzo1M1rOHMMq8Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQyMzoyMjozM1rOHMPPXQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjU1MjU2MQ==", "bodyText": "Can we add these to wikipedia_index_task.json instead. This way we don't need to run another integration test which can be quite slow\nYou will probably want to do something very similar to #9277", "url": "https://github.com/apache/druid/pull/10332#discussion_r482552561", "createdAt": "2020-09-02T22:37:53Z", "author": {"login": "suneet-s"}, "path": "integration-tests/src/test/resources/indexer/wikipedia_merge_index_task.json", "diffHunk": "@@ -0,0 +1,70 @@\n+{\n+    \"type\": \"index\",\n+    \"spec\": {\n+        \"dataSchema\": {\n+            \"dataSource\": \"%%DATASOURCE%%\",\n+            \"metricsSpec\": [\n+                {\n+                    \"type\": \"count\",\n+                    \"name\": \"count\"\n+                },\n+                {\n+                    \"type\": \"doubleSum\",\n+                    \"name\": \"added\",\n+                    \"fieldName\": \"added\"\n+                },\n+                {\n+                    \"type\": \"doubleSum\",\n+                    \"name\": \"deleted\",\n+                    \"fieldName\": \"deleted\"\n+                },\n+                {\n+                    \"type\": \"doubleSum\",\n+                    \"name\": \"delta\",\n+                    \"fieldName\": \"delta\"\n+                },\n+                {\n+                    \"type\": \"stringFirst\",\n+                    \"name\": \"first_user\",\n+                    \"fieldName\": \"user\"\n+                },\n+                {\n+                    \"type\": \"stringLast\",\n+                    \"name\": \"last_user\",\n+                    \"fieldName\": \"user\"\n+                }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f14dd8aef85d51c4d574cc555f9749cfa6215c3c"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjU4OTQ0NA==", "bodyText": "The issue described in #7243 requires a trigger of merging of two index files, which will in turn cause a rollup of two rows. I wasn't able to trigger that in wikipedia_index_task.json. This is why I added a new task to capture this case.", "url": "https://github.com/apache/druid/pull/10332#discussion_r482589444", "createdAt": "2020-09-02T23:14:58Z", "author": {"login": "joykent99"}, "path": "integration-tests/src/test/resources/indexer/wikipedia_merge_index_task.json", "diffHunk": "@@ -0,0 +1,70 @@\n+{\n+    \"type\": \"index\",\n+    \"spec\": {\n+        \"dataSchema\": {\n+            \"dataSource\": \"%%DATASOURCE%%\",\n+            \"metricsSpec\": [\n+                {\n+                    \"type\": \"count\",\n+                    \"name\": \"count\"\n+                },\n+                {\n+                    \"type\": \"doubleSum\",\n+                    \"name\": \"added\",\n+                    \"fieldName\": \"added\"\n+                },\n+                {\n+                    \"type\": \"doubleSum\",\n+                    \"name\": \"deleted\",\n+                    \"fieldName\": \"deleted\"\n+                },\n+                {\n+                    \"type\": \"doubleSum\",\n+                    \"name\": \"delta\",\n+                    \"fieldName\": \"delta\"\n+                },\n+                {\n+                    \"type\": \"stringFirst\",\n+                    \"name\": \"first_user\",\n+                    \"fieldName\": \"user\"\n+                },\n+                {\n+                    \"type\": \"stringLast\",\n+                    \"name\": \"last_user\",\n+                    \"fieldName\": \"user\"\n+                }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjU1MjU2MQ=="}, "originalCommit": {"oid": "f14dd8aef85d51c4d574cc555f9749cfa6215c3c"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjU5NDY1Mw==", "bodyText": "I also added these in wikipedia_index_task.json, which led me to discover the issue with StringFirstAggregatorFactory.combine() below.", "url": "https://github.com/apache/druid/pull/10332#discussion_r482594653", "createdAt": "2020-09-02T23:22:33Z", "author": {"login": "joykent99"}, "path": "integration-tests/src/test/resources/indexer/wikipedia_merge_index_task.json", "diffHunk": "@@ -0,0 +1,70 @@\n+{\n+    \"type\": \"index\",\n+    \"spec\": {\n+        \"dataSchema\": {\n+            \"dataSource\": \"%%DATASOURCE%%\",\n+            \"metricsSpec\": [\n+                {\n+                    \"type\": \"count\",\n+                    \"name\": \"count\"\n+                },\n+                {\n+                    \"type\": \"doubleSum\",\n+                    \"name\": \"added\",\n+                    \"fieldName\": \"added\"\n+                },\n+                {\n+                    \"type\": \"doubleSum\",\n+                    \"name\": \"deleted\",\n+                    \"fieldName\": \"deleted\"\n+                },\n+                {\n+                    \"type\": \"doubleSum\",\n+                    \"name\": \"delta\",\n+                    \"fieldName\": \"delta\"\n+                },\n+                {\n+                    \"type\": \"stringFirst\",\n+                    \"name\": \"first_user\",\n+                    \"fieldName\": \"user\"\n+                },\n+                {\n+                    \"type\": \"stringLast\",\n+                    \"name\": \"last_user\",\n+                    \"fieldName\": \"user\"\n+                }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjU1MjU2MQ=="}, "originalCommit": {"oid": "f14dd8aef85d51c4d574cc555f9749cfa6215c3c"}, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAxNzE1ODA4OnYy", "diffSide": "RIGHT", "path": "processing/src/main/java/org/apache/druid/query/aggregation/first/StringFirstAggregatorFactory.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQyMjo0OTozM1rOHMNiLg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQyMzoxNTo1MFrOHMO9Xg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjU2NjcwMg==", "bodyText": "wow! Is there a test for this somewhere?", "url": "https://github.com/apache/druid/pull/10332#discussion_r482566702", "createdAt": "2020-09-02T22:49:33Z", "author": {"login": "suneet-s"}, "path": "processing/src/main/java/org/apache/druid/query/aggregation/first/StringFirstAggregatorFactory.java", "diffHunk": "@@ -188,7 +188,7 @@ public Comparator getComparator()\n   @Override\n   public Object combine(Object lhs, Object rhs)\n   {\n-    return TIME_COMPARATOR.compare(lhs, rhs) > 0 ? lhs : rhs;\n+    return TIME_COMPARATOR.compare(lhs, rhs) < 0 ? lhs : rhs;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f14dd8aef85d51c4d574cc555f9749cfa6215c3c"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjU5MDA0Ng==", "bodyText": "Yes. The existing test case was testing the wrong behavior. The fix to the test is also in this PR.", "url": "https://github.com/apache/druid/pull/10332#discussion_r482590046", "createdAt": "2020-09-02T23:15:50Z", "author": {"login": "joykent99"}, "path": "processing/src/main/java/org/apache/druid/query/aggregation/first/StringFirstAggregatorFactory.java", "diffHunk": "@@ -188,7 +188,7 @@ public Comparator getComparator()\n   @Override\n   public Object combine(Object lhs, Object rhs)\n   {\n-    return TIME_COMPARATOR.compare(lhs, rhs) > 0 ? lhs : rhs;\n+    return TIME_COMPARATOR.compare(lhs, rhs) < 0 ? lhs : rhs;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjU2NjcwMg=="}, "originalCommit": {"oid": "f14dd8aef85d51c4d574cc555f9749cfa6215c3c"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAxNzE3MzA1OnYy", "diffSide": "RIGHT", "path": "sql/src/main/java/org/apache/druid/sql/calcite/aggregation/builtin/EarliestLatestAnySqlAggregator.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQyMjo1MTo0M1rOHMNsYg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQyMzoxNjo0NFrOHMO_xA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjU2OTMxNA==", "bodyText": "We should reuse this instance across all calls to toDruidAggregation", "url": "https://github.com/apache/druid/pull/10332#discussion_r482569314", "createdAt": "2020-09-02T22:51:43Z", "author": {"login": "suneet-s"}, "path": "sql/src/main/java/org/apache/druid/sql/calcite/aggregation/builtin/EarliestLatestAnySqlAggregator.java", "diffHunk": "@@ -227,14 +257,14 @@ public Aggregation toDruidAggregation(\n           aggregatorType.name(),\n           null,\n           SqlKind.OTHER_FUNCTION,\n-          ReturnTypes.ARG0,\n+          new EarliestLatestReturnTypeInference(0),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f14dd8aef85d51c4d574cc555f9749cfa6215c3c"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjU5MDY2MA==", "bodyText": "Sounds good.", "url": "https://github.com/apache/druid/pull/10332#discussion_r482590660", "createdAt": "2020-09-02T23:16:44Z", "author": {"login": "joykent99"}, "path": "sql/src/main/java/org/apache/druid/sql/calcite/aggregation/builtin/EarliestLatestAnySqlAggregator.java", "diffHunk": "@@ -227,14 +257,14 @@ public Aggregation toDruidAggregation(\n           aggregatorType.name(),\n           null,\n           SqlKind.OTHER_FUNCTION,\n-          ReturnTypes.ARG0,\n+          new EarliestLatestReturnTypeInference(0),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjU2OTMxNA=="}, "originalCommit": {"oid": "f14dd8aef85d51c4d574cc555f9749cfa6215c3c"}, "originalPosition": 69}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAxNzE3Nzc1OnYy", "diffSide": "RIGHT", "path": "sql/src/main/java/org/apache/druid/sql/calcite/aggregation/builtin/EarliestLatestAnySqlAggregator.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQyMjo1MjoyMlrOHMNvcg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxOTowOTo0NVrOHOqdgA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjU3MDA5OA==", "bodyText": "shouldn't this remain STRING ?", "url": "https://github.com/apache/druid/pull/10332#discussion_r482570098", "createdAt": "2020-09-02T22:52:22Z", "author": {"login": "suneet-s"}, "path": "sql/src/main/java/org/apache/druid/sql/calcite/aggregation/builtin/EarliestLatestAnySqlAggregator.java", "diffHunk": "@@ -227,14 +257,14 @@ public Aggregation toDruidAggregation(\n           aggregatorType.name(),\n           null,\n           SqlKind.OTHER_FUNCTION,\n-          ReturnTypes.ARG0,\n+          new EarliestLatestReturnTypeInference(0),\n           InferTypes.RETURN_TYPE,\n           OperandTypes.or(\n               OperandTypes.NUMERIC,\n               OperandTypes.BOOLEAN,\n               OperandTypes.sequence(\n                   \"'\" + aggregatorType.name() + \"(expr, maxBytesPerString)'\\n\",\n-                  OperandTypes.STRING,\n+                  OperandTypes.ANY,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f14dd8aef85d51c4d574cc555f9749cfa6215c3c"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjU5MTkxNA==", "bodyText": "When we specify \"stringFirst/stringLast\" in ingestion MetricsSpec, the type for the columns stored in segments is OTHER. With STRING type here, the SQL will report an error when trying to call earliest/latest on those columns.", "url": "https://github.com/apache/druid/pull/10332#discussion_r482591914", "createdAt": "2020-09-02T23:18:38Z", "author": {"login": "joykent99"}, "path": "sql/src/main/java/org/apache/druid/sql/calcite/aggregation/builtin/EarliestLatestAnySqlAggregator.java", "diffHunk": "@@ -227,14 +257,14 @@ public Aggregation toDruidAggregation(\n           aggregatorType.name(),\n           null,\n           SqlKind.OTHER_FUNCTION,\n-          ReturnTypes.ARG0,\n+          new EarliestLatestReturnTypeInference(0),\n           InferTypes.RETURN_TYPE,\n           OperandTypes.or(\n               OperandTypes.NUMERIC,\n               OperandTypes.BOOLEAN,\n               OperandTypes.sequence(\n                   \"'\" + aggregatorType.name() + \"(expr, maxBytesPerString)'\\n\",\n-                  OperandTypes.STRING,\n+                  OperandTypes.ANY,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjU3MDA5OA=="}, "originalCommit": {"oid": "f14dd8aef85d51c4d574cc555f9749cfa6215c3c"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjU5MzI5NQ==", "bodyText": "If you have any suggestions on where is a good place to add a test for this, that would be great!", "url": "https://github.com/apache/druid/pull/10332#discussion_r482593295", "createdAt": "2020-09-02T23:20:34Z", "author": {"login": "joykent99"}, "path": "sql/src/main/java/org/apache/druid/sql/calcite/aggregation/builtin/EarliestLatestAnySqlAggregator.java", "diffHunk": "@@ -227,14 +257,14 @@ public Aggregation toDruidAggregation(\n           aggregatorType.name(),\n           null,\n           SqlKind.OTHER_FUNCTION,\n-          ReturnTypes.ARG0,\n+          new EarliestLatestReturnTypeInference(0),\n           InferTypes.RETURN_TYPE,\n           OperandTypes.or(\n               OperandTypes.NUMERIC,\n               OperandTypes.BOOLEAN,\n               OperandTypes.sequence(\n                   \"'\" + aggregatorType.name() + \"(expr, maxBytesPerString)'\\n\",\n-                  OperandTypes.STRING,\n+                  OperandTypes.ANY,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjU3MDA5OA=="}, "originalCommit": {"oid": "f14dd8aef85d51c4d574cc555f9749cfa6215c3c"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTEzNzc5Mg==", "bodyText": "Usually I sql add tests to CalciteQueryTest You can see testEarliestAggregators as an example. You could write a test in here to validate the SQL translation works, but I think you need to update CalciteTests#INDEX_SCHEMA_DIFFERENT_DIM3_M1_TYPES to add an earliest / latest aggregator. Then you should be able to test a SQL test in CalciteQueryTest - hope this helps", "url": "https://github.com/apache/druid/pull/10332#discussion_r485137792", "createdAt": "2020-09-08T19:09:45Z", "author": {"login": "suneet-s"}, "path": "sql/src/main/java/org/apache/druid/sql/calcite/aggregation/builtin/EarliestLatestAnySqlAggregator.java", "diffHunk": "@@ -227,14 +257,14 @@ public Aggregation toDruidAggregation(\n           aggregatorType.name(),\n           null,\n           SqlKind.OTHER_FUNCTION,\n-          ReturnTypes.ARG0,\n+          new EarliestLatestReturnTypeInference(0),\n           InferTypes.RETURN_TYPE,\n           OperandTypes.or(\n               OperandTypes.NUMERIC,\n               OperandTypes.BOOLEAN,\n               OperandTypes.sequence(\n                   \"'\" + aggregatorType.name() + \"(expr, maxBytesPerString)'\\n\",\n-                  OperandTypes.STRING,\n+                  OperandTypes.ANY,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjU3MDA5OA=="}, "originalCommit": {"oid": "f14dd8aef85d51c4d574cc555f9749cfa6215c3c"}, "originalPosition": 77}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAxNzMzODczOnYy", "diffSide": "RIGHT", "path": "processing/src/test/java/org/apache/druid/query/aggregation/first/StringFirstAggregationTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQyMzoyNjo0NFrOHMPaTg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQyMzoyNjo0NFrOHMPaTg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjU5NzQ1NA==", "bodyText": "This is the fix to the existing test for StringFirstAggregatorFactory.combine() fixes.", "url": "https://github.com/apache/druid/pull/10332#discussion_r482597454", "createdAt": "2020-09-02T23:26:44Z", "author": {"login": "joykent99"}, "path": "processing/src/test/java/org/apache/druid/query/aggregation/first/StringFirstAggregationTest.java", "diffHunk": "@@ -115,7 +117,7 @@ public void testCombine()\n   {\n     SerializablePairLongString pair1 = new SerializablePairLongString(1467225000L, \"AAAA\");\n     SerializablePairLongString pair2 = new SerializablePairLongString(1467240000L, \"BBBB\");\n-    Assert.assertEquals(pair2, stringFirstAggFactory.combine(pair1, pair2));\n+    Assert.assertEquals(pair1, stringFirstAggFactory.combine(pair1, pair2));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f14dd8aef85d51c4d574cc555f9749cfa6215c3c"}, "originalPosition": 21}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3132, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}