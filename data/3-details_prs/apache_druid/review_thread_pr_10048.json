{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDM2MTY2NzAz", "number": 10048, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQwNzoyODoyM1rOEGoZ2w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQxODoxODoxMFrOEG3KyQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1Mzg4ODkxOnYy", "diffSide": "RIGHT", "path": "server/src/test/java/org/apache/druid/server/coordinator/DruidCoordinatorTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQwNzoyODoyM1rOGli6lA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQwODo0NzoxN1rOGlluwA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjAyMjU0OA==", "bodyText": "It's probably worth making a method that takes a CountDownLatch and a DruidServer and does the thing going on here (and in a few other tests)", "url": "https://github.com/apache/druid/pull/10048#discussion_r442022548", "createdAt": "2020-06-18T07:28:23Z", "author": {"login": "clintropolis"}, "path": "server/src/test/java/org/apache/druid/server/coordinator/DruidCoordinatorTest.java", "diffHunk": "@@ -550,6 +551,241 @@ public void testCoordinatorTieredRun() throws Exception\n     EasyMock.verify(metadataRuleManager);\n   }\n \n+  @Test(timeout = 60_000L)\n+  public void testComputeUnderReplicationCountsPerDataSourcePerTierForSegmentsWithBroadcastRule() throws Exception\n+  {\n+    final String dataSource = \"dataSource\";\n+    final String hotTierName = \"hot\";\n+    final String coldTierName = \"cold\";\n+    final String tierName1 = \"tier1\";\n+    final String tierName2 = \"tier2\";\n+    final Rule broadcastDistributionRule = new ForeverBroadcastDistributionRule();\n+    final String loadPathCold = \"/druid/loadqueue/cold:1234\";\n+    final String loadPathBroker1 = \"/druid/loadqueue/broker1:1234\";\n+    final String loadPathBroker2 = \"/druid/loadqueue/broker2:1234\";\n+    final String loadPathPeon = \"/druid/loadqueue/peon:1234\";\n+    final DruidServer hotServer = new DruidServer(\"hot\", \"hot\", null, 5L, ServerType.HISTORICAL, hotTierName, 0);\n+    final DruidServer coldServer = new DruidServer(\"cold\", \"cold\", null, 5L, ServerType.HISTORICAL, coldTierName, 0);\n+    final DruidServer brokerServer1 = new DruidServer(\"broker1\", \"broker1\", null, 5L, ServerType.BROKER, tierName1, 0);\n+    final DruidServer brokerServer2 = new DruidServer(\"broker2\", \"broker2\", null, 5L, ServerType.BROKER, tierName2, 0);\n+    final DruidServer peonServer = new DruidServer(\"peon\", \"peon\", null, 5L, ServerType.INDEXER_EXECUTOR, tierName2, 0);\n+\n+    final Map<String, DataSegment> dataSegments = ImmutableMap.of(\n+        \"2018-01-02T00:00:00.000Z_2018-01-03T00:00:00.000Z\",\n+        new DataSegment(dataSource, Intervals.of(\"2018-01-02/P1D\"), \"v1\", null, null, null, null, 0x9, 0),\n+        \"2018-01-03T00:00:00.000Z_2018-01-04T00:00:00.000Z\",\n+        new DataSegment(dataSource, Intervals.of(\"2018-01-03/P1D\"), \"v1\", null, null, null, null, 0x9, 0),\n+        \"2017-01-01T00:00:00.000Z_2017-01-02T00:00:00.000Z\",\n+        new DataSegment(dataSource, Intervals.of(\"2017-01-01/P1D\"), \"v1\", null, null, null, null, 0x9, 0)\n+    );\n+\n+    final LoadQueuePeon loadQueuePeonCold = new CuratorLoadQueuePeon(\n+        curator,\n+        loadPathCold,\n+        objectMapper,\n+        Execs.scheduledSingleThreaded(\"coordinator_test_load_queue_peon_cold_scheduled-%d\"),\n+        Execs.singleThreaded(\"coordinator_test_load_queue_peon_cold-%d\"),\n+        druidCoordinatorConfig\n+    );\n+\n+    final LoadQueuePeon loadQueuePeonBroker1 = new CuratorLoadQueuePeon(\n+        curator,\n+        loadPathBroker1,\n+        objectMapper,\n+        Execs.scheduledSingleThreaded(\"coordinator_test_load_queue_peon_broker1_scheduled-%d\"),\n+        Execs.singleThreaded(\"coordinator_test_load_queue_peon_broker1-%d\"),\n+        druidCoordinatorConfig\n+    );\n+\n+    final LoadQueuePeon loadQueuePeonBroker2 = new CuratorLoadQueuePeon(\n+        curator,\n+        loadPathBroker2,\n+        objectMapper,\n+        Execs.scheduledSingleThreaded(\"coordinator_test_load_queue_peon_broker2_scheduled-%d\"),\n+        Execs.singleThreaded(\"coordinator_test_load_queue_peon_broker2-%d\"),\n+        druidCoordinatorConfig\n+    );\n+\n+    final LoadQueuePeon loadQueuePeonPoenServer = new CuratorLoadQueuePeon(\n+        curator,\n+        loadPathPeon,\n+        objectMapper,\n+        Execs.scheduledSingleThreaded(\"coordinator_test_load_queue_peon_peon_scheduled-%d\"),\n+        Execs.singleThreaded(\"coordinator_test_load_queue_peon_peon-%d\"),\n+        druidCoordinatorConfig\n+    );\n+    final PathChildrenCache pathChildrenCacheCold = new PathChildrenCache(\n+        curator,\n+        loadPathCold,\n+        true,\n+        true,\n+        Execs.singleThreaded(\"coordinator_test_path_children_cache_cold-%d\")\n+    );\n+    final PathChildrenCache pathChildrenCacheBroker1 = new PathChildrenCache(\n+        curator,\n+        loadPathBroker1,\n+        true,\n+        true,\n+        Execs.singleThreaded(\"coordinator_test_path_children_cache_broker1-%d\")\n+    );\n+    final PathChildrenCache pathChildrenCacheBroker2 = new PathChildrenCache(\n+        curator,\n+        loadPathBroker2,\n+        true,\n+        true,\n+        Execs.singleThreaded(\"coordinator_test_path_children_cache_broker2-%d\")\n+    );\n+    final PathChildrenCache pathChildrenCachePeon = new PathChildrenCache(\n+        curator,\n+        loadPathPeon,\n+        true,\n+        true,\n+        Execs.singleThreaded(\"coordinator_test_path_children_cache_peon-%d\")\n+    );\n+\n+    loadManagementPeons.putAll(ImmutableMap.of(\"hot\", loadQueuePeon,\n+                                               \"cold\", loadQueuePeonCold,\n+                                               \"broker1\", loadQueuePeonBroker1,\n+                                               \"broker2\", loadQueuePeonBroker2,\n+                                               \"peon\", loadQueuePeonPoenServer));\n+\n+    loadQueuePeonCold.start();\n+    loadQueuePeonBroker1.start();\n+    loadQueuePeonBroker2.start();\n+    loadQueuePeonPoenServer.start();\n+    pathChildrenCache.start();\n+    pathChildrenCacheCold.start();\n+    pathChildrenCacheBroker1.start();\n+    pathChildrenCacheBroker2.start();\n+    pathChildrenCachePeon.start();\n+\n+    DruidDataSource[] druidDataSources = {new DruidDataSource(dataSource, Collections.emptyMap())};\n+    dataSegments.values().forEach(druidDataSources[0]::addSegment);\n+\n+    setupSegmentsMetadataMock(druidDataSources[0]);\n+\n+    EasyMock.expect(metadataRuleManager.getRulesWithDefault(EasyMock.anyString()))\n+            .andReturn(ImmutableList.of(broadcastDistributionRule)).atLeastOnce();\n+    EasyMock.expect(metadataRuleManager.getAllRules())\n+            .andReturn(ImmutableMap.of(dataSource, ImmutableList.of(broadcastDistributionRule))).atLeastOnce();\n+\n+    EasyMock.expect(serverInventoryView.getInventory())\n+            .andReturn(ImmutableList.of(hotServer, coldServer, brokerServer1, brokerServer2, peonServer))\n+            .atLeastOnce();\n+    EasyMock.expect(serverInventoryView.isStarted()).andReturn(true).anyTimes();\n+\n+    EasyMock.replay(metadataRuleManager, serverInventoryView);\n+\n+    coordinator.start();\n+    leaderAnnouncerLatch.await(); // Wait for this coordinator to become leader\n+\n+    final CountDownLatch assignSegmentLatchHot = new CountDownLatch(1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fff1d86a20302aac9030ccf32bd50abf7033177a"}, "originalPosition": 140}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjA2ODY3Mg==", "bodyText": "Done", "url": "https://github.com/apache/druid/pull/10048#discussion_r442068672", "createdAt": "2020-06-18T08:47:17Z", "author": {"login": "maytasm"}, "path": "server/src/test/java/org/apache/druid/server/coordinator/DruidCoordinatorTest.java", "diffHunk": "@@ -550,6 +551,241 @@ public void testCoordinatorTieredRun() throws Exception\n     EasyMock.verify(metadataRuleManager);\n   }\n \n+  @Test(timeout = 60_000L)\n+  public void testComputeUnderReplicationCountsPerDataSourcePerTierForSegmentsWithBroadcastRule() throws Exception\n+  {\n+    final String dataSource = \"dataSource\";\n+    final String hotTierName = \"hot\";\n+    final String coldTierName = \"cold\";\n+    final String tierName1 = \"tier1\";\n+    final String tierName2 = \"tier2\";\n+    final Rule broadcastDistributionRule = new ForeverBroadcastDistributionRule();\n+    final String loadPathCold = \"/druid/loadqueue/cold:1234\";\n+    final String loadPathBroker1 = \"/druid/loadqueue/broker1:1234\";\n+    final String loadPathBroker2 = \"/druid/loadqueue/broker2:1234\";\n+    final String loadPathPeon = \"/druid/loadqueue/peon:1234\";\n+    final DruidServer hotServer = new DruidServer(\"hot\", \"hot\", null, 5L, ServerType.HISTORICAL, hotTierName, 0);\n+    final DruidServer coldServer = new DruidServer(\"cold\", \"cold\", null, 5L, ServerType.HISTORICAL, coldTierName, 0);\n+    final DruidServer brokerServer1 = new DruidServer(\"broker1\", \"broker1\", null, 5L, ServerType.BROKER, tierName1, 0);\n+    final DruidServer brokerServer2 = new DruidServer(\"broker2\", \"broker2\", null, 5L, ServerType.BROKER, tierName2, 0);\n+    final DruidServer peonServer = new DruidServer(\"peon\", \"peon\", null, 5L, ServerType.INDEXER_EXECUTOR, tierName2, 0);\n+\n+    final Map<String, DataSegment> dataSegments = ImmutableMap.of(\n+        \"2018-01-02T00:00:00.000Z_2018-01-03T00:00:00.000Z\",\n+        new DataSegment(dataSource, Intervals.of(\"2018-01-02/P1D\"), \"v1\", null, null, null, null, 0x9, 0),\n+        \"2018-01-03T00:00:00.000Z_2018-01-04T00:00:00.000Z\",\n+        new DataSegment(dataSource, Intervals.of(\"2018-01-03/P1D\"), \"v1\", null, null, null, null, 0x9, 0),\n+        \"2017-01-01T00:00:00.000Z_2017-01-02T00:00:00.000Z\",\n+        new DataSegment(dataSource, Intervals.of(\"2017-01-01/P1D\"), \"v1\", null, null, null, null, 0x9, 0)\n+    );\n+\n+    final LoadQueuePeon loadQueuePeonCold = new CuratorLoadQueuePeon(\n+        curator,\n+        loadPathCold,\n+        objectMapper,\n+        Execs.scheduledSingleThreaded(\"coordinator_test_load_queue_peon_cold_scheduled-%d\"),\n+        Execs.singleThreaded(\"coordinator_test_load_queue_peon_cold-%d\"),\n+        druidCoordinatorConfig\n+    );\n+\n+    final LoadQueuePeon loadQueuePeonBroker1 = new CuratorLoadQueuePeon(\n+        curator,\n+        loadPathBroker1,\n+        objectMapper,\n+        Execs.scheduledSingleThreaded(\"coordinator_test_load_queue_peon_broker1_scheduled-%d\"),\n+        Execs.singleThreaded(\"coordinator_test_load_queue_peon_broker1-%d\"),\n+        druidCoordinatorConfig\n+    );\n+\n+    final LoadQueuePeon loadQueuePeonBroker2 = new CuratorLoadQueuePeon(\n+        curator,\n+        loadPathBroker2,\n+        objectMapper,\n+        Execs.scheduledSingleThreaded(\"coordinator_test_load_queue_peon_broker2_scheduled-%d\"),\n+        Execs.singleThreaded(\"coordinator_test_load_queue_peon_broker2-%d\"),\n+        druidCoordinatorConfig\n+    );\n+\n+    final LoadQueuePeon loadQueuePeonPoenServer = new CuratorLoadQueuePeon(\n+        curator,\n+        loadPathPeon,\n+        objectMapper,\n+        Execs.scheduledSingleThreaded(\"coordinator_test_load_queue_peon_peon_scheduled-%d\"),\n+        Execs.singleThreaded(\"coordinator_test_load_queue_peon_peon-%d\"),\n+        druidCoordinatorConfig\n+    );\n+    final PathChildrenCache pathChildrenCacheCold = new PathChildrenCache(\n+        curator,\n+        loadPathCold,\n+        true,\n+        true,\n+        Execs.singleThreaded(\"coordinator_test_path_children_cache_cold-%d\")\n+    );\n+    final PathChildrenCache pathChildrenCacheBroker1 = new PathChildrenCache(\n+        curator,\n+        loadPathBroker1,\n+        true,\n+        true,\n+        Execs.singleThreaded(\"coordinator_test_path_children_cache_broker1-%d\")\n+    );\n+    final PathChildrenCache pathChildrenCacheBroker2 = new PathChildrenCache(\n+        curator,\n+        loadPathBroker2,\n+        true,\n+        true,\n+        Execs.singleThreaded(\"coordinator_test_path_children_cache_broker2-%d\")\n+    );\n+    final PathChildrenCache pathChildrenCachePeon = new PathChildrenCache(\n+        curator,\n+        loadPathPeon,\n+        true,\n+        true,\n+        Execs.singleThreaded(\"coordinator_test_path_children_cache_peon-%d\")\n+    );\n+\n+    loadManagementPeons.putAll(ImmutableMap.of(\"hot\", loadQueuePeon,\n+                                               \"cold\", loadQueuePeonCold,\n+                                               \"broker1\", loadQueuePeonBroker1,\n+                                               \"broker2\", loadQueuePeonBroker2,\n+                                               \"peon\", loadQueuePeonPoenServer));\n+\n+    loadQueuePeonCold.start();\n+    loadQueuePeonBroker1.start();\n+    loadQueuePeonBroker2.start();\n+    loadQueuePeonPoenServer.start();\n+    pathChildrenCache.start();\n+    pathChildrenCacheCold.start();\n+    pathChildrenCacheBroker1.start();\n+    pathChildrenCacheBroker2.start();\n+    pathChildrenCachePeon.start();\n+\n+    DruidDataSource[] druidDataSources = {new DruidDataSource(dataSource, Collections.emptyMap())};\n+    dataSegments.values().forEach(druidDataSources[0]::addSegment);\n+\n+    setupSegmentsMetadataMock(druidDataSources[0]);\n+\n+    EasyMock.expect(metadataRuleManager.getRulesWithDefault(EasyMock.anyString()))\n+            .andReturn(ImmutableList.of(broadcastDistributionRule)).atLeastOnce();\n+    EasyMock.expect(metadataRuleManager.getAllRules())\n+            .andReturn(ImmutableMap.of(dataSource, ImmutableList.of(broadcastDistributionRule))).atLeastOnce();\n+\n+    EasyMock.expect(serverInventoryView.getInventory())\n+            .andReturn(ImmutableList.of(hotServer, coldServer, brokerServer1, brokerServer2, peonServer))\n+            .atLeastOnce();\n+    EasyMock.expect(serverInventoryView.isStarted()).andReturn(true).anyTimes();\n+\n+    EasyMock.replay(metadataRuleManager, serverInventoryView);\n+\n+    coordinator.start();\n+    leaderAnnouncerLatch.await(); // Wait for this coordinator to become leader\n+\n+    final CountDownLatch assignSegmentLatchHot = new CountDownLatch(1);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjAyMjU0OA=="}, "originalCommit": {"oid": "fff1d86a20302aac9030ccf32bd50abf7033177a"}, "originalPosition": 140}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1NjMwNzY1OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/druid/server/coordinator/DruidCoordinator.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQxODoxODowNlrOGl67cw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQxODo1NzowNlrOGl8NyA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQxNTk4Nw==", "bodyText": "In a previous PR there was a discussion about why it's ok for segmentReplicantLookup to be stale in this method:  https://github.com/apache/druid/pull/9965/files#r440541949\nWhat do you think about having that explanation as a code comment for this method?", "url": "https://github.com/apache/druid/pull/10048#discussion_r442415987", "createdAt": "2020-06-18T18:18:06Z", "author": {"login": "ccaominh"}, "path": "server/src/main/java/org/apache/druid/server/coordinator/DruidCoordinator.java", "diffHunk": "@@ -269,6 +270,13 @@ public boolean isLeader()\n   )\n   {\n     final Map<String, Object2LongMap<String>> underReplicationCountsPerDataSourcePerTier = new HashMap<>();\n+    final Set<String> decommissioningServers = getDynamicConfigs().getDecommissioningNodes();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "95e84176a929717500d79ccaa92814ce1d04034d"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQzNzA2NA==", "bodyText": "Done", "url": "https://github.com/apache/druid/pull/10048#discussion_r442437064", "createdAt": "2020-06-18T18:57:06Z", "author": {"login": "maytasm"}, "path": "server/src/main/java/org/apache/druid/server/coordinator/DruidCoordinator.java", "diffHunk": "@@ -269,6 +270,13 @@ public boolean isLeader()\n   )\n   {\n     final Map<String, Object2LongMap<String>> underReplicationCountsPerDataSourcePerTier = new HashMap<>();\n+    final Set<String> decommissioningServers = getDynamicConfigs().getDecommissioningNodes();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQxNTk4Nw=="}, "originalCommit": {"oid": "95e84176a929717500d79ccaa92814ce1d04034d"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc1NjMwNzkzOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/druid/server/coordinator/DruidCoordinator.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQxODoxODoxMFrOGl67og==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOVQwMjoxNjoxMlrOGmF3TA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQxNjAzNA==", "bodyText": "If Rule subclasses are added in the future and should be considered in this method, is there a test that will fail?", "url": "https://github.com/apache/druid/pull/10048#discussion_r442416034", "createdAt": "2020-06-18T18:18:10Z", "author": {"login": "ccaominh"}, "path": "server/src/main/java/org/apache/druid/server/coordinator/DruidCoordinator.java", "diffHunk": "@@ -280,20 +288,38 @@ public boolean isLeader()\n       final List<Rule> rules = metadataRuleManager.getRulesWithDefault(segment.getDataSource());\n \n       for (final Rule rule : rules) {\n-        if (!(rule instanceof LoadRule && rule.appliesTo(segment, now))) {\n+        if (!rule.appliesTo(segment, now)) {\n           continue;\n         }\n \n-        ((LoadRule) rule)\n-            .getTieredReplicants()\n-            .forEach((final String tier, final Integer ruleReplicants) -> {\n-              int currentReplicants = segmentReplicantLookup.getLoadedReplicants(segment.getId(), tier);\n-              Object2LongMap<String> underReplicationPerDataSource = underReplicationCountsPerDataSourcePerTier\n-                  .computeIfAbsent(tier, ignored -> new Object2LongOpenHashMap<>());\n+        if (rule instanceof LoadRule) {\n+          ((LoadRule) rule)\n+              .getTieredReplicants()\n+              .forEach((final String tier, final Integer ruleReplicants) -> {\n+                int currentReplicants = segmentReplicantLookup.getLoadedReplicants(segment.getId(), tier);\n+                Object2LongMap<String> underReplicationPerDataSource = underReplicationCountsPerDataSourcePerTier\n+                    .computeIfAbsent(tier, ignored -> new Object2LongOpenHashMap<>());\n+                ((Object2LongOpenHashMap<String>) underReplicationPerDataSource)\n+                    .addTo(segment.getDataSource(), Math.max(ruleReplicants - currentReplicants, 0));\n+              });\n+        }\n+\n+        if (rule instanceof BroadcastDistributionRule) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "95e84176a929717500d79ccaa92814ce1d04034d"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQ0MDM3NQ==", "bodyText": "Not right now. A Rule subclass may not always be needed to be considered in this method. Also not sure how the test will be able to automatically create new Rule subclass", "url": "https://github.com/apache/druid/pull/10048#discussion_r442440375", "createdAt": "2020-06-18T19:03:10Z", "author": {"login": "maytasm"}, "path": "server/src/main/java/org/apache/druid/server/coordinator/DruidCoordinator.java", "diffHunk": "@@ -280,20 +288,38 @@ public boolean isLeader()\n       final List<Rule> rules = metadataRuleManager.getRulesWithDefault(segment.getDataSource());\n \n       for (final Rule rule : rules) {\n-        if (!(rule instanceof LoadRule && rule.appliesTo(segment, now))) {\n+        if (!rule.appliesTo(segment, now)) {\n           continue;\n         }\n \n-        ((LoadRule) rule)\n-            .getTieredReplicants()\n-            .forEach((final String tier, final Integer ruleReplicants) -> {\n-              int currentReplicants = segmentReplicantLookup.getLoadedReplicants(segment.getId(), tier);\n-              Object2LongMap<String> underReplicationPerDataSource = underReplicationCountsPerDataSourcePerTier\n-                  .computeIfAbsent(tier, ignored -> new Object2LongOpenHashMap<>());\n+        if (rule instanceof LoadRule) {\n+          ((LoadRule) rule)\n+              .getTieredReplicants()\n+              .forEach((final String tier, final Integer ruleReplicants) -> {\n+                int currentReplicants = segmentReplicantLookup.getLoadedReplicants(segment.getId(), tier);\n+                Object2LongMap<String> underReplicationPerDataSource = underReplicationCountsPerDataSourcePerTier\n+                    .computeIfAbsent(tier, ignored -> new Object2LongOpenHashMap<>());\n+                ((Object2LongOpenHashMap<String>) underReplicationPerDataSource)\n+                    .addTo(segment.getDataSource(), Math.max(ruleReplicants - currentReplicants, 0));\n+              });\n+        }\n+\n+        if (rule instanceof BroadcastDistributionRule) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQxNjAzNA=="}, "originalCommit": {"oid": "95e84176a929717500d79ccaa92814ce1d04034d"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjU0NTY4Nw==", "bodyText": "Maybe adding some comments to somewhere like Rule will be sufficient for now. Not sure how likely we'll add future Rules, but if we do I think there's a good chance we'll forget to update this method if it's needed.", "url": "https://github.com/apache/druid/pull/10048#discussion_r442545687", "createdAt": "2020-06-18T23:01:10Z", "author": {"login": "ccaominh"}, "path": "server/src/main/java/org/apache/druid/server/coordinator/DruidCoordinator.java", "diffHunk": "@@ -280,20 +288,38 @@ public boolean isLeader()\n       final List<Rule> rules = metadataRuleManager.getRulesWithDefault(segment.getDataSource());\n \n       for (final Rule rule : rules) {\n-        if (!(rule instanceof LoadRule && rule.appliesTo(segment, now))) {\n+        if (!rule.appliesTo(segment, now)) {\n           continue;\n         }\n \n-        ((LoadRule) rule)\n-            .getTieredReplicants()\n-            .forEach((final String tier, final Integer ruleReplicants) -> {\n-              int currentReplicants = segmentReplicantLookup.getLoadedReplicants(segment.getId(), tier);\n-              Object2LongMap<String> underReplicationPerDataSource = underReplicationCountsPerDataSourcePerTier\n-                  .computeIfAbsent(tier, ignored -> new Object2LongOpenHashMap<>());\n+        if (rule instanceof LoadRule) {\n+          ((LoadRule) rule)\n+              .getTieredReplicants()\n+              .forEach((final String tier, final Integer ruleReplicants) -> {\n+                int currentReplicants = segmentReplicantLookup.getLoadedReplicants(segment.getId(), tier);\n+                Object2LongMap<String> underReplicationPerDataSource = underReplicationCountsPerDataSourcePerTier\n+                    .computeIfAbsent(tier, ignored -> new Object2LongOpenHashMap<>());\n+                ((Object2LongOpenHashMap<String>) underReplicationPerDataSource)\n+                    .addTo(segment.getDataSource(), Math.max(ruleReplicants - currentReplicants, 0));\n+              });\n+        }\n+\n+        if (rule instanceof BroadcastDistributionRule) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQxNjAzNA=="}, "originalCommit": {"oid": "95e84176a929717500d79ccaa92814ce1d04034d"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjU5NTE0OA==", "bodyText": "#10054", "url": "https://github.com/apache/druid/pull/10048#discussion_r442595148", "createdAt": "2020-06-19T02:16:12Z", "author": {"login": "maytasm"}, "path": "server/src/main/java/org/apache/druid/server/coordinator/DruidCoordinator.java", "diffHunk": "@@ -280,20 +288,38 @@ public boolean isLeader()\n       final List<Rule> rules = metadataRuleManager.getRulesWithDefault(segment.getDataSource());\n \n       for (final Rule rule : rules) {\n-        if (!(rule instanceof LoadRule && rule.appliesTo(segment, now))) {\n+        if (!rule.appliesTo(segment, now)) {\n           continue;\n         }\n \n-        ((LoadRule) rule)\n-            .getTieredReplicants()\n-            .forEach((final String tier, final Integer ruleReplicants) -> {\n-              int currentReplicants = segmentReplicantLookup.getLoadedReplicants(segment.getId(), tier);\n-              Object2LongMap<String> underReplicationPerDataSource = underReplicationCountsPerDataSourcePerTier\n-                  .computeIfAbsent(tier, ignored -> new Object2LongOpenHashMap<>());\n+        if (rule instanceof LoadRule) {\n+          ((LoadRule) rule)\n+              .getTieredReplicants()\n+              .forEach((final String tier, final Integer ruleReplicants) -> {\n+                int currentReplicants = segmentReplicantLookup.getLoadedReplicants(segment.getId(), tier);\n+                Object2LongMap<String> underReplicationPerDataSource = underReplicationCountsPerDataSourcePerTier\n+                    .computeIfAbsent(tier, ignored -> new Object2LongOpenHashMap<>());\n+                ((Object2LongOpenHashMap<String>) underReplicationPerDataSource)\n+                    .addTo(segment.getDataSource(), Math.max(ruleReplicants - currentReplicants, 0));\n+              });\n+        }\n+\n+        if (rule instanceof BroadcastDistributionRule) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQxNjAzNA=="}, "originalCommit": {"oid": "95e84176a929717500d79ccaa92814ce1d04034d"}, "originalPosition": 49}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2345, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}