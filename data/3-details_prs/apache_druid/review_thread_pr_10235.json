{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDYyNDcxNjgx", "number": 10235, "reviewThreads": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQyMTo0MjoyMVrOEVLZtw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxNzoxNjoxNVrOEXuMCA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwNjQyMzU5OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/org/apache/druid/collections/StableLimitingSorter.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQyMTo0MjoyMVrOG7yhAw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxOTozNToyMlrOG8Xwlg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM0NjgxOQ==", "bodyText": "What does 'least first' mean? Is this referring to .thenComparing by the number?", "url": "https://github.com/apache/druid/pull/10235#discussion_r465346819", "createdAt": "2020-08-04T21:42:21Z", "author": {"login": "clintropolis"}, "path": "core/src/main/java/org/apache/druid/collections/StableLimitingSorter.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.collections;\n+\n+import com.google.common.collect.MinMaxPriorityQueue;\n+import com.google.common.collect.Ordering;\n+\n+import java.util.Comparator;\n+import java.util.Iterator;\n+import java.util.Objects;\n+\n+/**\n+ * Simultaneously sorts and limits its input.\n+ *\n+ * The sort is stable, meaning that equal elements (as determined by the comparator) will not be reordered.\n+ *\n+ * Not thread-safe.\n+ *\n+ * Note: this class doesn't have its own unit tests. It is tested along with\n+ * {@link org.apache.druid.java.util.common.guava.TopNSequence} in \"TopNSequenceTest\".\n+ */\n+public class StableLimitingSorter<T>\n+{\n+  private final MinMaxPriorityQueue<NumberedElement<T>> queue;\n+\n+  private long count = 0;\n+\n+  public StableLimitingSorter(final Comparator<T> comparator, final int limit)\n+  {\n+    this.queue = MinMaxPriorityQueue\n+        .orderedBy(\n+            Ordering.from(\n+                Comparator.<NumberedElement<T>, T>comparing(NumberedElement::getElement, comparator)\n+                    .thenComparing(NumberedElement::getNumber)\n+            )\n+        )\n+        .maximumSize(limit)\n+        .create();\n+  }\n+\n+  /**\n+   * Offer an element to the sorter.\n+   */\n+  public void add(T element)\n+  {\n+    queue.offer(new NumberedElement<>(element, count++));\n+  }\n+\n+  /**\n+   * Drain elements in sorted order (least first).", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "219cfa8e5f384a0ec39bba5b762a01b084c20546"}, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk1NzAxNA==", "bodyText": "It means the elements are returned in ascending order.", "url": "https://github.com/apache/druid/pull/10235#discussion_r465957014", "createdAt": "2020-08-05T19:35:22Z", "author": {"login": "gianm"}, "path": "core/src/main/java/org/apache/druid/collections/StableLimitingSorter.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.collections;\n+\n+import com.google.common.collect.MinMaxPriorityQueue;\n+import com.google.common.collect.Ordering;\n+\n+import java.util.Comparator;\n+import java.util.Iterator;\n+import java.util.Objects;\n+\n+/**\n+ * Simultaneously sorts and limits its input.\n+ *\n+ * The sort is stable, meaning that equal elements (as determined by the comparator) will not be reordered.\n+ *\n+ * Not thread-safe.\n+ *\n+ * Note: this class doesn't have its own unit tests. It is tested along with\n+ * {@link org.apache.druid.java.util.common.guava.TopNSequence} in \"TopNSequenceTest\".\n+ */\n+public class StableLimitingSorter<T>\n+{\n+  private final MinMaxPriorityQueue<NumberedElement<T>> queue;\n+\n+  private long count = 0;\n+\n+  public StableLimitingSorter(final Comparator<T> comparator, final int limit)\n+  {\n+    this.queue = MinMaxPriorityQueue\n+        .orderedBy(\n+            Ordering.from(\n+                Comparator.<NumberedElement<T>, T>comparing(NumberedElement::getElement, comparator)\n+                    .thenComparing(NumberedElement::getNumber)\n+            )\n+        )\n+        .maximumSize(limit)\n+        .create();\n+  }\n+\n+  /**\n+   * Offer an element to the sorter.\n+   */\n+  public void add(T element)\n+  {\n+    queue.offer(new NumberedElement<>(element, count++));\n+  }\n+\n+  /**\n+   * Drain elements in sorted order (least first).", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM0NjgxOQ=="}, "originalCommit": {"oid": "219cfa8e5f384a0ec39bba5b762a01b084c20546"}, "originalPosition": 67}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwNjQzMTE0OnYy", "diffSide": "RIGHT", "path": "docs/querying/limitspec.md", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQyMTo0NTowMVrOG7ylkw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQyMToxNzo0NFrOG8a-HA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM0Nzk4Nw==", "bodyText": "Any idea on numbers that are too large, or is this a try it and find out what your cluster can handle kind of thing?", "url": "https://github.com/apache/druid/pull/10235#discussion_r465347987", "createdAt": "2020-08-04T21:45:01Z", "author": {"login": "clintropolis"}, "path": "docs/querying/limitspec.md", "diffHunk": "@@ -35,11 +35,23 @@ The default limit spec takes a limit and the list of columns to do an orderBy op\n ```json\n {\n     \"type\"    : \"default\",\n-    \"limit\"   : <integer_value>,\n-    \"columns\" : [list of OrderByColumnSpec],\n+    \"limit\"   : <optional integer>,\n+    \"offset\"  : <optional integer>,\n+    \"columns\" : [<optional list of OrderByColumnSpec>],\n }\n ```\n \n+The \"limit\" parameter is the maximum number of rows to return.\n+\n+The \"offset\" parameter tells Druid to skip this many rows when returning results. If both \"limit\" and \"offset\" are\n+provided, then \"offset\" will be applied first, followed by \"limit\". For example, a spec with limit 100 and offset 10\n+will return 100 rows starting from row number 10. Skipped rows will still need to be generated internally and then\n+discarded, meaning that raising offsets to high values can cause queries to use additional resources.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "219cfa8e5f384a0ec39bba5b762a01b084c20546"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk2MDY3NQ==", "bodyText": "It would need to be based on the limit, I suppose. I'll add this language about how to think about this:\n\nInternally, the query is executed by extending the limit by the offset and then discarding a number of rows equal to the offset. This means that raising the offset will increase resource usage by an amount similar to increasing the limit.\n\nA full picture would require some docs about how to think of the impact of limits on resource usage, which would be awesome but I would consider outside the scope of this patch.", "url": "https://github.com/apache/druid/pull/10235#discussion_r465960675", "createdAt": "2020-08-05T19:42:35Z", "author": {"login": "gianm"}, "path": "docs/querying/limitspec.md", "diffHunk": "@@ -35,11 +35,23 @@ The default limit spec takes a limit and the list of columns to do an orderBy op\n ```json\n {\n     \"type\"    : \"default\",\n-    \"limit\"   : <integer_value>,\n-    \"columns\" : [list of OrderByColumnSpec],\n+    \"limit\"   : <optional integer>,\n+    \"offset\"  : <optional integer>,\n+    \"columns\" : [<optional list of OrderByColumnSpec>],\n }\n ```\n \n+The \"limit\" parameter is the maximum number of rows to return.\n+\n+The \"offset\" parameter tells Druid to skip this many rows when returning results. If both \"limit\" and \"offset\" are\n+provided, then \"offset\" will be applied first, followed by \"limit\". For example, a spec with limit 100 and offset 10\n+will return 100 rows starting from row number 10. Skipped rows will still need to be generated internally and then\n+discarded, meaning that raising offsets to high values can cause queries to use additional resources.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM0Nzk4Nw=="}, "originalCommit": {"oid": "219cfa8e5f384a0ec39bba5b762a01b084c20546"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjAwOTYyOA==", "bodyText": "sgtm \ud83d\udc4d", "url": "https://github.com/apache/druid/pull/10235#discussion_r466009628", "createdAt": "2020-08-05T21:17:44Z", "author": {"login": "clintropolis"}, "path": "docs/querying/limitspec.md", "diffHunk": "@@ -35,11 +35,23 @@ The default limit spec takes a limit and the list of columns to do an orderBy op\n ```json\n {\n     \"type\"    : \"default\",\n-    \"limit\"   : <integer_value>,\n-    \"columns\" : [list of OrderByColumnSpec],\n+    \"limit\"   : <optional integer>,\n+    \"offset\"  : <optional integer>,\n+    \"columns\" : [<optional list of OrderByColumnSpec>],\n }\n ```\n \n+The \"limit\" parameter is the maximum number of rows to return.\n+\n+The \"offset\" parameter tells Druid to skip this many rows when returning results. If both \"limit\" and \"offset\" are\n+provided, then \"offset\" will be applied first, followed by \"limit\". For example, a spec with limit 100 and offset 10\n+will return 100 rows starting from row number 10. Skipped rows will still need to be generated internally and then\n+discarded, meaning that raising offsets to high values can cause queries to use additional resources.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM0Nzk4Nw=="}, "originalCommit": {"oid": "219cfa8e5f384a0ec39bba5b762a01b084c20546"}, "originalPosition": 17}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwNjUyMTEwOnYy", "diffSide": "RIGHT", "path": "sql/src/main/java/org/apache/druid/sql/calcite/rel/DruidQuery.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQyMjoxNzo1MFrOG7zbOw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxOTo0Mjo0M1rOG8X_Ow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM2MTcyMw==", "bodyText": "Is the plan to update Sorting to store the offset, and computeSorting to set it when creating it from the calcite Sort in a follow-up so that this works in SQL?", "url": "https://github.com/apache/druid/pull/10235#discussion_r465361723", "createdAt": "2020-08-04T22:17:50Z", "author": {"login": "clintropolis"}, "path": "sql/src/main/java/org/apache/druid/sql/calcite/rel/DruidQuery.java", "diffHunk": "@@ -928,6 +928,7 @@ public GroupByQuery toGroupByQuery()\n         sorting != null\n         ? new DefaultLimitSpec(\n             sorting.getOrderBys(),\n+            0,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "219cfa8e5f384a0ec39bba5b762a01b084c20546"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk2MDc2Mw==", "bodyText": "Yes.", "url": "https://github.com/apache/druid/pull/10235#discussion_r465960763", "createdAt": "2020-08-05T19:42:43Z", "author": {"login": "gianm"}, "path": "sql/src/main/java/org/apache/druid/sql/calcite/rel/DruidQuery.java", "diffHunk": "@@ -928,6 +928,7 @@ public GroupByQuery toGroupByQuery()\n         sorting != null\n         ? new DefaultLimitSpec(\n             sorting.getOrderBys(),\n+            0,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM2MTcyMw=="}, "originalCommit": {"oid": "219cfa8e5f384a0ec39bba5b762a01b084c20546"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwNjUyMjk4OnYy", "diffSide": "RIGHT", "path": "processing/src/test/java/org/apache/druid/query/groupby/GroupByQueryRunnerTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQyMjoxODozNlrOG7zcRg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxOTo0Mjo0OFrOG8X_ag==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM2MTk5MA==", "bodyText": "Are these changes from the stabilization?", "url": "https://github.com/apache/druid/pull/10235#discussion_r465361990", "createdAt": "2020-08-04T22:18:36Z", "author": {"login": "clintropolis"}, "path": "processing/src/test/java/org/apache/druid/query/groupby/GroupByQueryRunnerTest.java", "diffHunk": "@@ -3700,7 +3702,7 @@ public void testGroupByWithOrderOnHyperUnique()\n             query,\n             \"1970-01-01T00:00:00.000Z\",\n             \"market\",\n-            \"upfront\",\n+            \"total_market\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "219cfa8e5f384a0ec39bba5b762a01b084c20546"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk2MDgxMA==", "bodyText": "Yes.", "url": "https://github.com/apache/druid/pull/10235#discussion_r465960810", "createdAt": "2020-08-05T19:42:48Z", "author": {"login": "gianm"}, "path": "processing/src/test/java/org/apache/druid/query/groupby/GroupByQueryRunnerTest.java", "diffHunk": "@@ -3700,7 +3702,7 @@ public void testGroupByWithOrderOnHyperUnique()\n             query,\n             \"1970-01-01T00:00:00.000Z\",\n             \"market\",\n-            \"upfront\",\n+            \"total_market\",", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM2MTk5MA=="}, "originalCommit": {"oid": "219cfa8e5f384a0ec39bba5b762a01b084c20546"}, "originalPosition": 43}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkzMzA5NDQ4OnYy", "diffSide": "RIGHT", "path": "processing/src/main/java/org/apache/druid/query/groupby/orderby/DefaultLimitSpec.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQxNzoxNjoxNVrOG_q48A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMlQyMToxODozMVrOG_zOeA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQxNjE3Ng==", "bodyText": "Should this perhaps be 'Limit for this query...' instead of 'Offset for this query...'?", "url": "https://github.com/apache/druid/pull/10235#discussion_r469416176", "createdAt": "2020-08-12T17:16:15Z", "author": {"login": "abhishekrb19"}, "path": "processing/src/main/java/org/apache/druid/query/groupby/orderby/DefaultLimitSpec.java", "diffHunk": "@@ -113,12 +139,32 @@ public DefaultLimitSpec(\n     return columns;\n   }\n \n+  /**\n+   * Offset for this query; behaves like SQL \"OFFSET\". Zero means no offset. Negative values are invalid.\n+   */\n   @JsonProperty\n+  @JsonInclude(JsonInclude.Include.NON_DEFAULT)\n+  public int getOffset()\n+  {\n+    return offset;\n+  }\n+\n+  /**\n+   * Offset for this query; behaves like SQL \"LIMIT\". Will always be positive. {@link Integer#MAX_VALUE} is used in", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aeb52ed1e41cda97ac3ae4d79e3dd20987d92749"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTU1Mjc2MA==", "bodyText": "Good catch. I raised a separate PR for it: #10269", "url": "https://github.com/apache/druid/pull/10235#discussion_r469552760", "createdAt": "2020-08-12T21:18:31Z", "author": {"login": "gianm"}, "path": "processing/src/main/java/org/apache/druid/query/groupby/orderby/DefaultLimitSpec.java", "diffHunk": "@@ -113,12 +139,32 @@ public DefaultLimitSpec(\n     return columns;\n   }\n \n+  /**\n+   * Offset for this query; behaves like SQL \"OFFSET\". Zero means no offset. Negative values are invalid.\n+   */\n   @JsonProperty\n+  @JsonInclude(JsonInclude.Include.NON_DEFAULT)\n+  public int getOffset()\n+  {\n+    return offset;\n+  }\n+\n+  /**\n+   * Offset for this query; behaves like SQL \"LIMIT\". Will always be positive. {@link Integer#MAX_VALUE} is used in", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2OTQxNjE3Ng=="}, "originalCommit": {"oid": "aeb52ed1e41cda97ac3ae4d79e3dd20987d92749"}, "originalPosition": 100}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2250, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}