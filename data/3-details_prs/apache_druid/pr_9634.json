{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDAwMDYxMjA3", "number": 9634, "title": "More optimize CNF conversion of filters", "bodyText": "Description\nA follow-up of #9608. Even with common subfilters elimination, the CNF conversion can result in a suboptimal CNF which is usually huge. One example is A && B && ((C && D && E) || (C && D && F)). The CNF conversion returned ((C || E) && (D || E) && (C || F) && (D || F) && C && D && (D || C) && A && B (F || E)) prior to this PR.\nI adopted the RexUtil.pullFactors() from Apache Calcite which seems to be able to address this issue. However, by its design, it can create a conjunctive form which is not necessarily a CNF. Since we still need CNF, I modified toCnf() method to call the adopted pull() method and then perform the existing CNF conversion. I added more unit tests to verify the modified behavior. Also, to verify that the filter is equivalent after conversion, I added a verification that checks the equivalence of filters by comparing their truth table.\n\nThis PR has:\n\n been self-reviewed.\n\n using the concurrency checklist (Remove this item if the PR doesn't have any relation to concurrency.)\n\n\n added documentation for new or modified features or behaviors.\n added Javadocs for most classes and all non-trivial methods. Linked related entities via Javadoc links.\n added or updated version, license, or notice information in licenses.yaml\n added comments explaining the \"why\" and the intent of the code wherever would not be obvious for an unfamiliar reader.\n added unit tests or modified existing tests to cover new code paths.\n added integration tests.\n been tested in a test Druid cluster.", "createdAt": "2020-04-07T06:14:38Z", "url": "https://github.com/apache/druid/pull/9634", "merged": true, "mergeCommit": {"oid": "a6790ff22a9d883d789f3b5de0da02b9d8d19b69"}, "closed": true, "closedAt": "2020-04-09T04:31:18Z", "author": {"login": "jihoonson"}, "timelineItems": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcVM3rVAH2gAyNDAwMDYxMjA3OjgzYjU2NjVhYjBmYWZmMDdkYTU4ZDczYzU3YmE4NzhhMTIzM2Q0ZjQ=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcV00tuAFqTM5MDQ4Mzc4NA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "83b5665ab0faff07da58d73c57ba878a1233d4f4", "author": {"user": {"login": "jihoonson", "name": "Jihoon Son"}}, "url": "https://github.com/apache/druid/commit/83b5665ab0faff07da58d73c57ba878a1233d4f4", "committedDate": "2020-04-07T05:58:10Z", "message": "More optimize CNF conversion of filters"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "21c3eace4fd55b073b96203b2c111921201a639d", "author": {"user": {"login": "jihoonson", "name": "Jihoon Son"}}, "url": "https://github.com/apache/druid/commit/21c3eace4fd55b073b96203b2c111921201a639d", "committedDate": "2020-04-07T06:38:56Z", "message": "update license"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "153f163e767a1f9e419c3f1dc9559b28ea28eb62", "author": {"user": {"login": "jihoonson", "name": "Jihoon Son"}}, "url": "https://github.com/apache/druid/commit/153f163e767a1f9e419c3f1dc9559b28ea28eb62", "committedDate": "2020-04-07T16:36:32Z", "message": "fix build"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8ddfff4604572dbd57169c91a3e456a7f7e57495", "author": {"user": {"login": "jihoonson", "name": "Jihoon Son"}}, "url": "https://github.com/apache/druid/commit/8ddfff4604572dbd57169c91a3e456a7f7e57495", "committedDate": "2020-04-07T18:40:55Z", "message": "checkstyle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d9821ee1b85006fd38d770b8c2038baa59a41769", "author": {"user": {"login": "jihoonson", "name": "Jihoon Son"}}, "url": "https://github.com/apache/druid/commit/d9821ee1b85006fd38d770b8c2038baa59a41769", "committedDate": "2020-04-07T20:10:22Z", "message": "remove unnecessary code"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5NTg4MzAy", "url": "https://github.com/apache/druid/pull/9634#pullrequestreview-389588302", "createdAt": "2020-04-08T01:02:02Z", "commit": {"oid": "d9821ee1b85006fd38d770b8c2038baa59a41769"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwMTowMjowMlrOGCbbAQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwMTowMjowMlrOGCbbAQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTE5OTYxNw==", "bodyText": "Looking at how the file has multiple inclusions from other projects, can we split the Calcite-based methods into their own class? I think it'd be easier to tell what's from what that way", "url": "https://github.com/apache/druid/pull/9634#discussion_r405199617", "createdAt": "2020-04-08T01:02:02Z", "author": {"login": "jon-wei"}, "path": "processing/src/main/java/org/apache/druid/segment/filter/CnfHelper.java", "diffHunk": "@@ -0,0 +1,464 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.filter;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import org.apache.druid.query.filter.BooleanFilter;\n+import org.apache.druid.query.filter.Filter;\n+\n+import javax.annotation.Nonnull;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+/**\n+ * A helper class to convert a filter to CNF.\n+ *\n+ * The methods in this class are mainly adopted from Apache Hive and Apache Calcite.\n+ */\n+public class CnfHelper\n+{\n+  public static Filter toCnf(Filter current)\n+  {\n+    current = pushDownNot(current);\n+    current = flatten(current);\n+    current = pull(current);\n+    current = convertToCNFInternal(current);\n+    current = flatten(current);\n+    return current;\n+  }\n+\n+  // A helper function adapted from Apache Hive, see:\n+  // https://github.com/apache/hive/blob/branch-2.0/storage-api/src/java/org/apache/hadoop/hive/ql/io/sarg/SearchArgumentImpl.java\n+  @VisibleForTesting\n+  static Filter pushDownNot(Filter current)\n+  {\n+    if (current instanceof NotFilter) {\n+      Filter child = ((NotFilter) current).getBaseFilter();\n+      if (child instanceof NotFilter) {\n+        return pushDownNot(((NotFilter) child).getBaseFilter());\n+      }\n+      if (child instanceof AndFilter) {\n+        Set<Filter> children = new HashSet<>();\n+        for (Filter grandChild : ((AndFilter) child).getFilters()) {\n+          children.add(pushDownNot(new NotFilter(grandChild)));\n+        }\n+        return new OrFilter(children);\n+      }\n+      if (child instanceof OrFilter) {\n+        Set<Filter> children = new HashSet<>();\n+        for (Filter grandChild : ((OrFilter) child).getFilters()) {\n+          children.add(pushDownNot(new NotFilter(grandChild)));\n+        }\n+        return new AndFilter(children);\n+      }\n+    }\n+\n+    if (current instanceof AndFilter) {\n+      Set<Filter> children = new HashSet<>();\n+      for (Filter child : ((AndFilter) current).getFilters()) {\n+        children.add(pushDownNot(child));\n+      }\n+      return new AndFilter(children);\n+    }\n+\n+    if (current instanceof OrFilter) {\n+      Set<Filter> children = new HashSet<>();\n+      for (Filter child : ((OrFilter) current).getFilters()) {\n+        children.add(pushDownNot(child));\n+      }\n+      return new OrFilter(children);\n+    }\n+    return current;\n+  }\n+\n+  // A helper function adapted from Apache Hive, see:\n+  // https://github.com/apache/hive/blob/branch-2.0/storage-api/src/java/org/apache/hadoop/hive/ql/io/sarg/SearchArgumentImpl.java\n+  private static Filter convertToCNFInternal(Filter current)\n+  {\n+    if (current instanceof NotFilter) {\n+      return new NotFilter(convertToCNFInternal(((NotFilter) current).getBaseFilter()));\n+    }\n+    if (current instanceof AndFilter) {\n+      Set<Filter> children = new HashSet<>();\n+      for (Filter child : ((AndFilter) current).getFilters()) {\n+        children.add(convertToCNFInternal(child));\n+      }\n+      return new AndFilter(children);\n+    }\n+    if (current instanceof OrFilter) {\n+      // a list of leaves that weren't under AND expressions\n+      List<Filter> nonAndList = new ArrayList<Filter>();\n+      // a list of AND expressions that we need to distribute\n+      List<Filter> andList = new ArrayList<Filter>();\n+      for (Filter child : ((OrFilter) current).getFilters()) {\n+        if (child instanceof AndFilter) {\n+          andList.add(child);\n+        } else if (child instanceof OrFilter) {\n+          // pull apart the kids of the OR expression\n+          nonAndList.addAll(((OrFilter) child).getFilters());\n+        } else {\n+          nonAndList.add(child);\n+        }\n+      }\n+      if (!andList.isEmpty()) {\n+        Set<Filter> result = new HashSet<>();\n+        generateAllCombinations(result, andList, nonAndList);\n+        return new AndFilter(result);\n+      }\n+    }\n+    return current;\n+  }\n+\n+  // A helper function adapted from Apache Hive, see:\n+  // https://github.com/apache/hive/blob/branch-2.0/storage-api/src/java/org/apache/hadoop/hive/ql/io/sarg/SearchArgumentImpl.java\n+  @VisibleForTesting\n+  static Filter flatten(Filter root)\n+  {\n+    if (root instanceof BooleanFilter) {\n+      List<Filter> children = new ArrayList<>(((BooleanFilter) root).getFilters());\n+      // iterate through the index, so that if we add more children,\n+      // they don't get re-visited\n+      for (int i = 0; i < children.size(); ++i) {\n+        Filter child = flatten(children.get(i));\n+        // do we need to flatten?\n+        if (child.getClass() == root.getClass() && !(child instanceof NotFilter)) {\n+          boolean first = true;\n+          Set<Filter> grandKids = ((BooleanFilter) child).getFilters();\n+          for (Filter grandkid : grandKids) {\n+            // for the first grandkid replace the original parent\n+            if (first) {\n+              first = false;\n+              children.set(i, grandkid);\n+            } else {\n+              children.add(++i, grandkid);\n+            }\n+          }\n+        } else {\n+          children.set(i, child);\n+        }\n+      }\n+      // if we have a singleton AND or OR, just return the child\n+      if (children.size() == 1 && (root instanceof AndFilter || root instanceof OrFilter)) {\n+        return children.get(0);\n+      }\n+\n+      if (root instanceof AndFilter) {\n+        return new AndFilter(children);\n+      } else if (root instanceof OrFilter) {\n+        return new OrFilter(children);\n+      }\n+    }\n+    return root;\n+  }\n+\n+  // A helper function adapted from Apache Hive, see:\n+  // https://github.com/apache/hive/blob/branch-2.0/storage-api/src/java/org/apache/hadoop/hive/ql/io/sarg/SearchArgumentImpl.java\n+  private static void generateAllCombinations(\n+      Set<Filter> result,\n+      List<Filter> andList,\n+      List<Filter> nonAndList\n+  )\n+  {\n+    Set<Filter> children = ((AndFilter) andList.get(0)).getFilters();\n+    if (result.isEmpty()) {\n+      for (Filter child : children) {\n+        Set<Filter> a = new HashSet<>(nonAndList);\n+        a.add(child);\n+        result.add(new OrFilter(a));\n+      }\n+    } else {\n+      List<Filter> work = new ArrayList<>(result);\n+      result.clear();\n+      for (Filter child : children) {\n+        for (Filter or : work) {\n+          Set<Filter> a = new HashSet<>((((OrFilter) or).getFilters()));\n+          a.add(child);\n+          result.add(new OrFilter(a));\n+        }\n+      }\n+    }\n+    if (andList.size() > 1) {\n+      generateAllCombinations(result, andList.subList(1, andList.size()), nonAndList);\n+    }\n+  }\n+\n+  // All functions below were basically adopted from Apache Calcite and modified to use them in Druid.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d9821ee1b85006fd38d770b8c2038baa59a41769"}, "originalPosition": 210}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c14af652fe0ff2b00618d9ed76a9c390056a2dea", "author": {"user": {"login": "jihoonson", "name": "Jihoon Son"}}, "url": "https://github.com/apache/druid/commit/c14af652fe0ff2b00618d9ed76a9c390056a2dea", "committedDate": "2020-04-08T01:23:39Z", "message": "split helper"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c704152063e46738c412102292047ce2cc5df115", "author": {"user": {"login": "jihoonson", "name": "Jihoon Son"}}, "url": "https://github.com/apache/druid/commit/c704152063e46738c412102292047ce2cc5df115", "committedDate": "2020-04-08T01:24:47Z", "message": "license"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "258421b60aae35bbd4be0ebf9d6f6c1edb230c32", "author": {"user": {"login": "jihoonson", "name": "Jihoon Son"}}, "url": "https://github.com/apache/druid/commit/258421b60aae35bbd4be0ebf9d6f6c1edb230c32", "committedDate": "2020-04-08T18:08:17Z", "message": "checkstyle"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkwMjc2MTg0", "url": "https://github.com/apache/druid/pull/9634#pullrequestreview-390276184", "createdAt": "2020-04-08T19:42:06Z", "commit": {"oid": "258421b60aae35bbd4be0ebf9d6f6c1edb230c32"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxOTo0MjowNlrOGC-LRA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxOTo0MjowNlrOGC-LRA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc2OTAyOA==", "bodyText": "It would be nice to add some commentary on each line describing (possibly with example) why it exists. I know there is something in PR description but this is non-trivial.", "url": "https://github.com/apache/druid/pull/9634#discussion_r405769028", "createdAt": "2020-04-08T19:42:06Z", "author": {"login": "himanshug"}, "path": "processing/src/main/java/org/apache/druid/segment/filter/Filters.java", "diffHunk": "@@ -426,175 +424,21 @@ public static Filter convertToCNFFromQueryContext(Query query, @Nullable Filter\n       return null;\n     }\n     boolean useCNF = query.getContextBoolean(CTX_KEY_USE_FILTER_CNF, false);\n-    return useCNF ? toCNF(filter) : filter;\n+    return useCNF ? Filters.toCnf(filter) : filter;\n   }\n \n-  public static Filter toCNF(Filter current)\n+  public static Filter toCnf(Filter current)\n   {\n-    current = pushDownNot(current);\n-    current = flatten(current);\n-    current = convertToCNFInternal(current);\n-    current = flatten(current);\n+    current = HiveCnfHelper.pushDownNot(current);\n+    current = HiveCnfHelper.flatten(current);\n+    // Pull out AND filters first to convert the filter into a conjunctive form.\n+    // This is important to not create a huge CNF.\n+    current = CalciteCnfHelper.pull(current);\n+    current = HiveCnfHelper.convertToCNFInternal(current);\n+    current = HiveCnfHelper.flatten(current);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "258421b60aae35bbd4be0ebf9d6f6c1edb230c32"}, "originalPosition": 52}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkwMjc2NTk4", "url": "https://github.com/apache/druid/pull/9634#pullrequestreview-390276598", "createdAt": "2020-04-08T19:42:46Z", "commit": {"oid": "258421b60aae35bbd4be0ebf9d6f6c1edb230c32"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxOTo0Mjo0NlrOGC-MuA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQxOTo0Mjo0NlrOGC-MuA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTc2OTQwMA==", "bodyText": "is this still \"Internal\" ?", "url": "https://github.com/apache/druid/pull/9634#discussion_r405769400", "createdAt": "2020-04-08T19:42:46Z", "author": {"login": "himanshug"}, "path": "processing/src/main/java/org/apache/druid/segment/filter/cnf/HiveCnfHelper.java", "diffHunk": "@@ -0,0 +1,190 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.filter.cnf;\n+\n+import org.apache.druid.query.filter.BooleanFilter;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.NotFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+\n+/**\n+ * All functions in this class were basically adopted from Apache Hive and modified to use them in Druid.\n+ * See https://github.com/apache/hive/blob/branch-2.0/storage-api/src/java/org/apache/hadoop/hive/ql/io/sarg/SearchArgumentImpl.java\n+ * for original implementation.\n+ */\n+public class HiveCnfHelper\n+{\n+  public static Filter pushDownNot(Filter current)\n+  {\n+    if (current instanceof NotFilter) {\n+      Filter child = ((NotFilter) current).getBaseFilter();\n+      if (child instanceof NotFilter) {\n+        return pushDownNot(((NotFilter) child).getBaseFilter());\n+      }\n+      if (child instanceof AndFilter) {\n+        Set<Filter> children = new HashSet<>();\n+        for (Filter grandChild : ((AndFilter) child).getFilters()) {\n+          children.add(pushDownNot(new NotFilter(grandChild)));\n+        }\n+        return new OrFilter(children);\n+      }\n+      if (child instanceof OrFilter) {\n+        Set<Filter> children = new HashSet<>();\n+        for (Filter grandChild : ((OrFilter) child).getFilters()) {\n+          children.add(pushDownNot(new NotFilter(grandChild)));\n+        }\n+        return new AndFilter(children);\n+      }\n+    }\n+\n+    if (current instanceof AndFilter) {\n+      Set<Filter> children = new HashSet<>();\n+      for (Filter child : ((AndFilter) current).getFilters()) {\n+        children.add(pushDownNot(child));\n+      }\n+      return new AndFilter(children);\n+    }\n+\n+    if (current instanceof OrFilter) {\n+      Set<Filter> children = new HashSet<>();\n+      for (Filter child : ((OrFilter) current).getFilters()) {\n+        children.add(pushDownNot(child));\n+      }\n+      return new OrFilter(children);\n+    }\n+    return current;\n+  }\n+\n+  public static Filter convertToCNFInternal(Filter current)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "258421b60aae35bbd4be0ebf9d6f6c1edb230c32"}, "originalPosition": 81}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "587db12487d07d147e953bbc2c4741056f16017c", "author": {"user": {"login": "jihoonson", "name": "Jihoon Son"}}, "url": "https://github.com/apache/druid/commit/587db12487d07d147e953bbc2c4741056f16017c", "committedDate": "2020-04-08T21:02:20Z", "message": "add comments on cnf conversion"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkwMzkxOTA5", "url": "https://github.com/apache/druid/pull/9634#pullrequestreview-390391909", "createdAt": "2020-04-08T23:11:37Z", "commit": {"oid": "587db12487d07d147e953bbc2c4741056f16017c"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkwNDgzNzg0", "url": "https://github.com/apache/druid/pull/9634#pullrequestreview-390483784", "createdAt": "2020-04-09T04:31:08Z", "commit": {"oid": "587db12487d07d147e953bbc2c4741056f16017c"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2441, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}