{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg0MTI3MTY2", "number": 9459, "title": "Ability to Delete task logs and segments from S3", "bodyText": "implement ability to delete all tasks logs or all task logs\nwritten before a particular date when written to S3\nimplement ability to delete all segments from S3 deep storage\nupgrade version of aws SDK in use\n\nThis PR has:\n\n been self-reviewed.\n using the concurrency checklist (Remove this item if the PR doesn't have any relation to concurrency.)\n added documentation for new or modified features or behaviors.\n added Javadocs for most classes and all non-trivial methods. Linked related entities via Javadoc links.\n added or updated version, license, or notice information in licenses.yaml\n added comments explaining the \"why\" and the intent of the code wherever would not be obvious for an unfamiliar reader.\n added unit tests or modified existing tests to cover new code paths.\n added integration tests.\n been tested in a test Druid cluster.", "createdAt": "2020-03-05T08:10:53Z", "url": "https://github.com/apache/druid/pull/9459", "merged": true, "mergeCommit": {"oid": "7e0e767cc28d3c94e46e3a0645a89abf7a3f449e"}, "closed": true, "closedAt": "2020-03-10T20:13:47Z", "author": {"login": "zachjsh"}, "timelineItems": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcKm9mWAH2gAyMzg0MTI3MTY2OjkxNDUxMGYxY2Y3YmMzZjFkZTBhMDhhMmUyMTI3ZmZiODA3YTA0ZjI=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcMRYLTAFqTM3MTY0ODk0OA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "914510f1cf7bc3f1de0a08a2e2127ffb807a04f2", "author": {"user": {"login": "zachjsh", "name": null}}, "url": "https://github.com/apache/druid/commit/914510f1cf7bc3f1de0a08a2e2127ffb807a04f2", "committedDate": "2020-03-05T08:09:00Z", "message": "Ability to Delete task logs and segments from S3\n\n* implement ability to delete all tasks logs or all task logs\n  written before a particular date when written to S3\n* implement ability to delete all segments from S3 deep storage\n* upgrade version of aws SDK in use"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5d505a1d23d79c88261011d5abd9d670401b107b", "author": {"user": {"login": "zachjsh", "name": null}}, "url": "https://github.com/apache/druid/commit/5d505a1d23d79c88261011d5abd9d670401b107b", "committedDate": "2020-03-05T08:14:22Z", "message": "* update licenses for updated AWS SDK version"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2af8070937c585eefa012a1dec96751fa0e562fc", "author": {"user": {"login": "zachjsh", "name": null}}, "url": "https://github.com/apache/druid/commit/2af8070937c585eefa012a1dec96751fa0e562fc", "committedDate": "2020-03-06T00:57:34Z", "message": "* fix bug in iterating through results from S3\n* revert back to original version of AWS SDK"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcwMDQ2NDg1", "url": "https://github.com/apache/druid/pull/9459#pullrequestreview-370046485", "createdAt": "2020-03-06T02:25:42Z", "commit": {"oid": "2af8070937c585eefa012a1dec96751fa0e562fc"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNlQwMjoyNTo0MlrOFyrSiw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNlQwMzowNDo0N1rOFyr2ng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODY4MjM3OQ==", "bodyText": "Hmm, this block is almost identical to the block in S3TaskLogs.killOlderThan, and both partially very close to what ObjectSummaryIterator is providing.\nI think it would be nicer if this class and S3TaskLogs could use ObjectSummaryIterator, and if the method that does the bulk key delete can be put in a shared method in S3Utils.\nCan I recommend something like this in S3Utils?\n  public static void deleteObjectsInPath(\n      ServerSideEncryptingAmazonS3 s3Client,\n      S3InputDataConfig config,\n      String bucket,\n      String prefix,\n      Predicate<S3ObjectSummary> filter\n  )\n      throws Exception\n  {\n    final List<DeleteObjectsRequest.KeyVersion> keysToDelete = new ArrayList<>(config.getMaxListingLength());\n    final ObjectSummaryIterator iterator = new ObjectSummaryIterator(\n        s3Client,\n        ImmutableList.of(new CloudObjectLocation(bucket, prefix).toUri(\"s3\")),\n        config.getMaxListingLength()\n    );\n\n    while (iterator.hasNext()) {\n      final S3ObjectSummary nextObject = iterator.next();\n      if (filter.apply(nextObject)) {\n        keysToDelete.add(new DeleteObjectsRequest.KeyVersion(nextObject.getKey()));\n        if (keysToDelete.size() == config.getMaxListingLength()) {\n          deleteBucketKeys(s3Client, bucket, keysToDelete);\n          keysToDelete.clear();\n        }\n      }\n    }\n\n    if (keysToDelete.size() > 0) {\n      deleteBucketKeys(s3Client, bucket, keysToDelete);\n    }\n  }\n\n  public static void deleteBucketKeys(\n      ServerSideEncryptingAmazonS3 s3Client,\n      String bucket,\n      List<DeleteObjectsRequest.KeyVersion> keysToDelete\n  )\n      throws Exception\n  {\n    DeleteObjectsRequest deleteRequest = new DeleteObjectsRequest(bucket).withKeys(keysToDelete);\n    S3Utils.retryS3Operation(() -> {\n      s3Client.deleteObjects(deleteRequest);\n      return null;\n    });\n  }\nThen, not only does it share all the code for listing objects, it also pushes down the retry to the specific API calls to list and delete, instead of wrapping the entire loop, which I think is better.\nIf you make a change like this, then the kill calls become something like:\n  @Override\n  public void killAll() throws IOException\n  {\n    try {\n      S3Utils.deleteObjectsInPath(\n          s3Client,\n          inputDataConfig,\n          segmentPusherConfig.getBucket(),\n          segmentPusherConfig.getBaseKey(),\n          Predicates.alwaysTrue()\n      );\n    }\n    catch (Exception e) {\n      log.error(\"Error occurred while deleting segment files from s3. Error: %s\", e.getMessage());\n      throw new IOException(e);\n    }\n  }\nand\n  @Override\n  public void killOlderThan(long timestamp) throws IOException\n  {\n    try {\n      S3Utils.deleteObjectsInPath(\n          service,\n          inputDataConfig,\n          config.getS3Bucket(),\n          config.getS3Prefix(),\n          (object) -> object.getLastModified().getTime() < timestamp\n      );\n    }\n    catch (Exception e) {\n      log.error(\"Error occurred while deleting task log files from s3. Error: %s\", e.getMessage());\n      throw new IOException(e);\n    }\n  }\nObjectSummaryIterator currently will skip things it thinks are directories, if this is not desirable for deleting segments and task logs, then I would suggest maybe pushing down the predicate to the ObjectSummaryIterator so that the existing users can filter out directories, and your usages can get everything or filter by timestamp as appropriate. In addition, if it shouldn't skip directories, it would probably be worth adding a test for what happens when one is present in the list objects response, if not present.\ndisclaimer: I didn't test this in real s3, but did run unit tests which passed after some modifications to expected calls, but would still recommend to review these snippets first to make sure they are correct.\nWhat do you think?", "url": "https://github.com/apache/druid/pull/9459#discussion_r388682379", "createdAt": "2020-03-06T02:25:42Z", "author": {"login": "clintropolis"}, "path": "extensions-core/s3-extensions/src/main/java/org/apache/druid/storage/s3/S3DataSegmentKiller.java", "diffHunk": "@@ -69,8 +85,48 @@ public void kill(DataSegment segment) throws SegmentLoadingException\n   }\n \n   @Override\n-  public void killAll()\n+  public void killAll() throws IOException\n   {\n-    throw new UnsupportedOperationException(\"not implemented\");\n+    try {\n+      S3Utils.retryS3Operation(\n+          () -> {\n+            String bucketName = segmentPusherConfig.getBucket();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2af8070937c585eefa012a1dec96751fa0e562fc"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODY4NDk4OA==", "bodyText": "I think these expect/expectLastCall lines can be collapsed into the form of:\nEasyMock.expect(request.getBucketName()).andReturn(bucket).anyTimes();\n\nplus a handful of other places in the tests.", "url": "https://github.com/apache/druid/pull/9459#discussion_r388684988", "createdAt": "2020-03-06T02:36:43Z", "author": {"login": "clintropolis"}, "path": "extensions-core/s3-extensions/src/test/java/org/apache/druid/storage/s3/S3TestUtils.java", "diffHunk": "@@ -0,0 +1,212 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.storage.s3;\n+\n+import com.amazonaws.services.s3.model.DeleteObjectsRequest;\n+import com.amazonaws.services.s3.model.ListObjectsV2Request;\n+import com.amazonaws.services.s3.model.ListObjectsV2Result;\n+import com.amazonaws.services.s3.model.S3ObjectSummary;\n+import junit.framework.AssertionFailedError;\n+import org.apache.commons.collections4.map.HashedMap;\n+import org.easymock.EasyMock;\n+import org.easymock.EasyMockSupport;\n+import org.easymock.IArgumentMatcher;\n+import org.easymock.IExpectationSetters;\n+\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+public class S3TestUtils extends EasyMockSupport\n+{\n+  public static ListObjectsV2Request listObjectsV2RequestArgumentMatcher(ListObjectsV2Request listObjectsV2Request)\n+  {\n+    EasyMock.reportMatcher(new IArgumentMatcher()\n+    {\n+      @Override\n+      public boolean matches(Object argument)\n+      {\n+\n+        return argument instanceof ListObjectsV2Request\n+               && listObjectsV2Request.getBucketName().equals(((ListObjectsV2Request) argument).getBucketName())\n+               && listObjectsV2Request.getPrefix().equals(((ListObjectsV2Request) argument).getPrefix())\n+               && ((listObjectsV2Request.getContinuationToken() == null\n+                    && ((ListObjectsV2Request) argument).getContinuationToken() == null)\n+                   || (listObjectsV2Request.getContinuationToken()\n+                                           .equals(((ListObjectsV2Request) argument).getContinuationToken())))\n+               && listObjectsV2Request.getMaxKeys().equals(((ListObjectsV2Request) argument).getMaxKeys());\n+      }\n+\n+      @Override\n+      public void appendTo(StringBuffer buffer)\n+      {\n+        String str = \"ListObjectsV2Request(\\\"bucketName:\\\" \\\"\"\n+                     + listObjectsV2Request.getBucketName()\n+                     + \"\\\", \\\"prefix:\\\"\"\n+                     + listObjectsV2Request.getPrefix()\n+                     + \"\\\", \\\"continuationToken:\\\"\"\n+                     + listObjectsV2Request.getContinuationToken()\n+                     + \"\\\", \\\"maxKeys:\\\"\"\n+                     + listObjectsV2Request.getMaxKeys()\n+                     + \"\\\")\";\n+        buffer.append(str);\n+      }\n+    });\n+    return null;\n+  }\n+\n+  public static DeleteObjectsRequest deleteObjectsRequestArgumentMatcher(DeleteObjectsRequest deleteObjectsRequest)\n+  {\n+    EasyMock.reportMatcher(new IArgumentMatcher()\n+    {\n+      @Override\n+      public boolean matches(Object argument)\n+      {\n+\n+        boolean matches = argument instanceof DeleteObjectsRequest\n+                          && deleteObjectsRequest.getBucketName()\n+                                                 .equals(((DeleteObjectsRequest) argument).getBucketName())\n+                          && deleteObjectsRequest.getKeys().size() == ((DeleteObjectsRequest) argument).getKeys()\n+                                                                                                       .size();\n+        if (matches) {\n+          Map<String, String> expectedKeysAndVersions = deleteObjectsRequest.getKeys().stream().collect(\n+              Collectors.toMap(DeleteObjectsRequest.KeyVersion::getKey, x -> {\n+                return x.getVersion() == null ? \"null\" : x.getVersion();\n+              }));\n+          Map<String, String> actualKeysAndVersions = ((DeleteObjectsRequest) argument).getKeys().stream().collect(\n+              Collectors.toMap(DeleteObjectsRequest.KeyVersion::getKey, x -> {\n+                return x.getVersion() == null ? \"null\" : x.getVersion();\n+              }));\n+          matches = expectedKeysAndVersions.equals(actualKeysAndVersions);\n+        }\n+        return matches;\n+      }\n+\n+      @Override\n+      public void appendTo(StringBuffer buffer)\n+      {\n+        String str = \"DeleteObjectsRequest(\\\"bucketName:\\\" \\\"\"\n+                     + deleteObjectsRequest.getBucketName()\n+                     + \"\\\", \\\"keys:\\\"\"\n+                     + deleteObjectsRequest.getKeys()\n+                     + \"\\\")\";\n+        buffer.append(str);\n+      }\n+    });\n+    return null;\n+  }\n+\n+  public static S3ObjectSummary mockS3ObjectSummary(long lastModified, String key)\n+  {\n+    S3ObjectSummary objectSummary = EasyMock.createMock(S3ObjectSummary.class);\n+    EasyMock.expect(objectSummary.getLastModified()).andReturn(new Date(lastModified));\n+    EasyMock.expectLastCall().anyTimes();\n+    EasyMock.expect(objectSummary.getKey()).andReturn(key);\n+    EasyMock.expectLastCall().anyTimes();\n+    return objectSummary;\n+  }\n+\n+  public static ListObjectsV2Request mockRequest(\n+      String bucket,\n+      String prefix,\n+      int maxKeys,\n+      String continuationToken\n+  )\n+  {\n+    ListObjectsV2Request request = EasyMock.createMock(ListObjectsV2Request.class);\n+    EasyMock.expect(request.getBucketName()).andReturn(bucket);\n+    EasyMock.expectLastCall().anyTimes();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2af8070937c585eefa012a1dec96751fa0e562fc"}, "originalPosition": 136}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODY4NjE4OQ==", "bodyText": "I have mixed feelings about this class. It seems to exist in service of testing S3TaskLogs.killAll, but isn't that kind of leaking what is basically a test fixture, into the production code? Since the killAll method does nothing but delegate to the other call that takes an explicit timestamp, is this abstraction really worth having?\nOn the other hand, I can see an argument for using something like this to control system time, and I guess we already have similar situations sometimes when @VisibleForTesting are only used by tests, so I'm not strictly against using this, just thinking out loud to have the discussion.\nIn the very least I think it should be renamed CurrentTimeMillisSupplier to indicate what time it is supplying, and add javadocs to describe its intended usage to ease testing.\nDoes this need to be setup in the module so that it gets injected into S3TaskLogs? (or did I miss that somewhere?)", "url": "https://github.com/apache/druid/pull/9459#discussion_r388686189", "createdAt": "2020-03-06T02:42:07Z", "author": {"login": "clintropolis"}, "path": "core/src/main/java/org/apache/druid/common/utils/TimeSupplier.java", "diffHunk": "@@ -0,0 +1,32 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+\n+package org.apache.druid.common.utils;\n+\n+import java.util.function.Supplier;\n+\n+public class TimeSupplier implements Supplier<Long>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2af8070937c585eefa012a1dec96751fa0e562fc"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODY5MTYxNA==", "bodyText": "log.info is a bit too informative for this operation I think, inside the loop at least. If you need to log anything, I suggest just counting the number of keys actually deleted and reporting the total at the end outside of the loop, or just a single message before the loop happens indicating that a some deletes are going to happen.", "url": "https://github.com/apache/druid/pull/9459#discussion_r388691614", "createdAt": "2020-03-06T03:04:47Z", "author": {"login": "clintropolis"}, "path": "extensions-core/s3-extensions/src/main/java/org/apache/druid/storage/s3/S3DataSegmentKiller.java", "diffHunk": "@@ -69,8 +85,48 @@ public void kill(DataSegment segment) throws SegmentLoadingException\n   }\n \n   @Override\n-  public void killAll()\n+  public void killAll() throws IOException\n   {\n-    throw new UnsupportedOperationException(\"not implemented\");\n+    try {\n+      S3Utils.retryS3Operation(\n+          () -> {\n+            String bucketName = segmentPusherConfig.getBucket();\n+            String prefix = segmentPusherConfig.getBaseKey();\n+            int maxListingLength = inputDataConfig.getMaxListingLength();\n+            ListObjectsV2Result result;\n+            String continuationToken = null;\n+            do {\n+              log.info(\"Deleting batch of %d segment files from s3 location [bucket: %s    prefix: %s].\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2af8070937c585eefa012a1dec96751fa0e562fc"}, "originalPosition": 62}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "345c22e98636cb96bb500f07bb06d937b6c3c782", "author": {"user": {"login": "zachjsh", "name": null}}, "url": "https://github.com/apache/druid/commit/345c22e98636cb96bb500f07bb06d937b6c3c782", "committedDate": "2020-03-10T00:52:51Z", "message": "* Address review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1c54e4cddfc0c2fa09259078c645e8465b61b12b", "author": {"user": {"login": "zachjsh", "name": null}}, "url": "https://github.com/apache/druid/commit/1c54e4cddfc0c2fa09259078c645e8465b61b12b", "committedDate": "2020-03-10T07:01:59Z", "message": "* Fix failing dependency check"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcxNjQ4OTQ4", "url": "https://github.com/apache/druid/pull/9459#pullrequestreview-371648948", "createdAt": "2020-03-10T02:45:56Z", "commit": {"oid": "345c22e98636cb96bb500f07bb06d937b6c3c782"}, "state": "APPROVED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQwMjo0NTo1N1rOFz_w_A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQwMjo0ODozNlrOFz_zhQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDA2NjQyOA==", "bodyText": "nit: this can be private actually (my bad)", "url": "https://github.com/apache/druid/pull/9459#discussion_r390066428", "createdAt": "2020-03-10T02:45:57Z", "author": {"login": "clintropolis"}, "path": "extensions-core/s3-extensions/src/main/java/org/apache/druid/storage/s3/S3Utils.java", "diffHunk": "@@ -200,6 +204,54 @@ public static S3ObjectSummary getSingleObjectSummary(ServerSideEncryptingAmazonS\n     return objectSummary;\n   }\n \n+  public static void deleteObjectsInPath(\n+      ServerSideEncryptingAmazonS3 s3Client,\n+      S3InputDataConfig config,\n+      String bucket,\n+      String prefix,\n+      Predicate<S3ObjectSummary> filter\n+  )\n+      throws Exception\n+  {\n+    final List<DeleteObjectsRequest.KeyVersion> keysToDelete = new ArrayList<>(config.getMaxListingLength());\n+    final ObjectSummaryIterator iterator = new ObjectSummaryIterator(\n+        s3Client,\n+        ImmutableList.of(new CloudObjectLocation(bucket, prefix).toUri(\"s3\")),\n+        config.getMaxListingLength()\n+    );\n+\n+    while (iterator.hasNext()) {\n+      final S3ObjectSummary nextObject = iterator.next();\n+      if (filter.apply(nextObject)) {\n+        keysToDelete.add(new DeleteObjectsRequest.KeyVersion(nextObject.getKey()));\n+        if (keysToDelete.size() == config.getMaxListingLength()) {\n+          deleteBucketKeys(s3Client, bucket, keysToDelete);\n+          log.info(\"Deleted %d files\", keysToDelete.size());\n+          keysToDelete.clear();\n+        }\n+      }\n+    }\n+\n+    if (keysToDelete.size() > 0) {\n+      deleteBucketKeys(s3Client, bucket, keysToDelete);\n+      log.info(\"Deleted %d files\", keysToDelete.size());\n+    }\n+  }\n+\n+  public static void deleteBucketKeys(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "345c22e98636cb96bb500f07bb06d937b6c3c782"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDA2NzA3Nw==", "bodyText": "nit: javadocs describing this method would be nice", "url": "https://github.com/apache/druid/pull/9459#discussion_r390067077", "createdAt": "2020-03-10T02:48:36Z", "author": {"login": "clintropolis"}, "path": "extensions-core/s3-extensions/src/main/java/org/apache/druid/storage/s3/S3Utils.java", "diffHunk": "@@ -200,6 +204,54 @@ public static S3ObjectSummary getSingleObjectSummary(ServerSideEncryptingAmazonS\n     return objectSummary;\n   }\n \n+  public static void deleteObjectsInPath(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "345c22e98636cb96bb500f07bb06d937b6c3c782"}, "originalPosition": 30}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3014, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}