{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDk0MjY3MzQ0", "number": 10445, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQyMjozNTozNlrOEoyCjA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0zMFQyMjo0MTo1NVrOEpOsAw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzExMTk4MzQ4OnYy", "diffSide": "RIGHT", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/ParallelIndexSupervisorTask.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQyMjozNTozNlrOHaEkPQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQyMjozNTozNlrOHaEkPQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzA5OTgzNw==", "bodyText": "nit: Can you create a static method useRangePartitions that takes in tuningConfig as argument to avoid repeating code/logic", "url": "https://github.com/apache/druid/pull/10445#discussion_r497099837", "createdAt": "2020-09-29T22:35:36Z", "author": {"login": "maytasm"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/ParallelIndexSupervisorTask.java", "diffHunk": "@@ -466,13 +466,20 @@ private void initializeSubTaskCleaner()\n     registerResourceCloserOnAbnormalExit(currentSubTaskHolder);\n   }\n \n-  private boolean isParallelMode()\n+  public static boolean isParallelMode(InputSource inputSource, @Nullable ParallelIndexTuningConfig tuningConfig)\n   {\n+    if (null == tuningConfig) {\n+      return false;\n+    }\n+    boolean useRangePartitions = tuningConfig.getGivenOrDefaultPartitionsSpec() instanceof SingleDimensionPartitionsSpec;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dbda34be64b709f3c5dd55c30ac4fe78daf05907"}, "originalPosition": 10}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzExMTk4NTM1OnYy", "diffSide": "RIGHT", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/CompactionTask.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQyMjozNjozMFrOHaElWQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0zMFQwNzowNTo0MlrOHaP6nA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzEwMDEyMQ==", "bodyText": "nit: You can use ingestionSpec here (instead of repeating ingestionSpecs.get(i))", "url": "https://github.com/apache/druid/pull/10445#discussion_r497100121", "createdAt": "2020-09-29T22:36:30Z", "author": {"login": "maytasm"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/CompactionTask.java", "diffHunk": "@@ -361,9 +362,13 @@ public TaskStatus runTask(TaskToolbox toolbox) throws Exception\n           // a new Appenderator on its own instead. As a result, they should use different sequence names to allocate\n           // new segmentIds properly. See IndexerSQLMetadataStorageCoordinator.allocatePendingSegments() for details.\n           // In this case, we use different fake IDs for each created index task.\n-          final String subtaskId = tuningConfig == null || tuningConfig.getMaxNumConcurrentSubTasks() == 1\n-                                   ? createIndexTaskSpecId(i)\n-                                   : getId();\n+          ParallelIndexIngestionSpec ingestionSpec = ingestionSpecs.get(i);\n+          InputSource inputSource = ingestionSpec.getIOConfig().getNonNullInputSource(\n+              ingestionSpec.getDataSchema().getParser()\n+          );\n+          final String subtaskId = ParallelIndexSupervisorTask.isParallelMode(inputSource, tuningConfig)\n+                                   ? getId()\n+                                   : createIndexTaskSpecId(i);\n           return newTask(subtaskId, ingestionSpecs.get(i));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dbda34be64b709f3c5dd55c30ac4fe78daf05907"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzI4NTc4OA==", "bodyText": "Done", "url": "https://github.com/apache/druid/pull/10445#discussion_r497285788", "createdAt": "2020-09-30T07:05:42Z", "author": {"login": "abhishekagarwal87"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/CompactionTask.java", "diffHunk": "@@ -361,9 +362,13 @@ public TaskStatus runTask(TaskToolbox toolbox) throws Exception\n           // a new Appenderator on its own instead. As a result, they should use different sequence names to allocate\n           // new segmentIds properly. See IndexerSQLMetadataStorageCoordinator.allocatePendingSegments() for details.\n           // In this case, we use different fake IDs for each created index task.\n-          final String subtaskId = tuningConfig == null || tuningConfig.getMaxNumConcurrentSubTasks() == 1\n-                                   ? createIndexTaskSpecId(i)\n-                                   : getId();\n+          ParallelIndexIngestionSpec ingestionSpec = ingestionSpecs.get(i);\n+          InputSource inputSource = ingestionSpec.getIOConfig().getNonNullInputSource(\n+              ingestionSpec.getDataSchema().getParser()\n+          );\n+          final String subtaskId = ParallelIndexSupervisorTask.isParallelMode(inputSource, tuningConfig)\n+                                   ? getId()\n+                                   : createIndexTaskSpecId(i);\n           return newTask(subtaskId, ingestionSpecs.get(i));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzEwMDEyMQ=="}, "originalCommit": {"oid": "dbda34be64b709f3c5dd55c30ac4fe78daf05907"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzExNjY3NzA3OnYy", "diffSide": "RIGHT", "path": "indexing-service/src/test/java/org/apache/druid/indexing/common/task/CompactionTaskParallelRunTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0zMFQyMjo0MTo1NVrOHaxzVg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0zMFQyMjo0MTo1NVrOHaxzVg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Nzg0MDk4Mg==", "bodyText": "There's at least one typo in this comment", "url": "https://github.com/apache/druid/pull/10445#discussion_r497840982", "createdAt": "2020-09-30T22:41:55Z", "author": {"login": "ccaominh"}, "path": "indexing-service/src/test/java/org/apache/druid/indexing/common/task/CompactionTaskParallelRunTest.java", "diffHunk": "@@ -219,6 +219,37 @@ public void testRunParallelWithRangePartitioning()\n     }\n   }\n \n+  @Test\n+  public void testRunParallelWithRangePartitioningWithSingleTask()\n+  {\n+    // Range partitioning is not supported with segment lock yet\n+    if (lockGranularity == LockGranularity.SEGMENT) {\n+      return;\n+    }\n+    runIndexTask(null, true);\n+\n+    final Builder builder = new Builder(\n+        DATA_SOURCE,\n+        getSegmentLoaderFactory(),\n+        RETRY_POLICY_FACTORY\n+    );\n+    final CompactionTask compactionTask = builder\n+        .inputSpec(new CompactionIntervalSpec(INTERVAL_TO_INDEX, null))\n+        .tuningConfig(newTuningConfig(new SingleDimensionPartitionsSpec(7, null, \"dim\", false), 1, true))\n+        .build();\n+\n+    final Set<DataSegment> compactedSegments = runTask(compactionTask);\n+    final CompactionState expectedState = new CompactionState(\n+        new SingleDimensionPartitionsSpec(7, null, \"dim\", false),\n+        compactionTask.getTuningConfig().getIndexSpec().asMap(getObjectMapper())\n+    );\n+    for (DataSegment segment : compactedSegments) {\n+      // Expecte compaction state to exist as store compaction state by default", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7322fbee6dc13d6013408a34e20ee1dd0ccb83e0"}, "originalPosition": 29}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzExNjY3NzE1OnYy", "diffSide": "RIGHT", "path": "indexing-service/src/test/java/org/apache/druid/indexing/common/task/CompactionTaskParallelRunTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0zMFQyMjo0MTo1NVrOHaxzXw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0zMFQyMjo0MTo1NVrOHaxzXw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Nzg0MDk5MQ==", "bodyText": "JUnit has an Assume API, which could be a good fit here.", "url": "https://github.com/apache/druid/pull/10445#discussion_r497840991", "createdAt": "2020-09-30T22:41:55Z", "author": {"login": "ccaominh"}, "path": "indexing-service/src/test/java/org/apache/druid/indexing/common/task/CompactionTaskParallelRunTest.java", "diffHunk": "@@ -219,6 +219,37 @@ public void testRunParallelWithRangePartitioning()\n     }\n   }\n \n+  @Test\n+  public void testRunParallelWithRangePartitioningWithSingleTask()\n+  {\n+    // Range partitioning is not supported with segment lock yet\n+    if (lockGranularity == LockGranularity.SEGMENT) {\n+      return;\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7322fbee6dc13d6013408a34e20ee1dd0ccb83e0"}, "originalPosition": 10}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2986, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}