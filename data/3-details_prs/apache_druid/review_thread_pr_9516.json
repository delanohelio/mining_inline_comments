{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg4MDgwNjE3", "number": 9516, "reviewThreads": {"totalCount": 13, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQxODo0ODoyOFrODodfRA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xN1QwMTo1Mzo1NFrODojp1A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzNzUyNzcyOnYy", "diffSide": "RIGHT", "path": "processing/src/main/java/org/apache/druid/segment/join/Joinable.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQxODo0ODoyOFrOF3BiCw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xN1QwMDowMzo0N1rOF3Jxag==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI0MTA5OQ==", "bodyText": "please update javadoc with new parameters", "url": "https://github.com/apache/druid/pull/9516#discussion_r393241099", "createdAt": "2020-03-16T18:48:28Z", "author": {"login": "clintropolis"}, "path": "processing/src/main/java/org/apache/druid/segment/join/Joinable.java", "diffHunk": "@@ -89,6 +89,8 @@ JoinMatcher makeJoinMatcher(\n   Set<String> getCorrelatedColumnValues(\n       String searchColumnName,\n       String searchColumnValue,\n-      String retrievalColumnName\n+      String retrievalColumnName,\n+      long maxCorrelationSetSize,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b4ad07fd06d0c4043bb463786bd753208fe53d17"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM3NjEwNg==", "bodyText": "Updated javadocs", "url": "https://github.com/apache/druid/pull/9516#discussion_r393376106", "createdAt": "2020-03-17T00:03:47Z", "author": {"login": "jon-wei"}, "path": "processing/src/main/java/org/apache/druid/segment/join/Joinable.java", "diffHunk": "@@ -89,6 +89,8 @@ JoinMatcher makeJoinMatcher(\n   Set<String> getCorrelatedColumnValues(\n       String searchColumnName,\n       String searchColumnValue,\n-      String retrievalColumnName\n+      String retrievalColumnName,\n+      long maxCorrelationSetSize,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI0MTA5OQ=="}, "originalCommit": {"oid": "b4ad07fd06d0c4043bb463786bd753208fe53d17"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzNzUyODY1OnYy", "diffSide": "RIGHT", "path": "processing/src/main/java/org/apache/druid/segment/join/Joinables.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQxODo0ODo1MFrOF3Bitw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xN1QwMDowMzo1M1rOF3Jxlg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI0MTI3MQ==", "bodyText": "ditto javadoc", "url": "https://github.com/apache/druid/pull/9516#discussion_r393241271", "createdAt": "2020-03-16T18:48:50Z", "author": {"login": "clintropolis"}, "path": "processing/src/main/java/org/apache/druid/segment/join/Joinables.java", "diffHunk": "@@ -83,17 +87,31 @@ public static boolean isPrefixedBy(final String columnName, final String prefix)\n       final JoinableFactory joinableFactory,\n       final AtomicLong cpuTimeAccumulator,\n       final boolean enableFilterPushDown,\n-      final boolean enableFilterRewrite\n+      final boolean enableFilterRewrite,\n+      final boolean enableRewriteValueColumnFilters,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b4ad07fd06d0c4043bb463786bd753208fe53d17"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM3NjE1MA==", "bodyText": "Updated javadocs", "url": "https://github.com/apache/druid/pull/9516#discussion_r393376150", "createdAt": "2020-03-17T00:03:53Z", "author": {"login": "jon-wei"}, "path": "processing/src/main/java/org/apache/druid/segment/join/Joinables.java", "diffHunk": "@@ -83,17 +87,31 @@ public static boolean isPrefixedBy(final String columnName, final String prefix)\n       final JoinableFactory joinableFactory,\n       final AtomicLong cpuTimeAccumulator,\n       final boolean enableFilterPushDown,\n-      final boolean enableFilterRewrite\n+      final boolean enableFilterRewrite,\n+      final boolean enableRewriteValueColumnFilters,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI0MTI3MQ=="}, "originalCommit": {"oid": "b4ad07fd06d0c4043bb463786bd753208fe53d17"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzNzY0NzY3OnYy", "diffSide": "RIGHT", "path": "processing/src/test/java/org/apache/druid/segment/join/JoinFilterAnalyzerTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQxOToyMzo1NVrOF3CuTg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xN1QwMDowMzo1OVrOF3Jxrg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI2MDYyMg==", "bodyText": "could you make a utility method that makes a JoinFilterPreAnalysis from a joinableClauses and originalFilter? seems like a lot of these blocks and all the other arguments are the same. Alternatively a builder for JoinFilterPreAnalysis would work, though idk if worth the effort since it would be mostly used by tests.", "url": "https://github.com/apache/druid/pull/9516#discussion_r393260622", "createdAt": "2020-03-16T19:23:55Z", "author": {"login": "clintropolis"}, "path": "processing/src/test/java/org/apache/druid/segment/join/JoinFilterAnalyzerTest.java", "diffHunk": "@@ -245,6 +266,27 @@ public void test_filterPushDown_factToRegionToCountryLeftFilterOnNullColumns()\n         )\n     );\n \n+    List<JoinableClause> joinableClauses = ImmutableList.of(\n+        factToRegion(JoinType.LEFT),\n+        regionToCountry(JoinType.LEFT)\n+    );\n+\n+    JoinFilterPreAnalysis joinFilterPreAnalysis = JoinFilterAnalyzer.computeJoinFilterPreAnalysis(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "06847170cfcc09d2a82f650a32de75975fa6715c"}, "originalPosition": 209}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM3NjE3NA==", "bodyText": "Made a utility method", "url": "https://github.com/apache/druid/pull/9516#discussion_r393376174", "createdAt": "2020-03-17T00:03:59Z", "author": {"login": "jon-wei"}, "path": "processing/src/test/java/org/apache/druid/segment/join/JoinFilterAnalyzerTest.java", "diffHunk": "@@ -245,6 +266,27 @@ public void test_filterPushDown_factToRegionToCountryLeftFilterOnNullColumns()\n         )\n     );\n \n+    List<JoinableClause> joinableClauses = ImmutableList.of(\n+        factToRegion(JoinType.LEFT),\n+        regionToCountry(JoinType.LEFT)\n+    );\n+\n+    JoinFilterPreAnalysis joinFilterPreAnalysis = JoinFilterAnalyzer.computeJoinFilterPreAnalysis(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI2MDYyMg=="}, "originalCommit": {"oid": "06847170cfcc09d2a82f650a32de75975fa6715c"}, "originalPosition": 209}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzNzY2NjY3OnYy", "diffSide": "RIGHT", "path": "processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQxOTozMDozNVrOF3C60g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xN1QwMDowNDoxMFrOF3Jx1Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI2MzgyNg==", "bodyText": "did you mean to put these <p> tags?", "url": "https://github.com/apache/druid/pull/9516#discussion_r393263826", "createdAt": "2020-03-16T19:30:35Z", "author": {"login": "clintropolis"}, "path": "processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java", "diffHunk": "@@ -50,73 +51,126 @@\n /**\n  * When there is a filter in a join query, we can sometimes improve performance by applying parts of the filter\n  * when we first read from the base table instead of after the join.\n- *\n- * This class provides a {@link #splitFilter(HashJoinSegmentStorageAdapter, Set, Filter, boolean, boolean)} method that\n- * takes a filter and splits it into a portion that should be applied to the base table prior to the join, and a\n- * portion that should be applied after the join.\n- *\n+ * <p>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "06847170cfcc09d2a82f650a32de75975fa6715c"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM3NjIxMw==", "bodyText": "I removed the <p> tags", "url": "https://github.com/apache/druid/pull/9516#discussion_r393376213", "createdAt": "2020-03-17T00:04:10Z", "author": {"login": "jon-wei"}, "path": "processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java", "diffHunk": "@@ -50,73 +51,126 @@\n /**\n  * When there is a filter in a join query, we can sometimes improve performance by applying parts of the filter\n  * when we first read from the base table instead of after the join.\n- *\n- * This class provides a {@link #splitFilter(HashJoinSegmentStorageAdapter, Set, Filter, boolean, boolean)} method that\n- * takes a filter and splits it into a portion that should be applied to the base table prior to the join, and a\n- * portion that should be applied after the join.\n- *\n+ * <p>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI2MzgyNg=="}, "originalCommit": {"oid": "06847170cfcc09d2a82f650a32de75975fa6715c"}, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzNzY3MjQ5OnYy", "diffSide": "RIGHT", "path": "processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQxOTozMjoyOVrOF3C-dg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xN1QwMDowNDoxOFrOF3Jx9Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI2NDc1OA==", "bodyText": "super nit: could you retain the old formatting where the descriptions are offset to the right and aligned? I find it a bit easier to read", "url": "https://github.com/apache/druid/pull/9516#discussion_r393264758", "createdAt": "2020-03-16T19:32:29Z", "author": {"login": "clintropolis"}, "path": "processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java", "diffHunk": "@@ -50,73 +51,126 @@\n /**\n  * When there is a filter in a join query, we can sometimes improve performance by applying parts of the filter\n  * when we first read from the base table instead of after the join.\n- *\n- * This class provides a {@link #splitFilter(HashJoinSegmentStorageAdapter, Set, Filter, boolean, boolean)} method that\n- * takes a filter and splits it into a portion that should be applied to the base table prior to the join, and a\n- * portion that should be applied after the join.\n- *\n+ * <p>\n  * The first step of the filter splitting is to convert the filter into\n  * https://en.wikipedia.org/wiki/Conjunctive_normal_form (an AND of ORs). This allows us to consider each\n  * OR clause independently as a candidate for filter push down to the base table.\n- *\n+ * <p>\n  * A filter clause can be pushed down if it meets one of the following conditions:\n  * - The filter only applies to columns from the base table\n  * - The filter applies to columns from the join table, and we determine that the filter can be rewritten\n  *   into a filter on columns from the base table\n- *\n+ * <p>\n  * For the second case, where we rewrite filter clauses, the rewritten clause can be less selective than the original,\n  * so we preserve the original clause in the post-join filtering phase.\n+ * <p>\n+ * The starting point for join analysis is the {@link #computeJoinFilterPreAnalysis} method. This method should be\n+ * called before performing any per-segment join query work. This method converts the query filter into\n+ * conjunctive normal form, and splits the CNF clauses into a portion that only references base table columns and\n+ * a portion that references join table columns. For the filter clauses that apply to join table columns, the\n+ * pre-analysis step computes the information necessary for rewriting such filters into filters on base table columns.\n+ * <p>\n+ * The result of this pre-analysis method should be passed into the next step of join filter analysis, described below.\n+ * <p>\n+ * The {@link #splitFilter(JoinFilterPreAnalysis)} method takes the pre-analysis result and optionally applies the\\\n+ * filter rewrite and push down operations on a per-segment level.\n  */\n public class JoinFilterAnalyzer\n {\n   private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n   private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n \n   /**\n-   * Analyze a filter and return a JoinFilterSplit indicating what parts of the filter should be applied pre-join\n-   * and post-join.\n+   * Before making per-segment filter splitting decisions, we first do a pre-analysis step\n+   * where we convert the query filter (if any) into conjunctive normal form and then\n+   * determine the structure of RHS filter rewrites (if any), since this information is shared across all\n+   * per-segment operations.\n    *\n-   * @param hashJoinSegmentStorageAdapter The storage adapter that is being queried\n-   * @param baseColumnNames               Set of names of columns that belong to the base table,\n-   *                                      including pre-join virtual columns\n-   * @param originalFilter                Original filter from the query\n-   * @param enableFilterPushDown          Whether to enable filter push down\n-   * @return A JoinFilterSplit indicating what parts of the filter should be applied pre-join\n-   *         and post-join.\n+   * See {@link JoinFilterPreAnalysis} for details on the result of this pre-analysis step.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "06847170cfcc09d2a82f650a32de75975fa6715c"}, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM3NjI0NQ==", "bodyText": "Adjusted the alignment", "url": "https://github.com/apache/druid/pull/9516#discussion_r393376245", "createdAt": "2020-03-17T00:04:18Z", "author": {"login": "jon-wei"}, "path": "processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java", "diffHunk": "@@ -50,73 +51,126 @@\n /**\n  * When there is a filter in a join query, we can sometimes improve performance by applying parts of the filter\n  * when we first read from the base table instead of after the join.\n- *\n- * This class provides a {@link #splitFilter(HashJoinSegmentStorageAdapter, Set, Filter, boolean, boolean)} method that\n- * takes a filter and splits it into a portion that should be applied to the base table prior to the join, and a\n- * portion that should be applied after the join.\n- *\n+ * <p>\n  * The first step of the filter splitting is to convert the filter into\n  * https://en.wikipedia.org/wiki/Conjunctive_normal_form (an AND of ORs). This allows us to consider each\n  * OR clause independently as a candidate for filter push down to the base table.\n- *\n+ * <p>\n  * A filter clause can be pushed down if it meets one of the following conditions:\n  * - The filter only applies to columns from the base table\n  * - The filter applies to columns from the join table, and we determine that the filter can be rewritten\n  *   into a filter on columns from the base table\n- *\n+ * <p>\n  * For the second case, where we rewrite filter clauses, the rewritten clause can be less selective than the original,\n  * so we preserve the original clause in the post-join filtering phase.\n+ * <p>\n+ * The starting point for join analysis is the {@link #computeJoinFilterPreAnalysis} method. This method should be\n+ * called before performing any per-segment join query work. This method converts the query filter into\n+ * conjunctive normal form, and splits the CNF clauses into a portion that only references base table columns and\n+ * a portion that references join table columns. For the filter clauses that apply to join table columns, the\n+ * pre-analysis step computes the information necessary for rewriting such filters into filters on base table columns.\n+ * <p>\n+ * The result of this pre-analysis method should be passed into the next step of join filter analysis, described below.\n+ * <p>\n+ * The {@link #splitFilter(JoinFilterPreAnalysis)} method takes the pre-analysis result and optionally applies the\\\n+ * filter rewrite and push down operations on a per-segment level.\n  */\n public class JoinFilterAnalyzer\n {\n   private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n   private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n \n   /**\n-   * Analyze a filter and return a JoinFilterSplit indicating what parts of the filter should be applied pre-join\n-   * and post-join.\n+   * Before making per-segment filter splitting decisions, we first do a pre-analysis step\n+   * where we convert the query filter (if any) into conjunctive normal form and then\n+   * determine the structure of RHS filter rewrites (if any), since this information is shared across all\n+   * per-segment operations.\n    *\n-   * @param hashJoinSegmentStorageAdapter The storage adapter that is being queried\n-   * @param baseColumnNames               Set of names of columns that belong to the base table,\n-   *                                      including pre-join virtual columns\n-   * @param originalFilter                Original filter from the query\n-   * @param enableFilterPushDown          Whether to enable filter push down\n-   * @return A JoinFilterSplit indicating what parts of the filter should be applied pre-join\n-   *         and post-join.\n+   * See {@link JoinFilterPreAnalysis} for details on the result of this pre-analysis step.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI2NDc1OA=="}, "originalCommit": {"oid": "06847170cfcc09d2a82f650a32de75975fa6715c"}, "originalPosition": 84}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzNzc5MzE4OnYy", "diffSide": "RIGHT", "path": "processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQyMDoxMzowMlrOF3ELeQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xN1QwMDowNDoyNlrOF3JyHw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI4NDQ3Mw==", "bodyText": "nit: I think this should probably be named RhsRewriteCandidate", "url": "https://github.com/apache/druid/pull/9516#discussion_r393284473", "createdAt": "2020-03-16T20:13:02Z", "author": {"login": "clintropolis"}, "path": "processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java", "diffHunk": "@@ -635,4 +694,106 @@ private static boolean filterMatchesNull(Filter filter)\n     ValueMatcher valueMatcher = filter.makeMatcher(ALL_NULL_COLUMN_SELECTOR_FACTORY);\n     return valueMatcher.matches();\n   }\n+\n+  private static JoinableClause isColumnFromJoin(\n+      List<JoinableClause> joinableClauses,\n+      String column\n+  )\n+  {\n+    for (JoinableClause joinableClause : joinableClauses) {\n+      if (joinableClause.includesColumn(column)) {\n+        return joinableClause;\n+      }\n+    }\n+\n+    return null;\n+  }\n+\n+  private static boolean isColumnFromPostJoinVirtualColumns(\n+      List<VirtualColumn> postJoinVirtualColumns,\n+      String column\n+  )\n+  {\n+    for (VirtualColumn postJoinVirtualColumn : postJoinVirtualColumns) {\n+      if (column.equals(postJoinVirtualColumn.getOutputName())) {\n+        return true;\n+      }\n+    }\n+    return false;\n+  }\n+\n+  private static boolean areSomeColumnsFromJoin(\n+      List<JoinableClause> joinableClauses,\n+      Collection<String> columns\n+  )\n+  {\n+    for (String column : columns) {\n+      if (isColumnFromJoin(joinableClauses, column) != null) {\n+        return true;\n+      }\n+    }\n+    return false;\n+  }\n+\n+  private static boolean areSomeColumnsFromPostJoinVirtualColumns(\n+      List<VirtualColumn> postJoinVirtualColumns,\n+      Collection<String> columns\n+  )\n+  {\n+    for (String column : columns) {\n+      if (isColumnFromPostJoinVirtualColumns(postJoinVirtualColumns, column)) {\n+        return true;\n+      }\n+    }\n+    return false;\n+  }\n+\n+  private static void splitVirtualColumns(\n+      List<JoinableClause> joinableClauses,\n+      final VirtualColumns virtualColumns,\n+      final List<VirtualColumn> preJoinVirtualColumns,\n+      final List<VirtualColumn> postJoinVirtualColumns\n+  )\n+  {\n+    for (VirtualColumn virtualColumn : virtualColumns.getVirtualColumns()) {\n+      if (areSomeColumnsFromJoin(joinableClauses, virtualColumn.requiredColumns())) {\n+        postJoinVirtualColumns.add(virtualColumn);\n+      } else {\n+        preJoinVirtualColumns.add(virtualColumn);\n+      }\n+    }\n+  }\n+\n+  private static class RHSRewriteCandidate", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "06847170cfcc09d2a82f650a32de75975fa6715c"}, "originalPosition": 976}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM3NjI4Nw==", "bodyText": "Renamed to that casing", "url": "https://github.com/apache/druid/pull/9516#discussion_r393376287", "createdAt": "2020-03-17T00:04:26Z", "author": {"login": "jon-wei"}, "path": "processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java", "diffHunk": "@@ -635,4 +694,106 @@ private static boolean filterMatchesNull(Filter filter)\n     ValueMatcher valueMatcher = filter.makeMatcher(ALL_NULL_COLUMN_SELECTOR_FACTORY);\n     return valueMatcher.matches();\n   }\n+\n+  private static JoinableClause isColumnFromJoin(\n+      List<JoinableClause> joinableClauses,\n+      String column\n+  )\n+  {\n+    for (JoinableClause joinableClause : joinableClauses) {\n+      if (joinableClause.includesColumn(column)) {\n+        return joinableClause;\n+      }\n+    }\n+\n+    return null;\n+  }\n+\n+  private static boolean isColumnFromPostJoinVirtualColumns(\n+      List<VirtualColumn> postJoinVirtualColumns,\n+      String column\n+  )\n+  {\n+    for (VirtualColumn postJoinVirtualColumn : postJoinVirtualColumns) {\n+      if (column.equals(postJoinVirtualColumn.getOutputName())) {\n+        return true;\n+      }\n+    }\n+    return false;\n+  }\n+\n+  private static boolean areSomeColumnsFromJoin(\n+      List<JoinableClause> joinableClauses,\n+      Collection<String> columns\n+  )\n+  {\n+    for (String column : columns) {\n+      if (isColumnFromJoin(joinableClauses, column) != null) {\n+        return true;\n+      }\n+    }\n+    return false;\n+  }\n+\n+  private static boolean areSomeColumnsFromPostJoinVirtualColumns(\n+      List<VirtualColumn> postJoinVirtualColumns,\n+      Collection<String> columns\n+  )\n+  {\n+    for (String column : columns) {\n+      if (isColumnFromPostJoinVirtualColumns(postJoinVirtualColumns, column)) {\n+        return true;\n+      }\n+    }\n+    return false;\n+  }\n+\n+  private static void splitVirtualColumns(\n+      List<JoinableClause> joinableClauses,\n+      final VirtualColumns virtualColumns,\n+      final List<VirtualColumn> preJoinVirtualColumns,\n+      final List<VirtualColumn> postJoinVirtualColumns\n+  )\n+  {\n+    for (VirtualColumn virtualColumn : virtualColumns.getVirtualColumns()) {\n+      if (areSomeColumnsFromJoin(joinableClauses, virtualColumn.requiredColumns())) {\n+        postJoinVirtualColumns.add(virtualColumn);\n+      } else {\n+        preJoinVirtualColumns.add(virtualColumn);\n+      }\n+    }\n+  }\n+\n+  private static class RHSRewriteCandidate", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI4NDQ3Mw=="}, "originalCommit": {"oid": "06847170cfcc09d2a82f650a32de75975fa6715c"}, "originalPosition": 976}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzNzc5Njk1OnYy", "diffSide": "RIGHT", "path": "processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQyMDoxNDoxOVrOF3EN0A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xN1QwMDowNDozM1rOF3JyOw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI4NTA3Mg==", "bodyText": "ditto question if <p> are intentional", "url": "https://github.com/apache/druid/pull/9516#discussion_r393285072", "createdAt": "2020-03-16T20:14:19Z", "author": {"login": "clintropolis"}, "path": "processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java", "diffHunk": "@@ -602,20 +660,21 @@ private static void getCorrelationForRHSColumn(\n   /**\n    * Given a list of JoinFilterColumnCorrelationAnalysis, prune the list so that we only have one\n    * JoinFilterColumnCorrelationAnalysis for each unique combination of base columns.\n-   *\n+   * <p>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "06847170cfcc09d2a82f650a32de75975fa6715c"}, "originalPosition": 880}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM3NjMxNQ==", "bodyText": "Removed the <p> tags", "url": "https://github.com/apache/druid/pull/9516#discussion_r393376315", "createdAt": "2020-03-17T00:04:33Z", "author": {"login": "jon-wei"}, "path": "processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java", "diffHunk": "@@ -602,20 +660,21 @@ private static void getCorrelationForRHSColumn(\n   /**\n    * Given a list of JoinFilterColumnCorrelationAnalysis, prune the list so that we only have one\n    * JoinFilterColumnCorrelationAnalysis for each unique combination of base columns.\n-   *\n+   * <p>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI4NTA3Mg=="}, "originalCommit": {"oid": "06847170cfcc09d2a82f650a32de75975fa6715c"}, "originalPosition": 880}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzNzgwMDIyOnYy", "diffSide": "RIGHT", "path": "processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQyMDoxNTozNlrOF3EQCA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xN1QwMDowNTowM1rOF3JysA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI4NTY0MA==", "bodyText": "why remove javadocs?", "url": "https://github.com/apache/druid/pull/9516#discussion_r393285640", "createdAt": "2020-03-16T20:15:36Z", "author": {"login": "clintropolis"}, "path": "processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java", "diffHunk": "@@ -462,45 +559,14 @@ private static String getCorrelatedBaseExprVirtualColumnName(int counter)\n     return clauseForFilteredTable.getJoinable().getCorrelatedColumnValues(\n         filterColumnNoPrefix,\n         filterValue,\n-        correlatedColumnNoPrefix\n+        correlatedColumnNoPrefix,\n+        filterRewriteMaxSize,\n+        enableRewriteValueColumnFilters\n     );\n   }\n \n-  /**\n-   * For each rhs column that appears in the equiconditions for a table's JoinableClause,\n-   * we try to determine what base table columns are related to the rhs column through the total set of equiconditions.\n-   * We do this by searching backwards through the chain of join equiconditions using the provided equicondition map.\n-   *\n-   * For example, suppose we have 3 tables, A,B,C, joined with the following conditions, where A is the base table:\n-   *   A.joinColumn == B.joinColumn\n-   *   B.joinColum == C.joinColumn\n-   *\n-   * We would determine that C.joinColumn is correlated with A.joinColumn: we first see that\n-   * C.joinColumn is linked to B.joinColumn which in turn is linked to A.joinColumn\n-   *\n-   * Suppose we had the following join conditions instead:\n-   *   f(A.joinColumn) == B.joinColumn\n-   *   B.joinColum == C.joinColumn\n-   * In this case, the JoinFilterColumnCorrelationAnalysis for C.joinColumn would be linked to f(A.joinColumn).\n-   *\n-   * Suppose we had the following join conditions instead:\n-   *   A.joinColumn == B.joinColumn\n-   *   f(B.joinColum) == C.joinColumn\n-   *\n-   * Because we cannot reverse the function f() applied to the second table B in all cases,\n-   * we cannot relate C.joinColumn to A.joinColumn, and we would not generate a correlation for C.joinColumn\n-   *\n-   * @param baseColumnNames      Set of names of columns that belong to the base table, including pre-join virtual\n-   *                             columns\n-   * @param tablePrefix          Prefix for a join table\n-   * @param clauseForTablePrefix Joinable clause for the prefix\n-   * @param equiConditions       Map of equiconditions, keyed by the right hand columns\n-   *\n-   * @return A list of correlatation analyses for the equicondition RHS columns that reside in the table associated with\n-   * the tablePrefix\n-   */\n-  private static Optional<List<JoinFilterColumnCorrelationAnalysis>> findCorrelatedBaseTableColumns(\n-      Set<String> baseColumnNames,\n+  private static Optional<Map<String, JoinFilterColumnCorrelationAnalysis>> findCorrelatedBaseTableColumns(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "06847170cfcc09d2a82f650a32de75975fa6715c"}, "originalPosition": 784}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM3NjQzMg==", "bodyText": "Whoops, restored the missing javadocs", "url": "https://github.com/apache/druid/pull/9516#discussion_r393376432", "createdAt": "2020-03-17T00:05:03Z", "author": {"login": "jon-wei"}, "path": "processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java", "diffHunk": "@@ -462,45 +559,14 @@ private static String getCorrelatedBaseExprVirtualColumnName(int counter)\n     return clauseForFilteredTable.getJoinable().getCorrelatedColumnValues(\n         filterColumnNoPrefix,\n         filterValue,\n-        correlatedColumnNoPrefix\n+        correlatedColumnNoPrefix,\n+        filterRewriteMaxSize,\n+        enableRewriteValueColumnFilters\n     );\n   }\n \n-  /**\n-   * For each rhs column that appears in the equiconditions for a table's JoinableClause,\n-   * we try to determine what base table columns are related to the rhs column through the total set of equiconditions.\n-   * We do this by searching backwards through the chain of join equiconditions using the provided equicondition map.\n-   *\n-   * For example, suppose we have 3 tables, A,B,C, joined with the following conditions, where A is the base table:\n-   *   A.joinColumn == B.joinColumn\n-   *   B.joinColum == C.joinColumn\n-   *\n-   * We would determine that C.joinColumn is correlated with A.joinColumn: we first see that\n-   * C.joinColumn is linked to B.joinColumn which in turn is linked to A.joinColumn\n-   *\n-   * Suppose we had the following join conditions instead:\n-   *   f(A.joinColumn) == B.joinColumn\n-   *   B.joinColum == C.joinColumn\n-   * In this case, the JoinFilterColumnCorrelationAnalysis for C.joinColumn would be linked to f(A.joinColumn).\n-   *\n-   * Suppose we had the following join conditions instead:\n-   *   A.joinColumn == B.joinColumn\n-   *   f(B.joinColum) == C.joinColumn\n-   *\n-   * Because we cannot reverse the function f() applied to the second table B in all cases,\n-   * we cannot relate C.joinColumn to A.joinColumn, and we would not generate a correlation for C.joinColumn\n-   *\n-   * @param baseColumnNames      Set of names of columns that belong to the base table, including pre-join virtual\n-   *                             columns\n-   * @param tablePrefix          Prefix for a join table\n-   * @param clauseForTablePrefix Joinable clause for the prefix\n-   * @param equiConditions       Map of equiconditions, keyed by the right hand columns\n-   *\n-   * @return A list of correlatation analyses for the equicondition RHS columns that reside in the table associated with\n-   * the tablePrefix\n-   */\n-  private static Optional<List<JoinFilterColumnCorrelationAnalysis>> findCorrelatedBaseTableColumns(\n-      Set<String> baseColumnNames,\n+  private static Optional<Map<String, JoinFilterColumnCorrelationAnalysis>> findCorrelatedBaseTableColumns(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI4NTY0MA=="}, "originalCommit": {"oid": "06847170cfcc09d2a82f650a32de75975fa6715c"}, "originalPosition": 784}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzNzgwMTMwOnYy", "diffSide": "RIGHT", "path": "processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQyMDoxNTo1N1rOF3EQrQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xN1QwMDowNToxMlrOF3Jy4w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI4NTgwNQ==", "bodyText": "same question about removing javadocs", "url": "https://github.com/apache/druid/pull/9516#discussion_r393285805", "createdAt": "2020-03-16T20:15:57Z", "author": {"login": "clintropolis"}, "path": "processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java", "diffHunk": "@@ -540,25 +607,15 @@ private static String getCorrelatedBaseExprVirtualColumnName(int counter)\n       );\n     }\n \n-    List<JoinFilterColumnCorrelationAnalysis> dedupCorrelations = eliminateCorrelationDuplicates(correlations);\n-\n-    return Optional.of(dedupCorrelations);\n+    if (correlations.size() == 0) {\n+      return Optional.empty();\n+    } else {\n+      return Optional.of(correlations);\n+    }\n   }\n \n-  /**\n-   * Helper method for {@link #findCorrelatedBaseTableColumns} that determines correlated base table columns\n-   * and/or expressions for a single RHS column and adds them to the provided sets as it traverses the\n-   * equicondition column relationships.\n-   *\n-   * @param baseColumnNames  Set of names of columns that belong to the base table, including pre-join virtual columns\n-   * @param equiConditions Map of equiconditions, keyed by the right hand columns\n-   * @param rhsColumn RHS column to find base table correlations for\n-   * @param correlatedBaseColumns Set of correlated base column names for the provided RHS column. Will be modified.\n-   * @param correlatedBaseExpressions Set of correlated base column expressions for the provided RHS column. Will be\n-   *                                  modified.\n-   */\n   private static void getCorrelationForRHSColumn(\n-      Set<String> baseColumnNames,\n+      List<JoinableClause> joinableClauses,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "06847170cfcc09d2a82f650a32de75975fa6715c"}, "originalPosition": 848}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM3NjQ4Mw==", "bodyText": "Fixed, restored the docs", "url": "https://github.com/apache/druid/pull/9516#discussion_r393376483", "createdAt": "2020-03-17T00:05:12Z", "author": {"login": "jon-wei"}, "path": "processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java", "diffHunk": "@@ -540,25 +607,15 @@ private static String getCorrelatedBaseExprVirtualColumnName(int counter)\n       );\n     }\n \n-    List<JoinFilterColumnCorrelationAnalysis> dedupCorrelations = eliminateCorrelationDuplicates(correlations);\n-\n-    return Optional.of(dedupCorrelations);\n+    if (correlations.size() == 0) {\n+      return Optional.empty();\n+    } else {\n+      return Optional.of(correlations);\n+    }\n   }\n \n-  /**\n-   * Helper method for {@link #findCorrelatedBaseTableColumns} that determines correlated base table columns\n-   * and/or expressions for a single RHS column and adds them to the provided sets as it traverses the\n-   * equicondition column relationships.\n-   *\n-   * @param baseColumnNames  Set of names of columns that belong to the base table, including pre-join virtual columns\n-   * @param equiConditions Map of equiconditions, keyed by the right hand columns\n-   * @param rhsColumn RHS column to find base table correlations for\n-   * @param correlatedBaseColumns Set of correlated base column names for the provided RHS column. Will be modified.\n-   * @param correlatedBaseExpressions Set of correlated base column expressions for the provided RHS column. Will be\n-   *                                  modified.\n-   */\n   private static void getCorrelationForRHSColumn(\n-      Set<String> baseColumnNames,\n+      List<JoinableClause> joinableClauses,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI4NTgwNQ=="}, "originalCommit": {"oid": "06847170cfcc09d2a82f650a32de75975fa6715c"}, "originalPosition": 848}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzNzgwNzM2OnYy", "diffSide": "RIGHT", "path": "processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQyMDoxODoxMVrOF3EUgQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xN1QwMDo0NDo1NFrOF3KY0Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI4Njc4NQ==", "bodyText": "hmm, this is already done in #9367, should you make the modification to make this comment no longer true?", "url": "https://github.com/apache/druid/pull/9516#discussion_r393286785", "createdAt": "2020-03-16T20:18:11Z", "author": {"login": "clintropolis"}, "path": "processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java", "diffHunk": "@@ -311,124 +431,99 @@ private static JoinFilterAnalysis rewriteOrFilter(\n     );\n   }\n \n-  /**\n-   * Rewrites a selector filter on a join table into an IN filter on the base table.\n-   *\n-   * @param baseColumnNames  Set of names of columns that belong to the base table, including pre-join virtual\n-   *                         columns\n-   * @param selectorFilter   SelectorFilter to be rewritten\n-   * @param prefixes         Map of join table prefixes to clauses\n-   * @param equiconditions   Map of equiconditions\n-   * @param correlationCache Cache of column correlation analyses. This will be potentially modified by adding\n-   *                         any new column correlation analyses to the cache.\n-   *\n-   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n-   */\n   private static JoinFilterAnalysis rewriteSelectorFilter(\n-      Set<String> baseColumnNames,\n       SelectorFilter selectorFilter,\n-      Map<String, JoinableClause> prefixes,\n-      Map<String, Set<Expr>> equiconditions,\n-      Map<String, Optional<List<JoinFilterColumnCorrelationAnalysis>>> correlationCache\n+      JoinFilterPreAnalysis joinFilterPreAnalysis\n   )\n   {\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    List<VirtualColumn> pushdownVirtualColumns = new ArrayList<>();\n+\n     String filteringColumn = selectorFilter.getDimension();\n-    for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n-      if (prefixAndClause.getValue().includesColumn(filteringColumn)) {\n-        Optional<List<JoinFilterColumnCorrelationAnalysis>> correlations = correlationCache.computeIfAbsent(\n-            prefixAndClause.getKey(),\n-            p -> findCorrelatedBaseTableColumns(\n-                baseColumnNames,\n-                p,\n-                prefixes.get(p),\n-                equiconditions\n-            )\n-        );\n+    String filteringValue = selectorFilter.getValue();\n \n-        if (!correlations.isPresent()) {\n-          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n-        }\n+    if (areSomeColumnsFromPostJoinVirtualColumns(\n+        joinFilterPreAnalysis.getPostJoinVirtualColumns(),\n+        selectorFilter.getRequiredColumns()\n+    )) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+    }\n \n-        List<Filter> newFilters = new ArrayList<>();\n-        List<VirtualColumn> pushdownVirtualColumns = new ArrayList<>();\n+    if (!areSomeColumnsFromJoin(joinFilterPreAnalysis.getJoinableClauses(), selectorFilter.getRequiredColumns())) {\n+      return new JoinFilterAnalysis(\n+          true,\n+          selectorFilter,\n+          selectorFilter,\n+          pushdownVirtualColumns\n+      );\n+    }\n \n-        for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlations.get()) {\n-          if (correlationAnalysis.supportsPushDown()) {\n-            Set<String> correlatedValues = getCorrelatedValuesForPushDown(\n-                selectorFilter.getDimension(),\n-                selectorFilter.getValue(),\n-                correlationAnalysis.getJoinColumn(),\n-                prefixAndClause.getValue()\n-            );\n+    Optional<List<JoinFilterColumnCorrelationAnalysis>> correlationAnalyses = joinFilterPreAnalysis.getCorrelationsByFilteringColumn()\n+                                                                                                   .get(filteringColumn);\n \n-            if (correlatedValues.isEmpty()) {\n-              return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n-            }\n+    if (!correlationAnalyses.isPresent()) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+    }\n \n-            for (String correlatedBaseColumn : correlationAnalysis.getBaseColumns()) {\n-              Filter rewrittenFilter = new InDimFilter(\n-                  correlatedBaseColumn,\n-                  correlatedValues,\n-                  null,\n-                  null\n-              ).toFilter();\n-              newFilters.add(rewrittenFilter);\n-            }\n \n-            for (Expr correlatedBaseExpr : correlationAnalysis.getBaseExpressions()) {\n-              // We need to create a virtual column for the expressions when pushing down.\n-              // Note that this block is never entered right now, since correlationAnalysis.supportsPushDown()\n-              // will return false if there any correlated expressions on the base table.\n-              // Pushdown of such filters is disabled until the expressions system supports converting an expression\n-              // into a String representation that can be reparsed into the same expression.\n-              // https://github.com/apache/druid/issues/9326 tracks this expressions issue.\n-              String vcName = getCorrelatedBaseExprVirtualColumnName(pushdownVirtualColumns.size());\n-\n-              VirtualColumn correlatedBaseExprVirtualColumn = new ExpressionVirtualColumn(\n-                  vcName,\n-                  correlatedBaseExpr,\n-                  ValueType.STRING\n-              );\n-              pushdownVirtualColumns.add(correlatedBaseExprVirtualColumn);\n-\n-              Filter rewrittenFilter = new InDimFilter(\n-                  vcName,\n-                  correlatedValues,\n-                  null,\n-                  null\n-              ).toFilter();\n-              newFilters.add(rewrittenFilter);\n-            }\n-          }\n-        }\n+    for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlationAnalyses.get()) {\n+      if (correlationAnalysis.supportsPushDown()) {\n+        Optional<Set<String>> correlatedValues = correlationAnalysis.getCorrelatedValuesMap().get(\n+            Pair.of(filteringColumn, filteringValue)\n+        );\n \n-        if (newFilters.isEmpty()) {\n+        if (!correlatedValues.isPresent()) {\n           return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n         }\n \n-        return new JoinFilterAnalysis(\n-            true,\n-            selectorFilter,\n-            Filters.and(newFilters),\n-            pushdownVirtualColumns\n-        );\n+        for (String correlatedBaseColumn : correlationAnalysis.getBaseColumns()) {\n+          Filter rewrittenFilter = new InDimFilter(\n+              correlatedBaseColumn,\n+              correlatedValues.get(),\n+              null,\n+              null\n+          ).toFilter();\n+          newFilters.add(rewrittenFilter);\n+        }\n+\n+        for (Expr correlatedBaseExpr : correlationAnalysis.getBaseExpressions()) {\n+          // We need to create a virtual column for the expressions when pushing down.\n+          // Note that this block is never entered right now, since correlationAnalysis.supportsPushDown()\n+          // will return false if there any correlated expressions on the base table.\n+          // Pushdown of such filters is disabled until the expressions system supports converting an expression\n+          // into a String representation that can be reparsed into the same expression.\n+          // https://github.com/apache/druid/issues/9326 tracks this expressions issue.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "06847170cfcc09d2a82f650a32de75975fa6715c"}, "originalPosition": 681}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM3NzE0OQ==", "bodyText": "I'll do that in a follow-on PR", "url": "https://github.com/apache/druid/pull/9516#discussion_r393377149", "createdAt": "2020-03-17T00:07:26Z", "author": {"login": "jon-wei"}, "path": "processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java", "diffHunk": "@@ -311,124 +431,99 @@ private static JoinFilterAnalysis rewriteOrFilter(\n     );\n   }\n \n-  /**\n-   * Rewrites a selector filter on a join table into an IN filter on the base table.\n-   *\n-   * @param baseColumnNames  Set of names of columns that belong to the base table, including pre-join virtual\n-   *                         columns\n-   * @param selectorFilter   SelectorFilter to be rewritten\n-   * @param prefixes         Map of join table prefixes to clauses\n-   * @param equiconditions   Map of equiconditions\n-   * @param correlationCache Cache of column correlation analyses. This will be potentially modified by adding\n-   *                         any new column correlation analyses to the cache.\n-   *\n-   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n-   */\n   private static JoinFilterAnalysis rewriteSelectorFilter(\n-      Set<String> baseColumnNames,\n       SelectorFilter selectorFilter,\n-      Map<String, JoinableClause> prefixes,\n-      Map<String, Set<Expr>> equiconditions,\n-      Map<String, Optional<List<JoinFilterColumnCorrelationAnalysis>>> correlationCache\n+      JoinFilterPreAnalysis joinFilterPreAnalysis\n   )\n   {\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    List<VirtualColumn> pushdownVirtualColumns = new ArrayList<>();\n+\n     String filteringColumn = selectorFilter.getDimension();\n-    for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n-      if (prefixAndClause.getValue().includesColumn(filteringColumn)) {\n-        Optional<List<JoinFilterColumnCorrelationAnalysis>> correlations = correlationCache.computeIfAbsent(\n-            prefixAndClause.getKey(),\n-            p -> findCorrelatedBaseTableColumns(\n-                baseColumnNames,\n-                p,\n-                prefixes.get(p),\n-                equiconditions\n-            )\n-        );\n+    String filteringValue = selectorFilter.getValue();\n \n-        if (!correlations.isPresent()) {\n-          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n-        }\n+    if (areSomeColumnsFromPostJoinVirtualColumns(\n+        joinFilterPreAnalysis.getPostJoinVirtualColumns(),\n+        selectorFilter.getRequiredColumns()\n+    )) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+    }\n \n-        List<Filter> newFilters = new ArrayList<>();\n-        List<VirtualColumn> pushdownVirtualColumns = new ArrayList<>();\n+    if (!areSomeColumnsFromJoin(joinFilterPreAnalysis.getJoinableClauses(), selectorFilter.getRequiredColumns())) {\n+      return new JoinFilterAnalysis(\n+          true,\n+          selectorFilter,\n+          selectorFilter,\n+          pushdownVirtualColumns\n+      );\n+    }\n \n-        for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlations.get()) {\n-          if (correlationAnalysis.supportsPushDown()) {\n-            Set<String> correlatedValues = getCorrelatedValuesForPushDown(\n-                selectorFilter.getDimension(),\n-                selectorFilter.getValue(),\n-                correlationAnalysis.getJoinColumn(),\n-                prefixAndClause.getValue()\n-            );\n+    Optional<List<JoinFilterColumnCorrelationAnalysis>> correlationAnalyses = joinFilterPreAnalysis.getCorrelationsByFilteringColumn()\n+                                                                                                   .get(filteringColumn);\n \n-            if (correlatedValues.isEmpty()) {\n-              return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n-            }\n+    if (!correlationAnalyses.isPresent()) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+    }\n \n-            for (String correlatedBaseColumn : correlationAnalysis.getBaseColumns()) {\n-              Filter rewrittenFilter = new InDimFilter(\n-                  correlatedBaseColumn,\n-                  correlatedValues,\n-                  null,\n-                  null\n-              ).toFilter();\n-              newFilters.add(rewrittenFilter);\n-            }\n \n-            for (Expr correlatedBaseExpr : correlationAnalysis.getBaseExpressions()) {\n-              // We need to create a virtual column for the expressions when pushing down.\n-              // Note that this block is never entered right now, since correlationAnalysis.supportsPushDown()\n-              // will return false if there any correlated expressions on the base table.\n-              // Pushdown of such filters is disabled until the expressions system supports converting an expression\n-              // into a String representation that can be reparsed into the same expression.\n-              // https://github.com/apache/druid/issues/9326 tracks this expressions issue.\n-              String vcName = getCorrelatedBaseExprVirtualColumnName(pushdownVirtualColumns.size());\n-\n-              VirtualColumn correlatedBaseExprVirtualColumn = new ExpressionVirtualColumn(\n-                  vcName,\n-                  correlatedBaseExpr,\n-                  ValueType.STRING\n-              );\n-              pushdownVirtualColumns.add(correlatedBaseExprVirtualColumn);\n-\n-              Filter rewrittenFilter = new InDimFilter(\n-                  vcName,\n-                  correlatedValues,\n-                  null,\n-                  null\n-              ).toFilter();\n-              newFilters.add(rewrittenFilter);\n-            }\n-          }\n-        }\n+    for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlationAnalyses.get()) {\n+      if (correlationAnalysis.supportsPushDown()) {\n+        Optional<Set<String>> correlatedValues = correlationAnalysis.getCorrelatedValuesMap().get(\n+            Pair.of(filteringColumn, filteringValue)\n+        );\n \n-        if (newFilters.isEmpty()) {\n+        if (!correlatedValues.isPresent()) {\n           return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n         }\n \n-        return new JoinFilterAnalysis(\n-            true,\n-            selectorFilter,\n-            Filters.and(newFilters),\n-            pushdownVirtualColumns\n-        );\n+        for (String correlatedBaseColumn : correlationAnalysis.getBaseColumns()) {\n+          Filter rewrittenFilter = new InDimFilter(\n+              correlatedBaseColumn,\n+              correlatedValues.get(),\n+              null,\n+              null\n+          ).toFilter();\n+          newFilters.add(rewrittenFilter);\n+        }\n+\n+        for (Expr correlatedBaseExpr : correlationAnalysis.getBaseExpressions()) {\n+          // We need to create a virtual column for the expressions when pushing down.\n+          // Note that this block is never entered right now, since correlationAnalysis.supportsPushDown()\n+          // will return false if there any correlated expressions on the base table.\n+          // Pushdown of such filters is disabled until the expressions system supports converting an expression\n+          // into a String representation that can be reparsed into the same expression.\n+          // https://github.com/apache/druid/issues/9326 tracks this expressions issue.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI4Njc4NQ=="}, "originalCommit": {"oid": "06847170cfcc09d2a82f650a32de75975fa6715c"}, "originalPosition": 681}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM4NjE5Mw==", "bodyText": "Actually, I changed my mind, I re-enabled filter rewrites when there are LHS expressions in the join condition, and removed the @Ignore annotations on the tests for that", "url": "https://github.com/apache/druid/pull/9516#discussion_r393386193", "createdAt": "2020-03-17T00:44:54Z", "author": {"login": "jon-wei"}, "path": "processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java", "diffHunk": "@@ -311,124 +431,99 @@ private static JoinFilterAnalysis rewriteOrFilter(\n     );\n   }\n \n-  /**\n-   * Rewrites a selector filter on a join table into an IN filter on the base table.\n-   *\n-   * @param baseColumnNames  Set of names of columns that belong to the base table, including pre-join virtual\n-   *                         columns\n-   * @param selectorFilter   SelectorFilter to be rewritten\n-   * @param prefixes         Map of join table prefixes to clauses\n-   * @param equiconditions   Map of equiconditions\n-   * @param correlationCache Cache of column correlation analyses. This will be potentially modified by adding\n-   *                         any new column correlation analyses to the cache.\n-   *\n-   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n-   */\n   private static JoinFilterAnalysis rewriteSelectorFilter(\n-      Set<String> baseColumnNames,\n       SelectorFilter selectorFilter,\n-      Map<String, JoinableClause> prefixes,\n-      Map<String, Set<Expr>> equiconditions,\n-      Map<String, Optional<List<JoinFilterColumnCorrelationAnalysis>>> correlationCache\n+      JoinFilterPreAnalysis joinFilterPreAnalysis\n   )\n   {\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    List<VirtualColumn> pushdownVirtualColumns = new ArrayList<>();\n+\n     String filteringColumn = selectorFilter.getDimension();\n-    for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n-      if (prefixAndClause.getValue().includesColumn(filteringColumn)) {\n-        Optional<List<JoinFilterColumnCorrelationAnalysis>> correlations = correlationCache.computeIfAbsent(\n-            prefixAndClause.getKey(),\n-            p -> findCorrelatedBaseTableColumns(\n-                baseColumnNames,\n-                p,\n-                prefixes.get(p),\n-                equiconditions\n-            )\n-        );\n+    String filteringValue = selectorFilter.getValue();\n \n-        if (!correlations.isPresent()) {\n-          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n-        }\n+    if (areSomeColumnsFromPostJoinVirtualColumns(\n+        joinFilterPreAnalysis.getPostJoinVirtualColumns(),\n+        selectorFilter.getRequiredColumns()\n+    )) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+    }\n \n-        List<Filter> newFilters = new ArrayList<>();\n-        List<VirtualColumn> pushdownVirtualColumns = new ArrayList<>();\n+    if (!areSomeColumnsFromJoin(joinFilterPreAnalysis.getJoinableClauses(), selectorFilter.getRequiredColumns())) {\n+      return new JoinFilterAnalysis(\n+          true,\n+          selectorFilter,\n+          selectorFilter,\n+          pushdownVirtualColumns\n+      );\n+    }\n \n-        for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlations.get()) {\n-          if (correlationAnalysis.supportsPushDown()) {\n-            Set<String> correlatedValues = getCorrelatedValuesForPushDown(\n-                selectorFilter.getDimension(),\n-                selectorFilter.getValue(),\n-                correlationAnalysis.getJoinColumn(),\n-                prefixAndClause.getValue()\n-            );\n+    Optional<List<JoinFilterColumnCorrelationAnalysis>> correlationAnalyses = joinFilterPreAnalysis.getCorrelationsByFilteringColumn()\n+                                                                                                   .get(filteringColumn);\n \n-            if (correlatedValues.isEmpty()) {\n-              return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n-            }\n+    if (!correlationAnalyses.isPresent()) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+    }\n \n-            for (String correlatedBaseColumn : correlationAnalysis.getBaseColumns()) {\n-              Filter rewrittenFilter = new InDimFilter(\n-                  correlatedBaseColumn,\n-                  correlatedValues,\n-                  null,\n-                  null\n-              ).toFilter();\n-              newFilters.add(rewrittenFilter);\n-            }\n \n-            for (Expr correlatedBaseExpr : correlationAnalysis.getBaseExpressions()) {\n-              // We need to create a virtual column for the expressions when pushing down.\n-              // Note that this block is never entered right now, since correlationAnalysis.supportsPushDown()\n-              // will return false if there any correlated expressions on the base table.\n-              // Pushdown of such filters is disabled until the expressions system supports converting an expression\n-              // into a String representation that can be reparsed into the same expression.\n-              // https://github.com/apache/druid/issues/9326 tracks this expressions issue.\n-              String vcName = getCorrelatedBaseExprVirtualColumnName(pushdownVirtualColumns.size());\n-\n-              VirtualColumn correlatedBaseExprVirtualColumn = new ExpressionVirtualColumn(\n-                  vcName,\n-                  correlatedBaseExpr,\n-                  ValueType.STRING\n-              );\n-              pushdownVirtualColumns.add(correlatedBaseExprVirtualColumn);\n-\n-              Filter rewrittenFilter = new InDimFilter(\n-                  vcName,\n-                  correlatedValues,\n-                  null,\n-                  null\n-              ).toFilter();\n-              newFilters.add(rewrittenFilter);\n-            }\n-          }\n-        }\n+    for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlationAnalyses.get()) {\n+      if (correlationAnalysis.supportsPushDown()) {\n+        Optional<Set<String>> correlatedValues = correlationAnalysis.getCorrelatedValuesMap().get(\n+            Pair.of(filteringColumn, filteringValue)\n+        );\n \n-        if (newFilters.isEmpty()) {\n+        if (!correlatedValues.isPresent()) {\n           return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n         }\n \n-        return new JoinFilterAnalysis(\n-            true,\n-            selectorFilter,\n-            Filters.and(newFilters),\n-            pushdownVirtualColumns\n-        );\n+        for (String correlatedBaseColumn : correlationAnalysis.getBaseColumns()) {\n+          Filter rewrittenFilter = new InDimFilter(\n+              correlatedBaseColumn,\n+              correlatedValues.get(),\n+              null,\n+              null\n+          ).toFilter();\n+          newFilters.add(rewrittenFilter);\n+        }\n+\n+        for (Expr correlatedBaseExpr : correlationAnalysis.getBaseExpressions()) {\n+          // We need to create a virtual column for the expressions when pushing down.\n+          // Note that this block is never entered right now, since correlationAnalysis.supportsPushDown()\n+          // will return false if there any correlated expressions on the base table.\n+          // Pushdown of such filters is disabled until the expressions system supports converting an expression\n+          // into a String representation that can be reparsed into the same expression.\n+          // https://github.com/apache/druid/issues/9326 tracks this expressions issue.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI4Njc4NQ=="}, "originalCommit": {"oid": "06847170cfcc09d2a82f650a32de75975fa6715c"}, "originalPosition": 681}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzNzgwOTQ5OnYy", "diffSide": "RIGHT", "path": "processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQyMDoxODo1M1rOF3EVzQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xN1QwMDowNzo0N1rOF3J10w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI4NzExNw==", "bodyText": "same question about removal of javadocs", "url": "https://github.com/apache/druid/pull/9516#discussion_r393287117", "createdAt": "2020-03-16T20:18:53Z", "author": {"login": "clintropolis"}, "path": "processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java", "diffHunk": "@@ -311,124 +431,99 @@ private static JoinFilterAnalysis rewriteOrFilter(\n     );\n   }\n \n-  /**\n-   * Rewrites a selector filter on a join table into an IN filter on the base table.\n-   *\n-   * @param baseColumnNames  Set of names of columns that belong to the base table, including pre-join virtual\n-   *                         columns\n-   * @param selectorFilter   SelectorFilter to be rewritten\n-   * @param prefixes         Map of join table prefixes to clauses\n-   * @param equiconditions   Map of equiconditions\n-   * @param correlationCache Cache of column correlation analyses. This will be potentially modified by adding\n-   *                         any new column correlation analyses to the cache.\n-   *\n-   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n-   */\n   private static JoinFilterAnalysis rewriteSelectorFilter(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "06847170cfcc09d2a82f650a32de75975fa6715c"}, "originalPosition": 546}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM3NzIzNQ==", "bodyText": "Restored missing javadocs", "url": "https://github.com/apache/druid/pull/9516#discussion_r393377235", "createdAt": "2020-03-17T00:07:47Z", "author": {"login": "jon-wei"}, "path": "processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java", "diffHunk": "@@ -311,124 +431,99 @@ private static JoinFilterAnalysis rewriteOrFilter(\n     );\n   }\n \n-  /**\n-   * Rewrites a selector filter on a join table into an IN filter on the base table.\n-   *\n-   * @param baseColumnNames  Set of names of columns that belong to the base table, including pre-join virtual\n-   *                         columns\n-   * @param selectorFilter   SelectorFilter to be rewritten\n-   * @param prefixes         Map of join table prefixes to clauses\n-   * @param equiconditions   Map of equiconditions\n-   * @param correlationCache Cache of column correlation analyses. This will be potentially modified by adding\n-   *                         any new column correlation analyses to the cache.\n-   *\n-   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n-   */\n   private static JoinFilterAnalysis rewriteSelectorFilter(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzI4NzExNw=="}, "originalCommit": {"oid": "06847170cfcc09d2a82f650a32de75975fa6715c"}, "originalPosition": 546}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzODUzNTY0OnYy", "diffSide": "RIGHT", "path": "processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xN1QwMTo1MjoyMVrOF3LXaQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xN1QwMTo1MjoyMVrOF3LXaQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzQwMjIxNw==", "bodyText": "With the deletion below, CI (spotbugs and intellij inspections) is flagging this as unused now", "url": "https://github.com/apache/druid/pull/9516#discussion_r393402217", "createdAt": "2020-03-17T01:52:21Z", "author": {"login": "ccaominh"}, "path": "processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java", "diffHunk": "@@ -237,22 +218,16 @@ public Metadata getMetadata()\n       @Nullable final QueryMetrics<?> queryMetrics\n   )\n   {\n-\n     final List<VirtualColumn> preJoinVirtualColumns = new ArrayList<>();\n     final List<VirtualColumn> postJoinVirtualColumns = new ArrayList<>();\n+\n     final Set<String> baseColumns = determineBaseColumnsWithPreAndPostJoinVirtualColumns(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e93d282389e30a608ea10a6ccd071e4876219ca9"}, "originalPosition": 74}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQzODUzNzgwOnYy", "diffSide": "RIGHT", "path": "processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xN1QwMTo1Mzo1NFrOF3LYyA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xN1QwMTo1Mzo1NFrOF3LYyA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzQwMjU2OA==", "bodyText": "CI (spotbugs and intellij inspections) is flagging this as unused", "url": "https://github.com/apache/druid/pull/9516#discussion_r393402568", "createdAt": "2020-03-17T01:53:54Z", "author": {"login": "ccaominh"}, "path": "processing/src/main/java/org/apache/druid/segment/join/filter/JoinFilterAnalyzer.java", "diffHunk": "@@ -128,31 +183,172 @@ public static JoinFilterSplit splitFilter(\n       }\n     }\n \n-    // List of candidates for pushdown\n-    // CNF normalization will generate either\n-    // - an AND filter with multiple subfilters\n-    // - or a single non-AND subfilter which cannot be split further\n-    List<Filter> normalizedOrClauses;\n-    if (normalizedFilter instanceof AndFilter) {\n-      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n-    } else {\n-      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e93d282389e30a608ea10a6ccd071e4876219ca9"}, "originalPosition": 206}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2633, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}