{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzY5Nzg1MDMy", "number": 9301, "title": "Join filter pushdown initial implementation", "bodyText": "This PR adds an initial implementation for pushing down filters to the base table in a join query.\nThe bulk of logic added is in the new JoinFilterAnalyzer utils class. This class has methods that split a Filter into a base table portion that can be pushed down and a post-join portion. The analyzer is capable of rewriting filters that apply to columns on the join tables into filters on the base table.\nCurrent limitations:\n\nOnly selector filters can be rewritten\nIS NULL filters are not pushed down\nThere is currently no limit on the IN filter size for rewrites, future work can improve the heuristics for deciding when to rewrite filters\nThe filter push down could benefit from more efficient lookups for values of non-key columns in Joinables\n\nThis PR has:\n\n been self-reviewed.\n added Javadocs for most classes and all non-trivial methods. Linked related entities via Javadoc links.\n added comments explaining the \"why\" and the intent of the code wherever would not be obvious for an unfamiliar reader.\n added unit tests or modified existing tests to cover new code paths.\n added integration tests.\n been tested in a test Druid cluster.\n\nKey changed/added classes in this PR\n\nJoinFilterAnalyzer\nHashJoinSegmentStorageAdapter", "createdAt": "2020-01-31T21:48:24Z", "url": "https://github.com/apache/druid/pull/9301", "merged": true, "mergeCommit": {"oid": "ad8afc565c631c826bb1db0ebac611398a7ec9f3"}, "closed": true, "closedAt": "2020-02-08T00:23:38Z", "author": {"login": "jon-wei"}, "timelineItems": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABb_4jYKgH2gAyMzY5Nzg1MDMyOjNjMWM2NzQ5YTNmOTRmMGY4YWJmNjE3Y2ZhZmFiZDEwOTczZGY5ZWI=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcCIuCBgFqTM1NTUwODIzNg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "3c1c6749a3f94f0f8abf617cfafabd10973df9eb", "author": {"user": {"login": "jon-wei", "name": "Jonathan Wei"}}, "url": "https://github.com/apache/druid/commit/3c1c6749a3f94f0f8abf617cfafabd10973df9eb", "committedDate": "2020-02-01T00:25:29Z", "message": "Join filter pushdown initial implementation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "443d7274a49c71429d87afce3667b96d35dba517", "author": {"user": {"login": "jon-wei", "name": "Jonathan Wei"}}, "url": "https://github.com/apache/druid/commit/443d7274a49c71429d87afce3667b96d35dba517", "committedDate": "2020-02-01T00:25:29Z", "message": "Fix test and spotbugs check"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "443d7274a49c71429d87afce3667b96d35dba517", "author": {"user": {"login": "jon-wei", "name": "Jonathan Wei"}}, "url": "https://github.com/apache/druid/commit/443d7274a49c71429d87afce3667b96d35dba517", "committedDate": "2020-02-01T00:25:29Z", "message": "Fix test and spotbugs check"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUyNDg0ODM4", "url": "https://github.com/apache/druid/pull/9301#pullrequestreview-352484838", "createdAt": "2020-02-03T18:58:03Z", "commit": {"oid": "443d7274a49c71429d87afce3667b96d35dba517"}, "state": "COMMENTED", "comments": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QxODo1ODowM1rOFk8PDw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QyMDoyMDoxNFrOFk-rOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI3OTk1MQ==", "bodyText": "Do you want to add a unit test to AndFilterTest that uses EqualsVerifier (similar to https://github.com/apache/druid/blob/master/processing/src/test/java/org/apache/druid/query/QueryDataSourceTest.java#L142)", "url": "https://github.com/apache/druid/pull/9301#discussion_r374279951", "createdAt": "2020-02-03T18:58:03Z", "author": {"login": "ccaominh"}, "path": "processing/src/main/java/org/apache/druid/segment/filter/AndFilter.java", "diffHunk": "@@ -234,4 +235,23 @@ public ReadableVectorMatch match(final ReadableVectorMatch mask)\n       }\n     };\n   }\n+\n+  @Override\n+  public boolean equals(Object o)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "443d7274a49c71429d87afce3667b96d35dba517"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI4MDUwNA==", "bodyText": "Similar comment about testing with EqualsVerifier", "url": "https://github.com/apache/druid/pull/9301#discussion_r374280504", "createdAt": "2020-02-03T18:59:07Z", "author": {"login": "ccaominh"}, "path": "processing/src/main/java/org/apache/druid/segment/filter/BoundFilter.java", "diffHunk": "@@ -306,4 +307,26 @@ private boolean doesMatch(String input)\n     }\n     return (lowerComparing >= 0) && (upperComparing >= 0);\n   }\n+\n+  @Override\n+  public boolean equals(Object o)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "443d7274a49c71429d87afce3667b96d35dba517"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI4MDY3Nw==", "bodyText": "Similar comment about testing with EqualsVerifier", "url": "https://github.com/apache/druid/pull/9301#discussion_r374280677", "createdAt": "2020-02-03T18:59:30Z", "author": {"login": "ccaominh"}, "path": "processing/src/main/java/org/apache/druid/segment/filter/InFilter.java", "diffHunk": "@@ -235,4 +236,26 @@ public DruidDoublePredicate makeDoublePredicate()\n       }\n     };\n   }\n+\n+  @Override\n+  public boolean equals(Object o)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "443d7274a49c71429d87afce3667b96d35dba517"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI4MDg1OQ==", "bodyText": "Similar comment about testing with EqualsVerifier", "url": "https://github.com/apache/druid/pull/9301#discussion_r374280859", "createdAt": "2020-02-03T18:59:53Z", "author": {"login": "ccaominh"}, "path": "processing/src/main/java/org/apache/druid/segment/filter/OrFilter.java", "diffHunk": "@@ -218,4 +219,23 @@ public ReadableVectorMatch match(final ReadableVectorMatch mask)\n       }\n     };\n   }\n+\n+  @Override\n+  public boolean equals(Object o)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "443d7274a49c71429d87afce3667b96d35dba517"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI4MTA0OA==", "bodyText": "Similar comment about testing with EqualsVerifier", "url": "https://github.com/apache/druid/pull/9301#discussion_r374281048", "createdAt": "2020-02-03T19:00:19Z", "author": {"login": "ccaominh"}, "path": "processing/src/main/java/org/apache/druid/segment/filter/SelectorFilter.java", "diffHunk": "@@ -127,4 +128,35 @@ public String toString()\n   {\n     return StringUtils.format(\"%s = %s\", dimension, value);\n   }\n+\n+  public String getDimension()\n+  {\n+    return dimension;\n+  }\n+\n+  public String getValue()\n+  {\n+    return value;\n+  }\n+\n+  @Override\n+  public boolean equals(Object o)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "443d7274a49c71429d87afce3667b96d35dba517"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMwNTgwNg==", "bodyText": "Maybe use Collections.singletonList() instead", "url": "https://github.com/apache/druid/pull/9301#discussion_r374305806", "createdAt": "2020-02-03T19:50:56Z", "author": {"login": "ccaominh"}, "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,739 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+\n+  public static JoinFilterSplit splitFilter(\n+      Filter originalFilter,\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      List<JoinableClause> clauses\n+  )\n+  {\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : clauses) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = new ArrayList<>();\n+      normalizedOrClauses.add(normalizedFilter);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "443d7274a49c71429d87afce3667b96d35dba517"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMwODM2MA==", "bodyText": "Similar comment about testing with EqualsVerifier", "url": "https://github.com/apache/druid/pull/9301#discussion_r374308360", "createdAt": "2020-02-03T19:56:02Z", "author": {"login": "ccaominh"}, "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,739 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+\n+  public static JoinFilterSplit splitFilter(\n+      Filter originalFilter,\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      List<JoinableClause> clauses\n+  )\n+  {\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : clauses) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = new ArrayList<>();\n+      normalizedOrClauses.add(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          baseAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "443d7274a49c71429d87afce3667b96d35dba517"}, "originalPosition": 171}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMxMDEzNQ==", "bodyText": "Can AllNullColumnSelectorFactory be made a private class variable so it does not need to be allocated each time?", "url": "https://github.com/apache/druid/pull/9301#discussion_r374310135", "createdAt": "2020-02-03T19:59:22Z", "author": {"login": "ccaominh"}, "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,739 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+\n+  public static JoinFilterSplit splitFilter(\n+      Filter originalFilter,\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      List<JoinableClause> clauses\n+  )\n+  {\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : clauses) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = new ArrayList<>();\n+      normalizedOrClauses.add(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          baseAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  @Nullable\n+  private static JoinFilterAnalysis rewriteOrFilter(\n+      HashJoinSegmentStorageAdapter adapter,\n+      OrFilter orFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    boolean retainRhs = false;\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    for (Filter filter : orFilter.getFilters()) {\n+      boolean allBaseColumns = true;\n+      for (String requiredColumn : filter.getRequiredColumns()) {\n+        if (!adapter.isBaseColumn(requiredColumn)) {\n+          allBaseColumns = false;\n+        }\n+      }\n+\n+      if (!allBaseColumns) {\n+        retainRhs = true;\n+        if (filter instanceof SelectorFilter) {\n+          JoinFilterAnalysis rewritten = rewriteSelectorFilter(\n+              adapter,\n+              filter,\n+              prefixes,\n+              equiconditions,\n+              correlationCache\n+          );\n+          if (!rewritten.isCanPushDown()) {\n+            return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+          } else {\n+            newFilters.add(rewritten.getPushdownFilter());\n+          }\n+        } else {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+        }\n+      } else {\n+        newFilters.add(filter);\n+      }\n+    }\n+\n+    return new JoinFilterAnalysis(\n+        true,\n+        retainRhs,\n+        orFilter,\n+        new OrFilter(newFilters),\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Rewrites a selector filter on a join table into an IN filter on the base table.\n+   *\n+   * @param baseAdapter      The adapter for the join\n+   * @param filter           Filter to be rewritten\n+   * @param prefixes         Map of join table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteSelectorFilter(\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      Filter filter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    assert (filter instanceof SelectorFilter);\n+    SelectorFilter selectorFilter = (SelectorFilter) filter;\n+\n+    String filteringColumn = selectorFilter.getDimension();\n+    for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n+      if (filteringColumn.startsWith(prefixAndClause.getKey())) {\n+        List<JoinFilterColumnCorrelationAnalysis> correlations = correlationCache.computeIfAbsent(\n+            prefixAndClause.getKey(),\n+            p -> findCorrelatedBaseTableColumns(\n+                baseAdapter,\n+                p,\n+                prefixes.get(p),\n+                equiconditions\n+            )\n+        );\n+\n+        if (correlations == null) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filter);\n+        }\n+\n+        List<Filter> newFilters = new ArrayList<>();\n+        List<VirtualColumn> pushdownVirtualColumns = new ArrayList<>();\n+\n+        for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlations) {\n+          if (correlationAnalysis.supportsPushDown()) {\n+            List<String> correlatedValues = getCorrelatedValuesForPushDown(\n+                selectorFilter.getDimension(),\n+                selectorFilter.getValue(),\n+                correlationAnalysis.getJoinColumn(),\n+                prefixAndClause.getValue()\n+            );\n+\n+            if (correlatedValues == null) {\n+              return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+            }\n+\n+            for (String correlatedBaseColumn : correlationAnalysis.getBaseColumns()) {\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  correlatedBaseColumn,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+\n+            for (Expr correlatedBaseExpr : correlationAnalysis.getBaseExpressions()) {\n+              // need to create a virtual column for the expressions when pushing down\n+              String vcName = getCorrelatedBaseExprVirtualColumnName(pushdownVirtualColumns.size());\n+\n+              VirtualColumn correlatedBaseExprVirtualColumn = new ExpressionVirtualColumn(\n+                  vcName,\n+                  correlatedBaseExpr,\n+                  ValueType.STRING\n+              );\n+              pushdownVirtualColumns.add(correlatedBaseExprVirtualColumn);\n+\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  vcName,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+          }\n+        }\n+\n+        if (newFilters.isEmpty()) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filter);\n+        }\n+\n+        return new JoinFilterAnalysis(\n+            true,\n+            true,\n+            filter,\n+            newFilters.size() == 1 ? newFilters.get(0) : new AndFilter(newFilters),\n+            pushdownVirtualColumns\n+        );\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filter,\n+        filter,\n+        null\n+    );\n+  }\n+\n+  private static String getCorrelatedBaseExprVirtualColumnName(int counter)\n+  {\n+    // May want to have this check other column names to absolutely prevent name conflicts\n+    return PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE + counter;\n+  }\n+\n+  /**\n+   * Helper method for rewriting filters on join table columns into filters on base table columns.\n+   *\n+   * @param filterColumn           A join table column that we're filtering on\n+   * @param filterValue            The value to filter on\n+   * @param correlatedJoinColumn   A join table column that appears as the RHS of an equicondition, which we can correlate\n+   *                               with a column on the base table\n+   * @param clauseForFilteredTable The joinable clause that corresponds to the join table being filtered on\n+   *\n+   * @return A list of values of the correlatedJoinColumn that appear in rows where filterColumn = filterValue\n+   * Returns null if we cannot determine the correlated values.\n+   */\n+  @Nullable\n+  private static List<String> getCorrelatedValuesForPushDown(\n+      String filterColumn,\n+      String filterValue,\n+      String correlatedJoinColumn,\n+      JoinableClause clauseForFilteredTable\n+  )\n+  {\n+    String filterColumnNoPrefix = filterColumn.substring(clauseForFilteredTable.getPrefix().length());\n+    String correlatedColumnNoPrefix = correlatedJoinColumn.substring(clauseForFilteredTable.getPrefix().length());\n+\n+    // would be good to allow non-key column indices on the Joinables for better perf\n+    if (clauseForFilteredTable.getJoinable() instanceof LookupJoinable) {\n+      LookupJoinable lookupJoinable = (LookupJoinable) clauseForFilteredTable.getJoinable();\n+      List<String> correlatedValues;\n+      if (LookupColumnSelectorFactory.KEY_COLUMN.equals(filterColumnNoPrefix)) {\n+        if (LookupColumnSelectorFactory.KEY_COLUMN.equals(correlatedColumnNoPrefix)) {\n+          correlatedValues = ImmutableList.of(filterValue);\n+        } else {\n+          correlatedValues = ImmutableList.of(lookupJoinable.getExtractor().apply(filterColumnNoPrefix));\n+        }\n+      } else {\n+        if (LookupColumnSelectorFactory.VALUE_COLUMN.equals(correlatedColumnNoPrefix)) {\n+          correlatedValues = ImmutableList.of(filterValue);\n+        } else {\n+          correlatedValues = lookupJoinable.getExtractor().unapply(filterValue);\n+        }\n+      }\n+      return correlatedValues;\n+    }\n+\n+    if (clauseForFilteredTable.getJoinable() instanceof IndexedTableJoinable) {\n+      IndexedTableJoinable indexedTableJoinable = (IndexedTableJoinable) clauseForFilteredTable.getJoinable();\n+      IndexedTable indexedTable = indexedTableJoinable.getTable();\n+\n+      int filterColumnPosition = indexedTable.allColumns().indexOf(filterColumnNoPrefix);\n+      int correlatedColumnPosition = indexedTable.allColumns().indexOf(correlatedColumnNoPrefix);\n+\n+      if (filterColumnPosition < 0 || correlatedColumnPosition < 0) {\n+        return null;\n+      }\n+\n+      if (indexedTable.keyColumns().contains(filterColumnNoPrefix)) {\n+        IndexedTable.Index index = indexedTable.columnIndex(filterColumnPosition);\n+        IndexedTable.Reader reader = indexedTable.columnReader(correlatedColumnPosition);\n+        IntList rowIndex = index.find(filterValue);\n+        List<String> correlatedValues = new ArrayList<>();\n+        for (int i = 0; i < rowIndex.size(); i++) {\n+          int rowNum = rowIndex.getInt(i);\n+          correlatedValues.add(reader.read(rowNum).toString());\n+        }\n+        return correlatedValues;\n+      } else {\n+        IndexedTable.Reader dimNameReader = indexedTable.columnReader(filterColumnPosition);\n+        IndexedTable.Reader correlatedColumnReader = indexedTable.columnReader(correlatedColumnPosition);\n+        Set<String> correlatedValueSet = new HashSet<>();\n+        for (int i = 0; i < indexedTable.numRows(); i++) {\n+          if (filterValue.equals(dimNameReader.read(i).toString())) {\n+            correlatedValueSet.add(correlatedColumnReader.read(i).toString());\n+          }\n+        }\n+\n+        return new ArrayList<>(correlatedValueSet);\n+      }\n+    }\n+\n+    return null;\n+  }\n+\n+  /**\n+   * For all RHS columns that appear in the join's equiconditions, correlate them with base table columns if possible.\n+   *\n+   * @param adapter              The adapter for the join. Used to determine if a column is a base table column.\n+   * @param tablePrefix          Prefix for a join table\n+   * @param clauseForTablePrefix Joinable clause for the prefix\n+   * @param equiconditions       Map of equiconditions, keyed by the right hand columns\n+   *\n+   * @return A list of correlatation analyses for the equicondition RHS columns that reside in the table associated with\n+   * the tablePrefix\n+   */\n+  @Nullable\n+  private static List<JoinFilterColumnCorrelationAnalysis> findCorrelatedBaseTableColumns(\n+      HashJoinSegmentStorageAdapter adapter,\n+      String tablePrefix,\n+      JoinableClause clauseForTablePrefix,\n+      Map<String, Expr> equiconditions\n+  )\n+  {\n+    JoinConditionAnalysis jca = clauseForTablePrefix.getCondition();\n+\n+    List<String> rhsColumns = new ArrayList<>();\n+    for (Equality eq : jca.getEquiConditions()) {\n+      rhsColumns.add(tablePrefix + eq.getRightColumn());\n+    }\n+\n+    List<JoinFilterColumnCorrelationAnalysis> correlations = new ArrayList<>();\n+\n+    for (String rhsColumn : rhsColumns) {\n+      List<String> correlatedBaseColumns = new ArrayList<>();\n+      List<Expr> correlatedBaseExpressions = new ArrayList<>();\n+      boolean terminate = false;\n+\n+      String findMappingFor = rhsColumn;\n+      while (!terminate) {\n+        Expr lhs = equiconditions.get(findMappingFor);\n+        if (lhs == null) {\n+          break;\n+        }\n+        String identifier = lhs.getBindingIfIdentifier();\n+        if (identifier == null) {\n+          // We push down if the function only requires base table columns\n+          Expr.BindingDetails bindingDetails = lhs.analyzeInputs();\n+          Set<String> requiredBindings = bindingDetails.getRequiredBindings();\n+          for (String requiredBinding : requiredBindings) {\n+            if (!adapter.isBaseColumn(requiredBinding)) {\n+              return null;\n+            }\n+          }\n+\n+          terminate = true;\n+          correlatedBaseExpressions.add(lhs);\n+        } else {\n+          // simple identifier, see if we can correlate it with a column on the base table\n+          findMappingFor = identifier;\n+          if (adapter.isBaseColumn(identifier)) {\n+            terminate = true;\n+            correlatedBaseColumns.add(findMappingFor);\n+          }\n+        }\n+      }\n+\n+      if (correlatedBaseColumns.isEmpty() && correlatedBaseExpressions.isEmpty()) {\n+        return null;\n+      }\n+\n+      correlations.add(\n+          new JoinFilterColumnCorrelationAnalysis(\n+              rhsColumn,\n+              correlatedBaseColumns,\n+              correlatedBaseExpressions\n+          )\n+      );\n+    }\n+\n+    return correlations;\n+  }\n+\n+  private static boolean filterMatchesNull(Filter filter)\n+  {\n+    ValueMatcher valueMatcher = filter.makeMatcher(new AllNullColumnSelectorFactory());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "443d7274a49c71429d87afce3667b96d35dba517"}, "originalPosition": 592}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMxMjExMg==", "bodyText": "Would you still need this if JoinFilterAnalyzerTest was created and had unit tests for JoinFilterAnalyzer?", "url": "https://github.com/apache/druid/pull/9301#discussion_r374312112", "createdAt": "2020-02-03T20:03:25Z", "author": {"login": "ccaominh"}, "path": "processing/src/main/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapter.java", "diffHunk": "@@ -52,6 +54,11 @@\n   private final StorageAdapter baseAdapter;\n   private final List<JoinableClause> clauses;\n \n+  // A reference to the last JoinFilterSplit created during a makeCursors call,\n+  // saved and exposed so that tests can verify the filter splitting behavior.\n+  @VisibleForTesting\n+  private JoinFilterAnalyzer.JoinFilterSplit previousJoinFilterSplitForTesting;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "443d7274a49c71429d87afce3667b96d35dba517"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMxMjc1OA==", "bodyText": "Can remove since this method never returns null", "url": "https://github.com/apache/druid/pull/9301#discussion_r374312758", "createdAt": "2020-02-03T20:04:48Z", "author": {"login": "ccaominh"}, "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,739 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+\n+  public static JoinFilterSplit splitFilter(\n+      Filter originalFilter,\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      List<JoinableClause> clauses\n+  )\n+  {\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : clauses) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = new ArrayList<>();\n+      normalizedOrClauses.add(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          baseAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  @Nullable", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "443d7274a49c71429d87afce3667b96d35dba517"}, "originalPosition": 264}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMxNDM4MQ==", "bodyText": "Can rewriteSelectorFilter's filter parameter be of type SelectorFilter instead?", "url": "https://github.com/apache/druid/pull/9301#discussion_r374314381", "createdAt": "2020-02-03T20:08:22Z", "author": {"login": "ccaominh"}, "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,739 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+\n+  public static JoinFilterSplit splitFilter(\n+      Filter originalFilter,\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      List<JoinableClause> clauses\n+  )\n+  {\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : clauses) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = new ArrayList<>();\n+      normalizedOrClauses.add(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          baseAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  @Nullable\n+  private static JoinFilterAnalysis rewriteOrFilter(\n+      HashJoinSegmentStorageAdapter adapter,\n+      OrFilter orFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    boolean retainRhs = false;\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    for (Filter filter : orFilter.getFilters()) {\n+      boolean allBaseColumns = true;\n+      for (String requiredColumn : filter.getRequiredColumns()) {\n+        if (!adapter.isBaseColumn(requiredColumn)) {\n+          allBaseColumns = false;\n+        }\n+      }\n+\n+      if (!allBaseColumns) {\n+        retainRhs = true;\n+        if (filter instanceof SelectorFilter) {\n+          JoinFilterAnalysis rewritten = rewriteSelectorFilter(\n+              adapter,\n+              filter,\n+              prefixes,\n+              equiconditions,\n+              correlationCache\n+          );\n+          if (!rewritten.isCanPushDown()) {\n+            return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+          } else {\n+            newFilters.add(rewritten.getPushdownFilter());\n+          }\n+        } else {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+        }\n+      } else {\n+        newFilters.add(filter);\n+      }\n+    }\n+\n+    return new JoinFilterAnalysis(\n+        true,\n+        retainRhs,\n+        orFilter,\n+        new OrFilter(newFilters),\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Rewrites a selector filter on a join table into an IN filter on the base table.\n+   *\n+   * @param baseAdapter      The adapter for the join\n+   * @param filter           Filter to be rewritten\n+   * @param prefixes         Map of join table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteSelectorFilter(\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      Filter filter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    assert (filter instanceof SelectorFilter);\n+    SelectorFilter selectorFilter = (SelectorFilter) filter;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "443d7274a49c71429d87afce3667b96d35dba517"}, "originalPosition": 336}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDMxOTkyOQ==", "bodyText": "The test coverage of the filter push down code is great!\nWhat do you think about making many of these test cases as unit tests in JoinFilterAnalyzerTest instead? That way it's more straightforward to map the test case to the relevant code.", "url": "https://github.com/apache/druid/pull/9301#discussion_r374319929", "createdAt": "2020-02-03T20:20:14Z", "author": {"login": "ccaominh"}, "path": "processing/src/test/java/org/apache/druid/segment/join/HashJoinSegmentStorageAdapterTest.java", "diffHunk": "@@ -1288,103 +1313,1163 @@ public void test_makeCursors_errorOnNonKeyBasedJoin()\n     );\n   }\n \n-  private JoinableClause factToCountryNameUsingIsoCodeLookup(final JoinType joinType)\n+  // Filter push down tests", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "443d7274a49c71429d87afce3667b96d35dba517"}, "originalPosition": 214}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2150436af7691541d0462c39a9caa5e9a46e5c29", "author": {"user": {"login": "jon-wei", "name": "Jonathan Wei"}}, "url": "https://github.com/apache/druid/commit/2150436af7691541d0462c39a9caa5e9a46e5c29", "committedDate": "2020-02-05T00:02:32Z", "message": "Address PR comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b31fbddcd678b5f9faf705a2def1864072188929", "author": {"user": {"login": "jon-wei", "name": "Jonathan Wei"}}, "url": "https://github.com/apache/druid/commit/b31fbddcd678b5f9faf705a2def1864072188929", "committedDate": "2020-02-05T00:12:03Z", "message": "More PR comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUzMzk1MzY3", "url": "https://github.com/apache/druid/pull/9301#pullrequestreview-353395367", "createdAt": "2020-02-05T00:22:10Z", "commit": {"oid": "b31fbddcd678b5f9faf705a2def1864072188929"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwMDoyMjoxMFrOFloF4w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwMDoyMjoxMFrOFloF4w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDk5ODQ5OQ==", "bodyText": "I just realized there's a bug with this part (it needs to create a globally unique virtual column name), will fix in a follow-on PR.", "url": "https://github.com/apache/druid/pull/9301#discussion_r374998499", "createdAt": "2020-02-05T00:22:10Z", "author": {"login": "jon-wei"}, "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          (SelectorFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteOrFilter(\n+      HashJoinSegmentStorageAdapter adapter,\n+      OrFilter orFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    boolean retainRhs = false;\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    for (Filter filter : orFilter.getFilters()) {\n+      boolean allBaseColumns = true;\n+      for (String requiredColumn : filter.getRequiredColumns()) {\n+        if (!adapter.isBaseColumn(requiredColumn)) {\n+          allBaseColumns = false;\n+        }\n+      }\n+\n+      if (!allBaseColumns) {\n+        retainRhs = true;\n+        if (filter instanceof SelectorFilter) {\n+          JoinFilterAnalysis rewritten = rewriteSelectorFilter(\n+              adapter,\n+              (SelectorFilter) filter,\n+              prefixes,\n+              equiconditions,\n+              correlationCache\n+          );\n+          if (!rewritten.isCanPushDown()) {\n+            return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+          } else {\n+            newFilters.add(rewritten.getPushdownFilter());\n+          }\n+        } else {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+        }\n+      } else {\n+        newFilters.add(filter);\n+      }\n+    }\n+\n+    return new JoinFilterAnalysis(\n+        true,\n+        retainRhs,\n+        orFilter,\n+        new OrFilter(newFilters),\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Rewrites a selector filter on a join table into an IN filter on the base table.\n+   *\n+   * @param baseAdapter      The adapter for the join\n+   * @param selectorFilter   SelectorFilter to be rewritten\n+   * @param prefixes         Map of join table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteSelectorFilter(\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      SelectorFilter selectorFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    String filteringColumn = selectorFilter.getDimension();\n+    for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n+      if (filteringColumn.startsWith(prefixAndClause.getKey())) {\n+        List<JoinFilterColumnCorrelationAnalysis> correlations = correlationCache.computeIfAbsent(\n+            prefixAndClause.getKey(),\n+            p -> findCorrelatedBaseTableColumns(\n+                baseAdapter,\n+                p,\n+                prefixes.get(p),\n+                equiconditions\n+            )\n+        );\n+\n+        if (correlations == null) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        List<Filter> newFilters = new ArrayList<>();\n+        List<VirtualColumn> pushdownVirtualColumns = new ArrayList<>();\n+\n+        for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlations) {\n+          if (correlationAnalysis.supportsPushDown()) {\n+            List<String> correlatedValues = getCorrelatedValuesForPushDown(\n+                selectorFilter.getDimension(),\n+                selectorFilter.getValue(),\n+                correlationAnalysis.getJoinColumn(),\n+                prefixAndClause.getValue()\n+            );\n+\n+            if (correlatedValues == null) {\n+              return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+            }\n+\n+            for (String correlatedBaseColumn : correlationAnalysis.getBaseColumns()) {\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  correlatedBaseColumn,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+\n+            for (Expr correlatedBaseExpr : correlationAnalysis.getBaseExpressions()) {\n+              // need to create a virtual column for the expressions when pushing down\n+              String vcName = getCorrelatedBaseExprVirtualColumnName(pushdownVirtualColumns.size());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b31fbddcd678b5f9faf705a2def1864072188929"}, "originalPosition": 387}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUzMzk3MDE0", "url": "https://github.com/apache/druid/pull/9301#pullrequestreview-353397014", "createdAt": "2020-02-05T00:27:17Z", "commit": {"oid": "b31fbddcd678b5f9faf705a2def1864072188929"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUzNDA1Njg3", "url": "https://github.com/apache/druid/pull/9301#pullrequestreview-353405687", "createdAt": "2020-02-05T00:55:19Z", "commit": {"oid": "b31fbddcd678b5f9faf705a2def1864072188929"}, "state": "COMMENTED", "comments": {"totalCount": 23, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwMDo1NToyMFrOFlooKw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQwMjoyOToxOVrOFlqDQQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAwNzI3NQ==", "bodyText": "It would be great to have a javadoc here describing what kind of analysis this class is trying to do, and why. Something like the javadocs at the top of JoinConditionAnalysis and DataSourceAnalysis.", "url": "https://github.com/apache/druid/pull/9301#discussion_r375007275", "createdAt": "2020-02-05T00:55:20Z", "author": {"login": "gianm"}, "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b31fbddcd678b5f9faf705a2def1864072188929"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAwNzg3Nw==", "bodyText": "Skimming a bit, it seems like this would work if it was given a List<JoinableClause> instead of a HashJoinSegmentStorageAdapter. If so, that'd be a good change (it's better for methods like this to take conceptually smaller objects \u2014\u00a0unit testing is easier, and it makes it clearer what the 'real' dependencies are of the computation it is doing).", "url": "https://github.com/apache/druid/pull/9301#discussion_r375007877", "createdAt": "2020-02-05T00:57:27Z", "author": {"login": "gianm"}, "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b31fbddcd678b5f9faf705a2def1864072188929"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAwOTMyMw==", "bodyText": "This code assumes that no two clauses have the same prefix, and (maybe also?) that the prefixes don't shadow each other. I don't think anything currently verifies either of those preconditions. It'd be good to add validation somewhere. Maybe right here, or maybe in HashJoinSegment's constructor. Maybe add a Joinables function that verifies it and call it wherever might care.", "url": "https://github.com/apache/druid/pull/9301#discussion_r375009323", "createdAt": "2020-02-05T01:02:49Z", "author": {"login": "gianm"}, "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b31fbddcd678b5f9faf705a2def1864072188929"}, "originalPosition": 81}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxMDcyOA==", "bodyText": "Maybe clearer to say that this single clause is expected to be either an OR or a leaf filter.", "url": "https://github.com/apache/druid/pull/9301#discussion_r375010728", "createdAt": "2020-02-05T01:07:55Z", "author": {"login": "gianm"}, "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b31fbddcd678b5f9faf705a2def1864072188929"}, "originalPosition": 201}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxMjQ4OA==", "bodyText": "Would be nice to say why (I presume it's something like: conditions that match NULL are tricky to push down when doing OUTER JOINs, and we'd rather not worry about that right now).", "url": "https://github.com/apache/druid/pull/9301#discussion_r375012488", "createdAt": "2020-02-05T01:15:05Z", "author": {"login": "gianm"}, "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b31fbddcd678b5f9faf705a2def1864072188929"}, "originalPosition": 220}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxMzQxNA==", "bodyText": "It looks like it's expected that callers will modify this parameter. It'd be good to note that (and any other case where it's expected that parameters will be modified).", "url": "https://github.com/apache/druid/pull/9301#discussion_r375013414", "createdAt": "2020-02-05T01:18:30Z", "author": {"login": "gianm"}, "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b31fbddcd678b5f9faf705a2def1864072188929"}, "originalPosition": 208}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxNDczMA==", "bodyText": "Instead of doing an instanceof, could you add a method to Joinable that enables this use case? The interface is still really new and we should be evolving it to meet our needs.", "url": "https://github.com/apache/druid/pull/9301#discussion_r375014730", "createdAt": "2020-02-05T01:23:16Z", "author": {"login": "gianm"}, "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          (SelectorFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteOrFilter(\n+      HashJoinSegmentStorageAdapter adapter,\n+      OrFilter orFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    boolean retainRhs = false;\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    for (Filter filter : orFilter.getFilters()) {\n+      boolean allBaseColumns = true;\n+      for (String requiredColumn : filter.getRequiredColumns()) {\n+        if (!adapter.isBaseColumn(requiredColumn)) {\n+          allBaseColumns = false;\n+        }\n+      }\n+\n+      if (!allBaseColumns) {\n+        retainRhs = true;\n+        if (filter instanceof SelectorFilter) {\n+          JoinFilterAnalysis rewritten = rewriteSelectorFilter(\n+              adapter,\n+              (SelectorFilter) filter,\n+              prefixes,\n+              equiconditions,\n+              correlationCache\n+          );\n+          if (!rewritten.isCanPushDown()) {\n+            return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+          } else {\n+            newFilters.add(rewritten.getPushdownFilter());\n+          }\n+        } else {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+        }\n+      } else {\n+        newFilters.add(filter);\n+      }\n+    }\n+\n+    return new JoinFilterAnalysis(\n+        true,\n+        retainRhs,\n+        orFilter,\n+        new OrFilter(newFilters),\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Rewrites a selector filter on a join table into an IN filter on the base table.\n+   *\n+   * @param baseAdapter      The adapter for the join\n+   * @param selectorFilter   SelectorFilter to be rewritten\n+   * @param prefixes         Map of join table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteSelectorFilter(\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      SelectorFilter selectorFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    String filteringColumn = selectorFilter.getDimension();\n+    for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n+      if (filteringColumn.startsWith(prefixAndClause.getKey())) {\n+        List<JoinFilterColumnCorrelationAnalysis> correlations = correlationCache.computeIfAbsent(\n+            prefixAndClause.getKey(),\n+            p -> findCorrelatedBaseTableColumns(\n+                baseAdapter,\n+                p,\n+                prefixes.get(p),\n+                equiconditions\n+            )\n+        );\n+\n+        if (correlations == null) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        List<Filter> newFilters = new ArrayList<>();\n+        List<VirtualColumn> pushdownVirtualColumns = new ArrayList<>();\n+\n+        for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlations) {\n+          if (correlationAnalysis.supportsPushDown()) {\n+            List<String> correlatedValues = getCorrelatedValuesForPushDown(\n+                selectorFilter.getDimension(),\n+                selectorFilter.getValue(),\n+                correlationAnalysis.getJoinColumn(),\n+                prefixAndClause.getValue()\n+            );\n+\n+            if (correlatedValues == null) {\n+              return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+            }\n+\n+            for (String correlatedBaseColumn : correlationAnalysis.getBaseColumns()) {\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  correlatedBaseColumn,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+\n+            for (Expr correlatedBaseExpr : correlationAnalysis.getBaseExpressions()) {\n+              // need to create a virtual column for the expressions when pushing down\n+              String vcName = getCorrelatedBaseExprVirtualColumnName(pushdownVirtualColumns.size());\n+\n+              VirtualColumn correlatedBaseExprVirtualColumn = new ExpressionVirtualColumn(\n+                  vcName,\n+                  correlatedBaseExpr,\n+                  ValueType.STRING\n+              );\n+              pushdownVirtualColumns.add(correlatedBaseExprVirtualColumn);\n+\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  vcName,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+          }\n+        }\n+\n+        if (newFilters.isEmpty()) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        return new JoinFilterAnalysis(\n+            true,\n+            true,\n+            selectorFilter,\n+            newFilters.size() == 1 ? newFilters.get(0) : new AndFilter(newFilters),\n+            pushdownVirtualColumns\n+        );\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        selectorFilter,\n+        selectorFilter,\n+        null\n+    );\n+  }\n+\n+  private static String getCorrelatedBaseExprVirtualColumnName(int counter)\n+  {\n+    // May want to have this check other column names to absolutely prevent name conflicts\n+    return PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE + counter;\n+  }\n+\n+  /**\n+   * Helper method for rewriting filters on join table columns into filters on base table columns.\n+   *\n+   * @param filterColumn           A join table column that we're filtering on\n+   * @param filterValue            The value to filter on\n+   * @param correlatedJoinColumn   A join table column that appears as the RHS of an equicondition, which we can correlate\n+   *                               with a column on the base table\n+   * @param clauseForFilteredTable The joinable clause that corresponds to the join table being filtered on\n+   *\n+   * @return A list of values of the correlatedJoinColumn that appear in rows where filterColumn = filterValue\n+   * Returns null if we cannot determine the correlated values.\n+   */\n+  @Nullable\n+  private static List<String> getCorrelatedValuesForPushDown(\n+      String filterColumn,\n+      String filterValue,\n+      String correlatedJoinColumn,\n+      JoinableClause clauseForFilteredTable\n+  )\n+  {\n+    String filterColumnNoPrefix = filterColumn.substring(clauseForFilteredTable.getPrefix().length());\n+    String correlatedColumnNoPrefix = correlatedJoinColumn.substring(clauseForFilteredTable.getPrefix().length());\n+\n+    // would be good to allow non-key column indices on the Joinables for better perf\n+    if (clauseForFilteredTable.getJoinable() instanceof LookupJoinable) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b31fbddcd678b5f9faf705a2def1864072188929"}, "originalPosition": 459}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxNjgxMQ==", "bodyText": "Do people outside this class need to be able to make their own? Could be private if not.", "url": "https://github.com/apache/druid/pull/9301#discussion_r375016811", "createdAt": "2020-02-05T01:31:22Z", "author": {"login": "gianm"}, "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b31fbddcd678b5f9faf705a2def1864072188929"}, "originalPosition": 142}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxNzA4Mw==", "bodyText": "This should be @Nullable given the annotation in the constructor.\nAlternatively, consider Optional<Filter> rather than @Nullable Filter.", "url": "https://github.com/apache/druid/pull/9301#discussion_r375017083", "createdAt": "2020-02-05T01:32:31Z", "author": {"login": "gianm"}, "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b31fbddcd678b5f9faf705a2def1864072188929"}, "originalPosition": 158}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAxOTc2Nw==", "bodyText": "nit: Inconsistent spelling of \"pushdown\" (or \"pushDown\"?) between isCanPushDown, getPushdownFilter.", "url": "https://github.com/apache/druid/pull/9301#discussion_r375019767", "createdAt": "2020-02-05T01:43:06Z", "author": {"login": "gianm"}, "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b31fbddcd678b5f9faf705a2def1864072188929"}, "originalPosition": 113}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyMDIwOQ==", "bodyText": "It looks like this is the only spot getPushdownVirtualColumns is null-guarded, and in this case, using an empty list instead of null would have the same effect. Maybe nix the nullability and use an empty list instead?", "url": "https://github.com/apache/druid/pull/9301#discussion_r375020209", "createdAt": "2020-02-05T01:44:53Z", "author": {"login": "gianm"}, "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b31fbddcd678b5f9faf705a2def1864072188929"}, "originalPosition": 114}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyMDc3Ng==", "bodyText": "Small suggestion: might be nice to make this a helper method like Filters.and(List<Filter>). This logic is duplicated in QueryableIndexStroageAdapter, so they could both use such a helper.", "url": "https://github.com/apache/druid/pull/9301#discussion_r375020776", "createdAt": "2020-02-05T01:47:12Z", "author": {"login": "gianm"}, "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b31fbddcd678b5f9faf705a2def1864072188929"}, "originalPosition": 124}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyMjI2Nw==", "bodyText": "Should use prefixAndClause.getValue().includesColumn(filteringColumn) \u2014\u00a0it's more semantically intentful and also the logic is slightly different.", "url": "https://github.com/apache/druid/pull/9301#discussion_r375022267", "createdAt": "2020-02-05T01:53:24Z", "author": {"login": "gianm"}, "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          (SelectorFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteOrFilter(\n+      HashJoinSegmentStorageAdapter adapter,\n+      OrFilter orFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    boolean retainRhs = false;\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    for (Filter filter : orFilter.getFilters()) {\n+      boolean allBaseColumns = true;\n+      for (String requiredColumn : filter.getRequiredColumns()) {\n+        if (!adapter.isBaseColumn(requiredColumn)) {\n+          allBaseColumns = false;\n+        }\n+      }\n+\n+      if (!allBaseColumns) {\n+        retainRhs = true;\n+        if (filter instanceof SelectorFilter) {\n+          JoinFilterAnalysis rewritten = rewriteSelectorFilter(\n+              adapter,\n+              (SelectorFilter) filter,\n+              prefixes,\n+              equiconditions,\n+              correlationCache\n+          );\n+          if (!rewritten.isCanPushDown()) {\n+            return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+          } else {\n+            newFilters.add(rewritten.getPushdownFilter());\n+          }\n+        } else {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+        }\n+      } else {\n+        newFilters.add(filter);\n+      }\n+    }\n+\n+    return new JoinFilterAnalysis(\n+        true,\n+        retainRhs,\n+        orFilter,\n+        new OrFilter(newFilters),\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Rewrites a selector filter on a join table into an IN filter on the base table.\n+   *\n+   * @param baseAdapter      The adapter for the join\n+   * @param selectorFilter   SelectorFilter to be rewritten\n+   * @param prefixes         Map of join table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteSelectorFilter(\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      SelectorFilter selectorFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    String filteringColumn = selectorFilter.getDimension();\n+    for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n+      if (filteringColumn.startsWith(prefixAndClause.getKey())) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b31fbddcd678b5f9faf705a2def1864072188929"}, "originalPosition": 344}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyMzA0MQ==", "bodyText": "null is used for two things here:\n(a) correlationCache hasn't been populated yet\n(b) correlationCache has been populated, but findCorrelatedBaseTableColumns returned null\nWould it make sense to have findCorrelatedBaseTableColumns return Optional<List<JoinFilterColumnCorrelationAnalysis>> rather than @Nullable List<JoinFilterColumnCorrelationAnalysis>?", "url": "https://github.com/apache/druid/pull/9301#discussion_r375023041", "createdAt": "2020-02-05T01:56:41Z", "author": {"login": "gianm"}, "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          (SelectorFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteOrFilter(\n+      HashJoinSegmentStorageAdapter adapter,\n+      OrFilter orFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    boolean retainRhs = false;\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    for (Filter filter : orFilter.getFilters()) {\n+      boolean allBaseColumns = true;\n+      for (String requiredColumn : filter.getRequiredColumns()) {\n+        if (!adapter.isBaseColumn(requiredColumn)) {\n+          allBaseColumns = false;\n+        }\n+      }\n+\n+      if (!allBaseColumns) {\n+        retainRhs = true;\n+        if (filter instanceof SelectorFilter) {\n+          JoinFilterAnalysis rewritten = rewriteSelectorFilter(\n+              adapter,\n+              (SelectorFilter) filter,\n+              prefixes,\n+              equiconditions,\n+              correlationCache\n+          );\n+          if (!rewritten.isCanPushDown()) {\n+            return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+          } else {\n+            newFilters.add(rewritten.getPushdownFilter());\n+          }\n+        } else {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+        }\n+      } else {\n+        newFilters.add(filter);\n+      }\n+    }\n+\n+    return new JoinFilterAnalysis(\n+        true,\n+        retainRhs,\n+        orFilter,\n+        new OrFilter(newFilters),\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Rewrites a selector filter on a join table into an IN filter on the base table.\n+   *\n+   * @param baseAdapter      The adapter for the join\n+   * @param selectorFilter   SelectorFilter to be rewritten\n+   * @param prefixes         Map of join table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteSelectorFilter(\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      SelectorFilter selectorFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    String filteringColumn = selectorFilter.getDimension();\n+    for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n+      if (filteringColumn.startsWith(prefixAndClause.getKey())) {\n+        List<JoinFilterColumnCorrelationAnalysis> correlations = correlationCache.computeIfAbsent(\n+            prefixAndClause.getKey(),\n+            p -> findCorrelatedBaseTableColumns(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b31fbddcd678b5f9faf705a2def1864072188929"}, "originalPosition": 347}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNDYyNg==", "bodyText": "This class is pretty jam packed with different concepts and inner classes, maybe it would make sense to put it in its own org.apache.druid.segment.join.filter package and split it up into different classes? (Sort of like DataSourceAnalysis and its friend PreJoinableClause in org.apache.druid.query.planning, but this one is even more complex)", "url": "https://github.com/apache/druid/pull/9301#discussion_r375024626", "createdAt": "2020-02-05T02:03:20Z", "author": {"login": "gianm"}, "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          (SelectorFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteOrFilter(\n+      HashJoinSegmentStorageAdapter adapter,\n+      OrFilter orFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    boolean retainRhs = false;\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    for (Filter filter : orFilter.getFilters()) {\n+      boolean allBaseColumns = true;\n+      for (String requiredColumn : filter.getRequiredColumns()) {\n+        if (!adapter.isBaseColumn(requiredColumn)) {\n+          allBaseColumns = false;\n+        }\n+      }\n+\n+      if (!allBaseColumns) {\n+        retainRhs = true;\n+        if (filter instanceof SelectorFilter) {\n+          JoinFilterAnalysis rewritten = rewriteSelectorFilter(\n+              adapter,\n+              (SelectorFilter) filter,\n+              prefixes,\n+              equiconditions,\n+              correlationCache\n+          );\n+          if (!rewritten.isCanPushDown()) {\n+            return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+          } else {\n+            newFilters.add(rewritten.getPushdownFilter());\n+          }\n+        } else {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+        }\n+      } else {\n+        newFilters.add(filter);\n+      }\n+    }\n+\n+    return new JoinFilterAnalysis(\n+        true,\n+        retainRhs,\n+        orFilter,\n+        new OrFilter(newFilters),\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Rewrites a selector filter on a join table into an IN filter on the base table.\n+   *\n+   * @param baseAdapter      The adapter for the join\n+   * @param selectorFilter   SelectorFilter to be rewritten\n+   * @param prefixes         Map of join table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteSelectorFilter(\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      SelectorFilter selectorFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    String filteringColumn = selectorFilter.getDimension();\n+    for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n+      if (filteringColumn.startsWith(prefixAndClause.getKey())) {\n+        List<JoinFilterColumnCorrelationAnalysis> correlations = correlationCache.computeIfAbsent(\n+            prefixAndClause.getKey(),\n+            p -> findCorrelatedBaseTableColumns(\n+                baseAdapter,\n+                p,\n+                prefixes.get(p),\n+                equiconditions\n+            )\n+        );\n+\n+        if (correlations == null) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        List<Filter> newFilters = new ArrayList<>();\n+        List<VirtualColumn> pushdownVirtualColumns = new ArrayList<>();\n+\n+        for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlations) {\n+          if (correlationAnalysis.supportsPushDown()) {\n+            List<String> correlatedValues = getCorrelatedValuesForPushDown(\n+                selectorFilter.getDimension(),\n+                selectorFilter.getValue(),\n+                correlationAnalysis.getJoinColumn(),\n+                prefixAndClause.getValue()\n+            );\n+\n+            if (correlatedValues == null) {\n+              return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+            }\n+\n+            for (String correlatedBaseColumn : correlationAnalysis.getBaseColumns()) {\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  correlatedBaseColumn,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+\n+            for (Expr correlatedBaseExpr : correlationAnalysis.getBaseExpressions()) {\n+              // need to create a virtual column for the expressions when pushing down\n+              String vcName = getCorrelatedBaseExprVirtualColumnName(pushdownVirtualColumns.size());\n+\n+              VirtualColumn correlatedBaseExprVirtualColumn = new ExpressionVirtualColumn(\n+                  vcName,\n+                  correlatedBaseExpr,\n+                  ValueType.STRING\n+              );\n+              pushdownVirtualColumns.add(correlatedBaseExprVirtualColumn);\n+\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  vcName,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+          }\n+        }\n+\n+        if (newFilters.isEmpty()) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        return new JoinFilterAnalysis(\n+            true,\n+            true,\n+            selectorFilter,\n+            newFilters.size() == 1 ? newFilters.get(0) : new AndFilter(newFilters),\n+            pushdownVirtualColumns\n+        );\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        selectorFilter,\n+        selectorFilter,\n+        null\n+    );\n+  }\n+\n+  private static String getCorrelatedBaseExprVirtualColumnName(int counter)\n+  {\n+    // May want to have this check other column names to absolutely prevent name conflicts\n+    return PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE + counter;\n+  }\n+\n+  /**\n+   * Helper method for rewriting filters on join table columns into filters on base table columns.\n+   *\n+   * @param filterColumn           A join table column that we're filtering on\n+   * @param filterValue            The value to filter on\n+   * @param correlatedJoinColumn   A join table column that appears as the RHS of an equicondition, which we can correlate\n+   *                               with a column on the base table\n+   * @param clauseForFilteredTable The joinable clause that corresponds to the join table being filtered on\n+   *\n+   * @return A list of values of the correlatedJoinColumn that appear in rows where filterColumn = filterValue\n+   * Returns null if we cannot determine the correlated values.\n+   */\n+  @Nullable\n+  private static List<String> getCorrelatedValuesForPushDown(\n+      String filterColumn,\n+      String filterValue,\n+      String correlatedJoinColumn,\n+      JoinableClause clauseForFilteredTable\n+  )\n+  {\n+    String filterColumnNoPrefix = filterColumn.substring(clauseForFilteredTable.getPrefix().length());\n+    String correlatedColumnNoPrefix = correlatedJoinColumn.substring(clauseForFilteredTable.getPrefix().length());\n+\n+    // would be good to allow non-key column indices on the Joinables for better perf\n+    if (clauseForFilteredTable.getJoinable() instanceof LookupJoinable) {\n+      LookupJoinable lookupJoinable = (LookupJoinable) clauseForFilteredTable.getJoinable();\n+      List<String> correlatedValues;\n+      if (LookupColumnSelectorFactory.KEY_COLUMN.equals(filterColumnNoPrefix)) {\n+        if (LookupColumnSelectorFactory.KEY_COLUMN.equals(correlatedColumnNoPrefix)) {\n+          correlatedValues = ImmutableList.of(filterValue);\n+        } else {\n+          correlatedValues = ImmutableList.of(lookupJoinable.getExtractor().apply(filterColumnNoPrefix));\n+        }\n+      } else {\n+        if (LookupColumnSelectorFactory.VALUE_COLUMN.equals(correlatedColumnNoPrefix)) {\n+          correlatedValues = ImmutableList.of(filterValue);\n+        } else {\n+          correlatedValues = lookupJoinable.getExtractor().unapply(filterValue);\n+        }\n+      }\n+      return correlatedValues;\n+    }\n+\n+    if (clauseForFilteredTable.getJoinable() instanceof IndexedTableJoinable) {\n+      IndexedTableJoinable indexedTableJoinable = (IndexedTableJoinable) clauseForFilteredTable.getJoinable();\n+      IndexedTable indexedTable = indexedTableJoinable.getTable();\n+\n+      int filterColumnPosition = indexedTable.allColumns().indexOf(filterColumnNoPrefix);\n+      int correlatedColumnPosition = indexedTable.allColumns().indexOf(correlatedColumnNoPrefix);\n+\n+      if (filterColumnPosition < 0 || correlatedColumnPosition < 0) {\n+        return null;\n+      }\n+\n+      if (indexedTable.keyColumns().contains(filterColumnNoPrefix)) {\n+        IndexedTable.Index index = indexedTable.columnIndex(filterColumnPosition);\n+        IndexedTable.Reader reader = indexedTable.columnReader(correlatedColumnPosition);\n+        IntList rowIndex = index.find(filterValue);\n+        List<String> correlatedValues = new ArrayList<>();\n+        for (int i = 0; i < rowIndex.size(); i++) {\n+          int rowNum = rowIndex.getInt(i);\n+          correlatedValues.add(reader.read(rowNum).toString());\n+        }\n+        return correlatedValues;\n+      } else {\n+        IndexedTable.Reader dimNameReader = indexedTable.columnReader(filterColumnPosition);\n+        IndexedTable.Reader correlatedColumnReader = indexedTable.columnReader(correlatedColumnPosition);\n+        Set<String> correlatedValueSet = new HashSet<>();\n+        for (int i = 0; i < indexedTable.numRows(); i++) {\n+          if (filterValue.equals(dimNameReader.read(i).toString())) {\n+            correlatedValueSet.add(correlatedColumnReader.read(i).toString());\n+          }\n+        }\n+\n+        return new ArrayList<>(correlatedValueSet);\n+      }\n+    }\n+\n+    return null;\n+  }\n+\n+  /**\n+   * For all RHS columns that appear in the join's equiconditions, correlate them with base table columns if possible.\n+   *\n+   * @param adapter              The adapter for the join. Used to determine if a column is a base table column.\n+   * @param tablePrefix          Prefix for a join table\n+   * @param clauseForTablePrefix Joinable clause for the prefix\n+   * @param equiconditions       Map of equiconditions, keyed by the right hand columns\n+   *\n+   * @return A list of correlatation analyses for the equicondition RHS columns that reside in the table associated with\n+   * the tablePrefix\n+   */\n+  @Nullable\n+  private static List<JoinFilterColumnCorrelationAnalysis> findCorrelatedBaseTableColumns(\n+      HashJoinSegmentStorageAdapter adapter,\n+      String tablePrefix,\n+      JoinableClause clauseForTablePrefix,\n+      Map<String, Expr> equiconditions\n+  )\n+  {\n+    JoinConditionAnalysis jca = clauseForTablePrefix.getCondition();\n+\n+    List<String> rhsColumns = new ArrayList<>();\n+    for (Equality eq : jca.getEquiConditions()) {\n+      rhsColumns.add(tablePrefix + eq.getRightColumn());\n+    }\n+\n+    List<JoinFilterColumnCorrelationAnalysis> correlations = new ArrayList<>();\n+\n+    for (String rhsColumn : rhsColumns) {\n+      List<String> correlatedBaseColumns = new ArrayList<>();\n+      List<Expr> correlatedBaseExpressions = new ArrayList<>();\n+      boolean terminate = false;\n+\n+      String findMappingFor = rhsColumn;\n+      while (!terminate) {\n+        Expr lhs = equiconditions.get(findMappingFor);\n+        if (lhs == null) {\n+          break;\n+        }\n+        String identifier = lhs.getBindingIfIdentifier();\n+        if (identifier == null) {\n+          // We push down if the function only requires base table columns\n+          Expr.BindingDetails bindingDetails = lhs.analyzeInputs();\n+          Set<String> requiredBindings = bindingDetails.getRequiredBindings();\n+          for (String requiredBinding : requiredBindings) {\n+            if (!adapter.isBaseColumn(requiredBinding)) {\n+              return null;\n+            }\n+          }\n+\n+          terminate = true;\n+          correlatedBaseExpressions.add(lhs);\n+        } else {\n+          // simple identifier, see if we can correlate it with a column on the base table\n+          findMappingFor = identifier;\n+          if (adapter.isBaseColumn(identifier)) {\n+            terminate = true;\n+            correlatedBaseColumns.add(findMappingFor);\n+          }\n+        }\n+      }\n+\n+      if (correlatedBaseColumns.isEmpty() && correlatedBaseExpressions.isEmpty()) {\n+        return null;\n+      }\n+\n+      correlations.add(\n+          new JoinFilterColumnCorrelationAnalysis(\n+              rhsColumn,\n+              correlatedBaseColumns,\n+              correlatedBaseExpressions\n+          )\n+      );\n+    }\n+\n+    return correlations;\n+  }\n+\n+  private static boolean filterMatchesNull(Filter filter)\n+  {\n+    ValueMatcher valueMatcher = filter.makeMatcher(ALL_NULL_COLUMN_SELECTOR_FACTORY);\n+    return valueMatcher.matches();\n+  }\n+\n+  private static class AllNullColumnSelectorFactory implements ColumnSelectorFactory", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b31fbddcd678b5f9faf705a2def1864072188929"}, "originalPosition": 600}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNTMyNg==", "bodyText": "equiConditions would match the spelling from JoinConditionAnalysis.", "url": "https://github.com/apache/druid/pull/9301#discussion_r375025326", "createdAt": "2020-02-05T02:06:19Z", "author": {"login": "gianm"}, "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          (SelectorFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteOrFilter(\n+      HashJoinSegmentStorageAdapter adapter,\n+      OrFilter orFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    boolean retainRhs = false;\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    for (Filter filter : orFilter.getFilters()) {\n+      boolean allBaseColumns = true;\n+      for (String requiredColumn : filter.getRequiredColumns()) {\n+        if (!adapter.isBaseColumn(requiredColumn)) {\n+          allBaseColumns = false;\n+        }\n+      }\n+\n+      if (!allBaseColumns) {\n+        retainRhs = true;\n+        if (filter instanceof SelectorFilter) {\n+          JoinFilterAnalysis rewritten = rewriteSelectorFilter(\n+              adapter,\n+              (SelectorFilter) filter,\n+              prefixes,\n+              equiconditions,\n+              correlationCache\n+          );\n+          if (!rewritten.isCanPushDown()) {\n+            return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+          } else {\n+            newFilters.add(rewritten.getPushdownFilter());\n+          }\n+        } else {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+        }\n+      } else {\n+        newFilters.add(filter);\n+      }\n+    }\n+\n+    return new JoinFilterAnalysis(\n+        true,\n+        retainRhs,\n+        orFilter,\n+        new OrFilter(newFilters),\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Rewrites a selector filter on a join table into an IN filter on the base table.\n+   *\n+   * @param baseAdapter      The adapter for the join\n+   * @param selectorFilter   SelectorFilter to be rewritten\n+   * @param prefixes         Map of join table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteSelectorFilter(\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      SelectorFilter selectorFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    String filteringColumn = selectorFilter.getDimension();\n+    for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n+      if (filteringColumn.startsWith(prefixAndClause.getKey())) {\n+        List<JoinFilterColumnCorrelationAnalysis> correlations = correlationCache.computeIfAbsent(\n+            prefixAndClause.getKey(),\n+            p -> findCorrelatedBaseTableColumns(\n+                baseAdapter,\n+                p,\n+                prefixes.get(p),\n+                equiconditions\n+            )\n+        );\n+\n+        if (correlations == null) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        List<Filter> newFilters = new ArrayList<>();\n+        List<VirtualColumn> pushdownVirtualColumns = new ArrayList<>();\n+\n+        for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlations) {\n+          if (correlationAnalysis.supportsPushDown()) {\n+            List<String> correlatedValues = getCorrelatedValuesForPushDown(\n+                selectorFilter.getDimension(),\n+                selectorFilter.getValue(),\n+                correlationAnalysis.getJoinColumn(),\n+                prefixAndClause.getValue()\n+            );\n+\n+            if (correlatedValues == null) {\n+              return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+            }\n+\n+            for (String correlatedBaseColumn : correlationAnalysis.getBaseColumns()) {\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  correlatedBaseColumn,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+\n+            for (Expr correlatedBaseExpr : correlationAnalysis.getBaseExpressions()) {\n+              // need to create a virtual column for the expressions when pushing down\n+              String vcName = getCorrelatedBaseExprVirtualColumnName(pushdownVirtualColumns.size());\n+\n+              VirtualColumn correlatedBaseExprVirtualColumn = new ExpressionVirtualColumn(\n+                  vcName,\n+                  correlatedBaseExpr,\n+                  ValueType.STRING\n+              );\n+              pushdownVirtualColumns.add(correlatedBaseExprVirtualColumn);\n+\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  vcName,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+          }\n+        }\n+\n+        if (newFilters.isEmpty()) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        return new JoinFilterAnalysis(\n+            true,\n+            true,\n+            selectorFilter,\n+            newFilters.size() == 1 ? newFilters.get(0) : new AndFilter(newFilters),\n+            pushdownVirtualColumns\n+        );\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        selectorFilter,\n+        selectorFilter,\n+        null\n+    );\n+  }\n+\n+  private static String getCorrelatedBaseExprVirtualColumnName(int counter)\n+  {\n+    // May want to have this check other column names to absolutely prevent name conflicts\n+    return PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE + counter;\n+  }\n+\n+  /**\n+   * Helper method for rewriting filters on join table columns into filters on base table columns.\n+   *\n+   * @param filterColumn           A join table column that we're filtering on\n+   * @param filterValue            The value to filter on\n+   * @param correlatedJoinColumn   A join table column that appears as the RHS of an equicondition, which we can correlate\n+   *                               with a column on the base table\n+   * @param clauseForFilteredTable The joinable clause that corresponds to the join table being filtered on\n+   *\n+   * @return A list of values of the correlatedJoinColumn that appear in rows where filterColumn = filterValue\n+   * Returns null if we cannot determine the correlated values.\n+   */\n+  @Nullable\n+  private static List<String> getCorrelatedValuesForPushDown(\n+      String filterColumn,\n+      String filterValue,\n+      String correlatedJoinColumn,\n+      JoinableClause clauseForFilteredTable\n+  )\n+  {\n+    String filterColumnNoPrefix = filterColumn.substring(clauseForFilteredTable.getPrefix().length());\n+    String correlatedColumnNoPrefix = correlatedJoinColumn.substring(clauseForFilteredTable.getPrefix().length());\n+\n+    // would be good to allow non-key column indices on the Joinables for better perf\n+    if (clauseForFilteredTable.getJoinable() instanceof LookupJoinable) {\n+      LookupJoinable lookupJoinable = (LookupJoinable) clauseForFilteredTable.getJoinable();\n+      List<String> correlatedValues;\n+      if (LookupColumnSelectorFactory.KEY_COLUMN.equals(filterColumnNoPrefix)) {\n+        if (LookupColumnSelectorFactory.KEY_COLUMN.equals(correlatedColumnNoPrefix)) {\n+          correlatedValues = ImmutableList.of(filterValue);\n+        } else {\n+          correlatedValues = ImmutableList.of(lookupJoinable.getExtractor().apply(filterColumnNoPrefix));\n+        }\n+      } else {\n+        if (LookupColumnSelectorFactory.VALUE_COLUMN.equals(correlatedColumnNoPrefix)) {\n+          correlatedValues = ImmutableList.of(filterValue);\n+        } else {\n+          correlatedValues = lookupJoinable.getExtractor().unapply(filterValue);\n+        }\n+      }\n+      return correlatedValues;\n+    }\n+\n+    if (clauseForFilteredTable.getJoinable() instanceof IndexedTableJoinable) {\n+      IndexedTableJoinable indexedTableJoinable = (IndexedTableJoinable) clauseForFilteredTable.getJoinable();\n+      IndexedTable indexedTable = indexedTableJoinable.getTable();\n+\n+      int filterColumnPosition = indexedTable.allColumns().indexOf(filterColumnNoPrefix);\n+      int correlatedColumnPosition = indexedTable.allColumns().indexOf(correlatedColumnNoPrefix);\n+\n+      if (filterColumnPosition < 0 || correlatedColumnPosition < 0) {\n+        return null;\n+      }\n+\n+      if (indexedTable.keyColumns().contains(filterColumnNoPrefix)) {\n+        IndexedTable.Index index = indexedTable.columnIndex(filterColumnPosition);\n+        IndexedTable.Reader reader = indexedTable.columnReader(correlatedColumnPosition);\n+        IntList rowIndex = index.find(filterValue);\n+        List<String> correlatedValues = new ArrayList<>();\n+        for (int i = 0; i < rowIndex.size(); i++) {\n+          int rowNum = rowIndex.getInt(i);\n+          correlatedValues.add(reader.read(rowNum).toString());\n+        }\n+        return correlatedValues;\n+      } else {\n+        IndexedTable.Reader dimNameReader = indexedTable.columnReader(filterColumnPosition);\n+        IndexedTable.Reader correlatedColumnReader = indexedTable.columnReader(correlatedColumnPosition);\n+        Set<String> correlatedValueSet = new HashSet<>();\n+        for (int i = 0; i < indexedTable.numRows(); i++) {\n+          if (filterValue.equals(dimNameReader.read(i).toString())) {\n+            correlatedValueSet.add(correlatedColumnReader.read(i).toString());\n+          }\n+        }\n+\n+        return new ArrayList<>(correlatedValueSet);\n+      }\n+    }\n+\n+    return null;\n+  }\n+\n+  /**\n+   * For all RHS columns that appear in the join's equiconditions, correlate them with base table columns if possible.\n+   *\n+   * @param adapter              The adapter for the join. Used to determine if a column is a base table column.\n+   * @param tablePrefix          Prefix for a join table\n+   * @param clauseForTablePrefix Joinable clause for the prefix\n+   * @param equiconditions       Map of equiconditions, keyed by the right hand columns\n+   *\n+   * @return A list of correlatation analyses for the equicondition RHS columns that reside in the table associated with\n+   * the tablePrefix\n+   */\n+  @Nullable\n+  private static List<JoinFilterColumnCorrelationAnalysis> findCorrelatedBaseTableColumns(\n+      HashJoinSegmentStorageAdapter adapter,\n+      String tablePrefix,\n+      JoinableClause clauseForTablePrefix,\n+      Map<String, Expr> equiconditions", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b31fbddcd678b5f9faf705a2def1864072188929"}, "originalPosition": 532}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNTQxOA==", "bodyText": "Two conditions can refer to the same rhs column. Should this be a Set?", "url": "https://github.com/apache/druid/pull/9301#discussion_r375025418", "createdAt": "2020-02-05T02:06:37Z", "author": {"login": "gianm"}, "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          (SelectorFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteOrFilter(\n+      HashJoinSegmentStorageAdapter adapter,\n+      OrFilter orFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    boolean retainRhs = false;\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    for (Filter filter : orFilter.getFilters()) {\n+      boolean allBaseColumns = true;\n+      for (String requiredColumn : filter.getRequiredColumns()) {\n+        if (!adapter.isBaseColumn(requiredColumn)) {\n+          allBaseColumns = false;\n+        }\n+      }\n+\n+      if (!allBaseColumns) {\n+        retainRhs = true;\n+        if (filter instanceof SelectorFilter) {\n+          JoinFilterAnalysis rewritten = rewriteSelectorFilter(\n+              adapter,\n+              (SelectorFilter) filter,\n+              prefixes,\n+              equiconditions,\n+              correlationCache\n+          );\n+          if (!rewritten.isCanPushDown()) {\n+            return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+          } else {\n+            newFilters.add(rewritten.getPushdownFilter());\n+          }\n+        } else {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+        }\n+      } else {\n+        newFilters.add(filter);\n+      }\n+    }\n+\n+    return new JoinFilterAnalysis(\n+        true,\n+        retainRhs,\n+        orFilter,\n+        new OrFilter(newFilters),\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Rewrites a selector filter on a join table into an IN filter on the base table.\n+   *\n+   * @param baseAdapter      The adapter for the join\n+   * @param selectorFilter   SelectorFilter to be rewritten\n+   * @param prefixes         Map of join table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteSelectorFilter(\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      SelectorFilter selectorFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    String filteringColumn = selectorFilter.getDimension();\n+    for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n+      if (filteringColumn.startsWith(prefixAndClause.getKey())) {\n+        List<JoinFilterColumnCorrelationAnalysis> correlations = correlationCache.computeIfAbsent(\n+            prefixAndClause.getKey(),\n+            p -> findCorrelatedBaseTableColumns(\n+                baseAdapter,\n+                p,\n+                prefixes.get(p),\n+                equiconditions\n+            )\n+        );\n+\n+        if (correlations == null) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        List<Filter> newFilters = new ArrayList<>();\n+        List<VirtualColumn> pushdownVirtualColumns = new ArrayList<>();\n+\n+        for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlations) {\n+          if (correlationAnalysis.supportsPushDown()) {\n+            List<String> correlatedValues = getCorrelatedValuesForPushDown(\n+                selectorFilter.getDimension(),\n+                selectorFilter.getValue(),\n+                correlationAnalysis.getJoinColumn(),\n+                prefixAndClause.getValue()\n+            );\n+\n+            if (correlatedValues == null) {\n+              return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+            }\n+\n+            for (String correlatedBaseColumn : correlationAnalysis.getBaseColumns()) {\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  correlatedBaseColumn,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+\n+            for (Expr correlatedBaseExpr : correlationAnalysis.getBaseExpressions()) {\n+              // need to create a virtual column for the expressions when pushing down\n+              String vcName = getCorrelatedBaseExprVirtualColumnName(pushdownVirtualColumns.size());\n+\n+              VirtualColumn correlatedBaseExprVirtualColumn = new ExpressionVirtualColumn(\n+                  vcName,\n+                  correlatedBaseExpr,\n+                  ValueType.STRING\n+              );\n+              pushdownVirtualColumns.add(correlatedBaseExprVirtualColumn);\n+\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  vcName,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+          }\n+        }\n+\n+        if (newFilters.isEmpty()) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        return new JoinFilterAnalysis(\n+            true,\n+            true,\n+            selectorFilter,\n+            newFilters.size() == 1 ? newFilters.get(0) : new AndFilter(newFilters),\n+            pushdownVirtualColumns\n+        );\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        selectorFilter,\n+        selectorFilter,\n+        null\n+    );\n+  }\n+\n+  private static String getCorrelatedBaseExprVirtualColumnName(int counter)\n+  {\n+    // May want to have this check other column names to absolutely prevent name conflicts\n+    return PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE + counter;\n+  }\n+\n+  /**\n+   * Helper method for rewriting filters on join table columns into filters on base table columns.\n+   *\n+   * @param filterColumn           A join table column that we're filtering on\n+   * @param filterValue            The value to filter on\n+   * @param correlatedJoinColumn   A join table column that appears as the RHS of an equicondition, which we can correlate\n+   *                               with a column on the base table\n+   * @param clauseForFilteredTable The joinable clause that corresponds to the join table being filtered on\n+   *\n+   * @return A list of values of the correlatedJoinColumn that appear in rows where filterColumn = filterValue\n+   * Returns null if we cannot determine the correlated values.\n+   */\n+  @Nullable\n+  private static List<String> getCorrelatedValuesForPushDown(\n+      String filterColumn,\n+      String filterValue,\n+      String correlatedJoinColumn,\n+      JoinableClause clauseForFilteredTable\n+  )\n+  {\n+    String filterColumnNoPrefix = filterColumn.substring(clauseForFilteredTable.getPrefix().length());\n+    String correlatedColumnNoPrefix = correlatedJoinColumn.substring(clauseForFilteredTable.getPrefix().length());\n+\n+    // would be good to allow non-key column indices on the Joinables for better perf\n+    if (clauseForFilteredTable.getJoinable() instanceof LookupJoinable) {\n+      LookupJoinable lookupJoinable = (LookupJoinable) clauseForFilteredTable.getJoinable();\n+      List<String> correlatedValues;\n+      if (LookupColumnSelectorFactory.KEY_COLUMN.equals(filterColumnNoPrefix)) {\n+        if (LookupColumnSelectorFactory.KEY_COLUMN.equals(correlatedColumnNoPrefix)) {\n+          correlatedValues = ImmutableList.of(filterValue);\n+        } else {\n+          correlatedValues = ImmutableList.of(lookupJoinable.getExtractor().apply(filterColumnNoPrefix));\n+        }\n+      } else {\n+        if (LookupColumnSelectorFactory.VALUE_COLUMN.equals(correlatedColumnNoPrefix)) {\n+          correlatedValues = ImmutableList.of(filterValue);\n+        } else {\n+          correlatedValues = lookupJoinable.getExtractor().unapply(filterValue);\n+        }\n+      }\n+      return correlatedValues;\n+    }\n+\n+    if (clauseForFilteredTable.getJoinable() instanceof IndexedTableJoinable) {\n+      IndexedTableJoinable indexedTableJoinable = (IndexedTableJoinable) clauseForFilteredTable.getJoinable();\n+      IndexedTable indexedTable = indexedTableJoinable.getTable();\n+\n+      int filterColumnPosition = indexedTable.allColumns().indexOf(filterColumnNoPrefix);\n+      int correlatedColumnPosition = indexedTable.allColumns().indexOf(correlatedColumnNoPrefix);\n+\n+      if (filterColumnPosition < 0 || correlatedColumnPosition < 0) {\n+        return null;\n+      }\n+\n+      if (indexedTable.keyColumns().contains(filterColumnNoPrefix)) {\n+        IndexedTable.Index index = indexedTable.columnIndex(filterColumnPosition);\n+        IndexedTable.Reader reader = indexedTable.columnReader(correlatedColumnPosition);\n+        IntList rowIndex = index.find(filterValue);\n+        List<String> correlatedValues = new ArrayList<>();\n+        for (int i = 0; i < rowIndex.size(); i++) {\n+          int rowNum = rowIndex.getInt(i);\n+          correlatedValues.add(reader.read(rowNum).toString());\n+        }\n+        return correlatedValues;\n+      } else {\n+        IndexedTable.Reader dimNameReader = indexedTable.columnReader(filterColumnPosition);\n+        IndexedTable.Reader correlatedColumnReader = indexedTable.columnReader(correlatedColumnPosition);\n+        Set<String> correlatedValueSet = new HashSet<>();\n+        for (int i = 0; i < indexedTable.numRows(); i++) {\n+          if (filterValue.equals(dimNameReader.read(i).toString())) {\n+            correlatedValueSet.add(correlatedColumnReader.read(i).toString());\n+          }\n+        }\n+\n+        return new ArrayList<>(correlatedValueSet);\n+      }\n+    }\n+\n+    return null;\n+  }\n+\n+  /**\n+   * For all RHS columns that appear in the join's equiconditions, correlate them with base table columns if possible.\n+   *\n+   * @param adapter              The adapter for the join. Used to determine if a column is a base table column.\n+   * @param tablePrefix          Prefix for a join table\n+   * @param clauseForTablePrefix Joinable clause for the prefix\n+   * @param equiconditions       Map of equiconditions, keyed by the right hand columns\n+   *\n+   * @return A list of correlatation analyses for the equicondition RHS columns that reside in the table associated with\n+   * the tablePrefix\n+   */\n+  @Nullable\n+  private static List<JoinFilterColumnCorrelationAnalysis> findCorrelatedBaseTableColumns(\n+      HashJoinSegmentStorageAdapter adapter,\n+      String tablePrefix,\n+      JoinableClause clauseForTablePrefix,\n+      Map<String, Expr> equiconditions\n+  )\n+  {\n+    JoinConditionAnalysis jca = clauseForTablePrefix.getCondition();\n+\n+    List<String> rhsColumns = new ArrayList<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b31fbddcd678b5f9faf705a2def1864072188929"}, "originalPosition": 537}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNTg0MA==", "bodyText": "There could be more than one equi-condition for the same rhs column. It looks like this code disregards that possibility.", "url": "https://github.com/apache/druid/pull/9301#discussion_r375025840", "createdAt": "2020-02-05T02:08:12Z", "author": {"login": "gianm"}, "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b31fbddcd678b5f9faf705a2def1864072188929"}, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNjE4Mg==", "bodyText": "small suggestion: !requiredBindings.stream().allMatch( blah blah blah ) may be more readable", "url": "https://github.com/apache/druid/pull/9301#discussion_r375026182", "createdAt": "2020-02-05T02:09:44Z", "author": {"login": "gianm"}, "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          (SelectorFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteOrFilter(\n+      HashJoinSegmentStorageAdapter adapter,\n+      OrFilter orFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    boolean retainRhs = false;\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    for (Filter filter : orFilter.getFilters()) {\n+      boolean allBaseColumns = true;\n+      for (String requiredColumn : filter.getRequiredColumns()) {\n+        if (!adapter.isBaseColumn(requiredColumn)) {\n+          allBaseColumns = false;\n+        }\n+      }\n+\n+      if (!allBaseColumns) {\n+        retainRhs = true;\n+        if (filter instanceof SelectorFilter) {\n+          JoinFilterAnalysis rewritten = rewriteSelectorFilter(\n+              adapter,\n+              (SelectorFilter) filter,\n+              prefixes,\n+              equiconditions,\n+              correlationCache\n+          );\n+          if (!rewritten.isCanPushDown()) {\n+            return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+          } else {\n+            newFilters.add(rewritten.getPushdownFilter());\n+          }\n+        } else {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+        }\n+      } else {\n+        newFilters.add(filter);\n+      }\n+    }\n+\n+    return new JoinFilterAnalysis(\n+        true,\n+        retainRhs,\n+        orFilter,\n+        new OrFilter(newFilters),\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Rewrites a selector filter on a join table into an IN filter on the base table.\n+   *\n+   * @param baseAdapter      The adapter for the join\n+   * @param selectorFilter   SelectorFilter to be rewritten\n+   * @param prefixes         Map of join table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteSelectorFilter(\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      SelectorFilter selectorFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    String filteringColumn = selectorFilter.getDimension();\n+    for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n+      if (filteringColumn.startsWith(prefixAndClause.getKey())) {\n+        List<JoinFilterColumnCorrelationAnalysis> correlations = correlationCache.computeIfAbsent(\n+            prefixAndClause.getKey(),\n+            p -> findCorrelatedBaseTableColumns(\n+                baseAdapter,\n+                p,\n+                prefixes.get(p),\n+                equiconditions\n+            )\n+        );\n+\n+        if (correlations == null) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        List<Filter> newFilters = new ArrayList<>();\n+        List<VirtualColumn> pushdownVirtualColumns = new ArrayList<>();\n+\n+        for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlations) {\n+          if (correlationAnalysis.supportsPushDown()) {\n+            List<String> correlatedValues = getCorrelatedValuesForPushDown(\n+                selectorFilter.getDimension(),\n+                selectorFilter.getValue(),\n+                correlationAnalysis.getJoinColumn(),\n+                prefixAndClause.getValue()\n+            );\n+\n+            if (correlatedValues == null) {\n+              return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+            }\n+\n+            for (String correlatedBaseColumn : correlationAnalysis.getBaseColumns()) {\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  correlatedBaseColumn,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+\n+            for (Expr correlatedBaseExpr : correlationAnalysis.getBaseExpressions()) {\n+              // need to create a virtual column for the expressions when pushing down\n+              String vcName = getCorrelatedBaseExprVirtualColumnName(pushdownVirtualColumns.size());\n+\n+              VirtualColumn correlatedBaseExprVirtualColumn = new ExpressionVirtualColumn(\n+                  vcName,\n+                  correlatedBaseExpr,\n+                  ValueType.STRING\n+              );\n+              pushdownVirtualColumns.add(correlatedBaseExprVirtualColumn);\n+\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  vcName,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+          }\n+        }\n+\n+        if (newFilters.isEmpty()) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        return new JoinFilterAnalysis(\n+            true,\n+            true,\n+            selectorFilter,\n+            newFilters.size() == 1 ? newFilters.get(0) : new AndFilter(newFilters),\n+            pushdownVirtualColumns\n+        );\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        selectorFilter,\n+        selectorFilter,\n+        null\n+    );\n+  }\n+\n+  private static String getCorrelatedBaseExprVirtualColumnName(int counter)\n+  {\n+    // May want to have this check other column names to absolutely prevent name conflicts\n+    return PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE + counter;\n+  }\n+\n+  /**\n+   * Helper method for rewriting filters on join table columns into filters on base table columns.\n+   *\n+   * @param filterColumn           A join table column that we're filtering on\n+   * @param filterValue            The value to filter on\n+   * @param correlatedJoinColumn   A join table column that appears as the RHS of an equicondition, which we can correlate\n+   *                               with a column on the base table\n+   * @param clauseForFilteredTable The joinable clause that corresponds to the join table being filtered on\n+   *\n+   * @return A list of values of the correlatedJoinColumn that appear in rows where filterColumn = filterValue\n+   * Returns null if we cannot determine the correlated values.\n+   */\n+  @Nullable\n+  private static List<String> getCorrelatedValuesForPushDown(\n+      String filterColumn,\n+      String filterValue,\n+      String correlatedJoinColumn,\n+      JoinableClause clauseForFilteredTable\n+  )\n+  {\n+    String filterColumnNoPrefix = filterColumn.substring(clauseForFilteredTable.getPrefix().length());\n+    String correlatedColumnNoPrefix = correlatedJoinColumn.substring(clauseForFilteredTable.getPrefix().length());\n+\n+    // would be good to allow non-key column indices on the Joinables for better perf\n+    if (clauseForFilteredTable.getJoinable() instanceof LookupJoinable) {\n+      LookupJoinable lookupJoinable = (LookupJoinable) clauseForFilteredTable.getJoinable();\n+      List<String> correlatedValues;\n+      if (LookupColumnSelectorFactory.KEY_COLUMN.equals(filterColumnNoPrefix)) {\n+        if (LookupColumnSelectorFactory.KEY_COLUMN.equals(correlatedColumnNoPrefix)) {\n+          correlatedValues = ImmutableList.of(filterValue);\n+        } else {\n+          correlatedValues = ImmutableList.of(lookupJoinable.getExtractor().apply(filterColumnNoPrefix));\n+        }\n+      } else {\n+        if (LookupColumnSelectorFactory.VALUE_COLUMN.equals(correlatedColumnNoPrefix)) {\n+          correlatedValues = ImmutableList.of(filterValue);\n+        } else {\n+          correlatedValues = lookupJoinable.getExtractor().unapply(filterValue);\n+        }\n+      }\n+      return correlatedValues;\n+    }\n+\n+    if (clauseForFilteredTable.getJoinable() instanceof IndexedTableJoinable) {\n+      IndexedTableJoinable indexedTableJoinable = (IndexedTableJoinable) clauseForFilteredTable.getJoinable();\n+      IndexedTable indexedTable = indexedTableJoinable.getTable();\n+\n+      int filterColumnPosition = indexedTable.allColumns().indexOf(filterColumnNoPrefix);\n+      int correlatedColumnPosition = indexedTable.allColumns().indexOf(correlatedColumnNoPrefix);\n+\n+      if (filterColumnPosition < 0 || correlatedColumnPosition < 0) {\n+        return null;\n+      }\n+\n+      if (indexedTable.keyColumns().contains(filterColumnNoPrefix)) {\n+        IndexedTable.Index index = indexedTable.columnIndex(filterColumnPosition);\n+        IndexedTable.Reader reader = indexedTable.columnReader(correlatedColumnPosition);\n+        IntList rowIndex = index.find(filterValue);\n+        List<String> correlatedValues = new ArrayList<>();\n+        for (int i = 0; i < rowIndex.size(); i++) {\n+          int rowNum = rowIndex.getInt(i);\n+          correlatedValues.add(reader.read(rowNum).toString());\n+        }\n+        return correlatedValues;\n+      } else {\n+        IndexedTable.Reader dimNameReader = indexedTable.columnReader(filterColumnPosition);\n+        IndexedTable.Reader correlatedColumnReader = indexedTable.columnReader(correlatedColumnPosition);\n+        Set<String> correlatedValueSet = new HashSet<>();\n+        for (int i = 0; i < indexedTable.numRows(); i++) {\n+          if (filterValue.equals(dimNameReader.read(i).toString())) {\n+            correlatedValueSet.add(correlatedColumnReader.read(i).toString());\n+          }\n+        }\n+\n+        return new ArrayList<>(correlatedValueSet);\n+      }\n+    }\n+\n+    return null;\n+  }\n+\n+  /**\n+   * For all RHS columns that appear in the join's equiconditions, correlate them with base table columns if possible.\n+   *\n+   * @param adapter              The adapter for the join. Used to determine if a column is a base table column.\n+   * @param tablePrefix          Prefix for a join table\n+   * @param clauseForTablePrefix Joinable clause for the prefix\n+   * @param equiconditions       Map of equiconditions, keyed by the right hand columns\n+   *\n+   * @return A list of correlatation analyses for the equicondition RHS columns that reside in the table associated with\n+   * the tablePrefix\n+   */\n+  @Nullable\n+  private static List<JoinFilterColumnCorrelationAnalysis> findCorrelatedBaseTableColumns(\n+      HashJoinSegmentStorageAdapter adapter,\n+      String tablePrefix,\n+      JoinableClause clauseForTablePrefix,\n+      Map<String, Expr> equiconditions\n+  )\n+  {\n+    JoinConditionAnalysis jca = clauseForTablePrefix.getCondition();\n+\n+    List<String> rhsColumns = new ArrayList<>();\n+    for (Equality eq : jca.getEquiConditions()) {\n+      rhsColumns.add(tablePrefix + eq.getRightColumn());\n+    }\n+\n+    List<JoinFilterColumnCorrelationAnalysis> correlations = new ArrayList<>();\n+\n+    for (String rhsColumn : rhsColumns) {\n+      List<String> correlatedBaseColumns = new ArrayList<>();\n+      List<Expr> correlatedBaseExpressions = new ArrayList<>();\n+      boolean terminate = false;\n+\n+      String findMappingFor = rhsColumn;\n+      while (!terminate) {\n+        Expr lhs = equiconditions.get(findMappingFor);\n+        if (lhs == null) {\n+          break;\n+        }\n+        String identifier = lhs.getBindingIfIdentifier();\n+        if (identifier == null) {\n+          // We push down if the function only requires base table columns\n+          Expr.BindingDetails bindingDetails = lhs.analyzeInputs();\n+          Set<String> requiredBindings = bindingDetails.getRequiredBindings();\n+          for (String requiredBinding : requiredBindings) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b31fbddcd678b5f9faf705a2def1864072188929"}, "originalPosition": 560}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNjU0Mg==", "bodyText": "What case is this meant to handle? I don't understand why we'd need to switch findMappingFor from a rhs column to a lhs column.", "url": "https://github.com/apache/druid/pull/9301#discussion_r375026542", "createdAt": "2020-02-05T02:11:33Z", "author": {"login": "gianm"}, "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          (SelectorFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteOrFilter(\n+      HashJoinSegmentStorageAdapter adapter,\n+      OrFilter orFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    boolean retainRhs = false;\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    for (Filter filter : orFilter.getFilters()) {\n+      boolean allBaseColumns = true;\n+      for (String requiredColumn : filter.getRequiredColumns()) {\n+        if (!adapter.isBaseColumn(requiredColumn)) {\n+          allBaseColumns = false;\n+        }\n+      }\n+\n+      if (!allBaseColumns) {\n+        retainRhs = true;\n+        if (filter instanceof SelectorFilter) {\n+          JoinFilterAnalysis rewritten = rewriteSelectorFilter(\n+              adapter,\n+              (SelectorFilter) filter,\n+              prefixes,\n+              equiconditions,\n+              correlationCache\n+          );\n+          if (!rewritten.isCanPushDown()) {\n+            return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+          } else {\n+            newFilters.add(rewritten.getPushdownFilter());\n+          }\n+        } else {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+        }\n+      } else {\n+        newFilters.add(filter);\n+      }\n+    }\n+\n+    return new JoinFilterAnalysis(\n+        true,\n+        retainRhs,\n+        orFilter,\n+        new OrFilter(newFilters),\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Rewrites a selector filter on a join table into an IN filter on the base table.\n+   *\n+   * @param baseAdapter      The adapter for the join\n+   * @param selectorFilter   SelectorFilter to be rewritten\n+   * @param prefixes         Map of join table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteSelectorFilter(\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      SelectorFilter selectorFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    String filteringColumn = selectorFilter.getDimension();\n+    for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n+      if (filteringColumn.startsWith(prefixAndClause.getKey())) {\n+        List<JoinFilterColumnCorrelationAnalysis> correlations = correlationCache.computeIfAbsent(\n+            prefixAndClause.getKey(),\n+            p -> findCorrelatedBaseTableColumns(\n+                baseAdapter,\n+                p,\n+                prefixes.get(p),\n+                equiconditions\n+            )\n+        );\n+\n+        if (correlations == null) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        List<Filter> newFilters = new ArrayList<>();\n+        List<VirtualColumn> pushdownVirtualColumns = new ArrayList<>();\n+\n+        for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlations) {\n+          if (correlationAnalysis.supportsPushDown()) {\n+            List<String> correlatedValues = getCorrelatedValuesForPushDown(\n+                selectorFilter.getDimension(),\n+                selectorFilter.getValue(),\n+                correlationAnalysis.getJoinColumn(),\n+                prefixAndClause.getValue()\n+            );\n+\n+            if (correlatedValues == null) {\n+              return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+            }\n+\n+            for (String correlatedBaseColumn : correlationAnalysis.getBaseColumns()) {\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  correlatedBaseColumn,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+\n+            for (Expr correlatedBaseExpr : correlationAnalysis.getBaseExpressions()) {\n+              // need to create a virtual column for the expressions when pushing down\n+              String vcName = getCorrelatedBaseExprVirtualColumnName(pushdownVirtualColumns.size());\n+\n+              VirtualColumn correlatedBaseExprVirtualColumn = new ExpressionVirtualColumn(\n+                  vcName,\n+                  correlatedBaseExpr,\n+                  ValueType.STRING\n+              );\n+              pushdownVirtualColumns.add(correlatedBaseExprVirtualColumn);\n+\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(\n+                  vcName,\n+                  correlatedValues,\n+                  null,\n+                  null\n+              ).toFilter();\n+              newFilters.add(rewrittenFilter);\n+            }\n+          }\n+        }\n+\n+        if (newFilters.isEmpty()) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        return new JoinFilterAnalysis(\n+            true,\n+            true,\n+            selectorFilter,\n+            newFilters.size() == 1 ? newFilters.get(0) : new AndFilter(newFilters),\n+            pushdownVirtualColumns\n+        );\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        selectorFilter,\n+        selectorFilter,\n+        null\n+    );\n+  }\n+\n+  private static String getCorrelatedBaseExprVirtualColumnName(int counter)\n+  {\n+    // May want to have this check other column names to absolutely prevent name conflicts\n+    return PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE + counter;\n+  }\n+\n+  /**\n+   * Helper method for rewriting filters on join table columns into filters on base table columns.\n+   *\n+   * @param filterColumn           A join table column that we're filtering on\n+   * @param filterValue            The value to filter on\n+   * @param correlatedJoinColumn   A join table column that appears as the RHS of an equicondition, which we can correlate\n+   *                               with a column on the base table\n+   * @param clauseForFilteredTable The joinable clause that corresponds to the join table being filtered on\n+   *\n+   * @return A list of values of the correlatedJoinColumn that appear in rows where filterColumn = filterValue\n+   * Returns null if we cannot determine the correlated values.\n+   */\n+  @Nullable\n+  private static List<String> getCorrelatedValuesForPushDown(\n+      String filterColumn,\n+      String filterValue,\n+      String correlatedJoinColumn,\n+      JoinableClause clauseForFilteredTable\n+  )\n+  {\n+    String filterColumnNoPrefix = filterColumn.substring(clauseForFilteredTable.getPrefix().length());\n+    String correlatedColumnNoPrefix = correlatedJoinColumn.substring(clauseForFilteredTable.getPrefix().length());\n+\n+    // would be good to allow non-key column indices on the Joinables for better perf\n+    if (clauseForFilteredTable.getJoinable() instanceof LookupJoinable) {\n+      LookupJoinable lookupJoinable = (LookupJoinable) clauseForFilteredTable.getJoinable();\n+      List<String> correlatedValues;\n+      if (LookupColumnSelectorFactory.KEY_COLUMN.equals(filterColumnNoPrefix)) {\n+        if (LookupColumnSelectorFactory.KEY_COLUMN.equals(correlatedColumnNoPrefix)) {\n+          correlatedValues = ImmutableList.of(filterValue);\n+        } else {\n+          correlatedValues = ImmutableList.of(lookupJoinable.getExtractor().apply(filterColumnNoPrefix));\n+        }\n+      } else {\n+        if (LookupColumnSelectorFactory.VALUE_COLUMN.equals(correlatedColumnNoPrefix)) {\n+          correlatedValues = ImmutableList.of(filterValue);\n+        } else {\n+          correlatedValues = lookupJoinable.getExtractor().unapply(filterValue);\n+        }\n+      }\n+      return correlatedValues;\n+    }\n+\n+    if (clauseForFilteredTable.getJoinable() instanceof IndexedTableJoinable) {\n+      IndexedTableJoinable indexedTableJoinable = (IndexedTableJoinable) clauseForFilteredTable.getJoinable();\n+      IndexedTable indexedTable = indexedTableJoinable.getTable();\n+\n+      int filterColumnPosition = indexedTable.allColumns().indexOf(filterColumnNoPrefix);\n+      int correlatedColumnPosition = indexedTable.allColumns().indexOf(correlatedColumnNoPrefix);\n+\n+      if (filterColumnPosition < 0 || correlatedColumnPosition < 0) {\n+        return null;\n+      }\n+\n+      if (indexedTable.keyColumns().contains(filterColumnNoPrefix)) {\n+        IndexedTable.Index index = indexedTable.columnIndex(filterColumnPosition);\n+        IndexedTable.Reader reader = indexedTable.columnReader(correlatedColumnPosition);\n+        IntList rowIndex = index.find(filterValue);\n+        List<String> correlatedValues = new ArrayList<>();\n+        for (int i = 0; i < rowIndex.size(); i++) {\n+          int rowNum = rowIndex.getInt(i);\n+          correlatedValues.add(reader.read(rowNum).toString());\n+        }\n+        return correlatedValues;\n+      } else {\n+        IndexedTable.Reader dimNameReader = indexedTable.columnReader(filterColumnPosition);\n+        IndexedTable.Reader correlatedColumnReader = indexedTable.columnReader(correlatedColumnPosition);\n+        Set<String> correlatedValueSet = new HashSet<>();\n+        for (int i = 0; i < indexedTable.numRows(); i++) {\n+          if (filterValue.equals(dimNameReader.read(i).toString())) {\n+            correlatedValueSet.add(correlatedColumnReader.read(i).toString());\n+          }\n+        }\n+\n+        return new ArrayList<>(correlatedValueSet);\n+      }\n+    }\n+\n+    return null;\n+  }\n+\n+  /**\n+   * For all RHS columns that appear in the join's equiconditions, correlate them with base table columns if possible.\n+   *\n+   * @param adapter              The adapter for the join. Used to determine if a column is a base table column.\n+   * @param tablePrefix          Prefix for a join table\n+   * @param clauseForTablePrefix Joinable clause for the prefix\n+   * @param equiconditions       Map of equiconditions, keyed by the right hand columns\n+   *\n+   * @return A list of correlatation analyses for the equicondition RHS columns that reside in the table associated with\n+   * the tablePrefix\n+   */\n+  @Nullable\n+  private static List<JoinFilterColumnCorrelationAnalysis> findCorrelatedBaseTableColumns(\n+      HashJoinSegmentStorageAdapter adapter,\n+      String tablePrefix,\n+      JoinableClause clauseForTablePrefix,\n+      Map<String, Expr> equiconditions\n+  )\n+  {\n+    JoinConditionAnalysis jca = clauseForTablePrefix.getCondition();\n+\n+    List<String> rhsColumns = new ArrayList<>();\n+    for (Equality eq : jca.getEquiConditions()) {\n+      rhsColumns.add(tablePrefix + eq.getRightColumn());\n+    }\n+\n+    List<JoinFilterColumnCorrelationAnalysis> correlations = new ArrayList<>();\n+\n+    for (String rhsColumn : rhsColumns) {\n+      List<String> correlatedBaseColumns = new ArrayList<>();\n+      List<Expr> correlatedBaseExpressions = new ArrayList<>();\n+      boolean terminate = false;\n+\n+      String findMappingFor = rhsColumn;\n+      while (!terminate) {\n+        Expr lhs = equiconditions.get(findMappingFor);\n+        if (lhs == null) {\n+          break;\n+        }\n+        String identifier = lhs.getBindingIfIdentifier();\n+        if (identifier == null) {\n+          // We push down if the function only requires base table columns\n+          Expr.BindingDetails bindingDetails = lhs.analyzeInputs();\n+          Set<String> requiredBindings = bindingDetails.getRequiredBindings();\n+          for (String requiredBinding : requiredBindings) {\n+            if (!adapter.isBaseColumn(requiredBinding)) {\n+              return null;\n+            }\n+          }\n+\n+          terminate = true;\n+          correlatedBaseExpressions.add(lhs);\n+        } else {\n+          // simple identifier, see if we can correlate it with a column on the base table\n+          findMappingFor = identifier;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b31fbddcd678b5f9faf705a2def1864072188929"}, "originalPosition": 570}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyNzkyMg==", "bodyText": "When would there be more than one base column?", "url": "https://github.com/apache/druid/pull/9301#discussion_r375027922", "createdAt": "2020-02-05T02:17:39Z", "author": {"login": "gianm"}, "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          (SelectorFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteOrFilter(\n+      HashJoinSegmentStorageAdapter adapter,\n+      OrFilter orFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    boolean retainRhs = false;\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    for (Filter filter : orFilter.getFilters()) {\n+      boolean allBaseColumns = true;\n+      for (String requiredColumn : filter.getRequiredColumns()) {\n+        if (!adapter.isBaseColumn(requiredColumn)) {\n+          allBaseColumns = false;\n+        }\n+      }\n+\n+      if (!allBaseColumns) {\n+        retainRhs = true;\n+        if (filter instanceof SelectorFilter) {\n+          JoinFilterAnalysis rewritten = rewriteSelectorFilter(\n+              adapter,\n+              (SelectorFilter) filter,\n+              prefixes,\n+              equiconditions,\n+              correlationCache\n+          );\n+          if (!rewritten.isCanPushDown()) {\n+            return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+          } else {\n+            newFilters.add(rewritten.getPushdownFilter());\n+          }\n+        } else {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+        }\n+      } else {\n+        newFilters.add(filter);\n+      }\n+    }\n+\n+    return new JoinFilterAnalysis(\n+        true,\n+        retainRhs,\n+        orFilter,\n+        new OrFilter(newFilters),\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Rewrites a selector filter on a join table into an IN filter on the base table.\n+   *\n+   * @param baseAdapter      The adapter for the join\n+   * @param selectorFilter   SelectorFilter to be rewritten\n+   * @param prefixes         Map of join table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteSelectorFilter(\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      SelectorFilter selectorFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    String filteringColumn = selectorFilter.getDimension();\n+    for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n+      if (filteringColumn.startsWith(prefixAndClause.getKey())) {\n+        List<JoinFilterColumnCorrelationAnalysis> correlations = correlationCache.computeIfAbsent(\n+            prefixAndClause.getKey(),\n+            p -> findCorrelatedBaseTableColumns(\n+                baseAdapter,\n+                p,\n+                prefixes.get(p),\n+                equiconditions\n+            )\n+        );\n+\n+        if (correlations == null) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        List<Filter> newFilters = new ArrayList<>();\n+        List<VirtualColumn> pushdownVirtualColumns = new ArrayList<>();\n+\n+        for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlations) {\n+          if (correlationAnalysis.supportsPushDown()) {\n+            List<String> correlatedValues = getCorrelatedValuesForPushDown(\n+                selectorFilter.getDimension(),\n+                selectorFilter.getValue(),\n+                correlationAnalysis.getJoinColumn(),\n+                prefixAndClause.getValue()\n+            );\n+\n+            if (correlatedValues == null) {\n+              return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+            }\n+\n+            for (String correlatedBaseColumn : correlationAnalysis.getBaseColumns()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b31fbddcd678b5f9faf705a2def1864072188929"}, "originalPosition": 375}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAyOTg1MQ==", "bodyText": "This code is nasty for the reason you mentioned in your comment. I don't think it'd be good to leave it like this, since it means any attempt to serialize this virtual column will yield something unusable, potentially leading to latent bugs.\nI'd almost consider not supporting pushdown of filters where the lhs is an expression until we have a way to actually convert parsed expressions to strings.\nAnother option:\n\nMake a single private constructor of ExpressionVirtualColumn that takes a nullable 'expression' and an optional pre-parsed expression.\nMake a @JsonCreator static factory method that Jackson will use.\nMake another static factory method that accepts a pre-parsed expression, and stores null for the 'expression'.\nMake getExpression() throw an exception if 'expression' is null. This means anyone trying to serialize it will realize what is going on before getting hit by latent bugs.\nMake sure to note in the javadoc of JoinFilterAnalysis that the virtual columns are not serializable.\n\nOpen to other ideas.", "url": "https://github.com/apache/druid/pull/9301#discussion_r375029851", "createdAt": "2020-02-05T02:25:57Z", "author": {"login": "gianm"}, "path": "processing/src/main/java/org/apache/druid/segment/virtual/ExpressionVirtualColumn.java", "diffHunk": "@@ -62,6 +64,23 @@ public ExpressionVirtualColumn(\n     this.parsedExpression = Suppliers.memoize(() -> Parser.parse(expression, macroTable));\n   }\n \n+  /**\n+   * Constructor for creating an ExpressionVirtualColumn from a pre-parsed expression.\n+   */\n+  public ExpressionVirtualColumn(\n+      String name,\n+      Expr parsedExpression,\n+      ValueType outputType\n+  )\n+  {\n+    this.name = Preconditions.checkNotNull(name, \"name\");\n+    // Unfortunately this string representation can't be reparsed into the same expression, might be useful\n+    // if the expression system supported that\n+    this.expression = parsedExpression.toString();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b31fbddcd678b5f9faf705a2def1864072188929"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTAzMDU5Mw==", "bodyText": "Is there a reason for this cast? Seems like we could let it go in to newFilters as an uncast Filter.", "url": "https://github.com/apache/druid/pull/9301#discussion_r375030593", "createdAt": "2020-02-05T02:29:19Z", "author": {"login": "gianm"}, "path": "processing/src/main/java/org/apache/druid/segment/join/JoinFilterAnalyzer.java", "diffHunk": "@@ -0,0 +1,743 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.ImmutableList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.math.expr.Expr;\n+import org.apache.druid.query.dimension.DimensionSpec;\n+import org.apache.druid.query.filter.Filter;\n+import org.apache.druid.query.filter.InDimFilter;\n+import org.apache.druid.query.filter.ValueMatcher;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.ColumnValueSelector;\n+import org.apache.druid.segment.DimensionSelector;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.VirtualColumn;\n+import org.apache.druid.segment.column.ColumnCapabilities;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.AndFilter;\n+import org.apache.druid.segment.filter.Filters;\n+import org.apache.druid.segment.filter.InFilter;\n+import org.apache.druid.segment.filter.OrFilter;\n+import org.apache.druid.segment.filter.SelectorFilter;\n+import org.apache.druid.segment.join.lookup.LookupColumnSelectorFactory;\n+import org.apache.druid.segment.join.lookup.LookupJoinable;\n+import org.apache.druid.segment.join.table.IndexedTable;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.virtual.ExpressionVirtualColumn;\n+\n+import javax.annotation.Nullable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+\n+public class JoinFilterAnalyzer\n+{\n+  private static final String PUSH_DOWN_VIRTUAL_COLUMN_NAME_BASE = \"JOIN-FILTER-PUSHDOWN-VIRTUAL-COLUMN-\";\n+  private static final ColumnSelectorFactory ALL_NULL_COLUMN_SELECTOR_FACTORY = new AllNullColumnSelectorFactory();\n+\n+  public static JoinFilterSplit splitFilter(\n+      HashJoinSegmentStorageAdapter hashJoinSegmentStorageAdapter,\n+      @Nullable Filter originalFilter\n+  )\n+  {\n+    if (originalFilter == null) {\n+      return new JoinFilterAnalyzer.JoinFilterSplit(\n+          null,\n+          null,\n+          ImmutableList.of()\n+      );\n+    }\n+\n+    Filter normalizedFilter = Filters.convertToCNF(originalFilter);\n+\n+    // build the prefix and equicondition maps\n+    Map<String, Expr> equiconditions = new HashMap<>();\n+    Map<String, JoinableClause> prefixes = new HashMap<>();\n+    for (JoinableClause clause : hashJoinSegmentStorageAdapter.getClauses()) {\n+      prefixes.put(clause.getPrefix(), clause);\n+      for (Equality equality : clause.getCondition().getEquiConditions()) {\n+        equiconditions.put(clause.getPrefix() + equality.getRightColumn(), equality.getLeftExpr());\n+      }\n+    }\n+\n+    // List of candidates for pushdown\n+    // CNF normalization will generate either\n+    // - an AND filter with multiple subfilters\n+    // - or a single non-AND subfilter which cannot be split further\n+    List<Filter> normalizedOrClauses;\n+    if (normalizedFilter instanceof AndFilter) {\n+      normalizedOrClauses = ((AndFilter) normalizedFilter).getFilters();\n+    } else {\n+      normalizedOrClauses = Collections.singletonList(normalizedFilter);\n+    }\n+\n+    // Pushdown filters, rewriting if necessary\n+    List<Filter> leftFilters = new ArrayList<>();\n+    List<Filter> rightFilters = new ArrayList<>();\n+    List<VirtualColumn> pushDownVirtualColumns = new ArrayList<>();\n+    Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache = new HashMap<>();\n+\n+    for (Filter orClause : normalizedOrClauses) {\n+      JoinFilterAnalysis joinFilterAnalysis = analyzeJoinFilterClause(\n+          hashJoinSegmentStorageAdapter,\n+          orClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+      if (joinFilterAnalysis.isCanPushDown()) {\n+        leftFilters.add(joinFilterAnalysis.getPushdownFilter());\n+        if (joinFilterAnalysis.getPushdownVirtualColumns() != null) {\n+          pushDownVirtualColumns.addAll(joinFilterAnalysis.getPushdownVirtualColumns());\n+        }\n+      }\n+      if (joinFilterAnalysis.isRetainAfterJoin()) {\n+        rightFilters.add(joinFilterAnalysis.getOriginalFilter());\n+      }\n+    }\n+\n+    return new JoinFilterSplit(\n+        leftFilters.isEmpty() ? null : leftFilters.size() == 1 ? leftFilters.get(0) : new AndFilter(leftFilters),\n+        rightFilters.isEmpty() ? null : rightFilters.size() == 1 ? rightFilters.get(0) : new AndFilter(rightFilters),\n+        pushDownVirtualColumns\n+    );\n+  }\n+\n+  /**\n+   * Holds the result of splitting a filter into:\n+   * - a portion that can be pushed down to the base table\n+   * - a portion that will be applied post-join\n+   * - additional virtual columns that need to be created on the base table to support the pushed down filters.\n+   */\n+  public static class JoinFilterSplit\n+  {\n+    final Filter baseTableFilter;\n+    final Filter joinTableFilter;\n+    final List<VirtualColumn> pushDownVirtualColumns;\n+\n+    public JoinFilterSplit(\n+        Filter baseTableFilter,\n+        @Nullable Filter joinTableFilter,\n+        List<VirtualColumn> pushDownVirtualColumns\n+    )\n+    {\n+      this.baseTableFilter = baseTableFilter;\n+      this.joinTableFilter = joinTableFilter;\n+      this.pushDownVirtualColumns = pushDownVirtualColumns;\n+    }\n+\n+    public Filter getBaseTableFilter()\n+    {\n+      return baseTableFilter;\n+    }\n+\n+    public Filter getJoinTableFilter()\n+    {\n+      return joinTableFilter;\n+    }\n+\n+    public List<VirtualColumn> getPushDownVirtualColumns()\n+    {\n+      return pushDownVirtualColumns;\n+    }\n+\n+    @Override\n+    public String toString()\n+    {\n+      return \"JoinFilterSplit{\" +\n+             \"baseTableFilter=\" + baseTableFilter +\n+             \", joinTableFilter=\" + joinTableFilter +\n+             \", pushDownVirtualColumns=\" + pushDownVirtualColumns +\n+             '}';\n+    }\n+\n+    @Override\n+    public boolean equals(Object o)\n+    {\n+      if (this == o) {\n+        return true;\n+      }\n+      if (o == null || getClass() != o.getClass()) {\n+        return false;\n+      }\n+      JoinFilterSplit that = (JoinFilterSplit) o;\n+      return Objects.equals(getBaseTableFilter(), that.getBaseTableFilter()) &&\n+             Objects.equals(getJoinTableFilter(), that.getJoinTableFilter()) &&\n+             Objects.equals(getPushDownVirtualColumns(), that.getPushDownVirtualColumns());\n+    }\n+\n+    @Override\n+    public int hashCode()\n+    {\n+      return Objects.hash(getBaseTableFilter(), getJoinTableFilter(), getPushDownVirtualColumns());\n+    }\n+  }\n+\n+  /**\n+   * Analyze a single filter clause from a filter that is in conjunctive normal form (AND of ORs),\n+   * returning a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param filterClause     Individual filter clause from a filter that is in CNF\n+   * @param prefixes         Map of table prefixes\n+   * @param equiconditions   Equicondition map\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return a JoinFilterAnalysis that contains a possible filter rewrite and information on how to handle the filter.\n+   */\n+  private static JoinFilterAnalysis analyzeJoinFilterClause(\n+      HashJoinSegmentStorageAdapter adapter,\n+      Filter filterClause,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    // NULL matching conditions are not currently pushed down\n+    if (filterMatchesNull(filterClause)) {\n+      return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+    }\n+\n+    // Currently we only support rewrites of selector filters and selector filters within OR filters.\n+    if (filterClause instanceof SelectorFilter) {\n+      return rewriteSelectorFilter(\n+          adapter,\n+          (SelectorFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    if (filterClause instanceof OrFilter) {\n+      return rewriteOrFilter(\n+          adapter,\n+          (OrFilter) filterClause,\n+          prefixes,\n+          equiconditions,\n+          correlationCache\n+      );\n+    }\n+\n+    for (String requiredColumn : filterClause.getRequiredColumns()) {\n+      if (!adapter.isBaseColumn(requiredColumn)) {\n+        return JoinFilterAnalysis.createNoPushdownFilterAnalysis(filterClause);\n+      }\n+    }\n+    return new JoinFilterAnalysis(\n+        true,\n+        false,\n+        filterClause,\n+        filterClause,\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Potentially rewrite the subfilters of an OR filter so that the whole OR filter can be pushed down to\n+   * the base table.\n+   *\n+   * @param adapter          Adapter for the join\n+   * @param orFilter         OrFilter to be rewritten\n+   * @param prefixes         Map of table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Column correlation analysis cache\n+   *\n+   * @return A JoinFilterAnalysis indicating how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteOrFilter(\n+      HashJoinSegmentStorageAdapter adapter,\n+      OrFilter orFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    boolean retainRhs = false;\n+\n+    List<Filter> newFilters = new ArrayList<>();\n+    for (Filter filter : orFilter.getFilters()) {\n+      boolean allBaseColumns = true;\n+      for (String requiredColumn : filter.getRequiredColumns()) {\n+        if (!adapter.isBaseColumn(requiredColumn)) {\n+          allBaseColumns = false;\n+        }\n+      }\n+\n+      if (!allBaseColumns) {\n+        retainRhs = true;\n+        if (filter instanceof SelectorFilter) {\n+          JoinFilterAnalysis rewritten = rewriteSelectorFilter(\n+              adapter,\n+              (SelectorFilter) filter,\n+              prefixes,\n+              equiconditions,\n+              correlationCache\n+          );\n+          if (!rewritten.isCanPushDown()) {\n+            return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+          } else {\n+            newFilters.add(rewritten.getPushdownFilter());\n+          }\n+        } else {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(orFilter);\n+        }\n+      } else {\n+        newFilters.add(filter);\n+      }\n+    }\n+\n+    return new JoinFilterAnalysis(\n+        true,\n+        retainRhs,\n+        orFilter,\n+        new OrFilter(newFilters),\n+        null\n+    );\n+  }\n+\n+  /**\n+   * Rewrites a selector filter on a join table into an IN filter on the base table.\n+   *\n+   * @param baseAdapter      The adapter for the join\n+   * @param selectorFilter   SelectorFilter to be rewritten\n+   * @param prefixes         Map of join table prefixes to clauses\n+   * @param equiconditions   Map of equiconditions\n+   * @param correlationCache Cache of column correlation analyses\n+   *\n+   * @return A JoinFilterAnalysis that indicates how to handle the potentially rewritten filter\n+   */\n+  private static JoinFilterAnalysis rewriteSelectorFilter(\n+      HashJoinSegmentStorageAdapter baseAdapter,\n+      SelectorFilter selectorFilter,\n+      Map<String, JoinableClause> prefixes,\n+      Map<String, Expr> equiconditions,\n+      Map<String, List<JoinFilterColumnCorrelationAnalysis>> correlationCache\n+  )\n+  {\n+    String filteringColumn = selectorFilter.getDimension();\n+    for (Map.Entry<String, JoinableClause> prefixAndClause : prefixes.entrySet()) {\n+      if (filteringColumn.startsWith(prefixAndClause.getKey())) {\n+        List<JoinFilterColumnCorrelationAnalysis> correlations = correlationCache.computeIfAbsent(\n+            prefixAndClause.getKey(),\n+            p -> findCorrelatedBaseTableColumns(\n+                baseAdapter,\n+                p,\n+                prefixes.get(p),\n+                equiconditions\n+            )\n+        );\n+\n+        if (correlations == null) {\n+          return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+        }\n+\n+        List<Filter> newFilters = new ArrayList<>();\n+        List<VirtualColumn> pushdownVirtualColumns = new ArrayList<>();\n+\n+        for (JoinFilterColumnCorrelationAnalysis correlationAnalysis : correlations) {\n+          if (correlationAnalysis.supportsPushDown()) {\n+            List<String> correlatedValues = getCorrelatedValuesForPushDown(\n+                selectorFilter.getDimension(),\n+                selectorFilter.getValue(),\n+                correlationAnalysis.getJoinColumn(),\n+                prefixAndClause.getValue()\n+            );\n+\n+            if (correlatedValues == null) {\n+              return JoinFilterAnalysis.createNoPushdownFilterAnalysis(selectorFilter);\n+            }\n+\n+            for (String correlatedBaseColumn : correlationAnalysis.getBaseColumns()) {\n+              InFilter rewrittenFilter = (InFilter) new InDimFilter(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b31fbddcd678b5f9faf705a2def1864072188929"}, "originalPosition": 376}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0de4d0f4019ae7aeed5180281722fee9b9ef8c27", "author": {"user": {"login": "jon-wei", "name": "Jonathan Wei"}}, "url": "https://github.com/apache/druid/commit/0de4d0f4019ae7aeed5180281722fee9b9ef8c27", "committedDate": "2020-02-06T01:39:32Z", "message": "Merge remote-tracking branch 'upstream/master' into join_filter_pushdowns2"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d3e603321d5a8239ddb9addd5396c5c94e8b8893", "author": {"user": {"login": "jon-wei", "name": "Jonathan Wei"}}, "url": "https://github.com/apache/druid/commit/d3e603321d5a8239ddb9addd5396c5c94e8b8893", "committedDate": "2020-02-06T06:42:32Z", "message": "Address some PR comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "194a1ef09a7ac70f26159eff40581a3184a4926d", "author": {"user": {"login": "jon-wei", "name": "Jonathan Wei"}}, "url": "https://github.com/apache/druid/commit/194a1ef09a7ac70f26159eff40581a3184a4926d", "committedDate": "2020-02-06T08:22:06Z", "message": "Address more PR comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dcbbcb09b8d8e98f37d237cdd6f5b028d9718433", "author": {"user": {"login": "jon-wei", "name": "Jonathan Wei"}}, "url": "https://github.com/apache/druid/commit/dcbbcb09b8d8e98f37d237cdd6f5b028d9718433", "committedDate": "2020-02-06T22:56:51Z", "message": "Fix TC failures and address PR comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU1NTA4MjM2", "url": "https://github.com/apache/druid/pull/9301#pullrequestreview-355508236", "createdAt": "2020-02-08T00:23:27Z", "commit": {"oid": "dcbbcb09b8d8e98f37d237cdd6f5b028d9718433"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2823, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}