{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzcwNTM0Mjc1", "number": 9306, "title": "implement Azure InputSource reader and deprecate Azure FireHose", "bodyText": "Description\nThis change implements the inputSource reader for druid, which is used for native batch ingestion. This implementation follows those for S3 and GoogleCloud.\n\nThis PR has:\n\n been self-reviewed.\n\n using the concurrency checklist (Remove this item if the PR doesn't have any relation to concurrency.)\n\n\n added documentation for new or modified features or behaviors.\n added Javadocs for most classes and all non-trivial methods. Linked related entities via Javadoc links.\n added or updated version, license, or notice information in licenses.yaml\n added comments explaining the \"why\" and the intent of the code wherever would not be obvious for an unfamiliar reader.\n added unit tests or modified existing tests to cover new code paths.\n added integration tests.\n been tested in a test Druid cluster.", "createdAt": "2020-02-03T21:35:35Z", "url": "https://github.com/apache/druid/pull/9306", "merged": true, "mergeCommit": {"oid": "5c202343c96e59694808b7c232d85c72704b9926"}, "closed": true, "closedAt": "2020-02-12T01:41:59Z", "author": {"login": "zachjsh"}, "timelineItems": {"totalCount": 32, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABb-TtdYgH2gAyMzcwNTM0Mjc1OjA5MTM3Njg4NTY4N2Y4NzRmNjA2NzY3Mjg5NzliZTcwYzBlNTI0ZGY=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcDcPI8AFqTM1NzEzOTI5MA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "091376885687f874f60676728979be70c0e524df", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/091376885687f874f60676728979be70c0e524df", "committedDate": "2020-01-27T02:56:05Z", "message": "IMPLY-1946: Improve code quality and unit test coverage of the Azure extension\n\n* Update unit tests to increase test coverage for the extension\n* Clean up any messy code\n* Enfore code coverage as part of tests."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5b9e4c3b216e37a0292a278072283abdb425030f", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/5b9e4c3b216e37a0292a278072283abdb425030f", "committedDate": "2020-01-27T19:50:09Z", "message": "Merge remote-tracking branch 'origin/master' into IMPLY-1946"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c845f68a0b4fa5b0e90f527b13bf6525660ed353", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/c845f68a0b4fa5b0e90f527b13bf6525660ed353", "committedDate": "2020-01-27T21:10:56Z", "message": "* Update azure extension pom to remove unnecessary things\n* update jacoco thresholds"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "85aa0a004dd6d544de111c980f1f3507cd7ac429", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/85aa0a004dd6d544de111c980f1f3507cd7ac429", "committedDate": "2020-01-27T22:33:24Z", "message": "* updgrade version of azure-storage library version uses to\n  most upto-date version"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "85293294d93e4bd7f08efa207e873c49de97d135", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/85293294d93e4bd7f08efa207e873c49de97d135", "committedDate": "2020-01-28T00:08:57Z", "message": "Merge remote-tracking branch 'origin/master' into IMPLY-1946"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9e7ab6f7bb1e027066e9db39751efc765efb9987", "author": {"user": {"login": "zachjsh", "name": null}}, "url": "https://github.com/apache/druid/commit/9e7ab6f7bb1e027066e9db39751efc765efb9987", "committedDate": "2020-01-28T00:42:19Z", "message": "Merge pull request #1 from zachjsh/IMPLY-1946-2\n\nImply 1946 2"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a97ad656925ced089972e5b9fd13343e6b7b7d84", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/a97ad656925ced089972e5b9fd13343e6b7b7d84", "committedDate": "2020-01-28T19:18:09Z", "message": "implement Azure InputSource reader and deprecate Azure FireHose\n\n* implement azure InputSource reader\n* deprecate Azure FireHose implementation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c5103fb69db63e058b68edfc52dddc33509101d4", "author": {"user": {"login": "zachjsh", "name": null}}, "url": "https://github.com/apache/druid/commit/c5103fb69db63e058b68edfc52dddc33509101d4", "committedDate": "2020-01-28T23:36:02Z", "message": "* exclude common libraries that are included from druid core"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "76c76b33b914658f0edead0deb2f8feb77e19aa6", "author": {"user": {"login": "zachjsh", "name": null}}, "url": "https://github.com/apache/druid/commit/76c76b33b914658f0edead0deb2f8feb77e19aa6", "committedDate": "2020-01-28T23:39:53Z", "message": "Merge remote-tracking branch 'zach-druid/IMPLY-1946' into IMPLY-1955"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b57e1733681b99417d5b430fe95400f1461b1e8a", "author": {"user": {"login": "zachjsh", "name": null}}, "url": "https://github.com/apache/druid/commit/b57e1733681b99417d5b430fe95400f1461b1e8a", "committedDate": "2020-01-31T00:53:41Z", "message": "Implement more of Azure input source."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3639d056d6159fe2b17c49cc805ba4415ba476a8", "author": {"user": {"login": "zachjsh", "name": null}}, "url": "https://github.com/apache/druid/commit/3639d056d6159fe2b17c49cc805ba4415ba476a8", "committedDate": "2020-01-31T19:33:41Z", "message": "* Add tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8f71ac208dae835ca1be927f2031c705f0eb2fc2", "author": {"user": {"login": "zachjsh", "name": null}}, "url": "https://github.com/apache/druid/commit/8f71ac208dae835ca1be927f2031c705f0eb2fc2", "committedDate": "2020-02-03T18:05:06Z", "message": "* Add more tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ae2e75008144a2b7189a002fbb534ebad1f90e94", "author": {"user": {"login": "zachjsh", "name": null}}, "url": "https://github.com/apache/druid/commit/ae2e75008144a2b7189a002fbb534ebad1f90e94", "committedDate": "2020-02-03T18:31:08Z", "message": "Merge remote-tracking branch 'apache/master' into IMPLY-1955"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "03f53aff53f9a2f1c82e72c28eb1e5df34a0da96", "author": {"user": {"login": "zachjsh", "name": null}}, "url": "https://github.com/apache/druid/commit/03f53aff53f9a2f1c82e72c28eb1e5df34a0da96", "committedDate": "2020-02-03T18:34:07Z", "message": "* deprecate azure firehose"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6dd498ea5575fb96813ae1814f2d5de2ff00affa", "author": {"user": {"login": "zachjsh", "name": null}}, "url": "https://github.com/apache/druid/commit/6dd498ea5575fb96813ae1814f2d5de2ff00affa", "committedDate": "2020-02-03T21:31:04Z", "message": "* added more tests"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUyNjE0NDcy", "url": "https://github.com/apache/druid/pull/9306#pullrequestreview-352614472", "createdAt": "2020-02-03T22:39:28Z", "commit": {"oid": "6dd498ea5575fb96813ae1814f2d5de2ff00affa"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QyMjozOToyOVrOFlCfJQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QyMjozOToyOVrOFlCfJQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDM4MjM3Mw==", "bodyText": "I don't think it's good to have the base class decide the max length for all the implementations. It would be better to expose this through a function. Should this be made configurable?\nI see the GoogleCloudStorageInputSource used to have a max of 10. This makes it 1024. Also the AzureInputSource uses it's own definition for MAX_LISTING_LENGTH", "url": "https://github.com/apache/druid/pull/9306#discussion_r374382373", "createdAt": "2020-02-03T22:39:29Z", "author": {"login": "suneet-s"}, "path": "core/src/main/java/org/apache/druid/data/input/impl/CloudObjectInputSource.java", "diffHunk": "@@ -40,6 +40,7 @@\n public abstract class CloudObjectInputSource<T extends InputEntity> extends AbstractInputSource\n     implements SplittableInputSource<CloudObjectLocation>\n {\n+  protected static final int MAX_LISTING_LENGTH = 1024;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6dd498ea5575fb96813ae1814f2d5de2ff00affa"}, "originalPosition": 4}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUyNjE1Njk4", "url": "https://github.com/apache/druid/pull/9306#pullrequestreview-352615698", "createdAt": "2020-02-03T22:42:01Z", "commit": {"oid": "6dd498ea5575fb96813ae1814f2d5de2ff00affa"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QyMjo0MjowMlrOFlCjMw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QyMjo0MzozNVrOFlClqQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDM4MzQxMQ==", "bodyText": "\ud83e\udd18", "url": "https://github.com/apache/druid/pull/9306#discussion_r374383411", "createdAt": "2020-02-03T22:42:02Z", "author": {"login": "suneet-s"}, "path": "extensions-contrib/azure-extensions/pom.xml", "diffHunk": "@@ -91,6 +91,11 @@\n             <artifactId>guice</artifactId>\n             <scope>provided</scope>\n         </dependency>\n+        <dependency>\n+            <groupId>com.google.inject.extensions</groupId>\n+            <artifactId>guice-assistedinject</artifactId>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6dd498ea5575fb96813ae1814f2d5de2ff00affa"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDM4NDA0MQ==", "bodyText": "javadocs please", "url": "https://github.com/apache/druid/pull/9306#discussion_r374384041", "createdAt": "2020-02-03T22:43:35Z", "author": {"login": "suneet-s"}, "path": "extensions-contrib/azure-extensions/src/main/java/org/apache/druid/data/input/azure/AzureEntity.java", "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.data.input.azure;\n+\n+import com.google.common.base.Predicate;\n+import com.google.inject.assistedinject.Assisted;\n+import com.google.inject.assistedinject.AssistedInject;\n+import org.apache.druid.data.input.RetryingInputEntity;\n+import org.apache.druid.data.input.impl.CloudObjectLocation;\n+import org.apache.druid.java.util.common.logger.Logger;\n+import org.apache.druid.storage.azure.AzureByteSource;\n+import org.apache.druid.storage.azure.AzureByteSourceFactory;\n+import org.apache.druid.storage.azure.AzureStorage;\n+import org.apache.druid.storage.azure.AzureUtils;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.net.URI;\n+\n+public class AzureEntity extends RetryingInputEntity", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6dd498ea5575fb96813ae1814f2d5de2ff00affa"}, "originalPosition": 38}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUyNjE4MDEy", "url": "https://github.com/apache/druid/pull/9306#pullrequestreview-352618012", "createdAt": "2020-02-03T22:46:53Z", "commit": {"oid": "6dd498ea5575fb96813ae1814f2d5de2ff00affa"}, "state": "COMMENTED", "comments": {"totalCount": 18, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QyMjo0Njo1M1rOFlCqiQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QyMzo1MDozMVrOFlD-JQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDM4NTI4OQ==", "bodyText": "private static final Logger LOG = new Logger(AzureEntity.class);", "url": "https://github.com/apache/druid/pull/9306#discussion_r374385289", "createdAt": "2020-02-03T22:46:53Z", "author": {"login": "suneet-s"}, "path": "extensions-contrib/azure-extensions/src/main/java/org/apache/druid/data/input/azure/AzureEntity.java", "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.data.input.azure;\n+\n+import com.google.common.base.Predicate;\n+import com.google.inject.assistedinject.Assisted;\n+import com.google.inject.assistedinject.AssistedInject;\n+import org.apache.druid.data.input.RetryingInputEntity;\n+import org.apache.druid.data.input.impl.CloudObjectLocation;\n+import org.apache.druid.java.util.common.logger.Logger;\n+import org.apache.druid.storage.azure.AzureByteSource;\n+import org.apache.druid.storage.azure.AzureByteSourceFactory;\n+import org.apache.druid.storage.azure.AzureStorage;\n+import org.apache.druid.storage.azure.AzureUtils;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.net.URI;\n+\n+public class AzureEntity extends RetryingInputEntity\n+{\n+  private final Logger log = new Logger(AzureEntity.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6dd498ea5575fb96813ae1814f2d5de2ff00affa"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDM4NjI4Mw==", "bodyText": "Add @NotNull or is EverythingNotNullByDefault in this package? I didn't see that annotation used in this package", "url": "https://github.com/apache/druid/pull/9306#discussion_r374386283", "createdAt": "2020-02-03T22:49:33Z", "author": {"login": "suneet-s"}, "path": "extensions-contrib/azure-extensions/src/main/java/org/apache/druid/data/input/azure/AzureEntity.java", "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.data.input.azure;\n+\n+import com.google.common.base.Predicate;\n+import com.google.inject.assistedinject.Assisted;\n+import com.google.inject.assistedinject.AssistedInject;\n+import org.apache.druid.data.input.RetryingInputEntity;\n+import org.apache.druid.data.input.impl.CloudObjectLocation;\n+import org.apache.druid.java.util.common.logger.Logger;\n+import org.apache.druid.storage.azure.AzureByteSource;\n+import org.apache.druid.storage.azure.AzureByteSourceFactory;\n+import org.apache.druid.storage.azure.AzureStorage;\n+import org.apache.druid.storage.azure.AzureUtils;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.net.URI;\n+\n+public class AzureEntity extends RetryingInputEntity\n+{\n+  private final Logger log = new Logger(AzureEntity.class);\n+  private final CloudObjectLocation location;\n+  private final AzureByteSource byteSource;\n+\n+  @AssistedInject\n+  AzureEntity(\n+      AzureStorage storage,\n+      @Assisted CloudObjectLocation location,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6dd498ea5575fb96813ae1814f2d5de2ff00affa"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDM4NjMzMg==", "bodyText": "storage isn't used", "url": "https://github.com/apache/druid/pull/9306#discussion_r374386332", "createdAt": "2020-02-03T22:49:42Z", "author": {"login": "suneet-s"}, "path": "extensions-contrib/azure-extensions/src/main/java/org/apache/druid/data/input/azure/AzureEntity.java", "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.data.input.azure;\n+\n+import com.google.common.base.Predicate;\n+import com.google.inject.assistedinject.Assisted;\n+import com.google.inject.assistedinject.AssistedInject;\n+import org.apache.druid.data.input.RetryingInputEntity;\n+import org.apache.druid.data.input.impl.CloudObjectLocation;\n+import org.apache.druid.java.util.common.logger.Logger;\n+import org.apache.druid.storage.azure.AzureByteSource;\n+import org.apache.druid.storage.azure.AzureByteSourceFactory;\n+import org.apache.druid.storage.azure.AzureStorage;\n+import org.apache.druid.storage.azure.AzureUtils;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.net.URI;\n+\n+public class AzureEntity extends RetryingInputEntity\n+{\n+  private final Logger log = new Logger(AzureEntity.class);\n+  private final CloudObjectLocation location;\n+  private final AzureByteSource byteSource;\n+\n+  @AssistedInject\n+  AzureEntity(\n+      AzureStorage storage,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6dd498ea5575fb96813ae1814f2d5de2ff00affa"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDM4NzIwNg==", "bodyText": "How can this ever return null? If location is null, this will throw an NPE, and it doesn't look like toUri ever returns a null", "url": "https://github.com/apache/druid/pull/9306#discussion_r374387206", "createdAt": "2020-02-03T22:51:57Z", "author": {"login": "suneet-s"}, "path": "extensions-contrib/azure-extensions/src/main/java/org/apache/druid/data/input/azure/AzureEntity.java", "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.data.input.azure;\n+\n+import com.google.common.base.Predicate;\n+import com.google.inject.assistedinject.Assisted;\n+import com.google.inject.assistedinject.AssistedInject;\n+import org.apache.druid.data.input.RetryingInputEntity;\n+import org.apache.druid.data.input.impl.CloudObjectLocation;\n+import org.apache.druid.java.util.common.logger.Logger;\n+import org.apache.druid.storage.azure.AzureByteSource;\n+import org.apache.druid.storage.azure.AzureByteSourceFactory;\n+import org.apache.druid.storage.azure.AzureStorage;\n+import org.apache.druid.storage.azure.AzureUtils;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.net.URI;\n+\n+public class AzureEntity extends RetryingInputEntity\n+{\n+  private final Logger log = new Logger(AzureEntity.class);\n+  private final CloudObjectLocation location;\n+  private final AzureByteSource byteSource;\n+\n+  @AssistedInject\n+  AzureEntity(\n+      AzureStorage storage,\n+      @Assisted CloudObjectLocation location,\n+      AzureByteSourceFactory byteSourceFactory\n+  )\n+  {\n+    this.location = location;\n+    this.byteSource = byteSourceFactory.create(location.getBucket(), location.getPath());\n+  }\n+\n+  @Nullable\n+  @Override\n+  public URI getUri()\n+  {\n+    return location.toUri(AzureInputSource.SCHEME);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6dd498ea5575fb96813ae1814f2d5de2ff00affa"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDM4NzYzMQ==", "bodyText": "javadocs please", "url": "https://github.com/apache/druid/pull/9306#discussion_r374387631", "createdAt": "2020-02-03T22:53:04Z", "author": {"login": "suneet-s"}, "path": "extensions-contrib/azure-extensions/src/main/java/org/apache/druid/data/input/azure/AzureEntityFactory.java", "diffHunk": "@@ -0,0 +1,27 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.data.input.azure;\n+\n+import org.apache.druid.data.input.impl.CloudObjectLocation;\n+\n+public interface AzureEntityFactory", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6dd498ea5575fb96813ae1814f2d5de2ff00affa"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDM4Nzk0Nw==", "bodyText": "@VisibleForTesting", "url": "https://github.com/apache/druid/pull/9306#discussion_r374387947", "createdAt": "2020-02-03T22:53:54Z", "author": {"login": "suneet-s"}, "path": "extensions-contrib/azure-extensions/src/main/java/org/apache/druid/data/input/azure/AzureInputSource.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.data.input.azure;\n+\n+import com.fasterxml.jackson.annotation.JacksonInject;\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.ImmutableList;\n+import org.apache.druid.data.input.InputSplit;\n+import org.apache.druid.data.input.impl.CloudObjectInputSource;\n+import org.apache.druid.data.input.impl.CloudObjectLocation;\n+import org.apache.druid.data.input.impl.SplittableInputSource;\n+import org.apache.druid.java.util.common.logger.Logger;\n+import org.apache.druid.storage.azure.AzureCloudBlobDruidToCloudObjectLocationConverter;\n+import org.apache.druid.storage.azure.AzureCloudBlobIterableFactory;\n+import org.apache.druid.storage.azure.AzureStorage;\n+import org.apache.druid.storage.azure.CloudBlobDruid;\n+\n+import javax.annotation.Nullable;\n+import java.net.URI;\n+import java.util.List;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+\n+public class AzureInputSource extends CloudObjectInputSource<AzureEntity>\n+{\n+  static final int MAX_LISTING_LENGTH = 1024;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6dd498ea5575fb96813ae1814f2d5de2ff00affa"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDM4ODU0NA==", "bodyText": "javadocs please - I'll stop asking for the rest of this review", "url": "https://github.com/apache/druid/pull/9306#discussion_r374388544", "createdAt": "2020-02-03T22:55:30Z", "author": {"login": "suneet-s"}, "path": "extensions-contrib/azure-extensions/src/main/java/org/apache/druid/data/input/azure/AzureInputSource.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.data.input.azure;\n+\n+import com.fasterxml.jackson.annotation.JacksonInject;\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.ImmutableList;\n+import org.apache.druid.data.input.InputSplit;\n+import org.apache.druid.data.input.impl.CloudObjectInputSource;\n+import org.apache.druid.data.input.impl.CloudObjectLocation;\n+import org.apache.druid.data.input.impl.SplittableInputSource;\n+import org.apache.druid.java.util.common.logger.Logger;\n+import org.apache.druid.storage.azure.AzureCloudBlobDruidToCloudObjectLocationConverter;\n+import org.apache.druid.storage.azure.AzureCloudBlobIterableFactory;\n+import org.apache.druid.storage.azure.AzureStorage;\n+import org.apache.druid.storage.azure.CloudBlobDruid;\n+\n+import javax.annotation.Nullable;\n+import java.net.URI;\n+import java.util.List;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+\n+public class AzureInputSource extends CloudObjectInputSource<AzureEntity>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6dd498ea5575fb96813ae1814f2d5de2ff00affa"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDM4ODcxOA==", "bodyText": "private static final - I'll stop making this comment for the rest of this review", "url": "https://github.com/apache/druid/pull/9306#discussion_r374388718", "createdAt": "2020-02-03T22:56:01Z", "author": {"login": "suneet-s"}, "path": "extensions-contrib/azure-extensions/src/main/java/org/apache/druid/data/input/azure/AzureInputSource.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.data.input.azure;\n+\n+import com.fasterxml.jackson.annotation.JacksonInject;\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.ImmutableList;\n+import org.apache.druid.data.input.InputSplit;\n+import org.apache.druid.data.input.impl.CloudObjectInputSource;\n+import org.apache.druid.data.input.impl.CloudObjectLocation;\n+import org.apache.druid.data.input.impl.SplittableInputSource;\n+import org.apache.druid.java.util.common.logger.Logger;\n+import org.apache.druid.storage.azure.AzureCloudBlobDruidToCloudObjectLocationConverter;\n+import org.apache.druid.storage.azure.AzureCloudBlobIterableFactory;\n+import org.apache.druid.storage.azure.AzureStorage;\n+import org.apache.druid.storage.azure.CloudBlobDruid;\n+\n+import javax.annotation.Nullable;\n+import java.net.URI;\n+import java.util.List;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+\n+public class AzureInputSource extends CloudObjectInputSource<AzureEntity>\n+{\n+  static final int MAX_LISTING_LENGTH = 1024;\n+  static final String SCHEME = \"azure\";\n+\n+  private final Logger log = new Logger(AzureInputSource.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6dd498ea5575fb96813ae1814f2d5de2ff00affa"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDM5MDYzMw==", "bodyText": "The javadocs for InputSplit say this is used for FiniteFirehoseFactory maybe we should update those docs?", "url": "https://github.com/apache/druid/pull/9306#discussion_r374390633", "createdAt": "2020-02-03T23:00:55Z", "author": {"login": "suneet-s"}, "path": "extensions-contrib/azure-extensions/src/main/java/org/apache/druid/data/input/azure/AzureInputSource.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.data.input.azure;\n+\n+import com.fasterxml.jackson.annotation.JacksonInject;\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.ImmutableList;\n+import org.apache.druid.data.input.InputSplit;\n+import org.apache.druid.data.input.impl.CloudObjectInputSource;\n+import org.apache.druid.data.input.impl.CloudObjectLocation;\n+import org.apache.druid.data.input.impl.SplittableInputSource;\n+import org.apache.druid.java.util.common.logger.Logger;\n+import org.apache.druid.storage.azure.AzureCloudBlobDruidToCloudObjectLocationConverter;\n+import org.apache.druid.storage.azure.AzureCloudBlobIterableFactory;\n+import org.apache.druid.storage.azure.AzureStorage;\n+import org.apache.druid.storage.azure.CloudBlobDruid;\n+\n+import javax.annotation.Nullable;\n+import java.net.URI;\n+import java.util.List;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+\n+public class AzureInputSource extends CloudObjectInputSource<AzureEntity>\n+{\n+  static final int MAX_LISTING_LENGTH = 1024;\n+  static final String SCHEME = \"azure\";\n+\n+  private final Logger log = new Logger(AzureInputSource.class);\n+  private final AzureStorage storage;\n+  private final AzureEntityFactory entityFactory;\n+  private final AzureCloudBlobIterableFactory azureCloudBlobIterableFactory;\n+  private final AzureCloudBlobDruidToCloudObjectLocationConverter azureCloudBlobToLocationConverter;\n+\n+  @JsonCreator\n+  public AzureInputSource(\n+      @JacksonInject AzureStorage storage,\n+      @JacksonInject AzureEntityFactory entityFactory,\n+      @JacksonInject AzureCloudBlobIterableFactory azureCloudBlobIterableFactory,\n+      @JacksonInject AzureCloudBlobDruidToCloudObjectLocationConverter azureCloudBlobToLocationConverter,\n+      @JsonProperty(\"uris\") @Nullable List<URI> uris,\n+      @JsonProperty(\"prefixes\") @Nullable List<URI> prefixes,\n+      @JsonProperty(\"objects\") @Nullable List<CloudObjectLocation> objects\n+  )\n+  {\n+    super(SCHEME, uris, prefixes, objects);\n+    this.storage = Preconditions.checkNotNull(storage, \"AzureStorage\");\n+    this.entityFactory = Preconditions.checkNotNull(entityFactory, \"AzureEntityFactory\");\n+    this.azureCloudBlobIterableFactory = Preconditions.checkNotNull(\n+        azureCloudBlobIterableFactory,\n+        \"AzureCloudBlobIterableFactory\"\n+    );\n+    this.azureCloudBlobToLocationConverter = Preconditions.checkNotNull(azureCloudBlobToLocationConverter, \"AzureCloudBlobToLocationConverter\");\n+  }\n+\n+  @Override\n+  protected AzureEntity createEntity(InputSplit<CloudObjectLocation> split)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6dd498ea5575fb96813ae1814f2d5de2ff00affa"}, "originalPosition": 76}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDM5MTk2MQ==", "bodyText": "Add instructions about how to move away from this deprecated class and if there are any benefits, why the new way is preferred.\nSimilar comments for other deprecated annotations", "url": "https://github.com/apache/druid/pull/9306#discussion_r374391961", "createdAt": "2020-02-03T23:04:36Z", "author": {"login": "suneet-s"}, "path": "extensions-contrib/azure-extensions/src/main/java/org/apache/druid/firehose/azure/AzureBlob.java", "diffHunk": "@@ -26,6 +26,7 @@\n import java.util.Objects;\n \n \n+@Deprecated", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6dd498ea5575fb96813ae1814f2d5de2ff00affa"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQwMTI1Ng==", "bodyText": "You don't need the assisted annotations here", "url": "https://github.com/apache/druid/pull/9306#discussion_r374401256", "createdAt": "2020-02-03T23:32:13Z", "author": {"login": "suneet-s"}, "path": "extensions-contrib/azure-extensions/src/main/java/org/apache/druid/storage/azure/AzureByteSourceFactory.java", "diffHunk": "@@ -0,0 +1,27 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.storage.azure;\n+\n+import com.google.inject.assistedinject.Assisted;\n+\n+public interface AzureByteSourceFactory\n+{\n+  AzureByteSource create(@Assisted(\"containerName\") String containerName, @Assisted(\"blobPath\") String blobPath);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6dd498ea5575fb96813ae1814f2d5de2ff00affa"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQwMTYwOA==", "bodyText": "Should this handle retryable exceptions?\nAzureUtils.AZURE_RETRY.apply(e)", "url": "https://github.com/apache/druid/pull/9306#discussion_r374401608", "createdAt": "2020-02-03T23:33:27Z", "author": {"login": "suneet-s"}, "path": "extensions-contrib/azure-extensions/src/main/java/org/apache/druid/storage/azure/AzureCloudBlobDruidToCloudObjectLocationConverter.java", "diffHunk": "@@ -0,0 +1,37 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.storage.azure;\n+\n+import org.apache.druid.data.input.impl.CloudObjectLocation;\n+\n+public class AzureCloudBlobDruidToCloudObjectLocationConverter\n+    implements ICloudSpecificObjectToCloudObjectLocationConverter<CloudBlobDruid>\n+{\n+  @Override\n+  public CloudObjectLocation createCloudObjectLocation(CloudBlobDruid cloudBlob)\n+  {\n+    try {\n+      return new CloudObjectLocation(cloudBlob.getContainerName(), cloudBlob.getName());\n+    }\n+    catch (Exception e) {\n+      throw new RuntimeException(e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6dd498ea5575fb96813ae1814f2d5de2ff00affa"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQwMzY4Nw==", "bodyText": "Do we want a unit test to make sure we're using flat blob listing?", "url": "https://github.com/apache/druid/pull/9306#discussion_r374403687", "createdAt": "2020-02-03T23:40:11Z", "author": {"login": "suneet-s"}, "path": "extensions-contrib/azure-extensions/src/main/java/org/apache/druid/storage/azure/AzureStorage.java", "diffHunk": "@@ -117,4 +123,26 @@ private CloudBlobContainer getOrCreateCloudBlobContainer(final String containerN\n \n     return cloudBlobContainer;\n   }\n+\n+  public ResultSegmentDruid<ListBlobItem> listBlobsWithPrefixInContainerSegmented(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6dd498ea5575fb96813ae1814f2d5de2ff00affa"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQwMzk5Mg==", "bodyText": "I don't think you need to cast nulls", "url": "https://github.com/apache/druid/pull/9306#discussion_r374403992", "createdAt": "2020-02-03T23:41:05Z", "author": {"login": "suneet-s"}, "path": "extensions-contrib/azure-extensions/src/main/java/org/apache/druid/storage/azure/AzureStorage.java", "diffHunk": "@@ -117,4 +123,26 @@ private CloudBlobContainer getOrCreateCloudBlobContainer(final String containerN\n \n     return cloudBlobContainer;\n   }\n+\n+  public ResultSegmentDruid<ListBlobItem> listBlobsWithPrefixInContainerSegmented(\n+      final String containerName,\n+      final String prefix,\n+      ResultContinuation continuationToken,\n+      int maxResults\n+  ) throws StorageException, URISyntaxException\n+  {\n+    CloudBlobContainer cloudBlobContainer = cloudBlobClient.getContainerReference(containerName);\n+    return new ResultSegmentDruid<ListBlobItem>(cloudBlobContainer\n+                                                    .listBlobsSegmented(\n+                                                        prefix,\n+                                                        /* Use flat blob listing here so that we get only blob types and not directories.*/\n+                                                        USE_FLAT_BLOB_LISTING,\n+                                                        EnumSet\n+                                                            .noneOf(BlobListingDetails.class),\n+                                                        maxResults,\n+                                                        (ResultContinuation) null,\n+                                                        (BlobRequestOptions) null,\n+                                                        (OperationContext) null", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6dd498ea5575fb96813ae1814f2d5de2ff00affa"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQwNDYyNA==", "bodyText": "why not bind(AzureCloudBlobDruidToCloudObjectLocationConverter.class).in(Scopes.LazySingleton)", "url": "https://github.com/apache/druid/pull/9306#discussion_r374404624", "createdAt": "2020-02-03T23:43:16Z", "author": {"login": "suneet-s"}, "path": "extensions-contrib/azure-extensions/src/main/java/org/apache/druid/storage/azure/AzureStorageDruidModule.java", "diffHunk": "@@ -118,4 +133,11 @@ public AzureStorage getAzureStorageContainer(\n   {\n     return new AzureStorage(cloudBlobClient);\n   }\n+\n+  @Provides\n+  @LazySingleton\n+  public AzureCloudBlobDruidToCloudObjectLocationConverter getAzureCloudBlobToLocationConverter()\n+  {\n+    return new AzureCloudBlobDruidToCloudObjectLocationConverter();\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6dd498ea5575fb96813ae1814f2d5de2ff00affa"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQwNTIwOQ==", "bodyText": "ModuleTests to ensure the factories are injected and can create their objects?\nLook at this PR - #9279 I've added a bunch of module tests with mocks", "url": "https://github.com/apache/druid/pull/9306#discussion_r374405209", "createdAt": "2020-02-03T23:45:24Z", "author": {"login": "suneet-s"}, "path": "extensions-contrib/azure-extensions/src/main/java/org/apache/druid/storage/azure/AzureStorageDruidModule.java", "diffHunk": "@@ -91,6 +96,16 @@ public void configure(Binder binder)\n     Binders.taskLogsBinder(binder).addBinding(SCHEME).to(AzureTaskLogs.class);\n     JsonConfigProvider.bind(binder, \"druid.indexer.logs\", AzureTaskLogsConfig.class);\n     binder.bind(AzureTaskLogs.class).in(LazySingleton.class);\n+    binder.install(new FactoryModuleBuilder()\n+                       .build(AzureByteSourceFactory.class));\n+    binder.install(new FactoryModuleBuilder()\n+                       .build(AzureEntityFactory.class));\n+    binder.install(new FactoryModuleBuilder()\n+                       .build(AzureCloudBlobIteratorFactory.class));\n+    binder.install(new FactoryModuleBuilder()\n+                       .build(AzureCloudBlobIterableFactory.class));\n+    binder.install(new FactoryModuleBuilder()\n+                       .build(ListBlobItemDruidFactory.class));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6dd498ea5575fb96813ae1814f2d5de2ff00affa"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQwNTQ3NA==", "bodyText": "javadoc for utility function", "url": "https://github.com/apache/druid/pull/9306#discussion_r374405474", "createdAt": "2020-02-03T23:46:20Z", "author": {"login": "suneet-s"}, "path": "extensions-contrib/azure-extensions/src/main/java/org/apache/druid/storage/azure/AzureUtils.java", "diffHunk": "@@ -46,6 +48,11 @@\n     return false;\n   };\n \n+  public static String extractAzureKey(URI uri)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6dd498ea5575fb96813ae1814f2d5de2ff00affa"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQwNjY5Mw==", "bodyText": "What is the purpose of all these Druid classes that delegate to another class? Why not justuse the delegate class directly?", "url": "https://github.com/apache/druid/pull/9306#discussion_r374406693", "createdAt": "2020-02-03T23:50:31Z", "author": {"login": "suneet-s"}, "path": "extensions-contrib/azure-extensions/src/main/java/org/apache/druid/storage/azure/ResultSegmentDruid.java", "diffHunk": "@@ -0,0 +1,45 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.storage.azure;\n+\n+import com.microsoft.azure.storage.ResultContinuation;\n+import com.microsoft.azure.storage.ResultSegment;\n+\n+import java.util.ArrayList;\n+\n+public class ResultSegmentDruid<T>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6dd498ea5575fb96813ae1814f2d5de2ff00affa"}, "originalPosition": 27}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ce4a2d6742fbe7ed4ad61a17afd571f615744354", "author": {"user": {"login": "zachjsh", "name": null}}, "url": "https://github.com/apache/druid/commit/ce4a2d6742fbe7ed4ad61a17afd571f615744354", "committedDate": "2020-02-04T00:43:37Z", "message": "* rollback fix for google cloud batch ingestion bug. Will be\n  fixed in another PR."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUyNjg2MjYy", "url": "https://github.com/apache/druid/pull/9306#pullrequestreview-352686262", "createdAt": "2020-02-04T02:11:25Z", "commit": {"oid": "6dd498ea5575fb96813ae1814f2d5de2ff00affa"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQwMjoxMToyNlrOFlGIog==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQwMjoxMjoxNlrOFlGJVw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQ0MjE0Ng==", "bodyText": "Good point. We should fix the javaodc.", "url": "https://github.com/apache/druid/pull/9306#discussion_r374442146", "createdAt": "2020-02-04T02:11:26Z", "author": {"login": "jihoonson"}, "path": "extensions-contrib/azure-extensions/src/main/java/org/apache/druid/data/input/azure/AzureInputSource.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.data.input.azure;\n+\n+import com.fasterxml.jackson.annotation.JacksonInject;\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.ImmutableList;\n+import org.apache.druid.data.input.InputSplit;\n+import org.apache.druid.data.input.impl.CloudObjectInputSource;\n+import org.apache.druid.data.input.impl.CloudObjectLocation;\n+import org.apache.druid.data.input.impl.SplittableInputSource;\n+import org.apache.druid.java.util.common.logger.Logger;\n+import org.apache.druid.storage.azure.AzureCloudBlobDruidToCloudObjectLocationConverter;\n+import org.apache.druid.storage.azure.AzureCloudBlobIterableFactory;\n+import org.apache.druid.storage.azure.AzureStorage;\n+import org.apache.druid.storage.azure.CloudBlobDruid;\n+\n+import javax.annotation.Nullable;\n+import java.net.URI;\n+import java.util.List;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+\n+public class AzureInputSource extends CloudObjectInputSource<AzureEntity>\n+{\n+  static final int MAX_LISTING_LENGTH = 1024;\n+  static final String SCHEME = \"azure\";\n+\n+  private final Logger log = new Logger(AzureInputSource.class);\n+  private final AzureStorage storage;\n+  private final AzureEntityFactory entityFactory;\n+  private final AzureCloudBlobIterableFactory azureCloudBlobIterableFactory;\n+  private final AzureCloudBlobDruidToCloudObjectLocationConverter azureCloudBlobToLocationConverter;\n+\n+  @JsonCreator\n+  public AzureInputSource(\n+      @JacksonInject AzureStorage storage,\n+      @JacksonInject AzureEntityFactory entityFactory,\n+      @JacksonInject AzureCloudBlobIterableFactory azureCloudBlobIterableFactory,\n+      @JacksonInject AzureCloudBlobDruidToCloudObjectLocationConverter azureCloudBlobToLocationConverter,\n+      @JsonProperty(\"uris\") @Nullable List<URI> uris,\n+      @JsonProperty(\"prefixes\") @Nullable List<URI> prefixes,\n+      @JsonProperty(\"objects\") @Nullable List<CloudObjectLocation> objects\n+  )\n+  {\n+    super(SCHEME, uris, prefixes, objects);\n+    this.storage = Preconditions.checkNotNull(storage, \"AzureStorage\");\n+    this.entityFactory = Preconditions.checkNotNull(entityFactory, \"AzureEntityFactory\");\n+    this.azureCloudBlobIterableFactory = Preconditions.checkNotNull(\n+        azureCloudBlobIterableFactory,\n+        \"AzureCloudBlobIterableFactory\"\n+    );\n+    this.azureCloudBlobToLocationConverter = Preconditions.checkNotNull(azureCloudBlobToLocationConverter, \"AzureCloudBlobToLocationConverter\");\n+  }\n+\n+  @Override\n+  protected AzureEntity createEntity(InputSplit<CloudObjectLocation> split)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDM5MDYzMw=="}, "originalCommit": {"oid": "6dd498ea5575fb96813ae1814f2d5de2ff00affa"}, "originalPosition": 76}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQ0MjMyNw==", "bodyText": "Out of curiosity, what's the benefit of using the factory pattern here?", "url": "https://github.com/apache/druid/pull/9306#discussion_r374442327", "createdAt": "2020-02-04T02:12:16Z", "author": {"login": "jihoonson"}, "path": "extensions-contrib/azure-extensions/src/main/java/org/apache/druid/data/input/azure/AzureInputSource.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.data.input.azure;\n+\n+import com.fasterxml.jackson.annotation.JacksonInject;\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.ImmutableList;\n+import org.apache.druid.data.input.InputSplit;\n+import org.apache.druid.data.input.impl.CloudObjectInputSource;\n+import org.apache.druid.data.input.impl.CloudObjectLocation;\n+import org.apache.druid.data.input.impl.SplittableInputSource;\n+import org.apache.druid.java.util.common.logger.Logger;\n+import org.apache.druid.storage.azure.AzureCloudBlobDruidToCloudObjectLocationConverter;\n+import org.apache.druid.storage.azure.AzureCloudBlobIterableFactory;\n+import org.apache.druid.storage.azure.AzureStorage;\n+import org.apache.druid.storage.azure.CloudBlobDruid;\n+\n+import javax.annotation.Nullable;\n+import java.net.URI;\n+import java.util.List;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+\n+public class AzureInputSource extends CloudObjectInputSource<AzureEntity>\n+{\n+  static final int MAX_LISTING_LENGTH = 1024;\n+  static final String SCHEME = \"azure\";\n+\n+  private final Logger log = new Logger(AzureInputSource.class);\n+  private final AzureStorage storage;\n+  private final AzureEntityFactory entityFactory;\n+  private final AzureCloudBlobIterableFactory azureCloudBlobIterableFactory;\n+  private final AzureCloudBlobDruidToCloudObjectLocationConverter azureCloudBlobToLocationConverter;\n+\n+  @JsonCreator\n+  public AzureInputSource(\n+      @JacksonInject AzureStorage storage,\n+      @JacksonInject AzureEntityFactory entityFactory,\n+      @JacksonInject AzureCloudBlobIterableFactory azureCloudBlobIterableFactory,\n+      @JacksonInject AzureCloudBlobDruidToCloudObjectLocationConverter azureCloudBlobToLocationConverter,\n+      @JsonProperty(\"uris\") @Nullable List<URI> uris,\n+      @JsonProperty(\"prefixes\") @Nullable List<URI> prefixes,\n+      @JsonProperty(\"objects\") @Nullable List<CloudObjectLocation> objects\n+  )\n+  {\n+    super(SCHEME, uris, prefixes, objects);\n+    this.storage = Preconditions.checkNotNull(storage, \"AzureStorage\");\n+    this.entityFactory = Preconditions.checkNotNull(entityFactory, \"AzureEntityFactory\");\n+    this.azureCloudBlobIterableFactory = Preconditions.checkNotNull(\n+        azureCloudBlobIterableFactory,\n+        \"AzureCloudBlobIterableFactory\"\n+    );\n+    this.azureCloudBlobToLocationConverter = Preconditions.checkNotNull(azureCloudBlobToLocationConverter, \"AzureCloudBlobToLocationConverter\");\n+  }\n+\n+  @Override\n+  protected AzureEntity createEntity(InputSplit<CloudObjectLocation> split)\n+  {\n+    return entityFactory.create(split.get());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6dd498ea5575fb96813ae1814f2d5de2ff00affa"}, "originalPosition": 78}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7536255bbbf144e44955d111dd2985e2d65f25b3", "author": {"user": {"login": "zachjsh", "name": null}}, "url": "https://github.com/apache/druid/commit/7536255bbbf144e44955d111dd2985e2d65f25b3", "committedDate": "2020-02-06T01:00:20Z", "message": "* Added javadocs for all azure related classes\n* Addressed review comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU0Njg5Mjgw", "url": "https://github.com/apache/druid/pull/9306#pullrequestreview-354689280", "createdAt": "2020-02-06T18:52:06Z", "commit": {"oid": "7536255bbbf144e44955d111dd2985e2d65f25b3"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxODo1MjowN1rOFmmVYg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxODo1MzowNVrOFmmXJQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjAxODI3NA==", "bodyText": "nit: the suffix of Druid seems weird to me. Maybe because.. everything in Druid repo are druid? I suggest CloudBlobHolder.", "url": "https://github.com/apache/druid/pull/9306#discussion_r376018274", "createdAt": "2020-02-06T18:52:07Z", "author": {"login": "jihoonson"}, "path": "extensions-contrib/azure-extensions/src/main/java/org/apache/druid/storage/azure/CloudBlobDruid.java", "diffHunk": "@@ -0,0 +1,49 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.storage.azure;\n+\n+import com.microsoft.azure.storage.StorageException;\n+import com.microsoft.azure.storage.blob.CloudBlob;\n+\n+import java.net.URISyntaxException;\n+\n+/**\n+ * Wrapper for {@link CloudBlob}. Used to make testing easier, since {@link CloudBlob}\n+ * is a final class and so is difficult to mock in unit tests.\n+ */\n+public class CloudBlobDruid", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7536255bbbf144e44955d111dd2985e2d65f25b3"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjAxODcyNQ==", "bodyText": "Same for other classes ending with Druid.", "url": "https://github.com/apache/druid/pull/9306#discussion_r376018725", "createdAt": "2020-02-06T18:53:05Z", "author": {"login": "jihoonson"}, "path": "extensions-contrib/azure-extensions/src/main/java/org/apache/druid/storage/azure/CloudBlobDruid.java", "diffHunk": "@@ -0,0 +1,49 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.storage.azure;\n+\n+import com.microsoft.azure.storage.StorageException;\n+import com.microsoft.azure.storage.blob.CloudBlob;\n+\n+import java.net.URISyntaxException;\n+\n+/**\n+ * Wrapper for {@link CloudBlob}. Used to make testing easier, since {@link CloudBlob}\n+ * is a final class and so is difficult to mock in unit tests.\n+ */\n+public class CloudBlobDruid", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjAxODI3NA=="}, "originalCommit": {"oid": "7536255bbbf144e44955d111dd2985e2d65f25b3"}, "originalPosition": 31}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a67e00c9429cb83239b7284296ade5da3c48353d", "author": {"user": {"login": "zachjsh", "name": null}}, "url": "https://github.com/apache/druid/commit/a67e00c9429cb83239b7284296ade5da3c48353d", "committedDate": "2020-02-06T19:31:54Z", "message": "* Remove dependency on org.apache.commons:commons-collections4\n* Fix LGTM warnings\n* Add com.google.inject.extensions:guice-assistedinject to licenses"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "92f33066e763ae2ee3bd303f69535cac2adb1a54", "author": {"user": {"login": "zachjsh", "name": null}}, "url": "https://github.com/apache/druid/commit/92f33066e763ae2ee3bd303f69535cac2adb1a54", "committedDate": "2020-02-06T20:44:18Z", "message": "* rename classes as suggested in review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9226f9bb86234c7e1ccf156318e0bccea253999a", "author": {"user": {"login": "zachjsh", "name": null}}, "url": "https://github.com/apache/druid/commit/9226f9bb86234c7e1ccf156318e0bccea253999a", "committedDate": "2020-02-06T20:47:21Z", "message": "Merge remote-tracking branch 'apache/master' into IMPLY-1955"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU1MzM3NzAx", "url": "https://github.com/apache/druid/pull/9306#pullrequestreview-355337701", "createdAt": "2020-02-07T18:07:02Z", "commit": {"oid": "9226f9bb86234c7e1ccf156318e0bccea253999a"}, "state": "COMMENTED", "comments": {"totalCount": 16, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QxODoxNDoxOFrOFnFvnA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QxOTo0ODozNlrOFnIV_g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjUzMjg5Mg==", "bodyText": "missing serdeTest?", "url": "https://github.com/apache/druid/pull/9306#discussion_r376532892", "createdAt": "2020-02-07T18:14:18Z", "author": {"login": "suneet-s"}, "path": "extensions-contrib/azure-extensions/src/main/java/org/apache/druid/data/input/azure/AzureInputSource.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.data.input.azure;\n+\n+import com.fasterxml.jackson.annotation.JacksonInject;\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.ImmutableList;\n+import org.apache.druid.data.input.InputSplit;\n+import org.apache.druid.data.input.impl.CloudObjectInputSource;\n+import org.apache.druid.data.input.impl.CloudObjectLocation;\n+import org.apache.druid.data.input.impl.SplittableInputSource;\n+import org.apache.druid.storage.azure.AzureCloudBlobHolderToCloudObjectLocationConverter;\n+import org.apache.druid.storage.azure.AzureCloudBlobIterableFactory;\n+import org.apache.druid.storage.azure.AzureStorage;\n+import org.apache.druid.storage.azure.CloudBlobHolder;\n+\n+import javax.annotation.Nullable;\n+import java.net.URI;\n+import java.util.List;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+\n+/**\n+ * Abstracts the Azure storage system where input data is stored. Allows users to retrieve entities in\n+ * the storage system that match either a particular uri, prefix, or object.\n+ */\n+public class AzureInputSource extends CloudObjectInputSource<AzureEntity>\n+{\n+  static final int MAX_LISTING_LENGTH = 1024;\n+  public static final String SCHEME = \"azure\";\n+\n+  private final AzureStorage storage;\n+  private final AzureEntityFactory entityFactory;\n+  private final AzureCloudBlobIterableFactory azureCloudBlobIterableFactory;\n+  private final AzureCloudBlobHolderToCloudObjectLocationConverter azureCloudBlobToLocationConverter;\n+\n+  @JsonCreator\n+  public AzureInputSource(\n+      @JacksonInject AzureStorage storage,\n+      @JacksonInject AzureEntityFactory entityFactory,\n+      @JacksonInject AzureCloudBlobIterableFactory azureCloudBlobIterableFactory,\n+      @JacksonInject AzureCloudBlobHolderToCloudObjectLocationConverter azureCloudBlobToLocationConverter,\n+      @JsonProperty(\"uris\") @Nullable List<URI> uris,\n+      @JsonProperty(\"prefixes\") @Nullable List<URI> prefixes,\n+      @JsonProperty(\"objects\") @Nullable List<CloudObjectLocation> objects\n+  )\n+  {\n+    super(SCHEME, uris, prefixes, objects);\n+    this.storage = Preconditions.checkNotNull(storage, \"AzureStorage\");\n+    this.entityFactory = Preconditions.checkNotNull(entityFactory, \"AzureEntityFactory\");\n+    this.azureCloudBlobIterableFactory = Preconditions.checkNotNull(\n+        azureCloudBlobIterableFactory,\n+        \"AzureCloudBlobIterableFactory\"\n+    );\n+    this.azureCloudBlobToLocationConverter = Preconditions.checkNotNull(azureCloudBlobToLocationConverter, \"AzureCloudBlobToLocationConverter\");\n+  }\n+\n+  @Override\n+  public SplittableInputSource<CloudObjectLocation> withSplit(InputSplit<CloudObjectLocation> split)\n+  {\n+    return new AzureInputSource(\n+        storage,\n+        entityFactory,\n+        azureCloudBlobIterableFactory,\n+        azureCloudBlobToLocationConverter,\n+        null,\n+        null,\n+        ImmutableList.of(split.get())\n+    );\n+  }\n+\n+  @Override\n+  public String toString()\n+  {\n+    return \"AzureInputSource{\" +\n+           \"uris=\" + getUris() +\n+           \", prefixes=\" + getPrefixes() +\n+           \", objects=\" + getObjects() +\n+           '}';\n+  }\n+\n+  @Override\n+  protected AzureEntity createEntity(InputSplit<CloudObjectLocation> split)\n+  {\n+    return entityFactory.create(split.get());\n+  }\n+\n+  @Override\n+  protected Stream<InputSplit<CloudObjectLocation>> getPrefixesSplitStream()\n+  {\n+    return StreamSupport.stream(getIterableObjectsFromPrefixes().spliterator(), false)\n+                        .map(o -> azureCloudBlobToLocationConverter.createCloudObjectLocation(o))\n+                        .map(InputSplit::new);\n+  }\n+\n+  private Iterable<CloudBlobHolder> getIterableObjectsFromPrefixes()\n+  {\n+    return azureCloudBlobIterableFactory.create(getPrefixes(), MAX_LISTING_LENGTH);\n+  }\n+}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9226f9bb86234c7e1ccf156318e0bccea253999a"}, "originalPosition": 119}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjUzMzk2Nw==", "bodyText": "Can we move the toString() definition in to the base class? Looks like all the InputSources are using the same format.", "url": "https://github.com/apache/druid/pull/9306#discussion_r376533967", "createdAt": "2020-02-07T18:16:46Z", "author": {"login": "suneet-s"}, "path": "extensions-contrib/azure-extensions/src/main/java/org/apache/druid/data/input/azure/AzureInputSource.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.data.input.azure;\n+\n+import com.fasterxml.jackson.annotation.JacksonInject;\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.ImmutableList;\n+import org.apache.druid.data.input.InputSplit;\n+import org.apache.druid.data.input.impl.CloudObjectInputSource;\n+import org.apache.druid.data.input.impl.CloudObjectLocation;\n+import org.apache.druid.data.input.impl.SplittableInputSource;\n+import org.apache.druid.storage.azure.AzureCloudBlobHolderToCloudObjectLocationConverter;\n+import org.apache.druid.storage.azure.AzureCloudBlobIterableFactory;\n+import org.apache.druid.storage.azure.AzureStorage;\n+import org.apache.druid.storage.azure.CloudBlobHolder;\n+\n+import javax.annotation.Nullable;\n+import java.net.URI;\n+import java.util.List;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+\n+/**\n+ * Abstracts the Azure storage system where input data is stored. Allows users to retrieve entities in\n+ * the storage system that match either a particular uri, prefix, or object.\n+ */\n+public class AzureInputSource extends CloudObjectInputSource<AzureEntity>\n+{\n+  static final int MAX_LISTING_LENGTH = 1024;\n+  public static final String SCHEME = \"azure\";\n+\n+  private final AzureStorage storage;\n+  private final AzureEntityFactory entityFactory;\n+  private final AzureCloudBlobIterableFactory azureCloudBlobIterableFactory;\n+  private final AzureCloudBlobHolderToCloudObjectLocationConverter azureCloudBlobToLocationConverter;\n+\n+  @JsonCreator\n+  public AzureInputSource(\n+      @JacksonInject AzureStorage storage,\n+      @JacksonInject AzureEntityFactory entityFactory,\n+      @JacksonInject AzureCloudBlobIterableFactory azureCloudBlobIterableFactory,\n+      @JacksonInject AzureCloudBlobHolderToCloudObjectLocationConverter azureCloudBlobToLocationConverter,\n+      @JsonProperty(\"uris\") @Nullable List<URI> uris,\n+      @JsonProperty(\"prefixes\") @Nullable List<URI> prefixes,\n+      @JsonProperty(\"objects\") @Nullable List<CloudObjectLocation> objects\n+  )\n+  {\n+    super(SCHEME, uris, prefixes, objects);\n+    this.storage = Preconditions.checkNotNull(storage, \"AzureStorage\");\n+    this.entityFactory = Preconditions.checkNotNull(entityFactory, \"AzureEntityFactory\");\n+    this.azureCloudBlobIterableFactory = Preconditions.checkNotNull(\n+        azureCloudBlobIterableFactory,\n+        \"AzureCloudBlobIterableFactory\"\n+    );\n+    this.azureCloudBlobToLocationConverter = Preconditions.checkNotNull(azureCloudBlobToLocationConverter, \"AzureCloudBlobToLocationConverter\");\n+  }\n+\n+  @Override\n+  public SplittableInputSource<CloudObjectLocation> withSplit(InputSplit<CloudObjectLocation> split)\n+  {\n+    return new AzureInputSource(\n+        storage,\n+        entityFactory,\n+        azureCloudBlobIterableFactory,\n+        azureCloudBlobToLocationConverter,\n+        null,\n+        null,\n+        ImmutableList.of(split.get())\n+    );\n+  }\n+\n+  @Override\n+  public String toString()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9226f9bb86234c7e1ccf156318e0bccea253999a"}, "originalPosition": 92}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjUzNTI0Mw==", "bodyText": "I can't tell if equals/ hashCode is broken for this class. It looks like all the implementations just care about the class being the same an the uris/ prefixes/ objects to match.\nBut can we ever have a situation where AzureStorage is different but the uris are the same? My guess is no, but if that ever changes in the future it would be really tough to debug this. Unclear to me what the correct behavior is here. What do you think?", "url": "https://github.com/apache/druid/pull/9306#discussion_r376535243", "createdAt": "2020-02-07T18:19:31Z", "author": {"login": "suneet-s"}, "path": "extensions-contrib/azure-extensions/src/main/java/org/apache/druid/data/input/azure/AzureInputSource.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.data.input.azure;\n+\n+import com.fasterxml.jackson.annotation.JacksonInject;\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.ImmutableList;\n+import org.apache.druid.data.input.InputSplit;\n+import org.apache.druid.data.input.impl.CloudObjectInputSource;\n+import org.apache.druid.data.input.impl.CloudObjectLocation;\n+import org.apache.druid.data.input.impl.SplittableInputSource;\n+import org.apache.druid.storage.azure.AzureCloudBlobHolderToCloudObjectLocationConverter;\n+import org.apache.druid.storage.azure.AzureCloudBlobIterableFactory;\n+import org.apache.druid.storage.azure.AzureStorage;\n+import org.apache.druid.storage.azure.CloudBlobHolder;\n+\n+import javax.annotation.Nullable;\n+import java.net.URI;\n+import java.util.List;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+\n+/**\n+ * Abstracts the Azure storage system where input data is stored. Allows users to retrieve entities in\n+ * the storage system that match either a particular uri, prefix, or object.\n+ */\n+public class AzureInputSource extends CloudObjectInputSource<AzureEntity>\n+{\n+  static final int MAX_LISTING_LENGTH = 1024;\n+  public static final String SCHEME = \"azure\";\n+\n+  private final AzureStorage storage;\n+  private final AzureEntityFactory entityFactory;\n+  private final AzureCloudBlobIterableFactory azureCloudBlobIterableFactory;\n+  private final AzureCloudBlobHolderToCloudObjectLocationConverter azureCloudBlobToLocationConverter;\n+\n+  @JsonCreator\n+  public AzureInputSource(\n+      @JacksonInject AzureStorage storage,\n+      @JacksonInject AzureEntityFactory entityFactory,\n+      @JacksonInject AzureCloudBlobIterableFactory azureCloudBlobIterableFactory,\n+      @JacksonInject AzureCloudBlobHolderToCloudObjectLocationConverter azureCloudBlobToLocationConverter,\n+      @JsonProperty(\"uris\") @Nullable List<URI> uris,\n+      @JsonProperty(\"prefixes\") @Nullable List<URI> prefixes,\n+      @JsonProperty(\"objects\") @Nullable List<CloudObjectLocation> objects\n+  )\n+  {\n+    super(SCHEME, uris, prefixes, objects);\n+    this.storage = Preconditions.checkNotNull(storage, \"AzureStorage\");\n+    this.entityFactory = Preconditions.checkNotNull(entityFactory, \"AzureEntityFactory\");\n+    this.azureCloudBlobIterableFactory = Preconditions.checkNotNull(\n+        azureCloudBlobIterableFactory,\n+        \"AzureCloudBlobIterableFactory\"\n+    );\n+    this.azureCloudBlobToLocationConverter = Preconditions.checkNotNull(azureCloudBlobToLocationConverter, \"AzureCloudBlobToLocationConverter\");\n+  }\n+\n+  @Override\n+  public SplittableInputSource<CloudObjectLocation> withSplit(InputSplit<CloudObjectLocation> split)\n+  {\n+    return new AzureInputSource(\n+        storage,\n+        entityFactory,\n+        azureCloudBlobIterableFactory,\n+        azureCloudBlobToLocationConverter,\n+        null,\n+        null,\n+        ImmutableList.of(split.get())\n+    );\n+  }\n+\n+  @Override\n+  public String toString()\n+  {\n+    return \"AzureInputSource{\" +\n+           \"uris=\" + getUris() +\n+           \", prefixes=\" + getPrefixes() +\n+           \", objects=\" + getObjects() +\n+           '}';\n+  }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9226f9bb86234c7e1ccf156318e0bccea253999a"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU1NzUwMg==", "bodyText": "nit: intelliJ recommends using a method reference azureCloudBlobToLocationConverter::createCloudObjectLocation", "url": "https://github.com/apache/druid/pull/9306#discussion_r376557502", "createdAt": "2020-02-07T19:07:53Z", "author": {"login": "suneet-s"}, "path": "extensions-contrib/azure-extensions/src/main/java/org/apache/druid/data/input/azure/AzureInputSource.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.data.input.azure;\n+\n+import com.fasterxml.jackson.annotation.JacksonInject;\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.ImmutableList;\n+import org.apache.druid.data.input.InputSplit;\n+import org.apache.druid.data.input.impl.CloudObjectInputSource;\n+import org.apache.druid.data.input.impl.CloudObjectLocation;\n+import org.apache.druid.data.input.impl.SplittableInputSource;\n+import org.apache.druid.storage.azure.AzureCloudBlobHolderToCloudObjectLocationConverter;\n+import org.apache.druid.storage.azure.AzureCloudBlobIterableFactory;\n+import org.apache.druid.storage.azure.AzureStorage;\n+import org.apache.druid.storage.azure.CloudBlobHolder;\n+\n+import javax.annotation.Nullable;\n+import java.net.URI;\n+import java.util.List;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+\n+/**\n+ * Abstracts the Azure storage system where input data is stored. Allows users to retrieve entities in\n+ * the storage system that match either a particular uri, prefix, or object.\n+ */\n+public class AzureInputSource extends CloudObjectInputSource<AzureEntity>\n+{\n+  static final int MAX_LISTING_LENGTH = 1024;\n+  public static final String SCHEME = \"azure\";\n+\n+  private final AzureStorage storage;\n+  private final AzureEntityFactory entityFactory;\n+  private final AzureCloudBlobIterableFactory azureCloudBlobIterableFactory;\n+  private final AzureCloudBlobHolderToCloudObjectLocationConverter azureCloudBlobToLocationConverter;\n+\n+  @JsonCreator\n+  public AzureInputSource(\n+      @JacksonInject AzureStorage storage,\n+      @JacksonInject AzureEntityFactory entityFactory,\n+      @JacksonInject AzureCloudBlobIterableFactory azureCloudBlobIterableFactory,\n+      @JacksonInject AzureCloudBlobHolderToCloudObjectLocationConverter azureCloudBlobToLocationConverter,\n+      @JsonProperty(\"uris\") @Nullable List<URI> uris,\n+      @JsonProperty(\"prefixes\") @Nullable List<URI> prefixes,\n+      @JsonProperty(\"objects\") @Nullable List<CloudObjectLocation> objects\n+  )\n+  {\n+    super(SCHEME, uris, prefixes, objects);\n+    this.storage = Preconditions.checkNotNull(storage, \"AzureStorage\");\n+    this.entityFactory = Preconditions.checkNotNull(entityFactory, \"AzureEntityFactory\");\n+    this.azureCloudBlobIterableFactory = Preconditions.checkNotNull(\n+        azureCloudBlobIterableFactory,\n+        \"AzureCloudBlobIterableFactory\"\n+    );\n+    this.azureCloudBlobToLocationConverter = Preconditions.checkNotNull(azureCloudBlobToLocationConverter, \"AzureCloudBlobToLocationConverter\");\n+  }\n+\n+  @Override\n+  public SplittableInputSource<CloudObjectLocation> withSplit(InputSplit<CloudObjectLocation> split)\n+  {\n+    return new AzureInputSource(\n+        storage,\n+        entityFactory,\n+        azureCloudBlobIterableFactory,\n+        azureCloudBlobToLocationConverter,\n+        null,\n+        null,\n+        ImmutableList.of(split.get())\n+    );\n+  }\n+\n+  @Override\n+  public String toString()\n+  {\n+    return \"AzureInputSource{\" +\n+           \"uris=\" + getUris() +\n+           \", prefixes=\" + getPrefixes() +\n+           \", objects=\" + getObjects() +\n+           '}';\n+  }\n+\n+  @Override\n+  protected AzureEntity createEntity(InputSplit<CloudObjectLocation> split)\n+  {\n+    return entityFactory.create(split.get());\n+  }\n+\n+  @Override\n+  protected Stream<InputSplit<CloudObjectLocation>> getPrefixesSplitStream()\n+  {\n+    return StreamSupport.stream(getIterableObjectsFromPrefixes().spliterator(), false)\n+                        .map(o -> azureCloudBlobToLocationConverter.createCloudObjectLocation(o))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9226f9bb86234c7e1ccf156318e0bccea253999a"}, "originalPosition": 111}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU2MDM0OQ==", "bodyText": "As an operator - what should I do if I see this warning?", "url": "https://github.com/apache/druid/pull/9306#discussion_r376560349", "createdAt": "2020-02-07T19:14:31Z", "author": {"login": "suneet-s"}, "path": "extensions-contrib/azure-extensions/src/main/java/org/apache/druid/storage/azure/AzureByteSource.java", "diffHunk": "@@ -46,11 +53,19 @@ public AzureByteSource(\n \n   @Override\n   public InputStream openStream() throws IOException\n+  {\n+    return openStream(0L);\n+  }\n+\n+  public InputStream openStream(long offset) throws IOException\n   {\n     try {\n-      return azureStorage.getBlobInputStream(containerName, blobPath);\n+      return azureStorage.getBlobInputStream(offset, containerName, blobPath);\n     }\n     catch (StorageException | URISyntaxException e) {\n+      log.warn(\"Exception when opening stream to azure resource, containerName: %s, blobPath: %s, Error: %s\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9226f9bb86234c7e1ccf156318e0bccea253999a"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU2MTc5NA==", "bodyText": "In Druid, I see us throw RE which extends from RuntimeExceptions why did you choose to throw that here instead of RE? I don't know which one is the right one to throw...", "url": "https://github.com/apache/druid/pull/9306#discussion_r376561794", "createdAt": "2020-02-07T19:17:52Z", "author": {"login": "suneet-s"}, "path": "extensions-contrib/azure-extensions/src/main/java/org/apache/druid/storage/azure/AzureCloudBlobHolderToCloudObjectLocationConverter.java", "diffHunk": "@@ -0,0 +1,40 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.storage.azure;\n+\n+import org.apache.druid.data.input.impl.CloudObjectLocation;\n+\n+/**\n+ * Converts a {@link CloudBlobHolder} object to a {@link CloudObjectLocation} object\n+ */\n+public class AzureCloudBlobHolderToCloudObjectLocationConverter\n+    implements ICloudSpecificObjectToCloudObjectLocationConverter<CloudBlobHolder>\n+{\n+  @Override\n+  public CloudObjectLocation createCloudObjectLocation(CloudBlobHolder cloudBlob)\n+  {\n+    try {\n+      return new CloudObjectLocation(cloudBlob.getContainerName(), cloudBlob.getName());\n+    }\n+    catch (Exception e) {\n+      throw new RuntimeException(e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9226f9bb86234c7e1ccf156318e0bccea253999a"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU2NjA4OQ==", "bodyText": "Is there a test that verifies we've read all the blobs from a prefix if there is a continuation token?\nIs there a test for a prefix that has nothing in it? A prefix that has only directories?", "url": "https://github.com/apache/druid/pull/9306#discussion_r376566089", "createdAt": "2020-02-07T19:27:03Z", "author": {"login": "suneet-s"}, "path": "extensions-contrib/azure-extensions/src/test/java/org/apache/druid/storage/azure/AzureCloudBlobIteratorTest.java", "diffHunk": "@@ -0,0 +1,291 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.storage.azure;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.microsoft.azure.storage.ResultContinuation;\n+import com.microsoft.azure.storage.ResultSegment;\n+import com.microsoft.azure.storage.blob.ListBlobItem;\n+import org.apache.druid.java.util.common.RE;\n+import org.easymock.EasyMock;\n+import org.easymock.EasyMockSupport;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.net.URI;\n+import java.net.URISyntaxException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.NoSuchElementException;\n+\n+public class AzureCloudBlobIteratorTest extends EasyMockSupport\n+{\n+  private static final String AZURE = \"azure\";\n+  private static final String CONTAINER1 = \"container1\";\n+  private static final String PREFIX_ONLY_CLOUD_BLOBS = \"prefixOnlyCloudBlobs\";\n+  private static final String PREFIX_WITH_NO_BLOBS = \"prefixWithNoBlobs\";\n+  private static final String PREFIX_WITH_CLOUD_BLOBS_AND_DIRECTORIES = \"prefixWithCloudBlobsAndDirectories\";\n+  private static final URI PREFIX_ONLY_CLOUD_BLOBS_URI;\n+  private static final URI PREFIX_WITH_NO_BLOBS_URI;\n+  private static final URI PREFIX_WITH_CLOUD_BLOBS_AND_DIRECTORIES_URI;\n+  private static final List<URI> EMPTY_URI_PREFIXES = ImmutableList.of();\n+  private static final List<URI> PREFIXES;\n+  private static final int MAX_LISTING_LENGTH = 10;\n+\n+  private AzureStorage storage;\n+  private ListBlobItemHolderFactory blobItemDruidFactory;\n+  private ResultSegment<ListBlobItem> resultSegmentPrefixOnlyCloudBlobs1;\n+  private ResultSegment<ListBlobItem> resultSegmentPrefixOnlyCloudBlobs2;\n+  private ResultSegment<ListBlobItem> resultSegmentPrefixWithNoBlobs;\n+  private ResultSegment<ListBlobItem> resultSegmentPrefixWithCloudBlobsAndDirectories;\n+\n+  private ResultContinuation resultContinuationPrefixOnlyCloudBlobs = new ResultContinuation();\n+  private ResultContinuation nullResultContinuationToken = null;\n+\n+  private ListBlobItem blobItemPrefixWithOnlyCloudBlobs1;\n+  private ListBlobItemHolder cloudBlobItemPrefixWithOnlyCloudBlobs1;\n+  private CloudBlobHolder cloudBlobDruidPrefixWithOnlyCloudBlobs1;\n+\n+  private ListBlobItem blobItemPrefixWithOnlyCloudBlobs2;\n+  private ListBlobItemHolder cloudBlobItemPrefixWithOnlyCloudBlobs2;\n+  private CloudBlobHolder cloudBlobDruidPrefixWithOnlyCloudBlobs2;\n+\n+  private ListBlobItem blobItemPrefixWithCloudBlobsAndDirectories1;\n+  private ListBlobItemHolder directoryItemPrefixWithCloudBlobsAndDirectories;\n+\n+  private ListBlobItem blobItemPrefixWithCloudBlobsAndDirectories2;\n+  private ListBlobItemHolder cloudBlobItemPrefixWithCloudBlobsAndDirectories;\n+  private CloudBlobHolder cloudBlobDruidPrefixWithCloudBlobsAndDirectories;\n+\n+  private ListBlobItem blobItemPrefixWithCloudBlobsAndDirectories3;\n+  private ListBlobItemHolder directoryItemPrefixWithCloudBlobsAndDirectories3;\n+\n+\n+  private AzureCloudBlobIterator azureCloudBlobIterator;\n+\n+  static {\n+    try {\n+      PREFIX_ONLY_CLOUD_BLOBS_URI = new URI(AZURE + \"://\" + CONTAINER1 + \"/\" + PREFIX_ONLY_CLOUD_BLOBS);\n+      PREFIX_WITH_NO_BLOBS_URI = new URI(AZURE + \"://\" + CONTAINER1 + \"/\" + PREFIX_WITH_NO_BLOBS);\n+      PREFIX_WITH_CLOUD_BLOBS_AND_DIRECTORIES_URI = new URI(AZURE\n+                                                            + \"://\"\n+                                                            + CONTAINER1\n+                                                            + \"/\"\n+                                                            + PREFIX_WITH_CLOUD_BLOBS_AND_DIRECTORIES);\n+      PREFIXES = ImmutableList.of(\n+          PREFIX_ONLY_CLOUD_BLOBS_URI,\n+          PREFIX_WITH_NO_BLOBS_URI,\n+          PREFIX_WITH_CLOUD_BLOBS_AND_DIRECTORIES_URI\n+      );\n+    }\n+    catch (Exception e) {\n+      throw new RuntimeException(e);\n+    }\n+  }\n+\n+  @Before\n+  public void setup()\n+  {\n+    storage = createMock(AzureStorage.class);\n+    resultSegmentPrefixOnlyCloudBlobs1 = createMock(ResultSegment.class);\n+    resultSegmentPrefixOnlyCloudBlobs2 = createMock(ResultSegment.class);\n+    resultSegmentPrefixWithNoBlobs = createMock(ResultSegment.class);\n+    resultSegmentPrefixWithCloudBlobsAndDirectories = createMock(ResultSegment.class);\n+    cloudBlobItemPrefixWithOnlyCloudBlobs1 = createMock(ListBlobItemHolder.class);\n+\n+    blobItemPrefixWithOnlyCloudBlobs1 = createMock(ListBlobItem.class);\n+    cloudBlobItemPrefixWithOnlyCloudBlobs1 = createMock(ListBlobItemHolder.class);\n+    cloudBlobDruidPrefixWithOnlyCloudBlobs1 = createMock(CloudBlobHolder.class);\n+\n+    blobItemPrefixWithOnlyCloudBlobs2 = createMock(ListBlobItem.class);\n+    cloudBlobItemPrefixWithOnlyCloudBlobs2 = createMock(ListBlobItemHolder.class);\n+    cloudBlobDruidPrefixWithOnlyCloudBlobs2 = createMock(CloudBlobHolder.class);\n+\n+    blobItemPrefixWithCloudBlobsAndDirectories1 = createMock(ListBlobItem.class);\n+    directoryItemPrefixWithCloudBlobsAndDirectories = createMock(ListBlobItemHolder.class);\n+\n+    blobItemPrefixWithCloudBlobsAndDirectories2 = createMock(ListBlobItem.class);\n+    cloudBlobItemPrefixWithCloudBlobsAndDirectories = createMock(ListBlobItemHolder.class);\n+    cloudBlobDruidPrefixWithCloudBlobsAndDirectories = createMock(CloudBlobHolder.class);\n+\n+    blobItemPrefixWithCloudBlobsAndDirectories3 = createMock(ListBlobItem.class);\n+    directoryItemPrefixWithCloudBlobsAndDirectories3 = createMock(ListBlobItemHolder.class);\n+\n+\n+    blobItemDruidFactory = createMock(ListBlobItemHolderFactory.class);\n+  }\n+\n+  @Test\n+  public void test_hasNext_noBlobs_returnsFalse()\n+  {\n+    azureCloudBlobIterator = new AzureCloudBlobIterator(\n+        storage,\n+        blobItemDruidFactory,\n+        EMPTY_URI_PREFIXES,\n+        MAX_LISTING_LENGTH\n+    );\n+    boolean hasNext = azureCloudBlobIterator.hasNext();\n+    Assert.assertFalse(hasNext);\n+  }\n+\n+  @Test\n+  public void test_next_prefixesWithMultipleBlobsAndSomeDirectories_returnsExpectedBlobs() throws Exception\n+  {\n+    EasyMock.expect(cloudBlobItemPrefixWithOnlyCloudBlobs1.isCloudBlob()).andReturn(true);\n+    EasyMock.expect(cloudBlobItemPrefixWithOnlyCloudBlobs1.getCloudBlob()).andReturn(\n+        cloudBlobDruidPrefixWithOnlyCloudBlobs1);\n+    EasyMock.expect(blobItemDruidFactory.create(blobItemPrefixWithOnlyCloudBlobs1)).andReturn(\n+        cloudBlobItemPrefixWithOnlyCloudBlobs1);\n+\n+    EasyMock.expect(cloudBlobItemPrefixWithOnlyCloudBlobs2.isCloudBlob()).andReturn(true);\n+    EasyMock.expect(cloudBlobItemPrefixWithOnlyCloudBlobs2.getCloudBlob()).andReturn(\n+        cloudBlobDruidPrefixWithOnlyCloudBlobs2);\n+    EasyMock.expect(blobItemDruidFactory.create(blobItemPrefixWithOnlyCloudBlobs2)).andReturn(\n+        cloudBlobItemPrefixWithOnlyCloudBlobs2);\n+\n+    EasyMock.expect(directoryItemPrefixWithCloudBlobsAndDirectories.isCloudBlob()).andReturn(false);\n+    EasyMock.expect(blobItemDruidFactory.create(blobItemPrefixWithCloudBlobsAndDirectories1)).andReturn(\n+        directoryItemPrefixWithCloudBlobsAndDirectories);\n+\n+    EasyMock.expect(cloudBlobItemPrefixWithCloudBlobsAndDirectories.isCloudBlob()).andReturn(true);\n+    EasyMock.expect(cloudBlobItemPrefixWithCloudBlobsAndDirectories.getCloudBlob()).andReturn(\n+        cloudBlobDruidPrefixWithCloudBlobsAndDirectories);\n+    EasyMock.expect(blobItemDruidFactory.create(blobItemPrefixWithCloudBlobsAndDirectories2)).andReturn(\n+        cloudBlobItemPrefixWithCloudBlobsAndDirectories);\n+\n+    EasyMock.expect(directoryItemPrefixWithCloudBlobsAndDirectories3.isCloudBlob()).andReturn(false);\n+    EasyMock.expect(blobItemDruidFactory.create(blobItemPrefixWithCloudBlobsAndDirectories3)).andReturn(\n+        directoryItemPrefixWithCloudBlobsAndDirectories3);\n+\n+    ArrayList<ListBlobItem> resultBlobItemsPrefixWithOnlyCloudBlobs1 = new ArrayList<>();\n+    resultBlobItemsPrefixWithOnlyCloudBlobs1.add(blobItemPrefixWithOnlyCloudBlobs1);\n+    ArrayList<ListBlobItem> resultBlobItemsPrefixWithOnlyCloudBlobs2 = new ArrayList<>();\n+    resultBlobItemsPrefixWithOnlyCloudBlobs2.add(blobItemPrefixWithOnlyCloudBlobs2);\n+    ArrayList<ListBlobItem> resultBlobItemsPrefixWithNoBlobs = new ArrayList<>();\n+    ArrayList<ListBlobItem> resultBlobItemsPrefixWithCloudBlobsAndDirectories = new ArrayList<>();\n+    resultBlobItemsPrefixWithCloudBlobsAndDirectories.add(blobItemPrefixWithCloudBlobsAndDirectories1);\n+    resultBlobItemsPrefixWithCloudBlobsAndDirectories.add(blobItemPrefixWithCloudBlobsAndDirectories2);\n+    resultBlobItemsPrefixWithCloudBlobsAndDirectories.add(blobItemPrefixWithCloudBlobsAndDirectories3);\n+    EasyMock.expect(resultSegmentPrefixOnlyCloudBlobs1.getContinuationToken())\n+            .andReturn(resultContinuationPrefixOnlyCloudBlobs);\n+    EasyMock.expect(resultSegmentPrefixOnlyCloudBlobs1.getResults())\n+            .andReturn(resultBlobItemsPrefixWithOnlyCloudBlobs1);\n+\n+    EasyMock.expect(resultSegmentPrefixOnlyCloudBlobs2.getContinuationToken()).andReturn(nullResultContinuationToken);\n+    EasyMock.expect(resultSegmentPrefixOnlyCloudBlobs2.getResults())\n+            .andReturn(resultBlobItemsPrefixWithOnlyCloudBlobs2);\n+\n+    EasyMock.expect(resultSegmentPrefixWithNoBlobs.getContinuationToken()).andReturn(nullResultContinuationToken);\n+    EasyMock.expect(resultSegmentPrefixWithNoBlobs.getResults()).andReturn(resultBlobItemsPrefixWithNoBlobs);\n+\n+    EasyMock.expect(resultSegmentPrefixWithCloudBlobsAndDirectories.getContinuationToken())\n+            .andReturn(nullResultContinuationToken);\n+    EasyMock.expect(resultSegmentPrefixWithCloudBlobsAndDirectories.getResults())\n+            .andReturn(resultBlobItemsPrefixWithCloudBlobsAndDirectories);\n+\n+    EasyMock.expect(storage.listBlobsWithPrefixInContainerSegmented(\n+        CONTAINER1,\n+        PREFIX_ONLY_CLOUD_BLOBS,\n+        nullResultContinuationToken,\n+        MAX_LISTING_LENGTH\n+    )).andReturn(resultSegmentPrefixOnlyCloudBlobs1);\n+\n+\n+    EasyMock.expect(storage.listBlobsWithPrefixInContainerSegmented(\n+        CONTAINER1,\n+        PREFIX_ONLY_CLOUD_BLOBS,\n+        resultContinuationPrefixOnlyCloudBlobs,\n+        MAX_LISTING_LENGTH\n+    )).andReturn(resultSegmentPrefixOnlyCloudBlobs2);\n+\n+    EasyMock.expect(storage.listBlobsWithPrefixInContainerSegmented(\n+        CONTAINER1,\n+        PREFIX_WITH_NO_BLOBS,\n+        nullResultContinuationToken,\n+        MAX_LISTING_LENGTH\n+    )).andReturn(resultSegmentPrefixWithNoBlobs);\n+\n+    EasyMock.expect(storage.listBlobsWithPrefixInContainerSegmented(\n+        CONTAINER1,\n+        PREFIX_WITH_CLOUD_BLOBS_AND_DIRECTORIES,\n+        nullResultContinuationToken,\n+        MAX_LISTING_LENGTH\n+    )).andReturn(resultSegmentPrefixWithCloudBlobsAndDirectories);\n+\n+    replayAll();\n+\n+    azureCloudBlobIterator = new AzureCloudBlobIterator(\n+        storage,\n+        blobItemDruidFactory,\n+        PREFIXES,\n+        MAX_LISTING_LENGTH\n+    );\n+\n+    List<CloudBlobHolder> expectedBlobItems = ImmutableList.of(\n+        cloudBlobDruidPrefixWithOnlyCloudBlobs1,\n+        cloudBlobDruidPrefixWithOnlyCloudBlobs2,\n+        cloudBlobDruidPrefixWithCloudBlobsAndDirectories\n+    );\n+    List<CloudBlobHolder> actualBlobItems = new ArrayList<>();\n+    while (azureCloudBlobIterator.hasNext()) {\n+      actualBlobItems.add(azureCloudBlobIterator.next());\n+    }\n+    Assert.assertEquals(expectedBlobItems.size(), actualBlobItems.size());\n+    Assert.assertTrue(expectedBlobItems.containsAll(actualBlobItems));\n+    verifyAll();\n+  }\n+\n+  @Test(expected = NoSuchElementException.class)\n+  public void test_next_emptyPrefixes_throwsNoSuchElementException()\n+  {\n+    azureCloudBlobIterator = new AzureCloudBlobIterator(\n+        storage,\n+        blobItemDruidFactory,\n+        EMPTY_URI_PREFIXES,\n+        MAX_LISTING_LENGTH\n+    );\n+    azureCloudBlobIterator.next();\n+  }\n+\n+  @Test(expected = RE.class)\n+  public void test_fetchNextBatch_exceptionThrownInStorage_throwsREException() throws Exception\n+  {\n+    EasyMock.expect(storage.listBlobsWithPrefixInContainerSegmented(\n+        EasyMock.anyString(),\n+        EasyMock.anyString(),\n+        EasyMock.anyObject(),\n+        EasyMock.anyInt()\n+    )).andThrow(new URISyntaxException(\"\", \"\"));\n+    azureCloudBlobIterator = new AzureCloudBlobIterator(\n+        storage,\n+        blobItemDruidFactory,\n+        PREFIXES,\n+        MAX_LISTING_LENGTH\n+    );\n+  }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9226f9bb86234c7e1ccf156318e0bccea253999a"}, "originalPosition": 285}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU2NzQ3MA==", "bodyText": "we're not changing the containerName in this function are we? I think it's confusing if one parameter is marked as final and the other isn't when both are in fact final", "url": "https://github.com/apache/druid/pull/9306#discussion_r376567470", "createdAt": "2020-02-07T19:30:16Z", "author": {"login": "suneet-s"}, "path": "extensions-contrib/azure-extensions/src/main/java/org/apache/druid/storage/azure/AzureStorage.java", "diffHunk": "@@ -49,7 +57,7 @@ public AzureStorage(\n     this.cloudBlobClient = cloudBlobClient;\n   }\n \n-  public List<String> emptyCloudBlobDirectory(final String containerName, final String virtualDirPath)\n+  public List<String> emptyCloudBlobDirectory(String containerName, final String virtualDirPath)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9226f9bb86234c7e1ccf156318e0bccea253999a"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU2Nzc5Ng==", "bodyText": "package private\n@VisibleForTesting", "url": "https://github.com/apache/druid/pull/9306#discussion_r376567796", "createdAt": "2020-02-07T19:31:01Z", "author": {"login": "suneet-s"}, "path": "extensions-contrib/azure-extensions/src/main/java/org/apache/druid/storage/azure/AzureStorage.java", "diffHunk": "@@ -117,4 +125,26 @@ private CloudBlobContainer getOrCreateCloudBlobContainer(final String containerN\n \n     return cloudBlobContainer;\n   }\n+\n+  public ResultSegment<ListBlobItem> listBlobsWithPrefixInContainerSegmented(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9226f9bb86234c7e1ccf156318e0bccea253999a"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU3MDcyNA==", "bodyText": "nit: Move CloudBlobHolder and ListBlobItemHolder and their Factories to ...stoarge.azure.blob so that it's out of this package which has other classes that are relevant to how the extension works", "url": "https://github.com/apache/druid/pull/9306#discussion_r376570724", "createdAt": "2020-02-07T19:37:43Z", "author": {"login": "suneet-s"}, "path": "extensions-contrib/azure-extensions/src/main/java/org/apache/druid/storage/azure/ListBlobItemHolder.java", "diffHunk": "@@ -0,0 +1,71 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.storage.azure;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9226f9bb86234c7e1ccf156318e0bccea253999a"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU3MjEyOQ==", "bodyText": "nit: Add a test for readFromStart", "url": "https://github.com/apache/druid/pull/9306#discussion_r376572129", "createdAt": "2020-02-07T19:40:52Z", "author": {"login": "suneet-s"}, "path": "extensions-contrib/azure-extensions/src/test/java/org/apache/druid/data/input/azure/AzureEntityTest.java", "diffHunk": "@@ -0,0 +1,148 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.data.input.azure;\n+\n+import com.google.common.base.Predicate;\n+import org.apache.commons.io.input.NullInputStream;\n+import org.apache.druid.data.input.impl.CloudObjectLocation;\n+import org.apache.druid.storage.azure.AzureByteSource;\n+import org.apache.druid.storage.azure.AzureByteSourceFactory;\n+import org.apache.druid.storage.azure.AzureUtils;\n+import org.easymock.EasyMock;\n+import org.easymock.EasyMockSupport;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.net.URI;\n+\n+public class AzureEntityTest extends EasyMockSupport\n+{\n+  private static final String CONTAINER_NAME = \"container\";\n+  private static final String BLOB_NAME = \"blob\";\n+  private static final int OFFSET = 20;\n+  private static final InputStream INPUT_STREAM = new NullInputStream(OFFSET);\n+  private static final IOException IO_EXCEPTION = new IOException();\n+  private static final URI ENTITY_URI;\n+\n+  private CloudObjectLocation location;\n+  private AzureByteSourceFactory byteSourceFactory;\n+  private AzureByteSource byteSource;\n+\n+  private AzureEntity azureEntity;\n+\n+  static {\n+    try {\n+      ENTITY_URI = new URI(AzureInputSource.SCHEME + \"://\" + CONTAINER_NAME + \"/\" + BLOB_NAME);\n+    }\n+    catch (Exception e) {\n+      throw new RuntimeException(e);\n+    }\n+  }\n+\n+  @Before\n+  public void setup()\n+  {\n+    location = createMock(CloudObjectLocation.class);\n+    byteSourceFactory = createMock(AzureByteSourceFactory.class);\n+    byteSource = createMock(AzureByteSource.class);\n+  }\n+\n+  @Test\n+  public void test_getUri_returnsLocationUri()\n+  {\n+    EasyMock.expect(location.getBucket()).andReturn(CONTAINER_NAME);\n+    EasyMock.expect(location.getPath()).andReturn(BLOB_NAME);\n+    EasyMock.expect(byteSourceFactory.create(CONTAINER_NAME, BLOB_NAME)).andReturn(byteSource);\n+    EasyMock.expect(location.toUri(AzureInputSource.SCHEME)).andReturn(ENTITY_URI);\n+    replayAll();\n+\n+    azureEntity = new AzureEntity(location, byteSourceFactory);\n+\n+    URI actualUri = azureEntity.getUri();\n+    Assert.assertEquals(ENTITY_URI, actualUri);\n+\n+    verifyAll();\n+\n+  }\n+\n+  @Test\n+  public void test_readFrom_returnsExpectedStream() throws Exception\n+  {\n+    EasyMock.expect(location.getBucket()).andReturn(CONTAINER_NAME);\n+    EasyMock.expect(location.getPath()).andReturn(BLOB_NAME);\n+    EasyMock.expect(byteSource.openStream(OFFSET)).andReturn(INPUT_STREAM);\n+    EasyMock.expect(byteSourceFactory.create(CONTAINER_NAME, BLOB_NAME)).andReturn(byteSource);\n+    replayAll();\n+\n+    azureEntity = new AzureEntity(location, byteSourceFactory);\n+\n+    InputStream actualInputStream = azureEntity.readFrom(OFFSET);\n+    Assert.assertSame(INPUT_STREAM, actualInputStream);\n+  }\n+\n+  @Test\n+  public void test_readFrom_throwsIOException_propogatesError()\n+  {\n+    try {\n+      EasyMock.expect(location.getBucket()).andReturn(CONTAINER_NAME);\n+      EasyMock.expect(location.getPath()).andReturn(BLOB_NAME);\n+      EasyMock.expect(byteSource.openStream(OFFSET)).andThrow(IO_EXCEPTION);\n+      EasyMock.expect(byteSourceFactory.create(CONTAINER_NAME, BLOB_NAME)).andReturn(byteSource);\n+      replayAll();\n+\n+      azureEntity = new AzureEntity(location, byteSourceFactory);\n+      azureEntity.readFrom(OFFSET);\n+    }\n+    catch (IOException e) {\n+      verifyAll();\n+    }\n+  }\n+\n+  @Test\n+  public void test_getPath_returnsLocationPath()\n+  {\n+    EasyMock.expect(location.getBucket()).andReturn(CONTAINER_NAME);\n+    EasyMock.expect(location.getPath()).andReturn(BLOB_NAME).atLeastOnce();\n+    EasyMock.expect(byteSourceFactory.create(CONTAINER_NAME, BLOB_NAME)).andReturn(byteSource);\n+    replayAll();\n+\n+    azureEntity = new AzureEntity(location, byteSourceFactory);\n+    String actualPath = azureEntity.getPath();\n+\n+    Assert.assertEquals(BLOB_NAME, actualPath);\n+    verifyAll();\n+  }\n+\n+  @Test\n+  public void test_getRetryCondition_returnsExpectedRetryCondition()\n+  {\n+    EasyMock.expect(location.getBucket()).andReturn(CONTAINER_NAME);\n+    EasyMock.expect(location.getPath()).andReturn(BLOB_NAME).atLeastOnce();\n+    EasyMock.expect(byteSourceFactory.create(CONTAINER_NAME, BLOB_NAME)).andReturn(byteSource);\n+    replayAll();\n+\n+    azureEntity = new AzureEntity(location, byteSourceFactory);\n+    Predicate<Throwable> actualRetryCondition = azureEntity.getRetryCondition();\n+    Assert.assertSame(AzureUtils.AZURE_RETRY, actualRetryCondition);\n+  }\n+}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9226f9bb86234c7e1ccf156318e0bccea253999a"}, "originalPosition": 148}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU3Mjc0MQ==", "bodyText": "nit: I prefere test_init_... but maybe Constructor should be constructor since it's the first word after _", "url": "https://github.com/apache/druid/pull/9306#discussion_r376572741", "createdAt": "2020-02-07T19:42:22Z", "author": {"login": "suneet-s"}, "path": "extensions-contrib/azure-extensions/src/test/java/org/apache/druid/data/input/azure/AzureInputSourceTest.java", "diffHunk": "@@ -0,0 +1,207 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.data.input.azure;\n+\n+import com.google.common.collect.ImmutableList;\n+import org.apache.druid.data.input.InputSplit;\n+import org.apache.druid.data.input.impl.CloudObjectLocation;\n+import org.apache.druid.data.input.impl.SplittableInputSource;\n+import org.apache.druid.storage.azure.AzureCloudBlobHolderToCloudObjectLocationConverter;\n+import org.apache.druid.storage.azure.AzureCloudBlobIterable;\n+import org.apache.druid.storage.azure.AzureCloudBlobIterableFactory;\n+import org.apache.druid.storage.azure.AzureStorage;\n+import org.apache.druid.storage.azure.CloudBlobHolder;\n+import org.easymock.EasyMock;\n+import org.easymock.EasyMockSupport;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.net.URI;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Spliterators;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+public class AzureInputSourceTest extends EasyMockSupport\n+{\n+  private static final String CONTAINER_NAME = \"container\";\n+  private static final String BLOB_NAME = \"blob\";\n+  private static final URI PREFIX_URI;\n+  private final List<URI> EMPTY_URIS = ImmutableList.of();\n+  private final List<URI> EMPTY_PREFIXES = ImmutableList.of();\n+  private final List<CloudObjectLocation> EMPTY_OBJECTS = ImmutableList.of();\n+  private static final String CONTAINER = \"CONTAINER\";\n+  private static final String BLOB_PATH = \"BLOB_PATH\";\n+  private static final CloudObjectLocation CLOUD_OBJECT_LOCATION_1 = new CloudObjectLocation(CONTAINER, BLOB_PATH);\n+\n+  private AzureStorage storage;\n+  private AzureEntityFactory entityFactory;\n+  private AzureCloudBlobIterableFactory azureCloudBlobIterableFactory;\n+  private AzureCloudBlobHolderToCloudObjectLocationConverter azureCloudBlobToLocationConverter;\n+\n+  private InputSplit<CloudObjectLocation> inputSplit;\n+  private AzureEntity azureEntity1;\n+  private CloudBlobHolder cloudBlobDruid1;\n+  private AzureCloudBlobIterable azureCloudBlobIterable;\n+\n+  private AzureInputSource azureInputSource;\n+\n+  static {\n+    try {\n+      PREFIX_URI = new URI(AzureInputSource.SCHEME + \"://\" + CONTAINER_NAME + \"/\" + BLOB_NAME);\n+    }\n+    catch (Exception e) {\n+      throw new RuntimeException(e);\n+    }\n+  }\n+\n+  @Before\n+  public void setup()\n+  {\n+    storage = createMock(AzureStorage.class);\n+    entityFactory = createMock(AzureEntityFactory.class);\n+    inputSplit = createMock(InputSplit.class);\n+    azureEntity1 = createMock(AzureEntity.class);\n+    azureCloudBlobIterableFactory = createMock(AzureCloudBlobIterableFactory.class);\n+    azureCloudBlobToLocationConverter = createMock(AzureCloudBlobHolderToCloudObjectLocationConverter.class);\n+    cloudBlobDruid1 = createMock(CloudBlobHolder.class);\n+    azureCloudBlobIterable = createMock(AzureCloudBlobIterable.class);\n+  }\n+\n+  @Test(expected = IllegalArgumentException.class)\n+  public void test_Constructor_emptyUrisEmptyPrefixesEmptyObjects_throwsIllegalArgumentException()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9226f9bb86234c7e1ccf156318e0bccea253999a"}, "originalPosition": 92}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU3MzEyMw==", "bodyText": "Do we want tests for uris and prefixes or uris and objects, etc. Or is that covered by another test", "url": "https://github.com/apache/druid/pull/9306#discussion_r376573123", "createdAt": "2020-02-07T19:43:18Z", "author": {"login": "suneet-s"}, "path": "extensions-contrib/azure-extensions/src/test/java/org/apache/druid/data/input/azure/AzureInputSourceTest.java", "diffHunk": "@@ -0,0 +1,207 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.data.input.azure;\n+\n+import com.google.common.collect.ImmutableList;\n+import org.apache.druid.data.input.InputSplit;\n+import org.apache.druid.data.input.impl.CloudObjectLocation;\n+import org.apache.druid.data.input.impl.SplittableInputSource;\n+import org.apache.druid.storage.azure.AzureCloudBlobHolderToCloudObjectLocationConverter;\n+import org.apache.druid.storage.azure.AzureCloudBlobIterable;\n+import org.apache.druid.storage.azure.AzureCloudBlobIterableFactory;\n+import org.apache.druid.storage.azure.AzureStorage;\n+import org.apache.druid.storage.azure.CloudBlobHolder;\n+import org.easymock.EasyMock;\n+import org.easymock.EasyMockSupport;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.net.URI;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Spliterators;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+public class AzureInputSourceTest extends EasyMockSupport\n+{\n+  private static final String CONTAINER_NAME = \"container\";\n+  private static final String BLOB_NAME = \"blob\";\n+  private static final URI PREFIX_URI;\n+  private final List<URI> EMPTY_URIS = ImmutableList.of();\n+  private final List<URI> EMPTY_PREFIXES = ImmutableList.of();\n+  private final List<CloudObjectLocation> EMPTY_OBJECTS = ImmutableList.of();\n+  private static final String CONTAINER = \"CONTAINER\";\n+  private static final String BLOB_PATH = \"BLOB_PATH\";\n+  private static final CloudObjectLocation CLOUD_OBJECT_LOCATION_1 = new CloudObjectLocation(CONTAINER, BLOB_PATH);\n+\n+  private AzureStorage storage;\n+  private AzureEntityFactory entityFactory;\n+  private AzureCloudBlobIterableFactory azureCloudBlobIterableFactory;\n+  private AzureCloudBlobHolderToCloudObjectLocationConverter azureCloudBlobToLocationConverter;\n+\n+  private InputSplit<CloudObjectLocation> inputSplit;\n+  private AzureEntity azureEntity1;\n+  private CloudBlobHolder cloudBlobDruid1;\n+  private AzureCloudBlobIterable azureCloudBlobIterable;\n+\n+  private AzureInputSource azureInputSource;\n+\n+  static {\n+    try {\n+      PREFIX_URI = new URI(AzureInputSource.SCHEME + \"://\" + CONTAINER_NAME + \"/\" + BLOB_NAME);\n+    }\n+    catch (Exception e) {\n+      throw new RuntimeException(e);\n+    }\n+  }\n+\n+  @Before\n+  public void setup()\n+  {\n+    storage = createMock(AzureStorage.class);\n+    entityFactory = createMock(AzureEntityFactory.class);\n+    inputSplit = createMock(InputSplit.class);\n+    azureEntity1 = createMock(AzureEntity.class);\n+    azureCloudBlobIterableFactory = createMock(AzureCloudBlobIterableFactory.class);\n+    azureCloudBlobToLocationConverter = createMock(AzureCloudBlobHolderToCloudObjectLocationConverter.class);\n+    cloudBlobDruid1 = createMock(CloudBlobHolder.class);\n+    azureCloudBlobIterable = createMock(AzureCloudBlobIterable.class);\n+  }\n+\n+  @Test(expected = IllegalArgumentException.class)\n+  public void test_Constructor_emptyUrisEmptyPrefixesEmptyObjects_throwsIllegalArgumentException()\n+  {\n+    replayAll();\n+    azureInputSource = new AzureInputSource(\n+        storage,\n+        entityFactory,\n+        azureCloudBlobIterableFactory,\n+        azureCloudBlobToLocationConverter,\n+        EMPTY_URIS,\n+        EMPTY_PREFIXES,\n+        EMPTY_OBJECTS\n+    );", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9226f9bb86234c7e1ccf156318e0bccea253999a"}, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU3NDA4MA==", "bodyText": "just FYI - you can use @RunWith(EasyMockRunner.class) and then just annotate the variables in the class so you don't need to call createMock in the setUp method", "url": "https://github.com/apache/druid/pull/9306#discussion_r376574080", "createdAt": "2020-02-07T19:45:27Z", "author": {"login": "suneet-s"}, "path": "extensions-contrib/azure-extensions/src/test/java/org/apache/druid/storage/azure/AzureCloudBlobHolderToCloudObjectLocationConverterTest.java", "diffHunk": "@@ -0,0 +1,58 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.storage.azure;\n+\n+import org.apache.druid.data.input.impl.CloudObjectLocation;\n+import org.easymock.EasyMock;\n+import org.easymock.EasyMockSupport;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+public class AzureCloudBlobHolderToCloudObjectLocationConverterTest extends EasyMockSupport\n+{\n+  private static final String CONTAINER1 = \"container1\";\n+  private static final String BLOB1 = \"blob1\";\n+\n+  private CloudBlobHolder cloudBlob;\n+\n+  private AzureCloudBlobHolderToCloudObjectLocationConverter converter;\n+\n+  @Before\n+  public void setup()\n+  {\n+    cloudBlob = createMock(CloudBlobHolder.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9226f9bb86234c7e1ccf156318e0bccea253999a"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU3NDY1OA==", "bodyText": "I see this duplicated in a lot of tests, maybe we should put it in it's own utility function?", "url": "https://github.com/apache/druid/pull/9306#discussion_r376574658", "createdAt": "2020-02-07T19:46:41Z", "author": {"login": "suneet-s"}, "path": "extensions-contrib/azure-extensions/src/test/java/org/apache/druid/storage/azure/AzureStorageDruidModuleTest.java", "diffHunk": "@@ -101,6 +126,108 @@ public void test_getAzureStorageContainer_expectedClient()\n     Assert.assertSame(cloudBlobClient, azureStorage.getCloudBlobClient());\n   }\n \n+  @Test\n+  public void test_getAzureCloudBlobToLocationConverter_expectedConverted()\n+  {\n+    final Properties props = new Properties();\n+    props.put(\"druid.azure.account\", AZURE_ACCOUNT_NAME);\n+    props.put(\"druid.azure.key\", AZURE_ACCOUNT_KEY);\n+    props.put(\"druid.azure.container\", AZURE_CONTAINER);\n+    injector = makeInjectorWithProperties(props);\n+    AzureCloudBlobHolderToCloudObjectLocationConverter azureCloudBlobLocationConverter1 = injector.getInstance(\n+        AzureCloudBlobHolderToCloudObjectLocationConverter.class);\n+    AzureCloudBlobHolderToCloudObjectLocationConverter azureCloudBlobLocationConverter2 = injector.getInstance(\n+        AzureCloudBlobHolderToCloudObjectLocationConverter.class);\n+    Assert.assertSame(azureCloudBlobLocationConverter1, azureCloudBlobLocationConverter2);\n+  }\n+\n+  @Test\n+  public void test_getAzureByteSourceFactory_canCreateAzureByteSource()\n+  {\n+    final Properties props = new Properties();\n+    props.put(\"druid.azure.account\", AZURE_ACCOUNT_NAME);\n+    props.put(\"druid.azure.key\", AZURE_ACCOUNT_KEY);\n+    props.put(\"druid.azure.container\", AZURE_CONTAINER);\n+    injector = makeInjectorWithProperties(props);\n+    AzureByteSourceFactory factory = injector.getInstance(AzureByteSourceFactory.class);\n+    Object object1 = factory.create(\"container1\", \"blob1\");\n+    Object object2 = factory.create(\"container2\", \"blob2\");\n+    Assert.assertNotNull(object1);\n+    Assert.assertNotNull(object2);\n+    Assert.assertNotSame(object1, object2);\n+  }\n+\n+  @Test\n+  public void test_getAzureEntityFactory_canCreateAzureEntity()\n+  {\n+    final Properties props = new Properties();\n+    props.put(\"druid.azure.account\", AZURE_ACCOUNT_NAME);\n+    props.put(\"druid.azure.key\", AZURE_ACCOUNT_KEY);\n+    props.put(\"druid.azure.container\", AZURE_CONTAINER);\n+\n+    EasyMock.expect(cloudObjectLocation1.getBucket()).andReturn(AZURE_CONTAINER);\n+    EasyMock.expect(cloudObjectLocation2.getBucket()).andReturn(AZURE_CONTAINER);\n+    EasyMock.expect(cloudObjectLocation1.getPath()).andReturn(PATH);\n+    EasyMock.expect(cloudObjectLocation2.getPath()).andReturn(PATH);\n+    replayAll();\n+\n+    injector = makeInjectorWithProperties(props);\n+    AzureEntityFactory factory = injector.getInstance(AzureEntityFactory.class);\n+    Object object1 = factory.create(cloudObjectLocation1);\n+    Object object2 = factory.create(cloudObjectLocation2);\n+    Assert.assertNotNull(object1);\n+    Assert.assertNotNull(object2);\n+    Assert.assertNotSame(object1, object2);\n+  }\n+\n+  @Test\n+  public void test_getAzureCloudBlobIteratorFactory_canCreateAzureCloudBlobIterator()\n+  {\n+    final Properties props = new Properties();\n+    props.put(\"druid.azure.account\", AZURE_ACCOUNT_NAME);\n+    props.put(\"druid.azure.key\", AZURE_ACCOUNT_KEY);\n+    props.put(\"druid.azure.container\", AZURE_CONTAINER);\n+    injector = makeInjectorWithProperties(props);\n+    AzureCloudBlobIteratorFactory factory = injector.getInstance(AzureCloudBlobIteratorFactory.class);\n+    Object object1 = factory.create(EMPTY_PREFIXES_ITERABLE, 10);\n+    Object object2 = factory.create(EMPTY_PREFIXES_ITERABLE, 10);\n+    Assert.assertNotNull(object1);\n+    Assert.assertNotNull(object2);\n+    Assert.assertNotSame(object1, object2);\n+  }\n+\n+  @Test\n+  public void test_getAzureCloudBlobIterableFactory_canCreateAzureCloudBlobIterable()\n+  {\n+    final Properties props = new Properties();\n+    props.put(\"druid.azure.account\", AZURE_ACCOUNT_NAME);\n+    props.put(\"druid.azure.key\", AZURE_ACCOUNT_KEY);\n+    props.put(\"druid.azure.container\", AZURE_CONTAINER);\n+    injector = makeInjectorWithProperties(props);\n+    AzureCloudBlobIterableFactory factory = injector.getInstance(AzureCloudBlobIterableFactory.class);\n+    AzureCloudBlobIterable object1 = factory.create(EMPTY_PREFIXES_ITERABLE, 10);\n+    AzureCloudBlobIterable object2 = factory.create(EMPTY_PREFIXES_ITERABLE, 10);\n+    Assert.assertNotNull(object1);\n+    Assert.assertNotNull(object2);\n+    Assert.assertNotSame(object1, object2);\n+  }\n+\n+  @Test\n+  public void test_getListBlobItemDruidFactory_canCreateListBlobItemDruid()\n+  {\n+    final Properties props = new Properties();\n+    props.put(\"druid.azure.account\", AZURE_ACCOUNT_NAME);\n+    props.put(\"druid.azure.key\", AZURE_ACCOUNT_KEY);\n+    props.put(\"druid.azure.container\", AZURE_CONTAINER);\n+    injector = makeInjectorWithProperties(props);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9226f9bb86234c7e1ccf156318e0bccea253999a"}, "originalPosition": 154}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU3NTQ4Ng==", "bodyText": "Test to verify the AzureInputSource is registered to the scheme azure", "url": "https://github.com/apache/druid/pull/9306#discussion_r376575486", "createdAt": "2020-02-07T19:48:36Z", "author": {"login": "suneet-s"}, "path": "extensions-contrib/azure-extensions/src/test/java/org/apache/druid/storage/azure/AzureStorageDruidModuleTest.java", "diffHunk": "@@ -101,6 +126,108 @@ public void test_getAzureStorageContainer_expectedClient()\n     Assert.assertSame(cloudBlobClient, azureStorage.getCloudBlobClient());\n   }\n \n+  @Test\n+  public void test_getAzureCloudBlobToLocationConverter_expectedConverted()\n+  {\n+    final Properties props = new Properties();\n+    props.put(\"druid.azure.account\", AZURE_ACCOUNT_NAME);\n+    props.put(\"druid.azure.key\", AZURE_ACCOUNT_KEY);\n+    props.put(\"druid.azure.container\", AZURE_CONTAINER);\n+    injector = makeInjectorWithProperties(props);\n+    AzureCloudBlobHolderToCloudObjectLocationConverter azureCloudBlobLocationConverter1 = injector.getInstance(\n+        AzureCloudBlobHolderToCloudObjectLocationConverter.class);\n+    AzureCloudBlobHolderToCloudObjectLocationConverter azureCloudBlobLocationConverter2 = injector.getInstance(\n+        AzureCloudBlobHolderToCloudObjectLocationConverter.class);\n+    Assert.assertSame(azureCloudBlobLocationConverter1, azureCloudBlobLocationConverter2);\n+  }\n+\n+  @Test\n+  public void test_getAzureByteSourceFactory_canCreateAzureByteSource()\n+  {\n+    final Properties props = new Properties();\n+    props.put(\"druid.azure.account\", AZURE_ACCOUNT_NAME);\n+    props.put(\"druid.azure.key\", AZURE_ACCOUNT_KEY);\n+    props.put(\"druid.azure.container\", AZURE_CONTAINER);\n+    injector = makeInjectorWithProperties(props);\n+    AzureByteSourceFactory factory = injector.getInstance(AzureByteSourceFactory.class);\n+    Object object1 = factory.create(\"container1\", \"blob1\");\n+    Object object2 = factory.create(\"container2\", \"blob2\");\n+    Assert.assertNotNull(object1);\n+    Assert.assertNotNull(object2);\n+    Assert.assertNotSame(object1, object2);\n+  }\n+\n+  @Test\n+  public void test_getAzureEntityFactory_canCreateAzureEntity()\n+  {\n+    final Properties props = new Properties();\n+    props.put(\"druid.azure.account\", AZURE_ACCOUNT_NAME);\n+    props.put(\"druid.azure.key\", AZURE_ACCOUNT_KEY);\n+    props.put(\"druid.azure.container\", AZURE_CONTAINER);\n+\n+    EasyMock.expect(cloudObjectLocation1.getBucket()).andReturn(AZURE_CONTAINER);\n+    EasyMock.expect(cloudObjectLocation2.getBucket()).andReturn(AZURE_CONTAINER);\n+    EasyMock.expect(cloudObjectLocation1.getPath()).andReturn(PATH);\n+    EasyMock.expect(cloudObjectLocation2.getPath()).andReturn(PATH);\n+    replayAll();\n+\n+    injector = makeInjectorWithProperties(props);\n+    AzureEntityFactory factory = injector.getInstance(AzureEntityFactory.class);\n+    Object object1 = factory.create(cloudObjectLocation1);\n+    Object object2 = factory.create(cloudObjectLocation2);\n+    Assert.assertNotNull(object1);\n+    Assert.assertNotNull(object2);\n+    Assert.assertNotSame(object1, object2);\n+  }\n+\n+  @Test\n+  public void test_getAzureCloudBlobIteratorFactory_canCreateAzureCloudBlobIterator()\n+  {\n+    final Properties props = new Properties();\n+    props.put(\"druid.azure.account\", AZURE_ACCOUNT_NAME);\n+    props.put(\"druid.azure.key\", AZURE_ACCOUNT_KEY);\n+    props.put(\"druid.azure.container\", AZURE_CONTAINER);\n+    injector = makeInjectorWithProperties(props);\n+    AzureCloudBlobIteratorFactory factory = injector.getInstance(AzureCloudBlobIteratorFactory.class);\n+    Object object1 = factory.create(EMPTY_PREFIXES_ITERABLE, 10);\n+    Object object2 = factory.create(EMPTY_PREFIXES_ITERABLE, 10);\n+    Assert.assertNotNull(object1);\n+    Assert.assertNotNull(object2);\n+    Assert.assertNotSame(object1, object2);\n+  }\n+\n+  @Test\n+  public void test_getAzureCloudBlobIterableFactory_canCreateAzureCloudBlobIterable()\n+  {\n+    final Properties props = new Properties();\n+    props.put(\"druid.azure.account\", AZURE_ACCOUNT_NAME);\n+    props.put(\"druid.azure.key\", AZURE_ACCOUNT_KEY);\n+    props.put(\"druid.azure.container\", AZURE_CONTAINER);\n+    injector = makeInjectorWithProperties(props);\n+    AzureCloudBlobIterableFactory factory = injector.getInstance(AzureCloudBlobIterableFactory.class);\n+    AzureCloudBlobIterable object1 = factory.create(EMPTY_PREFIXES_ITERABLE, 10);\n+    AzureCloudBlobIterable object2 = factory.create(EMPTY_PREFIXES_ITERABLE, 10);\n+    Assert.assertNotNull(object1);\n+    Assert.assertNotNull(object2);\n+    Assert.assertNotSame(object1, object2);\n+  }\n+\n+  @Test\n+  public void test_getListBlobItemDruidFactory_canCreateListBlobItemDruid()\n+  {\n+    final Properties props = new Properties();\n+    props.put(\"druid.azure.account\", AZURE_ACCOUNT_NAME);\n+    props.put(\"druid.azure.key\", AZURE_ACCOUNT_KEY);\n+    props.put(\"druid.azure.container\", AZURE_CONTAINER);\n+    injector = makeInjectorWithProperties(props);\n+    ListBlobItemHolderFactory factory = injector.getInstance(ListBlobItemHolderFactory.class);\n+    ListBlobItemHolder object1 = factory.create(blobItem1);\n+    ListBlobItemHolder object2 = factory.create(blobItem2);\n+    Assert.assertNotNull(object1);\n+    Assert.assertNotNull(object2);\n+    Assert.assertNotSame(object1, object2);\n+  }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9226f9bb86234c7e1ccf156318e0bccea253999a"}, "originalPosition": 162}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "da83e24079fb7c9d4123fe81ca90d9d7f1a02261", "author": {"user": {"login": "zachjsh", "name": null}}, "url": "https://github.com/apache/druid/commit/da83e24079fb7c9d4123fe81ca90d9d7f1a02261", "committedDate": "2020-02-08T01:41:16Z", "message": "* Address review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "45b0bfa0f96c74e8a301a1a286da8aa206a153cc", "author": {"user": {"login": "zachjsh", "name": null}}, "url": "https://github.com/apache/druid/commit/45b0bfa0f96c74e8a301a1a286da8aa206a153cc", "committedDate": "2020-02-11T07:19:47Z", "message": "* Address review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "de70111c3af5b5fe0ce9d1f3cfdcecdfeee62cf3", "author": {"user": {"login": "zachjsh", "name": null}}, "url": "https://github.com/apache/druid/commit/de70111c3af5b5fe0ce9d1f3cfdcecdfeee62cf3", "committedDate": "2020-02-11T07:29:45Z", "message": "* Address review comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU1NjQ1MzM2", "url": "https://github.com/apache/druid/pull/9306#pullrequestreview-355645336", "createdAt": "2020-02-09T23:50:59Z", "commit": {"oid": "da83e24079fb7c9d4123fe81ca90d9d7f1a02261"}, "state": "APPROVED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wOVQyMzo1MDo1OVrOFnXxjQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wOVQyMzo1NzoyMlrOFnXzqg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjgyODMwMQ==", "bodyText": "Shouldn't AzureStorage#log be a static member?", "url": "https://github.com/apache/druid/pull/9306#discussion_r376828301", "createdAt": "2020-02-09T23:50:59Z", "author": {"login": "suneet-s"}, "path": "extensions-contrib/azure-extensions/src/test/java/org/apache/druid/data/input/azure/AzureInputSourceTest.java", "diffHunk": "@@ -199,6 +201,19 @@ public void test_toString_returnsExpectedString()\n     Assert.assertEquals(\"AzureInputSource{uris=[], prefixes=[azure://container/blob], objects=[]}\", actualToString);\n   }\n \n+  @Test\n+  public void abidesEqualsContract()\n+  {\n+    EqualsVerifier.forClass(AzureInputSource.class)\n+                  .usingGetClass()\n+                  .withPrefabValues(Logger.class, new Logger(AzureStorage.class), new Logger(AzureStorage.class))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da83e24079fb7c9d4123fe81ca90d9d7f1a02261"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjgyODg0Mg==", "bodyText": "hmm... strange that readFromStart isn't visible in this test \ud83e\udd14", "url": "https://github.com/apache/druid/pull/9306#discussion_r376828842", "createdAt": "2020-02-09T23:57:22Z", "author": {"login": "suneet-s"}, "path": "extensions-contrib/azure-extensions/src/test/java/org/apache/druid/data/input/azure/AzureEntityTest.java", "diffHunk": "@@ -85,6 +85,21 @@ public void test_getUri_returnsLocationUri()\n \n   }\n \n+  @Test\n+  public void test_readFromStart_returnsExpectedStream() throws Exception\n+  {\n+    EasyMock.expect(location.getBucket()).andReturn(CONTAINER_NAME);\n+    EasyMock.expect(location.getPath()).andReturn(BLOB_NAME);\n+    EasyMock.expect(byteSource.openStream(0)).andReturn(INPUT_STREAM);\n+    EasyMock.expect(byteSourceFactory.create(CONTAINER_NAME, BLOB_NAME)).andReturn(byteSource);\n+    replayAll();\n+\n+    azureEntity = new AzureEntity(location, byteSourceFactory);\n+\n+    InputStream actualInputStream = azureEntity.readFrom(0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "da83e24079fb7c9d4123fe81ca90d9d7f1a02261"}, "originalPosition": 15}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU3MTIxNDI3", "url": "https://github.com/apache/druid/pull/9306#pullrequestreview-357121427", "createdAt": "2020-02-12T00:43:56Z", "commit": {"oid": "de70111c3af5b5fe0ce9d1f3cfdcecdfeee62cf3"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMlQwMDo0Mzo1NlrOFoeUJg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMlQwMTowNDozM1rOFoeqMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzk4NDAzOA==", "bodyText": "I think this log is duplicate with that in RetryingInputStream which calls this method.", "url": "https://github.com/apache/druid/pull/9306#discussion_r377984038", "createdAt": "2020-02-12T00:43:56Z", "author": {"login": "jihoonson"}, "path": "extensions-contrib/azure-extensions/src/main/java/org/apache/druid/storage/azure/AzureByteSource.java", "diffHunk": "@@ -46,11 +53,19 @@ public AzureByteSource(\n \n   @Override\n   public InputStream openStream() throws IOException\n+  {\n+    return openStream(0L);\n+  }\n+\n+  public InputStream openStream(long offset) throws IOException\n   {\n     try {\n-      return azureStorage.getBlobInputStream(containerName, blobPath);\n+      return azureStorage.getBlobInputStream(offset, containerName, blobPath);\n     }\n     catch (StorageException | URISyntaxException e) {\n+      log.warn(\"Exception when opening stream to azure resource, containerName: %s, blobPath: %s, Error: %s\",", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjU2MDM0OQ=="}, "originalCommit": {"oid": "9226f9bb86234c7e1ccf156318e0bccea253999a"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzk4OTAzOA==", "bodyText": "Please make this a static final variable.", "url": "https://github.com/apache/druid/pull/9306#discussion_r377989038", "createdAt": "2020-02-12T01:02:06Z", "author": {"login": "jihoonson"}, "path": "extensions-contrib/azure-extensions/src/main/java/org/apache/druid/storage/azure/AzureStorage.java", "diffHunk": "@@ -33,10 +36,15 @@\n import java.io.InputStream;\n import java.net.URISyntaxException;\n import java.util.ArrayList;\n+import java.util.EnumSet;\n import java.util.List;\n \n+/**\n+ * Abstracts the Azure storage layer. Makes direct calls to Azure file system.\n+ */\n public class AzureStorage\n {\n+  private static final boolean USE_FLAT_BLOB_LISTING = true;\n \n   private final Logger log = new Logger(AzureStorage.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "de70111c3af5b5fe0ce9d1f3cfdcecdfeee62cf3"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzk4OTY4MQ==", "bodyText": "Why not using CloudObjectInputSource.MAX_LISTING_LENGTH?", "url": "https://github.com/apache/druid/pull/9306#discussion_r377989681", "createdAt": "2020-02-12T01:04:33Z", "author": {"login": "jihoonson"}, "path": "extensions-contrib/azure-extensions/src/main/java/org/apache/druid/data/input/azure/AzureInputSource.java", "diffHunk": "@@ -0,0 +1,153 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.data.input.azure;\n+\n+import com.fasterxml.jackson.annotation.JacksonInject;\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.ImmutableList;\n+import org.apache.druid.data.input.InputSplit;\n+import org.apache.druid.data.input.impl.CloudObjectInputSource;\n+import org.apache.druid.data.input.impl.CloudObjectLocation;\n+import org.apache.druid.data.input.impl.SplittableInputSource;\n+import org.apache.druid.storage.azure.AzureCloudBlobHolderToCloudObjectLocationConverter;\n+import org.apache.druid.storage.azure.AzureCloudBlobIterableFactory;\n+import org.apache.druid.storage.azure.AzureStorage;\n+import org.apache.druid.storage.azure.blob.CloudBlobHolder;\n+\n+import javax.annotation.Nullable;\n+import java.net.URI;\n+import java.util.List;\n+import java.util.Objects;\n+import java.util.stream.Stream;\n+import java.util.stream.StreamSupport;\n+\n+/**\n+ * Abstracts the Azure storage system where input data is stored. Allows users to retrieve entities in\n+ * the storage system that match either a particular uri, prefix, or object.\n+ */\n+public class AzureInputSource extends CloudObjectInputSource<AzureEntity>\n+{\n+  @VisibleForTesting\n+  static final int MAX_LISTING_LENGTH = 1024;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "de70111c3af5b5fe0ce9d1f3cfdcecdfeee62cf3"}, "originalPosition": 51}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU3MTM5Mjkw", "url": "https://github.com/apache/druid/pull/9306#pullrequestreview-357139290", "createdAt": "2020-02-12T01:41:44Z", "commit": {"oid": "de70111c3af5b5fe0ce9d1f3cfdcecdfeee62cf3"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2834, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}