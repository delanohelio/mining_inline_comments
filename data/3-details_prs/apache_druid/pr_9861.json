{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE3MDM3MDkw", "number": 9861, "title": "Empty partitionDimension has less rollup compared to when explicitly specified", "bodyText": "Fixes #9846\nDescription\nFixes the native ingestion issue where if you do not explicitly specify the partitionDimension, it leads to lesser rollup compared to the case when you do.\nThere are two possible solutions to the problem. More details in the original bug report. This implements one of the solution.\nThe primary problem is when we hash a row during the generate phase, we use timestamp as part of the hashKey along with the dimensions in the dimensionSpec. When we explicitly specify partitionDimensions, we do not use timestamp. In the native ingestion path, using row timestamps messes up the bucket assignment for these rows and 2 rows with same dimension values can end up in different buckets. This leads to lesser rollup. More details in the bug report.\nIn this PR, I have made Native ingestion match what Hadoop does. Instead of sending the actual timestamp it sends the interval start corresponding to the interval bucket this timestamp falls in.\nFixed the bug #9846\n\nThis PR has:\n\n been self-reviewed.\n added documentation for new or modified features or behaviors.\n added Javadocs for most classes and all non-trivial methods. Linked related entities via Javadoc links.\n added or updated version, license, or notice information in licenses.yaml\n added comments explaining the \"why\" and the intent of the code wherever would not be obvious for an unfamiliar reader.\n added unit tests or modified existing tests to cover new code paths.\n added integration tests.\n been tested in a test Druid cluster.", "createdAt": "2020-05-13T00:03:38Z", "url": "https://github.com/apache/druid/pull/9861", "merged": true, "mergeCommit": {"oid": "bcc066a27fb9dcde76558c2616189d0b2389a644"}, "closed": true, "closedAt": "2020-06-05T19:42:43Z", "author": {"login": "mghosh4"}, "timelineItems": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcgtHViAH2gAyNDE3MDM3MDkwOjUyM2QwMGU5OWU5YTZhNDJhY2ZkOTczZDVmMDE2NmE0YWJlZmI2NmI=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcoXR4YAFqTQyNTU0NTMyOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "523d00e99e9a6a42acfd973d5f0166a4abefb66b", "author": {"user": {"login": "mghosh4", "name": "Mainak Ghosh"}}, "url": "https://github.com/apache/druid/commit/523d00e99e9a6a42acfd973d5f0166a4abefb66b", "committedDate": "2020-05-12T23:45:24Z", "message": "Empty partitionDimension has less rollup compared to the case when it is explicitly specified"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0977ef169e4870d591ad6d8f4b901c997e18d2a2", "author": {"user": {"login": "mghosh4", "name": "Mainak Ghosh"}}, "url": "https://github.com/apache/druid/commit/0977ef169e4870d591ad6d8f4b901c997e18d2a2", "committedDate": "2020-06-03T06:08:53Z", "message": "Adding a unit test for the empty partitionDimension scenario. Fixing another test which was failing"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "34588e6b078c50cf79e7fbd7d95d2521866e1d58", "author": {"user": {"login": "mghosh4", "name": "Mainak Ghosh"}}, "url": "https://github.com/apache/druid/commit/34588e6b078c50cf79e7fbd7d95d2521866e1d58", "committedDate": "2020-06-03T18:40:32Z", "message": "Fixing CI Build Inspection Issue"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI0OTI4OTM0", "url": "https://github.com/apache/druid/pull/9861#pullrequestreview-424928934", "createdAt": "2020-06-05T00:51:10Z", "commit": {"oid": "34588e6b078c50cf79e7fbd7d95d2521866e1d58"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQwMDo1MToxMFrOGfc8hQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQwMDo1NzozMFrOGfdCSg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTYzMzI4NQ==", "bodyText": "nit: please use Granularities.HOUR.", "url": "https://github.com/apache/druid/pull/9861#discussion_r435633285", "createdAt": "2020-06-05T00:51:10Z", "author": {"login": "jihoonson"}, "path": "indexing-service/src/test/java/org/apache/druid/indexing/common/task/IndexTaskTest.java", "diffHunk": "@@ -1783,6 +1788,36 @@ public void testIndexTaskWithSingleDimPartitionsSpecThrowingException() throws E\n     task.isReady(createActionClient(task));\n   }\n \n+  @Test\n+  public void testShardSpecSelectionWithNullPartitionDimension()\n+  {\n+    ShardSpec spec1 = new HashBasedNumberedShardSpec(0, 2, null, jsonMapper);\n+    ShardSpec spec2 = new HashBasedNumberedShardSpec(1, 2, null, jsonMapper);\n+\n+    Map<Interval, List<ShardSpec>> shardSpecMap = new HashMap<>();\n+    shardSpecMap.put(Intervals.of(\"2014-01-01T00:00:00.000Z/2014-01-02T00:00:00.000Z\"), Lists.newArrayList(spec1, spec2));\n+\n+    IndexTask.ShardSpecs shardSpecs = new IndexTask.ShardSpecs(shardSpecMap, Granularity.fromString(\"HOUR\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "34588e6b078c50cf79e7fbd7d95d2521866e1d58"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTYzMzUyNQ==", "bodyText": "The Java convention is the camel case. Please rename these variables to visitorId and clientType.", "url": "https://github.com/apache/druid/pull/9861#discussion_r435633525", "createdAt": "2020-06-05T00:52:09Z", "author": {"login": "jihoonson"}, "path": "indexing-service/src/test/java/org/apache/druid/indexing/common/task/IndexTaskTest.java", "diffHunk": "@@ -1783,6 +1788,36 @@ public void testIndexTaskWithSingleDimPartitionsSpecThrowingException() throws E\n     task.isReady(createActionClient(task));\n   }\n \n+  @Test\n+  public void testShardSpecSelectionWithNullPartitionDimension()\n+  {\n+    ShardSpec spec1 = new HashBasedNumberedShardSpec(0, 2, null, jsonMapper);\n+    ShardSpec spec2 = new HashBasedNumberedShardSpec(1, 2, null, jsonMapper);\n+\n+    Map<Interval, List<ShardSpec>> shardSpecMap = new HashMap<>();\n+    shardSpecMap.put(Intervals.of(\"2014-01-01T00:00:00.000Z/2014-01-02T00:00:00.000Z\"), Lists.newArrayList(spec1, spec2));\n+\n+    IndexTask.ShardSpecs shardSpecs = new IndexTask.ShardSpecs(shardSpecMap, Granularity.fromString(\"HOUR\"));\n+    String visitor_id = \"visitor_id\";\n+    String client_type = \"client_type\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "34588e6b078c50cf79e7fbd7d95d2521866e1d58"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTYzMzkzMw==", "bodyText": "Please use Assert.assertSame() instead.", "url": "https://github.com/apache/druid/pull/9861#discussion_r435633933", "createdAt": "2020-06-05T00:53:52Z", "author": {"login": "jihoonson"}, "path": "indexing-service/src/test/java/org/apache/druid/indexing/common/task/IndexTaskTest.java", "diffHunk": "@@ -1783,6 +1788,36 @@ public void testIndexTaskWithSingleDimPartitionsSpecThrowingException() throws E\n     task.isReady(createActionClient(task));\n   }\n \n+  @Test\n+  public void testShardSpecSelectionWithNullPartitionDimension()\n+  {\n+    ShardSpec spec1 = new HashBasedNumberedShardSpec(0, 2, null, jsonMapper);\n+    ShardSpec spec2 = new HashBasedNumberedShardSpec(1, 2, null, jsonMapper);\n+\n+    Map<Interval, List<ShardSpec>> shardSpecMap = new HashMap<>();\n+    shardSpecMap.put(Intervals.of(\"2014-01-01T00:00:00.000Z/2014-01-02T00:00:00.000Z\"), Lists.newArrayList(spec1, spec2));\n+\n+    IndexTask.ShardSpecs shardSpecs = new IndexTask.ShardSpecs(shardSpecMap, Granularity.fromString(\"HOUR\"));\n+    String visitor_id = \"visitor_id\";\n+    String client_type = \"client_type\";\n+    long timestamp1 = DateTimes.of(\"2014-01-01T00:00:00.000Z\").getMillis();\n+    InputRow row1 = new MapBasedInputRow(timestamp1,\n+        Lists.newArrayList(visitor_id, client_type),\n+        ImmutableMap.of(visitor_id, \"0\", client_type, \"iphone\")\n+    );\n+\n+    long timestamp2 = DateTimes.of(\"2014-01-01T00:30:20.456Z\").getMillis();\n+    InputRow row2 = new MapBasedInputRow(timestamp2,\n+        Lists.newArrayList(visitor_id, client_type),\n+        ImmutableMap.of(visitor_id, \"0\", client_type, \"iphone\")\n+    );\n+\n+    ShardSpec spec3 = shardSpecs.getShardSpec(Intervals.of(\"2014-01-01T00:00:00.000Z/2014-01-02T00:00:00.000Z\"), row1);\n+    ShardSpec spec4 = shardSpecs.getShardSpec(Intervals.of(\"2014-01-01T00:00:00.000Z/2014-01-02T00:00:00.000Z\"), row2);\n+\n+    Assert.assertEquals(true, spec3 == spec4);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "34588e6b078c50cf79e7fbd7d95d2521866e1d58"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTYzNDI2OQ==", "bodyText": "Could you please add a test that shardSpecs.getShardSpec() returns different shardSpecs for two rows when they have exactly same values but different timestamps?", "url": "https://github.com/apache/druid/pull/9861#discussion_r435634269", "createdAt": "2020-06-05T00:55:20Z", "author": {"login": "jihoonson"}, "path": "indexing-service/src/test/java/org/apache/druid/indexing/common/task/IndexTaskTest.java", "diffHunk": "@@ -1783,6 +1788,36 @@ public void testIndexTaskWithSingleDimPartitionsSpecThrowingException() throws E\n     task.isReady(createActionClient(task));\n   }\n \n+  @Test\n+  public void testShardSpecSelectionWithNullPartitionDimension()\n+  {\n+    ShardSpec spec1 = new HashBasedNumberedShardSpec(0, 2, null, jsonMapper);\n+    ShardSpec spec2 = new HashBasedNumberedShardSpec(1, 2, null, jsonMapper);\n+\n+    Map<Interval, List<ShardSpec>> shardSpecMap = new HashMap<>();\n+    shardSpecMap.put(Intervals.of(\"2014-01-01T00:00:00.000Z/2014-01-02T00:00:00.000Z\"), Lists.newArrayList(spec1, spec2));\n+\n+    IndexTask.ShardSpecs shardSpecs = new IndexTask.ShardSpecs(shardSpecMap, Granularity.fromString(\"HOUR\"));\n+    String visitor_id = \"visitor_id\";\n+    String client_type = \"client_type\";\n+    long timestamp1 = DateTimes.of(\"2014-01-01T00:00:00.000Z\").getMillis();\n+    InputRow row1 = new MapBasedInputRow(timestamp1,\n+        Lists.newArrayList(visitor_id, client_type),\n+        ImmutableMap.of(visitor_id, \"0\", client_type, \"iphone\")\n+    );\n+\n+    long timestamp2 = DateTimes.of(\"2014-01-01T00:30:20.456Z\").getMillis();\n+    InputRow row2 = new MapBasedInputRow(timestamp2,\n+        Lists.newArrayList(visitor_id, client_type),\n+        ImmutableMap.of(visitor_id, \"0\", client_type, \"iphone\")\n+    );\n+\n+    ShardSpec spec3 = shardSpecs.getShardSpec(Intervals.of(\"2014-01-01T00:00:00.000Z/2014-01-02T00:00:00.000Z\"), row1);\n+    ShardSpec spec4 = shardSpecs.getShardSpec(Intervals.of(\"2014-01-01T00:00:00.000Z/2014-01-02T00:00:00.000Z\"), row2);\n+\n+    Assert.assertEquals(true, spec3 == spec4);\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "34588e6b078c50cf79e7fbd7d95d2521866e1d58"}, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTYzNDc2Mg==", "bodyText": "Thank you for adding a unit test! This test doesn't seem testing the IndexTask but testing ShardSpecs. Would you please move the ShardSpecs out of IndexTask and add a new class ShardSpecsTest? Then we can move this test to ShardSpecsTest.", "url": "https://github.com/apache/druid/pull/9861#discussion_r435634762", "createdAt": "2020-06-05T00:57:30Z", "author": {"login": "jihoonson"}, "path": "indexing-service/src/test/java/org/apache/druid/indexing/common/task/IndexTaskTest.java", "diffHunk": "@@ -1783,6 +1788,36 @@ public void testIndexTaskWithSingleDimPartitionsSpecThrowingException() throws E\n     task.isReady(createActionClient(task));\n   }\n \n+  @Test\n+  public void testShardSpecSelectionWithNullPartitionDimension()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "34588e6b078c50cf79e7fbd7d95d2521866e1d58"}, "originalPosition": 45}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8ee874891af60f794f70918457ec8985b5391cf6", "author": {"user": {"login": "mghosh4", "name": "Mainak Ghosh"}}, "url": "https://github.com/apache/druid/commit/8ee874891af60f794f70918457ec8985b5391cf6", "committedDate": "2020-06-05T03:44:45Z", "message": "Addressing all review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3e247761b2d9c871d1794edea4d9ed5ba34a6c37", "author": {"user": {"login": "mghosh4", "name": "Mainak Ghosh"}}, "url": "https://github.com/apache/druid/commit/3e247761b2d9c871d1794edea4d9ed5ba34a6c37", "committedDate": "2020-06-05T18:12:28Z", "message": "Updating the javadocs for the hash method in HashBasedNumberedShardSpec"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1NTQ1MzI4", "url": "https://github.com/apache/druid/pull/9861#pullrequestreview-425545328", "createdAt": "2020-06-05T18:50:24Z", "commit": {"oid": "3e247761b2d9c871d1794edea4d9ed5ba34a6c37"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2331, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}