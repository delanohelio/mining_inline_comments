{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg5Njg5NzYz", "number": 9525, "title": "Azure deep storage does not work with datasource name containing non-ASCII chars", "bodyText": "Fixes #9515\nDescription\nFixed a bug where recording the segment file location fails when\nusing Azure Deep Storage, if the datasource has any special\ncharacters. Verified fix with manual test.\n\nThis PR has:\n\n been self-reviewed.\n\n using the concurrency checklist (Remove this item if the PR doesn't have any relation to concurrency.)\n\n\n added documentation for new or modified features or behaviors.\n added Javadocs for most classes and all non-trivial methods. Linked related entities via Javadoc links.\n added or updated version, license, or notice information in licenses.yaml\n added comments explaining the \"why\" and the intent of the code wherever would not be obvious for an unfamiliar reader.\n added unit tests or modified existing tests to cover new code paths.\n added integration tests.\n been tested in a test Druid cluster.", "createdAt": "2020-03-17T08:16:55Z", "url": "https://github.com/apache/druid/pull/9525", "merged": true, "mergeCommit": {"oid": "4870ad7b56f6c9e40f08be2a9d485b1112b8ba31"}, "closed": true, "closedAt": "2020-03-19T19:32:36Z", "author": {"login": "zachjsh"}, "timelineItems": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcOeNSKgH2gAyMzg5Njg5NzYzOjg1ZDBiYjc1NzQyMDA4ZDQyY2YyOTEyYTYzMGVlZjZkM2NhYjIzZTM=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcPRIMegFqTM3ODAzMTQxMw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "85d0bb75742008d42cf2912a630eef6d3cab23e3", "author": {"user": {"login": "zachjsh", "name": null}}, "url": "https://github.com/apache/druid/commit/85d0bb75742008d42cf2912a630eef6d3cab23e3", "committedDate": "2020-03-17T08:12:41Z", "message": "Azure deep storage does not work with datasource name containing non-ASCII chars\n\nFixed a bug where recording the segment file location fails when\nusing Azure Deep Storage, if the datasource has any special\ncharacters"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b542a65c291e99a75704ffae707bd4b954196b32", "author": {"user": {"login": "zachjsh", "name": null}}, "url": "https://github.com/apache/druid/commit/b542a65c291e99a75704ffae707bd4b954196b32", "committedDate": "2020-03-18T22:28:56Z", "message": "* update jacoco thresholds"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc3MzUwNDMz", "url": "https://github.com/apache/druid/pull/9525#pullrequestreview-377350433", "createdAt": "2020-03-19T01:08:40Z", "commit": {"oid": "b542a65c291e99a75704ffae707bd4b954196b32"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQwMTowODo0MFrOF4cmuw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQwMTowODo0MFrOF4cmuw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NDczMzI0Mw==", "bodyText": "Could you make the other makeLoadSpec delegate to this method instead of duplicating it?\n  @Override\n  public Map<String, Object> makeLoadSpec(URI uri)\n  {\n    return makeLoadSpec(segmentConfig.getContainer(), uri.toString());\n  }\n\nAlso, is it necessary to pass container in since both invocations are using the same value (if you make the suggested modification)?", "url": "https://github.com/apache/druid/pull/9525#discussion_r394733243", "createdAt": "2020-03-19T01:08:40Z", "author": {"login": "clintropolis"}, "path": "extensions-core/azure-extensions/src/main/java/org/apache/druid/storage/azure/AzureDataSegmentPusher.java", "diffHunk": "@@ -186,12 +186,24 @@ DataSegment uploadDataSegment(\n \n     final DataSegment outSegment = segment\n         .withSize(size)\n-        .withLoadSpec(this.makeLoadSpec(new URI(azurePath)))\n+        .withLoadSpec(this.makeLoadSpec(segmentConfig.getContainer(), azurePath))\n         .withBinaryVersion(binaryVersion);\n \n     log.debug(\"Deleting file [%s]\", compressedSegmentData);\n     compressedSegmentData.delete();\n \n     return outSegment;\n   }\n+\n+  private Map<String, Object> makeLoadSpec(String container, String prefix)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b542a65c291e99a75704ffae707bd4b954196b32"}, "originalPosition": 14}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6a4c772599e99696dea40b1cfcd7bb16e53c3e06", "author": {"user": {"login": "zachjsh", "name": null}}, "url": "https://github.com/apache/druid/commit/6a4c772599e99696dea40b1cfcd7bb16e53c3e06", "committedDate": "2020-03-19T07:05:15Z", "message": "Merge remote-tracking branch 'zach-druid/master' into IMPLY-2441"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "01124d26ad8ac79e9e35e532ba47b173757ed3d5", "author": {"user": {"login": "zachjsh", "name": null}}, "url": "https://github.com/apache/druid/commit/01124d26ad8ac79e9e35e532ba47b173757ed3d5", "committedDate": "2020-03-19T07:22:33Z", "message": "* resolve merge conflicts\n* address review comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc4MDMxNDEz", "url": "https://github.com/apache/druid/pull/9525#pullrequestreview-378031413", "createdAt": "2020-03-19T19:31:58Z", "commit": {"oid": "01124d26ad8ac79e9e35e532ba47b173757ed3d5"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxOTozMTo1OFrOF49aaQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxOTozMTo1OFrOF49aaQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTI3MDc2MQ==", "bodyText": "It looks like hadoop indexing would still call this method so it might have issues with funny characters, but I don't think it is worth refactoring to fix the issue at this point.", "url": "https://github.com/apache/druid/pull/9525#discussion_r395270761", "createdAt": "2020-03-19T19:31:58Z", "author": {"login": "clintropolis"}, "path": "extensions-core/azure-extensions/src/main/java/org/apache/druid/storage/azure/AzureDataSegmentPusher.java", "diffHunk": "@@ -153,14 +153,7 @@ public DataSegment push(final File indexFilesDir, final DataSegment segment, fin\n   @Override\n   public Map<String, Object> makeLoadSpec(URI uri)\n   {\n-    return ImmutableMap.of(\n-        \"type\",\n-        AzureStorageDruidModule.SCHEME,\n-        \"containerName\",\n-        segmentConfig.getContainer(),\n-        \"blobPath\",\n-        uri.toString()\n-    );\n+    return makeLoadSpec(uri.toString());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "01124d26ad8ac79e9e35e532ba47b173757ed3d5"}, "originalPosition": 12}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2663, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}