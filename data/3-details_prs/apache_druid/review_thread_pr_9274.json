{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzY4MjUxODgz", "number": 9274, "reviewThreads": {"totalCount": 41, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOVQwMDo0MDozN1rODba22Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQyMjo0Mjo0MFrODdgdSA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMwMDc4MTY5OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/org/apache/druid/indexer/partitions/SecondaryPartitionType.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOVQwMDo0MDozN1rOFi5Z8A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QwNToxNTo1MVrOFkmkRw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjEzNjQzMg==", "bodyText": "Maybe change to {@link GranularitySpec#getSegmentGranularity}", "url": "https://github.com/apache/druid/pull/9274#discussion_r372136432", "createdAt": "2020-01-29T00:40:37Z", "author": {"login": "ccaominh"}, "path": "core/src/main/java/org/apache/druid/indexer/partitions/SecondaryPartitionType.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexer.partitions;\n+\n+/**\n+ * In Druid, ingested data are primarily partitioned based on time range (GranularitySpec#getSegmentGranularity),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkyNDkzNQ==", "bodyText": "GranularitySpec is in the server module and cannot be linked here.", "url": "https://github.com/apache/druid/pull/9274#discussion_r373924935", "createdAt": "2020-02-03T05:15:51Z", "author": {"login": "jihoonson"}, "path": "core/src/main/java/org/apache/druid/indexer/partitions/SecondaryPartitionType.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexer.partitions;\n+\n+/**\n+ * In Druid, ingested data are primarily partitioned based on time range (GranularitySpec#getSegmentGranularity),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjEzNjQzMg=="}, "originalCommit": {"oid": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMwMDc4NzAyOnYy", "diffSide": "RIGHT", "path": "core/src/main/java/org/apache/druid/timeline/partition/PartitionBoundaries.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOVQwMDo0Mzo1NFrOFi5dDg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QwNToxNTo1NVrOFkmkVA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjEzNzIzMA==", "bodyText": "Perhaps rename to getNumBuckets()", "url": "https://github.com/apache/druid/pull/9274#discussion_r372137230", "createdAt": "2020-01-29T00:43:54Z", "author": {"login": "ccaominh"}, "path": "core/src/main/java/org/apache/druid/timeline/partition/PartitionBoundaries.java", "diffHunk": "@@ -74,4 +74,9 @@ public PartitionBoundaries(String... partitions)\n   {\n     return delegate;\n   }\n+\n+  public int numBuckets()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE0MjQ5Mw==", "bodyText": "Can also add the respective unit test to PartitionBoundariesTest", "url": "https://github.com/apache/druid/pull/9274#discussion_r372142493", "createdAt": "2020-01-29T01:04:48Z", "author": {"login": "ccaominh"}, "path": "core/src/main/java/org/apache/druid/timeline/partition/PartitionBoundaries.java", "diffHunk": "@@ -74,4 +74,9 @@ public PartitionBoundaries(String... partitions)\n   {\n     return delegate;\n   }\n+\n+  public int numBuckets()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjEzNzIzMA=="}, "originalCommit": {"oid": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkyNDk0OA==", "bodyText": "Renamed and added a unit test. This class will be modified in my next PR. I'll add more tests especially for failure cases in it.", "url": "https://github.com/apache/druid/pull/9274#discussion_r373924948", "createdAt": "2020-02-03T05:15:55Z", "author": {"login": "jihoonson"}, "path": "core/src/main/java/org/apache/druid/timeline/partition/PartitionBoundaries.java", "diffHunk": "@@ -74,4 +74,9 @@ public PartitionBoundaries(String... partitions)\n   {\n     return delegate;\n   }\n+\n+  public int numBuckets()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjEzNzIzMA=="}, "originalCommit": {"oid": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMwMDc5MDg0OnYy", "diffSide": "RIGHT", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/AbstractBatchIndexTask.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOVQwMDo0NjoxOVrOFi5fXA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QwNToxNjowMVrOFkmkXw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjEzNzgyMA==", "bodyText": "Update the error message to say \"taskLockHelper\" instead of \"segmentLockHelper\"", "url": "https://github.com/apache/druid/pull/9274#discussion_r372137820", "createdAt": "2020-01-29T00:46:19Z", "author": {"login": "ccaominh"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/AbstractBatchIndexTask.java", "diffHunk": "@@ -194,14 +179,9 @@ public int getPriority()\n     return getContextValue(Tasks.PRIORITY_KEY, Tasks.DEFAULT_BATCH_INDEX_TASK_PRIORITY);\n   }\n \n-  public boolean isUseSegmentLock()\n-  {\n-    return useSegmentLock;\n-  }\n-\n-  public SegmentLockHelper getSegmentLockHelper()\n+  public TaskLockHelper getTaskLockHelper()\n   {\n-    return segmentLockHelper;\n+    return Preconditions.checkNotNull(taskLockHelper, \"segmentLockHelper is not initialized yet\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6"}, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkyNDk1OQ==", "bodyText": "Good catch! Fixed.", "url": "https://github.com/apache/druid/pull/9274#discussion_r373924959", "createdAt": "2020-02-03T05:16:01Z", "author": {"login": "jihoonson"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/AbstractBatchIndexTask.java", "diffHunk": "@@ -194,14 +179,9 @@ public int getPriority()\n     return getContextValue(Tasks.PRIORITY_KEY, Tasks.DEFAULT_BATCH_INDEX_TASK_PRIORITY);\n   }\n \n-  public boolean isUseSegmentLock()\n-  {\n-    return useSegmentLock;\n-  }\n-\n-  public SegmentLockHelper getSegmentLockHelper()\n+  public TaskLockHelper getTaskLockHelper()\n   {\n-    return segmentLockHelper;\n+    return Preconditions.checkNotNull(taskLockHelper, \"segmentLockHelper is not initialized yet\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjEzNzgyMA=="}, "originalCommit": {"oid": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6"}, "originalPosition": 91}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMwMDgzNzI1OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionShardSpecFactory.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOVQwMToxNTo0OVrOFi58Sw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QwNToxNjowNFrOFkmkZw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE0NTIyNw==", "bodyText": "PartitionBoundaries should probably override equals for this. Can use EqualsVerifier to add a unit test.", "url": "https://github.com/apache/druid/pull/9274#discussion_r372145227", "createdAt": "2020-01-29T01:15:49Z", "author": {"login": "ccaominh"}, "path": "core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionShardSpecFactory.java", "diffHunk": "@@ -0,0 +1,107 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.timeline.partition;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+import javax.annotation.Nullable;\n+import java.util.Objects;\n+\n+public class SingleDimensionShardSpecFactory implements ShardSpecFactory\n+{\n+  private final String partitionDimension;\n+  private final PartitionBoundaries partitionBoundaries;\n+\n+  @JsonCreator\n+  public SingleDimensionShardSpecFactory(\n+      @JsonProperty(\"partitionDimension\") String partitionDimension,\n+      @JsonProperty(\"partitionBoundaries\") PartitionBoundaries partitionBoundaries\n+  )\n+  {\n+    this.partitionDimension = partitionDimension;\n+    this.partitionBoundaries = partitionBoundaries;\n+  }\n+\n+  @JsonProperty\n+  public String getPartitionDimension()\n+  {\n+    return partitionDimension;\n+  }\n+\n+  @JsonProperty\n+  public PartitionBoundaries getPartitionBoundaries()\n+  {\n+    return partitionBoundaries;\n+  }\n+\n+  @Override\n+  public ShardSpec create(ObjectMapper objectMapper, @Nullable ShardSpec specOfPreviousMaxPartitionId)\n+  {\n+    final int partitionId;\n+    if (specOfPreviousMaxPartitionId != null) {\n+      assert specOfPreviousMaxPartitionId instanceof SingleDimensionShardSpec;\n+      final SingleDimensionShardSpec prevSpec = (SingleDimensionShardSpec) specOfPreviousMaxPartitionId;\n+      partitionId = prevSpec.getPartitionNum() + 1;\n+    } else {\n+      partitionId = 0;\n+    }\n+    return create(objectMapper, partitionId);\n+  }\n+\n+  @Override\n+  public ShardSpec create(ObjectMapper objectMapper, int partitionId)\n+  {\n+    // TODO: numBuckets should be added to SingleDimensionShardSpec in a follow-up PR.\n+    return new SingleDimensionShardSpec(\n+        partitionDimension,\n+        partitionBoundaries.get(partitionId),\n+        partitionBoundaries.get(partitionId + 1),\n+        partitionId\n+    );\n+  }\n+\n+  @Override\n+  public Class<? extends ShardSpec> getShardSpecClass()\n+  {\n+    return SingleDimensionShardSpec.class;\n+  }\n+\n+  @Override\n+  public boolean equals(Object o)\n+  {\n+    if (this == o) {\n+      return true;\n+    }\n+    if (o == null || getClass() != o.getClass()) {\n+      return false;\n+    }\n+    SingleDimensionShardSpecFactory that = (SingleDimensionShardSpecFactory) o;\n+    return Objects.equals(partitionDimension, that.partitionDimension) &&\n+           Objects.equals(partitionBoundaries, that.partitionBoundaries);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6"}, "originalPosition": 99}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkyNDk2Nw==", "bodyText": "Added.", "url": "https://github.com/apache/druid/pull/9274#discussion_r373924967", "createdAt": "2020-02-03T05:16:04Z", "author": {"login": "jihoonson"}, "path": "core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionShardSpecFactory.java", "diffHunk": "@@ -0,0 +1,107 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.timeline.partition;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+import javax.annotation.Nullable;\n+import java.util.Objects;\n+\n+public class SingleDimensionShardSpecFactory implements ShardSpecFactory\n+{\n+  private final String partitionDimension;\n+  private final PartitionBoundaries partitionBoundaries;\n+\n+  @JsonCreator\n+  public SingleDimensionShardSpecFactory(\n+      @JsonProperty(\"partitionDimension\") String partitionDimension,\n+      @JsonProperty(\"partitionBoundaries\") PartitionBoundaries partitionBoundaries\n+  )\n+  {\n+    this.partitionDimension = partitionDimension;\n+    this.partitionBoundaries = partitionBoundaries;\n+  }\n+\n+  @JsonProperty\n+  public String getPartitionDimension()\n+  {\n+    return partitionDimension;\n+  }\n+\n+  @JsonProperty\n+  public PartitionBoundaries getPartitionBoundaries()\n+  {\n+    return partitionBoundaries;\n+  }\n+\n+  @Override\n+  public ShardSpec create(ObjectMapper objectMapper, @Nullable ShardSpec specOfPreviousMaxPartitionId)\n+  {\n+    final int partitionId;\n+    if (specOfPreviousMaxPartitionId != null) {\n+      assert specOfPreviousMaxPartitionId instanceof SingleDimensionShardSpec;\n+      final SingleDimensionShardSpec prevSpec = (SingleDimensionShardSpec) specOfPreviousMaxPartitionId;\n+      partitionId = prevSpec.getPartitionNum() + 1;\n+    } else {\n+      partitionId = 0;\n+    }\n+    return create(objectMapper, partitionId);\n+  }\n+\n+  @Override\n+  public ShardSpec create(ObjectMapper objectMapper, int partitionId)\n+  {\n+    // TODO: numBuckets should be added to SingleDimensionShardSpec in a follow-up PR.\n+    return new SingleDimensionShardSpec(\n+        partitionDimension,\n+        partitionBoundaries.get(partitionId),\n+        partitionBoundaries.get(partitionId + 1),\n+        partitionId\n+    );\n+  }\n+\n+  @Override\n+  public Class<? extends ShardSpec> getShardSpecClass()\n+  {\n+    return SingleDimensionShardSpec.class;\n+  }\n+\n+  @Override\n+  public boolean equals(Object o)\n+  {\n+    if (this == o) {\n+      return true;\n+    }\n+    if (o == null || getClass() != o.getClass()) {\n+      return false;\n+    }\n+    SingleDimensionShardSpecFactory that = (SingleDimensionShardSpecFactory) o;\n+    return Objects.equals(partitionDimension, that.partitionDimension) &&\n+           Objects.equals(partitionBoundaries, that.partitionBoundaries);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE0NTIyNw=="}, "originalCommit": {"oid": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6"}, "originalPosition": 99}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMwMDgzODUzOnYy", "diffSide": "RIGHT", "path": "core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionShardSpecFactory.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOVQwMToxNjozN1rOFi59Eg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QwNToxNjowN1rOFkmkbg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE0NTQyNg==", "bodyText": "Please add unit tests for the two create methods", "url": "https://github.com/apache/druid/pull/9274#discussion_r372145426", "createdAt": "2020-01-29T01:16:37Z", "author": {"login": "ccaominh"}, "path": "core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionShardSpecFactory.java", "diffHunk": "@@ -0,0 +1,107 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.timeline.partition;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+import javax.annotation.Nullable;\n+import java.util.Objects;\n+\n+public class SingleDimensionShardSpecFactory implements ShardSpecFactory\n+{\n+  private final String partitionDimension;\n+  private final PartitionBoundaries partitionBoundaries;\n+\n+  @JsonCreator\n+  public SingleDimensionShardSpecFactory(\n+      @JsonProperty(\"partitionDimension\") String partitionDimension,\n+      @JsonProperty(\"partitionBoundaries\") PartitionBoundaries partitionBoundaries\n+  )\n+  {\n+    this.partitionDimension = partitionDimension;\n+    this.partitionBoundaries = partitionBoundaries;\n+  }\n+\n+  @JsonProperty\n+  public String getPartitionDimension()\n+  {\n+    return partitionDimension;\n+  }\n+\n+  @JsonProperty\n+  public PartitionBoundaries getPartitionBoundaries()\n+  {\n+    return partitionBoundaries;\n+  }\n+\n+  @Override\n+  public ShardSpec create(ObjectMapper objectMapper, @Nullable ShardSpec specOfPreviousMaxPartitionId)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkyNDk3NA==", "bodyText": "There will be a pretty big change for these methods in my next PR. I'll add tests later.", "url": "https://github.com/apache/druid/pull/9274#discussion_r373924974", "createdAt": "2020-02-03T05:16:07Z", "author": {"login": "jihoonson"}, "path": "core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionShardSpecFactory.java", "diffHunk": "@@ -0,0 +1,107 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.timeline.partition;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+import javax.annotation.Nullable;\n+import java.util.Objects;\n+\n+public class SingleDimensionShardSpecFactory implements ShardSpecFactory\n+{\n+  private final String partitionDimension;\n+  private final PartitionBoundaries partitionBoundaries;\n+\n+  @JsonCreator\n+  public SingleDimensionShardSpecFactory(\n+      @JsonProperty(\"partitionDimension\") String partitionDimension,\n+      @JsonProperty(\"partitionBoundaries\") PartitionBoundaries partitionBoundaries\n+  )\n+  {\n+    this.partitionDimension = partitionDimension;\n+    this.partitionBoundaries = partitionBoundaries;\n+  }\n+\n+  @JsonProperty\n+  public String getPartitionDimension()\n+  {\n+    return partitionDimension;\n+  }\n+\n+  @JsonProperty\n+  public PartitionBoundaries getPartitionBoundaries()\n+  {\n+    return partitionBoundaries;\n+  }\n+\n+  @Override\n+  public ShardSpec create(ObjectMapper objectMapper, @Nullable ShardSpec specOfPreviousMaxPartitionId)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE0NTQyNg=="}, "originalCommit": {"oid": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6"}, "originalPosition": 57}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMwMDg1NjY2OnYy", "diffSide": "RIGHT", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/IndexTask.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOVQwMToyODoyM1rOFi6H-Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QwNToxNjoxMVrOFkmkgQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE0ODIxNw==", "bodyText": "What do you think about adding a method to the partition spec interface so that future addition of partition specs do not potentially require modification to this code?", "url": "https://github.com/apache/druid/pull/9274#discussion_r372148217", "createdAt": "2020-01-29T01:28:23Z", "author": {"login": "ccaominh"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/IndexTask.java", "diffHunk": "@@ -598,59 +612,74 @@ public TaskStatus runTask(final TaskToolbox toolbox)\n    *\n    * @return a map indicating how many shardSpecs need to be created per interval.\n    */\n-  private Map<Interval, Pair<ShardSpecFactory, Integer>> determineShardSpecs(\n+  private PartitionAnalysis determineShardSpecs(\n       final TaskToolbox toolbox,\n       final InputSource inputSource,\n       final File tmpDir,\n-      final PartitionsSpec nonNullPartitionsSpec\n+      @Nonnull final PartitionsSpec partitionsSpec\n   ) throws IOException\n   {\n     final ObjectMapper jsonMapper = toolbox.getJsonMapper();\n-    final IndexTuningConfig tuningConfig = ingestionSchema.getTuningConfig();\n-    final IndexIOConfig ioConfig = ingestionSchema.getIOConfig();\n \n     final GranularitySpec granularitySpec = ingestionSchema.getDataSchema().getGranularitySpec();\n \n     // Must determine intervals if unknown, since we acquire all locks before processing any data.\n     final boolean determineIntervals = !granularitySpec.bucketIntervals().isPresent();\n \n     // Must determine partitions if rollup is guaranteed and the user didn't provide a specific value.\n-    final boolean determineNumPartitions = nonNullPartitionsSpec.needsDeterminePartitions(false);\n+    final boolean determineNumPartitions = partitionsSpec.needsDeterminePartitions(false);\n \n     // if we were given number of shards per interval and the intervals, we don't need to scan the data\n     if (!determineNumPartitions && !determineIntervals) {\n       log.info(\"Skipping determine partition scan\");\n-      return createShardSpecWithoutInputScan(\n-          granularitySpec,\n-          ioConfig,\n-          tuningConfig,\n-          nonNullPartitionsSpec\n-      );\n+      if (partitionsSpec.getType() == SecondaryPartitionType.HASH) {\n+        return PartialHashSegmentGenerateTask.createHashPartitionAnalysisFromPartitionsSpec(\n+            granularitySpec,\n+            (HashedPartitionsSpec) partitionsSpec\n+        );\n+      } else if (partitionsSpec.getType() == SecondaryPartitionType.LINEAR) {\n+        return createLinearPartitionAnalysis(granularitySpec, (DynamicPartitionsSpec) partitionsSpec);\n+      } else {\n+        throw new UOE(\"%s\", partitionsSpec.getClass().getName());\n+      }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6"}, "originalPosition": 153}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkyNDk5Mw==", "bodyText": "I think it's a good idea. Unfortunately, CompletePartitionAnalysis needs TaskToolbox which is in the indexing-service module. This prevents partition analysis classes from moving to the core module.\nHowever, I think I can remove TaskToolbox from CompletePartitionAnalysis in my next PR. I'll do it later.", "url": "https://github.com/apache/druid/pull/9274#discussion_r373924993", "createdAt": "2020-02-03T05:16:11Z", "author": {"login": "jihoonson"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/IndexTask.java", "diffHunk": "@@ -598,59 +612,74 @@ public TaskStatus runTask(final TaskToolbox toolbox)\n    *\n    * @return a map indicating how many shardSpecs need to be created per interval.\n    */\n-  private Map<Interval, Pair<ShardSpecFactory, Integer>> determineShardSpecs(\n+  private PartitionAnalysis determineShardSpecs(\n       final TaskToolbox toolbox,\n       final InputSource inputSource,\n       final File tmpDir,\n-      final PartitionsSpec nonNullPartitionsSpec\n+      @Nonnull final PartitionsSpec partitionsSpec\n   ) throws IOException\n   {\n     final ObjectMapper jsonMapper = toolbox.getJsonMapper();\n-    final IndexTuningConfig tuningConfig = ingestionSchema.getTuningConfig();\n-    final IndexIOConfig ioConfig = ingestionSchema.getIOConfig();\n \n     final GranularitySpec granularitySpec = ingestionSchema.getDataSchema().getGranularitySpec();\n \n     // Must determine intervals if unknown, since we acquire all locks before processing any data.\n     final boolean determineIntervals = !granularitySpec.bucketIntervals().isPresent();\n \n     // Must determine partitions if rollup is guaranteed and the user didn't provide a specific value.\n-    final boolean determineNumPartitions = nonNullPartitionsSpec.needsDeterminePartitions(false);\n+    final boolean determineNumPartitions = partitionsSpec.needsDeterminePartitions(false);\n \n     // if we were given number of shards per interval and the intervals, we don't need to scan the data\n     if (!determineNumPartitions && !determineIntervals) {\n       log.info(\"Skipping determine partition scan\");\n-      return createShardSpecWithoutInputScan(\n-          granularitySpec,\n-          ioConfig,\n-          tuningConfig,\n-          nonNullPartitionsSpec\n-      );\n+      if (partitionsSpec.getType() == SecondaryPartitionType.HASH) {\n+        return PartialHashSegmentGenerateTask.createHashPartitionAnalysisFromPartitionsSpec(\n+            granularitySpec,\n+            (HashedPartitionsSpec) partitionsSpec\n+        );\n+      } else if (partitionsSpec.getType() == SecondaryPartitionType.LINEAR) {\n+        return createLinearPartitionAnalysis(granularitySpec, (DynamicPartitionsSpec) partitionsSpec);\n+      } else {\n+        throw new UOE(\"%s\", partitionsSpec.getClass().getName());\n+      }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE0ODIxNw=="}, "originalCommit": {"oid": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6"}, "originalPosition": 153}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMwMDg2MTU4OnYy", "diffSide": "RIGHT", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/IndexTask.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOVQwMTozMToyOFrOFi6K6A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOVQwMTozMToyOFrOFi6K6A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE0ODk2OA==", "bodyText": "What do you think about adding a method to the partition spec interface so that future addition of partition specs do not potentially require modification to this code?", "url": "https://github.com/apache/druid/pull/9274#discussion_r372148968", "createdAt": "2020-01-29T01:31:28Z", "author": {"login": "ccaominh"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/IndexTask.java", "diffHunk": "@@ -659,50 +688,49 @@ public TaskStatus runTask(final TaskToolbox toolbox)\n         inputSource,\n         tmpDir,\n         granularitySpec,\n-        nonNullPartitionsSpec,\n+        partitionsSpec,\n         determineIntervals\n     );\n-\n-    final Map<Interval, Pair<ShardSpecFactory, Integer>> allocateSpecs = new HashMap<>();\n+    final PartitionAnalysis<Integer, ?> partitionAnalysis;\n+    if (partitionsSpec.getType() == SecondaryPartitionType.LINEAR) {\n+      partitionAnalysis = new LinearPartitionAnalysis((DynamicPartitionsSpec) partitionsSpec);\n+    } else if (partitionsSpec.getType() == SecondaryPartitionType.HASH) {\n+      partitionAnalysis = new HashPartitionAnalysis((HashedPartitionsSpec) partitionsSpec);\n+    } else {\n+      throw new UOE(\"%s\", partitionsSpec.getClass().getName());\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6"}, "originalPosition": 216}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMwMDg2NjI5OnYy", "diffSide": "RIGHT", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/IndexTask.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOVQwMTozNDo0N1rOFi6Nww==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QwNToxNjoyMlrOFkmklg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE0OTY5OQ==", "bodyText": "May be useful add some unit tests to IndexTaskTest to cover the new code you've added", "url": "https://github.com/apache/druid/pull/9274#discussion_r372149699", "createdAt": "2020-01-29T01:34:47Z", "author": {"login": "ccaominh"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/IndexTask.java", "diffHunk": "@@ -264,6 +271,13 @@ public String getType()\n   @Override\n   public boolean isReady(TaskActionClient taskActionClient) throws Exception\n   {\n+    final IndexTuningConfig tuningConfig = getIngestionSchema().getTuningConfig();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkyNTAxNA==", "bodyText": "Added.", "url": "https://github.com/apache/druid/pull/9274#discussion_r373925014", "createdAt": "2020-02-03T05:16:22Z", "author": {"login": "jihoonson"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/IndexTask.java", "diffHunk": "@@ -264,6 +271,13 @@ public String getType()\n   @Override\n   public boolean isReady(TaskActionClient taskActionClient) throws Exception\n   {\n+    final IndexTuningConfig tuningConfig = getIngestionSchema().getTuningConfig();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE0OTY5OQ=="}, "originalCommit": {"oid": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6"}, "originalPosition": 66}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMwMDg4MjAwOnYy", "diffSide": "RIGHT", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/OverlordCoordinatingSegmentAllocator.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOVQwMTo0NDo1OVrOFi6XWg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QwNToxNjoyNVrOFkmkpA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE1MjE1NA==", "bodyText": "Is it worth adding unit test for this class now?", "url": "https://github.com/apache/druid/pull/9274#discussion_r372152154", "createdAt": "2020-01-29T01:44:59Z", "author": {"login": "ccaominh"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/OverlordCoordinatingSegmentAllocator.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.common.task;\n+\n+import org.apache.druid.data.input.InputRow;\n+import org.apache.druid.indexer.partitions.PartitionsSpec;\n+import org.apache.druid.indexer.partitions.SecondaryPartitionType;\n+import org.apache.druid.indexing.appenderator.ActionBasedSegmentAllocator;\n+import org.apache.druid.indexing.common.TaskToolbox;\n+import org.apache.druid.indexing.common.actions.SegmentAllocateAction;\n+import org.apache.druid.indexing.common.actions.SurrogateAction;\n+import org.apache.druid.indexing.common.task.TaskLockHelper.OverwritingRootGenerationPartitions;\n+import org.apache.druid.indexing.common.task.batch.parallel.SupervisorTaskAccess;\n+import org.apache.druid.java.util.common.ISE;\n+import org.apache.druid.segment.indexing.DataSchema;\n+import org.apache.druid.segment.indexing.granularity.GranularitySpec;\n+import org.apache.druid.segment.realtime.appenderator.SegmentAllocator;\n+import org.apache.druid.segment.realtime.appenderator.SegmentIdWithShardSpec;\n+import org.apache.druid.timeline.partition.NumberedOverwriteShardSpecFactory;\n+import org.apache.druid.timeline.partition.NumberedShardSpecFactory;\n+import org.apache.druid.timeline.partition.ShardSpecFactory;\n+import org.joda.time.Interval;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+\n+/**\n+ * Segment allocator which allocates new segments using the overlord per request.\n+ */\n+public class OverlordCoordinatingSegmentAllocator implements SegmentAllocator", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkyNTAyOA==", "bodyText": "Hmm, I'll add some in a follow-up PR.", "url": "https://github.com/apache/druid/pull/9274#discussion_r373925028", "createdAt": "2020-02-03T05:16:25Z", "author": {"login": "jihoonson"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/OverlordCoordinatingSegmentAllocator.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.common.task;\n+\n+import org.apache.druid.data.input.InputRow;\n+import org.apache.druid.indexer.partitions.PartitionsSpec;\n+import org.apache.druid.indexer.partitions.SecondaryPartitionType;\n+import org.apache.druid.indexing.appenderator.ActionBasedSegmentAllocator;\n+import org.apache.druid.indexing.common.TaskToolbox;\n+import org.apache.druid.indexing.common.actions.SegmentAllocateAction;\n+import org.apache.druid.indexing.common.actions.SurrogateAction;\n+import org.apache.druid.indexing.common.task.TaskLockHelper.OverwritingRootGenerationPartitions;\n+import org.apache.druid.indexing.common.task.batch.parallel.SupervisorTaskAccess;\n+import org.apache.druid.java.util.common.ISE;\n+import org.apache.druid.segment.indexing.DataSchema;\n+import org.apache.druid.segment.indexing.granularity.GranularitySpec;\n+import org.apache.druid.segment.realtime.appenderator.SegmentAllocator;\n+import org.apache.druid.segment.realtime.appenderator.SegmentIdWithShardSpec;\n+import org.apache.druid.timeline.partition.NumberedOverwriteShardSpecFactory;\n+import org.apache.druid.timeline.partition.NumberedShardSpecFactory;\n+import org.apache.druid.timeline.partition.ShardSpecFactory;\n+import org.joda.time.Interval;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+\n+/**\n+ * Segment allocator which allocates new segments using the overlord per request.\n+ */\n+public class OverlordCoordinatingSegmentAllocator implements SegmentAllocator", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE1MjE1NA=="}, "originalCommit": {"oid": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6"}, "originalPosition": 47}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMwMDg4NjYzOnYy", "diffSide": "RIGHT", "path": "indexing-service/src/test/java/org/apache/druid/indexing/common/task/CountingLocalTaskActionClient.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOVQwMTo0Nzo1NlrOFi6aBA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QwNToxNjozMFrOFkmksQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE1MjgzNg==", "bodyText": "Do you want to add unit tests for this class?", "url": "https://github.com/apache/druid/pull/9274#discussion_r372152836", "createdAt": "2020-01-29T01:47:56Z", "author": {"login": "ccaominh"}, "path": "indexing-service/src/test/java/org/apache/druid/indexing/common/task/CountingLocalTaskActionClient.java", "diffHunk": "@@ -0,0 +1,68 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.common.task;\n+\n+import org.apache.druid.indexing.common.actions.LocalTaskActionClient;\n+import org.apache.druid.indexing.common.actions.SurrogateAction;\n+import org.apache.druid.indexing.common.actions.TaskAction;\n+import org.apache.druid.indexing.common.actions.TaskActionClient;\n+import org.apache.druid.indexing.common.actions.TaskActionToolbox;\n+import org.apache.druid.indexing.common.actions.TaskAuditLogConfig;\n+import org.apache.druid.indexing.overlord.TaskStorage;\n+\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+public class CountingLocalTaskActionClient implements TaskActionClient", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkyNTA0MQ==", "bodyText": "This is a class for easy testing. Does it need unit tests?", "url": "https://github.com/apache/druid/pull/9274#discussion_r373925041", "createdAt": "2020-02-03T05:16:30Z", "author": {"login": "jihoonson"}, "path": "indexing-service/src/test/java/org/apache/druid/indexing/common/task/CountingLocalTaskActionClient.java", "diffHunk": "@@ -0,0 +1,68 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.common.task;\n+\n+import org.apache.druid.indexing.common.actions.LocalTaskActionClient;\n+import org.apache.druid.indexing.common.actions.SurrogateAction;\n+import org.apache.druid.indexing.common.actions.TaskAction;\n+import org.apache.druid.indexing.common.actions.TaskActionClient;\n+import org.apache.druid.indexing.common.actions.TaskActionToolbox;\n+import org.apache.druid.indexing.common.actions.TaskAuditLogConfig;\n+import org.apache.druid.indexing.overlord.TaskStorage;\n+\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+public class CountingLocalTaskActionClient implements TaskActionClient", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE1MjgzNg=="}, "originalCommit": {"oid": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMwMDg5MTY3OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/druid/segment/realtime/appenderator/SegmentAllocator.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOVQwMTo1MToxNlrOFi6dEA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOVQwMTo1MToxNlrOFi6dEA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjE1MzYxNg==", "bodyText": "Thanks for the additional helpful comments!", "url": "https://github.com/apache/druid/pull/9274#discussion_r372153616", "createdAt": "2020-01-29T01:51:16Z", "author": {"login": "ccaominh"}, "path": "server/src/main/java/org/apache/druid/segment/realtime/appenderator/SegmentAllocator.java", "diffHunk": "@@ -21,25 +21,32 @@\n \n import org.apache.druid.data.input.InputRow;\n \n+import javax.annotation.Nullable;\n import java.io.IOException;\n \n public interface SegmentAllocator\n {\n   /**\n-   * Allocates a new segment for a given timestamp.\n+   * Allocates a new segment for a given timestamp. Even though its name is \"allocate\", this method is actually", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b23fb556453c9fe5a9ecefff6ac1dd69d0cb89f6"}, "originalPosition": 11}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxMTM2OTM0OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/org/apache/druid/timeline/partition/PartialShardSpec.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wMVQxODoxMTo1M1rOFkejgA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QwNToxNjo0MFrOFkmk3Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5MzY2NA==", "bodyText": "Maybe revise the javadoc wording to match the method rename better (similar comment for the method below)", "url": "https://github.com/apache/druid/pull/9274#discussion_r373793664", "createdAt": "2020-02-01T18:11:53Z", "author": {"login": "ccaominh"}, "path": "core/src/main/java/org/apache/druid/timeline/partition/PartialShardSpec.java", "diffHunk": "@@ -20,34 +20,37 @@\n package org.apache.druid.timeline.partition;\n \n import com.fasterxml.jackson.annotation.JsonSubTypes;\n+import com.fasterxml.jackson.annotation.JsonSubTypes.Type;\n import com.fasterxml.jackson.annotation.JsonTypeInfo;\n import com.fasterxml.jackson.databind.ObjectMapper;\n \n import javax.annotation.Nullable;\n \n /**\n- * Factory to be used to allocate segments remotely in the overlord.\n+ * Class to contain all information of a {@link ShardSpec} except for the partition ID.\n+ * This class is mainly used by the indexing tasks to allocate new segments using the Overlord.\n  */\n @JsonTypeInfo(use = JsonTypeInfo.Id.NAME, property = \"type\")\n @JsonSubTypes({\n-    @JsonSubTypes.Type(name = \"numbered\", value = NumberedShardSpecFactory.class),\n-    @JsonSubTypes.Type(name = \"hashed\", value = HashBasedNumberedShardSpecFactory.class),\n-    @JsonSubTypes.Type(name = \"numbered_overwrite\", value = NumberedOverwritingShardSpecFactory.class),\n+    @Type(name = \"numbered\", value = NumberedPartialShardSpec.class),\n+    @Type(name = \"hashed\", value = HashBasedNumberedPartialShardSpec.class),\n+    @Type(name = \"single_dim\", value = SingleDimensionPartialShardSpec.class),\n+    @Type(name = \"numbered_overwrite\", value = NumberedOverwritePartialShardSpec.class),\n })\n-public interface ShardSpecFactory\n+public interface PartialShardSpec\n {\n   /**\n    * Create a new shardSpec based on {@code specOfPreviousMaxPartitionId}. If it's null, it assumes that this is the\n    * first call for the timeChunk where the new segment is created.\n    * Note that {@code specOfPreviousMaxPartitionId} can also be null for {@link OverwriteShardSpec} if all segments\n    * in the timeChunk are first-generation segments.\n    */\n-  ShardSpec create(ObjectMapper objectMapper, @Nullable ShardSpec specOfPreviousMaxPartitionId);\n+  ShardSpec complete(ObjectMapper objectMapper, @Nullable ShardSpec specOfPreviousMaxPartitionId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "58998ac74be63ce92e375d8d605daf35e69da637"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkyNTA4NQ==", "bodyText": "This method will be changed in my next PR. I'll update the javadoc in it.", "url": "https://github.com/apache/druid/pull/9274#discussion_r373925085", "createdAt": "2020-02-03T05:16:40Z", "author": {"login": "jihoonson"}, "path": "core/src/main/java/org/apache/druid/timeline/partition/PartialShardSpec.java", "diffHunk": "@@ -20,34 +20,37 @@\n package org.apache.druid.timeline.partition;\n \n import com.fasterxml.jackson.annotation.JsonSubTypes;\n+import com.fasterxml.jackson.annotation.JsonSubTypes.Type;\n import com.fasterxml.jackson.annotation.JsonTypeInfo;\n import com.fasterxml.jackson.databind.ObjectMapper;\n \n import javax.annotation.Nullable;\n \n /**\n- * Factory to be used to allocate segments remotely in the overlord.\n+ * Class to contain all information of a {@link ShardSpec} except for the partition ID.\n+ * This class is mainly used by the indexing tasks to allocate new segments using the Overlord.\n  */\n @JsonTypeInfo(use = JsonTypeInfo.Id.NAME, property = \"type\")\n @JsonSubTypes({\n-    @JsonSubTypes.Type(name = \"numbered\", value = NumberedShardSpecFactory.class),\n-    @JsonSubTypes.Type(name = \"hashed\", value = HashBasedNumberedShardSpecFactory.class),\n-    @JsonSubTypes.Type(name = \"numbered_overwrite\", value = NumberedOverwritingShardSpecFactory.class),\n+    @Type(name = \"numbered\", value = NumberedPartialShardSpec.class),\n+    @Type(name = \"hashed\", value = HashBasedNumberedPartialShardSpec.class),\n+    @Type(name = \"single_dim\", value = SingleDimensionPartialShardSpec.class),\n+    @Type(name = \"numbered_overwrite\", value = NumberedOverwritePartialShardSpec.class),\n })\n-public interface ShardSpecFactory\n+public interface PartialShardSpec\n {\n   /**\n    * Create a new shardSpec based on {@code specOfPreviousMaxPartitionId}. If it's null, it assumes that this is the\n    * first call for the timeChunk where the new segment is created.\n    * Note that {@code specOfPreviousMaxPartitionId} can also be null for {@link OverwriteShardSpec} if all segments\n    * in the timeChunk are first-generation segments.\n    */\n-  ShardSpec create(ObjectMapper objectMapper, @Nullable ShardSpec specOfPreviousMaxPartitionId);\n+  ShardSpec complete(ObjectMapper objectMapper, @Nullable ShardSpec specOfPreviousMaxPartitionId);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5MzY2NA=="}, "originalCommit": {"oid": "58998ac74be63ce92e375d8d605daf35e69da637"}, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxMTM2OTg2OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionPartialShardSpec.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wMVQxODoxMzoyN1rOFkejwA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QwNToxNjo0NFrOFkmk5w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5MzcyOA==", "bodyText": "Do you want to add a serde unit test?", "url": "https://github.com/apache/druid/pull/9274#discussion_r373793728", "createdAt": "2020-02-01T18:13:27Z", "author": {"login": "ccaominh"}, "path": "core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionPartialShardSpec.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.timeline.partition;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+import javax.annotation.Nullable;\n+\n+public class SingleDimensionPartialShardSpec implements PartialShardSpec\n+{\n+  private final String partitionDimension;\n+  private final int bucketId;\n+  @Nullable\n+  private final String start;\n+  @Nullable\n+  private final String end;\n+  private final int numBuckets;\n+\n+  @JsonCreator\n+  public SingleDimensionPartialShardSpec(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "58998ac74be63ce92e375d8d605daf35e69da637"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkyNTA5NQ==", "bodyText": "\ud83d\udc4d added.", "url": "https://github.com/apache/druid/pull/9274#discussion_r373925095", "createdAt": "2020-02-03T05:16:44Z", "author": {"login": "jihoonson"}, "path": "core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionPartialShardSpec.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.timeline.partition;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+import javax.annotation.Nullable;\n+\n+public class SingleDimensionPartialShardSpec implements PartialShardSpec\n+{\n+  private final String partitionDimension;\n+  private final int bucketId;\n+  @Nullable\n+  private final String start;\n+  @Nullable\n+  private final String end;\n+  private final int numBuckets;\n+\n+  @JsonCreator\n+  public SingleDimensionPartialShardSpec(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5MzcyOA=="}, "originalCommit": {"oid": "58998ac74be63ce92e375d8d605daf35e69da637"}, "originalPosition": 39}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxMTM3MDg3OnYy", "diffSide": "RIGHT", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/OverlordCoordinatingSegmentAllocator.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wMVQxODoxNTo0NFrOFkekWA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QwNToxNjo0NlrOFkmk8g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5Mzg4MA==", "bodyText": "This method name can be updated to match the rename to \"PartialShardSpec\"", "url": "https://github.com/apache/druid/pull/9274#discussion_r373793880", "createdAt": "2020-02-01T18:15:44Z", "author": {"login": "ccaominh"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/OverlordCoordinatingSegmentAllocator.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.common.task;\n+\n+import org.apache.druid.data.input.InputRow;\n+import org.apache.druid.indexer.partitions.PartitionsSpec;\n+import org.apache.druid.indexer.partitions.SecondaryPartitionType;\n+import org.apache.druid.indexing.appenderator.ActionBasedSegmentAllocator;\n+import org.apache.druid.indexing.common.TaskToolbox;\n+import org.apache.druid.indexing.common.actions.SegmentAllocateAction;\n+import org.apache.druid.indexing.common.actions.SurrogateAction;\n+import org.apache.druid.indexing.common.task.TaskLockHelper.OverwritingRootGenerationPartitions;\n+import org.apache.druid.indexing.common.task.batch.parallel.SupervisorTaskAccess;\n+import org.apache.druid.java.util.common.ISE;\n+import org.apache.druid.segment.indexing.DataSchema;\n+import org.apache.druid.segment.indexing.granularity.GranularitySpec;\n+import org.apache.druid.segment.realtime.appenderator.SegmentAllocator;\n+import org.apache.druid.segment.realtime.appenderator.SegmentIdWithShardSpec;\n+import org.apache.druid.timeline.partition.NumberedOverwritePartialShardSpec;\n+import org.apache.druid.timeline.partition.NumberedPartialShardSpec;\n+import org.apache.druid.timeline.partition.PartialShardSpec;\n+import org.joda.time.Interval;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+\n+/**\n+ * Segment allocator which allocates new segments using the overlord per request.\n+ */\n+public class OverlordCoordinatingSegmentAllocator implements SegmentAllocator\n+{\n+  private final ActionBasedSegmentAllocator internalAllocator;\n+\n+  OverlordCoordinatingSegmentAllocator(\n+      final TaskToolbox toolbox,\n+      final @Nullable SupervisorTaskAccess supervisorTaskAccess,\n+      final DataSchema dataSchema,\n+      final TaskLockHelper taskLockHelper,\n+      final boolean appendToExisting,\n+      final PartitionsSpec partitionsSpec\n+  )\n+  {\n+    this.internalAllocator = new ActionBasedSegmentAllocator(\n+        toolbox.getTaskActionClient(),\n+        dataSchema,\n+        (schema, row, sequenceName, previousSegmentId, skipSegmentLineageCheck) -> {\n+          final GranularitySpec granularitySpec = schema.getGranularitySpec();\n+          final Interval interval = granularitySpec\n+              .bucketInterval(row.getTimestamp())\n+              .or(granularitySpec.getSegmentGranularity().bucket(row.getTimestamp()));\n+          final PartialShardSpec partialShardSpec = createShardSpecFactory(\n+              appendToExisting,\n+              partitionsSpec,\n+              taskLockHelper,\n+              interval\n+          );\n+          if (supervisorTaskAccess != null) {\n+            return new SurrogateAction<>(\n+                supervisorTaskAccess.getSupervisorTaskId(),\n+                new SegmentAllocateAction(\n+                    schema.getDataSource(),\n+                    row.getTimestamp(),\n+                    schema.getGranularitySpec().getQueryGranularity(),\n+                    schema.getGranularitySpec().getSegmentGranularity(),\n+                    sequenceName,\n+                    previousSegmentId,\n+                    skipSegmentLineageCheck,\n+                    partialShardSpec,\n+                    taskLockHelper.getLockGranularityToUse()\n+                )\n+            );\n+          } else {\n+            return new SegmentAllocateAction(\n+                schema.getDataSource(),\n+                row.getTimestamp(),\n+                schema.getGranularitySpec().getQueryGranularity(),\n+                schema.getGranularitySpec().getSegmentGranularity(),\n+                sequenceName,\n+                previousSegmentId,\n+                skipSegmentLineageCheck,\n+                partialShardSpec,\n+                taskLockHelper.getLockGranularityToUse()\n+            );\n+          }\n+        }\n+    );\n+  }\n+\n+  @Nullable\n+  @Override\n+  public SegmentIdWithShardSpec allocate(\n+      InputRow row,\n+      String sequenceName,\n+      String previousSegmentId,\n+      boolean skipSegmentLineageCheck\n+  ) throws IOException\n+  {\n+    return internalAllocator.allocate(row, sequenceName, previousSegmentId, skipSegmentLineageCheck);\n+  }\n+\n+  private static PartialShardSpec createShardSpecFactory(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "58998ac74be63ce92e375d8d605daf35e69da637"}, "originalPosition": 118}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkyNTEwNg==", "bodyText": "Renamed.", "url": "https://github.com/apache/druid/pull/9274#discussion_r373925106", "createdAt": "2020-02-03T05:16:46Z", "author": {"login": "jihoonson"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/OverlordCoordinatingSegmentAllocator.java", "diffHunk": "@@ -0,0 +1,149 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.common.task;\n+\n+import org.apache.druid.data.input.InputRow;\n+import org.apache.druid.indexer.partitions.PartitionsSpec;\n+import org.apache.druid.indexer.partitions.SecondaryPartitionType;\n+import org.apache.druid.indexing.appenderator.ActionBasedSegmentAllocator;\n+import org.apache.druid.indexing.common.TaskToolbox;\n+import org.apache.druid.indexing.common.actions.SegmentAllocateAction;\n+import org.apache.druid.indexing.common.actions.SurrogateAction;\n+import org.apache.druid.indexing.common.task.TaskLockHelper.OverwritingRootGenerationPartitions;\n+import org.apache.druid.indexing.common.task.batch.parallel.SupervisorTaskAccess;\n+import org.apache.druid.java.util.common.ISE;\n+import org.apache.druid.segment.indexing.DataSchema;\n+import org.apache.druid.segment.indexing.granularity.GranularitySpec;\n+import org.apache.druid.segment.realtime.appenderator.SegmentAllocator;\n+import org.apache.druid.segment.realtime.appenderator.SegmentIdWithShardSpec;\n+import org.apache.druid.timeline.partition.NumberedOverwritePartialShardSpec;\n+import org.apache.druid.timeline.partition.NumberedPartialShardSpec;\n+import org.apache.druid.timeline.partition.PartialShardSpec;\n+import org.joda.time.Interval;\n+\n+import javax.annotation.Nullable;\n+import java.io.IOException;\n+\n+/**\n+ * Segment allocator which allocates new segments using the overlord per request.\n+ */\n+public class OverlordCoordinatingSegmentAllocator implements SegmentAllocator\n+{\n+  private final ActionBasedSegmentAllocator internalAllocator;\n+\n+  OverlordCoordinatingSegmentAllocator(\n+      final TaskToolbox toolbox,\n+      final @Nullable SupervisorTaskAccess supervisorTaskAccess,\n+      final DataSchema dataSchema,\n+      final TaskLockHelper taskLockHelper,\n+      final boolean appendToExisting,\n+      final PartitionsSpec partitionsSpec\n+  )\n+  {\n+    this.internalAllocator = new ActionBasedSegmentAllocator(\n+        toolbox.getTaskActionClient(),\n+        dataSchema,\n+        (schema, row, sequenceName, previousSegmentId, skipSegmentLineageCheck) -> {\n+          final GranularitySpec granularitySpec = schema.getGranularitySpec();\n+          final Interval interval = granularitySpec\n+              .bucketInterval(row.getTimestamp())\n+              .or(granularitySpec.getSegmentGranularity().bucket(row.getTimestamp()));\n+          final PartialShardSpec partialShardSpec = createShardSpecFactory(\n+              appendToExisting,\n+              partitionsSpec,\n+              taskLockHelper,\n+              interval\n+          );\n+          if (supervisorTaskAccess != null) {\n+            return new SurrogateAction<>(\n+                supervisorTaskAccess.getSupervisorTaskId(),\n+                new SegmentAllocateAction(\n+                    schema.getDataSource(),\n+                    row.getTimestamp(),\n+                    schema.getGranularitySpec().getQueryGranularity(),\n+                    schema.getGranularitySpec().getSegmentGranularity(),\n+                    sequenceName,\n+                    previousSegmentId,\n+                    skipSegmentLineageCheck,\n+                    partialShardSpec,\n+                    taskLockHelper.getLockGranularityToUse()\n+                )\n+            );\n+          } else {\n+            return new SegmentAllocateAction(\n+                schema.getDataSource(),\n+                row.getTimestamp(),\n+                schema.getGranularitySpec().getQueryGranularity(),\n+                schema.getGranularitySpec().getSegmentGranularity(),\n+                sequenceName,\n+                previousSegmentId,\n+                skipSegmentLineageCheck,\n+                partialShardSpec,\n+                taskLockHelper.getLockGranularityToUse()\n+            );\n+          }\n+        }\n+    );\n+  }\n+\n+  @Nullable\n+  @Override\n+  public SegmentIdWithShardSpec allocate(\n+      InputRow row,\n+      String sequenceName,\n+      String previousSegmentId,\n+      boolean skipSegmentLineageCheck\n+  ) throws IOException\n+  {\n+    return internalAllocator.allocate(row, sequenceName, previousSegmentId, skipSegmentLineageCheck);\n+  }\n+\n+  private static PartialShardSpec createShardSpecFactory(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5Mzg4MA=="}, "originalCommit": {"oid": "58998ac74be63ce92e375d8d605daf35e69da637"}, "originalPosition": 118}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxMTM3MzYwOnYy", "diffSide": "RIGHT", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/PartialHashSegmentGenerateTask.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wMVQxODoyMTo1N1rOFkelog==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QwNToxNjo1MFrOFkmk-Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NDIxMA==", "bodyText": "Is it worth adding a unit test for this method now?", "url": "https://github.com/apache/druid/pull/9274#discussion_r373794210", "createdAt": "2020-02-01T18:21:57Z", "author": {"login": "ccaominh"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/PartialHashSegmentGenerateTask.java", "diffHunk": "@@ -125,14 +127,18 @@ public boolean isReady(TaskActionClient taskActionClient) throws Exception\n   }\n \n   @Override\n-  IndexTaskSegmentAllocator createSegmentAllocator(TaskToolbox toolbox) throws IOException\n+  CachingSegmentAllocator createSegmentAllocator(TaskToolbox toolbox, ParallelIndexSupervisorTaskClient taskClient)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "58998ac74be63ce92e375d8d605daf35e69da637"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkyNTExMw==", "bodyText": "Do you mean for createSegmentAllocator()? Is it covered by HashPartitionMultiPhaseParallelIndexingTest? BTW, the return type of this method will also be changed to SegmentAllocator in my follow-up PR.", "url": "https://github.com/apache/druid/pull/9274#discussion_r373925113", "createdAt": "2020-02-03T05:16:50Z", "author": {"login": "jihoonson"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/PartialHashSegmentGenerateTask.java", "diffHunk": "@@ -125,14 +127,18 @@ public boolean isReady(TaskActionClient taskActionClient) throws Exception\n   }\n \n   @Override\n-  IndexTaskSegmentAllocator createSegmentAllocator(TaskToolbox toolbox) throws IOException\n+  CachingSegmentAllocator createSegmentAllocator(TaskToolbox toolbox, ParallelIndexSupervisorTaskClient taskClient)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NDIxMA=="}, "originalCommit": {"oid": "58998ac74be63ce92e375d8d605daf35e69da637"}, "originalPosition": 34}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxMTM3Mzc2OnYy", "diffSide": "RIGHT", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/PartialHashSegmentGenerateTask.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wMVQxODoyMjo1MVrOFkelvA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QwNToxNjo1NFrOFkmlAw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NDIzNg==", "bodyText": "Is it worth adding a unit test for this method now?", "url": "https://github.com/apache/druid/pull/9274#discussion_r373794236", "createdAt": "2020-02-01T18:22:51Z", "author": {"login": "ccaominh"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/PartialHashSegmentGenerateTask.java", "diffHunk": "@@ -158,17 +164,24 @@ private HashPartitionStat createPartitionStat(TaskToolbox toolbox, DataSegment s\n     );\n   }\n \n-  private Map<Interval, Pair<ShardSpecFactory, Integer>> createShardSpecs()\n+  /**\n+   * Creates shard specs based on the given configurations. The return value is a map between intervals created\n+   * based on the segment granularity and the shard specs to be created.\n+   * Note that the shard specs to be created is a pair of {@link PartialShardSpec} and number of segments per interval\n+   * and filled only when {@link #isGuaranteedRollup} = true. Otherwise, the return value contains only the set of\n+   * intervals generated based on the segment granularity.\n+   */\n+  public static HashPartitionAnalysis createHashPartitionAnalysisFromPartitionsSpec(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "58998ac74be63ce92e375d8d605daf35e69da637"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkyNTEyMw==", "bodyText": "Added.", "url": "https://github.com/apache/druid/pull/9274#discussion_r373925123", "createdAt": "2020-02-03T05:16:54Z", "author": {"login": "jihoonson"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/PartialHashSegmentGenerateTask.java", "diffHunk": "@@ -158,17 +164,24 @@ private HashPartitionStat createPartitionStat(TaskToolbox toolbox, DataSegment s\n     );\n   }\n \n-  private Map<Interval, Pair<ShardSpecFactory, Integer>> createShardSpecs()\n+  /**\n+   * Creates shard specs based on the given configurations. The return value is a map between intervals created\n+   * based on the segment granularity and the shard specs to be created.\n+   * Note that the shard specs to be created is a pair of {@link PartialShardSpec} and number of segments per interval\n+   * and filled only when {@link #isGuaranteedRollup} = true. Otherwise, the return value contains only the set of\n+   * intervals generated based on the segment granularity.\n+   */\n+  public static HashPartitionAnalysis createHashPartitionAnalysisFromPartitionsSpec(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NDIzNg=="}, "originalCommit": {"oid": "58998ac74be63ce92e375d8d605daf35e69da637"}, "originalPosition": 65}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxMTM3Mzg3OnYy", "diffSide": "RIGHT", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/PartialRangeSegmentGenerateTask.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wMVQxODoyMzowNlrOFkelyg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QwNToxNjo1N1rOFkmlCA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NDI1MA==", "bodyText": "Is it worth adding a unit test for this method now?", "url": "https://github.com/apache/druid/pull/9274#discussion_r373794250", "createdAt": "2020-02-01T18:23:06Z", "author": {"login": "ccaominh"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/PartialRangeSegmentGenerateTask.java", "diffHunk": "@@ -149,15 +150,19 @@ public boolean isReady(TaskActionClient taskActionClient)\n   }\n \n   @Override\n-  IndexTaskSegmentAllocator createSegmentAllocator(TaskToolbox toolbox) throws IOException\n+  CachingSegmentAllocator createSegmentAllocator(TaskToolbox toolbox, ParallelIndexSupervisorTaskClient taskClient)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "58998ac74be63ce92e375d8d605daf35e69da637"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkyNTEyOA==", "bodyText": "Is it covered by RangePartitionMultiPhaseParallelIndexingTest?", "url": "https://github.com/apache/druid/pull/9274#discussion_r373925128", "createdAt": "2020-02-03T05:16:57Z", "author": {"login": "jihoonson"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/PartialRangeSegmentGenerateTask.java", "diffHunk": "@@ -149,15 +150,19 @@ public boolean isReady(TaskActionClient taskActionClient)\n   }\n \n   @Override\n-  IndexTaskSegmentAllocator createSegmentAllocator(TaskToolbox toolbox) throws IOException\n+  CachingSegmentAllocator createSegmentAllocator(TaskToolbox toolbox, ParallelIndexSupervisorTaskClient taskClient)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NDI1MA=="}, "originalCommit": {"oid": "58998ac74be63ce92e375d8d605daf35e69da637"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxMTM3NjA3OnYy", "diffSide": "RIGHT", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/partition/HashPartitionAnalysis.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wMVQxODoyOToxMFrOFkem8A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QwNToxNjo1OVrOFkmlDg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NDU0NA==", "bodyText": "Is it worth adding a unit test for this method?", "url": "https://github.com/apache/druid/pull/9274#discussion_r373794544", "createdAt": "2020-02-01T18:29:10Z", "author": {"login": "ccaominh"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/partition/HashPartitionAnalysis.java", "diffHunk": "@@ -0,0 +1,127 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.common.task.batch.partition;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Maps;\n+import org.apache.druid.indexer.partitions.HashedPartitionsSpec;\n+import org.apache.druid.indexing.common.TaskToolbox;\n+import org.apache.druid.segment.realtime.appenderator.SegmentIdWithShardSpec;\n+import org.apache.druid.timeline.partition.HashBasedNumberedShardSpec;\n+import org.joda.time.Interval;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.BiConsumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n+\n+public class HashPartitionAnalysis implements CompletePartitionAnalysis<Integer, HashedPartitionsSpec>\n+{\n+  /**\n+   * Key is the time ranges for the primary partitioning.\n+   * Value is the number of partitions per time range for the secondary partitioning\n+   */\n+  private final Map<Interval, Integer> intervalToNumBuckets = new HashMap<>();\n+  private final HashedPartitionsSpec partitionsSpec;\n+\n+  public HashPartitionAnalysis(HashedPartitionsSpec partitionsSpec)\n+  {\n+    this.partitionsSpec = partitionsSpec;\n+  }\n+\n+  @Override\n+  public HashedPartitionsSpec getPartitionsSpec()\n+  {\n+    return partitionsSpec;\n+  }\n+\n+  @Override\n+  public void updateBucket(Interval interval, Integer bucketAnalysis)\n+  {\n+    intervalToNumBuckets.put(interval, bucketAnalysis);\n+  }\n+\n+  @Override\n+  public Integer getBucketAnalysis(Interval interval)\n+  {\n+    return Preconditions.checkNotNull(\n+        intervalToNumBuckets.get(interval),\n+        \"Missing numBuckets for interval[%s]\",\n+        interval\n+    );\n+  }\n+\n+  @Override\n+  public Set<Interval> getAllIntervalsToIndex()\n+  {\n+    return Collections.unmodifiableSet(intervalToNumBuckets.keySet());\n+  }\n+\n+  @Override\n+  public int numTimePartitions()\n+  {\n+    return intervalToNumBuckets.size();\n+  }\n+\n+  public void forEach(BiConsumer<Interval, Integer> consumer)\n+  {\n+    intervalToNumBuckets.forEach(consumer);\n+  }\n+\n+  @Override\n+  public Map<Interval, List<SegmentIdWithShardSpec>> convertToIntervalToSegmentIds(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "58998ac74be63ce92e375d8d605daf35e69da637"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkyNTEzNA==", "bodyText": "This method will be removed in my follow-up PR.", "url": "https://github.com/apache/druid/pull/9274#discussion_r373925134", "createdAt": "2020-02-03T05:16:59Z", "author": {"login": "jihoonson"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/partition/HashPartitionAnalysis.java", "diffHunk": "@@ -0,0 +1,127 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.common.task.batch.partition;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Maps;\n+import org.apache.druid.indexer.partitions.HashedPartitionsSpec;\n+import org.apache.druid.indexing.common.TaskToolbox;\n+import org.apache.druid.segment.realtime.appenderator.SegmentIdWithShardSpec;\n+import org.apache.druid.timeline.partition.HashBasedNumberedShardSpec;\n+import org.joda.time.Interval;\n+\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.BiConsumer;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.IntStream;\n+\n+public class HashPartitionAnalysis implements CompletePartitionAnalysis<Integer, HashedPartitionsSpec>\n+{\n+  /**\n+   * Key is the time ranges for the primary partitioning.\n+   * Value is the number of partitions per time range for the secondary partitioning\n+   */\n+  private final Map<Interval, Integer> intervalToNumBuckets = new HashMap<>();\n+  private final HashedPartitionsSpec partitionsSpec;\n+\n+  public HashPartitionAnalysis(HashedPartitionsSpec partitionsSpec)\n+  {\n+    this.partitionsSpec = partitionsSpec;\n+  }\n+\n+  @Override\n+  public HashedPartitionsSpec getPartitionsSpec()\n+  {\n+    return partitionsSpec;\n+  }\n+\n+  @Override\n+  public void updateBucket(Interval interval, Integer bucketAnalysis)\n+  {\n+    intervalToNumBuckets.put(interval, bucketAnalysis);\n+  }\n+\n+  @Override\n+  public Integer getBucketAnalysis(Interval interval)\n+  {\n+    return Preconditions.checkNotNull(\n+        intervalToNumBuckets.get(interval),\n+        \"Missing numBuckets for interval[%s]\",\n+        interval\n+    );\n+  }\n+\n+  @Override\n+  public Set<Interval> getAllIntervalsToIndex()\n+  {\n+    return Collections.unmodifiableSet(intervalToNumBuckets.keySet());\n+  }\n+\n+  @Override\n+  public int numTimePartitions()\n+  {\n+    return intervalToNumBuckets.size();\n+  }\n+\n+  public void forEach(BiConsumer<Interval, Integer> consumer)\n+  {\n+    intervalToNumBuckets.forEach(consumer);\n+  }\n+\n+  @Override\n+  public Map<Interval, List<SegmentIdWithShardSpec>> convertToIntervalToSegmentIds(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NDU0NA=="}, "originalCommit": {"oid": "58998ac74be63ce92e375d8d605daf35e69da637"}, "originalPosition": 94}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxMTM3NzIzOnYy", "diffSide": "RIGHT", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/partition/PartitionAnalysis.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wMVQxODozMjowOFrOFkenlA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QwNToxNzowMlrOFkmlFg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NDcwOA==", "bodyText": "Do you want to add javadocs (especially for these methods)", "url": "https://github.com/apache/druid/pull/9274#discussion_r373794708", "createdAt": "2020-02-01T18:32:08Z", "author": {"login": "ccaominh"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/partition/PartitionAnalysis.java", "diffHunk": "@@ -0,0 +1,45 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.common.task.batch.partition;\n+\n+import org.apache.druid.indexer.partitions.PartitionsSpec;\n+import org.joda.time.Interval;\n+\n+import java.util.Set;\n+\n+/**\n+ * Analysis of the partitions to create. The implementation is mutable and updated by the indexing\n+ * {@link org.apache.druid.indexing.common.task.Task}.\n+ *\n+ * This interface provides all time chunks for the primary partitioning and the bucket information per time chunk\n+ * for the secondary partitioning.\n+ */\n+public interface PartitionAnalysis<T, P extends PartitionsSpec>\n+{\n+  P getPartitionsSpec();\n+\n+  void updateBucket(Interval interval, T bucketAnalysis);\n+\n+  T getBucketAnalysis(Interval interval);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "58998ac74be63ce92e375d8d605daf35e69da637"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NDc0Mw==", "bodyText": "I assume getBucketAnalysis is used by a follow up PR?", "url": "https://github.com/apache/druid/pull/9274#discussion_r373794743", "createdAt": "2020-02-01T18:32:52Z", "author": {"login": "ccaominh"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/partition/PartitionAnalysis.java", "diffHunk": "@@ -0,0 +1,45 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.common.task.batch.partition;\n+\n+import org.apache.druid.indexer.partitions.PartitionsSpec;\n+import org.joda.time.Interval;\n+\n+import java.util.Set;\n+\n+/**\n+ * Analysis of the partitions to create. The implementation is mutable and updated by the indexing\n+ * {@link org.apache.druid.indexing.common.task.Task}.\n+ *\n+ * This interface provides all time chunks for the primary partitioning and the bucket information per time chunk\n+ * for the secondary partitioning.\n+ */\n+public interface PartitionAnalysis<T, P extends PartitionsSpec>\n+{\n+  P getPartitionsSpec();\n+\n+  void updateBucket(Interval interval, T bucketAnalysis);\n+\n+  T getBucketAnalysis(Interval interval);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NDcwOA=="}, "originalCommit": {"oid": "58998ac74be63ce92e375d8d605daf35e69da637"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkyNTE0Mg==", "bodyText": "Yes, it will be used in the follow-up PR. Added a simple javadoc and will add more details in the next PR because it will be more clear in it.", "url": "https://github.com/apache/druid/pull/9274#discussion_r373925142", "createdAt": "2020-02-03T05:17:02Z", "author": {"login": "jihoonson"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/partition/PartitionAnalysis.java", "diffHunk": "@@ -0,0 +1,45 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.common.task.batch.partition;\n+\n+import org.apache.druid.indexer.partitions.PartitionsSpec;\n+import org.joda.time.Interval;\n+\n+import java.util.Set;\n+\n+/**\n+ * Analysis of the partitions to create. The implementation is mutable and updated by the indexing\n+ * {@link org.apache.druid.indexing.common.task.Task}.\n+ *\n+ * This interface provides all time chunks for the primary partitioning and the bucket information per time chunk\n+ * for the secondary partitioning.\n+ */\n+public interface PartitionAnalysis<T, P extends PartitionsSpec>\n+{\n+  P getPartitionsSpec();\n+\n+  void updateBucket(Interval interval, T bucketAnalysis);\n+\n+  T getBucketAnalysis(Interval interval);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NDcwOA=="}, "originalCommit": {"oid": "58998ac74be63ce92e375d8d605daf35e69da637"}, "originalPosition": 40}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxMTM3OTMxOnYy", "diffSide": "RIGHT", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/partition/RangePartitionAnalysis.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wMVQxODozODoxOFrOFkeowA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QwNToxNzowNlrOFkmlIA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NTAwOA==", "bodyText": "Can this be private?", "url": "https://github.com/apache/druid/pull/9274#discussion_r373795008", "createdAt": "2020-02-01T18:38:18Z", "author": {"login": "ccaominh"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/partition/RangePartitionAnalysis.java", "diffHunk": "@@ -17,80 +17,109 @@\n  * under the License.\n  */\n \n-package org.apache.druid.indexing.common.task;\n+package org.apache.druid.indexing.common.task.batch.partition;\n \n import com.google.common.collect.Maps;\n-import org.apache.druid.data.input.InputRow;\n+import org.apache.druid.indexer.partitions.SingleDimensionPartitionsSpec;\n import org.apache.druid.indexing.common.TaskToolbox;\n-import org.apache.druid.indexing.common.task.batch.parallel.distribution.PartitionBoundaries;\n import org.apache.druid.segment.realtime.appenderator.SegmentIdWithShardSpec;\n+import org.apache.druid.timeline.partition.PartitionBoundaries;\n import org.apache.druid.timeline.partition.SingleDimensionShardSpec;\n import org.joda.time.Interval;\n \n import javax.annotation.Nullable;\n-import java.io.IOException;\n import java.util.Collections;\n+import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n+import java.util.Set;\n+import java.util.function.BiConsumer;\n import java.util.function.Function;\n import java.util.stream.Collectors;\n import java.util.stream.IntStream;\n \n-/**\n- * Allocates all necessary range-partitioned segments locally at the beginning and reuses them.\n- *\n- * @see CachingLocalSegmentAllocatorHelper\n- */\n-public class RangePartitionCachingLocalSegmentAllocator implements IndexTaskSegmentAllocator\n+public class RangePartitionAnalysis\n+    implements CompletePartitionAnalysis<PartitionBoundaries, SingleDimensionPartitionsSpec>\n {\n-  private final String dataSource;\n-  private final String partitionDimension;\n-  private final Map<Interval, PartitionBoundaries> intervalsToPartitions;\n-  private final IndexTaskSegmentAllocator delegate;\n+  private final Map<Interval, PartitionBoundaries> intervalToPartitionBoundaries = new HashMap<>();\n+  private final SingleDimensionPartitionsSpec partitionsSpec;\n+\n+  public RangePartitionAnalysis(SingleDimensionPartitionsSpec partitionsSpec)\n+  {\n+    this.partitionsSpec = partitionsSpec;\n+  }\n+\n+  @Override\n+  public SingleDimensionPartitionsSpec getPartitionsSpec()\n+  {\n+    return partitionsSpec;\n+  }\n+\n+  @Override\n+  public void updateBucket(Interval interval, PartitionBoundaries bucketAnalysis)\n+  {\n+    intervalToPartitionBoundaries.put(interval, bucketAnalysis);\n+  }\n+\n+  @Override\n+  public PartitionBoundaries getBucketAnalysis(Interval interval)\n+  {\n+    return intervalToPartitionBoundaries.get(interval);\n+  }\n+\n+  @Override\n+  public Set<Interval> getAllIntervalsToIndex()\n+  {\n+    return Collections.unmodifiableSet(intervalToPartitionBoundaries.keySet());\n+  }\n+\n+  public void forEach(BiConsumer<Interval, PartitionBoundaries> consumer)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "58998ac74be63ce92e375d8d605daf35e69da637"}, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkyNTE1Mg==", "bodyText": "Fixed.", "url": "https://github.com/apache/druid/pull/9274#discussion_r373925152", "createdAt": "2020-02-03T05:17:06Z", "author": {"login": "jihoonson"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/partition/RangePartitionAnalysis.java", "diffHunk": "@@ -17,80 +17,109 @@\n  * under the License.\n  */\n \n-package org.apache.druid.indexing.common.task;\n+package org.apache.druid.indexing.common.task.batch.partition;\n \n import com.google.common.collect.Maps;\n-import org.apache.druid.data.input.InputRow;\n+import org.apache.druid.indexer.partitions.SingleDimensionPartitionsSpec;\n import org.apache.druid.indexing.common.TaskToolbox;\n-import org.apache.druid.indexing.common.task.batch.parallel.distribution.PartitionBoundaries;\n import org.apache.druid.segment.realtime.appenderator.SegmentIdWithShardSpec;\n+import org.apache.druid.timeline.partition.PartitionBoundaries;\n import org.apache.druid.timeline.partition.SingleDimensionShardSpec;\n import org.joda.time.Interval;\n \n import javax.annotation.Nullable;\n-import java.io.IOException;\n import java.util.Collections;\n+import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n+import java.util.Set;\n+import java.util.function.BiConsumer;\n import java.util.function.Function;\n import java.util.stream.Collectors;\n import java.util.stream.IntStream;\n \n-/**\n- * Allocates all necessary range-partitioned segments locally at the beginning and reuses them.\n- *\n- * @see CachingLocalSegmentAllocatorHelper\n- */\n-public class RangePartitionCachingLocalSegmentAllocator implements IndexTaskSegmentAllocator\n+public class RangePartitionAnalysis\n+    implements CompletePartitionAnalysis<PartitionBoundaries, SingleDimensionPartitionsSpec>\n {\n-  private final String dataSource;\n-  private final String partitionDimension;\n-  private final Map<Interval, PartitionBoundaries> intervalsToPartitions;\n-  private final IndexTaskSegmentAllocator delegate;\n+  private final Map<Interval, PartitionBoundaries> intervalToPartitionBoundaries = new HashMap<>();\n+  private final SingleDimensionPartitionsSpec partitionsSpec;\n+\n+  public RangePartitionAnalysis(SingleDimensionPartitionsSpec partitionsSpec)\n+  {\n+    this.partitionsSpec = partitionsSpec;\n+  }\n+\n+  @Override\n+  public SingleDimensionPartitionsSpec getPartitionsSpec()\n+  {\n+    return partitionsSpec;\n+  }\n+\n+  @Override\n+  public void updateBucket(Interval interval, PartitionBoundaries bucketAnalysis)\n+  {\n+    intervalToPartitionBoundaries.put(interval, bucketAnalysis);\n+  }\n+\n+  @Override\n+  public PartitionBoundaries getBucketAnalysis(Interval interval)\n+  {\n+    return intervalToPartitionBoundaries.get(interval);\n+  }\n+\n+  @Override\n+  public Set<Interval> getAllIntervalsToIndex()\n+  {\n+    return Collections.unmodifiableSet(intervalToPartitionBoundaries.keySet());\n+  }\n+\n+  public void forEach(BiConsumer<Interval, PartitionBoundaries> consumer)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NTAwOA=="}, "originalCommit": {"oid": "58998ac74be63ce92e375d8d605daf35e69da637"}, "originalPosition": 74}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxMTM4MDk1OnYy", "diffSide": "RIGHT", "path": "indexing-service/src/test/java/org/apache/druid/indexing/common/task/CountingLocalTaskActionClient.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wMVQxODo0MjozMlrOFkepsA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QwNToxNzowOVrOFkmlJg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NTI0OA==", "bodyText": "Is this only needed for tests? If so, maybe add @VisibleForTesting", "url": "https://github.com/apache/druid/pull/9274#discussion_r373795248", "createdAt": "2020-02-01T18:42:32Z", "author": {"login": "ccaominh"}, "path": "indexing-service/src/test/java/org/apache/druid/indexing/common/task/CountingLocalTaskActionClient.java", "diffHunk": "@@ -0,0 +1,68 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.common.task;\n+\n+import org.apache.druid.indexing.common.actions.LocalTaskActionClient;\n+import org.apache.druid.indexing.common.actions.SurrogateAction;\n+import org.apache.druid.indexing.common.actions.TaskAction;\n+import org.apache.druid.indexing.common.actions.TaskActionClient;\n+import org.apache.druid.indexing.common.actions.TaskActionToolbox;\n+import org.apache.druid.indexing.common.actions.TaskAuditLogConfig;\n+import org.apache.druid.indexing.overlord.TaskStorage;\n+\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+public class CountingLocalTaskActionClient implements TaskActionClient\n+{\n+  private final ConcurrentHashMap<Class<? extends TaskAction>, AtomicInteger> actionCountMap =\n+      new ConcurrentHashMap<>();\n+  private final LocalTaskActionClient delegate;\n+\n+  public CountingLocalTaskActionClient(\n+      Task task,\n+      TaskStorage storage,\n+      TaskActionToolbox toolbox\n+  )\n+  {\n+    delegate = new LocalTaskActionClient(task, storage, toolbox, new TaskAuditLogConfig(false));\n+  }\n+\n+  @Override\n+  public <RetType> RetType submit(TaskAction<RetType> taskAction)\n+  {\n+    final RetType result = delegate.submit(taskAction);\n+    final TaskAction actionKey;\n+    if (taskAction instanceof SurrogateAction) {\n+      actionKey = ((SurrogateAction) taskAction).getTaskAction();\n+    } else {\n+      actionKey = taskAction;\n+    }\n+    actionCountMap.computeIfAbsent(actionKey.getClass(), k -> new AtomicInteger()).incrementAndGet();\n+    return result;\n+  }\n+\n+  public int getActionCount(Class<? extends TaskAction> actionClass)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "58998ac74be63ce92e375d8d605daf35e69da637"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkyNTE1OA==", "bodyText": "This class is defined in a test package. Renamed to CountingLocalTaskActionClientForTest for clarity.", "url": "https://github.com/apache/druid/pull/9274#discussion_r373925158", "createdAt": "2020-02-03T05:17:09Z", "author": {"login": "jihoonson"}, "path": "indexing-service/src/test/java/org/apache/druid/indexing/common/task/CountingLocalTaskActionClient.java", "diffHunk": "@@ -0,0 +1,68 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.common.task;\n+\n+import org.apache.druid.indexing.common.actions.LocalTaskActionClient;\n+import org.apache.druid.indexing.common.actions.SurrogateAction;\n+import org.apache.druid.indexing.common.actions.TaskAction;\n+import org.apache.druid.indexing.common.actions.TaskActionClient;\n+import org.apache.druid.indexing.common.actions.TaskActionToolbox;\n+import org.apache.druid.indexing.common.actions.TaskAuditLogConfig;\n+import org.apache.druid.indexing.overlord.TaskStorage;\n+\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.atomic.AtomicInteger;\n+\n+public class CountingLocalTaskActionClient implements TaskActionClient\n+{\n+  private final ConcurrentHashMap<Class<? extends TaskAction>, AtomicInteger> actionCountMap =\n+      new ConcurrentHashMap<>();\n+  private final LocalTaskActionClient delegate;\n+\n+  public CountingLocalTaskActionClient(\n+      Task task,\n+      TaskStorage storage,\n+      TaskActionToolbox toolbox\n+  )\n+  {\n+    delegate = new LocalTaskActionClient(task, storage, toolbox, new TaskAuditLogConfig(false));\n+  }\n+\n+  @Override\n+  public <RetType> RetType submit(TaskAction<RetType> taskAction)\n+  {\n+    final RetType result = delegate.submit(taskAction);\n+    final TaskAction actionKey;\n+    if (taskAction instanceof SurrogateAction) {\n+      actionKey = ((SurrogateAction) taskAction).getTaskAction();\n+    } else {\n+      actionKey = taskAction;\n+    }\n+    actionCountMap.computeIfAbsent(actionKey.getClass(), k -> new AtomicInteger()).incrementAndGet();\n+    return result;\n+  }\n+\n+  public int getActionCount(Class<? extends TaskAction> actionClass)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NTI0OA=="}, "originalCommit": {"oid": "58998ac74be63ce92e375d8d605daf35e69da637"}, "originalPosition": 62}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxMTM4MjUwOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/druid/indexing/overlord/IndexerMetadataStorageCoordinator.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wMVQxODo0NjoyM1rOFkeqcw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QwNToxNzoxMlrOFkmlLg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NTQ0Mw==", "bodyText": "Do you want to update the parameter description to match the rename?", "url": "https://github.com/apache/druid/pull/9274#discussion_r373795443", "createdAt": "2020-02-01T18:46:23Z", "author": {"login": "ccaominh"}, "path": "server/src/main/java/org/apache/druid/indexing/overlord/IndexerMetadataStorageCoordinator.java", "diffHunk": "@@ -157,7 +157,7 @@\n    * @param previousSegmentId       previous segment in the series; may be null or empty, meaning this is the first\n    *                                segment\n    * @param interval                interval for which to allocate a segment\n-   * @param shardSpecFactory        shardSpecFactory containing all necessary information to create a shardSpec for the\n+   * @param partialShardSpec        shardSpecFactory containing all necessary information to create a shardSpec for the", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "58998ac74be63ce92e375d8d605daf35e69da637"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzkyNTE2Ng==", "bodyText": "Thanks, updated.", "url": "https://github.com/apache/druid/pull/9274#discussion_r373925166", "createdAt": "2020-02-03T05:17:12Z", "author": {"login": "jihoonson"}, "path": "server/src/main/java/org/apache/druid/indexing/overlord/IndexerMetadataStorageCoordinator.java", "diffHunk": "@@ -157,7 +157,7 @@\n    * @param previousSegmentId       previous segment in the series; may be null or empty, meaning this is the first\n    *                                segment\n    * @param interval                interval for which to allocate a segment\n-   * @param shardSpecFactory        shardSpecFactory containing all necessary information to create a shardSpec for the\n+   * @param partialShardSpec        shardSpecFactory containing all necessary information to create a shardSpec for the", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Mzc5NTQ0Mw=="}, "originalCommit": {"oid": "58998ac74be63ce92e375d8d605daf35e69da637"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxNDE0NDczOnYy", "diffSide": "RIGHT", "path": "core/src/main/java/org/apache/druid/indexer/partitions/PartitionsSpec.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QxNjozMDowMFrOFk3onw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQwMTo1Nzo0M1rOFlF9Ew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIwNDU3NQ==", "bodyText": "javadocs please - what is this used for?", "url": "https://github.com/apache/druid/pull/9274#discussion_r374204575", "createdAt": "2020-02-03T16:30:00Z", "author": {"login": "suneet-s"}, "path": "core/src/main/java/org/apache/druid/indexer/partitions/PartitionsSpec.java", "diffHunk": "@@ -41,6 +41,9 @@\n   String MAX_ROWS_PER_SEGMENT = \"maxRowsPerSegment\";\n   int HISTORICAL_NULL = -1;\n \n+  @JsonIgnore\n+  SecondaryPartitionType getType();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQzOTE4Nw==", "bodyText": "This was originally to easily get some characteristics of the secondary partitioning type but turns out they are not that useful. But, I still find it useful especially when I need to do something based on the secondary partition type. I can use switch instead of multiple if statements. But maybe this will be unnecessary once I address #9274 (comment) in the follow-up PR. I'll remove this method or add javadoc later.", "url": "https://github.com/apache/druid/pull/9274#discussion_r374439187", "createdAt": "2020-02-04T01:57:43Z", "author": {"login": "jihoonson"}, "path": "core/src/main/java/org/apache/druid/indexer/partitions/PartitionsSpec.java", "diffHunk": "@@ -41,6 +41,9 @@\n   String MAX_ROWS_PER_SEGMENT = \"maxRowsPerSegment\";\n   int HISTORICAL_NULL = -1;\n \n+  @JsonIgnore\n+  SecondaryPartitionType getType();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIwNDU3NQ=="}, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxNDE1NTAxOnYy", "diffSide": "RIGHT", "path": "core/src/main/java/org/apache/druid/timeline/partition/HashBasedNumberedPartialShardSpec.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QxNjozMjo0M1rOFk3u6w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQwMTo1Nzo0N1rOFlF9Iw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIwNjE4Nw==", "bodyText": "Is there a test that fails if we change the property name here?\nIf there isn't, let's at least leave a comment here saying numPartitions is for backward compatibility.", "url": "https://github.com/apache/druid/pull/9274#discussion_r374206187", "createdAt": "2020-02-03T16:32:43Z", "author": {"login": "suneet-s"}, "path": "core/src/main/java/org/apache/druid/timeline/partition/HashBasedNumberedPartialShardSpec.java", "diffHunk": "@@ -27,20 +27,20 @@\n import java.util.List;\n import java.util.Objects;\n \n-public class HashBasedNumberedShardSpecFactory implements ShardSpecFactory\n+public class HashBasedNumberedPartialShardSpec implements PartialShardSpec\n {\n   @Nullable\n   private final List<String> partitionDimensions;\n-  private final int numPartitions;\n+  private final int numBuckets;\n \n   @JsonCreator\n-  public HashBasedNumberedShardSpecFactory(\n+  public HashBasedNumberedPartialShardSpec(\n       @JsonProperty(\"partitionDimensions\") @Nullable List<String> partitionDimensions,\n-      @JsonProperty(\"numPartitions\") int numPartitions\n+      @JsonProperty(\"numPartitions\") int numBuckets", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQzOTIwMw==", "bodyText": "\ud83d\udc4d added a test.", "url": "https://github.com/apache/druid/pull/9274#discussion_r374439203", "createdAt": "2020-02-04T01:57:47Z", "author": {"login": "jihoonson"}, "path": "core/src/main/java/org/apache/druid/timeline/partition/HashBasedNumberedPartialShardSpec.java", "diffHunk": "@@ -27,20 +27,20 @@\n import java.util.List;\n import java.util.Objects;\n \n-public class HashBasedNumberedShardSpecFactory implements ShardSpecFactory\n+public class HashBasedNumberedPartialShardSpec implements PartialShardSpec\n {\n   @Nullable\n   private final List<String> partitionDimensions;\n-  private final int numPartitions;\n+  private final int numBuckets;\n \n   @JsonCreator\n-  public HashBasedNumberedShardSpecFactory(\n+  public HashBasedNumberedPartialShardSpec(\n       @JsonProperty(\"partitionDimensions\") @Nullable List<String> partitionDimensions,\n-      @JsonProperty(\"numPartitions\") int numPartitions\n+      @JsonProperty(\"numPartitions\") int numBuckets", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIwNjE4Nw=="}, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 17}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxNDI2NDA3OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionPartialShardSpec.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QxNzowMzoxOVrOFk4yrA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQwMTo1Nzo1MFrOFlF9Mg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIyMzUzMg==", "bodyText": "do we need a unit test for this?", "url": "https://github.com/apache/druid/pull/9274#discussion_r374223532", "createdAt": "2020-02-03T17:03:19Z", "author": {"login": "suneet-s"}, "path": "core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionPartialShardSpec.java", "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.timeline.partition;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+import javax.annotation.Nullable;\n+import java.util.Objects;\n+\n+public class SingleDimensionPartialShardSpec implements PartialShardSpec\n+{\n+  private final String partitionDimension;\n+  private final int bucketId;\n+  @Nullable\n+  private final String start;\n+  @Nullable\n+  private final String end;\n+  private final int numBuckets;\n+\n+  @JsonCreator\n+  public SingleDimensionPartialShardSpec(\n+      @JsonProperty(\"partitionDimension\") String partitionDimension,\n+      @JsonProperty(\"bucketId\") int bucketId,\n+      @JsonProperty(\"start\") @Nullable String start,\n+      @JsonProperty(\"end\") @Nullable String end,\n+      @JsonProperty(\"numBuckets\") int numBuckets\n+  )\n+  {\n+    this.partitionDimension = partitionDimension;\n+    this.bucketId = bucketId;\n+    this.start = start;\n+    this.end = end;\n+    this.numBuckets = numBuckets;\n+  }\n+\n+  @JsonProperty\n+  public String getPartitionDimension()\n+  {\n+    return partitionDimension;\n+  }\n+\n+  @JsonProperty\n+  public int getBucketId()\n+  {\n+    return bucketId;\n+  }\n+\n+  @JsonProperty\n+  @Nullable\n+  public String getStart()\n+  {\n+    return start;\n+  }\n+\n+  @JsonProperty\n+  @Nullable\n+  public String getEnd()\n+  {\n+    return end;\n+  }\n+\n+  @JsonProperty\n+  public int getNumBuckets()\n+  {\n+    return numBuckets;\n+  }\n+\n+  @Override\n+  public ShardSpec complete(ObjectMapper objectMapper, @Nullable ShardSpec specOfPreviousMaxPartitionId)\n+  {\n+    final int partitionId;\n+    if (specOfPreviousMaxPartitionId != null) {\n+      assert specOfPreviousMaxPartitionId instanceof SingleDimensionShardSpec;\n+      final SingleDimensionShardSpec prevSpec = (SingleDimensionShardSpec) specOfPreviousMaxPartitionId;\n+      partitionId = prevSpec.getPartitionNum() + 1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQzOTIxOA==", "bodyText": "This logic will be changed in the follow-up PR.", "url": "https://github.com/apache/druid/pull/9274#discussion_r374439218", "createdAt": "2020-02-04T01:57:50Z", "author": {"login": "jihoonson"}, "path": "core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionPartialShardSpec.java", "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.timeline.partition;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+import javax.annotation.Nullable;\n+import java.util.Objects;\n+\n+public class SingleDimensionPartialShardSpec implements PartialShardSpec\n+{\n+  private final String partitionDimension;\n+  private final int bucketId;\n+  @Nullable\n+  private final String start;\n+  @Nullable\n+  private final String end;\n+  private final int numBuckets;\n+\n+  @JsonCreator\n+  public SingleDimensionPartialShardSpec(\n+      @JsonProperty(\"partitionDimension\") String partitionDimension,\n+      @JsonProperty(\"bucketId\") int bucketId,\n+      @JsonProperty(\"start\") @Nullable String start,\n+      @JsonProperty(\"end\") @Nullable String end,\n+      @JsonProperty(\"numBuckets\") int numBuckets\n+  )\n+  {\n+    this.partitionDimension = partitionDimension;\n+    this.bucketId = bucketId;\n+    this.start = start;\n+    this.end = end;\n+    this.numBuckets = numBuckets;\n+  }\n+\n+  @JsonProperty\n+  public String getPartitionDimension()\n+  {\n+    return partitionDimension;\n+  }\n+\n+  @JsonProperty\n+  public int getBucketId()\n+  {\n+    return bucketId;\n+  }\n+\n+  @JsonProperty\n+  @Nullable\n+  public String getStart()\n+  {\n+    return start;\n+  }\n+\n+  @JsonProperty\n+  @Nullable\n+  public String getEnd()\n+  {\n+    return end;\n+  }\n+\n+  @JsonProperty\n+  public int getNumBuckets()\n+  {\n+    return numBuckets;\n+  }\n+\n+  @Override\n+  public ShardSpec complete(ObjectMapper objectMapper, @Nullable ShardSpec specOfPreviousMaxPartitionId)\n+  {\n+    final int partitionId;\n+    if (specOfPreviousMaxPartitionId != null) {\n+      assert specOfPreviousMaxPartitionId instanceof SingleDimensionShardSpec;\n+      final SingleDimensionShardSpec prevSpec = (SingleDimensionShardSpec) specOfPreviousMaxPartitionId;\n+      partitionId = prevSpec.getPartitionNum() + 1;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIyMzUzMg=="}, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 94}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxNDI3MDY2OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionPartialShardSpec.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QxNzowNToxNVrOFk42qw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQwMTo1Nzo1M1rOFlF9QQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIyNDU1NQ==", "bodyText": "Why is this cast needed?", "url": "https://github.com/apache/druid/pull/9274#discussion_r374224555", "createdAt": "2020-02-03T17:05:15Z", "author": {"login": "suneet-s"}, "path": "core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionPartialShardSpec.java", "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.timeline.partition;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+import javax.annotation.Nullable;\n+import java.util.Objects;\n+\n+public class SingleDimensionPartialShardSpec implements PartialShardSpec\n+{\n+  private final String partitionDimension;\n+  private final int bucketId;\n+  @Nullable\n+  private final String start;\n+  @Nullable\n+  private final String end;\n+  private final int numBuckets;\n+\n+  @JsonCreator\n+  public SingleDimensionPartialShardSpec(\n+      @JsonProperty(\"partitionDimension\") String partitionDimension,\n+      @JsonProperty(\"bucketId\") int bucketId,\n+      @JsonProperty(\"start\") @Nullable String start,\n+      @JsonProperty(\"end\") @Nullable String end,\n+      @JsonProperty(\"numBuckets\") int numBuckets\n+  )\n+  {\n+    this.partitionDimension = partitionDimension;\n+    this.bucketId = bucketId;\n+    this.start = start;\n+    this.end = end;\n+    this.numBuckets = numBuckets;\n+  }\n+\n+  @JsonProperty\n+  public String getPartitionDimension()\n+  {\n+    return partitionDimension;\n+  }\n+\n+  @JsonProperty\n+  public int getBucketId()\n+  {\n+    return bucketId;\n+  }\n+\n+  @JsonProperty\n+  @Nullable\n+  public String getStart()\n+  {\n+    return start;\n+  }\n+\n+  @JsonProperty\n+  @Nullable\n+  public String getEnd()\n+  {\n+    return end;\n+  }\n+\n+  @JsonProperty\n+  public int getNumBuckets()\n+  {\n+    return numBuckets;\n+  }\n+\n+  @Override\n+  public ShardSpec complete(ObjectMapper objectMapper, @Nullable ShardSpec specOfPreviousMaxPartitionId)\n+  {\n+    final int partitionId;\n+    if (specOfPreviousMaxPartitionId != null) {\n+      assert specOfPreviousMaxPartitionId instanceof SingleDimensionShardSpec;\n+      final SingleDimensionShardSpec prevSpec = (SingleDimensionShardSpec) specOfPreviousMaxPartitionId;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQzOTIzMw==", "bodyText": "It doesn't necessary for now, but will be in the follow-up PR.", "url": "https://github.com/apache/druid/pull/9274#discussion_r374439233", "createdAt": "2020-02-04T01:57:53Z", "author": {"login": "jihoonson"}, "path": "core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionPartialShardSpec.java", "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.timeline.partition;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+import javax.annotation.Nullable;\n+import java.util.Objects;\n+\n+public class SingleDimensionPartialShardSpec implements PartialShardSpec\n+{\n+  private final String partitionDimension;\n+  private final int bucketId;\n+  @Nullable\n+  private final String start;\n+  @Nullable\n+  private final String end;\n+  private final int numBuckets;\n+\n+  @JsonCreator\n+  public SingleDimensionPartialShardSpec(\n+      @JsonProperty(\"partitionDimension\") String partitionDimension,\n+      @JsonProperty(\"bucketId\") int bucketId,\n+      @JsonProperty(\"start\") @Nullable String start,\n+      @JsonProperty(\"end\") @Nullable String end,\n+      @JsonProperty(\"numBuckets\") int numBuckets\n+  )\n+  {\n+    this.partitionDimension = partitionDimension;\n+    this.bucketId = bucketId;\n+    this.start = start;\n+    this.end = end;\n+    this.numBuckets = numBuckets;\n+  }\n+\n+  @JsonProperty\n+  public String getPartitionDimension()\n+  {\n+    return partitionDimension;\n+  }\n+\n+  @JsonProperty\n+  public int getBucketId()\n+  {\n+    return bucketId;\n+  }\n+\n+  @JsonProperty\n+  @Nullable\n+  public String getStart()\n+  {\n+    return start;\n+  }\n+\n+  @JsonProperty\n+  @Nullable\n+  public String getEnd()\n+  {\n+    return end;\n+  }\n+\n+  @JsonProperty\n+  public int getNumBuckets()\n+  {\n+    return numBuckets;\n+  }\n+\n+  @Override\n+  public ShardSpec complete(ObjectMapper objectMapper, @Nullable ShardSpec specOfPreviousMaxPartitionId)\n+  {\n+    final int partitionId;\n+    if (specOfPreviousMaxPartitionId != null) {\n+      assert specOfPreviousMaxPartitionId instanceof SingleDimensionShardSpec;\n+      final SingleDimensionShardSpec prevSpec = (SingleDimensionShardSpec) specOfPreviousMaxPartitionId;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIyNDU1NQ=="}, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 93}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxNDI4MTU4OnYy", "diffSide": "RIGHT", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/CachingLocalSegmentAllocator.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QxNzowODo1MlrOFk49qg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQwMTo1Nzo1N1rOFlF9Sw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIyNjM0Ng==", "bodyText": "why public?", "url": "https://github.com/apache/druid/pull/9274#discussion_r374226346", "createdAt": "2020-02-03T17:08:52Z", "author": {"login": "suneet-s"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/CachingLocalSegmentAllocator.java", "diffHunk": "@@ -41,11 +45,8 @@\n \n /**\n  * Allocates all necessary segments locally at the beginning and reuses them.\n- *\n- * @see HashPartitionCachingLocalSegmentAllocator\n- * @see RangePartitionCachingLocalSegmentAllocator\n  */\n-class CachingLocalSegmentAllocatorHelper implements IndexTaskSegmentAllocator\n+public class CachingLocalSegmentAllocator implements CachingSegmentAllocator", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQzOTI0Mw==", "bodyText": "It can be package default, but will be removed in the follow-up pr.", "url": "https://github.com/apache/druid/pull/9274#discussion_r374439243", "createdAt": "2020-02-04T01:57:57Z", "author": {"login": "jihoonson"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/CachingLocalSegmentAllocator.java", "diffHunk": "@@ -41,11 +45,8 @@\n \n /**\n  * Allocates all necessary segments locally at the beginning and reuses them.\n- *\n- * @see HashPartitionCachingLocalSegmentAllocator\n- * @see RangePartitionCachingLocalSegmentAllocator\n  */\n-class CachingLocalSegmentAllocatorHelper implements IndexTaskSegmentAllocator\n+public class CachingLocalSegmentAllocator implements CachingSegmentAllocator", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIyNjM0Ng=="}, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxNDI4Njc4OnYy", "diffSide": "RIGHT", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/CachingLocalSegmentAllocator.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QxNzoxMDo0N1rOFk5BCQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQwMTo1ODowMFrOFlF9XA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIyNzIwOQ==", "bodyText": "I don't see a unit test class for this. Do we want to write a test that makes sure we set the action correctly based on the passed in supervisorTaskAccess", "url": "https://github.com/apache/druid/pull/9274#discussion_r374227209", "createdAt": "2020-02-03T17:10:47Z", "author": {"login": "suneet-s"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/CachingLocalSegmentAllocator.java", "diffHunk": "@@ -59,30 +60,46 @@\n      *\n      * @return Information for segment preallocation\n      */\n-    Map<Interval, List<SegmentIdWithShardSpec>> create(Function<Interval, String> versionFinder);\n+    Map<Interval, List<SegmentIdWithShardSpec>> create(\n+        TaskToolbox toolbox,\n+        String dataSource,\n+        Function<Interval, String> versionFinder\n+    );\n   }\n \n-  CachingLocalSegmentAllocatorHelper(\n+  CachingLocalSegmentAllocator(\n       TaskToolbox toolbox,\n+      String dataSource,\n       String taskId,\n-      String supervisorTaskId,\n+      @Nullable SupervisorTaskAccess supervisorTaskAccess,\n       IntervalToSegmentIdsCreator intervalToSegmentIdsCreator\n   ) throws IOException\n   {\n     this.taskId = taskId;\n     this.sequenceNameToSegmentId = new HashMap<>();\n \n+    final TaskAction<List<TaskLock>> action;\n+    if (supervisorTaskAccess == null) {\n+      action = new LockListAction();\n+    } else {\n+      action = new SurrogateAction<>(supervisorTaskAccess.getSupervisorTaskId(), new LockListAction());\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQzOTI2MA==", "bodyText": "Same, this class will be removed.", "url": "https://github.com/apache/druid/pull/9274#discussion_r374439260", "createdAt": "2020-02-04T01:58:00Z", "author": {"login": "jihoonson"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/CachingLocalSegmentAllocator.java", "diffHunk": "@@ -59,30 +60,46 @@\n      *\n      * @return Information for segment preallocation\n      */\n-    Map<Interval, List<SegmentIdWithShardSpec>> create(Function<Interval, String> versionFinder);\n+    Map<Interval, List<SegmentIdWithShardSpec>> create(\n+        TaskToolbox toolbox,\n+        String dataSource,\n+        Function<Interval, String> versionFinder\n+    );\n   }\n \n-  CachingLocalSegmentAllocatorHelper(\n+  CachingLocalSegmentAllocator(\n       TaskToolbox toolbox,\n+      String dataSource,\n       String taskId,\n-      String supervisorTaskId,\n+      @Nullable SupervisorTaskAccess supervisorTaskAccess,\n       IntervalToSegmentIdsCreator intervalToSegmentIdsCreator\n   ) throws IOException\n   {\n     this.taskId = taskId;\n     this.sequenceNameToSegmentId = new HashMap<>();\n \n+    final TaskAction<List<TaskLock>> action;\n+    if (supervisorTaskAccess == null) {\n+      action = new LockListAction();\n+    } else {\n+      action = new SurrogateAction<>(supervisorTaskAccess.getSupervisorTaskId(), new LockListAction());\n+    }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIyNzIwOQ=="}, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 65}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxNDI5MTg5OnYy", "diffSide": "RIGHT", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/CachingLocalSegmentAllocator.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QxNzoxMjoxMVrOFk5EDA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQwMTo1ODowNVrOFlF9aw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIyNzk4MA==", "bodyText": "Why must this be NotNull? The javadocs say this function is nullable", "url": "https://github.com/apache/druid/pull/9274#discussion_r374227980", "createdAt": "2020-02-03T17:12:11Z", "author": {"login": "suneet-s"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/CachingLocalSegmentAllocator.java", "diffHunk": "@@ -115,14 +132,11 @@ public SegmentIdWithShardSpec allocate(\n       boolean skipSegmentLineageCheck\n   )\n   {\n-    return sequenceNameToSegmentId.get(sequenceName);\n-  }\n-\n-  @Override\n-  public String getSequenceName(Interval interval, InputRow inputRow)\n-  {\n-    // Sequence name is based solely on the shardSpec, and there will only be one segment per sequence.\n-    return getSequenceName(interval, shardSpecs.getShardSpec(interval, inputRow));\n+    return Preconditions.checkNotNull(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 99}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQzOTI3NQ==", "bodyText": "The CachingLocalSegmentAllocator allocates all necessary segment IDs upfront and returns a proper segment ID corresponding to the sequenceName. It's a bug if there's a missing segment ID for a sequence.", "url": "https://github.com/apache/druid/pull/9274#discussion_r374439275", "createdAt": "2020-02-04T01:58:05Z", "author": {"login": "jihoonson"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/CachingLocalSegmentAllocator.java", "diffHunk": "@@ -115,14 +132,11 @@ public SegmentIdWithShardSpec allocate(\n       boolean skipSegmentLineageCheck\n   )\n   {\n-    return sequenceNameToSegmentId.get(sequenceName);\n-  }\n-\n-  @Override\n-  public String getSequenceName(Interval interval, InputRow inputRow)\n-  {\n-    // Sequence name is based solely on the shardSpec, and there will only be one segment per sequence.\n-    return getSequenceName(interval, shardSpecs.getShardSpec(interval, inputRow));\n+    return Preconditions.checkNotNull(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIyNzk4MA=="}, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 99}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxNDMxODc0OnYy", "diffSide": "RIGHT", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/IndexTask.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QxNzoyMDowOVrOFk5UOQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQwMTo1ODoxNFrOFlF9jQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIzMjEyMQ==", "bodyText": "I think it's better to be explicit here about which types we expect to be non linear and throw a UOE exception if there another type is added. This forces the dev who adds a new type to think about which category it should fall in to.", "url": "https://github.com/apache/druid/pull/9274#discussion_r374232121", "createdAt": "2020-02-03T17:20:09Z", "author": {"login": "suneet-s"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/IndexTask.java", "diffHunk": "@@ -875,14 +876,36 @@ private TaskStatus generateAndPublishSegments(\n       toolbox.getMonitorScheduler().addMonitor(metricsMonitor);\n     }\n \n+    final PartitionsSpec partitionsSpec = partitionAnalysis.getPartitionsSpec();\n     final IndexTuningConfig tuningConfig = ingestionSchema.getTuningConfig();\n     final long pushTimeout = tuningConfig.getPushTimeout();\n \n-    final IndexTaskSegmentAllocator segmentAllocator = createSegmentAllocator(\n-        toolbox,\n-        dataSchema,\n-        allocateSpec\n-    );\n+    final SegmentAllocator segmentAllocator;\n+    final SequenceNameFunction sequenceNameFunction;\n+    if (partitionsSpec.getType() == SecondaryPartitionType.LINEAR) {\n+      segmentAllocator = SegmentAllocators.forLinearPartitioning(\n+          toolbox,\n+          null,\n+          dataSchema,\n+          getTaskLockHelper(),\n+          ingestionSchema.getIOConfig().isAppendToExisting(),\n+          partitionAnalysis.getPartitionsSpec()\n+      );\n+      sequenceNameFunction = new LinearlyPartitionedSequenceNameFunction(getId());\n+    } else {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 358}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQzOTMwOQ==", "bodyText": "Done.", "url": "https://github.com/apache/druid/pull/9274#discussion_r374439309", "createdAt": "2020-02-04T01:58:14Z", "author": {"login": "jihoonson"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/IndexTask.java", "diffHunk": "@@ -875,14 +876,36 @@ private TaskStatus generateAndPublishSegments(\n       toolbox.getMonitorScheduler().addMonitor(metricsMonitor);\n     }\n \n+    final PartitionsSpec partitionsSpec = partitionAnalysis.getPartitionsSpec();\n     final IndexTuningConfig tuningConfig = ingestionSchema.getTuningConfig();\n     final long pushTimeout = tuningConfig.getPushTimeout();\n \n-    final IndexTaskSegmentAllocator segmentAllocator = createSegmentAllocator(\n-        toolbox,\n-        dataSchema,\n-        allocateSpec\n-    );\n+    final SegmentAllocator segmentAllocator;\n+    final SequenceNameFunction sequenceNameFunction;\n+    if (partitionsSpec.getType() == SecondaryPartitionType.LINEAR) {\n+      segmentAllocator = SegmentAllocators.forLinearPartitioning(\n+          toolbox,\n+          null,\n+          dataSchema,\n+          getTaskLockHelper(),\n+          ingestionSchema.getIOConfig().isAppendToExisting(),\n+          partitionAnalysis.getPartitionsSpec()\n+      );\n+      sequenceNameFunction = new LinearlyPartitionedSequenceNameFunction(getId());\n+    } else {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIzMjEyMQ=="}, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 358}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxNDMyOTM1OnYy", "diffSide": "RIGHT", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/LinearlyPartitionedSequenceNameFunction.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QxNzoyMzoyNVrOFk5aqg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQwMTo1ODoxOVrOFlF9oA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIzMzc3MA==", "bodyText": "Does this need to be public", "url": "https://github.com/apache/druid/pull/9274#discussion_r374233770", "createdAt": "2020-02-03T17:23:25Z", "author": {"login": "suneet-s"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/LinearlyPartitionedSequenceNameFunction.java", "diffHunk": "@@ -0,0 +1,45 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.common.task;\n+\n+import org.apache.druid.data.input.InputRow;\n+import org.joda.time.Interval;\n+\n+/**\n+ * This sequence name function should be used for the linear partitioning. Since the segments are created as needed,\n+ * this function uses a single sequence name.\n+ *\n+ * @see org.apache.druid.indexer.partitions.SecondaryPartitionType\n+ */\n+public class LinearlyPartitionedSequenceNameFunction implements SequenceNameFunction", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQzOTMyOA==", "bodyText": "It may need to be public in the follow-up PR. I'll clean up in it.", "url": "https://github.com/apache/druid/pull/9274#discussion_r374439328", "createdAt": "2020-02-04T01:58:19Z", "author": {"login": "jihoonson"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/LinearlyPartitionedSequenceNameFunction.java", "diffHunk": "@@ -0,0 +1,45 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.indexing.common.task;\n+\n+import org.apache.druid.data.input.InputRow;\n+import org.joda.time.Interval;\n+\n+/**\n+ * This sequence name function should be used for the linear partitioning. Since the segments are created as needed,\n+ * this function uses a single sequence name.\n+ *\n+ * @see org.apache.druid.indexer.partitions.SecondaryPartitionType\n+ */\n+public class LinearlyPartitionedSequenceNameFunction implements SequenceNameFunction", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIzMzc3MA=="}, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxNDMzMTEyOnYy", "diffSide": "RIGHT", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/LocalSegmentAllocator.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QxNzoyMzo1OFrOFk5bvg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQwMTo1ODoyNVrOFlF9uA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIzNDA0Ng==", "bodyText": "does this need to be public?", "url": "https://github.com/apache/druid/pull/9274#discussion_r374234046", "createdAt": "2020-02-03T17:23:58Z", "author": {"login": "suneet-s"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/LocalSegmentAllocator.java", "diffHunk": "@@ -32,32 +34,27 @@\n import org.joda.time.DateTime;\n import org.joda.time.Interval;\n \n+import javax.annotation.Nullable;\n import java.io.IOException;\n-import java.util.HashMap;\n import java.util.Map;\n import java.util.Map.Entry;\n-import java.util.concurrent.atomic.AtomicInteger;\n import java.util.stream.Collectors;\n \n /**\n  * Segment allocator which allocates new segments locally per request.\n  */\n-class LocalSegmentAllocator implements IndexTaskSegmentAllocator\n+public class LocalSegmentAllocator implements SegmentAllocator", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQzOTM1Mg==", "bodyText": "Removed.", "url": "https://github.com/apache/druid/pull/9274#discussion_r374439352", "createdAt": "2020-02-04T01:58:25Z", "author": {"login": "jihoonson"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/LocalSegmentAllocator.java", "diffHunk": "@@ -32,32 +34,27 @@\n import org.joda.time.DateTime;\n import org.joda.time.Interval;\n \n+import javax.annotation.Nullable;\n import java.io.IOException;\n-import java.util.HashMap;\n import java.util.Map;\n import java.util.Map.Entry;\n-import java.util.concurrent.atomic.AtomicInteger;\n import java.util.stream.Collectors;\n \n /**\n  * Segment allocator which allocates new segments locally per request.\n  */\n-class LocalSegmentAllocator implements IndexTaskSegmentAllocator\n+public class LocalSegmentAllocator implements SegmentAllocator", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIzNDA0Ng=="}, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxNDMzNzA0OnYy", "diffSide": "RIGHT", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/LocalSegmentAllocator.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QxNzoyNTo1NFrOFk5faQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQwMTo1ODozMlrOFlF90g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIzNDk4NQ==", "bodyText": "For my understanding - why did we need to change this to MutableInt", "url": "https://github.com/apache/druid/pull/9274#discussion_r374234985", "createdAt": "2020-02-03T17:25:54Z", "author": {"login": "suneet-s"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/LocalSegmentAllocator.java", "diffHunk": "@@ -67,30 +64,25 @@\n       }\n \n       final Interval interval = maybeInterval.get();\n-      final String version = intervalToVersion.entrySet().stream()\n-                                              .filter(entry -> entry.getKey().contains(interval))\n-                                              .map(Entry::getValue)\n-                                              .findFirst()\n-                                              .orElseThrow(() -> new ISE(\"Cannot find a version for interval[%s]\", interval));\n+      final String version = intervalToVersion\n+          .entrySet()\n+          .stream()\n+          .filter(entry -> entry.getKey().contains(interval))\n+          .map(Entry::getValue)\n+          .findFirst()\n+          .orElseThrow(() -> new ISE(\"Cannot find a version for interval[%s]\", interval));\n \n-      final int partitionNum = counters.computeIfAbsent(interval, x -> new AtomicInteger()).getAndIncrement();\n+      final int partitionId = counters.computeIfAbsent(interval, x -> new MutableInt()).getAndIncrement();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQzOTM3OA==", "bodyText": "It doesn't have to be an AtomicInteger since there's no concurrent update.", "url": "https://github.com/apache/druid/pull/9274#discussion_r374439378", "createdAt": "2020-02-04T01:58:32Z", "author": {"login": "jihoonson"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/LocalSegmentAllocator.java", "diffHunk": "@@ -67,30 +64,25 @@\n       }\n \n       final Interval interval = maybeInterval.get();\n-      final String version = intervalToVersion.entrySet().stream()\n-                                              .filter(entry -> entry.getKey().contains(interval))\n-                                              .map(Entry::getValue)\n-                                              .findFirst()\n-                                              .orElseThrow(() -> new ISE(\"Cannot find a version for interval[%s]\", interval));\n+      final String version = intervalToVersion\n+          .entrySet()\n+          .stream()\n+          .filter(entry -> entry.getKey().contains(interval))\n+          .map(Entry::getValue)\n+          .findFirst()\n+          .orElseThrow(() -> new ISE(\"Cannot find a version for interval[%s]\", interval));\n \n-      final int partitionNum = counters.computeIfAbsent(interval, x -> new AtomicInteger()).getAndIncrement();\n+      final int partitionId = counters.computeIfAbsent(interval, x -> new MutableInt()).getAndIncrement();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDIzNDk4NQ=="}, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 69}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxNDM3MjM4OnYy", "diffSide": "RIGHT", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/PartialSegmentGenerateTask.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QxNzozNzowOVrOFk51Yw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQwMTo1ODozNlrOFlF94Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI0MDYxMQ==", "bodyText": "Why is this always NonLinearlyPartitionedSequenceNameFunction shouldn't we check the partitionsSpec type to determine the  sequenceNameFunction here?\nIf it is, I think we should , make the constructors package private and expose the function name creation through a factory that accepts a PartitionsSpec", "url": "https://github.com/apache/druid/pull/9274#discussion_r374240611", "createdAt": "2020-02-03T17:37:09Z", "author": {"login": "suneet-s"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/PartialSegmentGenerateTask.java", "diffHunk": "@@ -164,7 +171,11 @@ abstract T createGeneratedPartitionsReport(\n     final PartitionsSpec partitionsSpec = tuningConfig.getGivenOrDefaultPartitionsSpec();\n     final long pushTimeout = tuningConfig.getPushTimeout();\n \n-    final IndexTaskSegmentAllocator segmentAllocator = createSegmentAllocator(toolbox);\n+    final CachingSegmentAllocator segmentAllocator = createSegmentAllocator(toolbox, taskClient);\n+    final SequenceNameFunction sequenceNameFunction = new NonLinearlyPartitionedSequenceNameFunction(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQzOTM5Mw==", "bodyText": "PartialSegmentGenerateTask is used when shuffling intermediate segment is required. The hash or range partitionings need the shuffle, but for the linear partitioning, I think it would never need it.\nHmm, well actually I think I can make SequenceNameFunction to be more general so that it can create the proper sequence name based on the partialShardSpec. I will do it in the follow-up pr.", "url": "https://github.com/apache/druid/pull/9274#discussion_r374439393", "createdAt": "2020-02-04T01:58:36Z", "author": {"login": "jihoonson"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/PartialSegmentGenerateTask.java", "diffHunk": "@@ -164,7 +171,11 @@ abstract T createGeneratedPartitionsReport(\n     final PartitionsSpec partitionsSpec = tuningConfig.getGivenOrDefaultPartitionsSpec();\n     final long pushTimeout = tuningConfig.getPushTimeout();\n \n-    final IndexTaskSegmentAllocator segmentAllocator = createSegmentAllocator(toolbox);\n+    final CachingSegmentAllocator segmentAllocator = createSegmentAllocator(toolbox, taskClient);\n+    final SequenceNameFunction sequenceNameFunction = new NonLinearlyPartitionedSequenceNameFunction(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI0MDYxMQ=="}, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 59}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxNDM4MjYwOnYy", "diffSide": "RIGHT", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/SinglePhaseSubTask.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QxNzo0MDozOVrOFk57vA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQwMTo1OTowMFrOFlF-Tw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI0MjIzNg==", "bodyText": "This should look at partitionsSpec.getType() otherwise if that implementation changes to return a non linear type this will break", "url": "https://github.com/apache/druid/pull/9274#discussion_r374242236", "createdAt": "2020-02-03T17:40:39Z", "author": {"login": "suneet-s"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/SinglePhaseSubTask.java", "diffHunk": "@@ -410,7 +313,14 @@ private SegmentAllocator createSegmentAllocator()\n     final DynamicPartitionsSpec partitionsSpec = (DynamicPartitionsSpec) tuningConfig.getGivenOrDefaultPartitionsSpec();\n     final long pushTimeout = tuningConfig.getPushTimeout();\n     final boolean explicitIntervals = granularitySpec.bucketIntervals().isPresent();\n-    final SegmentAllocator segmentAllocator = createSegmentAllocator(toolbox, taskClient);\n+    final SegmentAllocator segmentAllocator = SegmentAllocators.forLinearPartitioning(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 152}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQzOTUwMw==", "bodyText": "This task type is supposed to be used with only linear partitioning.", "url": "https://github.com/apache/druid/pull/9274#discussion_r374439503", "createdAt": "2020-02-04T01:59:00Z", "author": {"login": "jihoonson"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/parallel/SinglePhaseSubTask.java", "diffHunk": "@@ -410,7 +313,14 @@ private SegmentAllocator createSegmentAllocator()\n     final DynamicPartitionsSpec partitionsSpec = (DynamicPartitionsSpec) tuningConfig.getGivenOrDefaultPartitionsSpec();\n     final long pushTimeout = tuningConfig.getPushTimeout();\n     final boolean explicitIntervals = granularitySpec.bucketIntervals().isPresent();\n-    final SegmentAllocator segmentAllocator = createSegmentAllocator(toolbox, taskClient);\n+    final SegmentAllocator segmentAllocator = SegmentAllocators.forLinearPartitioning(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI0MjIzNg=="}, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 152}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxNDQwMDU5OnYy", "diffSide": "RIGHT", "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/partition/RangePartitionAnalysis.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QxNzo0NjoyMlrOFk6G_w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQwMTo1OTowN1rOFlF-Yw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI0NTExOQ==", "bodyText": "Other implementations of ParitionAnalysis throw an exception if the interval is not found. This returns null. I think we should consolidate the behavior and document it in the interface to make it easy for consumers of the interface to interact with this function", "url": "https://github.com/apache/druid/pull/9274#discussion_r374245119", "createdAt": "2020-02-03T17:46:22Z", "author": {"login": "suneet-s"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/partition/RangePartitionAnalysis.java", "diffHunk": "@@ -17,80 +17,109 @@\n  * under the License.\n  */\n \n-package org.apache.druid.indexing.common.task;\n+package org.apache.druid.indexing.common.task.batch.partition;\n \n import com.google.common.collect.Maps;\n-import org.apache.druid.data.input.InputRow;\n+import org.apache.druid.indexer.partitions.SingleDimensionPartitionsSpec;\n import org.apache.druid.indexing.common.TaskToolbox;\n-import org.apache.druid.indexing.common.task.batch.parallel.distribution.PartitionBoundaries;\n import org.apache.druid.segment.realtime.appenderator.SegmentIdWithShardSpec;\n+import org.apache.druid.timeline.partition.PartitionBoundaries;\n import org.apache.druid.timeline.partition.SingleDimensionShardSpec;\n import org.joda.time.Interval;\n \n import javax.annotation.Nullable;\n-import java.io.IOException;\n import java.util.Collections;\n+import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n+import java.util.Set;\n+import java.util.function.BiConsumer;\n import java.util.function.Function;\n import java.util.stream.Collectors;\n import java.util.stream.IntStream;\n \n-/**\n- * Allocates all necessary range-partitioned segments locally at the beginning and reuses them.\n- *\n- * @see CachingLocalSegmentAllocatorHelper\n- */\n-public class RangePartitionCachingLocalSegmentAllocator implements IndexTaskSegmentAllocator\n+public class RangePartitionAnalysis\n+    implements CompletePartitionAnalysis<PartitionBoundaries, SingleDimensionPartitionsSpec>\n {\n-  private final String dataSource;\n-  private final String partitionDimension;\n-  private final Map<Interval, PartitionBoundaries> intervalsToPartitions;\n-  private final IndexTaskSegmentAllocator delegate;\n+  private final Map<Interval, PartitionBoundaries> intervalToPartitionBoundaries = new HashMap<>();\n+  private final SingleDimensionPartitionsSpec partitionsSpec;\n+\n+  public RangePartitionAnalysis(SingleDimensionPartitionsSpec partitionsSpec)\n+  {\n+    this.partitionsSpec = partitionsSpec;\n+  }\n+\n+  @Override\n+  public SingleDimensionPartitionsSpec getPartitionsSpec()\n+  {\n+    return partitionsSpec;\n+  }\n+\n+  @Override\n+  public void updateBucket(Interval interval, PartitionBoundaries bucketAnalysis)\n+  {\n+    intervalToPartitionBoundaries.put(interval, bucketAnalysis);\n+  }\n+\n+  @Override\n+  public PartitionBoundaries getBucketAnalysis(Interval interval)\n+  {\n+    return intervalToPartitionBoundaries.get(interval);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQzOTUyMw==", "bodyText": "Good catch! I fixed the code and updated the javadoc. I want to add unit tests for this but think it would be easier to do in the follow-up PR.", "url": "https://github.com/apache/druid/pull/9274#discussion_r374439523", "createdAt": "2020-02-04T01:59:07Z", "author": {"login": "jihoonson"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/common/task/batch/partition/RangePartitionAnalysis.java", "diffHunk": "@@ -17,80 +17,109 @@\n  * under the License.\n  */\n \n-package org.apache.druid.indexing.common.task;\n+package org.apache.druid.indexing.common.task.batch.partition;\n \n import com.google.common.collect.Maps;\n-import org.apache.druid.data.input.InputRow;\n+import org.apache.druid.indexer.partitions.SingleDimensionPartitionsSpec;\n import org.apache.druid.indexing.common.TaskToolbox;\n-import org.apache.druid.indexing.common.task.batch.parallel.distribution.PartitionBoundaries;\n import org.apache.druid.segment.realtime.appenderator.SegmentIdWithShardSpec;\n+import org.apache.druid.timeline.partition.PartitionBoundaries;\n import org.apache.druid.timeline.partition.SingleDimensionShardSpec;\n import org.joda.time.Interval;\n \n import javax.annotation.Nullable;\n-import java.io.IOException;\n import java.util.Collections;\n+import java.util.HashMap;\n import java.util.List;\n import java.util.Map;\n+import java.util.Set;\n+import java.util.function.BiConsumer;\n import java.util.function.Function;\n import java.util.stream.Collectors;\n import java.util.stream.IntStream;\n \n-/**\n- * Allocates all necessary range-partitioned segments locally at the beginning and reuses them.\n- *\n- * @see CachingLocalSegmentAllocatorHelper\n- */\n-public class RangePartitionCachingLocalSegmentAllocator implements IndexTaskSegmentAllocator\n+public class RangePartitionAnalysis\n+    implements CompletePartitionAnalysis<PartitionBoundaries, SingleDimensionPartitionsSpec>\n {\n-  private final String dataSource;\n-  private final String partitionDimension;\n-  private final Map<Interval, PartitionBoundaries> intervalsToPartitions;\n-  private final IndexTaskSegmentAllocator delegate;\n+  private final Map<Interval, PartitionBoundaries> intervalToPartitionBoundaries = new HashMap<>();\n+  private final SingleDimensionPartitionsSpec partitionsSpec;\n+\n+  public RangePartitionAnalysis(SingleDimensionPartitionsSpec partitionsSpec)\n+  {\n+    this.partitionsSpec = partitionsSpec;\n+  }\n+\n+  @Override\n+  public SingleDimensionPartitionsSpec getPartitionsSpec()\n+  {\n+    return partitionsSpec;\n+  }\n+\n+  @Override\n+  public void updateBucket(Interval interval, PartitionBoundaries bucketAnalysis)\n+  {\n+    intervalToPartitionBoundaries.put(interval, bucketAnalysis);\n+  }\n+\n+  @Override\n+  public PartitionBoundaries getBucketAnalysis(Interval interval)\n+  {\n+    return intervalToPartitionBoundaries.get(interval);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI0NTExOQ=="}, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 65}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMxNDQwODU5OnYy", "diffSide": "RIGHT", "path": "indexing-service/src/main/java/org/apache/druid/indexing/overlord/LockRequestForNewSegment.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wM1QxNzo0ODo1OFrOFk6MEA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQwMTo1OTowOVrOFlF-bg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI0NjQxNg==", "bodyText": "shardSpecFactory -> partialShardSpec. Lombok would be nice and hide all of this away :)", "url": "https://github.com/apache/druid/pull/9274#discussion_r374246416", "createdAt": "2020-02-03T17:48:58Z", "author": {"login": "suneet-s"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/overlord/LockRequestForNewSegment.java", "diffHunk": "@@ -187,7 +187,7 @@ public String toString()\n            \", groupId='\" + groupId + '\\'' +\n            \", dataSource='\" + dataSource + '\\'' +\n            \", interval=\" + interval +\n-           \", shardSpecFactory=\" + shardSpecFactory +\n+           \", shardSpecFactory=\" + partialShardSpec +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDQzOTUzNA==", "bodyText": "Thanks, fixed.", "url": "https://github.com/apache/druid/pull/9274#discussion_r374439534", "createdAt": "2020-02-04T01:59:09Z", "author": {"login": "jihoonson"}, "path": "indexing-service/src/main/java/org/apache/druid/indexing/overlord/LockRequestForNewSegment.java", "diffHunk": "@@ -187,7 +187,7 @@ public String toString()\n            \", groupId='\" + groupId + '\\'' +\n            \", dataSource='\" + dataSource + '\\'' +\n            \", interval=\" + interval +\n-           \", shardSpecFactory=\" + shardSpecFactory +\n+           \", shardSpecFactory=\" + partialShardSpec +", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDI0NjQxNg=="}, "originalCommit": {"oid": "b8962a37f884f3ca3cad3abb20eb801b13783936"}, "originalPosition": 71}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyMjYzODc2OnYy", "diffSide": "RIGHT", "path": "core/src/test/java/org/apache/druid/timeline/partition/PartitionBoundariesTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQyMjoyOTozM1rOFmJang==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QyMjoxNDozOFrOFnL1QQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU0NDQ3OA==", "bodyText": "Was there an issue with using TestHelper?", "url": "https://github.com/apache/druid/pull/9274#discussion_r375544478", "createdAt": "2020-02-05T22:29:33Z", "author": {"login": "ccaominh"}, "path": "core/src/test/java/org/apache/druid/timeline/partition/PartitionBoundariesTest.java", "diffHunk": "@@ -75,8 +76,23 @@ public void handlesRepeatedValue()\n   }\n \n   @Test\n-  public void serializesDeserializes()\n+  public void serializesDeserializes() throws JsonProcessingException\n   {\n-    TestHelper.testSerializesDeserializes(TestHelper.JSON_MAPPER, target);\n+    final ObjectMapper objectMapper = new ObjectMapper();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "02bea97c3c04911d6b71a788ed743b7bbdd4530c"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjYzMjY0MQ==", "bodyText": "TestHelper is in druid-processing while this class is in druid-core.", "url": "https://github.com/apache/druid/pull/9274#discussion_r376632641", "createdAt": "2020-02-07T22:14:38Z", "author": {"login": "jihoonson"}, "path": "core/src/test/java/org/apache/druid/timeline/partition/PartitionBoundariesTest.java", "diffHunk": "@@ -75,8 +76,23 @@ public void handlesRepeatedValue()\n   }\n \n   @Test\n-  public void serializesDeserializes()\n+  public void serializesDeserializes() throws JsonProcessingException\n   {\n-    TestHelper.testSerializesDeserializes(TestHelper.JSON_MAPPER, target);\n+    final ObjectMapper objectMapper = new ObjectMapper();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU0NDQ3OA=="}, "originalCommit": {"oid": "02bea97c3c04911d6b71a788ed743b7bbdd4530c"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyMjY2MDkyOnYy", "diffSide": "RIGHT", "path": "core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionPartialShardSpec.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQyMjozODozNFrOFmJoIg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QyMjoxNDo0MVrOFnL1UQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU0NzkzOA==", "bodyText": "May be useful to add an EqualsVerifier test for this.", "url": "https://github.com/apache/druid/pull/9274#discussion_r375547938", "createdAt": "2020-02-05T22:38:34Z", "author": {"login": "ccaominh"}, "path": "core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionPartialShardSpec.java", "diffHunk": "@@ -94,14 +125,17 @@ public boolean equals(Object o)\n     if (o == null || getClass() != o.getClass()) {\n       return false;\n     }\n-    SingleDimensionShardSpecFactory that = (SingleDimensionShardSpecFactory) o;\n-    return Objects.equals(partitionDimension, that.partitionDimension) &&\n-           Objects.equals(partitionBoundaries, that.partitionBoundaries);\n+    SingleDimensionPartialShardSpec that = (SingleDimensionPartialShardSpec) o;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "02bea97c3c04911d6b71a788ed743b7bbdd4530c"}, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjYzMjY1Nw==", "bodyText": "Added.", "url": "https://github.com/apache/druid/pull/9274#discussion_r376632657", "createdAt": "2020-02-07T22:14:41Z", "author": {"login": "jihoonson"}, "path": "core/src/main/java/org/apache/druid/timeline/partition/SingleDimensionPartialShardSpec.java", "diffHunk": "@@ -94,14 +125,17 @@ public boolean equals(Object o)\n     if (o == null || getClass() != o.getClass()) {\n       return false;\n     }\n-    SingleDimensionShardSpecFactory that = (SingleDimensionShardSpecFactory) o;\n-    return Objects.equals(partitionDimension, that.partitionDimension) &&\n-           Objects.equals(partitionBoundaries, that.partitionBoundaries);\n+    SingleDimensionPartialShardSpec that = (SingleDimensionPartialShardSpec) o;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU0NzkzOA=="}, "originalCommit": {"oid": "02bea97c3c04911d6b71a788ed743b7bbdd4530c"}, "originalPosition": 103}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyMjY2NDkzOnYy", "diffSide": "RIGHT", "path": "core/src/test/java/org/apache/druid/timeline/partition/HashBasedNumberedPartialShardSpecTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQyMjo0MDoxMVrOFmJqmg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QyMjoxNDo0NFrOFnL1Zg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU0ODU3MA==", "bodyText": "How about adding an EqualsVerifier test to this class?", "url": "https://github.com/apache/druid/pull/9274#discussion_r375548570", "createdAt": "2020-02-05T22:40:11Z", "author": {"login": "ccaominh"}, "path": "core/src/test/java/org/apache/druid/timeline/partition/HashBasedNumberedPartialShardSpecTest.java", "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.timeline.partition;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.google.common.collect.ImmutableList;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.Map;\n+\n+public class HashBasedNumberedPartialShardSpecTest\n+{\n+  private static final ObjectMapper MAPPER = new ObjectMapper();\n+\n+  @Test\n+  public void testSerde() throws IOException\n+  {\n+    final HashBasedNumberedPartialShardSpec expected = new HashBasedNumberedPartialShardSpec(\n+        ImmutableList.of(\"dim1\", \"dim2\"),\n+        3\n+    );\n+    final byte[] json = MAPPER.writeValueAsBytes(expected);\n+    final HashBasedNumberedPartialShardSpec fromJson = (HashBasedNumberedPartialShardSpec) MAPPER.readValue(\n+        json,\n+        PartialShardSpec.class\n+    );\n+    Assert.assertEquals(expected, fromJson);\n+  }\n+\n+  @Test\n+  public void testJsonPropertyNames() throws IOException\n+  {\n+    final HashBasedNumberedPartialShardSpec expected = new HashBasedNumberedPartialShardSpec(\n+        ImmutableList.of(\"dim1\", \"dim2\"),\n+        3\n+    );\n+    final byte[] json = MAPPER.writeValueAsBytes(expected);\n+    //noinspection unchecked\n+    final Map<String, Object> map = MAPPER.readValue(json, Map.class);\n+    Assert.assertEquals(3, map.size());\n+    Assert.assertEquals(HashBasedNumberedPartialShardSpec.TYPE, map.get(\"type\"));\n+    Assert.assertEquals(expected.getPartitionDimensions(), map.get(\"partitionDimensions\"));\n+    Assert.assertEquals(expected.getNumBuckets(), map.get(\"numPartitions\"));\n+  }\n+}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "02bea97c3c04911d6b71a788ed743b7bbdd4530c"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjYzMjY3OA==", "bodyText": "Added.", "url": "https://github.com/apache/druid/pull/9274#discussion_r376632678", "createdAt": "2020-02-07T22:14:44Z", "author": {"login": "jihoonson"}, "path": "core/src/test/java/org/apache/druid/timeline/partition/HashBasedNumberedPartialShardSpecTest.java", "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.timeline.partition;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.google.common.collect.ImmutableList;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+import java.util.Map;\n+\n+public class HashBasedNumberedPartialShardSpecTest\n+{\n+  private static final ObjectMapper MAPPER = new ObjectMapper();\n+\n+  @Test\n+  public void testSerde() throws IOException\n+  {\n+    final HashBasedNumberedPartialShardSpec expected = new HashBasedNumberedPartialShardSpec(\n+        ImmutableList.of(\"dim1\", \"dim2\"),\n+        3\n+    );\n+    final byte[] json = MAPPER.writeValueAsBytes(expected);\n+    final HashBasedNumberedPartialShardSpec fromJson = (HashBasedNumberedPartialShardSpec) MAPPER.readValue(\n+        json,\n+        PartialShardSpec.class\n+    );\n+    Assert.assertEquals(expected, fromJson);\n+  }\n+\n+  @Test\n+  public void testJsonPropertyNames() throws IOException\n+  {\n+    final HashBasedNumberedPartialShardSpec expected = new HashBasedNumberedPartialShardSpec(\n+        ImmutableList.of(\"dim1\", \"dim2\"),\n+        3\n+    );\n+    final byte[] json = MAPPER.writeValueAsBytes(expected);\n+    //noinspection unchecked\n+    final Map<String, Object> map = MAPPER.readValue(json, Map.class);\n+    Assert.assertEquals(3, map.size());\n+    Assert.assertEquals(HashBasedNumberedPartialShardSpec.TYPE, map.get(\"type\"));\n+    Assert.assertEquals(expected.getPartitionDimensions(), map.get(\"partitionDimensions\"));\n+    Assert.assertEquals(expected.getNumBuckets(), map.get(\"numPartitions\"));\n+  }\n+}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU0ODU3MA=="}, "originalCommit": {"oid": "02bea97c3c04911d6b71a788ed743b7bbdd4530c"}, "originalPosition": 64}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyMjY3MDgwOnYy", "diffSide": "RIGHT", "path": "core/src/test/java/org/apache/druid/timeline/partition/SingleDimensionPartialShardSpecTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQyMjo0Mjo0MFrOFmJuZA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wN1QyMjoxNDo0N1rOFnL1eQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU0OTU0MA==", "bodyText": "May be useful to add an EqualsVerifier test to this class.", "url": "https://github.com/apache/druid/pull/9274#discussion_r375549540", "createdAt": "2020-02-05T22:42:40Z", "author": {"login": "ccaominh"}, "path": "core/src/test/java/org/apache/druid/timeline/partition/SingleDimensionPartialShardSpecTest.java", "diffHunk": "@@ -0,0 +1,48 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.timeline.partition;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+\n+public class SingleDimensionPartialShardSpecTest\n+{\n+  @Test\n+  public void testSerde() throws IOException\n+  {\n+    final SingleDimensionPartialShardSpec expected = new SingleDimensionPartialShardSpec(\n+        \"partitionKey\",\n+        3,\n+        \"start\",\n+        \"end\",\n+        10\n+    );\n+    final ObjectMapper mapper = new ObjectMapper();\n+    final byte[] json = mapper.writeValueAsBytes(expected);\n+    final SingleDimensionPartialShardSpec fromJson = (SingleDimensionPartialShardSpec) mapper.readValue(\n+        json,\n+        PartialShardSpec.class\n+    );\n+    Assert.assertEquals(expected, fromJson);\n+  }\n+}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "02bea97c3c04911d6b71a788ed743b7bbdd4530c"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjYzMjY5Nw==", "bodyText": "Added.", "url": "https://github.com/apache/druid/pull/9274#discussion_r376632697", "createdAt": "2020-02-07T22:14:47Z", "author": {"login": "jihoonson"}, "path": "core/src/test/java/org/apache/druid/timeline/partition/SingleDimensionPartialShardSpecTest.java", "diffHunk": "@@ -0,0 +1,48 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.timeline.partition;\n+\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import java.io.IOException;\n+\n+public class SingleDimensionPartialShardSpecTest\n+{\n+  @Test\n+  public void testSerde() throws IOException\n+  {\n+    final SingleDimensionPartialShardSpec expected = new SingleDimensionPartialShardSpec(\n+        \"partitionKey\",\n+        3,\n+        \"start\",\n+        \"end\",\n+        10\n+    );\n+    final ObjectMapper mapper = new ObjectMapper();\n+    final byte[] json = mapper.writeValueAsBytes(expected);\n+    final SingleDimensionPartialShardSpec fromJson = (SingleDimensionPartialShardSpec) mapper.readValue(\n+        json,\n+        PartialShardSpec.class\n+    );\n+    Assert.assertEquals(expected, fromJson);\n+  }\n+}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTU0OTU0MA=="}, "originalCommit": {"oid": "02bea97c3c04911d6b71a788ed743b7bbdd4530c"}, "originalPosition": 48}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2179, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}