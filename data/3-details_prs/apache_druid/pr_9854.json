{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE2NjM4MDA5", "number": 9854, "title": "Integration Tests.", "bodyText": "refactored run_cluster.sh script. Split code in shell scripts.\nAdded docker-compose files to run druid cluster.\n\ndocker-compose.base.yml - contains configuration for all druid containers. This configuration is used in other docker yaml files\ndocker-compose.yml, docker-compose.override-env.yml - druid cluster containers for basic integration tests\ndocker-compose.druid-hadoop.yml - docker compose for druid-hadoop container\n\nAlso this Pull Request supports backward compatibility.\nOn run integration tests by maven we can run druid cluster by docker-compose.\nIn case if we wont to run docker-compose outside and do not restart druid cluster on running integration test we can first run \"docker-compose -f .... up\" for required cluster config and then run tests without restarting cluster: \"mvn verify -pl integration-tests -P integration-tests ... -Ddocker.build.skip=true -Ddocker.run.skip=true", "createdAt": "2020-05-12T10:37:21Z", "url": "https://github.com/apache/druid/pull/9854", "merged": true, "mergeCommit": {"oid": "56a9cad5329d97318502bd45bcafdb9d3adf88ee"}, "closed": true, "closedAt": "2020-06-02T16:38:54Z", "author": {"login": "agricenko"}, "timelineItems": {"totalCount": 22, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcghbZXgH2gAyNDE2NjM4MDA5OjZlZmRiYmYzMTJhOTFjYjU3ZjlmNzM2MjU0MWQ2ZWM5ODJlMzY5NzA=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcnXmJsgFqTQyMjg2MjEwMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "6efdbbf312a91cb57f9f7362541d6ec982e36970", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/6efdbbf312a91cb57f9f7362541d6ec982e36970", "committedDate": "2020-05-12T10:08:27Z", "message": "Integration Tests.\nAdded docker-compose with druid-cluster configuration.\nRefactored shell scripts. split code in a few files"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "afa4facc8ccc21673cc48e5d9d980cb0cba98501", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/afa4facc8ccc21673cc48e5d9d980cb0cba98501", "committedDate": "2020-05-14T11:12:47Z", "message": "Integration Tests.\nAdded environment variable: DRUID_INTEGRATION_TEST_GROUP"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDEyMjc5NDQw", "url": "https://github.com/apache/druid/pull/9854#pullrequestreview-412279440", "createdAt": "2020-05-15T00:54:26Z", "commit": {"oid": "afa4facc8ccc21673cc48e5d9d980cb0cba98501"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 13, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQwMDo1NDoyNlrOGVy-LQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQwMTo0NzowNlrOGVzxIg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTUwODM5Nw==", "bodyText": "nit: change skip.start.docker to skip.run.docker to be consistent", "url": "https://github.com/apache/druid/pull/9854#discussion_r425508397", "createdAt": "2020-05-15T00:54:26Z", "author": {"login": "maytasm"}, "path": "integration-tests/pom.xml", "diffHunk": "@@ -374,21 +375,23 @@\n                         <artifactId>exec-maven-plugin</artifactId>\n                         <executions>\n                             <execution>\n-                                <id>build-and-start-druid-cluster</id>\n+                                <id>docker-package</id>\n                                 <goals>\n                                     <goal>exec</goal>\n                                 </goals>\n                                 <phase>pre-integration-test</phase>\n                                 <configuration>\n                                     <environmentVariables>\n-                                    <DRUID_INTEGRATION_TEST_START_HADOOP_DOCKER>${start.hadoop.docker}</DRUID_INTEGRATION_TEST_START_HADOOP_DOCKER>\n-                                    <DRUID_INTEGRATION_TEST_SKIP_START_DOCKER>${skip.start.docker}</DRUID_INTEGRATION_TEST_SKIP_START_DOCKER>\n-                                    <DRUID_INTEGRATION_TEST_JVM_RUNTIME>${jvm.runtime}</DRUID_INTEGRATION_TEST_JVM_RUNTIME>\n-                                    <DRUID_INTEGRATION_TEST_GROUP>${groups}</DRUID_INTEGRATION_TEST_GROUP>\n-                                    <DRUID_INTEGRATION_TEST_OVERRIDE_CONFIG_PATH>${override.config.path}</DRUID_INTEGRATION_TEST_OVERRIDE_CONFIG_PATH>\n-                                    <DRUID_INTEGRATION_TEST_RESOURCE_FILE_DIR_PATH>${resource.file.dir.path}</DRUID_INTEGRATION_TEST_RESOURCE_FILE_DIR_PATH>>\n+                                        <DRUID_INTEGRATION_TEST_START_HADOOP_DOCKER>${start.hadoop.docker}</DRUID_INTEGRATION_TEST_START_HADOOP_DOCKER>\n+                                        <DRUID_INTEGRATION_TEST_JVM_RUNTIME>${jvm.runtime}</DRUID_INTEGRATION_TEST_JVM_RUNTIME>\n+                                        <DRUID_INTEGRATION_TEST_GROUP>${groups}</DRUID_INTEGRATION_TEST_GROUP>\n+                                        <DRUID_INTEGRATION_TEST_OVERRIDE_CONFIG_PATH>${override.config.path}</DRUID_INTEGRATION_TEST_OVERRIDE_CONFIG_PATH>\n+                                        <DRUID_INTEGRATION_TEST_RESOURCE_FILE_DIR_PATH>${resource.file.dir.path}</DRUID_INTEGRATION_TEST_RESOURCE_FILE_DIR_PATH>\n+                                        <DRUID_INTEGRATION_TEST_SKIP_BUILD_DOCKER>${skip.build.docker}</DRUID_INTEGRATION_TEST_SKIP_BUILD_DOCKER>\n+                                        <DRUID_INTEGRATION_TEST_SKIP_RUN_DOCKER>${skip.start.docker}</DRUID_INTEGRATION_TEST_SKIP_RUN_DOCKER>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "afa4facc8ccc21673cc48e5d9d980cb0cba98501"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTUwODcwMg==", "bodyText": "Where is the below deleted?\nWhy is the int-tests-config-file removed?", "url": "https://github.com/apache/druid/pull/9854#discussion_r425508702", "createdAt": "2020-05-15T00:55:31Z", "author": {"login": "maytasm"}, "path": "integration-tests/pom.xml", "diffHunk": "@@ -446,61 +450,7 @@\n                             </suiteXmlFiles>\n                         </configuration>\n                     </plugin>\n-                    <plugin>\n-                        <groupId>de.thetaphi</groupId>\n-                        <artifactId>forbiddenapis</artifactId>\n-                        <configuration>\n-                            <signaturesFiles>\n-                                <!-- Needed because of https://github.com/policeman-tools/forbidden-apis/issues/126 -->\n-                                <signaturesFile>../codestyle/joda-time-forbidden-apis.txt</signaturesFile>\n-                                <signaturesFile>../codestyle/druid-forbidden-apis.txt</signaturesFile>\n-                            </signaturesFiles>\n-                        </configuration>\n-                    </plugin>\n-                </plugins>\n-            </build>\n-        </profile>\n-        <profile>\n-            <id>int-tests-config-file</id>\n-            <build>\n-                <plugins>\n-                    <plugin>\n-                        <groupId>org.apache.maven.plugins</groupId>\n-                        <artifactId>maven-failsafe-plugin</artifactId>\n-                        <executions>\n-                            <execution>\n-                                <id>integration-tests</id>\n-                                <phase>integration-test</phase>\n-                                <goals>\n-                                    <goal>integration-test</goal>\n-                                    <goal>verify</goal>\n-                                </goals>\n-                            </execution>\n-                        </executions>\n-                        <configuration>\n-                            <properties>\n-                                <property>\n-                                    <name>testrunfactory</name>\n-                                    <value>org.testng.DruidTestRunnerFactory</value>\n-                                </property>\n-                            </properties>\n-                            <argLine>\n-                                -Duser.timezone=UTC\n-                                -Dfile.encoding=UTF-8\n-                                -Ddruid.test.config.type=configFile\n-                                -Ddruid.test.config.configFile=${env.CONFIG_FILE}\n-                                -Ddruid.client.https.trustStorePath=client_tls/truststore.jks\n-                                -Ddruid.client.https.trustStorePassword=druid123\n-                                -Ddruid.client.https.keyStorePath=client_tls/client.jks\n-                                -Ddruid.client.https.certAlias=druid\n-                                -Ddruid.client.https.keyManagerPassword=druid123\n-                                -Ddruid.client.https.keyStorePassword=druid123\n-                            </argLine>\n-                            <suiteXmlFiles>\n-                                <suiteXmlFile>src/test/resources/testng.xml</suiteXmlFile>\n-                            </suiteXmlFiles>\n-                        </configuration>\n-                    </plugin>\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "afa4facc8ccc21673cc48e5d9d980cb0cba98501"}, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTUxMjgwNQ==", "bodyText": "nit:new line", "url": "https://github.com/apache/druid/pull/9854#discussion_r425512805", "createdAt": "2020-05-15T01:12:15Z", "author": {"login": "maytasm"}, "path": "integration-tests/script/copy_resources.sh", "diffHunk": "@@ -0,0 +1,80 @@\n+#!/usr/bin/env bash\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+# setup client keystore\n+./docker/tls/generate-client-certs-and-keystores.sh\n+rm -rf docker/client_tls\n+cp -r client_tls docker/client_tls\n+\n+# Make directories if they dont exist\n+mkdir -p $SHARED_DIR/hadoop_xml\n+mkdir -p $SHARED_DIR/hadoop-dependencies\n+mkdir -p $SHARED_DIR/logs\n+mkdir -p $SHARED_DIR/tasklogs\n+mkdir -p $SHARED_DIR/docker/extensions\n+mkdir -p $SHARED_DIR/docker/credentials\n+\n+# install druid jars\n+rm -rf $SHARED_DIR/docker\n+cp -R docker $SHARED_DIR/docker\n+mvn -B dependency:copy-dependencies -DoutputDirectory=$SHARED_DIR/docker/lib\n+\n+# move extensions into a seperate extension folder\n+# For druid-s3-extensions\n+mkdir -p $SHARED_DIR/docker/extensions/druid-s3-extensions\n+mv $SHARED_DIR/docker/lib/druid-s3-extensions-* $SHARED_DIR/docker/extensions/druid-s3-extensions\n+# For druid-azure-extensions\n+mkdir -p $SHARED_DIR/docker/extensions/druid-azure-extensions\n+mv $SHARED_DIR/docker/lib/druid-azure-extensions-* $SHARED_DIR/docker/extensions/druid-azure-extensions\n+# For druid-google-extensions\n+mkdir -p $SHARED_DIR/docker/extensions/druid-google-extensions\n+mv $SHARED_DIR/docker/lib/druid-google-extensions-* $SHARED_DIR/docker/extensions/druid-google-extensions\n+# For druid-hdfs-storage\n+mkdir -p $SHARED_DIR/docker/extensions/druid-hdfs-storage\n+mv $SHARED_DIR/docker/lib/druid-hdfs-storage-* $SHARED_DIR/docker/extensions/druid-hdfs-storage\n+# For druid-kinesis-indexing-service\n+mkdir -p $SHARED_DIR/docker/extensions/druid-kinesis-indexing-service\n+mv $SHARED_DIR/docker/lib/druid-kinesis-indexing-service-* $SHARED_DIR/docker/extensions/druid-kinesis-indexing-service\n+# For druid-parquet-extensions\n+mkdir -p $SHARED_DIR/docker/extensions/druid-parquet-extensions\n+mv $SHARED_DIR/docker/lib/druid-parquet-extensions-* $SHARED_DIR/docker/extensions/druid-parquet-extensions\n+# For druid-orc-extensions\n+mkdir -p $SHARED_DIR/docker/extensions/druid-orc-extensions\n+mv $SHARED_DIR/docker/lib/druid-orc-extensions-* $SHARED_DIR/docker/extensions/druid-orc-extensions\n+\n+# Pull Hadoop dependency if needed\n+if [ -n \"$DRUID_INTEGRATION_TEST_START_HADOOP_DOCKER\" ] && [ \"$DRUID_INTEGRATION_TEST_START_HADOOP_DOCKER\" == true ]\n+then\n+  java -cp \"$SHARED_DIR/docker/lib/*\" -Ddruid.extensions.hadoopDependenciesDir=\"$SHARED_DIR/hadoop-dependencies\" org.apache.druid.cli.Main tools pull-deps -h org.apache.hadoop:hadoop-client:2.8.5 -h org.apache.hadoop:hadoop-aws:2.8.5 -h org.apache.hadoop:hadoop-azure:2.8.5\n+  curl https://storage.googleapis.com/hadoop-lib/gcs/gcs-connector-hadoop2-latest.jar --output $SHARED_DIR/docker/lib/gcs-connector-hadoop2-latest.jar\n+fi\n+\n+# install logging config\n+cp src/main/resources/log4j2.xml $SHARED_DIR/docker/lib/log4j2.xml\n+\n+# copy the integration test jar, it provides test-only extension implementations\n+cp target/druid-integration-tests*.jar $SHARED_DIR/docker/lib\n+\n+# one of the integration tests needs the wikiticker sample data\n+mkdir -p $SHARED_DIR/wikiticker-it\n+cp ../examples/quickstart/tutorial/wikiticker-2015-09-12-sampled.json.gz $SHARED_DIR/wikiticker-it/wikiticker-2015-09-12-sampled.json.gz\n+cp docker/wiki-simple-lookup.json $SHARED_DIR/wikiticker-it/wiki-simple-lookup.json\n+\n+# copy other files if needed\n+if [ -n \"$DRUID_INTEGRATION_TEST_RESOURCE_FILE_DIR_PATH\" ]\n+then\n+  cp -a $DRUID_INTEGRATION_TEST_RESOURCE_FILE_DIR_PATH/. $SHARED_DIR/docker/credentials/\n+fi", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "afa4facc8ccc21673cc48e5d9d980cb0cba98501"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTUxMjk1MQ==", "bodyText": "nit:new line", "url": "https://github.com/apache/druid/pull/9854#discussion_r425512951", "createdAt": "2020-05-15T01:12:47Z", "author": {"login": "maytasm"}, "path": "integration-tests/script/copy_hadoop_resources.sh", "diffHunk": "@@ -0,0 +1,44 @@\n+#!/usr/bin/env bash\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+# wait for hadoop namenode to be up\n+echo \"Waiting for hadoop namenode to be up\"\n+docker exec -t druid-it-hadoop sh -c \"./usr/local/hadoop/bin/hdfs dfs -mkdir -p /druid\"\n+while [ $? -ne 0 ]\n+do\n+   sleep 2\n+   docker exec -t druid-it-hadoop sh -c \"./usr/local/hadoop/bin/hdfs dfs -mkdir -p /druid\"\n+done\n+echo \"Finished waiting for Hadoop namenode\"\n+\n+# Setup hadoop druid dirs\n+echo \"Setting up druid hadoop dirs\"\n+docker exec -t druid-it-hadoop sh -c \"./usr/local/hadoop/bin/hdfs dfs -mkdir -p /druid\"\n+docker exec -t druid-it-hadoop sh -c \"./usr/local/hadoop/bin/hdfs dfs -mkdir -p /druid/segments\"\n+docker exec -t druid-it-hadoop sh -c \"./usr/local/hadoop/bin/hdfs dfs -mkdir -p /quickstart\"\n+docker exec -t druid-it-hadoop sh -c \"./usr/local/hadoop/bin/hdfs dfs -chmod 777 /druid\"\n+docker exec -t druid-it-hadoop sh -c \"./usr/local/hadoop/bin/hdfs dfs -chmod 777 /druid/segments\"\n+docker exec -t druid-it-hadoop sh -c \"./usr/local/hadoop/bin/hdfs dfs -chmod 777 /quickstart\"\n+docker exec -t druid-it-hadoop sh -c \"./usr/local/hadoop/bin/hdfs dfs -chmod -R 777 /tmp\"\n+docker exec -t druid-it-hadoop sh -c \"./usr/local/hadoop/bin/hdfs dfs -chmod -R 777 /user\"\n+# Copy data files to Hadoop container\n+docker exec -t druid-it-hadoop sh -c \"./usr/local/hadoop/bin/hdfs dfs -put /shared/wikiticker-it/wikiticker-2015-09-12-sampled.json.gz /quickstart/wikiticker-2015-09-12-sampled.json.gz\"\n+docker exec -t druid-it-hadoop sh -c \"./usr/local/hadoop/bin/hdfs dfs -put /resources/data/batch_index /batch_index\"\n+echo \"Finished setting up druid hadoop dirs\"\n+\n+echo \"Copying Hadoop XML files to shared\"\n+docker exec -t druid-it-hadoop sh -c \"cp /usr/local/hadoop/etc/hadoop/*.xml /shared/hadoop_xml\"\n+echo \"Copied Hadoop XML files to shared\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "afa4facc8ccc21673cc48e5d9d980cb0cba98501"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTUxNDkzMQ==", "bodyText": "stop_cluster.sh has a check for DRUID_INTEGRATION_TEST_SKIP_STOP_DOCKER\nThe check for DRUID_INTEGRATION_TEST_SKIP_STOP_DOCKER is too skip teardown of the cluster after the test finish running (for debugging). In this case, where we are stopping the cluster so that we can start then fresh to run integration test, we should skip checking DRUID_INTEGRATION_TEST_SKIP_STOP_DOCKER here.", "url": "https://github.com/apache/druid/pull/9854#discussion_r425514931", "createdAt": "2020-05-15T01:21:26Z", "author": {"login": "maytasm"}, "path": "integration-tests/build_run_cluster.sh", "diffHunk": "@@ -0,0 +1,43 @@\n+#!/usr/bin/env bash\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+echo $DRUID_INTEGRATION_TEST_OVERRIDE_CONFIG_PATH\n+\n+export DIR=$(cd $(dirname $0) && pwd)\n+export HADOOP_DOCKER_DIR=$DIR/../examples/quickstart/tutorial/hadoop/docker\n+export DOCKERDIR=$DIR/docker\n+export SERVICE_SUPERVISORDS_DIR=$DOCKERDIR/service-supervisords\n+export ENVIRONMENT_CONFIGS_DIR=$DOCKERDIR/environment-configs\n+export SHARED_DIR=${HOME}/shared\n+export SUPERVISORDIR=/usr/lib/druid/conf\n+export RESOURCEDIR=$DIR/src/test/resources\n+\n+# so docker IP addr will be known during docker build\n+echo ${DOCKER_IP:=127.0.0.1} > $DOCKERDIR/docker_ip\n+\n+if !($DRUID_INTEGRATION_TEST_SKIP_BUILD_DOCKER); then\n+  sh ./script/copy_resources.sh\n+  sh ./script/docker_build_containers.sh\n+fi\n+\n+if !($DRUID_INTEGRATION_TEST_SKIP_RUN_DOCKER); then\n+  sh ./stop_cluster.sh", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "afa4facc8ccc21673cc48e5d9d980cb0cba98501"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTUxNTczMQ==", "bodyText": "Why the split DRUID_INTEGRATION_TEST_SKIP_BUILD_DOCKER and DRUID_INTEGRATION_TEST_SKIP_RUN_DOCKER?\nI don't think we should ever want to BUILD but not RUN. I am also not really sure if having not BUILD and run is that useful. If your cluster is not running then you are not sure what state it is in, might as well be better to build and start fresh.", "url": "https://github.com/apache/druid/pull/9854#discussion_r425515731", "createdAt": "2020-05-15T01:24:51Z", "author": {"login": "maytasm"}, "path": "integration-tests/build_run_cluster.sh", "diffHunk": "@@ -0,0 +1,43 @@\n+#!/usr/bin/env bash\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+echo $DRUID_INTEGRATION_TEST_OVERRIDE_CONFIG_PATH\n+\n+export DIR=$(cd $(dirname $0) && pwd)\n+export HADOOP_DOCKER_DIR=$DIR/../examples/quickstart/tutorial/hadoop/docker\n+export DOCKERDIR=$DIR/docker\n+export SERVICE_SUPERVISORDS_DIR=$DOCKERDIR/service-supervisords\n+export ENVIRONMENT_CONFIGS_DIR=$DOCKERDIR/environment-configs\n+export SHARED_DIR=${HOME}/shared\n+export SUPERVISORDIR=/usr/lib/druid/conf\n+export RESOURCEDIR=$DIR/src/test/resources\n+\n+# so docker IP addr will be known during docker build\n+echo ${DOCKER_IP:=127.0.0.1} > $DOCKERDIR/docker_ip\n+\n+if !($DRUID_INTEGRATION_TEST_SKIP_BUILD_DOCKER); then", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "afa4facc8ccc21673cc48e5d9d980cb0cba98501"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTUxNjQyNQ==", "bodyText": "copy_hadoop_resources.sh have to be run after hadoop cluster started BUT BEFORE the other druid containers start.", "url": "https://github.com/apache/druid/pull/9854#discussion_r425516425", "createdAt": "2020-05-15T01:27:39Z", "author": {"login": "maytasm"}, "path": "integration-tests/build_run_cluster.sh", "diffHunk": "@@ -0,0 +1,43 @@\n+#!/usr/bin/env bash\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+echo $DRUID_INTEGRATION_TEST_OVERRIDE_CONFIG_PATH\n+\n+export DIR=$(cd $(dirname $0) && pwd)\n+export HADOOP_DOCKER_DIR=$DIR/../examples/quickstart/tutorial/hadoop/docker\n+export DOCKERDIR=$DIR/docker\n+export SERVICE_SUPERVISORDS_DIR=$DOCKERDIR/service-supervisords\n+export ENVIRONMENT_CONFIGS_DIR=$DOCKERDIR/environment-configs\n+export SHARED_DIR=${HOME}/shared\n+export SUPERVISORDIR=/usr/lib/druid/conf\n+export RESOURCEDIR=$DIR/src/test/resources\n+\n+# so docker IP addr will be known during docker build\n+echo ${DOCKER_IP:=127.0.0.1} > $DOCKERDIR/docker_ip\n+\n+if !($DRUID_INTEGRATION_TEST_SKIP_BUILD_DOCKER); then\n+  sh ./script/copy_resources.sh\n+  sh ./script/docker_build_containers.sh\n+fi\n+\n+if !($DRUID_INTEGRATION_TEST_SKIP_RUN_DOCKER); then\n+  sh ./stop_cluster.sh\n+  sh ./script/docker_run_cluster.sh\n+fi\n+\n+if ($DRUID_INTEGRATION_TEST_START_HADOOP_DOCKER); then\n+  sh ./script/copy_hadoop_resources.sh", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "afa4facc8ccc21673cc48e5d9d980cb0cba98501"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTUxNzk3Mg==", "bodyText": "Can you add \"hdfs-deep-storage\", \"s3-ingestion\", \"kinesis-index\", and \"kinesis-data-format\" to this list too.", "url": "https://github.com/apache/druid/pull/9854#discussion_r425517972", "createdAt": "2020-05-15T01:33:27Z", "author": {"login": "maytasm"}, "path": "integration-tests/script/docker_run_cluster.sh", "diffHunk": "@@ -0,0 +1,63 @@\n+#!/usr/bin/env bash\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+# Create docker network\n+{\n+  docker network create --subnet=172.172.172.0/24 druid-it-net\n+}\n+\n+# setup all enviornment variables to be pass to the containers\n+COMMON_ENV=\"--env-file=$ENVIRONMENT_CONFIGS_DIR/common -e DRUID_INTEGRATION_TEST_GROUP\"\n+BROKER_ENV=\"--env-file=$ENVIRONMENT_CONFIGS_DIR/broker\"\n+COORDINATOR_ENV=\"--env-file=$ENVIRONMENT_CONFIGS_DIR/coordinator\"\n+HISTORICAL_ENV=\"--env-file=$ENVIRONMENT_CONFIGS_DIR/historical\"\n+MIDDLEMANAGER_ENV=\"--env-file=$ENVIRONMENT_CONFIGS_DIR/middlemanager\"\n+OVERLORD_ENV=\"--env-file=$ENVIRONMENT_CONFIGS_DIR/overlord\"\n+ROUTER_ENV=\"--env-file=$ENVIRONMENT_CONFIGS_DIR/router\"\n+ROUTER_CUSTOM_CHECK_TLS_ENV=\"--env-file=$ENVIRONMENT_CONFIGS_DIR/router-custom-check-tls\"\n+ROUTER_NO_CLIENT_AUTH_TLS_ENV=\"--env-file=$ENVIRONMENT_CONFIGS_DIR/router-no-client-auth-tls\"\n+ROUTER_PERMISSIVE_TLS_ENV=\"--env-file=$ENVIRONMENT_CONFIGS_DIR/router-permissive-tls\"\n+\n+if [ -z \"$DRUID_INTEGRATION_TEST_OVERRIDE_CONFIG_PATH\" ]\n+then\n+    echo \"\\$DRUID_INTEGRATION_TEST_OVERRIDE_CONFIG_PATH is not set. No override config file provided\"\n+    if [ \"$DRUID_INTEGRATION_TEST_GROUP\" = \"s3-deep-storage\" ] || \\\n+    [ \"$DRUID_INTEGRATION_TEST_GROUP\" = \"gcs-deep-storage\" ] || \\\n+    [ \"$DRUID_INTEGRATION_TEST_GROUP\" = \"azure-deep-storage\" ]; then", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "afa4facc8ccc21673cc48e5d9d980cb0cba98501"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTUxOTk0Mw==", "bodyText": "What is the purpose of this since we already have integration-tests/docker/docker-compose.override-env.yml\nNote that the env file in environment-configs/override-examples/ is never meant to be use as-is or modified directly. User should copy this and write their own override env file and use integration-tests/docker/docker-compose.override-env.yml", "url": "https://github.com/apache/druid/pull/9854#discussion_r425519943", "createdAt": "2020-05-15T01:41:14Z", "author": {"login": "maytasm"}, "path": "integration-tests/docker/docker-compose.gcs.yml", "diffHunk": "@@ -0,0 +1,182 @@\n+# Licensed to the Apache Software Foundation (ASF) under one or more", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "afa4facc8ccc21673cc48e5d9d980cb0cba98501"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTUyMDAxNA==", "bodyText": "What is the purpose of this since we already have integration-tests/docker/docker-compose.override-env.yml\nNote that the env file in environment-configs/override-examples/ is never meant to be use as-is or modified directly. User should copy this and write their own override env file and use integration-tests/docker/docker-compose.override-env.yml", "url": "https://github.com/apache/druid/pull/9854#discussion_r425520014", "createdAt": "2020-05-15T01:41:38Z", "author": {"login": "maytasm"}, "path": "integration-tests/docker/docker-compose.azure.yml", "diffHunk": "@@ -0,0 +1,182 @@\n+# Licensed to the Apache Software Foundation (ASF) under one or more", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "afa4facc8ccc21673cc48e5d9d980cb0cba98501"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTUyMDQ2Mg==", "bodyText": "What is the purpose of this since we already have integration-tests/docker/docker-compose.override-env.yml\nNote that the env file in environment-configs/override-examples/ is never meant to be use as-is or modified directly. User should copy this and write their own override env file and use integration-tests/docker/docker-compose.override-env.yml", "url": "https://github.com/apache/druid/pull/9854#discussion_r425520462", "createdAt": "2020-05-15T01:43:17Z", "author": {"login": "maytasm"}, "path": "integration-tests/docker/docker-compose.s3.yml", "diffHunk": "@@ -0,0 +1,182 @@\n+# Licensed to the Apache Software Foundation (ASF) under one or more", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "afa4facc8ccc21673cc48e5d9d980cb0cba98501"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTUyMDkyMw==", "bodyText": "Do we need both integration-tests/docker/docker-compose.test-env.yml and integration-tests/docker/docker-compose.yml?", "url": "https://github.com/apache/druid/pull/9854#discussion_r425520923", "createdAt": "2020-05-15T01:45:09Z", "author": {"login": "maytasm"}, "path": "integration-tests/docker/docker-compose.test-env.yml", "diffHunk": "@@ -0,0 +1,173 @@\n+# Licensed to the Apache Software Foundation (ASF) under one or more", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "afa4facc8ccc21673cc48e5d9d980cb0cba98501"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNTUyMTQ0Mg==", "bodyText": "Is it possible to use the environment variables we define in the scripts for the path to mount volumes and env files here. (i.e.  COMMON_ENV, SERVICE_SUPERVISORDS_DIR, SUPERVISORDIR, RESOURCEDIR, etc.)", "url": "https://github.com/apache/druid/pull/9854#discussion_r425521442", "createdAt": "2020-05-15T01:47:06Z", "author": {"login": "maytasm"}, "path": "integration-tests/docker/docker-compose.base.yml", "diffHunk": "@@ -0,0 +1,271 @@\n+# Licensed to the Apache Software Foundation (ASF) under one or more", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "afa4facc8ccc21673cc48e5d9d980cb0cba98501"}, "originalPosition": 1}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "61c4a1016a3be2bda2f1c0b23d8e3cf9b8b8eef0", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/61c4a1016a3be2bda2f1c0b23d8e3cf9b8b8eef0", "committedDate": "2020-05-15T10:54:10Z", "message": "Integration Tests. Removed nit"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5b6ece926fb6378cf0332fa6794bc8510c77dc97", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/5b6ece926fb6378cf0332fa6794bc8510c77dc97", "committedDate": "2020-05-15T10:59:12Z", "message": "Integration Tests. Updated if block in docker_run_cluster.sh."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "410d0cdf80045d9b274fa4f54841f9749fb0c47b", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/410d0cdf80045d9b274fa4f54841f9749fb0c47b", "committedDate": "2020-05-15T11:24:51Z", "message": "Integration Tests. Readme. Added Docker-compose section."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "55ee7a5134eeefc3df36e56696f31069c098b903", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/55ee7a5134eeefc3df36e56696f31069c098b903", "committedDate": "2020-05-15T12:01:20Z", "message": "Integration Tests. removed yml files for s3, gcs, azure.\nRenamed variables for skip start/stop/build docker.\nUpdated readme.\nRollback maven profile: int-tests-config-file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "578bca258cd81d23eb15e2f9345f34f0c56120df", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/578bca258cd81d23eb15e2f9345f34f0c56120df", "committedDate": "2020-05-15T12:19:09Z", "message": "Integration Tests. Removed docker-compose.test-env.yml file.\nAdded DRUID_INTEGRATION_TEST_GROUP variable to docker-compose.yml"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDEyOTc4MDQx", "url": "https://github.com/apache/druid/pull/9854#pullrequestreview-412978041", "createdAt": "2020-05-15T21:26:58Z", "commit": {"oid": "578bca258cd81d23eb15e2f9345f34f0c56120df"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQyMToyNjo1OVrOGWUU0Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQyMToyNjo1OVrOGWUU0Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjA1NDg2NQ==", "bodyText": "Can you mention that this is only if there is no code change to Druid. For example, your integration tests that you are writing might actually catch real bugs in the code. Then after you attempt to fix bug in code, you will need to build druid again.", "url": "https://github.com/apache/druid/pull/9854#discussion_r426054865", "createdAt": "2020-05-15T21:26:59Z", "author": {"login": "maytasm"}, "path": "integration-tests/README.md", "diffHunk": "@@ -68,16 +68,48 @@ can either be 8 or 11.\n Druid's configuration (using Docker) can be overrided by providing -Doverride.config.path=<PATH_TO_FILE>. \n The file must contain one property per line, the key must start with `druid_` and the format should be snake case. \n \n+## Running tests by docker-compose + mvn\n+\n+Build druid-cluster, druid-hadoop docker images. From root module run maven command:\n+```\n+mvn clean install -pl integration-tests -P integration-tests -Ddocker.run.skip=true -Dmaven.test.skip=true\n+```\n+\n+Run druid cluster by docker-compose:\n+```\n+docker-compose -f integration-tests/docker/docker-compose.yml up\n+```\n+\n+Run integration tests:\n+```\n+mvn verify -pl integration-tests -P integration-tests -Dgroups=batch-index -Djvm.runtime=8 -Pskip-static-checks -Ddruid.console.skip=true -Dmaven.javadoc.skip=true -Ddocker.run.skip=true -Ddocker.build.skip=true\n+```\n+\n+Run s3 | azure | gcs integration tests:\n+\n+Prepare configuration for integration tests:\n+```\n+   integration-tests/docker/environment-configs/override-examples/*\n+```\n+\n+Run docker compose for one of group:\n+```\n+    docker-compose -f integration-tests/docker/docker-compose-s3.yml up\n+```\n+\n+Run maven command to execute tests. \n+> See: Running a Test That Uses Cloud \n+\n ## Tips & tricks for debugging and developing integration tests\n \n ### Useful mvn command flags\n \n-- -Dskip.start.docker=true to skip starting docker containers. This can save ~3 minutes by skipping building and bringing \n+- -Ddocker.build.skip=true to skip build druid containers. This can save ~4 minutes to build druid cluster and druid hadoop.\n+You need to build druid containers only once, after you can skip docker build step. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "578bca258cd81d23eb15e2f9345f34f0c56120df"}, "originalPosition": 42}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDEyOTc5OTE1", "url": "https://github.com/apache/druid/pull/9854#pullrequestreview-412979915", "createdAt": "2020-05-15T21:31:05Z", "commit": {"oid": "578bca258cd81d23eb15e2f9345f34f0c56120df"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQyMTozMTowNVrOGWUasw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQyMTozMTowNVrOGWUasw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjA1NjM3MQ==", "bodyText": "I think this is not needed as this is still the same as the instruction above. Since we already have the instruction to run the test in ## Running tests and instruction on using -Ddocker.x.skip, I think this is redundant.", "url": "https://github.com/apache/druid/pull/9854#discussion_r426056371", "createdAt": "2020-05-15T21:31:05Z", "author": {"login": "maytasm"}, "path": "integration-tests/README.md", "diffHunk": "@@ -68,16 +68,48 @@ can either be 8 or 11.\n Druid's configuration (using Docker) can be overrided by providing -Doverride.config.path=<PATH_TO_FILE>. \n The file must contain one property per line, the key must start with `druid_` and the format should be snake case. \n \n+## Running tests by docker-compose + mvn\n+\n+Build druid-cluster, druid-hadoop docker images. From root module run maven command:\n+```\n+mvn clean install -pl integration-tests -P integration-tests -Ddocker.run.skip=true -Dmaven.test.skip=true\n+```\n+\n+Run druid cluster by docker-compose:\n+```\n+docker-compose -f integration-tests/docker/docker-compose.yml up\n+```\n+\n+Run integration tests:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "578bca258cd81d23eb15e2f9345f34f0c56120df"}, "originalPosition": 16}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDEyOTgwODg1", "url": "https://github.com/apache/druid/pull/9854#pullrequestreview-412980885", "createdAt": "2020-05-15T21:33:21Z", "commit": {"oid": "578bca258cd81d23eb15e2f9345f34f0c56120df"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQyMTozMzoyMlrOGWUdwQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQyMTozMzoyMlrOGWUdwQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjA1NzE1Mw==", "bodyText": "We do not need to run build and docker-compose manually right?\nIf we run mvn verify -pl integration-tests -P integration-tests... then it should automatically build and run docker containers. If that is the case, I think this section can be rename to instruction for using/manually bringing up docker containers instead of running tests.", "url": "https://github.com/apache/druid/pull/9854#discussion_r426057153", "createdAt": "2020-05-15T21:33:22Z", "author": {"login": "maytasm"}, "path": "integration-tests/README.md", "diffHunk": "@@ -68,16 +68,48 @@ can either be 8 or 11.\n Druid's configuration (using Docker) can be overrided by providing -Doverride.config.path=<PATH_TO_FILE>. \n The file must contain one property per line, the key must start with `druid_` and the format should be snake case. \n \n+## Running tests by docker-compose + mvn", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "578bca258cd81d23eb15e2f9345f34f0c56120df"}, "originalPosition": 4}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDEyOTgxMjIy", "url": "https://github.com/apache/druid/pull/9854#pullrequestreview-412981222", "createdAt": "2020-05-15T21:34:06Z", "commit": {"oid": "578bca258cd81d23eb15e2f9345f34f0c56120df"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQyMTozNDowN1rOGWUeww==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQyMTozNDowN1rOGWUeww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjA1NzQxMQ==", "bodyText": "I think this is not needed. If we run mvn verify -pl integration-tests -P integration-tests... then it should automatically build and run docker containers. If that is the case, the instruction in Running a Test That Uses Cloud  should be enough", "url": "https://github.com/apache/druid/pull/9854#discussion_r426057411", "createdAt": "2020-05-15T21:34:07Z", "author": {"login": "maytasm"}, "path": "integration-tests/README.md", "diffHunk": "@@ -68,16 +68,48 @@ can either be 8 or 11.\n Druid's configuration (using Docker) can be overrided by providing -Doverride.config.path=<PATH_TO_FILE>. \n The file must contain one property per line, the key must start with `druid_` and the format should be snake case. \n \n+## Running tests by docker-compose + mvn\n+\n+Build druid-cluster, druid-hadoop docker images. From root module run maven command:\n+```\n+mvn clean install -pl integration-tests -P integration-tests -Ddocker.run.skip=true -Dmaven.test.skip=true\n+```\n+\n+Run druid cluster by docker-compose:\n+```\n+docker-compose -f integration-tests/docker/docker-compose.yml up\n+```\n+\n+Run integration tests:\n+```\n+mvn verify -pl integration-tests -P integration-tests -Dgroups=batch-index -Djvm.runtime=8 -Pskip-static-checks -Ddruid.console.skip=true -Dmaven.javadoc.skip=true -Ddocker.run.skip=true -Ddocker.build.skip=true\n+```\n+\n+Run s3 | azure | gcs integration tests:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "578bca258cd81d23eb15e2f9345f34f0c56120df"}, "originalPosition": 21}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDEyOTgxNDMw", "url": "https://github.com/apache/druid/pull/9854#pullrequestreview-412981430", "createdAt": "2020-05-15T21:34:40Z", "commit": {"oid": "578bca258cd81d23eb15e2f9345f34f0c56120df"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQyMTozNDo0MFrOGWUfag==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQyMTozNDo0MFrOGWUfag==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjA1NzU3OA==", "bodyText": "I think this file no longer exist?", "url": "https://github.com/apache/druid/pull/9854#discussion_r426057578", "createdAt": "2020-05-15T21:34:40Z", "author": {"login": "maytasm"}, "path": "integration-tests/README.md", "diffHunk": "@@ -68,16 +68,48 @@ can either be 8 or 11.\n Druid's configuration (using Docker) can be overrided by providing -Doverride.config.path=<PATH_TO_FILE>. \n The file must contain one property per line, the key must start with `druid_` and the format should be snake case. \n \n+## Running tests by docker-compose + mvn\n+\n+Build druid-cluster, druid-hadoop docker images. From root module run maven command:\n+```\n+mvn clean install -pl integration-tests -P integration-tests -Ddocker.run.skip=true -Dmaven.test.skip=true\n+```\n+\n+Run druid cluster by docker-compose:\n+```\n+docker-compose -f integration-tests/docker/docker-compose.yml up\n+```\n+\n+Run integration tests:\n+```\n+mvn verify -pl integration-tests -P integration-tests -Dgroups=batch-index -Djvm.runtime=8 -Pskip-static-checks -Ddruid.console.skip=true -Dmaven.javadoc.skip=true -Ddocker.run.skip=true -Ddocker.build.skip=true\n+```\n+\n+Run s3 | azure | gcs integration tests:\n+\n+Prepare configuration for integration tests:\n+```\n+   integration-tests/docker/environment-configs/override-examples/*\n+```\n+\n+Run docker compose for one of group:\n+```\n+    docker-compose -f integration-tests/docker/docker-compose-s3.yml up", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "578bca258cd81d23eb15e2f9345f34f0c56120df"}, "originalPosition": 30}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDEyOTgyMTEy", "url": "https://github.com/apache/druid/pull/9854#pullrequestreview-412982112", "createdAt": "2020-05-15T21:36:16Z", "commit": {"oid": "578bca258cd81d23eb15e2f9345f34f0c56120df"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQyMTozNjoxNlrOGWUhdw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQyMTozNjoxNlrOGWUhdw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjA1ODEwMw==", "bodyText": "Thanks for adding \"Build druid-cluster, druid-hadoop docker images. From root module run maven command:\" and \"Run druid cluster by docker-compose:\". I think it might be nice if we document the variation of yml we have here too", "url": "https://github.com/apache/druid/pull/9854#discussion_r426058103", "createdAt": "2020-05-15T21:36:16Z", "author": {"login": "maytasm"}, "path": "integration-tests/README.md", "diffHunk": "@@ -68,16 +68,48 @@ can either be 8 or 11.\n Druid's configuration (using Docker) can be overrided by providing -Doverride.config.path=<PATH_TO_FILE>. \n The file must contain one property per line, the key must start with `druid_` and the format should be snake case. \n \n+## Running tests by docker-compose + mvn\n+\n+Build druid-cluster, druid-hadoop docker images. From root module run maven command:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "578bca258cd81d23eb15e2f9345f34f0c56120df"}, "originalPosition": 6}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDEyOTg0Mzcx", "url": "https://github.com/apache/druid/pull/9854#pullrequestreview-412984371", "createdAt": "2020-05-15T21:41:47Z", "commit": {"oid": "578bca258cd81d23eb15e2f9345f34f0c56120df"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQyMTo0MTo0N1rOGWUoXQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xNVQyMTo0MTo0N1rOGWUoXQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjA1OTg2OQ==", "bodyText": "Do we still need all of these variables?\nI think SERVICE_SUPERVISORDS_DIR, SUPERVISORDIR, RESOURCEDIR can be reomved since the yml doesn't use them", "url": "https://github.com/apache/druid/pull/9854#discussion_r426059869", "createdAt": "2020-05-15T21:41:47Z", "author": {"login": "maytasm"}, "path": "integration-tests/build_run_cluster.sh", "diffHunk": "@@ -0,0 +1,43 @@\n+#!/usr/bin/env bash\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+echo $DRUID_INTEGRATION_TEST_OVERRIDE_CONFIG_PATH\n+\n+export DIR=$(cd $(dirname $0) && pwd)\n+export HADOOP_DOCKER_DIR=$DIR/../examples/quickstart/tutorial/hadoop/docker\n+export DOCKERDIR=$DIR/docker\n+export SERVICE_SUPERVISORDS_DIR=$DOCKERDIR/service-supervisords", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "578bca258cd81d23eb15e2f9345f34f0c56120df"}, "originalPosition": 22}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1776ea2711f30aba860260fba11f867c6028f1aa", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/1776ea2711f30aba860260fba11f867c6028f1aa", "committedDate": "2020-05-18T09:42:07Z", "message": "Integration Tests. Readme. Added details about docker-compose"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4076bdba1c58ea568f4b21dbdb3bb7700f00fc43", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/4076bdba1c58ea568f4b21dbdb3bb7700f00fc43", "committedDate": "2020-05-18T10:14:14Z", "message": "Integration Tests. cleanup shell scripts"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE0MDcwNzIw", "url": "https://github.com/apache/druid/pull/9854#pullrequestreview-414070720", "createdAt": "2020-05-19T03:07:54Z", "commit": {"oid": "4076bdba1c58ea568f4b21dbdb3bb7700f00fc43"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIyMjQ3ODky", "url": "https://github.com/apache/druid/pull/9854#pullrequestreview-422247892", "createdAt": "2020-06-01T23:32:57Z", "commit": {"oid": "4076bdba1c58ea568f4b21dbdb3bb7700f00fc43"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c478c1ca1ee60e04093e36aabab8d512c4b6a1a3", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/c478c1ca1ee60e04093e36aabab8d512c4b6a1a3", "committedDate": "2020-06-02T11:57:00Z", "message": "Merge remote-tracking branch 'remotes/origin/master' into integration_tests_improvements_docker_compose"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "56d086d26fe255aa6a0c4c8715bd8fc3fd69fa84", "author": {"user": null}, "url": "https://github.com/apache/druid/commit/56d086d26fe255aa6a0c4c8715bd8fc3fd69fa84", "committedDate": "2020-06-02T12:15:44Z", "message": "Merge branch 'master' into integration_tests_improvements_docker_compose"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIyODYyMTAx", "url": "https://github.com/apache/druid/pull/9854#pullrequestreview-422862101", "createdAt": "2020-06-02T16:38:37Z", "commit": {"oid": "56d086d26fe255aa6a0c4c8715bd8fc3fd69fa84"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2315, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}