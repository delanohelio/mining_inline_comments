{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDI2MzM4NjMw", "number": 9965, "reviewThreads": {"totalCount": 29, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQwMTo0MTo1MlrOECYF3Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQyMTo0MDoxOVrOEGHkEg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcwOTI3MzI1OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/druid/server/http/DataSourcesResource.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQwMTo0MTo1MlrOGey9bQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQwMTo1ODoyNFrOGhiPCw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDk0NTM4OQ==", "bodyText": "I think this parameter should be something like forceMetadataPoll or forceMetadataRefresh something", "url": "https://github.com/apache/druid/pull/9965#discussion_r434945389", "createdAt": "2020-06-04T01:41:52Z", "author": {"login": "clintropolis"}, "path": "server/src/main/java/org/apache/druid/server/http/DataSourcesResource.java", "diffHunk": "@@ -391,6 +393,43 @@ public Response getServedSegmentsInInterval(\n     return getServedSegmentsInInterval(dataSourceName, full != null, theInterval::contains);\n   }\n \n+  @GET\n+  @Path(\"/{dataSourceName}/loadstatus\")\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @ResourceFilters(DatasourceResourceFilter.class)\n+  public Response getDatasourceLoadstatus(\n+      @PathParam(\"dataSourceName\") String dataSourceName,\n+      @QueryParam(\"interval\") @Nullable final String interval,\n+      @QueryParam(\"firstCheck\") @Nullable final Boolean firstCheck", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6dc035cb2d5dcf5796c7ad516ab39700ef7204a5"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzgxNzA5OQ==", "bodyText": "Done", "url": "https://github.com/apache/druid/pull/9965#discussion_r437817099", "createdAt": "2020-06-10T01:58:24Z", "author": {"login": "maytasm"}, "path": "server/src/main/java/org/apache/druid/server/http/DataSourcesResource.java", "diffHunk": "@@ -391,6 +393,43 @@ public Response getServedSegmentsInInterval(\n     return getServedSegmentsInInterval(dataSourceName, full != null, theInterval::contains);\n   }\n \n+  @GET\n+  @Path(\"/{dataSourceName}/loadstatus\")\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @ResourceFilters(DatasourceResourceFilter.class)\n+  public Response getDatasourceLoadstatus(\n+      @PathParam(\"dataSourceName\") String dataSourceName,\n+      @QueryParam(\"interval\") @Nullable final String interval,\n+      @QueryParam(\"firstCheck\") @Nullable final Boolean firstCheck", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDk0NTM4OQ=="}, "originalCommit": {"oid": "6dc035cb2d5dcf5796c7ad516ab39700ef7204a5"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcwOTI3OTMxOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/druid/server/http/DataSourcesResource.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQwMTo0NToxMFrOGezBCg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQwMTo1OTo1OFrOGhiQog==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDk0NjMxNA==", "bodyText": "It seems a little off that not having serverInventoryView or it not being initialized would return a {\"loaded\":false} but a datasource not existing would be an empty response. I think this response is fine, but maybe the serverInventoryView == null case should be an error response indicating that information in unavailable", "url": "https://github.com/apache/druid/pull/9965#discussion_r434946314", "createdAt": "2020-06-04T01:45:10Z", "author": {"login": "clintropolis"}, "path": "server/src/main/java/org/apache/druid/server/http/DataSourcesResource.java", "diffHunk": "@@ -391,6 +393,43 @@ public Response getServedSegmentsInInterval(\n     return getServedSegmentsInInterval(dataSourceName, full != null, theInterval::contains);\n   }\n \n+  @GET\n+  @Path(\"/{dataSourceName}/loadstatus\")\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @ResourceFilters(DatasourceResourceFilter.class)\n+  public Response getDatasourceLoadstatus(\n+      @PathParam(\"dataSourceName\") String dataSourceName,\n+      @QueryParam(\"interval\") @Nullable final String interval,\n+      @QueryParam(\"firstCheck\") @Nullable final Boolean firstCheck\n+  )\n+  {\n+    if (serverInventoryView == null || serverInventoryView.getSegmentLoadInfos() == null) {\n+      return Response.ok(ImmutableMap.of(\"loaded\", false)).build();\n+    }\n+    // Force poll\n+    Interval theInterval = interval == null ? Intervals.ETERNITY : Intervals.of(interval);\n+    boolean requiresMetadataStorePoll = firstCheck == null ? true :firstCheck;\n+\n+    Optional<Iterable<DataSegment>> segments = segmentsMetadataManager.iterateAllUsedNonOvershadowedSegmentsForDatasourceInterval(\n+        dataSourceName,\n+        theInterval,\n+        requiresMetadataStorePoll\n+    );\n+\n+    if (!segments.isPresent()) {\n+      return logAndCreateDataSourceNotFoundResponse(dataSourceName);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6dc035cb2d5dcf5796c7ad516ab39700ef7204a5"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzgxNzUwNg==", "bodyText": "serverInventoryView and segmentLoadInfos are never null", "url": "https://github.com/apache/druid/pull/9965#discussion_r437817506", "createdAt": "2020-06-10T01:59:58Z", "author": {"login": "maytasm"}, "path": "server/src/main/java/org/apache/druid/server/http/DataSourcesResource.java", "diffHunk": "@@ -391,6 +393,43 @@ public Response getServedSegmentsInInterval(\n     return getServedSegmentsInInterval(dataSourceName, full != null, theInterval::contains);\n   }\n \n+  @GET\n+  @Path(\"/{dataSourceName}/loadstatus\")\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @ResourceFilters(DatasourceResourceFilter.class)\n+  public Response getDatasourceLoadstatus(\n+      @PathParam(\"dataSourceName\") String dataSourceName,\n+      @QueryParam(\"interval\") @Nullable final String interval,\n+      @QueryParam(\"firstCheck\") @Nullable final Boolean firstCheck\n+  )\n+  {\n+    if (serverInventoryView == null || serverInventoryView.getSegmentLoadInfos() == null) {\n+      return Response.ok(ImmutableMap.of(\"loaded\", false)).build();\n+    }\n+    // Force poll\n+    Interval theInterval = interval == null ? Intervals.ETERNITY : Intervals.of(interval);\n+    boolean requiresMetadataStorePoll = firstCheck == null ? true :firstCheck;\n+\n+    Optional<Iterable<DataSegment>> segments = segmentsMetadataManager.iterateAllUsedNonOvershadowedSegmentsForDatasourceInterval(\n+        dataSourceName,\n+        theInterval,\n+        requiresMetadataStorePoll\n+    );\n+\n+    if (!segments.isPresent()) {\n+      return logAndCreateDataSourceNotFoundResponse(dataSourceName);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDk0NjMxNA=="}, "originalCommit": {"oid": "6dc035cb2d5dcf5796c7ad516ab39700ef7204a5"}, "originalPosition": 42}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcwOTI4MTQ4OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/druid/metadata/SqlSegmentsMetadataManager.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQwMTo0Njo0M1rOGezCXw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQwMjowNDo1NFrOGhiVXA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDk0NjY1NQ==", "bodyText": "nit: i think the old name was better, and still works with the new method being named forceOrWaitOngoingDatabasePoll", "url": "https://github.com/apache/druid/pull/9965#discussion_r434946655", "createdAt": "2020-06-04T01:46:43Z", "author": {"login": "clintropolis"}, "path": "server/src/main/java/org/apache/druid/metadata/SqlSegmentsMetadataManager.java", "diffHunk": "@@ -403,11 +425,16 @@ private void awaitOrPerformDatabasePoll()\n   }\n \n   /**\n-   * If the latest {@link DatabasePoll} is a {@link PeriodicDatabasePoll}, or an {@link OnDemandDatabasePoll} that is\n-   * made not longer than {@link #periodicPollDelay} from now, awaits for it and returns true; returns false otherwise,\n-   * meaning that a new on-demand database poll should be initiated.\n+   * This method returns true without waiting for database poll if the latest {@link DatabasePoll} is a\n+   * {@link PeriodicDatabasePoll} that has completed it's first poll, or an {@link OnDemandDatabasePoll} that is\n+   * made not longer than {@link #periodicPollDelay} from current time.\n+   * This method does wait untill completion for if the latest {@link DatabasePoll} is a\n+   * {@link PeriodicDatabasePoll} that has not completed it's first poll, or an {@link OnDemandDatabasePoll} that is\n+   * alrady in the process of polling the database.\n+   * This means that any method using this check can read from snapshot that is\n+   * up to {@link SqlSegmentsMetadataManager#periodicPollDelay} old.\n    */\n-  private boolean awaitLatestDatabasePoll()\n+  private boolean useLatestSnapshotIfWithinDelay()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6dc035cb2d5dcf5796c7ad516ab39700ef7204a5"}, "originalPosition": 149}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzgxODUxOQ==", "bodyText": "I really dont like the old name. This method most of the time does not wait (even though the method is called await). For example, if the latest poll is PeriodicDatabasePoll, it will never wait and just return the last poll. Even if there is a on-going PeriodicDatabasePoll, it does not wait and return the last poll. If the latest poll is OnDemandDatabasePoll, it will only wait if the latest is older than pollPeriod. This means that most of the time this method does not await and return last poll.", "url": "https://github.com/apache/druid/pull/9965#discussion_r437818519", "createdAt": "2020-06-10T02:04:06Z", "author": {"login": "maytasm"}, "path": "server/src/main/java/org/apache/druid/metadata/SqlSegmentsMetadataManager.java", "diffHunk": "@@ -403,11 +425,16 @@ private void awaitOrPerformDatabasePoll()\n   }\n \n   /**\n-   * If the latest {@link DatabasePoll} is a {@link PeriodicDatabasePoll}, or an {@link OnDemandDatabasePoll} that is\n-   * made not longer than {@link #periodicPollDelay} from now, awaits for it and returns true; returns false otherwise,\n-   * meaning that a new on-demand database poll should be initiated.\n+   * This method returns true without waiting for database poll if the latest {@link DatabasePoll} is a\n+   * {@link PeriodicDatabasePoll} that has completed it's first poll, or an {@link OnDemandDatabasePoll} that is\n+   * made not longer than {@link #periodicPollDelay} from current time.\n+   * This method does wait untill completion for if the latest {@link DatabasePoll} is a\n+   * {@link PeriodicDatabasePoll} that has not completed it's first poll, or an {@link OnDemandDatabasePoll} that is\n+   * alrady in the process of polling the database.\n+   * This means that any method using this check can read from snapshot that is\n+   * up to {@link SqlSegmentsMetadataManager#periodicPollDelay} old.\n    */\n-  private boolean awaitLatestDatabasePoll()\n+  private boolean useLatestSnapshotIfWithinDelay()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDk0NjY1NQ=="}, "originalCommit": {"oid": "6dc035cb2d5dcf5796c7ad516ab39700ef7204a5"}, "originalPosition": 149}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzgxODcxNg==", "bodyText": "Just saying awaitLatestDatabasePoll is misleading as it does not always guarantee wait on latest database poll.", "url": "https://github.com/apache/druid/pull/9965#discussion_r437818716", "createdAt": "2020-06-10T02:04:54Z", "author": {"login": "maytasm"}, "path": "server/src/main/java/org/apache/druid/metadata/SqlSegmentsMetadataManager.java", "diffHunk": "@@ -403,11 +425,16 @@ private void awaitOrPerformDatabasePoll()\n   }\n \n   /**\n-   * If the latest {@link DatabasePoll} is a {@link PeriodicDatabasePoll}, or an {@link OnDemandDatabasePoll} that is\n-   * made not longer than {@link #periodicPollDelay} from now, awaits for it and returns true; returns false otherwise,\n-   * meaning that a new on-demand database poll should be initiated.\n+   * This method returns true without waiting for database poll if the latest {@link DatabasePoll} is a\n+   * {@link PeriodicDatabasePoll} that has completed it's first poll, or an {@link OnDemandDatabasePoll} that is\n+   * made not longer than {@link #periodicPollDelay} from current time.\n+   * This method does wait untill completion for if the latest {@link DatabasePoll} is a\n+   * {@link PeriodicDatabasePoll} that has not completed it's first poll, or an {@link OnDemandDatabasePoll} that is\n+   * alrady in the process of polling the database.\n+   * This means that any method using this check can read from snapshot that is\n+   * up to {@link SqlSegmentsMetadataManager#periodicPollDelay} old.\n    */\n-  private boolean awaitLatestDatabasePoll()\n+  private boolean useLatestSnapshotIfWithinDelay()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDk0NjY1NQ=="}, "originalCommit": {"oid": "6dc035cb2d5dcf5796c7ad516ab39700ef7204a5"}, "originalPosition": 149}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcwOTMxNTQyOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/druid/metadata/SegmentsMetadataManager.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQwMjowODo0MFrOGezXjQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQwMjowNToyNFrOGhiV3w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDk1MjA3Nw==", "bodyText": "nit: formatting seems strange here, i suggest:\n  Optional<Iterable<DataSegment>> iterateAllUsedNonOvershadowedSegmentsForDatasourceInterval(\n      String datasource,\n      Interval interval,\n      boolean requiresLatest\n  );", "url": "https://github.com/apache/druid/pull/9965#discussion_r434952077", "createdAt": "2020-06-04T02:08:40Z", "author": {"login": "clintropolis"}, "path": "server/src/main/java/org/apache/druid/metadata/SegmentsMetadataManager.java", "diffHunk": "@@ -113,6 +114,18 @@ int markAsUsedNonOvershadowedSegments(String dataSource, Set<String> segmentIds)\n    */\n   Iterable<DataSegment> iterateAllUsedSegments();\n \n+  /**\n+   * Returns an iterable to go over all used and non-overshadowed segments of given data sources over given interval.\n+   * The order in which segments are iterated is unspecified.\n+   * If {@param requiresLatest} is true then a force metadatastore poll will be triggered. This can cause a longer\n+   * response time but will ensure that the latest segment information (at the time this method is called) is returned.\n+   * If {@param requiresLatest} is false then segment information from stale snapshot of up to the last periodic poll\n+   * period {@link SqlSegmentsMetadataManager#periodicPollDelay} will be used.\n+   */\n+  Optional<Iterable<DataSegment>> iterateAllUsedNonOvershadowedSegmentsForDatasourceInterval(String datasource,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6dc035cb2d5dcf5796c7ad516ab39700ef7204a5"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzgxODg0Nw==", "bodyText": "Done", "url": "https://github.com/apache/druid/pull/9965#discussion_r437818847", "createdAt": "2020-06-10T02:05:24Z", "author": {"login": "maytasm"}, "path": "server/src/main/java/org/apache/druid/metadata/SegmentsMetadataManager.java", "diffHunk": "@@ -113,6 +114,18 @@ int markAsUsedNonOvershadowedSegments(String dataSource, Set<String> segmentIds)\n    */\n   Iterable<DataSegment> iterateAllUsedSegments();\n \n+  /**\n+   * Returns an iterable to go over all used and non-overshadowed segments of given data sources over given interval.\n+   * The order in which segments are iterated is unspecified.\n+   * If {@param requiresLatest} is true then a force metadatastore poll will be triggered. This can cause a longer\n+   * response time but will ensure that the latest segment information (at the time this method is called) is returned.\n+   * If {@param requiresLatest} is false then segment information from stale snapshot of up to the last periodic poll\n+   * period {@link SqlSegmentsMetadataManager#periodicPollDelay} will be used.\n+   */\n+  Optional<Iterable<DataSegment>> iterateAllUsedNonOvershadowedSegmentsForDatasourceInterval(String datasource,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDk1MjA3Nw=="}, "originalCommit": {"oid": "6dc035cb2d5dcf5796c7ad516ab39700ef7204a5"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczMDg0OTA3OnYy", "diffSide": "RIGHT", "path": "docs/operations/api-reference.md", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxOTozNjoxNVrOGiDiBg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xM1QwMjoxMzoxNVrOGjVKdA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM2MjYzMA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            #### Segment Loading for Datasource\n          \n          \n            \n            #### Segment Loading by Datasource", "url": "https://github.com/apache/druid/pull/9965#discussion_r438362630", "createdAt": "2020-06-10T19:36:15Z", "author": {"login": "sthetland"}, "path": "docs/operations/api-reference.md", "diffHunk": "@@ -114,6 +114,41 @@ Returns the number of segments to load and drop, as well as the total segment lo\n \n Returns the serialized JSON of segments to load and drop for each Historical process.\n \n+\n+#### Segment Loading for Datasource", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "172ef6ac47e1566ad889d937bd8f12ad170bf4ff"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTcwMDA4NA==", "bodyText": "Done", "url": "https://github.com/apache/druid/pull/9965#discussion_r439700084", "createdAt": "2020-06-13T02:13:15Z", "author": {"login": "maytasm"}, "path": "docs/operations/api-reference.md", "diffHunk": "@@ -114,6 +114,41 @@ Returns the number of segments to load and drop, as well as the total segment lo\n \n Returns the serialized JSON of segments to load and drop for each Historical process.\n \n+\n+#### Segment Loading for Datasource", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM2MjYzMA=="}, "originalCommit": {"oid": "172ef6ac47e1566ad889d937bd8f12ad170bf4ff"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczMDg1MjEzOnYy", "diffSide": "RIGHT", "path": "docs/operations/api-reference.md", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxOTozNzoxNlrOGiDkAw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xM1QwMjoxMzo1NVrOGjVKnQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM2MzEzOQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            These APIs can be used to verify if segments created by recent ingestion task are loaded onto historicals and available for query.\n          \n          \n            \n            You can verify if segments created by a recent ingestion task are loaded onto historicals and available for querying using the following APIs.", "url": "https://github.com/apache/druid/pull/9965#discussion_r438363139", "createdAt": "2020-06-10T19:37:16Z", "author": {"login": "sthetland"}, "path": "docs/operations/api-reference.md", "diffHunk": "@@ -114,6 +114,41 @@ Returns the number of segments to load and drop, as well as the total segment lo\n \n Returns the serialized JSON of segments to load and drop for each Historical process.\n \n+\n+#### Segment Loading for Datasource\n+\n+These APIs can be used to verify if segments created by recent ingestion task are loaded onto historicals and available for query.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "172ef6ac47e1566ad889d937bd8f12ad170bf4ff"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTcwMDEyNQ==", "bodyText": "Done", "url": "https://github.com/apache/druid/pull/9965#discussion_r439700125", "createdAt": "2020-06-13T02:13:55Z", "author": {"login": "maytasm"}, "path": "docs/operations/api-reference.md", "diffHunk": "@@ -114,6 +114,41 @@ Returns the number of segments to load and drop, as well as the total segment lo\n \n Returns the serialized JSON of segments to load and drop for each Historical process.\n \n+\n+#### Segment Loading for Datasource\n+\n+These APIs can be used to verify if segments created by recent ingestion task are loaded onto historicals and available for query.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM2MzEzOQ=="}, "originalCommit": {"oid": "172ef6ac47e1566ad889d937bd8f12ad170bf4ff"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczMDg1NDAxOnYy", "diffSide": "RIGHT", "path": "docs/operations/api-reference.md", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxOTozNzo1MVrOGiDlNQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xM1QwMjoxNDoxOFrOGjVKsQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM2MzQ0NQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            1. Submit your ingestion task\n          \n          \n            \n            1. Submit your ingestion task.", "url": "https://github.com/apache/druid/pull/9965#discussion_r438363445", "createdAt": "2020-06-10T19:37:51Z", "author": {"login": "sthetland"}, "path": "docs/operations/api-reference.md", "diffHunk": "@@ -114,6 +114,41 @@ Returns the number of segments to load and drop, as well as the total segment lo\n \n Returns the serialized JSON of segments to load and drop for each Historical process.\n \n+\n+#### Segment Loading for Datasource\n+\n+These APIs can be used to verify if segments created by recent ingestion task are loaded onto historicals and available for query.\n+An example workflow for this is:\n+1. Submit your ingestion task", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "172ef6ac47e1566ad889d937bd8f12ad170bf4ff"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTcwMDE0NQ==", "bodyText": "Done", "url": "https://github.com/apache/druid/pull/9965#discussion_r439700145", "createdAt": "2020-06-13T02:14:18Z", "author": {"login": "maytasm"}, "path": "docs/operations/api-reference.md", "diffHunk": "@@ -114,6 +114,41 @@ Returns the number of segments to load and drop, as well as the total segment lo\n \n Returns the serialized JSON of segments to load and drop for each Historical process.\n \n+\n+#### Segment Loading for Datasource\n+\n+These APIs can be used to verify if segments created by recent ingestion task are loaded onto historicals and available for query.\n+An example workflow for this is:\n+1. Submit your ingestion task", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM2MzQ0NQ=="}, "originalCommit": {"oid": "172ef6ac47e1566ad889d937bd8f12ad170bf4ff"}, "originalPosition": 9}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczMDg1NzE4OnYy", "diffSide": "RIGHT", "path": "docs/operations/api-reference.md", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxOTozODo0OVrOGiDnNg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xM1QwMjoxNDo0MVrOGjVKwQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM2Mzk1OA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            2. Repeatedly poll Overlord's task API ( `/druid/indexer/v1/task/{taskId}/status`) until task is completed and succeeded.\n          \n          \n            \n            2. Repeatedly poll the Overlord's task API ( `/druid/indexer/v1/task/{taskId}/status`) until your task is shown to be successfully completed.", "url": "https://github.com/apache/druid/pull/9965#discussion_r438363958", "createdAt": "2020-06-10T19:38:49Z", "author": {"login": "sthetland"}, "path": "docs/operations/api-reference.md", "diffHunk": "@@ -114,6 +114,41 @@ Returns the number of segments to load and drop, as well as the total segment lo\n \n Returns the serialized JSON of segments to load and drop for each Historical process.\n \n+\n+#### Segment Loading for Datasource\n+\n+These APIs can be used to verify if segments created by recent ingestion task are loaded onto historicals and available for query.\n+An example workflow for this is:\n+1. Submit your ingestion task\n+2. Repeatedly poll Overlord's task API ( `/druid/indexer/v1/task/{taskId}/status`) until task is completed and succeeded.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "172ef6ac47e1566ad889d937bd8f12ad170bf4ff"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTcwMDE2MQ==", "bodyText": "Done", "url": "https://github.com/apache/druid/pull/9965#discussion_r439700161", "createdAt": "2020-06-13T02:14:41Z", "author": {"login": "maytasm"}, "path": "docs/operations/api-reference.md", "diffHunk": "@@ -114,6 +114,41 @@ Returns the number of segments to load and drop, as well as the total segment lo\n \n Returns the serialized JSON of segments to load and drop for each Historical process.\n \n+\n+#### Segment Loading for Datasource\n+\n+These APIs can be used to verify if segments created by recent ingestion task are loaded onto historicals and available for query.\n+An example workflow for this is:\n+1. Submit your ingestion task\n+2. Repeatedly poll Overlord's task API ( `/druid/indexer/v1/task/{taskId}/status`) until task is completed and succeeded.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM2Mzk1OA=="}, "originalCommit": {"oid": "172ef6ac47e1566ad889d937bd8f12ad170bf4ff"}, "originalPosition": 10}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczMDg2NDI1OnYy", "diffSide": "RIGHT", "path": "docs/operations/api-reference.md", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxOTo0MTowMFrOGiDrxA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xM1QwMjoxNToyNFrOGjVLBw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM2NTEyNA==", "bodyText": "maybe call it loadstatus?\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            3. Poll Segment Loading for Datasource API (`/druid/coordinator/v1/datasources/{dataSourceName}/loadstatus`) with `forceMetadataRefresh=true` once. \n          \n          \n            \n            3. Poll the datasource loadstatus API (`/druid/coordinator/v1/datasources/{dataSourceName}/loadstatus`) with `forceMetadataRefresh=true` once.", "url": "https://github.com/apache/druid/pull/9965#discussion_r438365124", "createdAt": "2020-06-10T19:41:00Z", "author": {"login": "sthetland"}, "path": "docs/operations/api-reference.md", "diffHunk": "@@ -114,6 +114,41 @@ Returns the number of segments to load and drop, as well as the total segment lo\n \n Returns the serialized JSON of segments to load and drop for each Historical process.\n \n+\n+#### Segment Loading for Datasource\n+\n+These APIs can be used to verify if segments created by recent ingestion task are loaded onto historicals and available for query.\n+An example workflow for this is:\n+1. Submit your ingestion task\n+2. Repeatedly poll Overlord's task API ( `/druid/indexer/v1/task/{taskId}/status`) until task is completed and succeeded.\n+3. Poll Segment Loading for Datasource API (`/druid/coordinator/v1/datasources/{dataSourceName}/loadstatus`) with `forceMetadataRefresh=true` once. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "172ef6ac47e1566ad889d937bd8f12ad170bf4ff"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTcwMDIzMQ==", "bodyText": "Done", "url": "https://github.com/apache/druid/pull/9965#discussion_r439700231", "createdAt": "2020-06-13T02:15:24Z", "author": {"login": "maytasm"}, "path": "docs/operations/api-reference.md", "diffHunk": "@@ -114,6 +114,41 @@ Returns the number of segments to load and drop, as well as the total segment lo\n \n Returns the serialized JSON of segments to load and drop for each Historical process.\n \n+\n+#### Segment Loading for Datasource\n+\n+These APIs can be used to verify if segments created by recent ingestion task are loaded onto historicals and available for query.\n+An example workflow for this is:\n+1. Submit your ingestion task\n+2. Repeatedly poll Overlord's task API ( `/druid/indexer/v1/task/{taskId}/status`) until task is completed and succeeded.\n+3. Poll Segment Loading for Datasource API (`/druid/coordinator/v1/datasources/{dataSourceName}/loadstatus`) with `forceMetadataRefresh=true` once. ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM2NTEyNA=="}, "originalCommit": {"oid": "172ef6ac47e1566ad889d937bd8f12ad170bf4ff"}, "originalPosition": 11}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczMDg3MjkwOnYy", "diffSide": "RIGHT", "path": "docs/operations/api-reference.md", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxOTo0MzozNlrOGiDxIg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xM1QwMjoyMDo1OFrOGjVMqw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM2NjQ5OA==", "bodyText": "Maybe indicate that true is the default here? and remove the sentence that comes later (\"forceMetadataRefresh will be set to true if not given.\")\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            over the given interval (or last 2 weeks if interval is not given). Setting `forceMetadataRefresh=true`\n          \n          \n            \n            over the given interval (or last 2 weeks if interval is not given). Setting `forceMetadataRefresh` to true (the default)", "url": "https://github.com/apache/druid/pull/9965#discussion_r438366498", "createdAt": "2020-06-10T19:43:36Z", "author": {"login": "sthetland"}, "path": "docs/operations/api-reference.md", "diffHunk": "@@ -114,6 +114,41 @@ Returns the number of segments to load and drop, as well as the total segment lo\n \n Returns the serialized JSON of segments to load and drop for each Historical process.\n \n+\n+#### Segment Loading for Datasource\n+\n+These APIs can be used to verify if segments created by recent ingestion task are loaded onto historicals and available for query.\n+An example workflow for this is:\n+1. Submit your ingestion task\n+2. Repeatedly poll Overlord's task API ( `/druid/indexer/v1/task/{taskId}/status`) until task is completed and succeeded.\n+3. Poll Segment Loading for Datasource API (`/druid/coordinator/v1/datasources/{dataSourceName}/loadstatus`) with `forceMetadataRefresh=true` once. \n+If there are segments not yet loaded, continue to step 4, otherwise you can now query the data.\n+4. Repeatedly poll Segment Loading for Datasource API (`/druid/coordinator/v1/datasources/{dataSourceName}/loadstatus`) with `forceMetadataRefresh=false`. \n+Continue polling until all segments are loaded. Once all segments are loaded you can now query the data.\n+\n+##### GET\n+\n+* `/druid/coordinator/v1/datasources/{dataSourceName}/loadstatus?forceMetadataRefresh={boolean}&interval={myInterval}`\n+\n+Returns the percentage of segments actually loaded in the cluster versus segments that should be loaded in the cluster for the given datasource \n+over the given interval (or last 2 weeks if interval is not given). Setting `forceMetadataRefresh=true`", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "172ef6ac47e1566ad889d937bd8f12ad170bf4ff"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTcwMDY1MQ==", "bodyText": "Done", "url": "https://github.com/apache/druid/pull/9965#discussion_r439700651", "createdAt": "2020-06-13T02:20:58Z", "author": {"login": "maytasm"}, "path": "docs/operations/api-reference.md", "diffHunk": "@@ -114,6 +114,41 @@ Returns the number of segments to load and drop, as well as the total segment lo\n \n Returns the serialized JSON of segments to load and drop for each Historical process.\n \n+\n+#### Segment Loading for Datasource\n+\n+These APIs can be used to verify if segments created by recent ingestion task are loaded onto historicals and available for query.\n+An example workflow for this is:\n+1. Submit your ingestion task\n+2. Repeatedly poll Overlord's task API ( `/druid/indexer/v1/task/{taskId}/status`) until task is completed and succeeded.\n+3. Poll Segment Loading for Datasource API (`/druid/coordinator/v1/datasources/{dataSourceName}/loadstatus`) with `forceMetadataRefresh=true` once. \n+If there are segments not yet loaded, continue to step 4, otherwise you can now query the data.\n+4. Repeatedly poll Segment Loading for Datasource API (`/druid/coordinator/v1/datasources/{dataSourceName}/loadstatus`) with `forceMetadataRefresh=false`. \n+Continue polling until all segments are loaded. Once all segments are loaded you can now query the data.\n+\n+##### GET\n+\n+* `/druid/coordinator/v1/datasources/{dataSourceName}/loadstatus?forceMetadataRefresh={boolean}&interval={myInterval}`\n+\n+Returns the percentage of segments actually loaded in the cluster versus segments that should be loaded in the cluster for the given datasource \n+over the given interval (or last 2 weeks if interval is not given). Setting `forceMetadataRefresh=true`", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM2NjQ5OA=="}, "originalCommit": {"oid": "172ef6ac47e1566ad889d937bd8f12ad170bf4ff"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczMDg4MzAyOnYy", "diffSide": "RIGHT", "path": "docs/operations/api-reference.md", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxOTo0Njo0M1rOGiD3pg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xM1QwMjoyMTo0NVrOGjVM7A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM2ODE2Ng==", "bodyText": "Maybe add the positive case as well, if this is the case?\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            If no used segments found for the given inputs, this API returns 100% as the value.\n          \n          \n            \n            If all segments have been loaded or no used segments are found for the given inputs, this API returns 100% as the value.", "url": "https://github.com/apache/druid/pull/9965#discussion_r438368166", "createdAt": "2020-06-10T19:46:43Z", "author": {"login": "sthetland"}, "path": "docs/operations/api-reference.md", "diffHunk": "@@ -114,6 +114,41 @@ Returns the number of segments to load and drop, as well as the total segment lo\n \n Returns the serialized JSON of segments to load and drop for each Historical process.\n \n+\n+#### Segment Loading for Datasource\n+\n+These APIs can be used to verify if segments created by recent ingestion task are loaded onto historicals and available for query.\n+An example workflow for this is:\n+1. Submit your ingestion task\n+2. Repeatedly poll Overlord's task API ( `/druid/indexer/v1/task/{taskId}/status`) until task is completed and succeeded.\n+3. Poll Segment Loading for Datasource API (`/druid/coordinator/v1/datasources/{dataSourceName}/loadstatus`) with `forceMetadataRefresh=true` once. \n+If there are segments not yet loaded, continue to step 4, otherwise you can now query the data.\n+4. Repeatedly poll Segment Loading for Datasource API (`/druid/coordinator/v1/datasources/{dataSourceName}/loadstatus`) with `forceMetadataRefresh=false`. \n+Continue polling until all segments are loaded. Once all segments are loaded you can now query the data.\n+\n+##### GET\n+\n+* `/druid/coordinator/v1/datasources/{dataSourceName}/loadstatus?forceMetadataRefresh={boolean}&interval={myInterval}`\n+\n+Returns the percentage of segments actually loaded in the cluster versus segments that should be loaded in the cluster for the given datasource \n+over the given interval (or last 2 weeks if interval is not given). Setting `forceMetadataRefresh=true`\n+will force the coordinator to poll latest segment metadata from the metadata store. `forceMetadataRefresh` will be set to true if not given.\n+If no used segments found for the given inputs, this API returns 100% as the value.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "172ef6ac47e1566ad889d937bd8f12ad170bf4ff"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTcwMDcxNg==", "bodyText": "Done", "url": "https://github.com/apache/druid/pull/9965#discussion_r439700716", "createdAt": "2020-06-13T02:21:45Z", "author": {"login": "maytasm"}, "path": "docs/operations/api-reference.md", "diffHunk": "@@ -114,6 +114,41 @@ Returns the number of segments to load and drop, as well as the total segment lo\n \n Returns the serialized JSON of segments to load and drop for each Historical process.\n \n+\n+#### Segment Loading for Datasource\n+\n+These APIs can be used to verify if segments created by recent ingestion task are loaded onto historicals and available for query.\n+An example workflow for this is:\n+1. Submit your ingestion task\n+2. Repeatedly poll Overlord's task API ( `/druid/indexer/v1/task/{taskId}/status`) until task is completed and succeeded.\n+3. Poll Segment Loading for Datasource API (`/druid/coordinator/v1/datasources/{dataSourceName}/loadstatus`) with `forceMetadataRefresh=true` once. \n+If there are segments not yet loaded, continue to step 4, otherwise you can now query the data.\n+4. Repeatedly poll Segment Loading for Datasource API (`/druid/coordinator/v1/datasources/{dataSourceName}/loadstatus`) with `forceMetadataRefresh=false`. \n+Continue polling until all segments are loaded. Once all segments are loaded you can now query the data.\n+\n+##### GET\n+\n+* `/druid/coordinator/v1/datasources/{dataSourceName}/loadstatus?forceMetadataRefresh={boolean}&interval={myInterval}`\n+\n+Returns the percentage of segments actually loaded in the cluster versus segments that should be loaded in the cluster for the given datasource \n+over the given interval (or last 2 weeks if interval is not given). Setting `forceMetadataRefresh=true`\n+will force the coordinator to poll latest segment metadata from the metadata store. `forceMetadataRefresh` will be set to true if not given.\n+If no used segments found for the given inputs, this API returns 100% as the value.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM2ODE2Ng=="}, "originalCommit": {"oid": "172ef6ac47e1566ad889d937bd8f12ad170bf4ff"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczMDk2MTYwOnYy", "diffSide": "RIGHT", "path": "docs/operations/api-reference.md", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQyMDoxMjowOFrOGiEqgg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xM1QwMjoyMzoyOFrOGjVNng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM4MTE4Ng==", "bodyText": "\"This does not include replication\" Meaning, replicated segments?", "url": "https://github.com/apache/druid/pull/9965#discussion_r438381186", "createdAt": "2020-06-10T20:12:08Z", "author": {"login": "sthetland"}, "path": "docs/operations/api-reference.md", "diffHunk": "@@ -114,6 +114,41 @@ Returns the number of segments to load and drop, as well as the total segment lo\n \n Returns the serialized JSON of segments to load and drop for each Historical process.\n \n+\n+#### Segment Loading for Datasource\n+\n+These APIs can be used to verify if segments created by recent ingestion task are loaded onto historicals and available for query.\n+An example workflow for this is:\n+1. Submit your ingestion task\n+2. Repeatedly poll Overlord's task API ( `/druid/indexer/v1/task/{taskId}/status`) until task is completed and succeeded.\n+3. Poll Segment Loading for Datasource API (`/druid/coordinator/v1/datasources/{dataSourceName}/loadstatus`) with `forceMetadataRefresh=true` once. \n+If there are segments not yet loaded, continue to step 4, otherwise you can now query the data.\n+4. Repeatedly poll Segment Loading for Datasource API (`/druid/coordinator/v1/datasources/{dataSourceName}/loadstatus`) with `forceMetadataRefresh=false`. \n+Continue polling until all segments are loaded. Once all segments are loaded you can now query the data.\n+\n+##### GET\n+\n+* `/druid/coordinator/v1/datasources/{dataSourceName}/loadstatus?forceMetadataRefresh={boolean}&interval={myInterval}`\n+\n+Returns the percentage of segments actually loaded in the cluster versus segments that should be loaded in the cluster for the given datasource \n+over the given interval (or last 2 weeks if interval is not given). Setting `forceMetadataRefresh=true`\n+will force the coordinator to poll latest segment metadata from the metadata store. `forceMetadataRefresh` will be set to true if not given.\n+If no used segments found for the given inputs, this API returns 100% as the value.\n+\n+ * `/druid/coordinator/v1/datasources/{dataSourceName}/loadstatus?simple&forceMetadataRefresh={boolean}&interval={myInterval}`\n+\n+Returns the number of segments left to load until segments that should be loaded in the cluster are available for the given datasource \n+over the given interval (or last 2 weeks if interval is not given). This does not include replication. Setting `forceMetadataRefresh=true` ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "172ef6ac47e1566ad889d937bd8f12ad170bf4ff"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTcwMDg5NA==", "bodyText": "Yes.\nMaybe \"This does not include replica of segments\"?", "url": "https://github.com/apache/druid/pull/9965#discussion_r439700894", "createdAt": "2020-06-13T02:23:28Z", "author": {"login": "maytasm"}, "path": "docs/operations/api-reference.md", "diffHunk": "@@ -114,6 +114,41 @@ Returns the number of segments to load and drop, as well as the total segment lo\n \n Returns the serialized JSON of segments to load and drop for each Historical process.\n \n+\n+#### Segment Loading for Datasource\n+\n+These APIs can be used to verify if segments created by recent ingestion task are loaded onto historicals and available for query.\n+An example workflow for this is:\n+1. Submit your ingestion task\n+2. Repeatedly poll Overlord's task API ( `/druid/indexer/v1/task/{taskId}/status`) until task is completed and succeeded.\n+3. Poll Segment Loading for Datasource API (`/druid/coordinator/v1/datasources/{dataSourceName}/loadstatus`) with `forceMetadataRefresh=true` once. \n+If there are segments not yet loaded, continue to step 4, otherwise you can now query the data.\n+4. Repeatedly poll Segment Loading for Datasource API (`/druid/coordinator/v1/datasources/{dataSourceName}/loadstatus`) with `forceMetadataRefresh=false`. \n+Continue polling until all segments are loaded. Once all segments are loaded you can now query the data.\n+\n+##### GET\n+\n+* `/druid/coordinator/v1/datasources/{dataSourceName}/loadstatus?forceMetadataRefresh={boolean}&interval={myInterval}`\n+\n+Returns the percentage of segments actually loaded in the cluster versus segments that should be loaded in the cluster for the given datasource \n+over the given interval (or last 2 weeks if interval is not given). Setting `forceMetadataRefresh=true`\n+will force the coordinator to poll latest segment metadata from the metadata store. `forceMetadataRefresh` will be set to true if not given.\n+If no used segments found for the given inputs, this API returns 100% as the value.\n+\n+ * `/druid/coordinator/v1/datasources/{dataSourceName}/loadstatus?simple&forceMetadataRefresh={boolean}&interval={myInterval}`\n+\n+Returns the number of segments left to load until segments that should be loaded in the cluster are available for the given datasource \n+over the given interval (or last 2 weeks if interval is not given). This does not include replication. Setting `forceMetadataRefresh=true` ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODM4MTE4Ng=="}, "originalCommit": {"oid": "172ef6ac47e1566ad889d937bd8f12ad170bf4ff"}, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczNTg5MzAxOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/druid/server/http/DataSourcesResource.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQwMjo1MToxM1rOGi1XZg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xM1QwNDoxMzo1MlrOGjVmOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTE3OTExMA==", "bodyText": "I really don't think this should default to true since it is a heavy operation, but also, since the docs recommend polling the API with the not default option to determine when your segments are all available and only calling with the default option once.", "url": "https://github.com/apache/druid/pull/9965#discussion_r439179110", "createdAt": "2020-06-12T02:51:13Z", "author": {"login": "clintropolis"}, "path": "server/src/main/java/org/apache/druid/server/http/DataSourcesResource.java", "diffHunk": "@@ -391,6 +396,123 @@ public Response getServedSegmentsInInterval(\n     return getServedSegmentsInInterval(dataSourceName, full != null, theInterval::contains);\n   }\n \n+  @GET\n+  @Path(\"/{dataSourceName}/loadstatus\")\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @ResourceFilters(DatasourceResourceFilter.class)\n+  public Response getDatasourceLoadstatus(\n+      @PathParam(\"dataSourceName\") String dataSourceName,\n+      @QueryParam(\"interval\") @Nullable final String interval,\n+      @QueryParam(\"forceMetadataRefresh\") @Nullable final Boolean forceMetadataRefresh,\n+      @QueryParam(\"simple\") @Nullable final String simple,\n+      @QueryParam(\"full\") @Nullable final String full\n+  )\n+  {\n+    final Interval theInterval;\n+    if (interval == null) {\n+      long defaultIntervalOffset = 14 * 24 * 60 * 60 * 1000;\n+      long currentTimeInMs = System.currentTimeMillis();\n+      theInterval = Intervals.utc(currentTimeInMs - defaultIntervalOffset, currentTimeInMs);\n+    } else {\n+      theInterval = Intervals.of(interval.replace('_', '/'));\n+    }\n+\n+    boolean requiresMetadataStorePoll = forceMetadataRefresh == null ? true : forceMetadataRefresh;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "172ef6ac47e1566ad889d937bd8f12ad170bf4ff"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTcwMTU4Ng==", "bodyText": "The reason I have the default as true is to prevent operator mistake by forgetting to set to true on the first call. Basically, you will get the correct result if you make every call with true. However, you will not get the correct result (and can be making query when segments are not yet loaded!) if you make every call with false. Hence, having default to true to a safer option imo.", "url": "https://github.com/apache/druid/pull/9965#discussion_r439701586", "createdAt": "2020-06-13T02:32:37Z", "author": {"login": "maytasm"}, "path": "server/src/main/java/org/apache/druid/server/http/DataSourcesResource.java", "diffHunk": "@@ -391,6 +396,123 @@ public Response getServedSegmentsInInterval(\n     return getServedSegmentsInInterval(dataSourceName, full != null, theInterval::contains);\n   }\n \n+  @GET\n+  @Path(\"/{dataSourceName}/loadstatus\")\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @ResourceFilters(DatasourceResourceFilter.class)\n+  public Response getDatasourceLoadstatus(\n+      @PathParam(\"dataSourceName\") String dataSourceName,\n+      @QueryParam(\"interval\") @Nullable final String interval,\n+      @QueryParam(\"forceMetadataRefresh\") @Nullable final Boolean forceMetadataRefresh,\n+      @QueryParam(\"simple\") @Nullable final String simple,\n+      @QueryParam(\"full\") @Nullable final String full\n+  )\n+  {\n+    final Interval theInterval;\n+    if (interval == null) {\n+      long defaultIntervalOffset = 14 * 24 * 60 * 60 * 1000;\n+      long currentTimeInMs = System.currentTimeMillis();\n+      theInterval = Intervals.utc(currentTimeInMs - defaultIntervalOffset, currentTimeInMs);\n+    } else {\n+      theInterval = Intervals.of(interval.replace('_', '/'));\n+    }\n+\n+    boolean requiresMetadataStorePoll = forceMetadataRefresh == null ? true : forceMetadataRefresh;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTE3OTExMA=="}, "originalCommit": {"oid": "172ef6ac47e1566ad889d937bd8f12ad170bf4ff"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTcwMTYyNQ==", "bodyText": "Setting to false is an optional optimization that can be done on the calls after the first call.", "url": "https://github.com/apache/druid/pull/9965#discussion_r439701625", "createdAt": "2020-06-13T02:33:17Z", "author": {"login": "maytasm"}, "path": "server/src/main/java/org/apache/druid/server/http/DataSourcesResource.java", "diffHunk": "@@ -391,6 +396,123 @@ public Response getServedSegmentsInInterval(\n     return getServedSegmentsInInterval(dataSourceName, full != null, theInterval::contains);\n   }\n \n+  @GET\n+  @Path(\"/{dataSourceName}/loadstatus\")\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @ResourceFilters(DatasourceResourceFilter.class)\n+  public Response getDatasourceLoadstatus(\n+      @PathParam(\"dataSourceName\") String dataSourceName,\n+      @QueryParam(\"interval\") @Nullable final String interval,\n+      @QueryParam(\"forceMetadataRefresh\") @Nullable final Boolean forceMetadataRefresh,\n+      @QueryParam(\"simple\") @Nullable final String simple,\n+      @QueryParam(\"full\") @Nullable final String full\n+  )\n+  {\n+    final Interval theInterval;\n+    if (interval == null) {\n+      long defaultIntervalOffset = 14 * 24 * 60 * 60 * 1000;\n+      long currentTimeInMs = System.currentTimeMillis();\n+      theInterval = Intervals.utc(currentTimeInMs - defaultIntervalOffset, currentTimeInMs);\n+    } else {\n+      theInterval = Intervals.of(interval.replace('_', '/'));\n+    }\n+\n+    boolean requiresMetadataStorePoll = forceMetadataRefresh == null ? true : forceMetadataRefresh;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTE3OTExMA=="}, "originalCommit": {"oid": "172ef6ac47e1566ad889d937bd8f12ad170bf4ff"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTcwNzE5Mw==", "bodyText": "Making this field mandatory instead. 400 bad request will be returned if forceMetadataRefresh is not given. This will make sure user read and understand the doc when using this API. To use this API properly, you will have to change the flag in the flow between first call and subsequent call. Hence, there is no \u201cdefault\u201d as the flag are for different cases. Basically both flags are as default as the other flag and are needed for different step in the flow.", "url": "https://github.com/apache/druid/pull/9965#discussion_r439707193", "createdAt": "2020-06-13T04:13:52Z", "author": {"login": "maytasm"}, "path": "server/src/main/java/org/apache/druid/server/http/DataSourcesResource.java", "diffHunk": "@@ -391,6 +396,123 @@ public Response getServedSegmentsInInterval(\n     return getServedSegmentsInInterval(dataSourceName, full != null, theInterval::contains);\n   }\n \n+  @GET\n+  @Path(\"/{dataSourceName}/loadstatus\")\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @ResourceFilters(DatasourceResourceFilter.class)\n+  public Response getDatasourceLoadstatus(\n+      @PathParam(\"dataSourceName\") String dataSourceName,\n+      @QueryParam(\"interval\") @Nullable final String interval,\n+      @QueryParam(\"forceMetadataRefresh\") @Nullable final Boolean forceMetadataRefresh,\n+      @QueryParam(\"simple\") @Nullable final String simple,\n+      @QueryParam(\"full\") @Nullable final String full\n+  )\n+  {\n+    final Interval theInterval;\n+    if (interval == null) {\n+      long defaultIntervalOffset = 14 * 24 * 60 * 60 * 1000;\n+      long currentTimeInMs = System.currentTimeMillis();\n+      theInterval = Intervals.utc(currentTimeInMs - defaultIntervalOffset, currentTimeInMs);\n+    } else {\n+      theInterval = Intervals.of(interval.replace('_', '/'));\n+    }\n+\n+    boolean requiresMetadataStorePoll = forceMetadataRefresh == null ? true : forceMetadataRefresh;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTE3OTExMA=="}, "originalCommit": {"oid": "172ef6ac47e1566ad889d937bd8f12ad170bf4ff"}, "originalPosition": 42}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczNTkwMzgyOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/druid/server/http/DataSourcesResource.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQwMjo1ODo1M1rOGi1eGg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xM1QwNDoxMzo1OVrOGjVmPA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTE4MDgyNg==", "bodyText": "It seems like there is quite a lot of logic in this API entry point method, it would be worth breaking each of these blocks out into methods dedicated for each response so it's a bit easier to follow", "url": "https://github.com/apache/druid/pull/9965#discussion_r439180826", "createdAt": "2020-06-12T02:58:53Z", "author": {"login": "clintropolis"}, "path": "server/src/main/java/org/apache/druid/server/http/DataSourcesResource.java", "diffHunk": "@@ -391,6 +396,123 @@ public Response getServedSegmentsInInterval(\n     return getServedSegmentsInInterval(dataSourceName, full != null, theInterval::contains);\n   }\n \n+  @GET\n+  @Path(\"/{dataSourceName}/loadstatus\")\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @ResourceFilters(DatasourceResourceFilter.class)\n+  public Response getDatasourceLoadstatus(\n+      @PathParam(\"dataSourceName\") String dataSourceName,\n+      @QueryParam(\"interval\") @Nullable final String interval,\n+      @QueryParam(\"forceMetadataRefresh\") @Nullable final Boolean forceMetadataRefresh,\n+      @QueryParam(\"simple\") @Nullable final String simple,\n+      @QueryParam(\"full\") @Nullable final String full\n+  )\n+  {\n+    final Interval theInterval;\n+    if (interval == null) {\n+      long defaultIntervalOffset = 14 * 24 * 60 * 60 * 1000;\n+      long currentTimeInMs = System.currentTimeMillis();\n+      theInterval = Intervals.utc(currentTimeInMs - defaultIntervalOffset, currentTimeInMs);\n+    } else {\n+      theInterval = Intervals.of(interval.replace('_', '/'));\n+    }\n+\n+    boolean requiresMetadataStorePoll = forceMetadataRefresh == null ? true : forceMetadataRefresh;\n+\n+    Optional<Iterable<DataSegment>> segments = segmentsMetadataManager.iterateAllUsedNonOvershadowedSegmentsForDatasourceInterval(\n+        dataSourceName,\n+        theInterval,\n+        requiresMetadataStorePoll\n+    );\n+\n+    if (!segments.isPresent()) {\n+      return logAndCreateDataSourceNotFoundResponse(dataSourceName);\n+    }\n+\n+    if (simple != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "172ef6ac47e1566ad889d937bd8f12ad170bf4ff"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTcwNzE5Ng==", "bodyText": "Done", "url": "https://github.com/apache/druid/pull/9965#discussion_r439707196", "createdAt": "2020-06-13T04:13:59Z", "author": {"login": "maytasm"}, "path": "server/src/main/java/org/apache/druid/server/http/DataSourcesResource.java", "diffHunk": "@@ -391,6 +396,123 @@ public Response getServedSegmentsInInterval(\n     return getServedSegmentsInInterval(dataSourceName, full != null, theInterval::contains);\n   }\n \n+  @GET\n+  @Path(\"/{dataSourceName}/loadstatus\")\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @ResourceFilters(DatasourceResourceFilter.class)\n+  public Response getDatasourceLoadstatus(\n+      @PathParam(\"dataSourceName\") String dataSourceName,\n+      @QueryParam(\"interval\") @Nullable final String interval,\n+      @QueryParam(\"forceMetadataRefresh\") @Nullable final Boolean forceMetadataRefresh,\n+      @QueryParam(\"simple\") @Nullable final String simple,\n+      @QueryParam(\"full\") @Nullable final String full\n+  )\n+  {\n+    final Interval theInterval;\n+    if (interval == null) {\n+      long defaultIntervalOffset = 14 * 24 * 60 * 60 * 1000;\n+      long currentTimeInMs = System.currentTimeMillis();\n+      theInterval = Intervals.utc(currentTimeInMs - defaultIntervalOffset, currentTimeInMs);\n+    } else {\n+      theInterval = Intervals.of(interval.replace('_', '/'));\n+    }\n+\n+    boolean requiresMetadataStorePoll = forceMetadataRefresh == null ? true : forceMetadataRefresh;\n+\n+    Optional<Iterable<DataSegment>> segments = segmentsMetadataManager.iterateAllUsedNonOvershadowedSegmentsForDatasourceInterval(\n+        dataSourceName,\n+        theInterval,\n+        requiresMetadataStorePoll\n+    );\n+\n+    if (!segments.isPresent()) {\n+      return logAndCreateDataSourceNotFoundResponse(dataSourceName);\n+    }\n+\n+    if (simple != null) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTE4MDgyNg=="}, "originalCommit": {"oid": "172ef6ac47e1566ad889d937bd8f12ad170bf4ff"}, "originalPosition": 54}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczNTkwNjcwOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/druid/server/http/DataSourcesResource.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQwMzowMDo0MlrOGi1fzg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xM1QwNDoxNDoyOVrOGjVmTQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTE4MTI2Mg==", "bodyText": "resposne -> response", "url": "https://github.com/apache/druid/pull/9965#discussion_r439181262", "createdAt": "2020-06-12T03:00:42Z", "author": {"login": "clintropolis"}, "path": "server/src/main/java/org/apache/druid/server/http/DataSourcesResource.java", "diffHunk": "@@ -391,6 +396,123 @@ public Response getServedSegmentsInInterval(\n     return getServedSegmentsInInterval(dataSourceName, full != null, theInterval::contains);\n   }\n \n+  @GET\n+  @Path(\"/{dataSourceName}/loadstatus\")\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @ResourceFilters(DatasourceResourceFilter.class)\n+  public Response getDatasourceLoadstatus(\n+      @PathParam(\"dataSourceName\") String dataSourceName,\n+      @QueryParam(\"interval\") @Nullable final String interval,\n+      @QueryParam(\"forceMetadataRefresh\") @Nullable final Boolean forceMetadataRefresh,\n+      @QueryParam(\"simple\") @Nullable final String simple,\n+      @QueryParam(\"full\") @Nullable final String full\n+  )\n+  {\n+    final Interval theInterval;\n+    if (interval == null) {\n+      long defaultIntervalOffset = 14 * 24 * 60 * 60 * 1000;\n+      long currentTimeInMs = System.currentTimeMillis();\n+      theInterval = Intervals.utc(currentTimeInMs - defaultIntervalOffset, currentTimeInMs);\n+    } else {\n+      theInterval = Intervals.of(interval.replace('_', '/'));\n+    }\n+\n+    boolean requiresMetadataStorePoll = forceMetadataRefresh == null ? true : forceMetadataRefresh;\n+\n+    Optional<Iterable<DataSegment>> segments = segmentsMetadataManager.iterateAllUsedNonOvershadowedSegmentsForDatasourceInterval(\n+        dataSourceName,\n+        theInterval,\n+        requiresMetadataStorePoll\n+    );\n+\n+    if (!segments.isPresent()) {\n+      return logAndCreateDataSourceNotFoundResponse(dataSourceName);\n+    }\n+\n+    if (simple != null) {\n+      // Calculate resposne for simple mode", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "172ef6ac47e1566ad889d937bd8f12ad170bf4ff"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTcwNzIxMw==", "bodyText": "Done", "url": "https://github.com/apache/druid/pull/9965#discussion_r439707213", "createdAt": "2020-06-13T04:14:29Z", "author": {"login": "maytasm"}, "path": "server/src/main/java/org/apache/druid/server/http/DataSourcesResource.java", "diffHunk": "@@ -391,6 +396,123 @@ public Response getServedSegmentsInInterval(\n     return getServedSegmentsInInterval(dataSourceName, full != null, theInterval::contains);\n   }\n \n+  @GET\n+  @Path(\"/{dataSourceName}/loadstatus\")\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @ResourceFilters(DatasourceResourceFilter.class)\n+  public Response getDatasourceLoadstatus(\n+      @PathParam(\"dataSourceName\") String dataSourceName,\n+      @QueryParam(\"interval\") @Nullable final String interval,\n+      @QueryParam(\"forceMetadataRefresh\") @Nullable final Boolean forceMetadataRefresh,\n+      @QueryParam(\"simple\") @Nullable final String simple,\n+      @QueryParam(\"full\") @Nullable final String full\n+  )\n+  {\n+    final Interval theInterval;\n+    if (interval == null) {\n+      long defaultIntervalOffset = 14 * 24 * 60 * 60 * 1000;\n+      long currentTimeInMs = System.currentTimeMillis();\n+      theInterval = Intervals.utc(currentTimeInMs - defaultIntervalOffset, currentTimeInMs);\n+    } else {\n+      theInterval = Intervals.of(interval.replace('_', '/'));\n+    }\n+\n+    boolean requiresMetadataStorePoll = forceMetadataRefresh == null ? true : forceMetadataRefresh;\n+\n+    Optional<Iterable<DataSegment>> segments = segmentsMetadataManager.iterateAllUsedNonOvershadowedSegmentsForDatasourceInterval(\n+        dataSourceName,\n+        theInterval,\n+        requiresMetadataStorePoll\n+    );\n+\n+    if (!segments.isPresent()) {\n+      return logAndCreateDataSourceNotFoundResponse(dataSourceName);\n+    }\n+\n+    if (simple != null) {\n+      // Calculate resposne for simple mode", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTE4MTI2Mg=="}, "originalCommit": {"oid": "172ef6ac47e1566ad889d937bd8f12ad170bf4ff"}, "originalPosition": 55}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczNTkxNTM3OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/druid/server/http/DataSourcesResource.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQwMzowNjo1NFrOGi1lMA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xM1QwNDoxNzoyNVrOGjVm_w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTE4MjY0MA==", "bodyText": "Hmm, is there a way to re-arrange this without iterating the entire set of segments twice? If not it would maybe be worth pushing this into DruidCoordinator, at least if force refresh is true, since it potentially has segmentReplicantLookup already built, or exposing it to this resource in some manner.", "url": "https://github.com/apache/druid/pull/9965#discussion_r439182640", "createdAt": "2020-06-12T03:06:54Z", "author": {"login": "clintropolis"}, "path": "server/src/main/java/org/apache/druid/server/http/DataSourcesResource.java", "diffHunk": "@@ -391,6 +396,123 @@ public Response getServedSegmentsInInterval(\n     return getServedSegmentsInInterval(dataSourceName, full != null, theInterval::contains);\n   }\n \n+  @GET\n+  @Path(\"/{dataSourceName}/loadstatus\")\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @ResourceFilters(DatasourceResourceFilter.class)\n+  public Response getDatasourceLoadstatus(\n+      @PathParam(\"dataSourceName\") String dataSourceName,\n+      @QueryParam(\"interval\") @Nullable final String interval,\n+      @QueryParam(\"forceMetadataRefresh\") @Nullable final Boolean forceMetadataRefresh,\n+      @QueryParam(\"simple\") @Nullable final String simple,\n+      @QueryParam(\"full\") @Nullable final String full\n+  )\n+  {\n+    final Interval theInterval;\n+    if (interval == null) {\n+      long defaultIntervalOffset = 14 * 24 * 60 * 60 * 1000;\n+      long currentTimeInMs = System.currentTimeMillis();\n+      theInterval = Intervals.utc(currentTimeInMs - defaultIntervalOffset, currentTimeInMs);\n+    } else {\n+      theInterval = Intervals.of(interval.replace('_', '/'));\n+    }\n+\n+    boolean requiresMetadataStorePoll = forceMetadataRefresh == null ? true : forceMetadataRefresh;\n+\n+    Optional<Iterable<DataSegment>> segments = segmentsMetadataManager.iterateAllUsedNonOvershadowedSegmentsForDatasourceInterval(\n+        dataSourceName,\n+        theInterval,\n+        requiresMetadataStorePoll\n+    );\n+\n+    if (!segments.isPresent()) {\n+      return logAndCreateDataSourceNotFoundResponse(dataSourceName);\n+    }\n+\n+    if (simple != null) {\n+      // Calculate resposne for simple mode\n+      Map<SegmentId, SegmentLoadInfo> segmentLoadInfos = serverInventoryView.getSegmentLoadInfos();\n+      int numUnloadedSegments = 0;\n+      for (DataSegment segment : segments.get()) {\n+        if (!segmentLoadInfos.containsKey(segment.getId())) {\n+          numUnloadedSegments++;\n+        }\n+      }\n+      return Response.ok(\n+          ImmutableMap.of(\n+              dataSourceName,\n+              numUnloadedSegments\n+          )\n+      ).build();\n+    } else if (full != null) {\n+      // Calculate resposne for full mode\n+      final Map<String, Object2LongMap<String>> underReplicationCountsPerDataSourcePerTier = new HashMap<>();\n+      final List<Rule> rules = metadataRuleManager.getRulesWithDefault(dataSourceName);\n+      final Table<SegmentId, String, Integer> segmentsInCluster = HashBasedTable.create();\n+      final DateTime now = DateTimes.nowUtc();\n+\n+      for (DataSegment segment : segments.get()) {\n+        for (DruidServer druidServer : serverInventoryView.getInventory()) {\n+          String tier = druidServer.getTier();\n+          SegmentId segmentId = segment.getId();\n+          DruidDataSource druidDataSource = druidServer.getDataSource(dataSourceName);\n+          if (druidDataSource != null && druidDataSource.getSegment(segmentId) != null) {\n+            Integer numReplicants = segmentsInCluster.get(segmentId, tier);\n+            if (numReplicants == null) {\n+              numReplicants = 0;\n+            }\n+            segmentsInCluster.put(segmentId, tier, numReplicants + 1);\n+          }\n+        }\n+      }\n+      for (DataSegment segment : segments.get()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "172ef6ac47e1566ad889d937bd8f12ad170bf4ff"}, "originalPosition": 90}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTcwNzM5MQ==", "bodyText": "Removed this code in DataSourcesResource. Reuse the code for calculating the underReplicationCountsPerDataSourcePerTier in DruidCoordinator by making the call to DruidCoordinator. This basically reuse segmentReplicantLookup in DruidCoordinator. This can make sure that the behavior is consistent between the full format of the new API and the existing coordinator loadstatus API. For example, if there is a bug in the full format coordinator loadstatus API where it is ignoring broadcast rule, then we just have to remember to fix it in one place ;)", "url": "https://github.com/apache/druid/pull/9965#discussion_r439707391", "createdAt": "2020-06-13T04:17:25Z", "author": {"login": "maytasm"}, "path": "server/src/main/java/org/apache/druid/server/http/DataSourcesResource.java", "diffHunk": "@@ -391,6 +396,123 @@ public Response getServedSegmentsInInterval(\n     return getServedSegmentsInInterval(dataSourceName, full != null, theInterval::contains);\n   }\n \n+  @GET\n+  @Path(\"/{dataSourceName}/loadstatus\")\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @ResourceFilters(DatasourceResourceFilter.class)\n+  public Response getDatasourceLoadstatus(\n+      @PathParam(\"dataSourceName\") String dataSourceName,\n+      @QueryParam(\"interval\") @Nullable final String interval,\n+      @QueryParam(\"forceMetadataRefresh\") @Nullable final Boolean forceMetadataRefresh,\n+      @QueryParam(\"simple\") @Nullable final String simple,\n+      @QueryParam(\"full\") @Nullable final String full\n+  )\n+  {\n+    final Interval theInterval;\n+    if (interval == null) {\n+      long defaultIntervalOffset = 14 * 24 * 60 * 60 * 1000;\n+      long currentTimeInMs = System.currentTimeMillis();\n+      theInterval = Intervals.utc(currentTimeInMs - defaultIntervalOffset, currentTimeInMs);\n+    } else {\n+      theInterval = Intervals.of(interval.replace('_', '/'));\n+    }\n+\n+    boolean requiresMetadataStorePoll = forceMetadataRefresh == null ? true : forceMetadataRefresh;\n+\n+    Optional<Iterable<DataSegment>> segments = segmentsMetadataManager.iterateAllUsedNonOvershadowedSegmentsForDatasourceInterval(\n+        dataSourceName,\n+        theInterval,\n+        requiresMetadataStorePoll\n+    );\n+\n+    if (!segments.isPresent()) {\n+      return logAndCreateDataSourceNotFoundResponse(dataSourceName);\n+    }\n+\n+    if (simple != null) {\n+      // Calculate resposne for simple mode\n+      Map<SegmentId, SegmentLoadInfo> segmentLoadInfos = serverInventoryView.getSegmentLoadInfos();\n+      int numUnloadedSegments = 0;\n+      for (DataSegment segment : segments.get()) {\n+        if (!segmentLoadInfos.containsKey(segment.getId())) {\n+          numUnloadedSegments++;\n+        }\n+      }\n+      return Response.ok(\n+          ImmutableMap.of(\n+              dataSourceName,\n+              numUnloadedSegments\n+          )\n+      ).build();\n+    } else if (full != null) {\n+      // Calculate resposne for full mode\n+      final Map<String, Object2LongMap<String>> underReplicationCountsPerDataSourcePerTier = new HashMap<>();\n+      final List<Rule> rules = metadataRuleManager.getRulesWithDefault(dataSourceName);\n+      final Table<SegmentId, String, Integer> segmentsInCluster = HashBasedTable.create();\n+      final DateTime now = DateTimes.nowUtc();\n+\n+      for (DataSegment segment : segments.get()) {\n+        for (DruidServer druidServer : serverInventoryView.getInventory()) {\n+          String tier = druidServer.getTier();\n+          SegmentId segmentId = segment.getId();\n+          DruidDataSource druidDataSource = druidServer.getDataSource(dataSourceName);\n+          if (druidDataSource != null && druidDataSource.getSegment(segmentId) != null) {\n+            Integer numReplicants = segmentsInCluster.get(segmentId, tier);\n+            if (numReplicants == null) {\n+              numReplicants = 0;\n+            }\n+            segmentsInCluster.put(segmentId, tier, numReplicants + 1);\n+          }\n+        }\n+      }\n+      for (DataSegment segment : segments.get()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTE4MjY0MA=="}, "originalCommit": {"oid": "172ef6ac47e1566ad889d937bd8f12ad170bf4ff"}, "originalPosition": 90}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczNTkyMTQ2OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/druid/server/http/DataSourcesResource.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQwMzoxMToxOVrOGi1o8Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xM1QwNDoxNzo0M1rOGjVnEg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTE4MzYwMQ==", "bodyText": "resposne -> response", "url": "https://github.com/apache/druid/pull/9965#discussion_r439183601", "createdAt": "2020-06-12T03:11:19Z", "author": {"login": "clintropolis"}, "path": "server/src/main/java/org/apache/druid/server/http/DataSourcesResource.java", "diffHunk": "@@ -391,6 +396,123 @@ public Response getServedSegmentsInInterval(\n     return getServedSegmentsInInterval(dataSourceName, full != null, theInterval::contains);\n   }\n \n+  @GET\n+  @Path(\"/{dataSourceName}/loadstatus\")\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @ResourceFilters(DatasourceResourceFilter.class)\n+  public Response getDatasourceLoadstatus(\n+      @PathParam(\"dataSourceName\") String dataSourceName,\n+      @QueryParam(\"interval\") @Nullable final String interval,\n+      @QueryParam(\"forceMetadataRefresh\") @Nullable final Boolean forceMetadataRefresh,\n+      @QueryParam(\"simple\") @Nullable final String simple,\n+      @QueryParam(\"full\") @Nullable final String full\n+  )\n+  {\n+    final Interval theInterval;\n+    if (interval == null) {\n+      long defaultIntervalOffset = 14 * 24 * 60 * 60 * 1000;\n+      long currentTimeInMs = System.currentTimeMillis();\n+      theInterval = Intervals.utc(currentTimeInMs - defaultIntervalOffset, currentTimeInMs);\n+    } else {\n+      theInterval = Intervals.of(interval.replace('_', '/'));\n+    }\n+\n+    boolean requiresMetadataStorePoll = forceMetadataRefresh == null ? true : forceMetadataRefresh;\n+\n+    Optional<Iterable<DataSegment>> segments = segmentsMetadataManager.iterateAllUsedNonOvershadowedSegmentsForDatasourceInterval(\n+        dataSourceName,\n+        theInterval,\n+        requiresMetadataStorePoll\n+    );\n+\n+    if (!segments.isPresent()) {\n+      return logAndCreateDataSourceNotFoundResponse(dataSourceName);\n+    }\n+\n+    if (simple != null) {\n+      // Calculate resposne for simple mode\n+      Map<SegmentId, SegmentLoadInfo> segmentLoadInfos = serverInventoryView.getSegmentLoadInfos();\n+      int numUnloadedSegments = 0;\n+      for (DataSegment segment : segments.get()) {\n+        if (!segmentLoadInfos.containsKey(segment.getId())) {\n+          numUnloadedSegments++;\n+        }\n+      }\n+      return Response.ok(\n+          ImmutableMap.of(\n+              dataSourceName,\n+              numUnloadedSegments\n+          )\n+      ).build();\n+    } else if (full != null) {\n+      // Calculate resposne for full mode\n+      final Map<String, Object2LongMap<String>> underReplicationCountsPerDataSourcePerTier = new HashMap<>();\n+      final List<Rule> rules = metadataRuleManager.getRulesWithDefault(dataSourceName);\n+      final Table<SegmentId, String, Integer> segmentsInCluster = HashBasedTable.create();\n+      final DateTime now = DateTimes.nowUtc();\n+\n+      for (DataSegment segment : segments.get()) {\n+        for (DruidServer druidServer : serverInventoryView.getInventory()) {\n+          String tier = druidServer.getTier();\n+          SegmentId segmentId = segment.getId();\n+          DruidDataSource druidDataSource = druidServer.getDataSource(dataSourceName);\n+          if (druidDataSource != null && druidDataSource.getSegment(segmentId) != null) {\n+            Integer numReplicants = segmentsInCluster.get(segmentId, tier);\n+            if (numReplicants == null) {\n+              numReplicants = 0;\n+            }\n+            segmentsInCluster.put(segmentId, tier, numReplicants + 1);\n+          }\n+        }\n+      }\n+      for (DataSegment segment : segments.get()) {\n+        for (final Rule rule : rules) {\n+          if (!(rule instanceof LoadRule && rule.appliesTo(segment, now))) {\n+            continue;\n+          }\n+          ((LoadRule) rule)\n+              .getTieredReplicants()\n+              .forEach((final String tier, final Integer ruleReplicants) -> {\n+                Integer currentReplicantsRetVal = segmentsInCluster.get(segment.getId(), tier);\n+                int currentReplicants = currentReplicantsRetVal == null ? 0 : currentReplicantsRetVal;\n+                Object2LongMap<String> underReplicationPerDataSource = underReplicationCountsPerDataSourcePerTier\n+                    .computeIfAbsent(tier, ignored -> new Object2LongOpenHashMap<>());\n+                ((Object2LongOpenHashMap<String>) underReplicationPerDataSource)\n+                    .addTo(dataSourceName, Math.max(ruleReplicants - currentReplicants, 0));\n+              });\n+          break; // only the first matching rule applies\n+        }\n+      }\n+      return Response.ok(underReplicationCountsPerDataSourcePerTier).build();\n+    } else {\n+      // Calculate resposne for default mode", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "172ef6ac47e1566ad889d937bd8f12ad170bf4ff"}, "originalPosition": 110}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTcwNzQxMA==", "bodyText": "Done", "url": "https://github.com/apache/druid/pull/9965#discussion_r439707410", "createdAt": "2020-06-13T04:17:43Z", "author": {"login": "maytasm"}, "path": "server/src/main/java/org/apache/druid/server/http/DataSourcesResource.java", "diffHunk": "@@ -391,6 +396,123 @@ public Response getServedSegmentsInInterval(\n     return getServedSegmentsInInterval(dataSourceName, full != null, theInterval::contains);\n   }\n \n+  @GET\n+  @Path(\"/{dataSourceName}/loadstatus\")\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @ResourceFilters(DatasourceResourceFilter.class)\n+  public Response getDatasourceLoadstatus(\n+      @PathParam(\"dataSourceName\") String dataSourceName,\n+      @QueryParam(\"interval\") @Nullable final String interval,\n+      @QueryParam(\"forceMetadataRefresh\") @Nullable final Boolean forceMetadataRefresh,\n+      @QueryParam(\"simple\") @Nullable final String simple,\n+      @QueryParam(\"full\") @Nullable final String full\n+  )\n+  {\n+    final Interval theInterval;\n+    if (interval == null) {\n+      long defaultIntervalOffset = 14 * 24 * 60 * 60 * 1000;\n+      long currentTimeInMs = System.currentTimeMillis();\n+      theInterval = Intervals.utc(currentTimeInMs - defaultIntervalOffset, currentTimeInMs);\n+    } else {\n+      theInterval = Intervals.of(interval.replace('_', '/'));\n+    }\n+\n+    boolean requiresMetadataStorePoll = forceMetadataRefresh == null ? true : forceMetadataRefresh;\n+\n+    Optional<Iterable<DataSegment>> segments = segmentsMetadataManager.iterateAllUsedNonOvershadowedSegmentsForDatasourceInterval(\n+        dataSourceName,\n+        theInterval,\n+        requiresMetadataStorePoll\n+    );\n+\n+    if (!segments.isPresent()) {\n+      return logAndCreateDataSourceNotFoundResponse(dataSourceName);\n+    }\n+\n+    if (simple != null) {\n+      // Calculate resposne for simple mode\n+      Map<SegmentId, SegmentLoadInfo> segmentLoadInfos = serverInventoryView.getSegmentLoadInfos();\n+      int numUnloadedSegments = 0;\n+      for (DataSegment segment : segments.get()) {\n+        if (!segmentLoadInfos.containsKey(segment.getId())) {\n+          numUnloadedSegments++;\n+        }\n+      }\n+      return Response.ok(\n+          ImmutableMap.of(\n+              dataSourceName,\n+              numUnloadedSegments\n+          )\n+      ).build();\n+    } else if (full != null) {\n+      // Calculate resposne for full mode\n+      final Map<String, Object2LongMap<String>> underReplicationCountsPerDataSourcePerTier = new HashMap<>();\n+      final List<Rule> rules = metadataRuleManager.getRulesWithDefault(dataSourceName);\n+      final Table<SegmentId, String, Integer> segmentsInCluster = HashBasedTable.create();\n+      final DateTime now = DateTimes.nowUtc();\n+\n+      for (DataSegment segment : segments.get()) {\n+        for (DruidServer druidServer : serverInventoryView.getInventory()) {\n+          String tier = druidServer.getTier();\n+          SegmentId segmentId = segment.getId();\n+          DruidDataSource druidDataSource = druidServer.getDataSource(dataSourceName);\n+          if (druidDataSource != null && druidDataSource.getSegment(segmentId) != null) {\n+            Integer numReplicants = segmentsInCluster.get(segmentId, tier);\n+            if (numReplicants == null) {\n+              numReplicants = 0;\n+            }\n+            segmentsInCluster.put(segmentId, tier, numReplicants + 1);\n+          }\n+        }\n+      }\n+      for (DataSegment segment : segments.get()) {\n+        for (final Rule rule : rules) {\n+          if (!(rule instanceof LoadRule && rule.appliesTo(segment, now))) {\n+            continue;\n+          }\n+          ((LoadRule) rule)\n+              .getTieredReplicants()\n+              .forEach((final String tier, final Integer ruleReplicants) -> {\n+                Integer currentReplicantsRetVal = segmentsInCluster.get(segment.getId(), tier);\n+                int currentReplicants = currentReplicantsRetVal == null ? 0 : currentReplicantsRetVal;\n+                Object2LongMap<String> underReplicationPerDataSource = underReplicationCountsPerDataSourcePerTier\n+                    .computeIfAbsent(tier, ignored -> new Object2LongOpenHashMap<>());\n+                ((Object2LongOpenHashMap<String>) underReplicationPerDataSource)\n+                    .addTo(dataSourceName, Math.max(ruleReplicants - currentReplicants, 0));\n+              });\n+          break; // only the first matching rule applies\n+        }\n+      }\n+      return Response.ok(underReplicationCountsPerDataSourcePerTier).build();\n+    } else {\n+      // Calculate resposne for default mode", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTE4MzYwMQ=="}, "originalCommit": {"oid": "172ef6ac47e1566ad889d937bd8f12ad170bf4ff"}, "originalPosition": 110}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczNTkyNDUxOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/druid/server/http/DataSourcesResource.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQwMzoxMzo1MFrOGi1q9A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xM1QwNDoxODowN1rOGjVnJw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTE4NDExNg==", "bodyText": "Yeah, I think you need to handle BroadcastDistributionRule here too if you want to be totally complete, however CoordinatorResource loadstatus api call has this problem too, so it would probably be ok to fix both in a follow-up PR.", "url": "https://github.com/apache/druid/pull/9965#discussion_r439184116", "createdAt": "2020-06-12T03:13:50Z", "author": {"login": "clintropolis"}, "path": "server/src/main/java/org/apache/druid/server/http/DataSourcesResource.java", "diffHunk": "@@ -391,6 +396,123 @@ public Response getServedSegmentsInInterval(\n     return getServedSegmentsInInterval(dataSourceName, full != null, theInterval::contains);\n   }\n \n+  @GET\n+  @Path(\"/{dataSourceName}/loadstatus\")\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @ResourceFilters(DatasourceResourceFilter.class)\n+  public Response getDatasourceLoadstatus(\n+      @PathParam(\"dataSourceName\") String dataSourceName,\n+      @QueryParam(\"interval\") @Nullable final String interval,\n+      @QueryParam(\"forceMetadataRefresh\") @Nullable final Boolean forceMetadataRefresh,\n+      @QueryParam(\"simple\") @Nullable final String simple,\n+      @QueryParam(\"full\") @Nullable final String full\n+  )\n+  {\n+    final Interval theInterval;\n+    if (interval == null) {\n+      long defaultIntervalOffset = 14 * 24 * 60 * 60 * 1000;\n+      long currentTimeInMs = System.currentTimeMillis();\n+      theInterval = Intervals.utc(currentTimeInMs - defaultIntervalOffset, currentTimeInMs);\n+    } else {\n+      theInterval = Intervals.of(interval.replace('_', '/'));\n+    }\n+\n+    boolean requiresMetadataStorePoll = forceMetadataRefresh == null ? true : forceMetadataRefresh;\n+\n+    Optional<Iterable<DataSegment>> segments = segmentsMetadataManager.iterateAllUsedNonOvershadowedSegmentsForDatasourceInterval(\n+        dataSourceName,\n+        theInterval,\n+        requiresMetadataStorePoll\n+    );\n+\n+    if (!segments.isPresent()) {\n+      return logAndCreateDataSourceNotFoundResponse(dataSourceName);\n+    }\n+\n+    if (simple != null) {\n+      // Calculate resposne for simple mode\n+      Map<SegmentId, SegmentLoadInfo> segmentLoadInfos = serverInventoryView.getSegmentLoadInfos();\n+      int numUnloadedSegments = 0;\n+      for (DataSegment segment : segments.get()) {\n+        if (!segmentLoadInfos.containsKey(segment.getId())) {\n+          numUnloadedSegments++;\n+        }\n+      }\n+      return Response.ok(\n+          ImmutableMap.of(\n+              dataSourceName,\n+              numUnloadedSegments\n+          )\n+      ).build();\n+    } else if (full != null) {\n+      // Calculate resposne for full mode\n+      final Map<String, Object2LongMap<String>> underReplicationCountsPerDataSourcePerTier = new HashMap<>();\n+      final List<Rule> rules = metadataRuleManager.getRulesWithDefault(dataSourceName);\n+      final Table<SegmentId, String, Integer> segmentsInCluster = HashBasedTable.create();\n+      final DateTime now = DateTimes.nowUtc();\n+\n+      for (DataSegment segment : segments.get()) {\n+        for (DruidServer druidServer : serverInventoryView.getInventory()) {\n+          String tier = druidServer.getTier();\n+          SegmentId segmentId = segment.getId();\n+          DruidDataSource druidDataSource = druidServer.getDataSource(dataSourceName);\n+          if (druidDataSource != null && druidDataSource.getSegment(segmentId) != null) {\n+            Integer numReplicants = segmentsInCluster.get(segmentId, tier);\n+            if (numReplicants == null) {\n+              numReplicants = 0;\n+            }\n+            segmentsInCluster.put(segmentId, tier, numReplicants + 1);\n+          }\n+        }\n+      }\n+      for (DataSegment segment : segments.get()) {\n+        for (final Rule rule : rules) {\n+          if (!(rule instanceof LoadRule && rule.appliesTo(segment, now))) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "172ef6ac47e1566ad889d937bd8f12ad170bf4ff"}, "originalPosition": 92}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTcwNzQzMQ==", "bodyText": "Since this is a bug in the original Coordinator loadstatus API. I'll fix this in a follow-up PR", "url": "https://github.com/apache/druid/pull/9965#discussion_r439707431", "createdAt": "2020-06-13T04:18:07Z", "author": {"login": "maytasm"}, "path": "server/src/main/java/org/apache/druid/server/http/DataSourcesResource.java", "diffHunk": "@@ -391,6 +396,123 @@ public Response getServedSegmentsInInterval(\n     return getServedSegmentsInInterval(dataSourceName, full != null, theInterval::contains);\n   }\n \n+  @GET\n+  @Path(\"/{dataSourceName}/loadstatus\")\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @ResourceFilters(DatasourceResourceFilter.class)\n+  public Response getDatasourceLoadstatus(\n+      @PathParam(\"dataSourceName\") String dataSourceName,\n+      @QueryParam(\"interval\") @Nullable final String interval,\n+      @QueryParam(\"forceMetadataRefresh\") @Nullable final Boolean forceMetadataRefresh,\n+      @QueryParam(\"simple\") @Nullable final String simple,\n+      @QueryParam(\"full\") @Nullable final String full\n+  )\n+  {\n+    final Interval theInterval;\n+    if (interval == null) {\n+      long defaultIntervalOffset = 14 * 24 * 60 * 60 * 1000;\n+      long currentTimeInMs = System.currentTimeMillis();\n+      theInterval = Intervals.utc(currentTimeInMs - defaultIntervalOffset, currentTimeInMs);\n+    } else {\n+      theInterval = Intervals.of(interval.replace('_', '/'));\n+    }\n+\n+    boolean requiresMetadataStorePoll = forceMetadataRefresh == null ? true : forceMetadataRefresh;\n+\n+    Optional<Iterable<DataSegment>> segments = segmentsMetadataManager.iterateAllUsedNonOvershadowedSegmentsForDatasourceInterval(\n+        dataSourceName,\n+        theInterval,\n+        requiresMetadataStorePoll\n+    );\n+\n+    if (!segments.isPresent()) {\n+      return logAndCreateDataSourceNotFoundResponse(dataSourceName);\n+    }\n+\n+    if (simple != null) {\n+      // Calculate resposne for simple mode\n+      Map<SegmentId, SegmentLoadInfo> segmentLoadInfos = serverInventoryView.getSegmentLoadInfos();\n+      int numUnloadedSegments = 0;\n+      for (DataSegment segment : segments.get()) {\n+        if (!segmentLoadInfos.containsKey(segment.getId())) {\n+          numUnloadedSegments++;\n+        }\n+      }\n+      return Response.ok(\n+          ImmutableMap.of(\n+              dataSourceName,\n+              numUnloadedSegments\n+          )\n+      ).build();\n+    } else if (full != null) {\n+      // Calculate resposne for full mode\n+      final Map<String, Object2LongMap<String>> underReplicationCountsPerDataSourcePerTier = new HashMap<>();\n+      final List<Rule> rules = metadataRuleManager.getRulesWithDefault(dataSourceName);\n+      final Table<SegmentId, String, Integer> segmentsInCluster = HashBasedTable.create();\n+      final DateTime now = DateTimes.nowUtc();\n+\n+      for (DataSegment segment : segments.get()) {\n+        for (DruidServer druidServer : serverInventoryView.getInventory()) {\n+          String tier = druidServer.getTier();\n+          SegmentId segmentId = segment.getId();\n+          DruidDataSource druidDataSource = druidServer.getDataSource(dataSourceName);\n+          if (druidDataSource != null && druidDataSource.getSegment(segmentId) != null) {\n+            Integer numReplicants = segmentsInCluster.get(segmentId, tier);\n+            if (numReplicants == null) {\n+              numReplicants = 0;\n+            }\n+            segmentsInCluster.put(segmentId, tier, numReplicants + 1);\n+          }\n+        }\n+      }\n+      for (DataSegment segment : segments.get()) {\n+        for (final Rule rule : rules) {\n+          if (!(rule instanceof LoadRule && rule.appliesTo(segment, now))) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTE4NDExNg=="}, "originalCommit": {"oid": "172ef6ac47e1566ad889d937bd8f12ad170bf4ff"}, "originalPosition": 92}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczNTkyODgyOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/druid/server/http/DataSourcesResource.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQwMzoxNjo1MFrOGi1tlw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xM1QwNDoyMDoxNFrOGjVngA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTE4NDc5MQ==", "bodyText": "super nit: it would probably be consistent to try to match the terminology that appears in the system segments table, which uses 'published' and 'available' for used and loaded\n\nnumUsedSegments -> numPublishedSegments\nnumUnloadedSegments -> numUnavailableSegments", "url": "https://github.com/apache/druid/pull/9965#discussion_r439184791", "createdAt": "2020-06-12T03:16:50Z", "author": {"login": "clintropolis"}, "path": "server/src/main/java/org/apache/druid/server/http/DataSourcesResource.java", "diffHunk": "@@ -391,6 +396,123 @@ public Response getServedSegmentsInInterval(\n     return getServedSegmentsInInterval(dataSourceName, full != null, theInterval::contains);\n   }\n \n+  @GET\n+  @Path(\"/{dataSourceName}/loadstatus\")\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @ResourceFilters(DatasourceResourceFilter.class)\n+  public Response getDatasourceLoadstatus(\n+      @PathParam(\"dataSourceName\") String dataSourceName,\n+      @QueryParam(\"interval\") @Nullable final String interval,\n+      @QueryParam(\"forceMetadataRefresh\") @Nullable final Boolean forceMetadataRefresh,\n+      @QueryParam(\"simple\") @Nullable final String simple,\n+      @QueryParam(\"full\") @Nullable final String full\n+  )\n+  {\n+    final Interval theInterval;\n+    if (interval == null) {\n+      long defaultIntervalOffset = 14 * 24 * 60 * 60 * 1000;\n+      long currentTimeInMs = System.currentTimeMillis();\n+      theInterval = Intervals.utc(currentTimeInMs - defaultIntervalOffset, currentTimeInMs);\n+    } else {\n+      theInterval = Intervals.of(interval.replace('_', '/'));\n+    }\n+\n+    boolean requiresMetadataStorePoll = forceMetadataRefresh == null ? true : forceMetadataRefresh;\n+\n+    Optional<Iterable<DataSegment>> segments = segmentsMetadataManager.iterateAllUsedNonOvershadowedSegmentsForDatasourceInterval(\n+        dataSourceName,\n+        theInterval,\n+        requiresMetadataStorePoll\n+    );\n+\n+    if (!segments.isPresent()) {\n+      return logAndCreateDataSourceNotFoundResponse(dataSourceName);\n+    }\n+\n+    if (simple != null) {\n+      // Calculate resposne for simple mode\n+      Map<SegmentId, SegmentLoadInfo> segmentLoadInfos = serverInventoryView.getSegmentLoadInfos();\n+      int numUnloadedSegments = 0;\n+      for (DataSegment segment : segments.get()) {\n+        if (!segmentLoadInfos.containsKey(segment.getId())) {\n+          numUnloadedSegments++;\n+        }\n+      }\n+      return Response.ok(\n+          ImmutableMap.of(\n+              dataSourceName,\n+              numUnloadedSegments\n+          )\n+      ).build();\n+    } else if (full != null) {\n+      // Calculate resposne for full mode\n+      final Map<String, Object2LongMap<String>> underReplicationCountsPerDataSourcePerTier = new HashMap<>();\n+      final List<Rule> rules = metadataRuleManager.getRulesWithDefault(dataSourceName);\n+      final Table<SegmentId, String, Integer> segmentsInCluster = HashBasedTable.create();\n+      final DateTime now = DateTimes.nowUtc();\n+\n+      for (DataSegment segment : segments.get()) {\n+        for (DruidServer druidServer : serverInventoryView.getInventory()) {\n+          String tier = druidServer.getTier();\n+          SegmentId segmentId = segment.getId();\n+          DruidDataSource druidDataSource = druidServer.getDataSource(dataSourceName);\n+          if (druidDataSource != null && druidDataSource.getSegment(segmentId) != null) {\n+            Integer numReplicants = segmentsInCluster.get(segmentId, tier);\n+            if (numReplicants == null) {\n+              numReplicants = 0;\n+            }\n+            segmentsInCluster.put(segmentId, tier, numReplicants + 1);\n+          }\n+        }\n+      }\n+      for (DataSegment segment : segments.get()) {\n+        for (final Rule rule : rules) {\n+          if (!(rule instanceof LoadRule && rule.appliesTo(segment, now))) {\n+            continue;\n+          }\n+          ((LoadRule) rule)\n+              .getTieredReplicants()\n+              .forEach((final String tier, final Integer ruleReplicants) -> {\n+                Integer currentReplicantsRetVal = segmentsInCluster.get(segment.getId(), tier);\n+                int currentReplicants = currentReplicantsRetVal == null ? 0 : currentReplicantsRetVal;\n+                Object2LongMap<String> underReplicationPerDataSource = underReplicationCountsPerDataSourcePerTier\n+                    .computeIfAbsent(tier, ignored -> new Object2LongOpenHashMap<>());\n+                ((Object2LongOpenHashMap<String>) underReplicationPerDataSource)\n+                    .addTo(dataSourceName, Math.max(ruleReplicants - currentReplicants, 0));\n+              });\n+          break; // only the first matching rule applies\n+        }\n+      }\n+      return Response.ok(underReplicationCountsPerDataSourcePerTier).build();\n+    } else {\n+      // Calculate resposne for default mode\n+      Map<SegmentId, SegmentLoadInfo> segmentLoadInfos = serverInventoryView.getSegmentLoadInfos();\n+      int numUsedSegments = 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "172ef6ac47e1566ad889d937bd8f12ad170bf4ff"}, "originalPosition": 112}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTcwNzUyMA==", "bodyText": "Done", "url": "https://github.com/apache/druid/pull/9965#discussion_r439707520", "createdAt": "2020-06-13T04:20:14Z", "author": {"login": "maytasm"}, "path": "server/src/main/java/org/apache/druid/server/http/DataSourcesResource.java", "diffHunk": "@@ -391,6 +396,123 @@ public Response getServedSegmentsInInterval(\n     return getServedSegmentsInInterval(dataSourceName, full != null, theInterval::contains);\n   }\n \n+  @GET\n+  @Path(\"/{dataSourceName}/loadstatus\")\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @ResourceFilters(DatasourceResourceFilter.class)\n+  public Response getDatasourceLoadstatus(\n+      @PathParam(\"dataSourceName\") String dataSourceName,\n+      @QueryParam(\"interval\") @Nullable final String interval,\n+      @QueryParam(\"forceMetadataRefresh\") @Nullable final Boolean forceMetadataRefresh,\n+      @QueryParam(\"simple\") @Nullable final String simple,\n+      @QueryParam(\"full\") @Nullable final String full\n+  )\n+  {\n+    final Interval theInterval;\n+    if (interval == null) {\n+      long defaultIntervalOffset = 14 * 24 * 60 * 60 * 1000;\n+      long currentTimeInMs = System.currentTimeMillis();\n+      theInterval = Intervals.utc(currentTimeInMs - defaultIntervalOffset, currentTimeInMs);\n+    } else {\n+      theInterval = Intervals.of(interval.replace('_', '/'));\n+    }\n+\n+    boolean requiresMetadataStorePoll = forceMetadataRefresh == null ? true : forceMetadataRefresh;\n+\n+    Optional<Iterable<DataSegment>> segments = segmentsMetadataManager.iterateAllUsedNonOvershadowedSegmentsForDatasourceInterval(\n+        dataSourceName,\n+        theInterval,\n+        requiresMetadataStorePoll\n+    );\n+\n+    if (!segments.isPresent()) {\n+      return logAndCreateDataSourceNotFoundResponse(dataSourceName);\n+    }\n+\n+    if (simple != null) {\n+      // Calculate resposne for simple mode\n+      Map<SegmentId, SegmentLoadInfo> segmentLoadInfos = serverInventoryView.getSegmentLoadInfos();\n+      int numUnloadedSegments = 0;\n+      for (DataSegment segment : segments.get()) {\n+        if (!segmentLoadInfos.containsKey(segment.getId())) {\n+          numUnloadedSegments++;\n+        }\n+      }\n+      return Response.ok(\n+          ImmutableMap.of(\n+              dataSourceName,\n+              numUnloadedSegments\n+          )\n+      ).build();\n+    } else if (full != null) {\n+      // Calculate resposne for full mode\n+      final Map<String, Object2LongMap<String>> underReplicationCountsPerDataSourcePerTier = new HashMap<>();\n+      final List<Rule> rules = metadataRuleManager.getRulesWithDefault(dataSourceName);\n+      final Table<SegmentId, String, Integer> segmentsInCluster = HashBasedTable.create();\n+      final DateTime now = DateTimes.nowUtc();\n+\n+      for (DataSegment segment : segments.get()) {\n+        for (DruidServer druidServer : serverInventoryView.getInventory()) {\n+          String tier = druidServer.getTier();\n+          SegmentId segmentId = segment.getId();\n+          DruidDataSource druidDataSource = druidServer.getDataSource(dataSourceName);\n+          if (druidDataSource != null && druidDataSource.getSegment(segmentId) != null) {\n+            Integer numReplicants = segmentsInCluster.get(segmentId, tier);\n+            if (numReplicants == null) {\n+              numReplicants = 0;\n+            }\n+            segmentsInCluster.put(segmentId, tier, numReplicants + 1);\n+          }\n+        }\n+      }\n+      for (DataSegment segment : segments.get()) {\n+        for (final Rule rule : rules) {\n+          if (!(rule instanceof LoadRule && rule.appliesTo(segment, now))) {\n+            continue;\n+          }\n+          ((LoadRule) rule)\n+              .getTieredReplicants()\n+              .forEach((final String tier, final Integer ruleReplicants) -> {\n+                Integer currentReplicantsRetVal = segmentsInCluster.get(segment.getId(), tier);\n+                int currentReplicants = currentReplicantsRetVal == null ? 0 : currentReplicantsRetVal;\n+                Object2LongMap<String> underReplicationPerDataSource = underReplicationCountsPerDataSourcePerTier\n+                    .computeIfAbsent(tier, ignored -> new Object2LongOpenHashMap<>());\n+                ((Object2LongOpenHashMap<String>) underReplicationPerDataSource)\n+                    .addTo(dataSourceName, Math.max(ruleReplicants - currentReplicants, 0));\n+              });\n+          break; // only the first matching rule applies\n+        }\n+      }\n+      return Response.ok(underReplicationCountsPerDataSourcePerTier).build();\n+    } else {\n+      // Calculate resposne for default mode\n+      Map<SegmentId, SegmentLoadInfo> segmentLoadInfos = serverInventoryView.getSegmentLoadInfos();\n+      int numUsedSegments = 0;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTE4NDc5MQ=="}, "originalCommit": {"oid": "172ef6ac47e1566ad889d937bd8f12ad170bf4ff"}, "originalPosition": 112}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczNTkzMjQzOnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/druid/server/http/DataSourcesResource.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQwMzoxOTozN1rOGi1v3g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xM1QwNDoyMDoyNVrOGjVnhQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTE4NTM3NA==", "bodyText": "resposne -> response", "url": "https://github.com/apache/druid/pull/9965#discussion_r439185374", "createdAt": "2020-06-12T03:19:37Z", "author": {"login": "clintropolis"}, "path": "server/src/main/java/org/apache/druid/server/http/DataSourcesResource.java", "diffHunk": "@@ -391,6 +396,123 @@ public Response getServedSegmentsInInterval(\n     return getServedSegmentsInInterval(dataSourceName, full != null, theInterval::contains);\n   }\n \n+  @GET\n+  @Path(\"/{dataSourceName}/loadstatus\")\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @ResourceFilters(DatasourceResourceFilter.class)\n+  public Response getDatasourceLoadstatus(\n+      @PathParam(\"dataSourceName\") String dataSourceName,\n+      @QueryParam(\"interval\") @Nullable final String interval,\n+      @QueryParam(\"forceMetadataRefresh\") @Nullable final Boolean forceMetadataRefresh,\n+      @QueryParam(\"simple\") @Nullable final String simple,\n+      @QueryParam(\"full\") @Nullable final String full\n+  )\n+  {\n+    final Interval theInterval;\n+    if (interval == null) {\n+      long defaultIntervalOffset = 14 * 24 * 60 * 60 * 1000;\n+      long currentTimeInMs = System.currentTimeMillis();\n+      theInterval = Intervals.utc(currentTimeInMs - defaultIntervalOffset, currentTimeInMs);\n+    } else {\n+      theInterval = Intervals.of(interval.replace('_', '/'));\n+    }\n+\n+    boolean requiresMetadataStorePoll = forceMetadataRefresh == null ? true : forceMetadataRefresh;\n+\n+    Optional<Iterable<DataSegment>> segments = segmentsMetadataManager.iterateAllUsedNonOvershadowedSegmentsForDatasourceInterval(\n+        dataSourceName,\n+        theInterval,\n+        requiresMetadataStorePoll\n+    );\n+\n+    if (!segments.isPresent()) {\n+      return logAndCreateDataSourceNotFoundResponse(dataSourceName);\n+    }\n+\n+    if (simple != null) {\n+      // Calculate resposne for simple mode\n+      Map<SegmentId, SegmentLoadInfo> segmentLoadInfos = serverInventoryView.getSegmentLoadInfos();\n+      int numUnloadedSegments = 0;\n+      for (DataSegment segment : segments.get()) {\n+        if (!segmentLoadInfos.containsKey(segment.getId())) {\n+          numUnloadedSegments++;\n+        }\n+      }\n+      return Response.ok(\n+          ImmutableMap.of(\n+              dataSourceName,\n+              numUnloadedSegments\n+          )\n+      ).build();\n+    } else if (full != null) {\n+      // Calculate resposne for full mode", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "172ef6ac47e1566ad889d937bd8f12ad170bf4ff"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTcwNzUyNQ==", "bodyText": "Done", "url": "https://github.com/apache/druid/pull/9965#discussion_r439707525", "createdAt": "2020-06-13T04:20:25Z", "author": {"login": "maytasm"}, "path": "server/src/main/java/org/apache/druid/server/http/DataSourcesResource.java", "diffHunk": "@@ -391,6 +396,123 @@ public Response getServedSegmentsInInterval(\n     return getServedSegmentsInInterval(dataSourceName, full != null, theInterval::contains);\n   }\n \n+  @GET\n+  @Path(\"/{dataSourceName}/loadstatus\")\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @ResourceFilters(DatasourceResourceFilter.class)\n+  public Response getDatasourceLoadstatus(\n+      @PathParam(\"dataSourceName\") String dataSourceName,\n+      @QueryParam(\"interval\") @Nullable final String interval,\n+      @QueryParam(\"forceMetadataRefresh\") @Nullable final Boolean forceMetadataRefresh,\n+      @QueryParam(\"simple\") @Nullable final String simple,\n+      @QueryParam(\"full\") @Nullable final String full\n+  )\n+  {\n+    final Interval theInterval;\n+    if (interval == null) {\n+      long defaultIntervalOffset = 14 * 24 * 60 * 60 * 1000;\n+      long currentTimeInMs = System.currentTimeMillis();\n+      theInterval = Intervals.utc(currentTimeInMs - defaultIntervalOffset, currentTimeInMs);\n+    } else {\n+      theInterval = Intervals.of(interval.replace('_', '/'));\n+    }\n+\n+    boolean requiresMetadataStorePoll = forceMetadataRefresh == null ? true : forceMetadataRefresh;\n+\n+    Optional<Iterable<DataSegment>> segments = segmentsMetadataManager.iterateAllUsedNonOvershadowedSegmentsForDatasourceInterval(\n+        dataSourceName,\n+        theInterval,\n+        requiresMetadataStorePoll\n+    );\n+\n+    if (!segments.isPresent()) {\n+      return logAndCreateDataSourceNotFoundResponse(dataSourceName);\n+    }\n+\n+    if (simple != null) {\n+      // Calculate resposne for simple mode\n+      Map<SegmentId, SegmentLoadInfo> segmentLoadInfos = serverInventoryView.getSegmentLoadInfos();\n+      int numUnloadedSegments = 0;\n+      for (DataSegment segment : segments.get()) {\n+        if (!segmentLoadInfos.containsKey(segment.getId())) {\n+          numUnloadedSegments++;\n+        }\n+      }\n+      return Response.ok(\n+          ImmutableMap.of(\n+              dataSourceName,\n+              numUnloadedSegments\n+          )\n+      ).build();\n+    } else if (full != null) {\n+      // Calculate resposne for full mode", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTE4NTM3NA=="}, "originalCommit": {"oid": "172ef6ac47e1566ad889d937bd8f12ad170bf4ff"}, "originalPosition": 70}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc0NDQwMTcwOnYy", "diffSide": "RIGHT", "path": "docs/operations/api-reference.md", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNVQyMzoxMTo1OFrOGkFvOg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQwMTozNzozM1rOGkIPnw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDQ5NTkzMA==", "bodyText": "\"This include replica of segments.\" doesn't quite seem right, maybe \"This includes segment replication counts.\"", "url": "https://github.com/apache/druid/pull/9965#discussion_r440495930", "createdAt": "2020-06-15T23:11:58Z", "author": {"login": "clintropolis"}, "path": "docs/operations/api-reference.md", "diffHunk": "@@ -96,11 +96,11 @@ Returns the percentage of segments actually loaded in the cluster versus segment\n \n  * `/druid/coordinator/v1/loadstatus?simple`\n \n-Returns the number of segments left to load until segments that should be loaded in the cluster are available for queries. This does not include replication.\n+Returns the number of segments left to load until segments that should be loaded in the cluster are available for queries. This does not include replica of segments.\n \n * `/druid/coordinator/v1/loadstatus?full`\n \n-Returns the number of segments left to load in each tier until segments that should be loaded in the cluster are all available. This includes replication.\n+Returns the number of segments left to load in each tier until segments that should be loaded in the cluster are all available. This include replica of segments.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2470e8fa81e483839e8903a6f982c6108c230c8a"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDUzNjk5MQ==", "bodyText": "Done", "url": "https://github.com/apache/druid/pull/9965#discussion_r440536991", "createdAt": "2020-06-16T01:37:33Z", "author": {"login": "maytasm"}, "path": "docs/operations/api-reference.md", "diffHunk": "@@ -96,11 +96,11 @@ Returns the percentage of segments actually loaded in the cluster versus segment\n \n  * `/druid/coordinator/v1/loadstatus?simple`\n \n-Returns the number of segments left to load until segments that should be loaded in the cluster are available for queries. This does not include replication.\n+Returns the number of segments left to load until segments that should be loaded in the cluster are available for queries. This does not include replica of segments.\n \n * `/druid/coordinator/v1/loadstatus?full`\n \n-Returns the number of segments left to load in each tier until segments that should be loaded in the cluster are all available. This includes replication.\n+Returns the number of segments left to load in each tier until segments that should be loaded in the cluster are all available. This include replica of segments.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDQ5NTkzMA=="}, "originalCommit": {"oid": "2470e8fa81e483839e8903a6f982c6108c230c8a"}, "originalPosition": 10}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc0NDQwMjgzOnYy", "diffSide": "RIGHT", "path": "docs/operations/api-reference.md", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNVQyMzoxMjozMFrOGkFv5w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQwMTozODoxM1rOGkIQdg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDQ5NjEwMw==", "bodyText": "\"This does not include replica of segments.\" -> \"This does not include segment replication counts.\"", "url": "https://github.com/apache/druid/pull/9965#discussion_r440496103", "createdAt": "2020-06-15T23:12:30Z", "author": {"login": "clintropolis"}, "path": "docs/operations/api-reference.md", "diffHunk": "@@ -96,11 +96,11 @@ Returns the percentage of segments actually loaded in the cluster versus segment\n \n  * `/druid/coordinator/v1/loadstatus?simple`\n \n-Returns the number of segments left to load until segments that should be loaded in the cluster are available for queries. This does not include replication.\n+Returns the number of segments left to load until segments that should be loaded in the cluster are available for queries. This does not include replica of segments.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2470e8fa81e483839e8903a6f982c6108c230c8a"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDUzNzIwNg==", "bodyText": "Done", "url": "https://github.com/apache/druid/pull/9965#discussion_r440537206", "createdAt": "2020-06-16T01:38:13Z", "author": {"login": "maytasm"}, "path": "docs/operations/api-reference.md", "diffHunk": "@@ -96,11 +96,11 @@ Returns the percentage of segments actually loaded in the cluster versus segment\n \n  * `/druid/coordinator/v1/loadstatus?simple`\n \n-Returns the number of segments left to load until segments that should be loaded in the cluster are available for queries. This does not include replication.\n+Returns the number of segments left to load until segments that should be loaded in the cluster are available for queries. This does not include replica of segments.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDQ5NjEwMw=="}, "originalCommit": {"oid": "2470e8fa81e483839e8903a6f982c6108c230c8a"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc0NDQxMjI4OnYy", "diffSide": "RIGHT", "path": "docs/operations/api-reference.md", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNVQyMzoxNjo1NlrOGkF1cQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQwMTo0MTo1N1rOGkIUcg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDQ5NzUyMQ==", "bodyText": "This example workflow seems useful, but also out of place given the rest of this document, which strictly documents API requests and responses instead of illustrating an example application of how to use the API. I'm not sure where else it should live, or if it should just be removed, or if maybe it is fine, but I think it is worth discussing.", "url": "https://github.com/apache/druid/pull/9965#discussion_r440497521", "createdAt": "2020-06-15T23:16:56Z", "author": {"login": "clintropolis"}, "path": "docs/operations/api-reference.md", "diffHunk": "@@ -114,6 +114,44 @@ Returns the number of segments to load and drop, as well as the total segment lo\n \n Returns the serialized JSON of segments to load and drop for each Historical process.\n \n+\n+#### Segment Loading by Datasource\n+\n+You can verify if segments created by a recent ingestion task are loaded onto historicals and available for querying using the following APIs.\n+An example workflow for this is:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2470e8fa81e483839e8903a6f982c6108c230c8a"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDUzODIyNg==", "bodyText": "I think this example is useful. Especially when user is trying to verify if segments are loaded and available right after ingestion task is done. The workflow also point out the difference with the coordinator loadstatus API (and how they have different use case). I think the https://druid.apache.org/docs/latest/ingestion/faq.html might be a better place for this.", "url": "https://github.com/apache/druid/pull/9965#discussion_r440538226", "createdAt": "2020-06-16T01:41:57Z", "author": {"login": "maytasm"}, "path": "docs/operations/api-reference.md", "diffHunk": "@@ -114,6 +114,44 @@ Returns the number of segments to load and drop, as well as the total segment lo\n \n Returns the serialized JSON of segments to load and drop for each Historical process.\n \n+\n+#### Segment Loading by Datasource\n+\n+You can verify if segments created by a recent ingestion task are loaded onto historicals and available for querying using the following APIs.\n+An example workflow for this is:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDQ5NzUyMQ=="}, "originalCommit": {"oid": "2470e8fa81e483839e8903a6f982c6108c230c8a"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc0NDQ0ODI2OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/druid/server/coordinator/DruidCoordinator.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNVQyMzozNTowMlrOGkGLFw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQwMTo1NTo1NVrOGkIi_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDUwMzA2Mw==", "bodyText": "I think it's ok that segmentReplicantLookup could potentially be stale since it is only updated on coordinator runs, since the refreshed segment metadata would at least ensure that the stale data would be under counting replication levels, rather than potentially falsely reporting that everything is available (when forcing refresh).", "url": "https://github.com/apache/druid/pull/9965#discussion_r440503063", "createdAt": "2020-06-15T23:35:02Z", "author": {"login": "clintropolis"}, "path": "server/src/main/java/org/apache/druid/server/coordinator/DruidCoordinator.java", "diffHunk": "@@ -256,15 +256,24 @@ public boolean isLeader()\n    * @return tier -> { dataSource -> underReplicationCount } map\n    */\n   public Map<String, Object2LongMap<String>> computeUnderReplicationCountsPerDataSourcePerTier()\n+  {\n+    final Iterable<DataSegment> dataSegments = segmentsMetadataManager.iterateAllUsedSegments();\n+    return computeUnderReplicationCountsPerDataSourcePerTierForSegments(dataSegments);\n+  }\n+\n+  /**\n+   * @return tier -> { dataSource -> underReplicationCount } map\n+   */\n+  public Map<String, Object2LongMap<String>> computeUnderReplicationCountsPerDataSourcePerTierForSegments(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2470e8fa81e483839e8903a6f982c6108c230c8a"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDU0MTk0OQ==", "bodyText": "Keeping the segmentReplicantLookup as possibly stale for now. This still ensures that we will never return true (available) when it\u2019s false (not available) since we force refresh metadata. Although we can return false (not available) when it\u2019s true (available) for up to a period of coordinator run longer for the full format response. This problem will only affects the full format. We can loop back to this if we find that having the option to force refresh the  segmentReplicantLookup is useful. If that is the case then we can use the existing query param, forceMetadataRefresh, to force refresh segmentReplicantLookup too.", "url": "https://github.com/apache/druid/pull/9965#discussion_r440541949", "createdAt": "2020-06-16T01:55:55Z", "author": {"login": "maytasm"}, "path": "server/src/main/java/org/apache/druid/server/coordinator/DruidCoordinator.java", "diffHunk": "@@ -256,15 +256,24 @@ public boolean isLeader()\n    * @return tier -> { dataSource -> underReplicationCount } map\n    */\n   public Map<String, Object2LongMap<String>> computeUnderReplicationCountsPerDataSourcePerTier()\n+  {\n+    final Iterable<DataSegment> dataSegments = segmentsMetadataManager.iterateAllUsedSegments();\n+    return computeUnderReplicationCountsPerDataSourcePerTierForSegments(dataSegments);\n+  }\n+\n+  /**\n+   * @return tier -> { dataSource -> underReplicationCount } map\n+   */\n+  public Map<String, Object2LongMap<String>> computeUnderReplicationCountsPerDataSourcePerTierForSegments(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDUwMzA2Mw=="}, "originalCommit": {"oid": "2470e8fa81e483839e8903a6f982c6108c230c8a"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc0ODE1MDI2OnYy", "diffSide": "RIGHT", "path": "docs/ingestion/faq.md", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQxOTo0NTozOVrOGkqoEw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QwMTowOTowMFrOGkyMrw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTEwMDMwNw==", "bodyText": "I think this applies to only batch ingestion. In streaming ingestion, each row becomes queryable once it's consumed by a realtime task.", "url": "https://github.com/apache/druid/pull/9965#discussion_r441100307", "createdAt": "2020-06-16T19:45:39Z", "author": {"login": "jihoonson"}, "path": "docs/ingestion/faq.md", "diffHunk": "@@ -66,6 +66,18 @@ Other common reasons that hand-off fails are as follows:\n \n Make sure to include the `druid-hdfs-storage` and all the hadoop configuration, dependencies (that can be obtained by running command `hadoop classpath` on a machine where hadoop has been setup) in the classpath. And, provide necessary HDFS settings as described in [deep storage](../dependencies/deep-storage.md) .\n \n+## How do I know when I can make query to Druid after submitting ingestion task?", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "afac4fd572a0b1fa4fd0439c98d61c3f19524f7f"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTIyNDM2Nw==", "bodyText": "Yes. Updated.", "url": "https://github.com/apache/druid/pull/9965#discussion_r441224367", "createdAt": "2020-06-17T01:09:00Z", "author": {"login": "maytasm"}, "path": "docs/ingestion/faq.md", "diffHunk": "@@ -66,6 +66,18 @@ Other common reasons that hand-off fails are as follows:\n \n Make sure to include the `druid-hdfs-storage` and all the hadoop configuration, dependencies (that can be obtained by running command `hadoop classpath` on a machine where hadoop has been setup) in the classpath. And, provide necessary HDFS settings as described in [deep storage](../dependencies/deep-storage.md) .\n \n+## How do I know when I can make query to Druid after submitting ingestion task?", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTEwMDMwNw=="}, "originalCommit": {"oid": "afac4fd572a0b1fa4fd0439c98d61c3f19524f7f"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc0ODMwNzY4OnYy", "diffSide": "RIGHT", "path": "docs/ingestion/faq.md", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQyMDozNDo1MVrOGksLXg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QwMToxNjoyNVrOGkyT-Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTEyNTcyNg==", "bodyText": "I think it would be nice to warn one more time here what will happen with forceMetadataRefresh=true. It could also be mentioned that this API will refresh not only the specified datasource, but all datasources.", "url": "https://github.com/apache/druid/pull/9965#discussion_r441125726", "createdAt": "2020-06-16T20:34:51Z", "author": {"login": "jihoonson"}, "path": "docs/ingestion/faq.md", "diffHunk": "@@ -66,6 +66,18 @@ Other common reasons that hand-off fails are as follows:\n \n Make sure to include the `druid-hdfs-storage` and all the hadoop configuration, dependencies (that can be obtained by running command `hadoop classpath` on a machine where hadoop has been setup) in the classpath. And, provide necessary HDFS settings as described in [deep storage](../dependencies/deep-storage.md) .\n \n+## How do I know when I can make query to Druid after submitting ingestion task?\n+\n+You can verify if segments created by a recent ingestion task are loaded onto historicals and available for querying using the following workflow.\n+1. Submit your ingestion task.\n+2. Repeatedly poll the [Overlord's tasks API](../operations/api-reference.md#tasks) ( `/druid/indexer/v1/task/{taskId}/status`) until your task is shown to be successfully completed.\n+3. Poll the [Segment Loading by Datasource API](../operations/api-reference.md#segment-loading-by-datasource) (`/druid/coordinator/v1/datasources/{dataSourceName}/loadstatus`) with \n+`forceMetadataRefresh=true` and `interval=<INTERVAL_OF_INGESTED_DATA>` once.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "afac4fd572a0b1fa4fd0439c98d61c3f19524f7f"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTIyNjIzMw==", "bodyText": "Done", "url": "https://github.com/apache/druid/pull/9965#discussion_r441226233", "createdAt": "2020-06-17T01:16:25Z", "author": {"login": "maytasm"}, "path": "docs/ingestion/faq.md", "diffHunk": "@@ -66,6 +66,18 @@ Other common reasons that hand-off fails are as follows:\n \n Make sure to include the `druid-hdfs-storage` and all the hadoop configuration, dependencies (that can be obtained by running command `hadoop classpath` on a machine where hadoop has been setup) in the classpath. And, provide necessary HDFS settings as described in [deep storage](../dependencies/deep-storage.md) .\n \n+## How do I know when I can make query to Druid after submitting ingestion task?\n+\n+You can verify if segments created by a recent ingestion task are loaded onto historicals and available for querying using the following workflow.\n+1. Submit your ingestion task.\n+2. Repeatedly poll the [Overlord's tasks API](../operations/api-reference.md#tasks) ( `/druid/indexer/v1/task/{taskId}/status`) until your task is shown to be successfully completed.\n+3. Poll the [Segment Loading by Datasource API](../operations/api-reference.md#segment-loading-by-datasource) (`/druid/coordinator/v1/datasources/{dataSourceName}/loadstatus`) with \n+`forceMetadataRefresh=true` and `interval=<INTERVAL_OF_INGESTED_DATA>` once.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTEyNTcyNg=="}, "originalCommit": {"oid": "afac4fd572a0b1fa4fd0439c98d61c3f19524f7f"}, "originalPosition": 10}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc0ODM1MDIxOnYy", "diffSide": "RIGHT", "path": "docs/operations/api-reference.md", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQyMDo0NzozMVrOGkslYg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QwMToxODozNFrOGkyV8A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTEzMjM4Ng==", "bodyText": "It would be nice to mention that it will refresh all datasources here too.", "url": "https://github.com/apache/druid/pull/9965#discussion_r441132386", "createdAt": "2020-06-16T20:47:31Z", "author": {"login": "jihoonson"}, "path": "docs/operations/api-reference.md", "diffHunk": "@@ -114,6 +114,35 @@ Returns the number of segments to load and drop, as well as the total segment lo\n \n Returns the serialized JSON of segments to load and drop for each Historical process.\n \n+\n+#### Segment Loading by Datasource\n+\n+##### GET\n+\n+* `/druid/coordinator/v1/datasources/{dataSourceName}/loadstatus?forceMetadataRefresh={boolean}&interval={myInterval}`\n+\n+Returns the percentage of segments actually loaded in the cluster versus segments that should be loaded in the cluster for the given \n+datasource over the given interval (or last 2 weeks if interval is not given). `forceMetadataRefresh` is required to be set. \n+Setting `forceMetadataRefresh` to true will force the coordinator to poll latest segment metadata from the metadata store. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "afac4fd572a0b1fa4fd0439c98d61c3f19524f7f"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTEzMjYxNg==", "bodyText": "Same for other APIs.", "url": "https://github.com/apache/druid/pull/9965#discussion_r441132616", "createdAt": "2020-06-16T20:47:59Z", "author": {"login": "jihoonson"}, "path": "docs/operations/api-reference.md", "diffHunk": "@@ -114,6 +114,35 @@ Returns the number of segments to load and drop, as well as the total segment lo\n \n Returns the serialized JSON of segments to load and drop for each Historical process.\n \n+\n+#### Segment Loading by Datasource\n+\n+##### GET\n+\n+* `/druid/coordinator/v1/datasources/{dataSourceName}/loadstatus?forceMetadataRefresh={boolean}&interval={myInterval}`\n+\n+Returns the percentage of segments actually loaded in the cluster versus segments that should be loaded in the cluster for the given \n+datasource over the given interval (or last 2 weeks if interval is not given). `forceMetadataRefresh` is required to be set. \n+Setting `forceMetadataRefresh` to true will force the coordinator to poll latest segment metadata from the metadata store. ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTEzMjM4Ng=="}, "originalCommit": {"oid": "afac4fd572a0b1fa4fd0439c98d61c3f19524f7f"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTIyNjczNg==", "bodyText": "Done", "url": "https://github.com/apache/druid/pull/9965#discussion_r441226736", "createdAt": "2020-06-17T01:18:34Z", "author": {"login": "maytasm"}, "path": "docs/operations/api-reference.md", "diffHunk": "@@ -114,6 +114,35 @@ Returns the number of segments to load and drop, as well as the total segment lo\n \n Returns the serialized JSON of segments to load and drop for each Historical process.\n \n+\n+#### Segment Loading by Datasource\n+\n+##### GET\n+\n+* `/druid/coordinator/v1/datasources/{dataSourceName}/loadstatus?forceMetadataRefresh={boolean}&interval={myInterval}`\n+\n+Returns the percentage of segments actually loaded in the cluster versus segments that should be loaded in the cluster for the given \n+datasource over the given interval (or last 2 weeks if interval is not given). `forceMetadataRefresh` is required to be set. \n+Setting `forceMetadataRefresh` to true will force the coordinator to poll latest segment metadata from the metadata store. ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTEzMjM4Ng=="}, "originalCommit": {"oid": "afac4fd572a0b1fa4fd0439c98d61c3f19524f7f"}, "originalPosition": 27}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc0ODQyOTc3OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/druid/metadata/SqlSegmentsMetadataManager.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQyMToxMjo0M1rOGktXmQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QwMToxODo1NVrOGkyWOw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTE0NTI0MQ==", "bodyText": "typo: alrady -> already", "url": "https://github.com/apache/druid/pull/9965#discussion_r441145241", "createdAt": "2020-06-16T21:12:43Z", "author": {"login": "jihoonson"}, "path": "server/src/main/java/org/apache/druid/metadata/SqlSegmentsMetadataManager.java", "diffHunk": "@@ -403,11 +427,17 @@ private void awaitOrPerformDatabasePoll()\n   }\n \n   /**\n-   * If the latest {@link DatabasePoll} is a {@link PeriodicDatabasePoll}, or an {@link OnDemandDatabasePoll} that is\n-   * made not longer than {@link #periodicPollDelay} from now, awaits for it and returns true; returns false otherwise,\n-   * meaning that a new on-demand database poll should be initiated.\n+   * This method returns true without waiting for database poll if the latest {@link DatabasePoll} is a\n+   * {@link PeriodicDatabasePoll} that has completed it's first poll, or an {@link OnDemandDatabasePoll} that is\n+   * made not longer than {@link #periodicPollDelay} from current time.\n+   * This method does wait untill completion for if the latest {@link DatabasePoll} is a\n+   * {@link PeriodicDatabasePoll} that has not completed it's first poll, or an {@link OnDemandDatabasePoll} that is\n+   * alrady in the process of polling the database.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "afac4fd572a0b1fa4fd0439c98d61c3f19524f7f"}, "originalPosition": 156}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTIyNjgxMQ==", "bodyText": "Done", "url": "https://github.com/apache/druid/pull/9965#discussion_r441226811", "createdAt": "2020-06-17T01:18:55Z", "author": {"login": "maytasm"}, "path": "server/src/main/java/org/apache/druid/metadata/SqlSegmentsMetadataManager.java", "diffHunk": "@@ -403,11 +427,17 @@ private void awaitOrPerformDatabasePoll()\n   }\n \n   /**\n-   * If the latest {@link DatabasePoll} is a {@link PeriodicDatabasePoll}, or an {@link OnDemandDatabasePoll} that is\n-   * made not longer than {@link #periodicPollDelay} from now, awaits for it and returns true; returns false otherwise,\n-   * meaning that a new on-demand database poll should be initiated.\n+   * This method returns true without waiting for database poll if the latest {@link DatabasePoll} is a\n+   * {@link PeriodicDatabasePoll} that has completed it's first poll, or an {@link OnDemandDatabasePoll} that is\n+   * made not longer than {@link #periodicPollDelay} from current time.\n+   * This method does wait untill completion for if the latest {@link DatabasePoll} is a\n+   * {@link PeriodicDatabasePoll} that has not completed it's first poll, or an {@link OnDemandDatabasePoll} that is\n+   * alrady in the process of polling the database.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTE0NTI0MQ=="}, "originalCommit": {"oid": "afac4fd572a0b1fa4fd0439c98d61c3f19524f7f"}, "originalPosition": 156}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc0ODUwODM0OnYy", "diffSide": "RIGHT", "path": "server/src/main/java/org/apache/druid/server/http/DataSourcesResource.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQyMTo0MDoxOVrOGkuJXw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xN1QwMToyMDowNVrOGkyXSg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTE1Nzk4Mw==", "bodyText": "Could be defined as a static final.", "url": "https://github.com/apache/druid/pull/9965#discussion_r441157983", "createdAt": "2020-06-16T21:40:19Z", "author": {"login": "jihoonson"}, "path": "server/src/main/java/org/apache/druid/server/http/DataSourcesResource.java", "diffHunk": "@@ -391,6 +397,131 @@ public Response getServedSegmentsInInterval(\n     return getServedSegmentsInInterval(dataSourceName, full != null, theInterval::contains);\n   }\n \n+  @GET\n+  @Path(\"/{dataSourceName}/loadstatus\")\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @ResourceFilters(DatasourceResourceFilter.class)\n+  public Response getDatasourceLoadstatus(\n+      @PathParam(\"dataSourceName\") String dataSourceName,\n+      @QueryParam(\"forceMetadataRefresh\") final Boolean forceMetadataRefresh,\n+      @QueryParam(\"interval\") @Nullable final String interval,\n+      @QueryParam(\"simple\") @Nullable final String simple,\n+      @QueryParam(\"full\") @Nullable final String full\n+  )\n+  {\n+    if (forceMetadataRefresh == null) {\n+      return Response\n+          .status(Response.Status.BAD_REQUEST)\n+          .entity(\"Invalid request. forceMetadataRefresh must be specified\")\n+          .build();\n+    }\n+    final Interval theInterval;\n+    if (interval == null) {\n+      long defaultIntervalOffset = 14 * 24 * 60 * 60 * 1000;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "afac4fd572a0b1fa4fd0439c98d61c3f19524f7f"}, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTIyNzA4Mg==", "bodyText": "Done", "url": "https://github.com/apache/druid/pull/9965#discussion_r441227082", "createdAt": "2020-06-17T01:20:05Z", "author": {"login": "maytasm"}, "path": "server/src/main/java/org/apache/druid/server/http/DataSourcesResource.java", "diffHunk": "@@ -391,6 +397,131 @@ public Response getServedSegmentsInInterval(\n     return getServedSegmentsInInterval(dataSourceName, full != null, theInterval::contains);\n   }\n \n+  @GET\n+  @Path(\"/{dataSourceName}/loadstatus\")\n+  @Produces(MediaType.APPLICATION_JSON)\n+  @ResourceFilters(DatasourceResourceFilter.class)\n+  public Response getDatasourceLoadstatus(\n+      @PathParam(\"dataSourceName\") String dataSourceName,\n+      @QueryParam(\"forceMetadataRefresh\") final Boolean forceMetadataRefresh,\n+      @QueryParam(\"interval\") @Nullable final String interval,\n+      @QueryParam(\"simple\") @Nullable final String simple,\n+      @QueryParam(\"full\") @Nullable final String full\n+  )\n+  {\n+    if (forceMetadataRefresh == null) {\n+      return Response\n+          .status(Response.Status.BAD_REQUEST)\n+          .entity(\"Invalid request. forceMetadataRefresh must be specified\")\n+          .build();\n+    }\n+    final Interval theInterval;\n+    if (interval == null) {\n+      long defaultIntervalOffset = 14 * 24 * 60 * 60 * 1000;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MTE1Nzk4Mw=="}, "originalCommit": {"oid": "afac4fd572a0b1fa4fd0439c98d61c3f19524f7f"}, "originalPosition": 72}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2287, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}