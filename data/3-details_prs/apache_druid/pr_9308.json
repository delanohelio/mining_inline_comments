{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzcwNjA5NTQw", "number": 9308, "title": "Add MemoryOpenHashTable, a table similar to ByteBufferHashTable.", "bodyText": "With some key differences to improve speed and design simplicity:\n\nUses Memory rather than ByteBuffer for its backing storage.\nUses faster hashing and comparison routines (see HashTableUtils).\nCapacity is always a power of two, allowing simpler design and more\nefficient implementation of findBucket.\nDoes not implement growability; instead, leaves that to its callers.\nThe idea is this removes the need for subclasses, while still giving\ncallers flexibility in how to handle table-full scenarios.\n\nThe combination of these techniques above can boost performance of\nper-segment groupBy processing on realistic queries by 30%+ (in some\ncases I tested, it was even more extreme: 2\u20134x when grouping by single\nlong dimensions).\nThe idea is that in time, users of ByteBufferHashTable will be migrated\nto this implementation.", "createdAt": "2020-02-04T02:01:22Z", "url": "https://github.com/apache/druid/pull/9308", "merged": true, "mergeCommit": {"oid": "3ef5c2f2e87d07c48eccdcafd8c08ce9bf657162"}, "closed": true, "closedAt": "2020-02-05T03:58:00Z", "author": {"login": "gianm"}, "timelineItems": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcA7VA3AH2gAyMzcwNjA5NTQwOjYzZDEzZDI5NGQxOGU2ZGE0YjUzZmY2M2U1MjJmZTFkZTg5ZjYzYmM=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcBL-kLAH2gAyMzcwNjA5NTQwOmU5ZmZlNjI1NTMxZDNhZjlkMjJmMjVhMzM2ZmY5OTM1YWNiNWRmMzQ=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "63d13d294d18e6da4b53ff63e522fe1de89f63bc", "author": {"user": {"login": "gianm", "name": "Gian Merlino"}}, "url": "https://github.com/apache/druid/commit/63d13d294d18e6da4b53ff63e522fe1de89f63bc", "committedDate": "2020-02-04T06:13:26Z", "message": "Add MemoryOpenHashTable, a table similar to ByteBufferHashTable.\n\nWith some key differences to improve speed and design simplicity:\n\n1) Uses Memory rather than ByteBuffer for its backing storage.\n2) Uses faster hashing and comparison routines (see HashTableUtils).\n3) Capacity is always a power of two, allowing simpler design and more\n   efficient implementation of findBucket.\n4) Does not implement growability; instead, leaves that to its callers.\n   The idea is this removes the need for subclasses, while still giving\n   callers flexibility in how to handle table-full scenarios."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": null, "afterCommit": {"oid": "63d13d294d18e6da4b53ff63e522fe1de89f63bc", "author": {"user": {"login": "gianm", "name": "Gian Merlino"}}, "url": "https://github.com/apache/druid/commit/63d13d294d18e6da4b53ff63e522fe1de89f63bc", "committedDate": "2020-02-04T06:13:26Z", "message": "Add MemoryOpenHashTable, a table similar to ByteBufferHashTable.\n\nWith some key differences to improve speed and design simplicity:\n\n1) Uses Memory rather than ByteBuffer for its backing storage.\n2) Uses faster hashing and comparison routines (see HashTableUtils).\n3) Capacity is always a power of two, allowing simpler design and more\n   efficient implementation of findBucket.\n4) Does not implement growability; instead, leaves that to its callers.\n   The idea is this removes the need for subclasses, while still giving\n   callers flexibility in how to handle table-full scenarios."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f1e5047eec64e49347fb6530fd95587b1e0b84bb", "author": {"user": {"login": "gianm", "name": "Gian Merlino"}}, "url": "https://github.com/apache/druid/commit/f1e5047eec64e49347fb6530fd95587b1e0b84bb", "committedDate": "2020-02-04T17:29:04Z", "message": "Fix LGTM warnings."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9a5cc44ac85d2a99570fb62ad3d19c85783e7a6e", "author": {"user": {"login": "gianm", "name": "Gian Merlino"}}, "url": "https://github.com/apache/druid/commit/9a5cc44ac85d2a99570fb62ad3d19c85783e7a6e", "committedDate": "2020-02-04T20:15:13Z", "message": "Adjust dependencies."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2df5b6513b315061022a82427871a04b38e27628", "author": {"user": {"login": "gianm", "name": "Gian Merlino"}}, "url": "https://github.com/apache/druid/commit/2df5b6513b315061022a82427871a04b38e27628", "committedDate": "2020-02-04T21:30:39Z", "message": "Remove easymock from druid-benchmarks."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bdad6e919c6a7ad73ab30e81780ee1c23013ee5a", "author": {"user": {"login": "gianm", "name": "Gian Merlino"}}, "url": "https://github.com/apache/druid/commit/bdad6e919c6a7ad73ab30e81780ee1c23013ee5a", "committedDate": "2020-02-04T21:36:54Z", "message": "Merge branch 'master' into groupby-moht"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUzMjYxMzY5", "url": "https://github.com/apache/druid/pull/9308#pullrequestreview-353261369", "createdAt": "2020-02-04T19:59:41Z", "commit": {"oid": "f1e5047eec64e49347fb6530fd95587b1e0b84bb"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQxOTo1OTo0MlrOFlhkaA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQyMjoxNjoyMVrOFllZDA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDg5MTYyNA==", "bodyText": "randomy -> randomly?", "url": "https://github.com/apache/druid/pull/9308#discussion_r374891624", "createdAt": "2020-02-04T19:59:42Z", "author": {"login": "jihoonson"}, "path": "benchmarks/src/main/java/org/apache/druid/benchmark/MemoryBenchmark.java", "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.benchmark;\n+\n+import org.apache.datasketches.memory.WritableMemory;\n+import org.apache.druid.common.config.NullHandling;\n+import org.apache.druid.query.groupby.epinephelinae.collection.HashTableUtils;\n+import org.openjdk.jmh.annotations.Benchmark;\n+import org.openjdk.jmh.annotations.BenchmarkMode;\n+import org.openjdk.jmh.annotations.Fork;\n+import org.openjdk.jmh.annotations.Measurement;\n+import org.openjdk.jmh.annotations.Mode;\n+import org.openjdk.jmh.annotations.OutputTimeUnit;\n+import org.openjdk.jmh.annotations.Param;\n+import org.openjdk.jmh.annotations.Scope;\n+import org.openjdk.jmh.annotations.Setup;\n+import org.openjdk.jmh.annotations.State;\n+import org.openjdk.jmh.annotations.Warmup;\n+import org.openjdk.jmh.infra.Blackhole;\n+\n+import java.nio.ByteBuffer;\n+import java.nio.ByteOrder;\n+import java.util.Random;\n+import java.util.concurrent.TimeUnit;\n+\n+@State(Scope.Benchmark)\n+@Fork(value = 1)\n+@Warmup(iterations = 10)\n+@Measurement(iterations = 15)\n+public class MemoryBenchmark\n+{\n+  static {\n+    NullHandling.initializeForTests();\n+  }\n+\n+  @Param({\"4\", \"5\", \"8\", \"9\", \"12\", \"16\", \"31\", \"32\", \"64\", \"128\"})\n+  public int numBytes;\n+\n+  @Param({\"offheap\"})\n+  public String where;\n+\n+  private ByteBuffer buffer1;\n+  private ByteBuffer buffer2;\n+  private ByteBuffer buffer3;\n+  private WritableMemory memory1;\n+  private WritableMemory memory2;\n+  private WritableMemory memory3;\n+\n+  @Setup\n+  public void setUp()\n+  {\n+    if (\"onheap\".equals(where)) {\n+      buffer1 = ByteBuffer.allocate(numBytes).order(ByteOrder.nativeOrder());\n+      buffer2 = ByteBuffer.allocate(numBytes).order(ByteOrder.nativeOrder());\n+      buffer3 = ByteBuffer.allocate(numBytes).order(ByteOrder.nativeOrder());\n+    } else if (\"offheap\".equals(where)) {\n+      buffer1 = ByteBuffer.allocateDirect(numBytes).order(ByteOrder.nativeOrder());\n+      buffer2 = ByteBuffer.allocateDirect(numBytes).order(ByteOrder.nativeOrder());\n+      buffer3 = ByteBuffer.allocateDirect(numBytes).order(ByteOrder.nativeOrder());\n+    }\n+\n+    memory1 = WritableMemory.wrap(buffer1, ByteOrder.nativeOrder());\n+    memory2 = WritableMemory.wrap(buffer2, ByteOrder.nativeOrder());\n+    memory3 = WritableMemory.wrap(buffer3, ByteOrder.nativeOrder());\n+\n+    // Scribble in some randomy but consistent (same seed) garbage.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1e5047eec64e49347fb6530fd95587b1e0b84bb"}, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDg5NjM0MA==", "bodyText": "Seems like + 31 isn't necessary.", "url": "https://github.com/apache/druid/pull/9308#discussion_r374896340", "createdAt": "2020-02-04T20:09:56Z", "author": {"login": "jihoonson"}, "path": "processing/src/main/java/org/apache/druid/query/groupby/epinephelinae/collection/HashTableUtils.java", "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.query.groupby.epinephelinae.collection;\n+\n+import org.apache.datasketches.memory.Memory;\n+\n+public class HashTableUtils\n+{\n+  private HashTableUtils()\n+  {\n+    // No instantiation.\n+  }\n+\n+  /**\n+   * Computes the previous power of two less than or equal to a given \"n\".\n+   *\n+   * The integer should be between 1 (inclusive) and {@link Integer#MAX_VALUE} for best results. Other parameters will\n+   * return {@link Integer#MIN_VALUE}.\n+   */\n+  public static int previousPowerOfTwo(final int n)\n+  {\n+    if (n > 0) {\n+      return Integer.highestOneBit(n);\n+    } else {\n+      return Integer.MIN_VALUE;\n+    }\n+  }\n+\n+  /**\n+   * Compute a simple, fast hash code of some memory range.\n+   *\n+   * @param memory   a region of memory\n+   * @param position position within the memory region\n+   * @param length   length of memory to hash, starting at the position\n+   */\n+  public static int hashMemory(final Memory memory, final long position, final int length)\n+  {\n+    // Special cases for small, common key sizes to speed them up: e.g. one int key, two int keys, one long key, etc.\n+    // The plus-one sizes (9, 13) are for nullable dimensions. The specific choices of special cases were chosen based\n+    // on benchmarking (see MemoryBenchmark) on a Skylake-based cloud instance.\n+\n+    switch (length) {\n+      case 4:\n+        return 31 + memory.getInt(position);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f1e5047eec64e49347fb6530fd95587b1e0b84bb"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDkzNjU3NQ==", "bodyText": "HashVectorGrouper -> BufferHashGrouper?", "url": "https://github.com/apache/druid/pull/9308#discussion_r374936575", "createdAt": "2020-02-04T21:36:38Z", "author": {"login": "jihoonson"}, "path": "processing/src/main/java/org/apache/druid/query/groupby/epinephelinae/collection/MemoryOpenHashTable.java", "diffHunk": "@@ -0,0 +1,433 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.query.groupby.epinephelinae.collection;\n+\n+import it.unimi.dsi.fastutil.ints.IntIterator;\n+import org.apache.datasketches.memory.Memory;\n+import org.apache.datasketches.memory.WritableMemory;\n+import org.apache.druid.java.util.common.ISE;\n+import org.apache.druid.query.groupby.epinephelinae.Groupers;\n+\n+import javax.annotation.Nullable;\n+import java.nio.ByteBuffer;\n+import java.nio.ByteOrder;\n+import java.util.NoSuchElementException;\n+\n+/**\n+ * An open-addressed hash table with linear probing backed by {@link WritableMemory}. Does not offer a similar\n+ * interface to {@link java.util.Map} because this is meant to be useful to lower-level, high-performance callers.\n+ * There is no copying or serde of keys and values: callers access the backing memory of the table directly.\n+ *\n+ * This table will not grow itself. Callers must handle growing if required; the {@link #copyTo} method is provided\n+ * to assist.\n+ */\n+public class MemoryOpenHashTable\n+{\n+  private static final byte USED_BYTE = 1;\n+  private static final int USED_BYTE_SIZE = Byte.BYTES;\n+\n+  private final WritableMemory tableMemory;\n+  private final int keySize;\n+  private final int valueSize;\n+  private final int bucketSize;\n+\n+  // Maximum number of elements in the table (based on numBuckets and maxLoadFactor).\n+  private final int maxSize;\n+\n+  // Number of available/used buckets in the table. Always a power of two.\n+  private final int numBuckets;\n+\n+  // Mask that clips a number to [0, numBuckets). Used when searching through buckets.\n+  private final int bucketMask;\n+\n+  // Number of elements in the table right now.\n+  private int size;\n+\n+  /**\n+   * Create a new table.\n+   *\n+   * @param tableMemory backing memory for the table; must be exactly large enough to hold \"numBuckets\"\n+   * @param numBuckets  number of buckets for the table\n+   * @param maxSize     maximum number of elements for the table; must be less than numBuckets\n+   * @param keySize     key size in bytes\n+   * @param valueSize   value size in bytes\n+   */\n+  public MemoryOpenHashTable(\n+      final WritableMemory tableMemory,\n+      final int numBuckets,\n+      final int maxSize,\n+      final int keySize,\n+      final int valueSize\n+  )\n+  {\n+    this.tableMemory = tableMemory;\n+    this.numBuckets = numBuckets;\n+    this.bucketMask = numBuckets - 1;\n+    this.maxSize = maxSize;\n+    this.keySize = keySize;\n+    this.valueSize = valueSize;\n+    this.bucketSize = bucketSize(keySize, valueSize);\n+\n+    // Our main user today (HashVectorGrouper) needs the tableMemory to be backed by a big-endian ByteBuffer that is", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2df5b6513b315061022a82427871a04b38e27628"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDk0Nzc3Mg==", "bodyText": "I guess the last byte is the flag indicating whether the key is null or not. If the key is null, should its hash value be same no matter what the remaining 8 bytes are?", "url": "https://github.com/apache/druid/pull/9308#discussion_r374947772", "createdAt": "2020-02-04T22:01:05Z", "author": {"login": "jihoonson"}, "path": "processing/src/main/java/org/apache/druid/query/groupby/epinephelinae/collection/HashTableUtils.java", "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.query.groupby.epinephelinae.collection;\n+\n+import org.apache.datasketches.memory.Memory;\n+\n+public class HashTableUtils\n+{\n+  private HashTableUtils()\n+  {\n+    // No instantiation.\n+  }\n+\n+  /**\n+   * Computes the previous power of two less than or equal to a given \"n\".\n+   *\n+   * The integer should be between 1 (inclusive) and {@link Integer#MAX_VALUE} for best results. Other parameters will\n+   * return {@link Integer#MIN_VALUE}.\n+   */\n+  public static int previousPowerOfTwo(final int n)\n+  {\n+    if (n > 0) {\n+      return Integer.highestOneBit(n);\n+    } else {\n+      return Integer.MIN_VALUE;\n+    }\n+  }\n+\n+  /**\n+   * Compute a simple, fast hash code of some memory range.\n+   *\n+   * @param memory   a region of memory\n+   * @param position position within the memory region\n+   * @param length   length of memory to hash, starting at the position\n+   */\n+  public static int hashMemory(final Memory memory, final long position, final int length)\n+  {\n+    // Special cases for small, common key sizes to speed them up: e.g. one int key, two int keys, one long key, etc.\n+    // The plus-one sizes (9, 13) are for nullable dimensions. The specific choices of special cases were chosen based\n+    // on benchmarking (see MemoryBenchmark) on a Skylake-based cloud instance.\n+\n+    switch (length) {\n+      case 4:\n+        return 31 + memory.getInt(position);\n+\n+      case 8:\n+        return 31 * (31 + memory.getInt(position)) + memory.getInt(position + Integer.BYTES);\n+\n+      case 9:\n+        return 31 * (31 * (31 + memory.getInt(position)) + memory.getInt(position + Integer.BYTES))\n+               + memory.getByte(position + 2 * Integer.BYTES);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bdad6e919c6a7ad73ab30e81780ee1c23013ee5a"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDk1MTY1OQ==", "bodyText": "When the key is nullable, I'm wondering whether we can share the last byte as both the null flag and the used bucket flag to save memory space. For example, the used bucket flag and the null flag can be stored in the upper 4 bits and the lower 4 bits, respectively. This way will need an extra branch (or some bit shifts) to extract the key properly from the bucket, but I guess it would be ok?", "url": "https://github.com/apache/druid/pull/9308#discussion_r374951659", "createdAt": "2020-02-04T22:10:09Z", "author": {"login": "jihoonson"}, "path": "processing/src/main/java/org/apache/druid/query/groupby/epinephelinae/collection/MemoryOpenHashTable.java", "diffHunk": "@@ -0,0 +1,433 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.query.groupby.epinephelinae.collection;\n+\n+import it.unimi.dsi.fastutil.ints.IntIterator;\n+import org.apache.datasketches.memory.Memory;\n+import org.apache.datasketches.memory.WritableMemory;\n+import org.apache.druid.java.util.common.ISE;\n+import org.apache.druid.query.groupby.epinephelinae.Groupers;\n+\n+import javax.annotation.Nullable;\n+import java.nio.ByteBuffer;\n+import java.nio.ByteOrder;\n+import java.util.NoSuchElementException;\n+\n+/**\n+ * An open-addressed hash table with linear probing backed by {@link WritableMemory}. Does not offer a similar\n+ * interface to {@link java.util.Map} because this is meant to be useful to lower-level, high-performance callers.\n+ * There is no copying or serde of keys and values: callers access the backing memory of the table directly.\n+ *\n+ * This table will not grow itself. Callers must handle growing if required; the {@link #copyTo} method is provided\n+ * to assist.\n+ */\n+public class MemoryOpenHashTable\n+{\n+  private static final byte USED_BYTE = 1;\n+  private static final int USED_BYTE_SIZE = Byte.BYTES;\n+\n+  private final WritableMemory tableMemory;\n+  private final int keySize;\n+  private final int valueSize;\n+  private final int bucketSize;\n+\n+  // Maximum number of elements in the table (based on numBuckets and maxLoadFactor).\n+  private final int maxSize;\n+\n+  // Number of available/used buckets in the table. Always a power of two.\n+  private final int numBuckets;\n+\n+  // Mask that clips a number to [0, numBuckets). Used when searching through buckets.\n+  private final int bucketMask;\n+\n+  // Number of elements in the table right now.\n+  private int size;\n+\n+  /**\n+   * Create a new table.\n+   *\n+   * @param tableMemory backing memory for the table; must be exactly large enough to hold \"numBuckets\"\n+   * @param numBuckets  number of buckets for the table\n+   * @param maxSize     maximum number of elements for the table; must be less than numBuckets\n+   * @param keySize     key size in bytes\n+   * @param valueSize   value size in bytes\n+   */\n+  public MemoryOpenHashTable(\n+      final WritableMemory tableMemory,\n+      final int numBuckets,\n+      final int maxSize,\n+      final int keySize,\n+      final int valueSize\n+  )\n+  {\n+    this.tableMemory = tableMemory;\n+    this.numBuckets = numBuckets;\n+    this.bucketMask = numBuckets - 1;\n+    this.maxSize = maxSize;\n+    this.keySize = keySize;\n+    this.valueSize = valueSize;\n+    this.bucketSize = bucketSize(keySize, valueSize);\n+\n+    // Our main user today (HashVectorGrouper) needs the tableMemory to be backed by a big-endian ByteBuffer that is\n+    // coterminous with the tableMemory, since it's going to feed that buffer into VectorAggregators instead of\n+    // interacting with our WritableMemory directly. Nothing about this class actually requires that the Memory be\n+    // backed by a ByteBuffer, but we'll check it here anyway for the benefit of our biggest customer.\n+    verifyMemoryIsByteBuffer(tableMemory);\n+\n+    if (!tableMemory.getTypeByteOrder().equals(ByteOrder.nativeOrder())) {\n+      throw new ISE(\"tableMemory must be native byte order\");\n+    }\n+\n+    if (tableMemory.getCapacity() != memoryNeeded(numBuckets, bucketSize)) {\n+      throw new ISE(\n+          \"tableMemory must be size[%,d] but was[%,d]\",\n+          memoryNeeded(numBuckets, bucketSize),\n+          tableMemory.getCapacity()\n+      );\n+    }\n+\n+    if (maxSize >= numBuckets) {\n+      throw new ISE(\"maxSize must be less than numBuckets\");\n+    }\n+\n+    if (Integer.bitCount(numBuckets) != 1) {\n+      throw new ISE(\"numBuckets must be a power of two but was[%,d]\", numBuckets);\n+    }\n+\n+    clear();\n+  }\n+\n+  /**\n+   * Returns the amount of memory needed for a table.\n+   *\n+   * This is just a multiplication, which is easy enough to do on your own, but sometimes it's nice for clarity's sake\n+   * to call a function with a name that indicates why the multiplication is happening.\n+   *\n+   * @param numBuckets number of buckets\n+   * @param bucketSize size per bucket (in bytes)\n+   *\n+   * @return size of table (in bytes)\n+   */\n+  public static int memoryNeeded(final int numBuckets, final int bucketSize)\n+  {\n+    return numBuckets * bucketSize;\n+  }\n+\n+  /**\n+   * Returns the size of each bucket in a table.\n+   *\n+   * @param keySize   size of keys (in bytes)\n+   * @param valueSize size of values (in bytes)\n+   *\n+   * @return size of buckets (in bytes)\n+   */\n+  public static int bucketSize(final int keySize, final int valueSize)\n+  {\n+    return USED_BYTE_SIZE + keySize + valueSize;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bdad6e919c6a7ad73ab30e81780ee1c23013ee5a"}, "originalPosition": 143}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDk1NDI1Mg==", "bodyText": "== USED_BYTE?", "url": "https://github.com/apache/druid/pull/9308#discussion_r374954252", "createdAt": "2020-02-04T22:16:21Z", "author": {"login": "jihoonson"}, "path": "processing/src/main/java/org/apache/druid/query/groupby/epinephelinae/collection/MemoryOpenHashTable.java", "diffHunk": "@@ -0,0 +1,433 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.query.groupby.epinephelinae.collection;\n+\n+import it.unimi.dsi.fastutil.ints.IntIterator;\n+import org.apache.datasketches.memory.Memory;\n+import org.apache.datasketches.memory.WritableMemory;\n+import org.apache.druid.java.util.common.ISE;\n+import org.apache.druid.query.groupby.epinephelinae.Groupers;\n+\n+import javax.annotation.Nullable;\n+import java.nio.ByteBuffer;\n+import java.nio.ByteOrder;\n+import java.util.NoSuchElementException;\n+\n+/**\n+ * An open-addressed hash table with linear probing backed by {@link WritableMemory}. Does not offer a similar\n+ * interface to {@link java.util.Map} because this is meant to be useful to lower-level, high-performance callers.\n+ * There is no copying or serde of keys and values: callers access the backing memory of the table directly.\n+ *\n+ * This table will not grow itself. Callers must handle growing if required; the {@link #copyTo} method is provided\n+ * to assist.\n+ */\n+public class MemoryOpenHashTable\n+{\n+  private static final byte USED_BYTE = 1;\n+  private static final int USED_BYTE_SIZE = Byte.BYTES;\n+\n+  private final WritableMemory tableMemory;\n+  private final int keySize;\n+  private final int valueSize;\n+  private final int bucketSize;\n+\n+  // Maximum number of elements in the table (based on numBuckets and maxLoadFactor).\n+  private final int maxSize;\n+\n+  // Number of available/used buckets in the table. Always a power of two.\n+  private final int numBuckets;\n+\n+  // Mask that clips a number to [0, numBuckets). Used when searching through buckets.\n+  private final int bucketMask;\n+\n+  // Number of elements in the table right now.\n+  private int size;\n+\n+  /**\n+   * Create a new table.\n+   *\n+   * @param tableMemory backing memory for the table; must be exactly large enough to hold \"numBuckets\"\n+   * @param numBuckets  number of buckets for the table\n+   * @param maxSize     maximum number of elements for the table; must be less than numBuckets\n+   * @param keySize     key size in bytes\n+   * @param valueSize   value size in bytes\n+   */\n+  public MemoryOpenHashTable(\n+      final WritableMemory tableMemory,\n+      final int numBuckets,\n+      final int maxSize,\n+      final int keySize,\n+      final int valueSize\n+  )\n+  {\n+    this.tableMemory = tableMemory;\n+    this.numBuckets = numBuckets;\n+    this.bucketMask = numBuckets - 1;\n+    this.maxSize = maxSize;\n+    this.keySize = keySize;\n+    this.valueSize = valueSize;\n+    this.bucketSize = bucketSize(keySize, valueSize);\n+\n+    // Our main user today (HashVectorGrouper) needs the tableMemory to be backed by a big-endian ByteBuffer that is\n+    // coterminous with the tableMemory, since it's going to feed that buffer into VectorAggregators instead of\n+    // interacting with our WritableMemory directly. Nothing about this class actually requires that the Memory be\n+    // backed by a ByteBuffer, but we'll check it here anyway for the benefit of our biggest customer.\n+    verifyMemoryIsByteBuffer(tableMemory);\n+\n+    if (!tableMemory.getTypeByteOrder().equals(ByteOrder.nativeOrder())) {\n+      throw new ISE(\"tableMemory must be native byte order\");\n+    }\n+\n+    if (tableMemory.getCapacity() != memoryNeeded(numBuckets, bucketSize)) {\n+      throw new ISE(\n+          \"tableMemory must be size[%,d] but was[%,d]\",\n+          memoryNeeded(numBuckets, bucketSize),\n+          tableMemory.getCapacity()\n+      );\n+    }\n+\n+    if (maxSize >= numBuckets) {\n+      throw new ISE(\"maxSize must be less than numBuckets\");\n+    }\n+\n+    if (Integer.bitCount(numBuckets) != 1) {\n+      throw new ISE(\"numBuckets must be a power of two but was[%,d]\", numBuckets);\n+    }\n+\n+    clear();\n+  }\n+\n+  /**\n+   * Returns the amount of memory needed for a table.\n+   *\n+   * This is just a multiplication, which is easy enough to do on your own, but sometimes it's nice for clarity's sake\n+   * to call a function with a name that indicates why the multiplication is happening.\n+   *\n+   * @param numBuckets number of buckets\n+   * @param bucketSize size per bucket (in bytes)\n+   *\n+   * @return size of table (in bytes)\n+   */\n+  public static int memoryNeeded(final int numBuckets, final int bucketSize)\n+  {\n+    return numBuckets * bucketSize;\n+  }\n+\n+  /**\n+   * Returns the size of each bucket in a table.\n+   *\n+   * @param keySize   size of keys (in bytes)\n+   * @param valueSize size of values (in bytes)\n+   *\n+   * @return size of buckets (in bytes)\n+   */\n+  public static int bucketSize(final int keySize, final int valueSize)\n+  {\n+    return USED_BYTE_SIZE + keySize + valueSize;\n+  }\n+\n+  /**\n+   * Clear the table, resetting size to zero.\n+   */\n+  public void clear()\n+  {\n+    size = 0;\n+\n+    // Clear used flags.\n+    for (int bucket = 0; bucket < numBuckets; bucket++) {\n+      tableMemory.putByte((long) bucket * bucketSize, (byte) 0);\n+    }\n+  }\n+\n+  /**\n+   * Copy this table into another one. The other table must be large enough to hold all the copied buckets. The other\n+   * table will be cleared before the copy takes place.\n+   *\n+   * @param other       the other table\n+   * @param copyHandler a callback that is notified for each copied bucket\n+   */\n+  public void copyTo(final MemoryOpenHashTable other, @Nullable final BucketCopyHandler copyHandler)\n+  {\n+    if (other.size() > 0) {\n+      other.clear();\n+    }\n+\n+    for (int bucket = 0; bucket < numBuckets; bucket++) {\n+      final int bucketOffset = bucket * bucketSize;\n+      if (isOffsetUsed(bucketOffset)) {\n+        final int keyPosition = bucketOffset + USED_BYTE_SIZE;\n+        final int keyHash = Groupers.smear(HashTableUtils.hashMemory(tableMemory, keyPosition, keySize));\n+        final int newBucket = other.findBucket(keyHash, tableMemory, keyPosition);\n+\n+        if (newBucket >= 0) {\n+          // Not expected to happen, since we cleared the other table first.\n+          throw new ISE(\"Found already-used bucket while copying\");\n+        }\n+\n+        if (!other.canInsertNewBucket()) {\n+          throw new ISE(\"Unable to copy bucket to new table, size[%,d]\", other.size());\n+        }\n+\n+        final int newBucketOffset = -(newBucket + 1) * bucketSize;\n+        assert !other.isOffsetUsed(newBucketOffset);\n+        tableMemory.copyTo(bucketOffset, other.tableMemory, newBucketOffset, bucketSize);\n+        other.size++;\n+\n+        if (copyHandler != null) {\n+          copyHandler.bucketCopied(bucket, -(newBucket + 1), this, other);\n+        }\n+      }\n+    }\n+\n+    // Sanity check.\n+    if (other.size() != size) {\n+      throw new ISE(\"New table size[%,d] != old table size[%,d] after copying\", other.size(), size);\n+    }\n+  }\n+\n+  /**\n+   * Finds the bucket for a particular key.\n+   *\n+   * @param keyHash          result of calling {@link HashTableUtils#hashMemory} on this key\n+   * @param keySpace         memory containing the key\n+   * @param keySpacePosition position of the key within keySpace\n+   *\n+   * @return bucket number if currently occupied, or {@code -bucket - 1} if not occupied (yet)\n+   */\n+  public int findBucket(final int keyHash, final Memory keySpace, final int keySpacePosition)\n+  {\n+    int bucket = keyHash & bucketMask;\n+\n+    while (true) {\n+      final int bucketOffset = bucket * bucketSize;\n+\n+      if (tableMemory.getByte(bucketOffset) == 0) {\n+        // Found unused bucket before finding our key.\n+        return -bucket - 1;\n+      }\n+\n+      final boolean keyFound = HashTableUtils.memoryEquals(\n+          tableMemory,\n+          bucketOffset + USED_BYTE_SIZE,\n+          keySpace,\n+          keySpacePosition,\n+          keySize\n+      );\n+\n+      if (keyFound) {\n+        return bucket;\n+      }\n+\n+      bucket = (bucket + 1) & bucketMask;\n+    }\n+  }\n+\n+  /**\n+   * Returns whether this table can accept a new bucket.\n+   */\n+  public boolean canInsertNewBucket()\n+  {\n+    return size < maxSize;\n+  }\n+\n+  /**\n+   * Initialize a bucket with a particular key.\n+   *\n+   * Do not call this method unless the bucket is currently unused and {@link #canInsertNewBucket()} returns true.\n+   *\n+   * @param bucket           bucket number\n+   * @param keySpace         memory containing the key\n+   * @param keySpacePosition position of the key within keySpace\n+   */\n+  public void initBucket(final int bucket, final Memory keySpace, final int keySpacePosition)\n+  {\n+    final int bucketOffset = bucket * bucketSize;\n+\n+    // Method preconditions.\n+    assert canInsertNewBucket() && !isOffsetUsed(bucketOffset);\n+\n+    // Mark the bucket used and write in the key.\n+    tableMemory.putByte(bucketOffset, USED_BYTE);\n+    keySpace.copyTo(keySpacePosition, tableMemory, bucketOffset + USED_BYTE_SIZE, keySize);\n+    size++;\n+  }\n+\n+  /**\n+   * Returns the number of elements currently in the table.\n+   */\n+  public int size()\n+  {\n+    return size;\n+  }\n+\n+  /**\n+   * Returns the number of buckets in this table. Note that not all of these can actually be used. The amount that\n+   * can be used depends on the \"maxSize\" parameter provided during construction.\n+   */\n+  public int numBuckets()\n+  {\n+    return numBuckets;\n+  }\n+\n+  /**\n+   * Returns the size of keys, in bytes.\n+   */\n+  public int keySize()\n+  {\n+    return keySize;\n+  }\n+\n+  /**\n+   * Returns the size of values, in bytes.\n+   */\n+  public int valueSize()\n+  {\n+    return valueSize;\n+  }\n+\n+  /**\n+   * Returns the offset within each bucket where the key starts.\n+   */\n+  public int bucketKeyOffset()\n+  {\n+    return USED_BYTE_SIZE;\n+  }\n+\n+  /**\n+   * Returns the offset within each bucket where the value starts.\n+   */\n+  public int bucketValueOffset()\n+  {\n+    return USED_BYTE_SIZE + keySize;\n+  }\n+\n+  /**\n+   * Returns the size in bytes of each bucket.\n+   */\n+  public int bucketSize()\n+  {\n+    return bucketSize;\n+  }\n+\n+  /**\n+   * Returns the position within {@link #memory()} where a particular bucket starts.\n+   */\n+  public int bucketMemoryPosition(final int bucket)\n+  {\n+    return bucket * bucketSize;\n+  }\n+\n+  /**\n+   * Returns the memory backing this table.\n+   */\n+  public WritableMemory memory()\n+  {\n+    return tableMemory;\n+  }\n+\n+  /**\n+   * Iterates over all used buckets, returning bucket numbers for each one.\n+   *\n+   * The intent is that callers will pass the bucket numbers to {@link #bucketMemoryPosition} and then use\n+   * {@link #bucketKeyOffset()} and {@link #bucketValueOffset()} to extract keys and values from the buckets as needed.\n+   */\n+  public IntIterator bucketIterator()\n+  {\n+    return new IntIterator()\n+    {\n+      private int curr = 0;\n+      private int currBucket = -1;\n+\n+      @Override\n+      public boolean hasNext()\n+      {\n+        return curr < size;\n+      }\n+\n+      @Override\n+      public int nextInt()\n+      {\n+        if (curr >= size) {\n+          throw new NoSuchElementException();\n+        }\n+\n+        currBucket++;\n+\n+        while (!isOffsetUsed(currBucket * bucketSize)) {\n+          currBucket++;\n+        }\n+\n+        curr++;\n+        return currBucket;\n+      }\n+    };\n+  }\n+\n+  /**\n+   * Returns whether the bucket at position \"bucketOffset\" is used or not. Note that this is a bucket position (in\n+   * bytes), not a bucket number.\n+   */\n+  private boolean isOffsetUsed(final int bucketOffset)\n+  {\n+    return tableMemory.getByte(bucketOffset) == 1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bdad6e919c6a7ad73ab30e81780ee1c23013ee5a"}, "originalPosition": 389}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUzMzQ2ODk0", "url": "https://github.com/apache/druid/pull/9308#pullrequestreview-353346894", "createdAt": "2020-02-04T22:26:32Z", "commit": {"oid": "bdad6e919c6a7ad73ab30e81780ee1c23013ee5a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQyMjoyNjozMlrOFllptQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNFQyMjoyNjozMlrOFllptQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NDk1ODUxNw==", "bodyText": "Did you intend 31 * (31 * memory.getInt(position)) + memory.getInt(position + Integer.BYTES);?", "url": "https://github.com/apache/druid/pull/9308#discussion_r374958517", "createdAt": "2020-02-04T22:26:32Z", "author": {"login": "jihoonson"}, "path": "processing/src/main/java/org/apache/druid/query/groupby/epinephelinae/collection/HashTableUtils.java", "diffHunk": "@@ -0,0 +1,162 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.query.groupby.epinephelinae.collection;\n+\n+import org.apache.datasketches.memory.Memory;\n+\n+public class HashTableUtils\n+{\n+  private HashTableUtils()\n+  {\n+    // No instantiation.\n+  }\n+\n+  /**\n+   * Computes the previous power of two less than or equal to a given \"n\".\n+   *\n+   * The integer should be between 1 (inclusive) and {@link Integer#MAX_VALUE} for best results. Other parameters will\n+   * return {@link Integer#MIN_VALUE}.\n+   */\n+  public static int previousPowerOfTwo(final int n)\n+  {\n+    if (n > 0) {\n+      return Integer.highestOneBit(n);\n+    } else {\n+      return Integer.MIN_VALUE;\n+    }\n+  }\n+\n+  /**\n+   * Compute a simple, fast hash code of some memory range.\n+   *\n+   * @param memory   a region of memory\n+   * @param position position within the memory region\n+   * @param length   length of memory to hash, starting at the position\n+   */\n+  public static int hashMemory(final Memory memory, final long position, final int length)\n+  {\n+    // Special cases for small, common key sizes to speed them up: e.g. one int key, two int keys, one long key, etc.\n+    // The plus-one sizes (9, 13) are for nullable dimensions. The specific choices of special cases were chosen based\n+    // on benchmarking (see MemoryBenchmark) on a Skylake-based cloud instance.\n+\n+    switch (length) {\n+      case 4:\n+        return 31 + memory.getInt(position);\n+\n+      case 8:\n+        return 31 * (31 + memory.getInt(position)) + memory.getInt(position + Integer.BYTES);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bdad6e919c6a7ad73ab30e81780ee1c23013ee5a"}, "originalPosition": 64}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e85219dd60b8bd594ed8cdd4c2efcd91ab2b2386", "author": {"user": {"login": "gianm", "name": "Gian Merlino"}}, "url": "https://github.com/apache/druid/commit/e85219dd60b8bd594ed8cdd4c2efcd91ab2b2386", "committedDate": "2020-02-04T23:31:55Z", "message": "Adjustments from review."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUzMzc5NTE2", "url": "https://github.com/apache/druid/pull/9308#pullrequestreview-353379516", "createdAt": "2020-02-04T23:38:09Z", "commit": {"oid": "e85219dd60b8bd594ed8cdd4c2efcd91ab2b2386"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "26f3a15bb026c62e510e819577cb52d554f3e135", "author": {"user": {"login": "gianm", "name": "Gian Merlino"}}, "url": "https://github.com/apache/druid/commit/26f3a15bb026c62e510e819577cb52d554f3e135", "committedDate": "2020-02-05T00:52:22Z", "message": "Fix datasketches unit tests."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e9ffe625531d3af9d22f25a336ff9935acb5df34", "author": {"user": {"login": "gianm", "name": "Gian Merlino"}}, "url": "https://github.com/apache/druid/commit/e9ffe625531d3af9d22f25a336ff9935acb5df34", "committedDate": "2020-02-05T01:37:18Z", "message": "Fix checkstyle."}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2844, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}