{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDMzMDc3NDQz", "number": 10020, "title": "global table datasource for broadcast segments", "bodyText": "Description\nRelated to #9953, this PR adds a GlobalTableDataSource (better name suggestions welcome) and injects SegmentManager into DruidSchema, which will now also poll the set of datasources for which the broker loads segments to construct the DruidTable with a GlobalTableDataSource.\nGlobalTableDataSource extends TableDataSource, but sets isGlobal to true, and isCacheable to false, though it might actually be cacheable... still need to think about that. Direct queries to these segments will be performed on historicals as being a TableDataSource it will fail the checks to run locally on the broker, but if wired up to a JoinableFactory that supplies an IndexedTable, can be used as part of a join clause and be run directly with the query instead of requiring a subquery join with an InlineDatasource.\nExamples to illustrate the implications/behavior, assuming GlobalTableDataSource is bound to JoinableFactory:\n1. direct query to broadcast segment\nSince GlobalTableDataSource is a TableDataSource, this is queried exactly like a normal Druid segment, on the historical\nSELECT\n   broadcast_table.string1,\n   SUM(broadcast_table.long1)\nFROM druid.broadcast_table\nGROUP BY 1\nORDER BY 2\n\n2. join regular segment to broadcast\njoin is pushed down, join applies index table of broadcast segment to each regular segment\nSELECT \n  regular_table.string1,\n  broadcast_table.string1,\n  SUM(broadcast_table.long1),\n  SUM(regular_table.long1)\nFROM druid.regular_table \nINNER JOIN druid.broadcast_table ON regular_table.string1 = broadcast_table.string1\nGROUP BY 1, 2\nORDER BY 3 DESC\n\n3. join broadcast segment to regular\nbroadcast segment is queried the same as a regular table segment table to table subquery join\nSELECT \n  regular_table.string1,\n  broadcast_table.string1,\n  SUM(broadcast_table.long1),\n  SUM(regular_table.long1)\nFROM druid.broadcast_table\nINNER JOIN druid.regular_table ON broadcast_table.string1 = regular_table.string1\nGROUP BY 1, 2\nORDER BY 3 DESC\n\n4. join broadcast segment to broadcast segment\nlhs broadcast segment is exactly the same as if a regular segment was used, join is pushed down, join applies index table of rhs broadcast segment2 to broadcast segment\nSELECT \n  broadcast_table.string1,\n  broadcast_table2.string1,\n  SUM(broadcast_table.long1),\n  SUM(broadcast_table2.long1)\nFROM druid.broadcast_table\nINNER JOIN druid.broadcast_table2 ON broadcast_table.string1 = broadcast_table2.string1\nGROUP BY 1, 2\nORDER BY 3 DESC\n\n5. join broadcast to lookup\nlhs broadcast segment is exactly the same as if a regular segment was used, join pushed down to a historical which holds the broadcast segment and lookup is joined\nSELECT \n  lookup_table.v,\n  broadcast_table.string1,\n  SUM(broadcast_table.long1)\nFROM druid.broadcast_table \nINNER JOIN lookup.lookup_table ON broadcast_table.string1 = lookup_table.k\nGROUP BY 1, 2\nORDER BY 3 DESC\n\n6. join lookup to broadcast table\nexecuted entirely on broker, broadcast is a joinable to the lookup which can be queried locally on the broker, this is the only path that currently will use the joinable from the GlobalTableDataSource on the broker\nSELECT \n  lookup_table.v,\n  broadcast_table.string1,\n  SUM(broadcast_table.long1)\nFROM lookup.lookup_table \nINNER JOIN druid.broadcast_table ON lookup_table.k = broadcast_table.string1\nGROUP BY 1, 2\nORDER BY 3 DESC\n\n\nThis PR has:\n\n been self-reviewed.\n\n using the concurrency checklist (Remove this item if the PR doesn't have any relation to concurrency.)\n\n\n added documentation for new or modified features or behaviors.\n added Javadocs for most classes and all non-trivial methods. Linked related entities via Javadoc links.\n added or updated version, license, or notice information in licenses.yaml\n added comments explaining the \"why\" and the intent of the code wherever would not be obvious for an unfamiliar reader.\n added unit tests or modified existing tests to cover new code paths, ensuring the threshold for code coverage is met.\n added integration tests.\n been tested in a test Druid cluster.\n\n\nKey changed/added classes in this PR\n\nDruidSchema\nGlobalTableDataSource", "createdAt": "2020-06-11T13:26:03Z", "url": "https://github.com/apache/druid/pull/10020", "merged": true, "mergeCommit": {"oid": "68aa3841904cc08c2d4ab43b37994a868574fb91"}, "closed": true, "closedAt": "2020-06-17T00:58:05Z", "author": {"login": "clintropolis"}, "timelineItems": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcqOIlegH2gAyNDMzMDc3NDQzOjQ4OWZkYzY3ZjQwYTk5ZmIxMjA4N2JiNDQ5MmNmM2Q5YWRkZTA2NjA=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcr_IQoAFqTQzMTk4Nzg5Nw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "489fdc67f40a99fb12087bb4492cf3d9adde0660", "author": {"user": {"login": "clintropolis", "name": "Clint Wylie"}}, "url": "https://github.com/apache/druid/commit/489fdc67f40a99fb12087bb4492cf3d9adde0660", "committedDate": "2020-06-11T13:18:57Z", "message": "global table datasource for broadcast segments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "eeb174a22d6a2d6823c45c997ef88adb625d6e3e", "author": {"user": {"login": "clintropolis", "name": "Clint Wylie"}}, "url": "https://github.com/apache/druid/commit/eeb174a22d6a2d6823c45c997ef88adb625d6e3e", "committedDate": "2020-06-12T11:51:25Z", "message": "tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bda1c7f86a1f74b0868472f0dd9b1b10ec9c9ed1", "author": {"user": {"login": "clintropolis", "name": "Clint Wylie"}}, "url": "https://github.com/apache/druid/commit/bda1c7f86a1f74b0868472f0dd9b1b10ec9c9ed1", "committedDate": "2020-06-12T13:34:04Z", "message": "fix"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "aff3b0ab96f11bb94cbe3a441adb8b1c1ec78b28", "author": {"user": {"login": "clintropolis", "name": "Clint Wylie"}}, "url": "https://github.com/apache/druid/commit/aff3b0ab96f11bb94cbe3a441adb8b1c1ec78b28", "committedDate": "2020-06-12T19:29:22Z", "message": "fix test"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI5OTc3Mzkw", "url": "https://github.com/apache/druid/pull/10020#pullrequestreview-429977390", "createdAt": "2020-06-12T19:07:52Z", "commit": {"oid": "bda1c7f86a1f74b0868472f0dd9b1b10ec9c9ed1"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQxOTowNzo1MlrOGjO2ng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQxOToyODoyN1rOGjPXVg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTU5NjcwMg==", "bodyText": "Should the global datasource type be added to the docs? https://druid.apache.org/docs/0.18.1/querying/query-execution.html#datasource-type", "url": "https://github.com/apache/druid/pull/10020#discussion_r439596702", "createdAt": "2020-06-12T19:07:52Z", "author": {"login": "ccaominh"}, "path": "processing/src/main/java/org/apache/druid/query/DataSource.java", "diffHunk": "@@ -35,7 +35,8 @@\n     @JsonSubTypes.Type(value = UnionDataSource.class, name = \"union\"),\n     @JsonSubTypes.Type(value = JoinDataSource.class, name = \"join\"),\n     @JsonSubTypes.Type(value = LookupDataSource.class, name = \"lookup\"),\n-    @JsonSubTypes.Type(value = InlineDataSource.class, name = \"inline\")\n+    @JsonSubTypes.Type(value = InlineDataSource.class, name = \"inline\"),\n+    @JsonSubTypes.Type(value = GlobalTableDataSource.class, name = \"global\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bda1c7f86a1f74b0868472f0dd9b1b10ec9c9ed1"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTU5NzQ1NA==", "bodyText": "What do you think about adding a javadoc explaining why this datasource type exists?", "url": "https://github.com/apache/druid/pull/10020#discussion_r439597454", "createdAt": "2020-06-12T19:09:38Z", "author": {"login": "ccaominh"}, "path": "processing/src/main/java/org/apache/druid/query/GlobalTableDataSource.java", "diffHunk": "@@ -0,0 +1,54 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.query;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.annotation.JsonTypeName;\n+\n+@JsonTypeName(\"global\")\n+public class GlobalTableDataSource extends TableDataSource", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bda1c7f86a1f74b0868472f0dd9b1b10ec9c9ed1"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTYwMTAzNw==", "bodyText": "Why are all of the datasources broadcast?", "url": "https://github.com/apache/druid/pull/10020#discussion_r439601037", "createdAt": "2020-06-12T19:18:28Z", "author": {"login": "ccaominh"}, "path": "sql/src/main/java/org/apache/druid/sql/calcite/schema/DruidSchema.java", "diffHunk": "@@ -196,119 +207,130 @@ public DruidSchema(\n   public void start() throws InterruptedException\n   {\n     cacheExec.submit(\n-        new Runnable()\n-        {\n-          @Override\n-          public void run()\n-          {\n-            try {\n-              while (!Thread.currentThread().isInterrupted()) {\n-                final Set<SegmentId> segmentsToRefresh = new TreeSet<>();\n-                final Set<String> dataSourcesToRebuild = new TreeSet<>();\n-\n-                try {\n-                  synchronized (lock) {\n-                    final long nextRefreshNoFuzz = DateTimes\n-                        .utc(lastRefresh)\n-                        .plus(config.getMetadataRefreshPeriod())\n-                        .getMillis();\n-\n-                    // Fuzz a bit to spread load out when we have multiple brokers.\n-                    final long nextRefresh = nextRefreshNoFuzz + (long) ((nextRefreshNoFuzz - lastRefresh) * 0.10);\n-\n-                    while (true) {\n-                      // Do not refresh if it's too soon after a failure (to avoid rapid cycles of failure).\n-                      final boolean wasRecentFailure = DateTimes.utc(lastFailure)\n-                                                                .plus(config.getMetadataRefreshPeriod())\n-                                                                .isAfterNow();\n-\n-                      if (isServerViewInitialized &&\n-                          !wasRecentFailure &&\n-                          (!segmentsNeedingRefresh.isEmpty() || !dataSourcesNeedingRebuild.isEmpty()) &&\n-                          (refreshImmediately || nextRefresh < System.currentTimeMillis())) {\n-                        // We need to do a refresh. Break out of the waiting loop.\n-                        break;\n-                      }\n-\n-                      if (isServerViewInitialized) {\n-                        // Server view is initialized, but we don't need to do a refresh. Could happen if there are\n-                        // no segments in the system yet. Just mark us as initialized, then.\n-                        initialized.countDown();\n-                      }\n-\n-                      // Wait some more, we'll wake up when it might be time to do another refresh.\n-                      lock.wait(Math.max(1, nextRefresh - System.currentTimeMillis()));\n+        () -> {\n+          try {\n+            while (!Thread.currentThread().isInterrupted()) {\n+              final Set<SegmentId> segmentsToRefresh = new TreeSet<>();\n+              final Set<String> dataSourcesToRebuild = new TreeSet<>();\n+\n+              try {\n+                synchronized (lock) {\n+                  final long nextRefreshNoFuzz = DateTimes\n+                      .utc(lastRefresh)\n+                      .plus(config.getMetadataRefreshPeriod())\n+                      .getMillis();\n+\n+                  // Fuzz a bit to spread load out when we have multiple brokers.\n+                  final long nextRefresh = nextRefreshNoFuzz + (long) ((nextRefreshNoFuzz - lastRefresh) * 0.10);\n+\n+                  while (true) {\n+                    // Do not refresh if it's too soon after a failure (to avoid rapid cycles of failure).\n+                    final boolean wasRecentFailure = DateTimes.utc(lastFailure)\n+                                                              .plus(config.getMetadataRefreshPeriod())\n+                                                              .isAfterNow();\n+\n+                    if (isServerViewInitialized &&\n+                        !wasRecentFailure &&\n+                        (!segmentsNeedingRefresh.isEmpty() || !dataSourcesNeedingRebuild.isEmpty()) &&\n+                        (refreshImmediately || nextRefresh < System.currentTimeMillis())) {\n+                      // We need to do a refresh. Break out of the waiting loop.\n+                      break;\n                     }\n \n-                    segmentsToRefresh.addAll(segmentsNeedingRefresh);\n-                    segmentsNeedingRefresh.clear();\n-\n-                    // Mutable segments need a refresh every period, since new columns could be added dynamically.\n-                    segmentsNeedingRefresh.addAll(mutableSegments);\n+                    if (isServerViewInitialized) {\n+                      // Server view is initialized, but we don't need to do a refresh. Could happen if there are\n+                      // no segments in the system yet. Just mark us as initialized, then.\n+                      initialized.countDown();\n+                    }\n \n-                    lastFailure = 0L;\n-                    lastRefresh = System.currentTimeMillis();\n-                    refreshImmediately = false;\n+                    // Wait some more, we'll wake up when it might be time to do another refresh.\n+                    lock.wait(Math.max(1, nextRefresh - System.currentTimeMillis()));\n                   }\n \n-                  // Refresh the segments.\n-                  final Set<SegmentId> refreshed = refreshSegments(segmentsToRefresh);\n+                  segmentsToRefresh.addAll(segmentsNeedingRefresh);\n+                  segmentsNeedingRefresh.clear();\n \n-                  synchronized (lock) {\n-                    // Add missing segments back to the refresh list.\n-                    segmentsNeedingRefresh.addAll(Sets.difference(segmentsToRefresh, refreshed));\n+                  // Mutable segments need a refresh every period, since new columns could be added dynamically.\n+                  segmentsNeedingRefresh.addAll(mutableSegments);\n \n-                    // Compute the list of dataSources to rebuild tables for.\n-                    dataSourcesToRebuild.addAll(dataSourcesNeedingRebuild);\n-                    refreshed.forEach(segment -> dataSourcesToRebuild.add(segment.getDataSource()));\n-                    dataSourcesNeedingRebuild.clear();\n+                  lastFailure = 0L;\n+                  lastRefresh = System.currentTimeMillis();\n+                  refreshImmediately = false;\n+                }\n \n-                    lock.notifyAll();\n-                  }\n+                // Refresh the segments.\n+                final Set<SegmentId> refreshed = refreshSegments(segmentsToRefresh);\n \n-                  // Rebuild the dataSources.\n-                  for (String dataSource : dataSourcesToRebuild) {\n-                    final DruidTable druidTable = buildDruidTable(dataSource);\n-                    final DruidTable oldTable = tables.put(dataSource, druidTable);\n-                    if (oldTable == null || !oldTable.getRowSignature().equals(druidTable.getRowSignature())) {\n-                      log.info(\"dataSource [%s] has new signature: %s.\", dataSource, druidTable.getRowSignature());\n-                    } else {\n-                      log.debug(\"dataSource [%s] signature is unchanged.\", dataSource);\n-                    }\n-                  }\n+                synchronized (lock) {\n+                  // Add missing segments back to the refresh list.\n+                  segmentsNeedingRefresh.addAll(Sets.difference(segmentsToRefresh, refreshed));\n \n-                  initialized.countDown();\n-                }\n-                catch (InterruptedException e) {\n-                  // Fall through.\n-                  throw e;\n+                  // Compute the list of dataSources to rebuild tables for.\n+                  dataSourcesToRebuild.addAll(dataSourcesNeedingRebuild);\n+                  refreshed.forEach(segment -> dataSourcesToRebuild.add(segment.getDataSource()));\n+                  dataSourcesNeedingRebuild.clear();\n+\n+                  lock.notifyAll();\n                 }\n-                catch (Exception e) {\n-                  log.warn(e, \"Metadata refresh failed, trying again soon.\");\n-\n-                  synchronized (lock) {\n-                    // Add our segments and dataSources back to their refresh and rebuild lists.\n-                    segmentsNeedingRefresh.addAll(segmentsToRefresh);\n-                    dataSourcesNeedingRebuild.addAll(dataSourcesToRebuild);\n-                    lastFailure = System.currentTimeMillis();\n-                    lock.notifyAll();\n+\n+                // Rebuild the dataSources.\n+                for (String dataSource : dataSourcesToRebuild) {\n+                  final DruidTable druidTable = buildDruidTable(dataSource);\n+                  final DruidTable oldTable = tables.put(dataSource, druidTable);\n+                  if (oldTable == null || !oldTable.getRowSignature().equals(druidTable.getRowSignature())) {\n+                    log.info(\"dataSource [%s] has new signature: %s.\", dataSource, druidTable.getRowSignature());\n+                  } else {\n+                    log.debug(\"dataSource [%s] signature is unchanged.\", dataSource);\n                   }\n                 }\n+\n+                initialized.countDown();\n+              }\n+              catch (InterruptedException e) {\n+                // Fall through.\n+                throw e;\n+              }\n+              catch (Exception e) {\n+                log.warn(e, \"Metadata refresh failed, trying again soon.\");\n+\n+                synchronized (lock) {\n+                  // Add our segments and dataSources back to their refresh and rebuild lists.\n+                  segmentsNeedingRefresh.addAll(segmentsToRefresh);\n+                  dataSourcesNeedingRebuild.addAll(dataSourcesToRebuild);\n+                  lastFailure = System.currentTimeMillis();\n+                  lock.notifyAll();\n+                }\n               }\n-            }\n-            catch (InterruptedException e) {\n-              // Just exit.\n-            }\n-            catch (Throwable e) {\n-              // Throwables that fall out to here (not caught by an inner try/catch) are potentially gnarly, like\n-              // OOMEs. Anyway, let's just emit an alert and stop refreshing metadata.\n-              log.makeAlert(e, \"Metadata refresh failed permanently\").emit();\n-              throw e;\n-            }\n-            finally {\n-              log.info(\"Metadata refresh stopped.\");\n             }\n           }\n+          catch (InterruptedException e) {\n+            // Just exit.\n+          }\n+          catch (Throwable e) {\n+            // Throwables that fall out to here (not caught by an inner try/catch) are potentially gnarly, like\n+            // OOMEs. Anyway, let's just emit an alert and stop refreshing metadata.\n+            log.makeAlert(e, \"Metadata refresh failed permanently\").emit();\n+            throw e;\n+          }\n+          finally {\n+            log.info(\"Metadata refresh stopped.\");\n+          }\n+        }\n+    );\n+\n+    ScheduledExecutors.scheduleWithFixedDelay(\n+        localSegmentExec,\n+        config.getMetadataRefreshPeriod().toStandardDuration(),\n+        config.getMetadataRefreshPeriod().toStandardDuration(),\n+        () -> {\n+          synchronized (lock) {\n+            // refresh known broadcast segments\n+            Set<String> localSegmentDatasources = segmentManager.getDataSourceNames();\n+            dataSourcesNeedingRebuild.addAll(localSegmentDatasources);\n+            broadcastDatasources.clear();\n+            broadcastDatasources.addAll(localSegmentDatasources);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bda1c7f86a1f74b0868472f0dd9b1b10ec9c9ed1"}, "originalPosition": 293}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTYwNTA3OA==", "bodyText": "This change is causing SegmentMetadataQueryTest.testSerde() to fail: https://travis-ci.org/github/apache/druid/jobs/697612764#L5001\nThe query variable has a LegacyDataSource whereas the deserialized serialized version has a TableDataSource.", "url": "https://github.com/apache/druid/pull/10020#discussion_r439605078", "createdAt": "2020-06-12T19:28:27Z", "author": {"login": "ccaominh"}, "path": "processing/src/main/java/org/apache/druid/query/TableDataSource.java", "diffHunk": "@@ -98,7 +98,7 @@ public final boolean equals(Object o)\n     if (this == o) {\n       return true;\n     }\n-    if (!(o instanceof TableDataSource)) {\n+    if (!(o instanceof TableDataSource) || !getClass().equals(o.getClass())) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bda1c7f86a1f74b0868472f0dd9b1b10ec9c9ed1"}, "originalPosition": 5}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9d7a9b6fce0b4d8ba4f9e7f4321aa6eb24458f01", "author": {"user": {"login": "clintropolis", "name": "Clint Wylie"}}, "url": "https://github.com/apache/druid/commit/9d7a9b6fce0b4d8ba4f9e7f4321aa6eb24458f01", "committedDate": "2020-06-12T22:59:27Z", "message": "comments and javadocs"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMwMDk2NDg1", "url": "https://github.com/apache/druid/pull/10020#pullrequestreview-430096485", "createdAt": "2020-06-13T00:36:04Z", "commit": {"oid": "9d7a9b6fce0b4d8ba4f9e7f4321aa6eb24458f01"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMxMDE5MzQw", "url": "https://github.com/apache/druid/pull/10020#pullrequestreview-431019340", "createdAt": "2020-06-15T21:52:09Z", "commit": {"oid": "9d7a9b6fce0b4d8ba4f9e7f4321aa6eb24458f01"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d0631b53e13436e59c4fe52671763956fec95d9b", "author": {"user": {"login": "clintropolis", "name": "Clint Wylie"}}, "url": "https://github.com/apache/druid/commit/d0631b53e13436e59c4fe52671763956fec95d9b", "committedDate": "2020-06-16T04:04:41Z", "message": "Merge remote-tracking branch 'upstream/master' into global-table-for-broadcast-segments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMxMTc0OTI5", "url": "https://github.com/apache/druid/pull/10020#pullrequestreview-431174929", "createdAt": "2020-06-16T05:43:15Z", "commit": {"oid": "9d7a9b6fce0b4d8ba4f9e7f4321aa6eb24458f01"}, "state": "COMMENTED", "comments": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQwNTo0MzoxNlrOGkMAJw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQwNTo1OTo1NlrOGkMTaA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDU5ODU2Nw==", "bodyText": "localSegmentDataSources would be more consistent spelling, I think.", "url": "https://github.com/apache/druid/pull/10020#discussion_r440598567", "createdAt": "2020-06-16T05:43:16Z", "author": {"login": "gianm"}, "path": "sql/src/main/java/org/apache/druid/sql/calcite/schema/DruidSchema.java", "diffHunk": "@@ -196,119 +207,132 @@ public DruidSchema(\n   public void start() throws InterruptedException\n   {\n     cacheExec.submit(\n-        new Runnable()\n-        {\n-          @Override\n-          public void run()\n-          {\n-            try {\n-              while (!Thread.currentThread().isInterrupted()) {\n-                final Set<SegmentId> segmentsToRefresh = new TreeSet<>();\n-                final Set<String> dataSourcesToRebuild = new TreeSet<>();\n-\n-                try {\n-                  synchronized (lock) {\n-                    final long nextRefreshNoFuzz = DateTimes\n-                        .utc(lastRefresh)\n-                        .plus(config.getMetadataRefreshPeriod())\n-                        .getMillis();\n-\n-                    // Fuzz a bit to spread load out when we have multiple brokers.\n-                    final long nextRefresh = nextRefreshNoFuzz + (long) ((nextRefreshNoFuzz - lastRefresh) * 0.10);\n-\n-                    while (true) {\n-                      // Do not refresh if it's too soon after a failure (to avoid rapid cycles of failure).\n-                      final boolean wasRecentFailure = DateTimes.utc(lastFailure)\n-                                                                .plus(config.getMetadataRefreshPeriod())\n-                                                                .isAfterNow();\n-\n-                      if (isServerViewInitialized &&\n-                          !wasRecentFailure &&\n-                          (!segmentsNeedingRefresh.isEmpty() || !dataSourcesNeedingRebuild.isEmpty()) &&\n-                          (refreshImmediately || nextRefresh < System.currentTimeMillis())) {\n-                        // We need to do a refresh. Break out of the waiting loop.\n-                        break;\n-                      }\n-\n-                      if (isServerViewInitialized) {\n-                        // Server view is initialized, but we don't need to do a refresh. Could happen if there are\n-                        // no segments in the system yet. Just mark us as initialized, then.\n-                        initialized.countDown();\n-                      }\n-\n-                      // Wait some more, we'll wake up when it might be time to do another refresh.\n-                      lock.wait(Math.max(1, nextRefresh - System.currentTimeMillis()));\n+        () -> {\n+          try {\n+            while (!Thread.currentThread().isInterrupted()) {\n+              final Set<SegmentId> segmentsToRefresh = new TreeSet<>();\n+              final Set<String> dataSourcesToRebuild = new TreeSet<>();\n+\n+              try {\n+                synchronized (lock) {\n+                  final long nextRefreshNoFuzz = DateTimes\n+                      .utc(lastRefresh)\n+                      .plus(config.getMetadataRefreshPeriod())\n+                      .getMillis();\n+\n+                  // Fuzz a bit to spread load out when we have multiple brokers.\n+                  final long nextRefresh = nextRefreshNoFuzz + (long) ((nextRefreshNoFuzz - lastRefresh) * 0.10);\n+\n+                  while (true) {\n+                    // Do not refresh if it's too soon after a failure (to avoid rapid cycles of failure).\n+                    final boolean wasRecentFailure = DateTimes.utc(lastFailure)\n+                                                              .plus(config.getMetadataRefreshPeriod())\n+                                                              .isAfterNow();\n+\n+                    if (isServerViewInitialized &&\n+                        !wasRecentFailure &&\n+                        (!segmentsNeedingRefresh.isEmpty() || !dataSourcesNeedingRebuild.isEmpty()) &&\n+                        (refreshImmediately || nextRefresh < System.currentTimeMillis())) {\n+                      // We need to do a refresh. Break out of the waiting loop.\n+                      break;\n                     }\n \n-                    segmentsToRefresh.addAll(segmentsNeedingRefresh);\n-                    segmentsNeedingRefresh.clear();\n-\n-                    // Mutable segments need a refresh every period, since new columns could be added dynamically.\n-                    segmentsNeedingRefresh.addAll(mutableSegments);\n+                    if (isServerViewInitialized) {\n+                      // Server view is initialized, but we don't need to do a refresh. Could happen if there are\n+                      // no segments in the system yet. Just mark us as initialized, then.\n+                      initialized.countDown();\n+                    }\n \n-                    lastFailure = 0L;\n-                    lastRefresh = System.currentTimeMillis();\n-                    refreshImmediately = false;\n+                    // Wait some more, we'll wake up when it might be time to do another refresh.\n+                    lock.wait(Math.max(1, nextRefresh - System.currentTimeMillis()));\n                   }\n \n-                  // Refresh the segments.\n-                  final Set<SegmentId> refreshed = refreshSegments(segmentsToRefresh);\n+                  segmentsToRefresh.addAll(segmentsNeedingRefresh);\n+                  segmentsNeedingRefresh.clear();\n \n-                  synchronized (lock) {\n-                    // Add missing segments back to the refresh list.\n-                    segmentsNeedingRefresh.addAll(Sets.difference(segmentsToRefresh, refreshed));\n+                  // Mutable segments need a refresh every period, since new columns could be added dynamically.\n+                  segmentsNeedingRefresh.addAll(mutableSegments);\n \n-                    // Compute the list of dataSources to rebuild tables for.\n-                    dataSourcesToRebuild.addAll(dataSourcesNeedingRebuild);\n-                    refreshed.forEach(segment -> dataSourcesToRebuild.add(segment.getDataSource()));\n-                    dataSourcesNeedingRebuild.clear();\n+                  lastFailure = 0L;\n+                  lastRefresh = System.currentTimeMillis();\n+                  refreshImmediately = false;\n+                }\n \n-                    lock.notifyAll();\n-                  }\n+                // Refresh the segments.\n+                final Set<SegmentId> refreshed = refreshSegments(segmentsToRefresh);\n \n-                  // Rebuild the dataSources.\n-                  for (String dataSource : dataSourcesToRebuild) {\n-                    final DruidTable druidTable = buildDruidTable(dataSource);\n-                    final DruidTable oldTable = tables.put(dataSource, druidTable);\n-                    if (oldTable == null || !oldTable.getRowSignature().equals(druidTable.getRowSignature())) {\n-                      log.info(\"dataSource [%s] has new signature: %s.\", dataSource, druidTable.getRowSignature());\n-                    } else {\n-                      log.debug(\"dataSource [%s] signature is unchanged.\", dataSource);\n-                    }\n-                  }\n+                synchronized (lock) {\n+                  // Add missing segments back to the refresh list.\n+                  segmentsNeedingRefresh.addAll(Sets.difference(segmentsToRefresh, refreshed));\n \n-                  initialized.countDown();\n-                }\n-                catch (InterruptedException e) {\n-                  // Fall through.\n-                  throw e;\n+                  // Compute the list of dataSources to rebuild tables for.\n+                  dataSourcesToRebuild.addAll(dataSourcesNeedingRebuild);\n+                  refreshed.forEach(segment -> dataSourcesToRebuild.add(segment.getDataSource()));\n+                  dataSourcesNeedingRebuild.clear();\n+\n+                  lock.notifyAll();\n                 }\n-                catch (Exception e) {\n-                  log.warn(e, \"Metadata refresh failed, trying again soon.\");\n-\n-                  synchronized (lock) {\n-                    // Add our segments and dataSources back to their refresh and rebuild lists.\n-                    segmentsNeedingRefresh.addAll(segmentsToRefresh);\n-                    dataSourcesNeedingRebuild.addAll(dataSourcesToRebuild);\n-                    lastFailure = System.currentTimeMillis();\n-                    lock.notifyAll();\n+\n+                // Rebuild the dataSources.\n+                for (String dataSource : dataSourcesToRebuild) {\n+                  final DruidTable druidTable = buildDruidTable(dataSource);\n+                  final DruidTable oldTable = tables.put(dataSource, druidTable);\n+                  if (oldTable == null || !oldTable.getRowSignature().equals(druidTable.getRowSignature())) {\n+                    log.info(\"dataSource [%s] has new signature: %s.\", dataSource, druidTable.getRowSignature());\n+                  } else {\n+                    log.debug(\"dataSource [%s] signature is unchanged.\", dataSource);\n                   }\n                 }\n+\n+                initialized.countDown();\n+              }\n+              catch (InterruptedException e) {\n+                // Fall through.\n+                throw e;\n+              }\n+              catch (Exception e) {\n+                log.warn(e, \"Metadata refresh failed, trying again soon.\");\n+\n+                synchronized (lock) {\n+                  // Add our segments and dataSources back to their refresh and rebuild lists.\n+                  segmentsNeedingRefresh.addAll(segmentsToRefresh);\n+                  dataSourcesNeedingRebuild.addAll(dataSourcesToRebuild);\n+                  lastFailure = System.currentTimeMillis();\n+                  lock.notifyAll();\n+                }\n               }\n-            }\n-            catch (InterruptedException e) {\n-              // Just exit.\n-            }\n-            catch (Throwable e) {\n-              // Throwables that fall out to here (not caught by an inner try/catch) are potentially gnarly, like\n-              // OOMEs. Anyway, let's just emit an alert and stop refreshing metadata.\n-              log.makeAlert(e, \"Metadata refresh failed permanently\").emit();\n-              throw e;\n-            }\n-            finally {\n-              log.info(\"Metadata refresh stopped.\");\n             }\n           }\n+          catch (InterruptedException e) {\n+            // Just exit.\n+          }\n+          catch (Throwable e) {\n+            // Throwables that fall out to here (not caught by an inner try/catch) are potentially gnarly, like\n+            // OOMEs. Anyway, let's just emit an alert and stop refreshing metadata.\n+            log.makeAlert(e, \"Metadata refresh failed permanently\").emit();\n+            throw e;\n+          }\n+          finally {\n+            log.info(\"Metadata refresh stopped.\");\n+          }\n+        }\n+    );\n+\n+    ScheduledExecutors.scheduleWithFixedDelay(\n+        localSegmentExec,\n+        config.getMetadataRefreshPeriod().toStandardDuration(),\n+        config.getMetadataRefreshPeriod().toStandardDuration(),\n+        () -> {\n+          synchronized (lock) {\n+            // refresh known broadcast segments. Since DruidSchema is only present on the broker, any segment we have\n+            // locally in the SegmentManager must be broadcast datasources. This could potentially be replaced in the\n+            // future by fetching load rules from the coordinator\n+            Set<String> localSegmentDatasources = segmentManager.getDataSourceNames();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9d7a9b6fce0b4d8ba4f9e7f4321aa6eb24458f01"}, "originalPosition": 292}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDU5OTY0NA==", "bodyText": "I think globalTable would be a better name. We only have one chance to get it right!\nIMO for some consistency between SQL and native, we'll need to either transparently globalify the regular table type (perhaps a rewrite step like ClientQuerySegmentWalker's inlining?) or we'll need to document the globalTable type. I think the former is nicer, because the latter comes with too many caveats (you have to make sure to use it in the proper conditions).", "url": "https://github.com/apache/druid/pull/10020#discussion_r440599644", "createdAt": "2020-06-16T05:47:06Z", "author": {"login": "gianm"}, "path": "processing/src/main/java/org/apache/druid/query/DataSource.java", "diffHunk": "@@ -35,7 +35,8 @@\n     @JsonSubTypes.Type(value = UnionDataSource.class, name = \"union\"),\n     @JsonSubTypes.Type(value = JoinDataSource.class, name = \"join\"),\n     @JsonSubTypes.Type(value = LookupDataSource.class, name = \"lookup\"),\n-    @JsonSubTypes.Type(value = InlineDataSource.class, name = \"inline\")\n+    @JsonSubTypes.Type(value = InlineDataSource.class, name = \"inline\"),\n+    @JsonSubTypes.Type(value = GlobalTableDataSource.class, name = \"global\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTU5NjcwMg=="}, "originalCommit": {"oid": "bda1c7f86a1f74b0868472f0dd9b1b10ec9c9ed1"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDYwMDc1Mw==", "bodyText": "\"datasource\" makes more sense here than \"segment\".", "url": "https://github.com/apache/druid/pull/10020#discussion_r440600753", "createdAt": "2020-06-16T05:51:04Z", "author": {"login": "gianm"}, "path": "processing/src/main/java/org/apache/druid/query/GlobalTableDataSource.java", "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.query;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.annotation.JsonTypeName;\n+\n+/**\n+ * {@link TableDataSource} variant for globally available 'broadcast' segments. If bound to a\n+ * {@link org.apache.druid.segment.join.JoinableFactory} that can create an\n+ * {@link org.apache.druid.segment.join.table.IndexedTable} using DruidBinders.joinableFactoryBinder, this allows\n+ * optimal usage of segments using this DataSource type in join operations (because they are global), and so can be pushed\n+ * down to historicals as a {@link JoinDataSource}, instead of requiring a subquery join using\n+ * {@link InlineDataSource} to construct an {@link org.apache.druid.segment.join.table.IndexedTable} on the fly on the\n+ * broker. Because it is also a {@link TableDataSource}, when queried directly, or on the left hand side of a join,\n+ * they will be treated as any normal segment.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9d7a9b6fce0b4d8ba4f9e7f4321aa6eb24458f01"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDYwMDkzOQ==", "bodyText": "Why shouldn't it be cacheable?", "url": "https://github.com/apache/druid/pull/10020#discussion_r440600939", "createdAt": "2020-06-16T05:51:48Z", "author": {"login": "gianm"}, "path": "processing/src/main/java/org/apache/druid/query/GlobalTableDataSource.java", "diffHunk": "@@ -0,0 +1,64 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.query;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.annotation.JsonTypeName;\n+\n+/**\n+ * {@link TableDataSource} variant for globally available 'broadcast' segments. If bound to a\n+ * {@link org.apache.druid.segment.join.JoinableFactory} that can create an\n+ * {@link org.apache.druid.segment.join.table.IndexedTable} using DruidBinders.joinableFactoryBinder, this allows\n+ * optimal usage of segments using this DataSource type in join operations (because they are global), and so can be pushed\n+ * down to historicals as a {@link JoinDataSource}, instead of requiring a subquery join using\n+ * {@link InlineDataSource} to construct an {@link org.apache.druid.segment.join.table.IndexedTable} on the fly on the\n+ * broker. Because it is also a {@link TableDataSource}, when queried directly, or on the left hand side of a join,\n+ * they will be treated as any normal segment.\n+ */\n+@JsonTypeName(\"global\")\n+public class GlobalTableDataSource extends TableDataSource\n+{\n+  @JsonCreator\n+  public GlobalTableDataSource(@JsonProperty(\"name\") String name)\n+  {\n+    super(name);\n+  }\n+\n+  @Override\n+  public boolean isCacheable()\n+  {\n+    return false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9d7a9b6fce0b4d8ba4f9e7f4321aa6eb24458f01"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDYwMTU1OQ==", "bodyText": "I think you can make this a little less gross by replacing this equals impl (and the one in GlobalTableDataSource) with a new auto-generated one that checks getClass.", "url": "https://github.com/apache/druid/pull/10020#discussion_r440601559", "createdAt": "2020-06-16T05:53:49Z", "author": {"login": "gianm"}, "path": "processing/src/main/java/org/apache/druid/query/TableDataSource.java", "diffHunk": "@@ -102,6 +102,11 @@ public final boolean equals(Object o)\n       return false;\n     }\n \n+    if ((o instanceof GlobalTableDataSource || this instanceof GlobalTableDataSource) &&\n+        !getClass().equals(o.getClass())) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9d7a9b6fce0b4d8ba4f9e7f4321aa6eb24458f01"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDYwMTcwMA==", "bodyText": "Please add a test for nonequality with a TableDataSource of the same name.", "url": "https://github.com/apache/druid/pull/10020#discussion_r440601700", "createdAt": "2020-06-16T05:54:18Z", "author": {"login": "gianm"}, "path": "processing/src/test/java/org/apache/druid/query/GlobalTableDataSourceTest.java", "diffHunk": "@@ -0,0 +1,65 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.query;\n+\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import nl.jqno.equalsverifier.EqualsVerifier;\n+import org.apache.druid.segment.TestHelper;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class GlobalTableDataSourceTest\n+{\n+  private static final GlobalTableDataSource GLOBAL_TABLE_DATA_SOURCE = new GlobalTableDataSource(\"foo\");\n+\n+  @Test\n+  public void testEquals()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9d7a9b6fce0b4d8ba4f9e7f4321aa6eb24458f01"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDYwMjEwNA==", "bodyText": "broadcastDataSources is more consistent spelling. Please add a comment too.", "url": "https://github.com/apache/druid/pull/10020#discussion_r440602104", "createdAt": "2020-06-16T05:55:22Z", "author": {"login": "gianm"}, "path": "sql/src/main/java/org/apache/druid/sql/calcite/schema/DruidSchema.java", "diffHunk": "@@ -122,6 +128,8 @@\n   // All dataSources that need tables regenerated.\n   private final Set<String> dataSourcesNeedingRebuild = new HashSet<>();\n \n+  private final Set<String> broadcastDatasources = new HashSet<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9d7a9b6fce0b4d8ba4f9e7f4321aa6eb24458f01"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDYwMjYyNw==", "bodyText": "Why not do this as part of the loop in the main thread?", "url": "https://github.com/apache/druid/pull/10020#discussion_r440602627", "createdAt": "2020-06-16T05:57:07Z", "author": {"login": "gianm"}, "path": "sql/src/main/java/org/apache/druid/sql/calcite/schema/DruidSchema.java", "diffHunk": "@@ -196,119 +207,132 @@ public DruidSchema(\n   public void start() throws InterruptedException\n   {\n     cacheExec.submit(\n-        new Runnable()\n-        {\n-          @Override\n-          public void run()\n-          {\n-            try {\n-              while (!Thread.currentThread().isInterrupted()) {\n-                final Set<SegmentId> segmentsToRefresh = new TreeSet<>();\n-                final Set<String> dataSourcesToRebuild = new TreeSet<>();\n-\n-                try {\n-                  synchronized (lock) {\n-                    final long nextRefreshNoFuzz = DateTimes\n-                        .utc(lastRefresh)\n-                        .plus(config.getMetadataRefreshPeriod())\n-                        .getMillis();\n-\n-                    // Fuzz a bit to spread load out when we have multiple brokers.\n-                    final long nextRefresh = nextRefreshNoFuzz + (long) ((nextRefreshNoFuzz - lastRefresh) * 0.10);\n-\n-                    while (true) {\n-                      // Do not refresh if it's too soon after a failure (to avoid rapid cycles of failure).\n-                      final boolean wasRecentFailure = DateTimes.utc(lastFailure)\n-                                                                .plus(config.getMetadataRefreshPeriod())\n-                                                                .isAfterNow();\n-\n-                      if (isServerViewInitialized &&\n-                          !wasRecentFailure &&\n-                          (!segmentsNeedingRefresh.isEmpty() || !dataSourcesNeedingRebuild.isEmpty()) &&\n-                          (refreshImmediately || nextRefresh < System.currentTimeMillis())) {\n-                        // We need to do a refresh. Break out of the waiting loop.\n-                        break;\n-                      }\n-\n-                      if (isServerViewInitialized) {\n-                        // Server view is initialized, but we don't need to do a refresh. Could happen if there are\n-                        // no segments in the system yet. Just mark us as initialized, then.\n-                        initialized.countDown();\n-                      }\n-\n-                      // Wait some more, we'll wake up when it might be time to do another refresh.\n-                      lock.wait(Math.max(1, nextRefresh - System.currentTimeMillis()));\n+        () -> {\n+          try {\n+            while (!Thread.currentThread().isInterrupted()) {\n+              final Set<SegmentId> segmentsToRefresh = new TreeSet<>();\n+              final Set<String> dataSourcesToRebuild = new TreeSet<>();\n+\n+              try {\n+                synchronized (lock) {\n+                  final long nextRefreshNoFuzz = DateTimes\n+                      .utc(lastRefresh)\n+                      .plus(config.getMetadataRefreshPeriod())\n+                      .getMillis();\n+\n+                  // Fuzz a bit to spread load out when we have multiple brokers.\n+                  final long nextRefresh = nextRefreshNoFuzz + (long) ((nextRefreshNoFuzz - lastRefresh) * 0.10);\n+\n+                  while (true) {\n+                    // Do not refresh if it's too soon after a failure (to avoid rapid cycles of failure).\n+                    final boolean wasRecentFailure = DateTimes.utc(lastFailure)\n+                                                              .plus(config.getMetadataRefreshPeriod())\n+                                                              .isAfterNow();\n+\n+                    if (isServerViewInitialized &&\n+                        !wasRecentFailure &&\n+                        (!segmentsNeedingRefresh.isEmpty() || !dataSourcesNeedingRebuild.isEmpty()) &&\n+                        (refreshImmediately || nextRefresh < System.currentTimeMillis())) {\n+                      // We need to do a refresh. Break out of the waiting loop.\n+                      break;\n                     }\n \n-                    segmentsToRefresh.addAll(segmentsNeedingRefresh);\n-                    segmentsNeedingRefresh.clear();\n-\n-                    // Mutable segments need a refresh every period, since new columns could be added dynamically.\n-                    segmentsNeedingRefresh.addAll(mutableSegments);\n+                    if (isServerViewInitialized) {\n+                      // Server view is initialized, but we don't need to do a refresh. Could happen if there are\n+                      // no segments in the system yet. Just mark us as initialized, then.\n+                      initialized.countDown();\n+                    }\n \n-                    lastFailure = 0L;\n-                    lastRefresh = System.currentTimeMillis();\n-                    refreshImmediately = false;\n+                    // Wait some more, we'll wake up when it might be time to do another refresh.\n+                    lock.wait(Math.max(1, nextRefresh - System.currentTimeMillis()));\n                   }\n \n-                  // Refresh the segments.\n-                  final Set<SegmentId> refreshed = refreshSegments(segmentsToRefresh);\n+                  segmentsToRefresh.addAll(segmentsNeedingRefresh);\n+                  segmentsNeedingRefresh.clear();\n \n-                  synchronized (lock) {\n-                    // Add missing segments back to the refresh list.\n-                    segmentsNeedingRefresh.addAll(Sets.difference(segmentsToRefresh, refreshed));\n+                  // Mutable segments need a refresh every period, since new columns could be added dynamically.\n+                  segmentsNeedingRefresh.addAll(mutableSegments);\n \n-                    // Compute the list of dataSources to rebuild tables for.\n-                    dataSourcesToRebuild.addAll(dataSourcesNeedingRebuild);\n-                    refreshed.forEach(segment -> dataSourcesToRebuild.add(segment.getDataSource()));\n-                    dataSourcesNeedingRebuild.clear();\n+                  lastFailure = 0L;\n+                  lastRefresh = System.currentTimeMillis();\n+                  refreshImmediately = false;\n+                }\n \n-                    lock.notifyAll();\n-                  }\n+                // Refresh the segments.\n+                final Set<SegmentId> refreshed = refreshSegments(segmentsToRefresh);\n \n-                  // Rebuild the dataSources.\n-                  for (String dataSource : dataSourcesToRebuild) {\n-                    final DruidTable druidTable = buildDruidTable(dataSource);\n-                    final DruidTable oldTable = tables.put(dataSource, druidTable);\n-                    if (oldTable == null || !oldTable.getRowSignature().equals(druidTable.getRowSignature())) {\n-                      log.info(\"dataSource [%s] has new signature: %s.\", dataSource, druidTable.getRowSignature());\n-                    } else {\n-                      log.debug(\"dataSource [%s] signature is unchanged.\", dataSource);\n-                    }\n-                  }\n+                synchronized (lock) {\n+                  // Add missing segments back to the refresh list.\n+                  segmentsNeedingRefresh.addAll(Sets.difference(segmentsToRefresh, refreshed));\n \n-                  initialized.countDown();\n-                }\n-                catch (InterruptedException e) {\n-                  // Fall through.\n-                  throw e;\n+                  // Compute the list of dataSources to rebuild tables for.\n+                  dataSourcesToRebuild.addAll(dataSourcesNeedingRebuild);\n+                  refreshed.forEach(segment -> dataSourcesToRebuild.add(segment.getDataSource()));\n+                  dataSourcesNeedingRebuild.clear();\n+\n+                  lock.notifyAll();\n                 }\n-                catch (Exception e) {\n-                  log.warn(e, \"Metadata refresh failed, trying again soon.\");\n-\n-                  synchronized (lock) {\n-                    // Add our segments and dataSources back to their refresh and rebuild lists.\n-                    segmentsNeedingRefresh.addAll(segmentsToRefresh);\n-                    dataSourcesNeedingRebuild.addAll(dataSourcesToRebuild);\n-                    lastFailure = System.currentTimeMillis();\n-                    lock.notifyAll();\n+\n+                // Rebuild the dataSources.\n+                for (String dataSource : dataSourcesToRebuild) {\n+                  final DruidTable druidTable = buildDruidTable(dataSource);\n+                  final DruidTable oldTable = tables.put(dataSource, druidTable);\n+                  if (oldTable == null || !oldTable.getRowSignature().equals(druidTable.getRowSignature())) {\n+                    log.info(\"dataSource [%s] has new signature: %s.\", dataSource, druidTable.getRowSignature());\n+                  } else {\n+                    log.debug(\"dataSource [%s] signature is unchanged.\", dataSource);\n                   }\n                 }\n+\n+                initialized.countDown();\n+              }\n+              catch (InterruptedException e) {\n+                // Fall through.\n+                throw e;\n+              }\n+              catch (Exception e) {\n+                log.warn(e, \"Metadata refresh failed, trying again soon.\");\n+\n+                synchronized (lock) {\n+                  // Add our segments and dataSources back to their refresh and rebuild lists.\n+                  segmentsNeedingRefresh.addAll(segmentsToRefresh);\n+                  dataSourcesNeedingRebuild.addAll(dataSourcesToRebuild);\n+                  lastFailure = System.currentTimeMillis();\n+                  lock.notifyAll();\n+                }\n               }\n-            }\n-            catch (InterruptedException e) {\n-              // Just exit.\n-            }\n-            catch (Throwable e) {\n-              // Throwables that fall out to here (not caught by an inner try/catch) are potentially gnarly, like\n-              // OOMEs. Anyway, let's just emit an alert and stop refreshing metadata.\n-              log.makeAlert(e, \"Metadata refresh failed permanently\").emit();\n-              throw e;\n-            }\n-            finally {\n-              log.info(\"Metadata refresh stopped.\");\n             }\n           }\n+          catch (InterruptedException e) {\n+            // Just exit.\n+          }\n+          catch (Throwable e) {\n+            // Throwables that fall out to here (not caught by an inner try/catch) are potentially gnarly, like\n+            // OOMEs. Anyway, let's just emit an alert and stop refreshing metadata.\n+            log.makeAlert(e, \"Metadata refresh failed permanently\").emit();\n+            throw e;\n+          }\n+          finally {\n+            log.info(\"Metadata refresh stopped.\");\n+          }\n+        }\n+    );\n+\n+    ScheduledExecutors.scheduleWithFixedDelay(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9d7a9b6fce0b4d8ba4f9e7f4321aa6eb24458f01"}, "originalPosition": 283}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDYwMjc1NA==", "bodyText": "Why do we need to rebuild them all continuously?", "url": "https://github.com/apache/druid/pull/10020#discussion_r440602754", "createdAt": "2020-06-16T05:57:31Z", "author": {"login": "gianm"}, "path": "sql/src/main/java/org/apache/druid/sql/calcite/schema/DruidSchema.java", "diffHunk": "@@ -196,119 +207,132 @@ public DruidSchema(\n   public void start() throws InterruptedException\n   {\n     cacheExec.submit(\n-        new Runnable()\n-        {\n-          @Override\n-          public void run()\n-          {\n-            try {\n-              while (!Thread.currentThread().isInterrupted()) {\n-                final Set<SegmentId> segmentsToRefresh = new TreeSet<>();\n-                final Set<String> dataSourcesToRebuild = new TreeSet<>();\n-\n-                try {\n-                  synchronized (lock) {\n-                    final long nextRefreshNoFuzz = DateTimes\n-                        .utc(lastRefresh)\n-                        .plus(config.getMetadataRefreshPeriod())\n-                        .getMillis();\n-\n-                    // Fuzz a bit to spread load out when we have multiple brokers.\n-                    final long nextRefresh = nextRefreshNoFuzz + (long) ((nextRefreshNoFuzz - lastRefresh) * 0.10);\n-\n-                    while (true) {\n-                      // Do not refresh if it's too soon after a failure (to avoid rapid cycles of failure).\n-                      final boolean wasRecentFailure = DateTimes.utc(lastFailure)\n-                                                                .plus(config.getMetadataRefreshPeriod())\n-                                                                .isAfterNow();\n-\n-                      if (isServerViewInitialized &&\n-                          !wasRecentFailure &&\n-                          (!segmentsNeedingRefresh.isEmpty() || !dataSourcesNeedingRebuild.isEmpty()) &&\n-                          (refreshImmediately || nextRefresh < System.currentTimeMillis())) {\n-                        // We need to do a refresh. Break out of the waiting loop.\n-                        break;\n-                      }\n-\n-                      if (isServerViewInitialized) {\n-                        // Server view is initialized, but we don't need to do a refresh. Could happen if there are\n-                        // no segments in the system yet. Just mark us as initialized, then.\n-                        initialized.countDown();\n-                      }\n-\n-                      // Wait some more, we'll wake up when it might be time to do another refresh.\n-                      lock.wait(Math.max(1, nextRefresh - System.currentTimeMillis()));\n+        () -> {\n+          try {\n+            while (!Thread.currentThread().isInterrupted()) {\n+              final Set<SegmentId> segmentsToRefresh = new TreeSet<>();\n+              final Set<String> dataSourcesToRebuild = new TreeSet<>();\n+\n+              try {\n+                synchronized (lock) {\n+                  final long nextRefreshNoFuzz = DateTimes\n+                      .utc(lastRefresh)\n+                      .plus(config.getMetadataRefreshPeriod())\n+                      .getMillis();\n+\n+                  // Fuzz a bit to spread load out when we have multiple brokers.\n+                  final long nextRefresh = nextRefreshNoFuzz + (long) ((nextRefreshNoFuzz - lastRefresh) * 0.10);\n+\n+                  while (true) {\n+                    // Do not refresh if it's too soon after a failure (to avoid rapid cycles of failure).\n+                    final boolean wasRecentFailure = DateTimes.utc(lastFailure)\n+                                                              .plus(config.getMetadataRefreshPeriod())\n+                                                              .isAfterNow();\n+\n+                    if (isServerViewInitialized &&\n+                        !wasRecentFailure &&\n+                        (!segmentsNeedingRefresh.isEmpty() || !dataSourcesNeedingRebuild.isEmpty()) &&\n+                        (refreshImmediately || nextRefresh < System.currentTimeMillis())) {\n+                      // We need to do a refresh. Break out of the waiting loop.\n+                      break;\n                     }\n \n-                    segmentsToRefresh.addAll(segmentsNeedingRefresh);\n-                    segmentsNeedingRefresh.clear();\n-\n-                    // Mutable segments need a refresh every period, since new columns could be added dynamically.\n-                    segmentsNeedingRefresh.addAll(mutableSegments);\n+                    if (isServerViewInitialized) {\n+                      // Server view is initialized, but we don't need to do a refresh. Could happen if there are\n+                      // no segments in the system yet. Just mark us as initialized, then.\n+                      initialized.countDown();\n+                    }\n \n-                    lastFailure = 0L;\n-                    lastRefresh = System.currentTimeMillis();\n-                    refreshImmediately = false;\n+                    // Wait some more, we'll wake up when it might be time to do another refresh.\n+                    lock.wait(Math.max(1, nextRefresh - System.currentTimeMillis()));\n                   }\n \n-                  // Refresh the segments.\n-                  final Set<SegmentId> refreshed = refreshSegments(segmentsToRefresh);\n+                  segmentsToRefresh.addAll(segmentsNeedingRefresh);\n+                  segmentsNeedingRefresh.clear();\n \n-                  synchronized (lock) {\n-                    // Add missing segments back to the refresh list.\n-                    segmentsNeedingRefresh.addAll(Sets.difference(segmentsToRefresh, refreshed));\n+                  // Mutable segments need a refresh every period, since new columns could be added dynamically.\n+                  segmentsNeedingRefresh.addAll(mutableSegments);\n \n-                    // Compute the list of dataSources to rebuild tables for.\n-                    dataSourcesToRebuild.addAll(dataSourcesNeedingRebuild);\n-                    refreshed.forEach(segment -> dataSourcesToRebuild.add(segment.getDataSource()));\n-                    dataSourcesNeedingRebuild.clear();\n+                  lastFailure = 0L;\n+                  lastRefresh = System.currentTimeMillis();\n+                  refreshImmediately = false;\n+                }\n \n-                    lock.notifyAll();\n-                  }\n+                // Refresh the segments.\n+                final Set<SegmentId> refreshed = refreshSegments(segmentsToRefresh);\n \n-                  // Rebuild the dataSources.\n-                  for (String dataSource : dataSourcesToRebuild) {\n-                    final DruidTable druidTable = buildDruidTable(dataSource);\n-                    final DruidTable oldTable = tables.put(dataSource, druidTable);\n-                    if (oldTable == null || !oldTable.getRowSignature().equals(druidTable.getRowSignature())) {\n-                      log.info(\"dataSource [%s] has new signature: %s.\", dataSource, druidTable.getRowSignature());\n-                    } else {\n-                      log.debug(\"dataSource [%s] signature is unchanged.\", dataSource);\n-                    }\n-                  }\n+                synchronized (lock) {\n+                  // Add missing segments back to the refresh list.\n+                  segmentsNeedingRefresh.addAll(Sets.difference(segmentsToRefresh, refreshed));\n \n-                  initialized.countDown();\n-                }\n-                catch (InterruptedException e) {\n-                  // Fall through.\n-                  throw e;\n+                  // Compute the list of dataSources to rebuild tables for.\n+                  dataSourcesToRebuild.addAll(dataSourcesNeedingRebuild);\n+                  refreshed.forEach(segment -> dataSourcesToRebuild.add(segment.getDataSource()));\n+                  dataSourcesNeedingRebuild.clear();\n+\n+                  lock.notifyAll();\n                 }\n-                catch (Exception e) {\n-                  log.warn(e, \"Metadata refresh failed, trying again soon.\");\n-\n-                  synchronized (lock) {\n-                    // Add our segments and dataSources back to their refresh and rebuild lists.\n-                    segmentsNeedingRefresh.addAll(segmentsToRefresh);\n-                    dataSourcesNeedingRebuild.addAll(dataSourcesToRebuild);\n-                    lastFailure = System.currentTimeMillis();\n-                    lock.notifyAll();\n+\n+                // Rebuild the dataSources.\n+                for (String dataSource : dataSourcesToRebuild) {\n+                  final DruidTable druidTable = buildDruidTable(dataSource);\n+                  final DruidTable oldTable = tables.put(dataSource, druidTable);\n+                  if (oldTable == null || !oldTable.getRowSignature().equals(druidTable.getRowSignature())) {\n+                    log.info(\"dataSource [%s] has new signature: %s.\", dataSource, druidTable.getRowSignature());\n+                  } else {\n+                    log.debug(\"dataSource [%s] signature is unchanged.\", dataSource);\n                   }\n                 }\n+\n+                initialized.countDown();\n+              }\n+              catch (InterruptedException e) {\n+                // Fall through.\n+                throw e;\n+              }\n+              catch (Exception e) {\n+                log.warn(e, \"Metadata refresh failed, trying again soon.\");\n+\n+                synchronized (lock) {\n+                  // Add our segments and dataSources back to their refresh and rebuild lists.\n+                  segmentsNeedingRefresh.addAll(segmentsToRefresh);\n+                  dataSourcesNeedingRebuild.addAll(dataSourcesToRebuild);\n+                  lastFailure = System.currentTimeMillis();\n+                  lock.notifyAll();\n+                }\n               }\n-            }\n-            catch (InterruptedException e) {\n-              // Just exit.\n-            }\n-            catch (Throwable e) {\n-              // Throwables that fall out to here (not caught by an inner try/catch) are potentially gnarly, like\n-              // OOMEs. Anyway, let's just emit an alert and stop refreshing metadata.\n-              log.makeAlert(e, \"Metadata refresh failed permanently\").emit();\n-              throw e;\n-            }\n-            finally {\n-              log.info(\"Metadata refresh stopped.\");\n             }\n           }\n+          catch (InterruptedException e) {\n+            // Just exit.\n+          }\n+          catch (Throwable e) {\n+            // Throwables that fall out to here (not caught by an inner try/catch) are potentially gnarly, like\n+            // OOMEs. Anyway, let's just emit an alert and stop refreshing metadata.\n+            log.makeAlert(e, \"Metadata refresh failed permanently\").emit();\n+            throw e;\n+          }\n+          finally {\n+            log.info(\"Metadata refresh stopped.\");\n+          }\n+        }\n+    );\n+\n+    ScheduledExecutors.scheduleWithFixedDelay(\n+        localSegmentExec,\n+        config.getMetadataRefreshPeriod().toStandardDuration(),\n+        config.getMetadataRefreshPeriod().toStandardDuration(),\n+        () -> {\n+          synchronized (lock) {\n+            // refresh known broadcast segments. Since DruidSchema is only present on the broker, any segment we have\n+            // locally in the SegmentManager must be broadcast datasources. This could potentially be replaced in the\n+            // future by fetching load rules from the coordinator\n+            Set<String> localSegmentDatasources = segmentManager.getDataSourceNames();\n+            dataSourcesNeedingRebuild.addAll(localSegmentDatasources);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9d7a9b6fce0b4d8ba4f9e7f4321aa6eb24458f01"}, "originalPosition": 293}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDYwMzI4NQ==", "bodyText": "tiny nit: the logic is laid out a bit weirdly here; it'd make more sense to emphasize what's different by having the dataSource be created in the if block, but the DruidTable created outside of it.", "url": "https://github.com/apache/druid/pull/10020#discussion_r440603285", "createdAt": "2020-06-16T05:59:17Z", "author": {"login": "gianm"}, "path": "sql/src/main/java/org/apache/druid/sql/calcite/schema/DruidSchema.java", "diffHunk": "@@ -616,6 +631,12 @@ private DruidTable buildDruidTable(final String dataSource)\n \n       final RowSignature.Builder builder = RowSignature.builder();\n       columnTypes.forEach(builder::add);\n+      if (broadcastDatasources.contains(dataSource)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9d7a9b6fce0b4d8ba4f9e7f4321aa6eb24458f01"}, "originalPosition": 346}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDYwMzQ5Ng==", "bodyText": "This should be @GuardedBy(\"lock\"), and so should dataSourcesNeedingRebuild, mutableSegments, segmentsNeedingRefresh, refreshImmediately, lastRefresh, lastFailure, and isServerViewInitialized.\nCould you please add those, and also remove the comment on lock, which is woefully out of date. (Thanks in advance for the housekeeping work.)", "url": "https://github.com/apache/druid/pull/10020#discussion_r440603496", "createdAt": "2020-06-16T05:59:56Z", "author": {"login": "gianm"}, "path": "sql/src/main/java/org/apache/druid/sql/calcite/schema/DruidSchema.java", "diffHunk": "@@ -122,6 +128,8 @@\n   // All dataSources that need tables regenerated.\n   private final Set<String> dataSourcesNeedingRebuild = new HashSet<>();\n \n+  private final Set<String> broadcastDatasources = new HashSet<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDYwMjEwNA=="}, "originalCommit": {"oid": "9d7a9b6fce0b4d8ba4f9e7f4321aa6eb24458f01"}, "originalPosition": 46}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7c5067460dd691ba3e090af67fa6da8fe05e3ddc", "author": {"user": {"login": "clintropolis", "name": "Clint Wylie"}}, "url": "https://github.com/apache/druid/commit/7c5067460dd691ba3e090af67fa6da8fe05e3ddc", "committedDate": "2020-06-16T12:18:59Z", "message": "review stuffs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a7d3443c55b9c76d914b9e3f49f85f3911462937", "author": {"user": {"login": "clintropolis", "name": "Clint Wylie"}}, "url": "https://github.com/apache/druid/commit/a7d3443c55b9c76d914b9e3f49f85f3911462937", "committedDate": "2020-06-16T21:41:12Z", "message": "Merge remote-tracking branch 'upstream/master' into global-table-for-broadcast-segments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5f0e4c2096540f70f3235567ae9e3c8399f61d57", "author": {"user": {"login": "clintropolis", "name": "Clint Wylie"}}, "url": "https://github.com/apache/druid/commit/5f0e4c2096540f70f3235567ae9e3c8399f61d57", "committedDate": "2020-06-16T21:46:19Z", "message": "use generated equals and hashcode"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMxOTg3ODk3", "url": "https://github.com/apache/druid/pull/10020#pullrequestreview-431987897", "createdAt": "2020-06-17T00:57:52Z", "commit": {"oid": "5f0e4c2096540f70f3235567ae9e3c8399f61d57"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2073, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}