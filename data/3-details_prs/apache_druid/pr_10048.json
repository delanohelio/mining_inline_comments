{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDM2MTY2NzAz", "number": 10048, "title": "Coordinator loadstatus API full format does not consider Broadcast rules", "bodyText": "Coordinator loadstatus API full format does not consider Broadcast rules\nDescription\nCoordinator loadstatus API full format does not consider Broadcast rules. Currently, this API only consider the normal load rules and does not return counts of segments that should be loaded under the Broadcast rules. This apply to both the coordinator loadstatus (/druid/coordinator/v1/loadstatus?full) and the new datasource loadstatus (/druid/coordinator/v1/datasources/{datasource}/loadstatus?full) since they share the same code path.\nThis PR has:\n\n been self-reviewed.\n added documentation for new or modified features or behaviors.\n added Javadocs for most classes and all non-trivial methods. Linked related entities via Javadoc links.\n added or updated version, license, or notice information in licenses.yaml\n added comments explaining the \"why\" and the intent of the code wherever would not be obvious for an unfamiliar reader.\n added unit tests or modified existing tests to cover new code paths, ensuring the threshold for code coverage is met.\n added integration tests.\n been tested in a test Druid cluster.", "createdAt": "2020-06-18T00:51:47Z", "url": "https://github.com/apache/druid/pull/10048", "merged": true, "mergeCommit": {"oid": "857e5204bf2e71b83da6eecb71105f4947bbd1d6"}, "closed": true, "closedAt": "2020-06-19T00:52:34Z", "author": {"login": "maytasm"}, "timelineItems": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcsTnyIAH2gAyNDM2MTY2NzAzOmZmZjFkODZhMjAzMDJhYWM5MDMwY2NmMzJiZDUwYWJmNzAzMzE3N2E=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcsoQARAFqTQzMzczNjQ0NQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "fff1d86a20302aac9030ccf32bd50abf7033177a", "author": {"user": {"login": "maytasm", "name": "Maytas Monsereenusorn"}}, "url": "https://github.com/apache/druid/commit/fff1d86a20302aac9030ccf32bd50abf7033177a", "committedDate": "2020-06-18T00:50:24Z", "message": "Coordinator loadstatus API full format does not consider Broadcast rules"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMzMDA5OTIy", "url": "https://github.com/apache/druid/pull/10048#pullrequestreview-433009922", "createdAt": "2020-06-18T07:28:23Z", "commit": {"oid": "fff1d86a20302aac9030ccf32bd50abf7033177a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQwNzoyODoyM1rOGli6lA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQwNzoyODoyM1rOGli6lA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjAyMjU0OA==", "bodyText": "It's probably worth making a method that takes a CountDownLatch and a DruidServer and does the thing going on here (and in a few other tests)", "url": "https://github.com/apache/druid/pull/10048#discussion_r442022548", "createdAt": "2020-06-18T07:28:23Z", "author": {"login": "clintropolis"}, "path": "server/src/test/java/org/apache/druid/server/coordinator/DruidCoordinatorTest.java", "diffHunk": "@@ -550,6 +551,241 @@ public void testCoordinatorTieredRun() throws Exception\n     EasyMock.verify(metadataRuleManager);\n   }\n \n+  @Test(timeout = 60_000L)\n+  public void testComputeUnderReplicationCountsPerDataSourcePerTierForSegmentsWithBroadcastRule() throws Exception\n+  {\n+    final String dataSource = \"dataSource\";\n+    final String hotTierName = \"hot\";\n+    final String coldTierName = \"cold\";\n+    final String tierName1 = \"tier1\";\n+    final String tierName2 = \"tier2\";\n+    final Rule broadcastDistributionRule = new ForeverBroadcastDistributionRule();\n+    final String loadPathCold = \"/druid/loadqueue/cold:1234\";\n+    final String loadPathBroker1 = \"/druid/loadqueue/broker1:1234\";\n+    final String loadPathBroker2 = \"/druid/loadqueue/broker2:1234\";\n+    final String loadPathPeon = \"/druid/loadqueue/peon:1234\";\n+    final DruidServer hotServer = new DruidServer(\"hot\", \"hot\", null, 5L, ServerType.HISTORICAL, hotTierName, 0);\n+    final DruidServer coldServer = new DruidServer(\"cold\", \"cold\", null, 5L, ServerType.HISTORICAL, coldTierName, 0);\n+    final DruidServer brokerServer1 = new DruidServer(\"broker1\", \"broker1\", null, 5L, ServerType.BROKER, tierName1, 0);\n+    final DruidServer brokerServer2 = new DruidServer(\"broker2\", \"broker2\", null, 5L, ServerType.BROKER, tierName2, 0);\n+    final DruidServer peonServer = new DruidServer(\"peon\", \"peon\", null, 5L, ServerType.INDEXER_EXECUTOR, tierName2, 0);\n+\n+    final Map<String, DataSegment> dataSegments = ImmutableMap.of(\n+        \"2018-01-02T00:00:00.000Z_2018-01-03T00:00:00.000Z\",\n+        new DataSegment(dataSource, Intervals.of(\"2018-01-02/P1D\"), \"v1\", null, null, null, null, 0x9, 0),\n+        \"2018-01-03T00:00:00.000Z_2018-01-04T00:00:00.000Z\",\n+        new DataSegment(dataSource, Intervals.of(\"2018-01-03/P1D\"), \"v1\", null, null, null, null, 0x9, 0),\n+        \"2017-01-01T00:00:00.000Z_2017-01-02T00:00:00.000Z\",\n+        new DataSegment(dataSource, Intervals.of(\"2017-01-01/P1D\"), \"v1\", null, null, null, null, 0x9, 0)\n+    );\n+\n+    final LoadQueuePeon loadQueuePeonCold = new CuratorLoadQueuePeon(\n+        curator,\n+        loadPathCold,\n+        objectMapper,\n+        Execs.scheduledSingleThreaded(\"coordinator_test_load_queue_peon_cold_scheduled-%d\"),\n+        Execs.singleThreaded(\"coordinator_test_load_queue_peon_cold-%d\"),\n+        druidCoordinatorConfig\n+    );\n+\n+    final LoadQueuePeon loadQueuePeonBroker1 = new CuratorLoadQueuePeon(\n+        curator,\n+        loadPathBroker1,\n+        objectMapper,\n+        Execs.scheduledSingleThreaded(\"coordinator_test_load_queue_peon_broker1_scheduled-%d\"),\n+        Execs.singleThreaded(\"coordinator_test_load_queue_peon_broker1-%d\"),\n+        druidCoordinatorConfig\n+    );\n+\n+    final LoadQueuePeon loadQueuePeonBroker2 = new CuratorLoadQueuePeon(\n+        curator,\n+        loadPathBroker2,\n+        objectMapper,\n+        Execs.scheduledSingleThreaded(\"coordinator_test_load_queue_peon_broker2_scheduled-%d\"),\n+        Execs.singleThreaded(\"coordinator_test_load_queue_peon_broker2-%d\"),\n+        druidCoordinatorConfig\n+    );\n+\n+    final LoadQueuePeon loadQueuePeonPoenServer = new CuratorLoadQueuePeon(\n+        curator,\n+        loadPathPeon,\n+        objectMapper,\n+        Execs.scheduledSingleThreaded(\"coordinator_test_load_queue_peon_peon_scheduled-%d\"),\n+        Execs.singleThreaded(\"coordinator_test_load_queue_peon_peon-%d\"),\n+        druidCoordinatorConfig\n+    );\n+    final PathChildrenCache pathChildrenCacheCold = new PathChildrenCache(\n+        curator,\n+        loadPathCold,\n+        true,\n+        true,\n+        Execs.singleThreaded(\"coordinator_test_path_children_cache_cold-%d\")\n+    );\n+    final PathChildrenCache pathChildrenCacheBroker1 = new PathChildrenCache(\n+        curator,\n+        loadPathBroker1,\n+        true,\n+        true,\n+        Execs.singleThreaded(\"coordinator_test_path_children_cache_broker1-%d\")\n+    );\n+    final PathChildrenCache pathChildrenCacheBroker2 = new PathChildrenCache(\n+        curator,\n+        loadPathBroker2,\n+        true,\n+        true,\n+        Execs.singleThreaded(\"coordinator_test_path_children_cache_broker2-%d\")\n+    );\n+    final PathChildrenCache pathChildrenCachePeon = new PathChildrenCache(\n+        curator,\n+        loadPathPeon,\n+        true,\n+        true,\n+        Execs.singleThreaded(\"coordinator_test_path_children_cache_peon-%d\")\n+    );\n+\n+    loadManagementPeons.putAll(ImmutableMap.of(\"hot\", loadQueuePeon,\n+                                               \"cold\", loadQueuePeonCold,\n+                                               \"broker1\", loadQueuePeonBroker1,\n+                                               \"broker2\", loadQueuePeonBroker2,\n+                                               \"peon\", loadQueuePeonPoenServer));\n+\n+    loadQueuePeonCold.start();\n+    loadQueuePeonBroker1.start();\n+    loadQueuePeonBroker2.start();\n+    loadQueuePeonPoenServer.start();\n+    pathChildrenCache.start();\n+    pathChildrenCacheCold.start();\n+    pathChildrenCacheBroker1.start();\n+    pathChildrenCacheBroker2.start();\n+    pathChildrenCachePeon.start();\n+\n+    DruidDataSource[] druidDataSources = {new DruidDataSource(dataSource, Collections.emptyMap())};\n+    dataSegments.values().forEach(druidDataSources[0]::addSegment);\n+\n+    setupSegmentsMetadataMock(druidDataSources[0]);\n+\n+    EasyMock.expect(metadataRuleManager.getRulesWithDefault(EasyMock.anyString()))\n+            .andReturn(ImmutableList.of(broadcastDistributionRule)).atLeastOnce();\n+    EasyMock.expect(metadataRuleManager.getAllRules())\n+            .andReturn(ImmutableMap.of(dataSource, ImmutableList.of(broadcastDistributionRule))).atLeastOnce();\n+\n+    EasyMock.expect(serverInventoryView.getInventory())\n+            .andReturn(ImmutableList.of(hotServer, coldServer, brokerServer1, brokerServer2, peonServer))\n+            .atLeastOnce();\n+    EasyMock.expect(serverInventoryView.isStarted()).andReturn(true).anyTimes();\n+\n+    EasyMock.replay(metadataRuleManager, serverInventoryView);\n+\n+    coordinator.start();\n+    leaderAnnouncerLatch.await(); // Wait for this coordinator to become leader\n+\n+    final CountDownLatch assignSegmentLatchHot = new CountDownLatch(1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fff1d86a20302aac9030ccf32bd50abf7033177a"}, "originalPosition": 140}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bb005677a9408157414236c664eb6f4a8e285626", "author": {"user": {"login": "maytasm", "name": "Maytas Monsereenusorn"}}, "url": "https://github.com/apache/druid/commit/bb005677a9408157414236c664eb6f4a8e285626", "committedDate": "2020-06-18T08:47:24Z", "message": "address comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f87ca9f325e8551b8f8037b5ffc283e8b0ab53cf", "author": {"user": {"login": "maytasm", "name": "Maytas Monsereenusorn"}}, "url": "https://github.com/apache/druid/commit/f87ca9f325e8551b8f8037b5ffc283e8b0ab53cf", "committedDate": "2020-06-18T08:50:23Z", "message": "fix checkstyle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "95e84176a929717500d79ccaa92814ce1d04034d", "author": {"user": {"login": "maytasm", "name": "Maytas Monsereenusorn"}}, "url": "https://github.com/apache/druid/commit/95e84176a929717500d79ccaa92814ce1d04034d", "committedDate": "2020-06-18T08:59:31Z", "message": "minor optimization"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMzNTM0ODEz", "url": "https://github.com/apache/druid/pull/10048#pullrequestreview-433534813", "createdAt": "2020-06-18T18:18:06Z", "commit": {"oid": "95e84176a929717500d79ccaa92814ce1d04034d"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQxODoxODowNlrOGl67cw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xOFQxODoxODoxMFrOGl67og==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQxNTk4Nw==", "bodyText": "In a previous PR there was a discussion about why it's ok for segmentReplicantLookup to be stale in this method:  https://github.com/apache/druid/pull/9965/files#r440541949\nWhat do you think about having that explanation as a code comment for this method?", "url": "https://github.com/apache/druid/pull/10048#discussion_r442415987", "createdAt": "2020-06-18T18:18:06Z", "author": {"login": "ccaominh"}, "path": "server/src/main/java/org/apache/druid/server/coordinator/DruidCoordinator.java", "diffHunk": "@@ -269,6 +270,13 @@ public boolean isLeader()\n   )\n   {\n     final Map<String, Object2LongMap<String>> underReplicationCountsPerDataSourcePerTier = new HashMap<>();\n+    final Set<String> decommissioningServers = getDynamicConfigs().getDecommissioningNodes();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "95e84176a929717500d79ccaa92814ce1d04034d"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MjQxNjAzNA==", "bodyText": "If Rule subclasses are added in the future and should be considered in this method, is there a test that will fail?", "url": "https://github.com/apache/druid/pull/10048#discussion_r442416034", "createdAt": "2020-06-18T18:18:10Z", "author": {"login": "ccaominh"}, "path": "server/src/main/java/org/apache/druid/server/coordinator/DruidCoordinator.java", "diffHunk": "@@ -280,20 +288,38 @@ public boolean isLeader()\n       final List<Rule> rules = metadataRuleManager.getRulesWithDefault(segment.getDataSource());\n \n       for (final Rule rule : rules) {\n-        if (!(rule instanceof LoadRule && rule.appliesTo(segment, now))) {\n+        if (!rule.appliesTo(segment, now)) {\n           continue;\n         }\n \n-        ((LoadRule) rule)\n-            .getTieredReplicants()\n-            .forEach((final String tier, final Integer ruleReplicants) -> {\n-              int currentReplicants = segmentReplicantLookup.getLoadedReplicants(segment.getId(), tier);\n-              Object2LongMap<String> underReplicationPerDataSource = underReplicationCountsPerDataSourcePerTier\n-                  .computeIfAbsent(tier, ignored -> new Object2LongOpenHashMap<>());\n+        if (rule instanceof LoadRule) {\n+          ((LoadRule) rule)\n+              .getTieredReplicants()\n+              .forEach((final String tier, final Integer ruleReplicants) -> {\n+                int currentReplicants = segmentReplicantLookup.getLoadedReplicants(segment.getId(), tier);\n+                Object2LongMap<String> underReplicationPerDataSource = underReplicationCountsPerDataSourcePerTier\n+                    .computeIfAbsent(tier, ignored -> new Object2LongOpenHashMap<>());\n+                ((Object2LongOpenHashMap<String>) underReplicationPerDataSource)\n+                    .addTo(segment.getDataSource(), Math.max(ruleReplicants - currentReplicants, 0));\n+              });\n+        }\n+\n+        if (rule instanceof BroadcastDistributionRule) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "95e84176a929717500d79ccaa92814ce1d04034d"}, "originalPosition": 49}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2eced94566472e7aa75172dd9023a863664809fe", "author": {"user": {"login": "maytasm", "name": "Maytas Monsereenusorn"}}, "url": "https://github.com/apache/druid/commit/2eced94566472e7aa75172dd9023a863664809fe", "committedDate": "2020-06-18T19:11:14Z", "message": "address comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMzNzAxNDQ3", "url": "https://github.com/apache/druid/pull/10048#pullrequestreview-433701447", "createdAt": "2020-06-18T23:01:05Z", "commit": {"oid": "2eced94566472e7aa75172dd9023a863664809fe"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMzNzAyMDE3", "url": "https://github.com/apache/druid/pull/10048#pullrequestreview-433702017", "createdAt": "2020-06-18T23:02:47Z", "commit": {"oid": "2eced94566472e7aa75172dd9023a863664809fe"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMzNzM2NDQ1", "url": "https://github.com/apache/druid/pull/10048#pullrequestreview-433736445", "createdAt": "2020-06-19T00:52:26Z", "commit": {"oid": "2eced94566472e7aa75172dd9023a863664809fe"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2120, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}