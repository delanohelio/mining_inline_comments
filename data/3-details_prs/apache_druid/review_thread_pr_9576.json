{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzk1MDQwMjEw", "number": 9576, "reviewThreads": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxNjo0Njo1N1rODtMm3g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwMzo0NDozOVrODtXYDQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4NzE5MDcwOnYy", "diffSide": "RIGHT", "path": "integration-tests/README.md", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxNjo0Njo1N1rOF-e4DQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxNjo0Njo1N1rOF-e4DQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTA2MTkwMQ==", "bodyText": "\ud83c\udf89", "url": "https://github.com/apache/druid/pull/9576#discussion_r401061901", "createdAt": "2020-03-31T16:46:57Z", "author": {"login": "suneet-s"}, "path": "integration-tests/README.md", "diffHunk": "@@ -68,6 +68,21 @@ can either be 8 or 11.\n Druid's configuration (using Docker) can be overrided by providing -Doverride.config.path=<PATH_TO_FILE>. \n The file must contain one property per line, the key must start with `druid_` and the format should be snake case. \n \n+## Debugging Druid while running tests", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d7637d53ff7fdee5ff28b15c49178b176bbf3a39"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4NzIwNDE3OnYy", "diffSide": "RIGHT", "path": "integration-tests/docker/tls/generate-server-certs-and-keystores.sh", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxNjo1MDowOFrOF-fAiQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMDowNzoyMFrOF_W7KA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTA2NDA3Mw==", "bodyText": "nit: No need to change if everything else looks good. If I saw the log line as is, it's a little ambiguous - which script? what's the impact of skipping running again?\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              echo \"Script was ran already. Skip running again.\"\n          \n          \n            \n              echo \"Using existing tls keys since /tls/server.key exists - skipping generation of all certs. To generate certs, delete this file\"", "url": "https://github.com/apache/druid/pull/9576#discussion_r401064073", "createdAt": "2020-03-31T16:50:08Z", "author": {"login": "suneet-s"}, "path": "integration-tests/docker/tls/generate-server-certs-and-keystores.sh", "diffHunk": "@@ -17,6 +17,12 @@\n \n cd /tls\n \n+FILE_CHECK_IF_RAN=/tls/server.key\n+if [ -f \"$FILE_CHECK_IF_RAN\" ]; then\n+  echo \"Script was ran already. Skip running again.\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d7637d53ff7fdee5ff28b15c49178b176bbf3a39"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTk4MDIwMA==", "bodyText": "Done", "url": "https://github.com/apache/druid/pull/9576#discussion_r401980200", "createdAt": "2020-04-02T00:07:20Z", "author": {"login": "maytasm"}, "path": "integration-tests/docker/tls/generate-server-certs-and-keystores.sh", "diffHunk": "@@ -17,6 +17,12 @@\n \n cd /tls\n \n+FILE_CHECK_IF_RAN=/tls/server.key\n+if [ -f \"$FILE_CHECK_IF_RAN\" ]; then\n+  echo \"Script was ran already. Skip running again.\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTA2NDA3Mw=="}, "originalCommit": {"oid": "d7637d53ff7fdee5ff28b15c49178b176bbf3a39"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4ODg3NjMyOnYy", "diffSide": "RIGHT", "path": "integration-tests/README.md", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwMjo1NDo1N1rOF-vF9w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMDoxMDowOVrOF_W-wA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMyNzYwNw==", "bodyText": "Looks like something from a conflict", "url": "https://github.com/apache/druid/pull/9576#discussion_r401327607", "createdAt": "2020-04-01T02:54:57Z", "author": {"login": "jon-wei"}, "path": "integration-tests/README.md", "diffHunk": "@@ -107,6 +122,7 @@ Then run the tests using a command similar to:\n   # Run all integration tests that have been verified to work against a quickstart cluster.\n   mvn verify -P int-tests-config-file -Dgroups=quickstart-compatible\n ```\n+>>>>>>> upstream/master", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d7637d53ff7fdee5ff28b15c49178b176bbf3a39"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTk4MTEyMA==", "bodyText": "Oops. Good catch. Removed", "url": "https://github.com/apache/druid/pull/9576#discussion_r401981120", "createdAt": "2020-04-02T00:10:09Z", "author": {"login": "maytasm"}, "path": "integration-tests/README.md", "diffHunk": "@@ -107,6 +122,7 @@ Then run the tests using a command similar to:\n   # Run all integration tests that have been verified to work against a quickstart cluster.\n   mvn verify -P int-tests-config-file -Dgroups=quickstart-compatible\n ```\n+>>>>>>> upstream/master", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMyNzYwNw=="}, "originalCommit": {"oid": "d7637d53ff7fdee5ff28b15c49178b176bbf3a39"}, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4ODkyOTg1OnYy", "diffSide": "RIGHT", "path": "integration-tests/src/main/java/org/apache/druid/testing/utils/WikipediaStreamEventStreamGenerator.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwMzoyOTowNVrOF-vlyw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMDoxMDoyOVrOF_W_JQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMzNTc1NQ==", "bodyText": "North Americ -> North America", "url": "https://github.com/apache/druid/pull/9576#discussion_r401335755", "createdAt": "2020-04-01T03:29:05Z", "author": {"login": "jon-wei"}, "path": "integration-tests/src/main/java/org/apache/druid/testing/utils/WikipediaStreamEventStreamGenerator.java", "diffHunk": "@@ -0,0 +1,60 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.testing.utils;\n+\n+import org.joda.time.DateTime;\n+import org.joda.time.format.DateTimeFormat;\n+import org.joda.time.format.DateTimeFormatter;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+public class WikipediaStreamEventStreamGenerator extends SyntheticStreamGenerator\n+{\n+  private static final DateTimeFormatter DATE_TIME_FORMATTER = DateTimeFormat.forPattern(\"yyyy-MM-dd'T'HH:mm:ss'Z'\");\n+\n+  public WikipediaStreamEventStreamGenerator(int eventsPerSeconds, long cyclePaddingMs)\n+  {\n+    super(eventsPerSeconds, cyclePaddingMs);\n+  }\n+\n+  @Override\n+  Object getEvent(int i, DateTime timestamp)\n+  {\n+    Map<String, Object> event = new HashMap<>();\n+    event.put(\"page\", \"Gypsy Danger\");\n+    event.put(\"language\", \"en\");\n+    event.put(\"user\", \"nuclear\");\n+    event.put(\"unpatrolled\", \"true\");\n+    event.put(\"newPage\", \"true\");\n+    event.put(\"robot\", \"false\");\n+    event.put(\"anonymous\", \"false\");\n+    event.put(\"namespace\", \"article\");\n+    event.put(\"continent\", \"North Americ\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d7637d53ff7fdee5ff28b15c49178b176bbf3a39"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTk4MTIyMQ==", "bodyText": "Done", "url": "https://github.com/apache/druid/pull/9576#discussion_r401981221", "createdAt": "2020-04-02T00:10:29Z", "author": {"login": "maytasm"}, "path": "integration-tests/src/main/java/org/apache/druid/testing/utils/WikipediaStreamEventStreamGenerator.java", "diffHunk": "@@ -0,0 +1,60 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.testing.utils;\n+\n+import org.joda.time.DateTime;\n+import org.joda.time.format.DateTimeFormat;\n+import org.joda.time.format.DateTimeFormatter;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+public class WikipediaStreamEventStreamGenerator extends SyntheticStreamGenerator\n+{\n+  private static final DateTimeFormatter DATE_TIME_FORMATTER = DateTimeFormat.forPattern(\"yyyy-MM-dd'T'HH:mm:ss'Z'\");\n+\n+  public WikipediaStreamEventStreamGenerator(int eventsPerSeconds, long cyclePaddingMs)\n+  {\n+    super(eventsPerSeconds, cyclePaddingMs);\n+  }\n+\n+  @Override\n+  Object getEvent(int i, DateTime timestamp)\n+  {\n+    Map<String, Object> event = new HashMap<>();\n+    event.put(\"page\", \"Gypsy Danger\");\n+    event.put(\"language\", \"en\");\n+    event.put(\"user\", \"nuclear\");\n+    event.put(\"unpatrolled\", \"true\");\n+    event.put(\"newPage\", \"true\");\n+    event.put(\"robot\", \"false\");\n+    event.put(\"anonymous\", \"false\");\n+    event.put(\"namespace\", \"article\");\n+    event.put(\"continent\", \"North Americ\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMzNTc1NQ=="}, "originalCommit": {"oid": "d7637d53ff7fdee5ff28b15c49178b176bbf3a39"}, "originalPosition": 50}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4ODkzNTg0OnYy", "diffSide": "RIGHT", "path": "integration-tests/src/test/java/org/apache/druid/tests/indexer/ITKinesisIndexingServiceTest.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwMzozMjozMVrOF-vpMg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMDoxNjoyM1rOF_XFqA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMzNjYyNg==", "bodyText": "How is the expire tag used?", "url": "https://github.com/apache/druid/pull/9576#discussion_r401336626", "createdAt": "2020-04-01T03:32:31Z", "author": {"login": "jon-wei"}, "path": "integration-tests/src/test/java/org/apache/druid/tests/indexer/ITKinesisIndexingServiceTest.java", "diffHunk": "@@ -0,0 +1,443 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.tests.indexer;\n+\n+import com.google.common.collect.ImmutableMap;\n+import com.google.inject.Inject;\n+import org.apache.druid.indexing.overlord.supervisor.SupervisorStateManager;\n+import org.apache.druid.java.util.common.DateTimes;\n+import org.apache.druid.java.util.common.StringUtils;\n+import org.apache.druid.java.util.common.logger.Logger;\n+import org.apache.druid.testing.guice.DruidTestModuleFactory;\n+import org.apache.druid.testing.utils.DruidClusterAdminClient;\n+import org.apache.druid.testing.utils.ITRetryUtil;\n+import org.apache.druid.testing.utils.KinesisAdminClient;\n+import org.apache.druid.testing.utils.KinesisEventWriter;\n+import org.apache.druid.testing.utils.WikipediaStreamEventStreamGenerator;\n+import org.apache.druid.tests.TestNGGroup;\n+import org.joda.time.DateTime;\n+import org.joda.time.format.DateTimeFormat;\n+import org.joda.time.format.DateTimeFormatter;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.AfterMethod;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.BeforeMethod;\n+import org.testng.annotations.Guice;\n+import org.testng.annotations.Test;\n+\n+import java.io.Closeable;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.function.Function;\n+\n+@Test(groups = TestNGGroup.KINESIS_INDEX)\n+@Guice(moduleFactory = DruidTestModuleFactory.class)\n+public class ITKinesisIndexingServiceTest extends AbstractITBatchIndexTest\n+{\n+  private static final Logger LOG = new Logger(AbstractKafkaIndexerTest.class);\n+  private static final int KINESIS_SHARD_COUNT = 2;\n+  private static final String STREAM_EXPIRE_TAG = \"druid-ci-expire-after\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d7637d53ff7fdee5ff28b15c49178b176bbf3a39"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMzOTg0NQ==", "bodyText": "Ah, nevermind, just saw that part of the description", "url": "https://github.com/apache/druid/pull/9576#discussion_r401339845", "createdAt": "2020-04-01T03:46:51Z", "author": {"login": "jon-wei"}, "path": "integration-tests/src/test/java/org/apache/druid/tests/indexer/ITKinesisIndexingServiceTest.java", "diffHunk": "@@ -0,0 +1,443 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.tests.indexer;\n+\n+import com.google.common.collect.ImmutableMap;\n+import com.google.inject.Inject;\n+import org.apache.druid.indexing.overlord.supervisor.SupervisorStateManager;\n+import org.apache.druid.java.util.common.DateTimes;\n+import org.apache.druid.java.util.common.StringUtils;\n+import org.apache.druid.java.util.common.logger.Logger;\n+import org.apache.druid.testing.guice.DruidTestModuleFactory;\n+import org.apache.druid.testing.utils.DruidClusterAdminClient;\n+import org.apache.druid.testing.utils.ITRetryUtil;\n+import org.apache.druid.testing.utils.KinesisAdminClient;\n+import org.apache.druid.testing.utils.KinesisEventWriter;\n+import org.apache.druid.testing.utils.WikipediaStreamEventStreamGenerator;\n+import org.apache.druid.tests.TestNGGroup;\n+import org.joda.time.DateTime;\n+import org.joda.time.format.DateTimeFormat;\n+import org.joda.time.format.DateTimeFormatter;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.AfterMethod;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.BeforeMethod;\n+import org.testng.annotations.Guice;\n+import org.testng.annotations.Test;\n+\n+import java.io.Closeable;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.function.Function;\n+\n+@Test(groups = TestNGGroup.KINESIS_INDEX)\n+@Guice(moduleFactory = DruidTestModuleFactory.class)\n+public class ITKinesisIndexingServiceTest extends AbstractITBatchIndexTest\n+{\n+  private static final Logger LOG = new Logger(AbstractKafkaIndexerTest.class);\n+  private static final int KINESIS_SHARD_COUNT = 2;\n+  private static final String STREAM_EXPIRE_TAG = \"druid-ci-expire-after\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMzNjYyNg=="}, "originalCommit": {"oid": "d7637d53ff7fdee5ff28b15c49178b176bbf3a39"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMzOTk4Mg==", "bodyText": "Can you add a comment here explaining what it's used for?", "url": "https://github.com/apache/druid/pull/9576#discussion_r401339982", "createdAt": "2020-04-01T03:47:29Z", "author": {"login": "jon-wei"}, "path": "integration-tests/src/test/java/org/apache/druid/tests/indexer/ITKinesisIndexingServiceTest.java", "diffHunk": "@@ -0,0 +1,443 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.tests.indexer;\n+\n+import com.google.common.collect.ImmutableMap;\n+import com.google.inject.Inject;\n+import org.apache.druid.indexing.overlord.supervisor.SupervisorStateManager;\n+import org.apache.druid.java.util.common.DateTimes;\n+import org.apache.druid.java.util.common.StringUtils;\n+import org.apache.druid.java.util.common.logger.Logger;\n+import org.apache.druid.testing.guice.DruidTestModuleFactory;\n+import org.apache.druid.testing.utils.DruidClusterAdminClient;\n+import org.apache.druid.testing.utils.ITRetryUtil;\n+import org.apache.druid.testing.utils.KinesisAdminClient;\n+import org.apache.druid.testing.utils.KinesisEventWriter;\n+import org.apache.druid.testing.utils.WikipediaStreamEventStreamGenerator;\n+import org.apache.druid.tests.TestNGGroup;\n+import org.joda.time.DateTime;\n+import org.joda.time.format.DateTimeFormat;\n+import org.joda.time.format.DateTimeFormatter;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.AfterMethod;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.BeforeMethod;\n+import org.testng.annotations.Guice;\n+import org.testng.annotations.Test;\n+\n+import java.io.Closeable;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.function.Function;\n+\n+@Test(groups = TestNGGroup.KINESIS_INDEX)\n+@Guice(moduleFactory = DruidTestModuleFactory.class)\n+public class ITKinesisIndexingServiceTest extends AbstractITBatchIndexTest\n+{\n+  private static final Logger LOG = new Logger(AbstractKafkaIndexerTest.class);\n+  private static final int KINESIS_SHARD_COUNT = 2;\n+  private static final String STREAM_EXPIRE_TAG = \"druid-ci-expire-after\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMzNjYyNg=="}, "originalCommit": {"oid": "d7637d53ff7fdee5ff28b15c49178b176bbf3a39"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTk4Mjg4OA==", "bodyText": "It's to help people cleanup the test streams if the IT cleanup method fails or didn't run (this shouldn't happen normally but can such as if the test unexpectedly terminates midway). Added the comment", "url": "https://github.com/apache/druid/pull/9576#discussion_r401982888", "createdAt": "2020-04-02T00:16:23Z", "author": {"login": "maytasm"}, "path": "integration-tests/src/test/java/org/apache/druid/tests/indexer/ITKinesisIndexingServiceTest.java", "diffHunk": "@@ -0,0 +1,443 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.tests.indexer;\n+\n+import com.google.common.collect.ImmutableMap;\n+import com.google.inject.Inject;\n+import org.apache.druid.indexing.overlord.supervisor.SupervisorStateManager;\n+import org.apache.druid.java.util.common.DateTimes;\n+import org.apache.druid.java.util.common.StringUtils;\n+import org.apache.druid.java.util.common.logger.Logger;\n+import org.apache.druid.testing.guice.DruidTestModuleFactory;\n+import org.apache.druid.testing.utils.DruidClusterAdminClient;\n+import org.apache.druid.testing.utils.ITRetryUtil;\n+import org.apache.druid.testing.utils.KinesisAdminClient;\n+import org.apache.druid.testing.utils.KinesisEventWriter;\n+import org.apache.druid.testing.utils.WikipediaStreamEventStreamGenerator;\n+import org.apache.druid.tests.TestNGGroup;\n+import org.joda.time.DateTime;\n+import org.joda.time.format.DateTimeFormat;\n+import org.joda.time.format.DateTimeFormatter;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.AfterMethod;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.BeforeMethod;\n+import org.testng.annotations.Guice;\n+import org.testng.annotations.Test;\n+\n+import java.io.Closeable;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.function.Function;\n+\n+@Test(groups = TestNGGroup.KINESIS_INDEX)\n+@Guice(moduleFactory = DruidTestModuleFactory.class)\n+public class ITKinesisIndexingServiceTest extends AbstractITBatchIndexTest\n+{\n+  private static final Logger LOG = new Logger(AbstractKafkaIndexerTest.class);\n+  private static final int KINESIS_SHARD_COUNT = 2;\n+  private static final String STREAM_EXPIRE_TAG = \"druid-ci-expire-after\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMzNjYyNg=="}, "originalCommit": {"oid": "d7637d53ff7fdee5ff28b15c49178b176bbf3a39"}, "originalPosition": 56}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4ODk0NDAwOnYy", "diffSide": "RIGHT", "path": "integration-tests/src/test/java/org/apache/druid/tests/indexer/ITKinesisIndexingServiceTest.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwMzozNzo1OVrOF-vtzw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMTo1NzowOFrOF_YtAw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMzNzgwNw==", "bodyText": "For the resharding test, I think you'll want to have longer timers for the event generation, with only 3s here I think it's maybe possible that AWS doesn't actually begin the resharding until you've already finished this second phase. Maybe 30s is better.\nOr maybe it could check for the stream status becoming UPDATING and start the second phase then.", "url": "https://github.com/apache/druid/pull/9576#discussion_r401337807", "createdAt": "2020-04-01T03:37:59Z", "author": {"login": "jon-wei"}, "path": "integration-tests/src/test/java/org/apache/druid/tests/indexer/ITKinesisIndexingServiceTest.java", "diffHunk": "@@ -0,0 +1,443 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.tests.indexer;\n+\n+import com.google.common.collect.ImmutableMap;\n+import com.google.inject.Inject;\n+import org.apache.druid.indexing.overlord.supervisor.SupervisorStateManager;\n+import org.apache.druid.java.util.common.DateTimes;\n+import org.apache.druid.java.util.common.StringUtils;\n+import org.apache.druid.java.util.common.logger.Logger;\n+import org.apache.druid.testing.guice.DruidTestModuleFactory;\n+import org.apache.druid.testing.utils.DruidClusterAdminClient;\n+import org.apache.druid.testing.utils.ITRetryUtil;\n+import org.apache.druid.testing.utils.KinesisAdminClient;\n+import org.apache.druid.testing.utils.KinesisEventWriter;\n+import org.apache.druid.testing.utils.WikipediaStreamEventStreamGenerator;\n+import org.apache.druid.tests.TestNGGroup;\n+import org.joda.time.DateTime;\n+import org.joda.time.format.DateTimeFormat;\n+import org.joda.time.format.DateTimeFormatter;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.AfterMethod;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.BeforeMethod;\n+import org.testng.annotations.Guice;\n+import org.testng.annotations.Test;\n+\n+import java.io.Closeable;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.function.Function;\n+\n+@Test(groups = TestNGGroup.KINESIS_INDEX)\n+@Guice(moduleFactory = DruidTestModuleFactory.class)\n+public class ITKinesisIndexingServiceTest extends AbstractITBatchIndexTest\n+{\n+  private static final Logger LOG = new Logger(AbstractKafkaIndexerTest.class);\n+  private static final int KINESIS_SHARD_COUNT = 2;\n+  private static final String STREAM_EXPIRE_TAG = \"druid-ci-expire-after\";\n+  private static final long WAIT_TIME_MILLIS = 3 * 60 * 1000L;\n+  private static final DateTime FIRST_EVENT_TIME = DateTimes.of(1994, 4, 29, 1, 0);\n+  private static final String INDEXER_FILE_LEGACY_PARSER = \"/indexer/stream_supervisor_spec_legacy_parser.json\";\n+  private static final String INDEXER_FILE_INPUT_FORMAT = \"/indexer/stream_supervisor_spec_input_format.json\";\n+  private static final String QUERIES_FILE = \"/indexer/stream_index_queries.json\";\n+  // format for the querying interval\n+  private static final DateTimeFormatter INTERVAL_FMT = DateTimeFormat.forPattern(\"yyyy-MM-dd'T'HH:mm:'00Z'\");\n+  // format for the expected timestamp in a query response\n+  private static final DateTimeFormatter TIMESTAMP_FMT = DateTimeFormat.forPattern(\"yyyy-MM-dd'T'HH:mm:ss'.000Z'\");\n+  private static final int EVENTS_PER_SECOND = 6;\n+  private static final long CYCLE_PADDING_MS = 100;\n+  private static final int TOTAL_NUMBER_OF_SECOND = 10;\n+\n+  @Inject\n+  private DruidClusterAdminClient druidClusterAdminClient;\n+\n+  private String streamName;\n+  private String fullDatasourceName;\n+  private KinesisAdminClient kinesisAdminClient;\n+  private KinesisEventWriter kinesisEventWriter;\n+  private WikipediaStreamEventStreamGenerator wikipediaStreamEventGenerator;\n+  private Function<String, String> kinesisIngestionPropsTransform;\n+  private Function<String, String> kinesisQueryPropsTransform;\n+  private String supervisorId;\n+  private int secondsToGenerateRemaining;\n+\n+  @BeforeClass\n+  public void beforeClass() throws Exception\n+  {\n+    kinesisAdminClient = new KinesisAdminClient(config.getStreamEndpoint());\n+    kinesisEventWriter = new KinesisEventWriter(config.getStreamEndpoint(), false);\n+    wikipediaStreamEventGenerator = new WikipediaStreamEventStreamGenerator(EVENTS_PER_SECOND, CYCLE_PADDING_MS);\n+  }\n+\n+  @AfterClass\n+  public void tearDown()\n+  {\n+    wikipediaStreamEventGenerator.shutdown();\n+    kinesisEventWriter.shutdown();\n+  }\n+\n+  @BeforeMethod\n+  public void before()\n+  {\n+    streamName = \"kinesis_index_test_\" + UUID.randomUUID();\n+    String datasource = \"kinesis_indexing_service_test_\" + UUID.randomUUID();\n+    Map<String, String> tags = ImmutableMap.of(STREAM_EXPIRE_TAG, Long.toString(DateTimes.nowUtc().plusMinutes(30).getMillis()));\n+    kinesisAdminClient.createStream(streamName, KINESIS_SHARD_COUNT, tags);\n+    ITRetryUtil.retryUntil(\n+        () -> kinesisAdminClient.isStreamActive(streamName),\n+        true,\n+        10000,\n+        30,\n+        \"Wait for stream active\"\n+    );\n+    secondsToGenerateRemaining = TOTAL_NUMBER_OF_SECOND;\n+    fullDatasourceName = datasource + config.getExtraDatasourceNameSuffix();\n+    kinesisIngestionPropsTransform = spec -> {\n+      try {\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%DATASOURCE%%\",\n+            fullDatasourceName\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%STREAM_TYPE%%\",\n+            \"kinesis\"\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TOPIC_KEY%%\",\n+            \"stream\"\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TOPIC_VALUE%%\",\n+            streamName\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%USE_EARLIEST_KEY%%\",\n+            \"useEarliestSequenceNumber\"\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%STREAM_PROPERTIES_KEY%%\",\n+            \"endpoint\"\n+        );\n+        return StringUtils.replace(\n+            spec,\n+            \"%%STREAM_PROPERTIES_VALUE%%\",\n+            jsonMapper.writeValueAsString(config.getStreamEndpoint())\n+        );\n+      }\n+      catch (Exception e) {\n+        throw new RuntimeException(e);\n+      }\n+    };\n+    kinesisQueryPropsTransform = spec -> {\n+      try {\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%DATASOURCE%%\",\n+            fullDatasourceName\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMEBOUNDARY_RESPONSE_TIMESTAMP%%\",\n+            TIMESTAMP_FMT.print(FIRST_EVENT_TIME)\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMEBOUNDARY_RESPONSE_MAXTIME%%\",\n+            TIMESTAMP_FMT.print(FIRST_EVENT_TIME.plusSeconds(TOTAL_NUMBER_OF_SECOND - 1))\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMEBOUNDARY_RESPONSE_MINTIME%%\",\n+            TIMESTAMP_FMT.print(FIRST_EVENT_TIME)\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_QUERY_START%%\",\n+            INTERVAL_FMT.print(FIRST_EVENT_TIME)\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_QUERY_END%%\",\n+            INTERVAL_FMT.print(FIRST_EVENT_TIME.plusSeconds(TOTAL_NUMBER_OF_SECOND - 1).plusMinutes(2))\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_RESPONSE_TIMESTAMP%%\",\n+            TIMESTAMP_FMT.print(FIRST_EVENT_TIME)\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_ADDED%%\",\n+            Long.toString(getSumOfEventSequence(EVENTS_PER_SECOND) * TOTAL_NUMBER_OF_SECOND)\n+        );\n+        return StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_NUMEVENTS%%\",\n+            Integer.toString(EVENTS_PER_SECOND * TOTAL_NUMBER_OF_SECOND)\n+        );\n+      }\n+      catch (Exception e) {\n+        throw new RuntimeException(e);\n+      }\n+    };\n+  }\n+\n+  @AfterMethod\n+  public void teardown()\n+  {\n+    try {\n+      kinesisEventWriter.flush();\n+      indexer.shutdownSupervisor(supervisorId);\n+      unloader(fullDatasourceName);\n+      kinesisAdminClient.deleteStream(streamName);\n+    }\n+    catch (Exception e) {\n+      // Best effort cleanup\n+    }\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithLegacyParserStableState() throws Exception\n+  {\n+    try (\n+        final Closeable ignored1 = unloader(fullDatasourceName)\n+    ) {\n+      final String taskSpec = kinesisIngestionPropsTransform.apply(getResourceAsString(INDEXER_FILE_LEGACY_PARSER));\n+      LOG.info(\"supervisorSpec: [%s]\\n\", taskSpec);\n+      // Start supervisor\n+      supervisorId = indexer.submitSupervisor(taskSpec);\n+      LOG.info(\"Submitted supervisor\");\n+      // Start Kinesis data generator\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, TOTAL_NUMBER_OF_SECOND, FIRST_EVENT_TIME);\n+      verifyIngestedData(supervisorId);\n+    }\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithInputFormatStableState() throws Exception\n+  {\n+    try (\n+        final Closeable ignored1 = unloader(fullDatasourceName)\n+    ) {\n+      final String taskSpec = kinesisIngestionPropsTransform.apply(getResourceAsString(INDEXER_FILE_INPUT_FORMAT));\n+      LOG.info(\"supervisorSpec: [%s]\\n\", taskSpec);\n+      // Start supervisor\n+      supervisorId = indexer.submitSupervisor(taskSpec);\n+      LOG.info(\"Submitted supervisor\");\n+      // Start Kinesis data generator\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, TOTAL_NUMBER_OF_SECOND, FIRST_EVENT_TIME);\n+      verifyIngestedData(supervisorId);\n+    }\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithLosingCoordinator() throws Exception\n+  {\n+    testIndexWithLosingNodeHelper(() -> druidClusterAdminClient.restartCoordinatorContainer(), () -> druidClusterAdminClient.waitUntilCoordinatorReady());\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithLosingOverlord() throws Exception\n+  {\n+    testIndexWithLosingNodeHelper(() -> druidClusterAdminClient.restartIndexerContainer(), () -> druidClusterAdminClient.waitUntilIndexerReady());\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithLosingHistorical() throws Exception\n+  {\n+    testIndexWithLosingNodeHelper(() -> druidClusterAdminClient.restartHistoricalContainer(), () -> druidClusterAdminClient.waitUntilHistoricalReady());\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithStartStopSupervisor() throws Exception\n+  {\n+    try (\n+        final Closeable ignored1 = unloader(fullDatasourceName)\n+    ) {\n+      final String taskSpec = kinesisIngestionPropsTransform.apply(getResourceAsString(INDEXER_FILE_INPUT_FORMAT));\n+      LOG.info(\"supervisorSpec: [%s]\\n\", taskSpec);\n+      // Start supervisor\n+      supervisorId = indexer.submitSupervisor(taskSpec);\n+      LOG.info(\"Submitted supervisor\");\n+      // Start generating half of the data\n+      int secondsToGenerateFirstRound = TOTAL_NUMBER_OF_SECOND / 2;\n+      secondsToGenerateRemaining = secondsToGenerateRemaining - secondsToGenerateFirstRound;\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateFirstRound, FIRST_EVENT_TIME);\n+      // Suspend the supervisor\n+      indexer.suspendSupervisor(supervisorId);\n+      // Start generating remainning half of the data\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateRemaining, FIRST_EVENT_TIME.plusSeconds(secondsToGenerateFirstRound));\n+      // Resume the supervisor\n+      indexer.resumeSupervisor(supervisorId);\n+      // Verify supervisor is healthy after suspension\n+      ITRetryUtil.retryUntil(\n+          () -> SupervisorStateManager.BasicState.RUNNING.equals(indexer.getSupervisorStatus(supervisorId)),\n+          true,\n+          10000,\n+          30,\n+          \"Waiting for supervisor to be healthy\"\n+      );\n+      // Verify that supervisor can catch up with the stream\n+      verifyIngestedData(supervisorId);\n+    }\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithKinesisReshardSplit() throws Exception\n+  {\n+    // Reshard the supervisor by split from KINESIS_SHARD_COUNT to KINESIS_SHARD_COUNT * 2\n+    testIndexWithKinesisReshardHelper(KINESIS_SHARD_COUNT * 2);\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithKinesisReshardMerge() throws Exception\n+  {\n+    // Reshard the supervisor by split from KINESIS_SHARD_COUNT to KINESIS_SHARD_COUNT / 2\n+    testIndexWithKinesisReshardHelper(KINESIS_SHARD_COUNT / 2);\n+  }\n+\n+  private void testIndexWithLosingNodeHelper(Runnable restartRunnable, Runnable waitForReadyRunnable) throws Exception\n+  {\n+    try (\n+        final Closeable ignored1 = unloader(fullDatasourceName)\n+    ) {\n+      final String taskSpec = kinesisIngestionPropsTransform.apply(getResourceAsString(INDEXER_FILE_INPUT_FORMAT));\n+      LOG.info(\"supervisorSpec: [%s]\\n\", taskSpec);\n+      // Start supervisor\n+      supervisorId = indexer.submitSupervisor(taskSpec);\n+      LOG.info(\"Submitted supervisor\");\n+      // Start generating one third of the data (before restarting)\n+      int secondsToGenerateFirstRound = TOTAL_NUMBER_OF_SECOND / 3;\n+      secondsToGenerateRemaining = secondsToGenerateRemaining - secondsToGenerateFirstRound;\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateFirstRound, FIRST_EVENT_TIME);\n+      // Restart Druid process\n+      LOG.info(\"Restarting Druid process\");\n+      restartRunnable.run();\n+      LOG.info(\"Restarted Druid process\");\n+      // Start generating one third of the data (while restarting)\n+      int secondsToGenerateSecondRound = TOTAL_NUMBER_OF_SECOND / 3;\n+      secondsToGenerateRemaining = secondsToGenerateRemaining - secondsToGenerateSecondRound;\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateSecondRound, FIRST_EVENT_TIME.plusSeconds(secondsToGenerateFirstRound));\n+      // Wait for Druid process to be available\n+      LOG.info(\"Waiting for Druid process to be available\");\n+      waitForReadyRunnable.run();\n+      LOG.info(\"Druid process is now available\");\n+      // Start generating remainding data (after restarting)\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateRemaining, FIRST_EVENT_TIME.plusSeconds(secondsToGenerateFirstRound + secondsToGenerateSecondRound));\n+      // Verify supervisor is healthy\n+      ITRetryUtil.retryUntil(\n+          () -> SupervisorStateManager.BasicState.RUNNING.equals(indexer.getSupervisorStatus(supervisorId)),\n+          true,\n+          10000,\n+          30,\n+          \"Waiting for supervisor to be healthy\"\n+      );\n+      // Verify that supervisor ingested all data\n+      verifyIngestedData(supervisorId);\n+    }\n+  }\n+\n+  private void testIndexWithKinesisReshardHelper(int newShardCount) throws Exception\n+  {\n+    try (\n+        final Closeable ignored1 = unloader(fullDatasourceName)\n+    ) {\n+      final String taskSpec = kinesisIngestionPropsTransform.apply(getResourceAsString(INDEXER_FILE_INPUT_FORMAT));\n+      LOG.info(\"supervisorSpec: [%s]\\n\", taskSpec);\n+      // Start supervisor\n+      supervisorId = indexer.submitSupervisor(taskSpec);\n+      LOG.info(\"Submitted supervisor\");\n+      // Start generating one third of the data (before resharding)\n+      int secondsToGenerateFirstRound = TOTAL_NUMBER_OF_SECOND / 3;\n+      secondsToGenerateRemaining = secondsToGenerateRemaining - secondsToGenerateFirstRound;\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateFirstRound, FIRST_EVENT_TIME);\n+      // Reshard the supervisor by split from KINESIS_SHARD_COUNT to newShardCount\n+      kinesisAdminClient.updateShardCount(streamName, newShardCount);\n+      // Start generating one third of the data (while resharding)\n+      int secondsToGenerateSecondRound = TOTAL_NUMBER_OF_SECOND / 3;\n+      secondsToGenerateRemaining = secondsToGenerateRemaining - secondsToGenerateSecondRound;\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateSecondRound, FIRST_EVENT_TIME.plusSeconds(secondsToGenerateFirstRound));\n+      // Wait for kinesis stream to finish resharding", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d7637d53ff7fdee5ff28b15c49178b176bbf3a39"}, "originalPosition": 385}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTk4MzM1MA==", "bodyText": "Changed the logic to:\n\nafter issuing reshard call\ndo DescribeStream polling for an updating status or an active status with the final expected number of shards\nbegin second phase when ^ true\ncheck that stream is active status (no need to check the number of shards since earlier we already check for \"updating status or an active status with the final expected number of shards\", hence if it is active now it was be the active after resharding)\nbegin third phase when ^ true", "url": "https://github.com/apache/druid/pull/9576#discussion_r401983350", "createdAt": "2020-04-02T00:18:02Z", "author": {"login": "maytasm"}, "path": "integration-tests/src/test/java/org/apache/druid/tests/indexer/ITKinesisIndexingServiceTest.java", "diffHunk": "@@ -0,0 +1,443 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.tests.indexer;\n+\n+import com.google.common.collect.ImmutableMap;\n+import com.google.inject.Inject;\n+import org.apache.druid.indexing.overlord.supervisor.SupervisorStateManager;\n+import org.apache.druid.java.util.common.DateTimes;\n+import org.apache.druid.java.util.common.StringUtils;\n+import org.apache.druid.java.util.common.logger.Logger;\n+import org.apache.druid.testing.guice.DruidTestModuleFactory;\n+import org.apache.druid.testing.utils.DruidClusterAdminClient;\n+import org.apache.druid.testing.utils.ITRetryUtil;\n+import org.apache.druid.testing.utils.KinesisAdminClient;\n+import org.apache.druid.testing.utils.KinesisEventWriter;\n+import org.apache.druid.testing.utils.WikipediaStreamEventStreamGenerator;\n+import org.apache.druid.tests.TestNGGroup;\n+import org.joda.time.DateTime;\n+import org.joda.time.format.DateTimeFormat;\n+import org.joda.time.format.DateTimeFormatter;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.AfterMethod;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.BeforeMethod;\n+import org.testng.annotations.Guice;\n+import org.testng.annotations.Test;\n+\n+import java.io.Closeable;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.function.Function;\n+\n+@Test(groups = TestNGGroup.KINESIS_INDEX)\n+@Guice(moduleFactory = DruidTestModuleFactory.class)\n+public class ITKinesisIndexingServiceTest extends AbstractITBatchIndexTest\n+{\n+  private static final Logger LOG = new Logger(AbstractKafkaIndexerTest.class);\n+  private static final int KINESIS_SHARD_COUNT = 2;\n+  private static final String STREAM_EXPIRE_TAG = \"druid-ci-expire-after\";\n+  private static final long WAIT_TIME_MILLIS = 3 * 60 * 1000L;\n+  private static final DateTime FIRST_EVENT_TIME = DateTimes.of(1994, 4, 29, 1, 0);\n+  private static final String INDEXER_FILE_LEGACY_PARSER = \"/indexer/stream_supervisor_spec_legacy_parser.json\";\n+  private static final String INDEXER_FILE_INPUT_FORMAT = \"/indexer/stream_supervisor_spec_input_format.json\";\n+  private static final String QUERIES_FILE = \"/indexer/stream_index_queries.json\";\n+  // format for the querying interval\n+  private static final DateTimeFormatter INTERVAL_FMT = DateTimeFormat.forPattern(\"yyyy-MM-dd'T'HH:mm:'00Z'\");\n+  // format for the expected timestamp in a query response\n+  private static final DateTimeFormatter TIMESTAMP_FMT = DateTimeFormat.forPattern(\"yyyy-MM-dd'T'HH:mm:ss'.000Z'\");\n+  private static final int EVENTS_PER_SECOND = 6;\n+  private static final long CYCLE_PADDING_MS = 100;\n+  private static final int TOTAL_NUMBER_OF_SECOND = 10;\n+\n+  @Inject\n+  private DruidClusterAdminClient druidClusterAdminClient;\n+\n+  private String streamName;\n+  private String fullDatasourceName;\n+  private KinesisAdminClient kinesisAdminClient;\n+  private KinesisEventWriter kinesisEventWriter;\n+  private WikipediaStreamEventStreamGenerator wikipediaStreamEventGenerator;\n+  private Function<String, String> kinesisIngestionPropsTransform;\n+  private Function<String, String> kinesisQueryPropsTransform;\n+  private String supervisorId;\n+  private int secondsToGenerateRemaining;\n+\n+  @BeforeClass\n+  public void beforeClass() throws Exception\n+  {\n+    kinesisAdminClient = new KinesisAdminClient(config.getStreamEndpoint());\n+    kinesisEventWriter = new KinesisEventWriter(config.getStreamEndpoint(), false);\n+    wikipediaStreamEventGenerator = new WikipediaStreamEventStreamGenerator(EVENTS_PER_SECOND, CYCLE_PADDING_MS);\n+  }\n+\n+  @AfterClass\n+  public void tearDown()\n+  {\n+    wikipediaStreamEventGenerator.shutdown();\n+    kinesisEventWriter.shutdown();\n+  }\n+\n+  @BeforeMethod\n+  public void before()\n+  {\n+    streamName = \"kinesis_index_test_\" + UUID.randomUUID();\n+    String datasource = \"kinesis_indexing_service_test_\" + UUID.randomUUID();\n+    Map<String, String> tags = ImmutableMap.of(STREAM_EXPIRE_TAG, Long.toString(DateTimes.nowUtc().plusMinutes(30).getMillis()));\n+    kinesisAdminClient.createStream(streamName, KINESIS_SHARD_COUNT, tags);\n+    ITRetryUtil.retryUntil(\n+        () -> kinesisAdminClient.isStreamActive(streamName),\n+        true,\n+        10000,\n+        30,\n+        \"Wait for stream active\"\n+    );\n+    secondsToGenerateRemaining = TOTAL_NUMBER_OF_SECOND;\n+    fullDatasourceName = datasource + config.getExtraDatasourceNameSuffix();\n+    kinesisIngestionPropsTransform = spec -> {\n+      try {\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%DATASOURCE%%\",\n+            fullDatasourceName\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%STREAM_TYPE%%\",\n+            \"kinesis\"\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TOPIC_KEY%%\",\n+            \"stream\"\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TOPIC_VALUE%%\",\n+            streamName\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%USE_EARLIEST_KEY%%\",\n+            \"useEarliestSequenceNumber\"\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%STREAM_PROPERTIES_KEY%%\",\n+            \"endpoint\"\n+        );\n+        return StringUtils.replace(\n+            spec,\n+            \"%%STREAM_PROPERTIES_VALUE%%\",\n+            jsonMapper.writeValueAsString(config.getStreamEndpoint())\n+        );\n+      }\n+      catch (Exception e) {\n+        throw new RuntimeException(e);\n+      }\n+    };\n+    kinesisQueryPropsTransform = spec -> {\n+      try {\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%DATASOURCE%%\",\n+            fullDatasourceName\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMEBOUNDARY_RESPONSE_TIMESTAMP%%\",\n+            TIMESTAMP_FMT.print(FIRST_EVENT_TIME)\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMEBOUNDARY_RESPONSE_MAXTIME%%\",\n+            TIMESTAMP_FMT.print(FIRST_EVENT_TIME.plusSeconds(TOTAL_NUMBER_OF_SECOND - 1))\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMEBOUNDARY_RESPONSE_MINTIME%%\",\n+            TIMESTAMP_FMT.print(FIRST_EVENT_TIME)\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_QUERY_START%%\",\n+            INTERVAL_FMT.print(FIRST_EVENT_TIME)\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_QUERY_END%%\",\n+            INTERVAL_FMT.print(FIRST_EVENT_TIME.plusSeconds(TOTAL_NUMBER_OF_SECOND - 1).plusMinutes(2))\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_RESPONSE_TIMESTAMP%%\",\n+            TIMESTAMP_FMT.print(FIRST_EVENT_TIME)\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_ADDED%%\",\n+            Long.toString(getSumOfEventSequence(EVENTS_PER_SECOND) * TOTAL_NUMBER_OF_SECOND)\n+        );\n+        return StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_NUMEVENTS%%\",\n+            Integer.toString(EVENTS_PER_SECOND * TOTAL_NUMBER_OF_SECOND)\n+        );\n+      }\n+      catch (Exception e) {\n+        throw new RuntimeException(e);\n+      }\n+    };\n+  }\n+\n+  @AfterMethod\n+  public void teardown()\n+  {\n+    try {\n+      kinesisEventWriter.flush();\n+      indexer.shutdownSupervisor(supervisorId);\n+      unloader(fullDatasourceName);\n+      kinesisAdminClient.deleteStream(streamName);\n+    }\n+    catch (Exception e) {\n+      // Best effort cleanup\n+    }\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithLegacyParserStableState() throws Exception\n+  {\n+    try (\n+        final Closeable ignored1 = unloader(fullDatasourceName)\n+    ) {\n+      final String taskSpec = kinesisIngestionPropsTransform.apply(getResourceAsString(INDEXER_FILE_LEGACY_PARSER));\n+      LOG.info(\"supervisorSpec: [%s]\\n\", taskSpec);\n+      // Start supervisor\n+      supervisorId = indexer.submitSupervisor(taskSpec);\n+      LOG.info(\"Submitted supervisor\");\n+      // Start Kinesis data generator\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, TOTAL_NUMBER_OF_SECOND, FIRST_EVENT_TIME);\n+      verifyIngestedData(supervisorId);\n+    }\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithInputFormatStableState() throws Exception\n+  {\n+    try (\n+        final Closeable ignored1 = unloader(fullDatasourceName)\n+    ) {\n+      final String taskSpec = kinesisIngestionPropsTransform.apply(getResourceAsString(INDEXER_FILE_INPUT_FORMAT));\n+      LOG.info(\"supervisorSpec: [%s]\\n\", taskSpec);\n+      // Start supervisor\n+      supervisorId = indexer.submitSupervisor(taskSpec);\n+      LOG.info(\"Submitted supervisor\");\n+      // Start Kinesis data generator\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, TOTAL_NUMBER_OF_SECOND, FIRST_EVENT_TIME);\n+      verifyIngestedData(supervisorId);\n+    }\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithLosingCoordinator() throws Exception\n+  {\n+    testIndexWithLosingNodeHelper(() -> druidClusterAdminClient.restartCoordinatorContainer(), () -> druidClusterAdminClient.waitUntilCoordinatorReady());\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithLosingOverlord() throws Exception\n+  {\n+    testIndexWithLosingNodeHelper(() -> druidClusterAdminClient.restartIndexerContainer(), () -> druidClusterAdminClient.waitUntilIndexerReady());\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithLosingHistorical() throws Exception\n+  {\n+    testIndexWithLosingNodeHelper(() -> druidClusterAdminClient.restartHistoricalContainer(), () -> druidClusterAdminClient.waitUntilHistoricalReady());\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithStartStopSupervisor() throws Exception\n+  {\n+    try (\n+        final Closeable ignored1 = unloader(fullDatasourceName)\n+    ) {\n+      final String taskSpec = kinesisIngestionPropsTransform.apply(getResourceAsString(INDEXER_FILE_INPUT_FORMAT));\n+      LOG.info(\"supervisorSpec: [%s]\\n\", taskSpec);\n+      // Start supervisor\n+      supervisorId = indexer.submitSupervisor(taskSpec);\n+      LOG.info(\"Submitted supervisor\");\n+      // Start generating half of the data\n+      int secondsToGenerateFirstRound = TOTAL_NUMBER_OF_SECOND / 2;\n+      secondsToGenerateRemaining = secondsToGenerateRemaining - secondsToGenerateFirstRound;\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateFirstRound, FIRST_EVENT_TIME);\n+      // Suspend the supervisor\n+      indexer.suspendSupervisor(supervisorId);\n+      // Start generating remainning half of the data\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateRemaining, FIRST_EVENT_TIME.plusSeconds(secondsToGenerateFirstRound));\n+      // Resume the supervisor\n+      indexer.resumeSupervisor(supervisorId);\n+      // Verify supervisor is healthy after suspension\n+      ITRetryUtil.retryUntil(\n+          () -> SupervisorStateManager.BasicState.RUNNING.equals(indexer.getSupervisorStatus(supervisorId)),\n+          true,\n+          10000,\n+          30,\n+          \"Waiting for supervisor to be healthy\"\n+      );\n+      // Verify that supervisor can catch up with the stream\n+      verifyIngestedData(supervisorId);\n+    }\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithKinesisReshardSplit() throws Exception\n+  {\n+    // Reshard the supervisor by split from KINESIS_SHARD_COUNT to KINESIS_SHARD_COUNT * 2\n+    testIndexWithKinesisReshardHelper(KINESIS_SHARD_COUNT * 2);\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithKinesisReshardMerge() throws Exception\n+  {\n+    // Reshard the supervisor by split from KINESIS_SHARD_COUNT to KINESIS_SHARD_COUNT / 2\n+    testIndexWithKinesisReshardHelper(KINESIS_SHARD_COUNT / 2);\n+  }\n+\n+  private void testIndexWithLosingNodeHelper(Runnable restartRunnable, Runnable waitForReadyRunnable) throws Exception\n+  {\n+    try (\n+        final Closeable ignored1 = unloader(fullDatasourceName)\n+    ) {\n+      final String taskSpec = kinesisIngestionPropsTransform.apply(getResourceAsString(INDEXER_FILE_INPUT_FORMAT));\n+      LOG.info(\"supervisorSpec: [%s]\\n\", taskSpec);\n+      // Start supervisor\n+      supervisorId = indexer.submitSupervisor(taskSpec);\n+      LOG.info(\"Submitted supervisor\");\n+      // Start generating one third of the data (before restarting)\n+      int secondsToGenerateFirstRound = TOTAL_NUMBER_OF_SECOND / 3;\n+      secondsToGenerateRemaining = secondsToGenerateRemaining - secondsToGenerateFirstRound;\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateFirstRound, FIRST_EVENT_TIME);\n+      // Restart Druid process\n+      LOG.info(\"Restarting Druid process\");\n+      restartRunnable.run();\n+      LOG.info(\"Restarted Druid process\");\n+      // Start generating one third of the data (while restarting)\n+      int secondsToGenerateSecondRound = TOTAL_NUMBER_OF_SECOND / 3;\n+      secondsToGenerateRemaining = secondsToGenerateRemaining - secondsToGenerateSecondRound;\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateSecondRound, FIRST_EVENT_TIME.plusSeconds(secondsToGenerateFirstRound));\n+      // Wait for Druid process to be available\n+      LOG.info(\"Waiting for Druid process to be available\");\n+      waitForReadyRunnable.run();\n+      LOG.info(\"Druid process is now available\");\n+      // Start generating remainding data (after restarting)\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateRemaining, FIRST_EVENT_TIME.plusSeconds(secondsToGenerateFirstRound + secondsToGenerateSecondRound));\n+      // Verify supervisor is healthy\n+      ITRetryUtil.retryUntil(\n+          () -> SupervisorStateManager.BasicState.RUNNING.equals(indexer.getSupervisorStatus(supervisorId)),\n+          true,\n+          10000,\n+          30,\n+          \"Waiting for supervisor to be healthy\"\n+      );\n+      // Verify that supervisor ingested all data\n+      verifyIngestedData(supervisorId);\n+    }\n+  }\n+\n+  private void testIndexWithKinesisReshardHelper(int newShardCount) throws Exception\n+  {\n+    try (\n+        final Closeable ignored1 = unloader(fullDatasourceName)\n+    ) {\n+      final String taskSpec = kinesisIngestionPropsTransform.apply(getResourceAsString(INDEXER_FILE_INPUT_FORMAT));\n+      LOG.info(\"supervisorSpec: [%s]\\n\", taskSpec);\n+      // Start supervisor\n+      supervisorId = indexer.submitSupervisor(taskSpec);\n+      LOG.info(\"Submitted supervisor\");\n+      // Start generating one third of the data (before resharding)\n+      int secondsToGenerateFirstRound = TOTAL_NUMBER_OF_SECOND / 3;\n+      secondsToGenerateRemaining = secondsToGenerateRemaining - secondsToGenerateFirstRound;\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateFirstRound, FIRST_EVENT_TIME);\n+      // Reshard the supervisor by split from KINESIS_SHARD_COUNT to newShardCount\n+      kinesisAdminClient.updateShardCount(streamName, newShardCount);\n+      // Start generating one third of the data (while resharding)\n+      int secondsToGenerateSecondRound = TOTAL_NUMBER_OF_SECOND / 3;\n+      secondsToGenerateRemaining = secondsToGenerateRemaining - secondsToGenerateSecondRound;\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateSecondRound, FIRST_EVENT_TIME.plusSeconds(secondsToGenerateFirstRound));\n+      // Wait for kinesis stream to finish resharding", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMzNzgwNw=="}, "originalCommit": {"oid": "d7637d53ff7fdee5ff28b15c49178b176bbf3a39"}, "originalPosition": 385}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMjAwOTM0Nw==", "bodyText": "From running locally, I can see that resharding does takes around 30000-40000ms (3-4 mins). This means that after issuing reshard call, when we check for \"updating status or an active status with the final expected number of shards\" immediately after, then very most likely it will be \"updating status\" that returns true (rather than \"active status with the final expected number of shards\"). I am only including \"active status with the final expected number of shards\" check in case the reshard finish by the time we do the check (most likely wont happen)", "url": "https://github.com/apache/druid/pull/9576#discussion_r402009347", "createdAt": "2020-04-02T01:57:08Z", "author": {"login": "maytasm"}, "path": "integration-tests/src/test/java/org/apache/druid/tests/indexer/ITKinesisIndexingServiceTest.java", "diffHunk": "@@ -0,0 +1,443 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.tests.indexer;\n+\n+import com.google.common.collect.ImmutableMap;\n+import com.google.inject.Inject;\n+import org.apache.druid.indexing.overlord.supervisor.SupervisorStateManager;\n+import org.apache.druid.java.util.common.DateTimes;\n+import org.apache.druid.java.util.common.StringUtils;\n+import org.apache.druid.java.util.common.logger.Logger;\n+import org.apache.druid.testing.guice.DruidTestModuleFactory;\n+import org.apache.druid.testing.utils.DruidClusterAdminClient;\n+import org.apache.druid.testing.utils.ITRetryUtil;\n+import org.apache.druid.testing.utils.KinesisAdminClient;\n+import org.apache.druid.testing.utils.KinesisEventWriter;\n+import org.apache.druid.testing.utils.WikipediaStreamEventStreamGenerator;\n+import org.apache.druid.tests.TestNGGroup;\n+import org.joda.time.DateTime;\n+import org.joda.time.format.DateTimeFormat;\n+import org.joda.time.format.DateTimeFormatter;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.AfterMethod;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.BeforeMethod;\n+import org.testng.annotations.Guice;\n+import org.testng.annotations.Test;\n+\n+import java.io.Closeable;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.function.Function;\n+\n+@Test(groups = TestNGGroup.KINESIS_INDEX)\n+@Guice(moduleFactory = DruidTestModuleFactory.class)\n+public class ITKinesisIndexingServiceTest extends AbstractITBatchIndexTest\n+{\n+  private static final Logger LOG = new Logger(AbstractKafkaIndexerTest.class);\n+  private static final int KINESIS_SHARD_COUNT = 2;\n+  private static final String STREAM_EXPIRE_TAG = \"druid-ci-expire-after\";\n+  private static final long WAIT_TIME_MILLIS = 3 * 60 * 1000L;\n+  private static final DateTime FIRST_EVENT_TIME = DateTimes.of(1994, 4, 29, 1, 0);\n+  private static final String INDEXER_FILE_LEGACY_PARSER = \"/indexer/stream_supervisor_spec_legacy_parser.json\";\n+  private static final String INDEXER_FILE_INPUT_FORMAT = \"/indexer/stream_supervisor_spec_input_format.json\";\n+  private static final String QUERIES_FILE = \"/indexer/stream_index_queries.json\";\n+  // format for the querying interval\n+  private static final DateTimeFormatter INTERVAL_FMT = DateTimeFormat.forPattern(\"yyyy-MM-dd'T'HH:mm:'00Z'\");\n+  // format for the expected timestamp in a query response\n+  private static final DateTimeFormatter TIMESTAMP_FMT = DateTimeFormat.forPattern(\"yyyy-MM-dd'T'HH:mm:ss'.000Z'\");\n+  private static final int EVENTS_PER_SECOND = 6;\n+  private static final long CYCLE_PADDING_MS = 100;\n+  private static final int TOTAL_NUMBER_OF_SECOND = 10;\n+\n+  @Inject\n+  private DruidClusterAdminClient druidClusterAdminClient;\n+\n+  private String streamName;\n+  private String fullDatasourceName;\n+  private KinesisAdminClient kinesisAdminClient;\n+  private KinesisEventWriter kinesisEventWriter;\n+  private WikipediaStreamEventStreamGenerator wikipediaStreamEventGenerator;\n+  private Function<String, String> kinesisIngestionPropsTransform;\n+  private Function<String, String> kinesisQueryPropsTransform;\n+  private String supervisorId;\n+  private int secondsToGenerateRemaining;\n+\n+  @BeforeClass\n+  public void beforeClass() throws Exception\n+  {\n+    kinesisAdminClient = new KinesisAdminClient(config.getStreamEndpoint());\n+    kinesisEventWriter = new KinesisEventWriter(config.getStreamEndpoint(), false);\n+    wikipediaStreamEventGenerator = new WikipediaStreamEventStreamGenerator(EVENTS_PER_SECOND, CYCLE_PADDING_MS);\n+  }\n+\n+  @AfterClass\n+  public void tearDown()\n+  {\n+    wikipediaStreamEventGenerator.shutdown();\n+    kinesisEventWriter.shutdown();\n+  }\n+\n+  @BeforeMethod\n+  public void before()\n+  {\n+    streamName = \"kinesis_index_test_\" + UUID.randomUUID();\n+    String datasource = \"kinesis_indexing_service_test_\" + UUID.randomUUID();\n+    Map<String, String> tags = ImmutableMap.of(STREAM_EXPIRE_TAG, Long.toString(DateTimes.nowUtc().plusMinutes(30).getMillis()));\n+    kinesisAdminClient.createStream(streamName, KINESIS_SHARD_COUNT, tags);\n+    ITRetryUtil.retryUntil(\n+        () -> kinesisAdminClient.isStreamActive(streamName),\n+        true,\n+        10000,\n+        30,\n+        \"Wait for stream active\"\n+    );\n+    secondsToGenerateRemaining = TOTAL_NUMBER_OF_SECOND;\n+    fullDatasourceName = datasource + config.getExtraDatasourceNameSuffix();\n+    kinesisIngestionPropsTransform = spec -> {\n+      try {\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%DATASOURCE%%\",\n+            fullDatasourceName\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%STREAM_TYPE%%\",\n+            \"kinesis\"\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TOPIC_KEY%%\",\n+            \"stream\"\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TOPIC_VALUE%%\",\n+            streamName\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%USE_EARLIEST_KEY%%\",\n+            \"useEarliestSequenceNumber\"\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%STREAM_PROPERTIES_KEY%%\",\n+            \"endpoint\"\n+        );\n+        return StringUtils.replace(\n+            spec,\n+            \"%%STREAM_PROPERTIES_VALUE%%\",\n+            jsonMapper.writeValueAsString(config.getStreamEndpoint())\n+        );\n+      }\n+      catch (Exception e) {\n+        throw new RuntimeException(e);\n+      }\n+    };\n+    kinesisQueryPropsTransform = spec -> {\n+      try {\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%DATASOURCE%%\",\n+            fullDatasourceName\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMEBOUNDARY_RESPONSE_TIMESTAMP%%\",\n+            TIMESTAMP_FMT.print(FIRST_EVENT_TIME)\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMEBOUNDARY_RESPONSE_MAXTIME%%\",\n+            TIMESTAMP_FMT.print(FIRST_EVENT_TIME.plusSeconds(TOTAL_NUMBER_OF_SECOND - 1))\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMEBOUNDARY_RESPONSE_MINTIME%%\",\n+            TIMESTAMP_FMT.print(FIRST_EVENT_TIME)\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_QUERY_START%%\",\n+            INTERVAL_FMT.print(FIRST_EVENT_TIME)\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_QUERY_END%%\",\n+            INTERVAL_FMT.print(FIRST_EVENT_TIME.plusSeconds(TOTAL_NUMBER_OF_SECOND - 1).plusMinutes(2))\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_RESPONSE_TIMESTAMP%%\",\n+            TIMESTAMP_FMT.print(FIRST_EVENT_TIME)\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_ADDED%%\",\n+            Long.toString(getSumOfEventSequence(EVENTS_PER_SECOND) * TOTAL_NUMBER_OF_SECOND)\n+        );\n+        return StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_NUMEVENTS%%\",\n+            Integer.toString(EVENTS_PER_SECOND * TOTAL_NUMBER_OF_SECOND)\n+        );\n+      }\n+      catch (Exception e) {\n+        throw new RuntimeException(e);\n+      }\n+    };\n+  }\n+\n+  @AfterMethod\n+  public void teardown()\n+  {\n+    try {\n+      kinesisEventWriter.flush();\n+      indexer.shutdownSupervisor(supervisorId);\n+      unloader(fullDatasourceName);\n+      kinesisAdminClient.deleteStream(streamName);\n+    }\n+    catch (Exception e) {\n+      // Best effort cleanup\n+    }\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithLegacyParserStableState() throws Exception\n+  {\n+    try (\n+        final Closeable ignored1 = unloader(fullDatasourceName)\n+    ) {\n+      final String taskSpec = kinesisIngestionPropsTransform.apply(getResourceAsString(INDEXER_FILE_LEGACY_PARSER));\n+      LOG.info(\"supervisorSpec: [%s]\\n\", taskSpec);\n+      // Start supervisor\n+      supervisorId = indexer.submitSupervisor(taskSpec);\n+      LOG.info(\"Submitted supervisor\");\n+      // Start Kinesis data generator\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, TOTAL_NUMBER_OF_SECOND, FIRST_EVENT_TIME);\n+      verifyIngestedData(supervisorId);\n+    }\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithInputFormatStableState() throws Exception\n+  {\n+    try (\n+        final Closeable ignored1 = unloader(fullDatasourceName)\n+    ) {\n+      final String taskSpec = kinesisIngestionPropsTransform.apply(getResourceAsString(INDEXER_FILE_INPUT_FORMAT));\n+      LOG.info(\"supervisorSpec: [%s]\\n\", taskSpec);\n+      // Start supervisor\n+      supervisorId = indexer.submitSupervisor(taskSpec);\n+      LOG.info(\"Submitted supervisor\");\n+      // Start Kinesis data generator\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, TOTAL_NUMBER_OF_SECOND, FIRST_EVENT_TIME);\n+      verifyIngestedData(supervisorId);\n+    }\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithLosingCoordinator() throws Exception\n+  {\n+    testIndexWithLosingNodeHelper(() -> druidClusterAdminClient.restartCoordinatorContainer(), () -> druidClusterAdminClient.waitUntilCoordinatorReady());\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithLosingOverlord() throws Exception\n+  {\n+    testIndexWithLosingNodeHelper(() -> druidClusterAdminClient.restartIndexerContainer(), () -> druidClusterAdminClient.waitUntilIndexerReady());\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithLosingHistorical() throws Exception\n+  {\n+    testIndexWithLosingNodeHelper(() -> druidClusterAdminClient.restartHistoricalContainer(), () -> druidClusterAdminClient.waitUntilHistoricalReady());\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithStartStopSupervisor() throws Exception\n+  {\n+    try (\n+        final Closeable ignored1 = unloader(fullDatasourceName)\n+    ) {\n+      final String taskSpec = kinesisIngestionPropsTransform.apply(getResourceAsString(INDEXER_FILE_INPUT_FORMAT));\n+      LOG.info(\"supervisorSpec: [%s]\\n\", taskSpec);\n+      // Start supervisor\n+      supervisorId = indexer.submitSupervisor(taskSpec);\n+      LOG.info(\"Submitted supervisor\");\n+      // Start generating half of the data\n+      int secondsToGenerateFirstRound = TOTAL_NUMBER_OF_SECOND / 2;\n+      secondsToGenerateRemaining = secondsToGenerateRemaining - secondsToGenerateFirstRound;\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateFirstRound, FIRST_EVENT_TIME);\n+      // Suspend the supervisor\n+      indexer.suspendSupervisor(supervisorId);\n+      // Start generating remainning half of the data\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateRemaining, FIRST_EVENT_TIME.plusSeconds(secondsToGenerateFirstRound));\n+      // Resume the supervisor\n+      indexer.resumeSupervisor(supervisorId);\n+      // Verify supervisor is healthy after suspension\n+      ITRetryUtil.retryUntil(\n+          () -> SupervisorStateManager.BasicState.RUNNING.equals(indexer.getSupervisorStatus(supervisorId)),\n+          true,\n+          10000,\n+          30,\n+          \"Waiting for supervisor to be healthy\"\n+      );\n+      // Verify that supervisor can catch up with the stream\n+      verifyIngestedData(supervisorId);\n+    }\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithKinesisReshardSplit() throws Exception\n+  {\n+    // Reshard the supervisor by split from KINESIS_SHARD_COUNT to KINESIS_SHARD_COUNT * 2\n+    testIndexWithKinesisReshardHelper(KINESIS_SHARD_COUNT * 2);\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithKinesisReshardMerge() throws Exception\n+  {\n+    // Reshard the supervisor by split from KINESIS_SHARD_COUNT to KINESIS_SHARD_COUNT / 2\n+    testIndexWithKinesisReshardHelper(KINESIS_SHARD_COUNT / 2);\n+  }\n+\n+  private void testIndexWithLosingNodeHelper(Runnable restartRunnable, Runnable waitForReadyRunnable) throws Exception\n+  {\n+    try (\n+        final Closeable ignored1 = unloader(fullDatasourceName)\n+    ) {\n+      final String taskSpec = kinesisIngestionPropsTransform.apply(getResourceAsString(INDEXER_FILE_INPUT_FORMAT));\n+      LOG.info(\"supervisorSpec: [%s]\\n\", taskSpec);\n+      // Start supervisor\n+      supervisorId = indexer.submitSupervisor(taskSpec);\n+      LOG.info(\"Submitted supervisor\");\n+      // Start generating one third of the data (before restarting)\n+      int secondsToGenerateFirstRound = TOTAL_NUMBER_OF_SECOND / 3;\n+      secondsToGenerateRemaining = secondsToGenerateRemaining - secondsToGenerateFirstRound;\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateFirstRound, FIRST_EVENT_TIME);\n+      // Restart Druid process\n+      LOG.info(\"Restarting Druid process\");\n+      restartRunnable.run();\n+      LOG.info(\"Restarted Druid process\");\n+      // Start generating one third of the data (while restarting)\n+      int secondsToGenerateSecondRound = TOTAL_NUMBER_OF_SECOND / 3;\n+      secondsToGenerateRemaining = secondsToGenerateRemaining - secondsToGenerateSecondRound;\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateSecondRound, FIRST_EVENT_TIME.plusSeconds(secondsToGenerateFirstRound));\n+      // Wait for Druid process to be available\n+      LOG.info(\"Waiting for Druid process to be available\");\n+      waitForReadyRunnable.run();\n+      LOG.info(\"Druid process is now available\");\n+      // Start generating remainding data (after restarting)\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateRemaining, FIRST_EVENT_TIME.plusSeconds(secondsToGenerateFirstRound + secondsToGenerateSecondRound));\n+      // Verify supervisor is healthy\n+      ITRetryUtil.retryUntil(\n+          () -> SupervisorStateManager.BasicState.RUNNING.equals(indexer.getSupervisorStatus(supervisorId)),\n+          true,\n+          10000,\n+          30,\n+          \"Waiting for supervisor to be healthy\"\n+      );\n+      // Verify that supervisor ingested all data\n+      verifyIngestedData(supervisorId);\n+    }\n+  }\n+\n+  private void testIndexWithKinesisReshardHelper(int newShardCount) throws Exception\n+  {\n+    try (\n+        final Closeable ignored1 = unloader(fullDatasourceName)\n+    ) {\n+      final String taskSpec = kinesisIngestionPropsTransform.apply(getResourceAsString(INDEXER_FILE_INPUT_FORMAT));\n+      LOG.info(\"supervisorSpec: [%s]\\n\", taskSpec);\n+      // Start supervisor\n+      supervisorId = indexer.submitSupervisor(taskSpec);\n+      LOG.info(\"Submitted supervisor\");\n+      // Start generating one third of the data (before resharding)\n+      int secondsToGenerateFirstRound = TOTAL_NUMBER_OF_SECOND / 3;\n+      secondsToGenerateRemaining = secondsToGenerateRemaining - secondsToGenerateFirstRound;\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateFirstRound, FIRST_EVENT_TIME);\n+      // Reshard the supervisor by split from KINESIS_SHARD_COUNT to newShardCount\n+      kinesisAdminClient.updateShardCount(streamName, newShardCount);\n+      // Start generating one third of the data (while resharding)\n+      int secondsToGenerateSecondRound = TOTAL_NUMBER_OF_SECOND / 3;\n+      secondsToGenerateRemaining = secondsToGenerateRemaining - secondsToGenerateSecondRound;\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateSecondRound, FIRST_EVENT_TIME.plusSeconds(secondsToGenerateFirstRound));\n+      // Wait for kinesis stream to finish resharding", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMzNzgwNw=="}, "originalCommit": {"oid": "d7637d53ff7fdee5ff28b15c49178b176bbf3a39"}, "originalPosition": 385}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4ODk1MjA5OnYy", "diffSide": "RIGHT", "path": "integration-tests/src/test/java/org/apache/druid/tests/indexer/ITKinesisIndexingServiceTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwMzo0MzowMVrOF-vyXw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMDo1MDozMVrOF_Xqrw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMzODk3NQ==", "bodyText": "Suggest having a supervisor healthy check as well before the resharding occurs, so the resharding occurs while the supervisor is running", "url": "https://github.com/apache/druid/pull/9576#discussion_r401338975", "createdAt": "2020-04-01T03:43:01Z", "author": {"login": "jon-wei"}, "path": "integration-tests/src/test/java/org/apache/druid/tests/indexer/ITKinesisIndexingServiceTest.java", "diffHunk": "@@ -0,0 +1,443 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.tests.indexer;\n+\n+import com.google.common.collect.ImmutableMap;\n+import com.google.inject.Inject;\n+import org.apache.druid.indexing.overlord.supervisor.SupervisorStateManager;\n+import org.apache.druid.java.util.common.DateTimes;\n+import org.apache.druid.java.util.common.StringUtils;\n+import org.apache.druid.java.util.common.logger.Logger;\n+import org.apache.druid.testing.guice.DruidTestModuleFactory;\n+import org.apache.druid.testing.utils.DruidClusterAdminClient;\n+import org.apache.druid.testing.utils.ITRetryUtil;\n+import org.apache.druid.testing.utils.KinesisAdminClient;\n+import org.apache.druid.testing.utils.KinesisEventWriter;\n+import org.apache.druid.testing.utils.WikipediaStreamEventStreamGenerator;\n+import org.apache.druid.tests.TestNGGroup;\n+import org.joda.time.DateTime;\n+import org.joda.time.format.DateTimeFormat;\n+import org.joda.time.format.DateTimeFormatter;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.AfterMethod;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.BeforeMethod;\n+import org.testng.annotations.Guice;\n+import org.testng.annotations.Test;\n+\n+import java.io.Closeable;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.function.Function;\n+\n+@Test(groups = TestNGGroup.KINESIS_INDEX)\n+@Guice(moduleFactory = DruidTestModuleFactory.class)\n+public class ITKinesisIndexingServiceTest extends AbstractITBatchIndexTest\n+{\n+  private static final Logger LOG = new Logger(AbstractKafkaIndexerTest.class);\n+  private static final int KINESIS_SHARD_COUNT = 2;\n+  private static final String STREAM_EXPIRE_TAG = \"druid-ci-expire-after\";\n+  private static final long WAIT_TIME_MILLIS = 3 * 60 * 1000L;\n+  private static final DateTime FIRST_EVENT_TIME = DateTimes.of(1994, 4, 29, 1, 0);\n+  private static final String INDEXER_FILE_LEGACY_PARSER = \"/indexer/stream_supervisor_spec_legacy_parser.json\";\n+  private static final String INDEXER_FILE_INPUT_FORMAT = \"/indexer/stream_supervisor_spec_input_format.json\";\n+  private static final String QUERIES_FILE = \"/indexer/stream_index_queries.json\";\n+  // format for the querying interval\n+  private static final DateTimeFormatter INTERVAL_FMT = DateTimeFormat.forPattern(\"yyyy-MM-dd'T'HH:mm:'00Z'\");\n+  // format for the expected timestamp in a query response\n+  private static final DateTimeFormatter TIMESTAMP_FMT = DateTimeFormat.forPattern(\"yyyy-MM-dd'T'HH:mm:ss'.000Z'\");\n+  private static final int EVENTS_PER_SECOND = 6;\n+  private static final long CYCLE_PADDING_MS = 100;\n+  private static final int TOTAL_NUMBER_OF_SECOND = 10;\n+\n+  @Inject\n+  private DruidClusterAdminClient druidClusterAdminClient;\n+\n+  private String streamName;\n+  private String fullDatasourceName;\n+  private KinesisAdminClient kinesisAdminClient;\n+  private KinesisEventWriter kinesisEventWriter;\n+  private WikipediaStreamEventStreamGenerator wikipediaStreamEventGenerator;\n+  private Function<String, String> kinesisIngestionPropsTransform;\n+  private Function<String, String> kinesisQueryPropsTransform;\n+  private String supervisorId;\n+  private int secondsToGenerateRemaining;\n+\n+  @BeforeClass\n+  public void beforeClass() throws Exception\n+  {\n+    kinesisAdminClient = new KinesisAdminClient(config.getStreamEndpoint());\n+    kinesisEventWriter = new KinesisEventWriter(config.getStreamEndpoint(), false);\n+    wikipediaStreamEventGenerator = new WikipediaStreamEventStreamGenerator(EVENTS_PER_SECOND, CYCLE_PADDING_MS);\n+  }\n+\n+  @AfterClass\n+  public void tearDown()\n+  {\n+    wikipediaStreamEventGenerator.shutdown();\n+    kinesisEventWriter.shutdown();\n+  }\n+\n+  @BeforeMethod\n+  public void before()\n+  {\n+    streamName = \"kinesis_index_test_\" + UUID.randomUUID();\n+    String datasource = \"kinesis_indexing_service_test_\" + UUID.randomUUID();\n+    Map<String, String> tags = ImmutableMap.of(STREAM_EXPIRE_TAG, Long.toString(DateTimes.nowUtc().plusMinutes(30).getMillis()));\n+    kinesisAdminClient.createStream(streamName, KINESIS_SHARD_COUNT, tags);\n+    ITRetryUtil.retryUntil(\n+        () -> kinesisAdminClient.isStreamActive(streamName),\n+        true,\n+        10000,\n+        30,\n+        \"Wait for stream active\"\n+    );\n+    secondsToGenerateRemaining = TOTAL_NUMBER_OF_SECOND;\n+    fullDatasourceName = datasource + config.getExtraDatasourceNameSuffix();\n+    kinesisIngestionPropsTransform = spec -> {\n+      try {\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%DATASOURCE%%\",\n+            fullDatasourceName\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%STREAM_TYPE%%\",\n+            \"kinesis\"\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TOPIC_KEY%%\",\n+            \"stream\"\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TOPIC_VALUE%%\",\n+            streamName\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%USE_EARLIEST_KEY%%\",\n+            \"useEarliestSequenceNumber\"\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%STREAM_PROPERTIES_KEY%%\",\n+            \"endpoint\"\n+        );\n+        return StringUtils.replace(\n+            spec,\n+            \"%%STREAM_PROPERTIES_VALUE%%\",\n+            jsonMapper.writeValueAsString(config.getStreamEndpoint())\n+        );\n+      }\n+      catch (Exception e) {\n+        throw new RuntimeException(e);\n+      }\n+    };\n+    kinesisQueryPropsTransform = spec -> {\n+      try {\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%DATASOURCE%%\",\n+            fullDatasourceName\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMEBOUNDARY_RESPONSE_TIMESTAMP%%\",\n+            TIMESTAMP_FMT.print(FIRST_EVENT_TIME)\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMEBOUNDARY_RESPONSE_MAXTIME%%\",\n+            TIMESTAMP_FMT.print(FIRST_EVENT_TIME.plusSeconds(TOTAL_NUMBER_OF_SECOND - 1))\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMEBOUNDARY_RESPONSE_MINTIME%%\",\n+            TIMESTAMP_FMT.print(FIRST_EVENT_TIME)\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_QUERY_START%%\",\n+            INTERVAL_FMT.print(FIRST_EVENT_TIME)\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_QUERY_END%%\",\n+            INTERVAL_FMT.print(FIRST_EVENT_TIME.plusSeconds(TOTAL_NUMBER_OF_SECOND - 1).plusMinutes(2))\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_RESPONSE_TIMESTAMP%%\",\n+            TIMESTAMP_FMT.print(FIRST_EVENT_TIME)\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_ADDED%%\",\n+            Long.toString(getSumOfEventSequence(EVENTS_PER_SECOND) * TOTAL_NUMBER_OF_SECOND)\n+        );\n+        return StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_NUMEVENTS%%\",\n+            Integer.toString(EVENTS_PER_SECOND * TOTAL_NUMBER_OF_SECOND)\n+        );\n+      }\n+      catch (Exception e) {\n+        throw new RuntimeException(e);\n+      }\n+    };\n+  }\n+\n+  @AfterMethod\n+  public void teardown()\n+  {\n+    try {\n+      kinesisEventWriter.flush();\n+      indexer.shutdownSupervisor(supervisorId);\n+      unloader(fullDatasourceName);\n+      kinesisAdminClient.deleteStream(streamName);\n+    }\n+    catch (Exception e) {\n+      // Best effort cleanup\n+    }\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithLegacyParserStableState() throws Exception\n+  {\n+    try (\n+        final Closeable ignored1 = unloader(fullDatasourceName)\n+    ) {\n+      final String taskSpec = kinesisIngestionPropsTransform.apply(getResourceAsString(INDEXER_FILE_LEGACY_PARSER));\n+      LOG.info(\"supervisorSpec: [%s]\\n\", taskSpec);\n+      // Start supervisor\n+      supervisorId = indexer.submitSupervisor(taskSpec);\n+      LOG.info(\"Submitted supervisor\");\n+      // Start Kinesis data generator\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, TOTAL_NUMBER_OF_SECOND, FIRST_EVENT_TIME);\n+      verifyIngestedData(supervisorId);\n+    }\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithInputFormatStableState() throws Exception\n+  {\n+    try (\n+        final Closeable ignored1 = unloader(fullDatasourceName)\n+    ) {\n+      final String taskSpec = kinesisIngestionPropsTransform.apply(getResourceAsString(INDEXER_FILE_INPUT_FORMAT));\n+      LOG.info(\"supervisorSpec: [%s]\\n\", taskSpec);\n+      // Start supervisor\n+      supervisorId = indexer.submitSupervisor(taskSpec);\n+      LOG.info(\"Submitted supervisor\");\n+      // Start Kinesis data generator\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, TOTAL_NUMBER_OF_SECOND, FIRST_EVENT_TIME);\n+      verifyIngestedData(supervisorId);\n+    }\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithLosingCoordinator() throws Exception\n+  {\n+    testIndexWithLosingNodeHelper(() -> druidClusterAdminClient.restartCoordinatorContainer(), () -> druidClusterAdminClient.waitUntilCoordinatorReady());\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithLosingOverlord() throws Exception\n+  {\n+    testIndexWithLosingNodeHelper(() -> druidClusterAdminClient.restartIndexerContainer(), () -> druidClusterAdminClient.waitUntilIndexerReady());\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithLosingHistorical() throws Exception\n+  {\n+    testIndexWithLosingNodeHelper(() -> druidClusterAdminClient.restartHistoricalContainer(), () -> druidClusterAdminClient.waitUntilHistoricalReady());\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithStartStopSupervisor() throws Exception\n+  {\n+    try (\n+        final Closeable ignored1 = unloader(fullDatasourceName)\n+    ) {\n+      final String taskSpec = kinesisIngestionPropsTransform.apply(getResourceAsString(INDEXER_FILE_INPUT_FORMAT));\n+      LOG.info(\"supervisorSpec: [%s]\\n\", taskSpec);\n+      // Start supervisor\n+      supervisorId = indexer.submitSupervisor(taskSpec);\n+      LOG.info(\"Submitted supervisor\");\n+      // Start generating half of the data\n+      int secondsToGenerateFirstRound = TOTAL_NUMBER_OF_SECOND / 2;\n+      secondsToGenerateRemaining = secondsToGenerateRemaining - secondsToGenerateFirstRound;\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateFirstRound, FIRST_EVENT_TIME);\n+      // Suspend the supervisor\n+      indexer.suspendSupervisor(supervisorId);\n+      // Start generating remainning half of the data\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateRemaining, FIRST_EVENT_TIME.plusSeconds(secondsToGenerateFirstRound));\n+      // Resume the supervisor\n+      indexer.resumeSupervisor(supervisorId);\n+      // Verify supervisor is healthy after suspension\n+      ITRetryUtil.retryUntil(\n+          () -> SupervisorStateManager.BasicState.RUNNING.equals(indexer.getSupervisorStatus(supervisorId)),\n+          true,\n+          10000,\n+          30,\n+          \"Waiting for supervisor to be healthy\"\n+      );\n+      // Verify that supervisor can catch up with the stream\n+      verifyIngestedData(supervisorId);\n+    }\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithKinesisReshardSplit() throws Exception\n+  {\n+    // Reshard the supervisor by split from KINESIS_SHARD_COUNT to KINESIS_SHARD_COUNT * 2\n+    testIndexWithKinesisReshardHelper(KINESIS_SHARD_COUNT * 2);\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithKinesisReshardMerge() throws Exception\n+  {\n+    // Reshard the supervisor by split from KINESIS_SHARD_COUNT to KINESIS_SHARD_COUNT / 2\n+    testIndexWithKinesisReshardHelper(KINESIS_SHARD_COUNT / 2);\n+  }\n+\n+  private void testIndexWithLosingNodeHelper(Runnable restartRunnable, Runnable waitForReadyRunnable) throws Exception\n+  {\n+    try (\n+        final Closeable ignored1 = unloader(fullDatasourceName)\n+    ) {\n+      final String taskSpec = kinesisIngestionPropsTransform.apply(getResourceAsString(INDEXER_FILE_INPUT_FORMAT));\n+      LOG.info(\"supervisorSpec: [%s]\\n\", taskSpec);\n+      // Start supervisor\n+      supervisorId = indexer.submitSupervisor(taskSpec);\n+      LOG.info(\"Submitted supervisor\");\n+      // Start generating one third of the data (before restarting)\n+      int secondsToGenerateFirstRound = TOTAL_NUMBER_OF_SECOND / 3;\n+      secondsToGenerateRemaining = secondsToGenerateRemaining - secondsToGenerateFirstRound;\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateFirstRound, FIRST_EVENT_TIME);\n+      // Restart Druid process\n+      LOG.info(\"Restarting Druid process\");\n+      restartRunnable.run();\n+      LOG.info(\"Restarted Druid process\");\n+      // Start generating one third of the data (while restarting)\n+      int secondsToGenerateSecondRound = TOTAL_NUMBER_OF_SECOND / 3;\n+      secondsToGenerateRemaining = secondsToGenerateRemaining - secondsToGenerateSecondRound;\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateSecondRound, FIRST_EVENT_TIME.plusSeconds(secondsToGenerateFirstRound));\n+      // Wait for Druid process to be available\n+      LOG.info(\"Waiting for Druid process to be available\");\n+      waitForReadyRunnable.run();\n+      LOG.info(\"Druid process is now available\");\n+      // Start generating remainding data (after restarting)\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateRemaining, FIRST_EVENT_TIME.plusSeconds(secondsToGenerateFirstRound + secondsToGenerateSecondRound));\n+      // Verify supervisor is healthy\n+      ITRetryUtil.retryUntil(\n+          () -> SupervisorStateManager.BasicState.RUNNING.equals(indexer.getSupervisorStatus(supervisorId)),\n+          true,\n+          10000,\n+          30,\n+          \"Waiting for supervisor to be healthy\"\n+      );\n+      // Verify that supervisor ingested all data\n+      verifyIngestedData(supervisorId);\n+    }\n+  }\n+\n+  private void testIndexWithKinesisReshardHelper(int newShardCount) throws Exception\n+  {\n+    try (\n+        final Closeable ignored1 = unloader(fullDatasourceName)\n+    ) {\n+      final String taskSpec = kinesisIngestionPropsTransform.apply(getResourceAsString(INDEXER_FILE_INPUT_FORMAT));\n+      LOG.info(\"supervisorSpec: [%s]\\n\", taskSpec);\n+      // Start supervisor\n+      supervisorId = indexer.submitSupervisor(taskSpec);\n+      LOG.info(\"Submitted supervisor\");\n+      // Start generating one third of the data (before resharding)\n+      int secondsToGenerateFirstRound = TOTAL_NUMBER_OF_SECOND / 3;\n+      secondsToGenerateRemaining = secondsToGenerateRemaining - secondsToGenerateFirstRound;\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateFirstRound, FIRST_EVENT_TIME);\n+      // Reshard the supervisor by split from KINESIS_SHARD_COUNT to newShardCount\n+      kinesisAdminClient.updateShardCount(streamName, newShardCount);\n+      // Start generating one third of the data (while resharding)\n+      int secondsToGenerateSecondRound = TOTAL_NUMBER_OF_SECOND / 3;\n+      secondsToGenerateRemaining = secondsToGenerateRemaining - secondsToGenerateSecondRound;\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateSecondRound, FIRST_EVENT_TIME.plusSeconds(secondsToGenerateFirstRound));\n+      // Wait for kinesis stream to finish resharding\n+      ITRetryUtil.retryUntil(\n+          () -> kinesisAdminClient.isStreamActive(streamName),\n+          true,\n+          10000,\n+          30,\n+          \"Waiting for Kinesis stream to finish resharding\"\n+      );\n+      // Start generating remainding data (after resharding)\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateRemaining, FIRST_EVENT_TIME.plusSeconds(secondsToGenerateFirstRound + secondsToGenerateSecondRound));\n+      // Verify supervisor is healthy after suspension", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d7637d53ff7fdee5ff28b15c49178b176bbf3a39"}, "originalPosition": 395}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTk5MjM2Nw==", "bodyText": "Done", "url": "https://github.com/apache/druid/pull/9576#discussion_r401992367", "createdAt": "2020-04-02T00:50:31Z", "author": {"login": "maytasm"}, "path": "integration-tests/src/test/java/org/apache/druid/tests/indexer/ITKinesisIndexingServiceTest.java", "diffHunk": "@@ -0,0 +1,443 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.tests.indexer;\n+\n+import com.google.common.collect.ImmutableMap;\n+import com.google.inject.Inject;\n+import org.apache.druid.indexing.overlord.supervisor.SupervisorStateManager;\n+import org.apache.druid.java.util.common.DateTimes;\n+import org.apache.druid.java.util.common.StringUtils;\n+import org.apache.druid.java.util.common.logger.Logger;\n+import org.apache.druid.testing.guice.DruidTestModuleFactory;\n+import org.apache.druid.testing.utils.DruidClusterAdminClient;\n+import org.apache.druid.testing.utils.ITRetryUtil;\n+import org.apache.druid.testing.utils.KinesisAdminClient;\n+import org.apache.druid.testing.utils.KinesisEventWriter;\n+import org.apache.druid.testing.utils.WikipediaStreamEventStreamGenerator;\n+import org.apache.druid.tests.TestNGGroup;\n+import org.joda.time.DateTime;\n+import org.joda.time.format.DateTimeFormat;\n+import org.joda.time.format.DateTimeFormatter;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.AfterMethod;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.BeforeMethod;\n+import org.testng.annotations.Guice;\n+import org.testng.annotations.Test;\n+\n+import java.io.Closeable;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.function.Function;\n+\n+@Test(groups = TestNGGroup.KINESIS_INDEX)\n+@Guice(moduleFactory = DruidTestModuleFactory.class)\n+public class ITKinesisIndexingServiceTest extends AbstractITBatchIndexTest\n+{\n+  private static final Logger LOG = new Logger(AbstractKafkaIndexerTest.class);\n+  private static final int KINESIS_SHARD_COUNT = 2;\n+  private static final String STREAM_EXPIRE_TAG = \"druid-ci-expire-after\";\n+  private static final long WAIT_TIME_MILLIS = 3 * 60 * 1000L;\n+  private static final DateTime FIRST_EVENT_TIME = DateTimes.of(1994, 4, 29, 1, 0);\n+  private static final String INDEXER_FILE_LEGACY_PARSER = \"/indexer/stream_supervisor_spec_legacy_parser.json\";\n+  private static final String INDEXER_FILE_INPUT_FORMAT = \"/indexer/stream_supervisor_spec_input_format.json\";\n+  private static final String QUERIES_FILE = \"/indexer/stream_index_queries.json\";\n+  // format for the querying interval\n+  private static final DateTimeFormatter INTERVAL_FMT = DateTimeFormat.forPattern(\"yyyy-MM-dd'T'HH:mm:'00Z'\");\n+  // format for the expected timestamp in a query response\n+  private static final DateTimeFormatter TIMESTAMP_FMT = DateTimeFormat.forPattern(\"yyyy-MM-dd'T'HH:mm:ss'.000Z'\");\n+  private static final int EVENTS_PER_SECOND = 6;\n+  private static final long CYCLE_PADDING_MS = 100;\n+  private static final int TOTAL_NUMBER_OF_SECOND = 10;\n+\n+  @Inject\n+  private DruidClusterAdminClient druidClusterAdminClient;\n+\n+  private String streamName;\n+  private String fullDatasourceName;\n+  private KinesisAdminClient kinesisAdminClient;\n+  private KinesisEventWriter kinesisEventWriter;\n+  private WikipediaStreamEventStreamGenerator wikipediaStreamEventGenerator;\n+  private Function<String, String> kinesisIngestionPropsTransform;\n+  private Function<String, String> kinesisQueryPropsTransform;\n+  private String supervisorId;\n+  private int secondsToGenerateRemaining;\n+\n+  @BeforeClass\n+  public void beforeClass() throws Exception\n+  {\n+    kinesisAdminClient = new KinesisAdminClient(config.getStreamEndpoint());\n+    kinesisEventWriter = new KinesisEventWriter(config.getStreamEndpoint(), false);\n+    wikipediaStreamEventGenerator = new WikipediaStreamEventStreamGenerator(EVENTS_PER_SECOND, CYCLE_PADDING_MS);\n+  }\n+\n+  @AfterClass\n+  public void tearDown()\n+  {\n+    wikipediaStreamEventGenerator.shutdown();\n+    kinesisEventWriter.shutdown();\n+  }\n+\n+  @BeforeMethod\n+  public void before()\n+  {\n+    streamName = \"kinesis_index_test_\" + UUID.randomUUID();\n+    String datasource = \"kinesis_indexing_service_test_\" + UUID.randomUUID();\n+    Map<String, String> tags = ImmutableMap.of(STREAM_EXPIRE_TAG, Long.toString(DateTimes.nowUtc().plusMinutes(30).getMillis()));\n+    kinesisAdminClient.createStream(streamName, KINESIS_SHARD_COUNT, tags);\n+    ITRetryUtil.retryUntil(\n+        () -> kinesisAdminClient.isStreamActive(streamName),\n+        true,\n+        10000,\n+        30,\n+        \"Wait for stream active\"\n+    );\n+    secondsToGenerateRemaining = TOTAL_NUMBER_OF_SECOND;\n+    fullDatasourceName = datasource + config.getExtraDatasourceNameSuffix();\n+    kinesisIngestionPropsTransform = spec -> {\n+      try {\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%DATASOURCE%%\",\n+            fullDatasourceName\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%STREAM_TYPE%%\",\n+            \"kinesis\"\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TOPIC_KEY%%\",\n+            \"stream\"\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TOPIC_VALUE%%\",\n+            streamName\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%USE_EARLIEST_KEY%%\",\n+            \"useEarliestSequenceNumber\"\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%STREAM_PROPERTIES_KEY%%\",\n+            \"endpoint\"\n+        );\n+        return StringUtils.replace(\n+            spec,\n+            \"%%STREAM_PROPERTIES_VALUE%%\",\n+            jsonMapper.writeValueAsString(config.getStreamEndpoint())\n+        );\n+      }\n+      catch (Exception e) {\n+        throw new RuntimeException(e);\n+      }\n+    };\n+    kinesisQueryPropsTransform = spec -> {\n+      try {\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%DATASOURCE%%\",\n+            fullDatasourceName\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMEBOUNDARY_RESPONSE_TIMESTAMP%%\",\n+            TIMESTAMP_FMT.print(FIRST_EVENT_TIME)\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMEBOUNDARY_RESPONSE_MAXTIME%%\",\n+            TIMESTAMP_FMT.print(FIRST_EVENT_TIME.plusSeconds(TOTAL_NUMBER_OF_SECOND - 1))\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMEBOUNDARY_RESPONSE_MINTIME%%\",\n+            TIMESTAMP_FMT.print(FIRST_EVENT_TIME)\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_QUERY_START%%\",\n+            INTERVAL_FMT.print(FIRST_EVENT_TIME)\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_QUERY_END%%\",\n+            INTERVAL_FMT.print(FIRST_EVENT_TIME.plusSeconds(TOTAL_NUMBER_OF_SECOND - 1).plusMinutes(2))\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_RESPONSE_TIMESTAMP%%\",\n+            TIMESTAMP_FMT.print(FIRST_EVENT_TIME)\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_ADDED%%\",\n+            Long.toString(getSumOfEventSequence(EVENTS_PER_SECOND) * TOTAL_NUMBER_OF_SECOND)\n+        );\n+        return StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_NUMEVENTS%%\",\n+            Integer.toString(EVENTS_PER_SECOND * TOTAL_NUMBER_OF_SECOND)\n+        );\n+      }\n+      catch (Exception e) {\n+        throw new RuntimeException(e);\n+      }\n+    };\n+  }\n+\n+  @AfterMethod\n+  public void teardown()\n+  {\n+    try {\n+      kinesisEventWriter.flush();\n+      indexer.shutdownSupervisor(supervisorId);\n+      unloader(fullDatasourceName);\n+      kinesisAdminClient.deleteStream(streamName);\n+    }\n+    catch (Exception e) {\n+      // Best effort cleanup\n+    }\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithLegacyParserStableState() throws Exception\n+  {\n+    try (\n+        final Closeable ignored1 = unloader(fullDatasourceName)\n+    ) {\n+      final String taskSpec = kinesisIngestionPropsTransform.apply(getResourceAsString(INDEXER_FILE_LEGACY_PARSER));\n+      LOG.info(\"supervisorSpec: [%s]\\n\", taskSpec);\n+      // Start supervisor\n+      supervisorId = indexer.submitSupervisor(taskSpec);\n+      LOG.info(\"Submitted supervisor\");\n+      // Start Kinesis data generator\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, TOTAL_NUMBER_OF_SECOND, FIRST_EVENT_TIME);\n+      verifyIngestedData(supervisorId);\n+    }\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithInputFormatStableState() throws Exception\n+  {\n+    try (\n+        final Closeable ignored1 = unloader(fullDatasourceName)\n+    ) {\n+      final String taskSpec = kinesisIngestionPropsTransform.apply(getResourceAsString(INDEXER_FILE_INPUT_FORMAT));\n+      LOG.info(\"supervisorSpec: [%s]\\n\", taskSpec);\n+      // Start supervisor\n+      supervisorId = indexer.submitSupervisor(taskSpec);\n+      LOG.info(\"Submitted supervisor\");\n+      // Start Kinesis data generator\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, TOTAL_NUMBER_OF_SECOND, FIRST_EVENT_TIME);\n+      verifyIngestedData(supervisorId);\n+    }\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithLosingCoordinator() throws Exception\n+  {\n+    testIndexWithLosingNodeHelper(() -> druidClusterAdminClient.restartCoordinatorContainer(), () -> druidClusterAdminClient.waitUntilCoordinatorReady());\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithLosingOverlord() throws Exception\n+  {\n+    testIndexWithLosingNodeHelper(() -> druidClusterAdminClient.restartIndexerContainer(), () -> druidClusterAdminClient.waitUntilIndexerReady());\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithLosingHistorical() throws Exception\n+  {\n+    testIndexWithLosingNodeHelper(() -> druidClusterAdminClient.restartHistoricalContainer(), () -> druidClusterAdminClient.waitUntilHistoricalReady());\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithStartStopSupervisor() throws Exception\n+  {\n+    try (\n+        final Closeable ignored1 = unloader(fullDatasourceName)\n+    ) {\n+      final String taskSpec = kinesisIngestionPropsTransform.apply(getResourceAsString(INDEXER_FILE_INPUT_FORMAT));\n+      LOG.info(\"supervisorSpec: [%s]\\n\", taskSpec);\n+      // Start supervisor\n+      supervisorId = indexer.submitSupervisor(taskSpec);\n+      LOG.info(\"Submitted supervisor\");\n+      // Start generating half of the data\n+      int secondsToGenerateFirstRound = TOTAL_NUMBER_OF_SECOND / 2;\n+      secondsToGenerateRemaining = secondsToGenerateRemaining - secondsToGenerateFirstRound;\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateFirstRound, FIRST_EVENT_TIME);\n+      // Suspend the supervisor\n+      indexer.suspendSupervisor(supervisorId);\n+      // Start generating remainning half of the data\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateRemaining, FIRST_EVENT_TIME.plusSeconds(secondsToGenerateFirstRound));\n+      // Resume the supervisor\n+      indexer.resumeSupervisor(supervisorId);\n+      // Verify supervisor is healthy after suspension\n+      ITRetryUtil.retryUntil(\n+          () -> SupervisorStateManager.BasicState.RUNNING.equals(indexer.getSupervisorStatus(supervisorId)),\n+          true,\n+          10000,\n+          30,\n+          \"Waiting for supervisor to be healthy\"\n+      );\n+      // Verify that supervisor can catch up with the stream\n+      verifyIngestedData(supervisorId);\n+    }\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithKinesisReshardSplit() throws Exception\n+  {\n+    // Reshard the supervisor by split from KINESIS_SHARD_COUNT to KINESIS_SHARD_COUNT * 2\n+    testIndexWithKinesisReshardHelper(KINESIS_SHARD_COUNT * 2);\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithKinesisReshardMerge() throws Exception\n+  {\n+    // Reshard the supervisor by split from KINESIS_SHARD_COUNT to KINESIS_SHARD_COUNT / 2\n+    testIndexWithKinesisReshardHelper(KINESIS_SHARD_COUNT / 2);\n+  }\n+\n+  private void testIndexWithLosingNodeHelper(Runnable restartRunnable, Runnable waitForReadyRunnable) throws Exception\n+  {\n+    try (\n+        final Closeable ignored1 = unloader(fullDatasourceName)\n+    ) {\n+      final String taskSpec = kinesisIngestionPropsTransform.apply(getResourceAsString(INDEXER_FILE_INPUT_FORMAT));\n+      LOG.info(\"supervisorSpec: [%s]\\n\", taskSpec);\n+      // Start supervisor\n+      supervisorId = indexer.submitSupervisor(taskSpec);\n+      LOG.info(\"Submitted supervisor\");\n+      // Start generating one third of the data (before restarting)\n+      int secondsToGenerateFirstRound = TOTAL_NUMBER_OF_SECOND / 3;\n+      secondsToGenerateRemaining = secondsToGenerateRemaining - secondsToGenerateFirstRound;\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateFirstRound, FIRST_EVENT_TIME);\n+      // Restart Druid process\n+      LOG.info(\"Restarting Druid process\");\n+      restartRunnable.run();\n+      LOG.info(\"Restarted Druid process\");\n+      // Start generating one third of the data (while restarting)\n+      int secondsToGenerateSecondRound = TOTAL_NUMBER_OF_SECOND / 3;\n+      secondsToGenerateRemaining = secondsToGenerateRemaining - secondsToGenerateSecondRound;\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateSecondRound, FIRST_EVENT_TIME.plusSeconds(secondsToGenerateFirstRound));\n+      // Wait for Druid process to be available\n+      LOG.info(\"Waiting for Druid process to be available\");\n+      waitForReadyRunnable.run();\n+      LOG.info(\"Druid process is now available\");\n+      // Start generating remainding data (after restarting)\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateRemaining, FIRST_EVENT_TIME.plusSeconds(secondsToGenerateFirstRound + secondsToGenerateSecondRound));\n+      // Verify supervisor is healthy\n+      ITRetryUtil.retryUntil(\n+          () -> SupervisorStateManager.BasicState.RUNNING.equals(indexer.getSupervisorStatus(supervisorId)),\n+          true,\n+          10000,\n+          30,\n+          \"Waiting for supervisor to be healthy\"\n+      );\n+      // Verify that supervisor ingested all data\n+      verifyIngestedData(supervisorId);\n+    }\n+  }\n+\n+  private void testIndexWithKinesisReshardHelper(int newShardCount) throws Exception\n+  {\n+    try (\n+        final Closeable ignored1 = unloader(fullDatasourceName)\n+    ) {\n+      final String taskSpec = kinesisIngestionPropsTransform.apply(getResourceAsString(INDEXER_FILE_INPUT_FORMAT));\n+      LOG.info(\"supervisorSpec: [%s]\\n\", taskSpec);\n+      // Start supervisor\n+      supervisorId = indexer.submitSupervisor(taskSpec);\n+      LOG.info(\"Submitted supervisor\");\n+      // Start generating one third of the data (before resharding)\n+      int secondsToGenerateFirstRound = TOTAL_NUMBER_OF_SECOND / 3;\n+      secondsToGenerateRemaining = secondsToGenerateRemaining - secondsToGenerateFirstRound;\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateFirstRound, FIRST_EVENT_TIME);\n+      // Reshard the supervisor by split from KINESIS_SHARD_COUNT to newShardCount\n+      kinesisAdminClient.updateShardCount(streamName, newShardCount);\n+      // Start generating one third of the data (while resharding)\n+      int secondsToGenerateSecondRound = TOTAL_NUMBER_OF_SECOND / 3;\n+      secondsToGenerateRemaining = secondsToGenerateRemaining - secondsToGenerateSecondRound;\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateSecondRound, FIRST_EVENT_TIME.plusSeconds(secondsToGenerateFirstRound));\n+      // Wait for kinesis stream to finish resharding\n+      ITRetryUtil.retryUntil(\n+          () -> kinesisAdminClient.isStreamActive(streamName),\n+          true,\n+          10000,\n+          30,\n+          \"Waiting for Kinesis stream to finish resharding\"\n+      );\n+      // Start generating remainding data (after resharding)\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateRemaining, FIRST_EVENT_TIME.plusSeconds(secondsToGenerateFirstRound + secondsToGenerateSecondRound));\n+      // Verify supervisor is healthy after suspension", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMzODk3NQ=="}, "originalCommit": {"oid": "d7637d53ff7fdee5ff28b15c49178b176bbf3a39"}, "originalPosition": 395}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4ODk1MjU4OnYy", "diffSide": "RIGHT", "path": "integration-tests/src/test/java/org/apache/druid/tests/indexer/ITKinesisIndexingServiceTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwMzo0MzoyNFrOF-vypw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMDo1MToxMlrOF_XrRA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMzOTA0Nw==", "bodyText": "kafka -> kinesis", "url": "https://github.com/apache/druid/pull/9576#discussion_r401339047", "createdAt": "2020-04-01T03:43:24Z", "author": {"login": "jon-wei"}, "path": "integration-tests/src/test/java/org/apache/druid/tests/indexer/ITKinesisIndexingServiceTest.java", "diffHunk": "@@ -0,0 +1,443 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.tests.indexer;\n+\n+import com.google.common.collect.ImmutableMap;\n+import com.google.inject.Inject;\n+import org.apache.druid.indexing.overlord.supervisor.SupervisorStateManager;\n+import org.apache.druid.java.util.common.DateTimes;\n+import org.apache.druid.java.util.common.StringUtils;\n+import org.apache.druid.java.util.common.logger.Logger;\n+import org.apache.druid.testing.guice.DruidTestModuleFactory;\n+import org.apache.druid.testing.utils.DruidClusterAdminClient;\n+import org.apache.druid.testing.utils.ITRetryUtil;\n+import org.apache.druid.testing.utils.KinesisAdminClient;\n+import org.apache.druid.testing.utils.KinesisEventWriter;\n+import org.apache.druid.testing.utils.WikipediaStreamEventStreamGenerator;\n+import org.apache.druid.tests.TestNGGroup;\n+import org.joda.time.DateTime;\n+import org.joda.time.format.DateTimeFormat;\n+import org.joda.time.format.DateTimeFormatter;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.AfterMethod;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.BeforeMethod;\n+import org.testng.annotations.Guice;\n+import org.testng.annotations.Test;\n+\n+import java.io.Closeable;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.function.Function;\n+\n+@Test(groups = TestNGGroup.KINESIS_INDEX)\n+@Guice(moduleFactory = DruidTestModuleFactory.class)\n+public class ITKinesisIndexingServiceTest extends AbstractITBatchIndexTest\n+{\n+  private static final Logger LOG = new Logger(AbstractKafkaIndexerTest.class);\n+  private static final int KINESIS_SHARD_COUNT = 2;\n+  private static final String STREAM_EXPIRE_TAG = \"druid-ci-expire-after\";\n+  private static final long WAIT_TIME_MILLIS = 3 * 60 * 1000L;\n+  private static final DateTime FIRST_EVENT_TIME = DateTimes.of(1994, 4, 29, 1, 0);\n+  private static final String INDEXER_FILE_LEGACY_PARSER = \"/indexer/stream_supervisor_spec_legacy_parser.json\";\n+  private static final String INDEXER_FILE_INPUT_FORMAT = \"/indexer/stream_supervisor_spec_input_format.json\";\n+  private static final String QUERIES_FILE = \"/indexer/stream_index_queries.json\";\n+  // format for the querying interval\n+  private static final DateTimeFormatter INTERVAL_FMT = DateTimeFormat.forPattern(\"yyyy-MM-dd'T'HH:mm:'00Z'\");\n+  // format for the expected timestamp in a query response\n+  private static final DateTimeFormatter TIMESTAMP_FMT = DateTimeFormat.forPattern(\"yyyy-MM-dd'T'HH:mm:ss'.000Z'\");\n+  private static final int EVENTS_PER_SECOND = 6;\n+  private static final long CYCLE_PADDING_MS = 100;\n+  private static final int TOTAL_NUMBER_OF_SECOND = 10;\n+\n+  @Inject\n+  private DruidClusterAdminClient druidClusterAdminClient;\n+\n+  private String streamName;\n+  private String fullDatasourceName;\n+  private KinesisAdminClient kinesisAdminClient;\n+  private KinesisEventWriter kinesisEventWriter;\n+  private WikipediaStreamEventStreamGenerator wikipediaStreamEventGenerator;\n+  private Function<String, String> kinesisIngestionPropsTransform;\n+  private Function<String, String> kinesisQueryPropsTransform;\n+  private String supervisorId;\n+  private int secondsToGenerateRemaining;\n+\n+  @BeforeClass\n+  public void beforeClass() throws Exception\n+  {\n+    kinesisAdminClient = new KinesisAdminClient(config.getStreamEndpoint());\n+    kinesisEventWriter = new KinesisEventWriter(config.getStreamEndpoint(), false);\n+    wikipediaStreamEventGenerator = new WikipediaStreamEventStreamGenerator(EVENTS_PER_SECOND, CYCLE_PADDING_MS);\n+  }\n+\n+  @AfterClass\n+  public void tearDown()\n+  {\n+    wikipediaStreamEventGenerator.shutdown();\n+    kinesisEventWriter.shutdown();\n+  }\n+\n+  @BeforeMethod\n+  public void before()\n+  {\n+    streamName = \"kinesis_index_test_\" + UUID.randomUUID();\n+    String datasource = \"kinesis_indexing_service_test_\" + UUID.randomUUID();\n+    Map<String, String> tags = ImmutableMap.of(STREAM_EXPIRE_TAG, Long.toString(DateTimes.nowUtc().plusMinutes(30).getMillis()));\n+    kinesisAdminClient.createStream(streamName, KINESIS_SHARD_COUNT, tags);\n+    ITRetryUtil.retryUntil(\n+        () -> kinesisAdminClient.isStreamActive(streamName),\n+        true,\n+        10000,\n+        30,\n+        \"Wait for stream active\"\n+    );\n+    secondsToGenerateRemaining = TOTAL_NUMBER_OF_SECOND;\n+    fullDatasourceName = datasource + config.getExtraDatasourceNameSuffix();\n+    kinesisIngestionPropsTransform = spec -> {\n+      try {\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%DATASOURCE%%\",\n+            fullDatasourceName\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%STREAM_TYPE%%\",\n+            \"kinesis\"\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TOPIC_KEY%%\",\n+            \"stream\"\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TOPIC_VALUE%%\",\n+            streamName\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%USE_EARLIEST_KEY%%\",\n+            \"useEarliestSequenceNumber\"\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%STREAM_PROPERTIES_KEY%%\",\n+            \"endpoint\"\n+        );\n+        return StringUtils.replace(\n+            spec,\n+            \"%%STREAM_PROPERTIES_VALUE%%\",\n+            jsonMapper.writeValueAsString(config.getStreamEndpoint())\n+        );\n+      }\n+      catch (Exception e) {\n+        throw new RuntimeException(e);\n+      }\n+    };\n+    kinesisQueryPropsTransform = spec -> {\n+      try {\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%DATASOURCE%%\",\n+            fullDatasourceName\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMEBOUNDARY_RESPONSE_TIMESTAMP%%\",\n+            TIMESTAMP_FMT.print(FIRST_EVENT_TIME)\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMEBOUNDARY_RESPONSE_MAXTIME%%\",\n+            TIMESTAMP_FMT.print(FIRST_EVENT_TIME.plusSeconds(TOTAL_NUMBER_OF_SECOND - 1))\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMEBOUNDARY_RESPONSE_MINTIME%%\",\n+            TIMESTAMP_FMT.print(FIRST_EVENT_TIME)\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_QUERY_START%%\",\n+            INTERVAL_FMT.print(FIRST_EVENT_TIME)\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_QUERY_END%%\",\n+            INTERVAL_FMT.print(FIRST_EVENT_TIME.plusSeconds(TOTAL_NUMBER_OF_SECOND - 1).plusMinutes(2))\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_RESPONSE_TIMESTAMP%%\",\n+            TIMESTAMP_FMT.print(FIRST_EVENT_TIME)\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_ADDED%%\",\n+            Long.toString(getSumOfEventSequence(EVENTS_PER_SECOND) * TOTAL_NUMBER_OF_SECOND)\n+        );\n+        return StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_NUMEVENTS%%\",\n+            Integer.toString(EVENTS_PER_SECOND * TOTAL_NUMBER_OF_SECOND)\n+        );\n+      }\n+      catch (Exception e) {\n+        throw new RuntimeException(e);\n+      }\n+    };\n+  }\n+\n+  @AfterMethod\n+  public void teardown()\n+  {\n+    try {\n+      kinesisEventWriter.flush();\n+      indexer.shutdownSupervisor(supervisorId);\n+      unloader(fullDatasourceName);\n+      kinesisAdminClient.deleteStream(streamName);\n+    }\n+    catch (Exception e) {\n+      // Best effort cleanup\n+    }\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithLegacyParserStableState() throws Exception\n+  {\n+    try (\n+        final Closeable ignored1 = unloader(fullDatasourceName)\n+    ) {\n+      final String taskSpec = kinesisIngestionPropsTransform.apply(getResourceAsString(INDEXER_FILE_LEGACY_PARSER));\n+      LOG.info(\"supervisorSpec: [%s]\\n\", taskSpec);\n+      // Start supervisor\n+      supervisorId = indexer.submitSupervisor(taskSpec);\n+      LOG.info(\"Submitted supervisor\");\n+      // Start Kinesis data generator\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, TOTAL_NUMBER_OF_SECOND, FIRST_EVENT_TIME);\n+      verifyIngestedData(supervisorId);\n+    }\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithInputFormatStableState() throws Exception\n+  {\n+    try (\n+        final Closeable ignored1 = unloader(fullDatasourceName)\n+    ) {\n+      final String taskSpec = kinesisIngestionPropsTransform.apply(getResourceAsString(INDEXER_FILE_INPUT_FORMAT));\n+      LOG.info(\"supervisorSpec: [%s]\\n\", taskSpec);\n+      // Start supervisor\n+      supervisorId = indexer.submitSupervisor(taskSpec);\n+      LOG.info(\"Submitted supervisor\");\n+      // Start Kinesis data generator\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, TOTAL_NUMBER_OF_SECOND, FIRST_EVENT_TIME);\n+      verifyIngestedData(supervisorId);\n+    }\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithLosingCoordinator() throws Exception\n+  {\n+    testIndexWithLosingNodeHelper(() -> druidClusterAdminClient.restartCoordinatorContainer(), () -> druidClusterAdminClient.waitUntilCoordinatorReady());\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithLosingOverlord() throws Exception\n+  {\n+    testIndexWithLosingNodeHelper(() -> druidClusterAdminClient.restartIndexerContainer(), () -> druidClusterAdminClient.waitUntilIndexerReady());\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithLosingHistorical() throws Exception\n+  {\n+    testIndexWithLosingNodeHelper(() -> druidClusterAdminClient.restartHistoricalContainer(), () -> druidClusterAdminClient.waitUntilHistoricalReady());\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithStartStopSupervisor() throws Exception\n+  {\n+    try (\n+        final Closeable ignored1 = unloader(fullDatasourceName)\n+    ) {\n+      final String taskSpec = kinesisIngestionPropsTransform.apply(getResourceAsString(INDEXER_FILE_INPUT_FORMAT));\n+      LOG.info(\"supervisorSpec: [%s]\\n\", taskSpec);\n+      // Start supervisor\n+      supervisorId = indexer.submitSupervisor(taskSpec);\n+      LOG.info(\"Submitted supervisor\");\n+      // Start generating half of the data\n+      int secondsToGenerateFirstRound = TOTAL_NUMBER_OF_SECOND / 2;\n+      secondsToGenerateRemaining = secondsToGenerateRemaining - secondsToGenerateFirstRound;\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateFirstRound, FIRST_EVENT_TIME);\n+      // Suspend the supervisor\n+      indexer.suspendSupervisor(supervisorId);\n+      // Start generating remainning half of the data\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateRemaining, FIRST_EVENT_TIME.plusSeconds(secondsToGenerateFirstRound));\n+      // Resume the supervisor\n+      indexer.resumeSupervisor(supervisorId);\n+      // Verify supervisor is healthy after suspension\n+      ITRetryUtil.retryUntil(\n+          () -> SupervisorStateManager.BasicState.RUNNING.equals(indexer.getSupervisorStatus(supervisorId)),\n+          true,\n+          10000,\n+          30,\n+          \"Waiting for supervisor to be healthy\"\n+      );\n+      // Verify that supervisor can catch up with the stream\n+      verifyIngestedData(supervisorId);\n+    }\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithKinesisReshardSplit() throws Exception\n+  {\n+    // Reshard the supervisor by split from KINESIS_SHARD_COUNT to KINESIS_SHARD_COUNT * 2\n+    testIndexWithKinesisReshardHelper(KINESIS_SHARD_COUNT * 2);\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithKinesisReshardMerge() throws Exception\n+  {\n+    // Reshard the supervisor by split from KINESIS_SHARD_COUNT to KINESIS_SHARD_COUNT / 2\n+    testIndexWithKinesisReshardHelper(KINESIS_SHARD_COUNT / 2);\n+  }\n+\n+  private void testIndexWithLosingNodeHelper(Runnable restartRunnable, Runnable waitForReadyRunnable) throws Exception\n+  {\n+    try (\n+        final Closeable ignored1 = unloader(fullDatasourceName)\n+    ) {\n+      final String taskSpec = kinesisIngestionPropsTransform.apply(getResourceAsString(INDEXER_FILE_INPUT_FORMAT));\n+      LOG.info(\"supervisorSpec: [%s]\\n\", taskSpec);\n+      // Start supervisor\n+      supervisorId = indexer.submitSupervisor(taskSpec);\n+      LOG.info(\"Submitted supervisor\");\n+      // Start generating one third of the data (before restarting)\n+      int secondsToGenerateFirstRound = TOTAL_NUMBER_OF_SECOND / 3;\n+      secondsToGenerateRemaining = secondsToGenerateRemaining - secondsToGenerateFirstRound;\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateFirstRound, FIRST_EVENT_TIME);\n+      // Restart Druid process\n+      LOG.info(\"Restarting Druid process\");\n+      restartRunnable.run();\n+      LOG.info(\"Restarted Druid process\");\n+      // Start generating one third of the data (while restarting)\n+      int secondsToGenerateSecondRound = TOTAL_NUMBER_OF_SECOND / 3;\n+      secondsToGenerateRemaining = secondsToGenerateRemaining - secondsToGenerateSecondRound;\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateSecondRound, FIRST_EVENT_TIME.plusSeconds(secondsToGenerateFirstRound));\n+      // Wait for Druid process to be available\n+      LOG.info(\"Waiting for Druid process to be available\");\n+      waitForReadyRunnable.run();\n+      LOG.info(\"Druid process is now available\");\n+      // Start generating remainding data (after restarting)\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateRemaining, FIRST_EVENT_TIME.plusSeconds(secondsToGenerateFirstRound + secondsToGenerateSecondRound));\n+      // Verify supervisor is healthy\n+      ITRetryUtil.retryUntil(\n+          () -> SupervisorStateManager.BasicState.RUNNING.equals(indexer.getSupervisorStatus(supervisorId)),\n+          true,\n+          10000,\n+          30,\n+          \"Waiting for supervisor to be healthy\"\n+      );\n+      // Verify that supervisor ingested all data\n+      verifyIngestedData(supervisorId);\n+    }\n+  }\n+\n+  private void testIndexWithKinesisReshardHelper(int newShardCount) throws Exception\n+  {\n+    try (\n+        final Closeable ignored1 = unloader(fullDatasourceName)\n+    ) {\n+      final String taskSpec = kinesisIngestionPropsTransform.apply(getResourceAsString(INDEXER_FILE_INPUT_FORMAT));\n+      LOG.info(\"supervisorSpec: [%s]\\n\", taskSpec);\n+      // Start supervisor\n+      supervisorId = indexer.submitSupervisor(taskSpec);\n+      LOG.info(\"Submitted supervisor\");\n+      // Start generating one third of the data (before resharding)\n+      int secondsToGenerateFirstRound = TOTAL_NUMBER_OF_SECOND / 3;\n+      secondsToGenerateRemaining = secondsToGenerateRemaining - secondsToGenerateFirstRound;\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateFirstRound, FIRST_EVENT_TIME);\n+      // Reshard the supervisor by split from KINESIS_SHARD_COUNT to newShardCount\n+      kinesisAdminClient.updateShardCount(streamName, newShardCount);\n+      // Start generating one third of the data (while resharding)\n+      int secondsToGenerateSecondRound = TOTAL_NUMBER_OF_SECOND / 3;\n+      secondsToGenerateRemaining = secondsToGenerateRemaining - secondsToGenerateSecondRound;\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateSecondRound, FIRST_EVENT_TIME.plusSeconds(secondsToGenerateFirstRound));\n+      // Wait for kinesis stream to finish resharding\n+      ITRetryUtil.retryUntil(\n+          () -> kinesisAdminClient.isStreamActive(streamName),\n+          true,\n+          10000,\n+          30,\n+          \"Waiting for Kinesis stream to finish resharding\"\n+      );\n+      // Start generating remainding data (after resharding)\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateRemaining, FIRST_EVENT_TIME.plusSeconds(secondsToGenerateFirstRound + secondsToGenerateSecondRound));\n+      // Verify supervisor is healthy after suspension\n+      ITRetryUtil.retryUntil(\n+          () -> SupervisorStateManager.BasicState.RUNNING.equals(indexer.getSupervisorStatus(supervisorId)),\n+          true,\n+          10000,\n+          30,\n+          \"Waiting for supervisor to be healthy\"\n+      );\n+      // Verify that supervisor can catch up with the stream\n+      verifyIngestedData(supervisorId);\n+    }\n+  }\n+\n+  private void verifyIngestedData(String supervisorId) throws Exception\n+  {\n+    // Wait for supervisor to consume events\n+    LOG.info(\"Waiting for [%s] millis for Kafka indexing tasks to consume events\", WAIT_TIME_MILLIS);\n+    Thread.sleep(WAIT_TIME_MILLIS);\n+    // Query data\n+    final String querySpec = kinesisQueryPropsTransform.apply(getResourceAsString(QUERIES_FILE));\n+    // this query will probably be answered from the indexing tasks but possibly from 2 historical segments / 2 indexing\n+    this.queryHelper.testQueriesFromString(querySpec, 2);\n+    LOG.info(\"Shutting down supervisor\");\n+    indexer.shutdownSupervisor(supervisorId);\n+    // wait for all kafka indexing tasks to finish", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d7637d53ff7fdee5ff28b15c49178b176bbf3a39"}, "originalPosition": 419}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTk5MjUxNg==", "bodyText": "Done", "url": "https://github.com/apache/druid/pull/9576#discussion_r401992516", "createdAt": "2020-04-02T00:51:12Z", "author": {"login": "maytasm"}, "path": "integration-tests/src/test/java/org/apache/druid/tests/indexer/ITKinesisIndexingServiceTest.java", "diffHunk": "@@ -0,0 +1,443 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.tests.indexer;\n+\n+import com.google.common.collect.ImmutableMap;\n+import com.google.inject.Inject;\n+import org.apache.druid.indexing.overlord.supervisor.SupervisorStateManager;\n+import org.apache.druid.java.util.common.DateTimes;\n+import org.apache.druid.java.util.common.StringUtils;\n+import org.apache.druid.java.util.common.logger.Logger;\n+import org.apache.druid.testing.guice.DruidTestModuleFactory;\n+import org.apache.druid.testing.utils.DruidClusterAdminClient;\n+import org.apache.druid.testing.utils.ITRetryUtil;\n+import org.apache.druid.testing.utils.KinesisAdminClient;\n+import org.apache.druid.testing.utils.KinesisEventWriter;\n+import org.apache.druid.testing.utils.WikipediaStreamEventStreamGenerator;\n+import org.apache.druid.tests.TestNGGroup;\n+import org.joda.time.DateTime;\n+import org.joda.time.format.DateTimeFormat;\n+import org.joda.time.format.DateTimeFormatter;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.AfterMethod;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.BeforeMethod;\n+import org.testng.annotations.Guice;\n+import org.testng.annotations.Test;\n+\n+import java.io.Closeable;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.function.Function;\n+\n+@Test(groups = TestNGGroup.KINESIS_INDEX)\n+@Guice(moduleFactory = DruidTestModuleFactory.class)\n+public class ITKinesisIndexingServiceTest extends AbstractITBatchIndexTest\n+{\n+  private static final Logger LOG = new Logger(AbstractKafkaIndexerTest.class);\n+  private static final int KINESIS_SHARD_COUNT = 2;\n+  private static final String STREAM_EXPIRE_TAG = \"druid-ci-expire-after\";\n+  private static final long WAIT_TIME_MILLIS = 3 * 60 * 1000L;\n+  private static final DateTime FIRST_EVENT_TIME = DateTimes.of(1994, 4, 29, 1, 0);\n+  private static final String INDEXER_FILE_LEGACY_PARSER = \"/indexer/stream_supervisor_spec_legacy_parser.json\";\n+  private static final String INDEXER_FILE_INPUT_FORMAT = \"/indexer/stream_supervisor_spec_input_format.json\";\n+  private static final String QUERIES_FILE = \"/indexer/stream_index_queries.json\";\n+  // format for the querying interval\n+  private static final DateTimeFormatter INTERVAL_FMT = DateTimeFormat.forPattern(\"yyyy-MM-dd'T'HH:mm:'00Z'\");\n+  // format for the expected timestamp in a query response\n+  private static final DateTimeFormatter TIMESTAMP_FMT = DateTimeFormat.forPattern(\"yyyy-MM-dd'T'HH:mm:ss'.000Z'\");\n+  private static final int EVENTS_PER_SECOND = 6;\n+  private static final long CYCLE_PADDING_MS = 100;\n+  private static final int TOTAL_NUMBER_OF_SECOND = 10;\n+\n+  @Inject\n+  private DruidClusterAdminClient druidClusterAdminClient;\n+\n+  private String streamName;\n+  private String fullDatasourceName;\n+  private KinesisAdminClient kinesisAdminClient;\n+  private KinesisEventWriter kinesisEventWriter;\n+  private WikipediaStreamEventStreamGenerator wikipediaStreamEventGenerator;\n+  private Function<String, String> kinesisIngestionPropsTransform;\n+  private Function<String, String> kinesisQueryPropsTransform;\n+  private String supervisorId;\n+  private int secondsToGenerateRemaining;\n+\n+  @BeforeClass\n+  public void beforeClass() throws Exception\n+  {\n+    kinesisAdminClient = new KinesisAdminClient(config.getStreamEndpoint());\n+    kinesisEventWriter = new KinesisEventWriter(config.getStreamEndpoint(), false);\n+    wikipediaStreamEventGenerator = new WikipediaStreamEventStreamGenerator(EVENTS_PER_SECOND, CYCLE_PADDING_MS);\n+  }\n+\n+  @AfterClass\n+  public void tearDown()\n+  {\n+    wikipediaStreamEventGenerator.shutdown();\n+    kinesisEventWriter.shutdown();\n+  }\n+\n+  @BeforeMethod\n+  public void before()\n+  {\n+    streamName = \"kinesis_index_test_\" + UUID.randomUUID();\n+    String datasource = \"kinesis_indexing_service_test_\" + UUID.randomUUID();\n+    Map<String, String> tags = ImmutableMap.of(STREAM_EXPIRE_TAG, Long.toString(DateTimes.nowUtc().plusMinutes(30).getMillis()));\n+    kinesisAdminClient.createStream(streamName, KINESIS_SHARD_COUNT, tags);\n+    ITRetryUtil.retryUntil(\n+        () -> kinesisAdminClient.isStreamActive(streamName),\n+        true,\n+        10000,\n+        30,\n+        \"Wait for stream active\"\n+    );\n+    secondsToGenerateRemaining = TOTAL_NUMBER_OF_SECOND;\n+    fullDatasourceName = datasource + config.getExtraDatasourceNameSuffix();\n+    kinesisIngestionPropsTransform = spec -> {\n+      try {\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%DATASOURCE%%\",\n+            fullDatasourceName\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%STREAM_TYPE%%\",\n+            \"kinesis\"\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TOPIC_KEY%%\",\n+            \"stream\"\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TOPIC_VALUE%%\",\n+            streamName\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%USE_EARLIEST_KEY%%\",\n+            \"useEarliestSequenceNumber\"\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%STREAM_PROPERTIES_KEY%%\",\n+            \"endpoint\"\n+        );\n+        return StringUtils.replace(\n+            spec,\n+            \"%%STREAM_PROPERTIES_VALUE%%\",\n+            jsonMapper.writeValueAsString(config.getStreamEndpoint())\n+        );\n+      }\n+      catch (Exception e) {\n+        throw new RuntimeException(e);\n+      }\n+    };\n+    kinesisQueryPropsTransform = spec -> {\n+      try {\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%DATASOURCE%%\",\n+            fullDatasourceName\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMEBOUNDARY_RESPONSE_TIMESTAMP%%\",\n+            TIMESTAMP_FMT.print(FIRST_EVENT_TIME)\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMEBOUNDARY_RESPONSE_MAXTIME%%\",\n+            TIMESTAMP_FMT.print(FIRST_EVENT_TIME.plusSeconds(TOTAL_NUMBER_OF_SECOND - 1))\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMEBOUNDARY_RESPONSE_MINTIME%%\",\n+            TIMESTAMP_FMT.print(FIRST_EVENT_TIME)\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_QUERY_START%%\",\n+            INTERVAL_FMT.print(FIRST_EVENT_TIME)\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_QUERY_END%%\",\n+            INTERVAL_FMT.print(FIRST_EVENT_TIME.plusSeconds(TOTAL_NUMBER_OF_SECOND - 1).plusMinutes(2))\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_RESPONSE_TIMESTAMP%%\",\n+            TIMESTAMP_FMT.print(FIRST_EVENT_TIME)\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_ADDED%%\",\n+            Long.toString(getSumOfEventSequence(EVENTS_PER_SECOND) * TOTAL_NUMBER_OF_SECOND)\n+        );\n+        return StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_NUMEVENTS%%\",\n+            Integer.toString(EVENTS_PER_SECOND * TOTAL_NUMBER_OF_SECOND)\n+        );\n+      }\n+      catch (Exception e) {\n+        throw new RuntimeException(e);\n+      }\n+    };\n+  }\n+\n+  @AfterMethod\n+  public void teardown()\n+  {\n+    try {\n+      kinesisEventWriter.flush();\n+      indexer.shutdownSupervisor(supervisorId);\n+      unloader(fullDatasourceName);\n+      kinesisAdminClient.deleteStream(streamName);\n+    }\n+    catch (Exception e) {\n+      // Best effort cleanup\n+    }\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithLegacyParserStableState() throws Exception\n+  {\n+    try (\n+        final Closeable ignored1 = unloader(fullDatasourceName)\n+    ) {\n+      final String taskSpec = kinesisIngestionPropsTransform.apply(getResourceAsString(INDEXER_FILE_LEGACY_PARSER));\n+      LOG.info(\"supervisorSpec: [%s]\\n\", taskSpec);\n+      // Start supervisor\n+      supervisorId = indexer.submitSupervisor(taskSpec);\n+      LOG.info(\"Submitted supervisor\");\n+      // Start Kinesis data generator\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, TOTAL_NUMBER_OF_SECOND, FIRST_EVENT_TIME);\n+      verifyIngestedData(supervisorId);\n+    }\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithInputFormatStableState() throws Exception\n+  {\n+    try (\n+        final Closeable ignored1 = unloader(fullDatasourceName)\n+    ) {\n+      final String taskSpec = kinesisIngestionPropsTransform.apply(getResourceAsString(INDEXER_FILE_INPUT_FORMAT));\n+      LOG.info(\"supervisorSpec: [%s]\\n\", taskSpec);\n+      // Start supervisor\n+      supervisorId = indexer.submitSupervisor(taskSpec);\n+      LOG.info(\"Submitted supervisor\");\n+      // Start Kinesis data generator\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, TOTAL_NUMBER_OF_SECOND, FIRST_EVENT_TIME);\n+      verifyIngestedData(supervisorId);\n+    }\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithLosingCoordinator() throws Exception\n+  {\n+    testIndexWithLosingNodeHelper(() -> druidClusterAdminClient.restartCoordinatorContainer(), () -> druidClusterAdminClient.waitUntilCoordinatorReady());\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithLosingOverlord() throws Exception\n+  {\n+    testIndexWithLosingNodeHelper(() -> druidClusterAdminClient.restartIndexerContainer(), () -> druidClusterAdminClient.waitUntilIndexerReady());\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithLosingHistorical() throws Exception\n+  {\n+    testIndexWithLosingNodeHelper(() -> druidClusterAdminClient.restartHistoricalContainer(), () -> druidClusterAdminClient.waitUntilHistoricalReady());\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithStartStopSupervisor() throws Exception\n+  {\n+    try (\n+        final Closeable ignored1 = unloader(fullDatasourceName)\n+    ) {\n+      final String taskSpec = kinesisIngestionPropsTransform.apply(getResourceAsString(INDEXER_FILE_INPUT_FORMAT));\n+      LOG.info(\"supervisorSpec: [%s]\\n\", taskSpec);\n+      // Start supervisor\n+      supervisorId = indexer.submitSupervisor(taskSpec);\n+      LOG.info(\"Submitted supervisor\");\n+      // Start generating half of the data\n+      int secondsToGenerateFirstRound = TOTAL_NUMBER_OF_SECOND / 2;\n+      secondsToGenerateRemaining = secondsToGenerateRemaining - secondsToGenerateFirstRound;\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateFirstRound, FIRST_EVENT_TIME);\n+      // Suspend the supervisor\n+      indexer.suspendSupervisor(supervisorId);\n+      // Start generating remainning half of the data\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateRemaining, FIRST_EVENT_TIME.plusSeconds(secondsToGenerateFirstRound));\n+      // Resume the supervisor\n+      indexer.resumeSupervisor(supervisorId);\n+      // Verify supervisor is healthy after suspension\n+      ITRetryUtil.retryUntil(\n+          () -> SupervisorStateManager.BasicState.RUNNING.equals(indexer.getSupervisorStatus(supervisorId)),\n+          true,\n+          10000,\n+          30,\n+          \"Waiting for supervisor to be healthy\"\n+      );\n+      // Verify that supervisor can catch up with the stream\n+      verifyIngestedData(supervisorId);\n+    }\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithKinesisReshardSplit() throws Exception\n+  {\n+    // Reshard the supervisor by split from KINESIS_SHARD_COUNT to KINESIS_SHARD_COUNT * 2\n+    testIndexWithKinesisReshardHelper(KINESIS_SHARD_COUNT * 2);\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithKinesisReshardMerge() throws Exception\n+  {\n+    // Reshard the supervisor by split from KINESIS_SHARD_COUNT to KINESIS_SHARD_COUNT / 2\n+    testIndexWithKinesisReshardHelper(KINESIS_SHARD_COUNT / 2);\n+  }\n+\n+  private void testIndexWithLosingNodeHelper(Runnable restartRunnable, Runnable waitForReadyRunnable) throws Exception\n+  {\n+    try (\n+        final Closeable ignored1 = unloader(fullDatasourceName)\n+    ) {\n+      final String taskSpec = kinesisIngestionPropsTransform.apply(getResourceAsString(INDEXER_FILE_INPUT_FORMAT));\n+      LOG.info(\"supervisorSpec: [%s]\\n\", taskSpec);\n+      // Start supervisor\n+      supervisorId = indexer.submitSupervisor(taskSpec);\n+      LOG.info(\"Submitted supervisor\");\n+      // Start generating one third of the data (before restarting)\n+      int secondsToGenerateFirstRound = TOTAL_NUMBER_OF_SECOND / 3;\n+      secondsToGenerateRemaining = secondsToGenerateRemaining - secondsToGenerateFirstRound;\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateFirstRound, FIRST_EVENT_TIME);\n+      // Restart Druid process\n+      LOG.info(\"Restarting Druid process\");\n+      restartRunnable.run();\n+      LOG.info(\"Restarted Druid process\");\n+      // Start generating one third of the data (while restarting)\n+      int secondsToGenerateSecondRound = TOTAL_NUMBER_OF_SECOND / 3;\n+      secondsToGenerateRemaining = secondsToGenerateRemaining - secondsToGenerateSecondRound;\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateSecondRound, FIRST_EVENT_TIME.plusSeconds(secondsToGenerateFirstRound));\n+      // Wait for Druid process to be available\n+      LOG.info(\"Waiting for Druid process to be available\");\n+      waitForReadyRunnable.run();\n+      LOG.info(\"Druid process is now available\");\n+      // Start generating remainding data (after restarting)\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateRemaining, FIRST_EVENT_TIME.plusSeconds(secondsToGenerateFirstRound + secondsToGenerateSecondRound));\n+      // Verify supervisor is healthy\n+      ITRetryUtil.retryUntil(\n+          () -> SupervisorStateManager.BasicState.RUNNING.equals(indexer.getSupervisorStatus(supervisorId)),\n+          true,\n+          10000,\n+          30,\n+          \"Waiting for supervisor to be healthy\"\n+      );\n+      // Verify that supervisor ingested all data\n+      verifyIngestedData(supervisorId);\n+    }\n+  }\n+\n+  private void testIndexWithKinesisReshardHelper(int newShardCount) throws Exception\n+  {\n+    try (\n+        final Closeable ignored1 = unloader(fullDatasourceName)\n+    ) {\n+      final String taskSpec = kinesisIngestionPropsTransform.apply(getResourceAsString(INDEXER_FILE_INPUT_FORMAT));\n+      LOG.info(\"supervisorSpec: [%s]\\n\", taskSpec);\n+      // Start supervisor\n+      supervisorId = indexer.submitSupervisor(taskSpec);\n+      LOG.info(\"Submitted supervisor\");\n+      // Start generating one third of the data (before resharding)\n+      int secondsToGenerateFirstRound = TOTAL_NUMBER_OF_SECOND / 3;\n+      secondsToGenerateRemaining = secondsToGenerateRemaining - secondsToGenerateFirstRound;\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateFirstRound, FIRST_EVENT_TIME);\n+      // Reshard the supervisor by split from KINESIS_SHARD_COUNT to newShardCount\n+      kinesisAdminClient.updateShardCount(streamName, newShardCount);\n+      // Start generating one third of the data (while resharding)\n+      int secondsToGenerateSecondRound = TOTAL_NUMBER_OF_SECOND / 3;\n+      secondsToGenerateRemaining = secondsToGenerateRemaining - secondsToGenerateSecondRound;\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateSecondRound, FIRST_EVENT_TIME.plusSeconds(secondsToGenerateFirstRound));\n+      // Wait for kinesis stream to finish resharding\n+      ITRetryUtil.retryUntil(\n+          () -> kinesisAdminClient.isStreamActive(streamName),\n+          true,\n+          10000,\n+          30,\n+          \"Waiting for Kinesis stream to finish resharding\"\n+      );\n+      // Start generating remainding data (after resharding)\n+      wikipediaStreamEventGenerator.start(streamName, kinesisEventWriter, secondsToGenerateRemaining, FIRST_EVENT_TIME.plusSeconds(secondsToGenerateFirstRound + secondsToGenerateSecondRound));\n+      // Verify supervisor is healthy after suspension\n+      ITRetryUtil.retryUntil(\n+          () -> SupervisorStateManager.BasicState.RUNNING.equals(indexer.getSupervisorStatus(supervisorId)),\n+          true,\n+          10000,\n+          30,\n+          \"Waiting for supervisor to be healthy\"\n+      );\n+      // Verify that supervisor can catch up with the stream\n+      verifyIngestedData(supervisorId);\n+    }\n+  }\n+\n+  private void verifyIngestedData(String supervisorId) throws Exception\n+  {\n+    // Wait for supervisor to consume events\n+    LOG.info(\"Waiting for [%s] millis for Kafka indexing tasks to consume events\", WAIT_TIME_MILLIS);\n+    Thread.sleep(WAIT_TIME_MILLIS);\n+    // Query data\n+    final String querySpec = kinesisQueryPropsTransform.apply(getResourceAsString(QUERIES_FILE));\n+    // this query will probably be answered from the indexing tasks but possibly from 2 historical segments / 2 indexing\n+    this.queryHelper.testQueriesFromString(querySpec, 2);\n+    LOG.info(\"Shutting down supervisor\");\n+    indexer.shutdownSupervisor(supervisorId);\n+    // wait for all kafka indexing tasks to finish", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMzOTA0Nw=="}, "originalCommit": {"oid": "d7637d53ff7fdee5ff28b15c49178b176bbf3a39"}, "originalPosition": 419}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4ODk1NTAxOnYy", "diffSide": "RIGHT", "path": "integration-tests/src/test/java/org/apache/druid/tests/indexer/ITKinesisIndexingServiceTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwMzo0NDozOVrOF-vz8A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMlQwMDo1MjowNFrOF_XsJw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMzOTM3Ng==", "bodyText": "In the test names, Kinese -> Kinesis here and elsewhere", "url": "https://github.com/apache/druid/pull/9576#discussion_r401339376", "createdAt": "2020-04-01T03:44:39Z", "author": {"login": "jon-wei"}, "path": "integration-tests/src/test/java/org/apache/druid/tests/indexer/ITKinesisIndexingServiceTest.java", "diffHunk": "@@ -0,0 +1,443 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.tests.indexer;\n+\n+import com.google.common.collect.ImmutableMap;\n+import com.google.inject.Inject;\n+import org.apache.druid.indexing.overlord.supervisor.SupervisorStateManager;\n+import org.apache.druid.java.util.common.DateTimes;\n+import org.apache.druid.java.util.common.StringUtils;\n+import org.apache.druid.java.util.common.logger.Logger;\n+import org.apache.druid.testing.guice.DruidTestModuleFactory;\n+import org.apache.druid.testing.utils.DruidClusterAdminClient;\n+import org.apache.druid.testing.utils.ITRetryUtil;\n+import org.apache.druid.testing.utils.KinesisAdminClient;\n+import org.apache.druid.testing.utils.KinesisEventWriter;\n+import org.apache.druid.testing.utils.WikipediaStreamEventStreamGenerator;\n+import org.apache.druid.tests.TestNGGroup;\n+import org.joda.time.DateTime;\n+import org.joda.time.format.DateTimeFormat;\n+import org.joda.time.format.DateTimeFormatter;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.AfterMethod;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.BeforeMethod;\n+import org.testng.annotations.Guice;\n+import org.testng.annotations.Test;\n+\n+import java.io.Closeable;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.function.Function;\n+\n+@Test(groups = TestNGGroup.KINESIS_INDEX)\n+@Guice(moduleFactory = DruidTestModuleFactory.class)\n+public class ITKinesisIndexingServiceTest extends AbstractITBatchIndexTest\n+{\n+  private static final Logger LOG = new Logger(AbstractKafkaIndexerTest.class);\n+  private static final int KINESIS_SHARD_COUNT = 2;\n+  private static final String STREAM_EXPIRE_TAG = \"druid-ci-expire-after\";\n+  private static final long WAIT_TIME_MILLIS = 3 * 60 * 1000L;\n+  private static final DateTime FIRST_EVENT_TIME = DateTimes.of(1994, 4, 29, 1, 0);\n+  private static final String INDEXER_FILE_LEGACY_PARSER = \"/indexer/stream_supervisor_spec_legacy_parser.json\";\n+  private static final String INDEXER_FILE_INPUT_FORMAT = \"/indexer/stream_supervisor_spec_input_format.json\";\n+  private static final String QUERIES_FILE = \"/indexer/stream_index_queries.json\";\n+  // format for the querying interval\n+  private static final DateTimeFormatter INTERVAL_FMT = DateTimeFormat.forPattern(\"yyyy-MM-dd'T'HH:mm:'00Z'\");\n+  // format for the expected timestamp in a query response\n+  private static final DateTimeFormatter TIMESTAMP_FMT = DateTimeFormat.forPattern(\"yyyy-MM-dd'T'HH:mm:ss'.000Z'\");\n+  private static final int EVENTS_PER_SECOND = 6;\n+  private static final long CYCLE_PADDING_MS = 100;\n+  private static final int TOTAL_NUMBER_OF_SECOND = 10;\n+\n+  @Inject\n+  private DruidClusterAdminClient druidClusterAdminClient;\n+\n+  private String streamName;\n+  private String fullDatasourceName;\n+  private KinesisAdminClient kinesisAdminClient;\n+  private KinesisEventWriter kinesisEventWriter;\n+  private WikipediaStreamEventStreamGenerator wikipediaStreamEventGenerator;\n+  private Function<String, String> kinesisIngestionPropsTransform;\n+  private Function<String, String> kinesisQueryPropsTransform;\n+  private String supervisorId;\n+  private int secondsToGenerateRemaining;\n+\n+  @BeforeClass\n+  public void beforeClass() throws Exception\n+  {\n+    kinesisAdminClient = new KinesisAdminClient(config.getStreamEndpoint());\n+    kinesisEventWriter = new KinesisEventWriter(config.getStreamEndpoint(), false);\n+    wikipediaStreamEventGenerator = new WikipediaStreamEventStreamGenerator(EVENTS_PER_SECOND, CYCLE_PADDING_MS);\n+  }\n+\n+  @AfterClass\n+  public void tearDown()\n+  {\n+    wikipediaStreamEventGenerator.shutdown();\n+    kinesisEventWriter.shutdown();\n+  }\n+\n+  @BeforeMethod\n+  public void before()\n+  {\n+    streamName = \"kinesis_index_test_\" + UUID.randomUUID();\n+    String datasource = \"kinesis_indexing_service_test_\" + UUID.randomUUID();\n+    Map<String, String> tags = ImmutableMap.of(STREAM_EXPIRE_TAG, Long.toString(DateTimes.nowUtc().plusMinutes(30).getMillis()));\n+    kinesisAdminClient.createStream(streamName, KINESIS_SHARD_COUNT, tags);\n+    ITRetryUtil.retryUntil(\n+        () -> kinesisAdminClient.isStreamActive(streamName),\n+        true,\n+        10000,\n+        30,\n+        \"Wait for stream active\"\n+    );\n+    secondsToGenerateRemaining = TOTAL_NUMBER_OF_SECOND;\n+    fullDatasourceName = datasource + config.getExtraDatasourceNameSuffix();\n+    kinesisIngestionPropsTransform = spec -> {\n+      try {\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%DATASOURCE%%\",\n+            fullDatasourceName\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%STREAM_TYPE%%\",\n+            \"kinesis\"\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TOPIC_KEY%%\",\n+            \"stream\"\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TOPIC_VALUE%%\",\n+            streamName\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%USE_EARLIEST_KEY%%\",\n+            \"useEarliestSequenceNumber\"\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%STREAM_PROPERTIES_KEY%%\",\n+            \"endpoint\"\n+        );\n+        return StringUtils.replace(\n+            spec,\n+            \"%%STREAM_PROPERTIES_VALUE%%\",\n+            jsonMapper.writeValueAsString(config.getStreamEndpoint())\n+        );\n+      }\n+      catch (Exception e) {\n+        throw new RuntimeException(e);\n+      }\n+    };\n+    kinesisQueryPropsTransform = spec -> {\n+      try {\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%DATASOURCE%%\",\n+            fullDatasourceName\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMEBOUNDARY_RESPONSE_TIMESTAMP%%\",\n+            TIMESTAMP_FMT.print(FIRST_EVENT_TIME)\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMEBOUNDARY_RESPONSE_MAXTIME%%\",\n+            TIMESTAMP_FMT.print(FIRST_EVENT_TIME.plusSeconds(TOTAL_NUMBER_OF_SECOND - 1))\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMEBOUNDARY_RESPONSE_MINTIME%%\",\n+            TIMESTAMP_FMT.print(FIRST_EVENT_TIME)\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_QUERY_START%%\",\n+            INTERVAL_FMT.print(FIRST_EVENT_TIME)\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_QUERY_END%%\",\n+            INTERVAL_FMT.print(FIRST_EVENT_TIME.plusSeconds(TOTAL_NUMBER_OF_SECOND - 1).plusMinutes(2))\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_RESPONSE_TIMESTAMP%%\",\n+            TIMESTAMP_FMT.print(FIRST_EVENT_TIME)\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_ADDED%%\",\n+            Long.toString(getSumOfEventSequence(EVENTS_PER_SECOND) * TOTAL_NUMBER_OF_SECOND)\n+        );\n+        return StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_NUMEVENTS%%\",\n+            Integer.toString(EVENTS_PER_SECOND * TOTAL_NUMBER_OF_SECOND)\n+        );\n+      }\n+      catch (Exception e) {\n+        throw new RuntimeException(e);\n+      }\n+    };\n+  }\n+\n+  @AfterMethod\n+  public void teardown()\n+  {\n+    try {\n+      kinesisEventWriter.flush();\n+      indexer.shutdownSupervisor(supervisorId);\n+      unloader(fullDatasourceName);\n+      kinesisAdminClient.deleteStream(streamName);\n+    }\n+    catch (Exception e) {\n+      // Best effort cleanup\n+    }\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithLegacyParserStableState() throws Exception", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d7637d53ff7fdee5ff28b15c49178b176bbf3a39"}, "originalPosition": 225}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTk5Mjc0Mw==", "bodyText": "Done", "url": "https://github.com/apache/druid/pull/9576#discussion_r401992743", "createdAt": "2020-04-02T00:52:04Z", "author": {"login": "maytasm"}, "path": "integration-tests/src/test/java/org/apache/druid/tests/indexer/ITKinesisIndexingServiceTest.java", "diffHunk": "@@ -0,0 +1,443 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.tests.indexer;\n+\n+import com.google.common.collect.ImmutableMap;\n+import com.google.inject.Inject;\n+import org.apache.druid.indexing.overlord.supervisor.SupervisorStateManager;\n+import org.apache.druid.java.util.common.DateTimes;\n+import org.apache.druid.java.util.common.StringUtils;\n+import org.apache.druid.java.util.common.logger.Logger;\n+import org.apache.druid.testing.guice.DruidTestModuleFactory;\n+import org.apache.druid.testing.utils.DruidClusterAdminClient;\n+import org.apache.druid.testing.utils.ITRetryUtil;\n+import org.apache.druid.testing.utils.KinesisAdminClient;\n+import org.apache.druid.testing.utils.KinesisEventWriter;\n+import org.apache.druid.testing.utils.WikipediaStreamEventStreamGenerator;\n+import org.apache.druid.tests.TestNGGroup;\n+import org.joda.time.DateTime;\n+import org.joda.time.format.DateTimeFormat;\n+import org.joda.time.format.DateTimeFormatter;\n+import org.testng.annotations.AfterClass;\n+import org.testng.annotations.AfterMethod;\n+import org.testng.annotations.BeforeClass;\n+import org.testng.annotations.BeforeMethod;\n+import org.testng.annotations.Guice;\n+import org.testng.annotations.Test;\n+\n+import java.io.Closeable;\n+import java.util.Map;\n+import java.util.UUID;\n+import java.util.function.Function;\n+\n+@Test(groups = TestNGGroup.KINESIS_INDEX)\n+@Guice(moduleFactory = DruidTestModuleFactory.class)\n+public class ITKinesisIndexingServiceTest extends AbstractITBatchIndexTest\n+{\n+  private static final Logger LOG = new Logger(AbstractKafkaIndexerTest.class);\n+  private static final int KINESIS_SHARD_COUNT = 2;\n+  private static final String STREAM_EXPIRE_TAG = \"druid-ci-expire-after\";\n+  private static final long WAIT_TIME_MILLIS = 3 * 60 * 1000L;\n+  private static final DateTime FIRST_EVENT_TIME = DateTimes.of(1994, 4, 29, 1, 0);\n+  private static final String INDEXER_FILE_LEGACY_PARSER = \"/indexer/stream_supervisor_spec_legacy_parser.json\";\n+  private static final String INDEXER_FILE_INPUT_FORMAT = \"/indexer/stream_supervisor_spec_input_format.json\";\n+  private static final String QUERIES_FILE = \"/indexer/stream_index_queries.json\";\n+  // format for the querying interval\n+  private static final DateTimeFormatter INTERVAL_FMT = DateTimeFormat.forPattern(\"yyyy-MM-dd'T'HH:mm:'00Z'\");\n+  // format for the expected timestamp in a query response\n+  private static final DateTimeFormatter TIMESTAMP_FMT = DateTimeFormat.forPattern(\"yyyy-MM-dd'T'HH:mm:ss'.000Z'\");\n+  private static final int EVENTS_PER_SECOND = 6;\n+  private static final long CYCLE_PADDING_MS = 100;\n+  private static final int TOTAL_NUMBER_OF_SECOND = 10;\n+\n+  @Inject\n+  private DruidClusterAdminClient druidClusterAdminClient;\n+\n+  private String streamName;\n+  private String fullDatasourceName;\n+  private KinesisAdminClient kinesisAdminClient;\n+  private KinesisEventWriter kinesisEventWriter;\n+  private WikipediaStreamEventStreamGenerator wikipediaStreamEventGenerator;\n+  private Function<String, String> kinesisIngestionPropsTransform;\n+  private Function<String, String> kinesisQueryPropsTransform;\n+  private String supervisorId;\n+  private int secondsToGenerateRemaining;\n+\n+  @BeforeClass\n+  public void beforeClass() throws Exception\n+  {\n+    kinesisAdminClient = new KinesisAdminClient(config.getStreamEndpoint());\n+    kinesisEventWriter = new KinesisEventWriter(config.getStreamEndpoint(), false);\n+    wikipediaStreamEventGenerator = new WikipediaStreamEventStreamGenerator(EVENTS_PER_SECOND, CYCLE_PADDING_MS);\n+  }\n+\n+  @AfterClass\n+  public void tearDown()\n+  {\n+    wikipediaStreamEventGenerator.shutdown();\n+    kinesisEventWriter.shutdown();\n+  }\n+\n+  @BeforeMethod\n+  public void before()\n+  {\n+    streamName = \"kinesis_index_test_\" + UUID.randomUUID();\n+    String datasource = \"kinesis_indexing_service_test_\" + UUID.randomUUID();\n+    Map<String, String> tags = ImmutableMap.of(STREAM_EXPIRE_TAG, Long.toString(DateTimes.nowUtc().plusMinutes(30).getMillis()));\n+    kinesisAdminClient.createStream(streamName, KINESIS_SHARD_COUNT, tags);\n+    ITRetryUtil.retryUntil(\n+        () -> kinesisAdminClient.isStreamActive(streamName),\n+        true,\n+        10000,\n+        30,\n+        \"Wait for stream active\"\n+    );\n+    secondsToGenerateRemaining = TOTAL_NUMBER_OF_SECOND;\n+    fullDatasourceName = datasource + config.getExtraDatasourceNameSuffix();\n+    kinesisIngestionPropsTransform = spec -> {\n+      try {\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%DATASOURCE%%\",\n+            fullDatasourceName\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%STREAM_TYPE%%\",\n+            \"kinesis\"\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TOPIC_KEY%%\",\n+            \"stream\"\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TOPIC_VALUE%%\",\n+            streamName\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%USE_EARLIEST_KEY%%\",\n+            \"useEarliestSequenceNumber\"\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%STREAM_PROPERTIES_KEY%%\",\n+            \"endpoint\"\n+        );\n+        return StringUtils.replace(\n+            spec,\n+            \"%%STREAM_PROPERTIES_VALUE%%\",\n+            jsonMapper.writeValueAsString(config.getStreamEndpoint())\n+        );\n+      }\n+      catch (Exception e) {\n+        throw new RuntimeException(e);\n+      }\n+    };\n+    kinesisQueryPropsTransform = spec -> {\n+      try {\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%DATASOURCE%%\",\n+            fullDatasourceName\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMEBOUNDARY_RESPONSE_TIMESTAMP%%\",\n+            TIMESTAMP_FMT.print(FIRST_EVENT_TIME)\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMEBOUNDARY_RESPONSE_MAXTIME%%\",\n+            TIMESTAMP_FMT.print(FIRST_EVENT_TIME.plusSeconds(TOTAL_NUMBER_OF_SECOND - 1))\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMEBOUNDARY_RESPONSE_MINTIME%%\",\n+            TIMESTAMP_FMT.print(FIRST_EVENT_TIME)\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_QUERY_START%%\",\n+            INTERVAL_FMT.print(FIRST_EVENT_TIME)\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_QUERY_END%%\",\n+            INTERVAL_FMT.print(FIRST_EVENT_TIME.plusSeconds(TOTAL_NUMBER_OF_SECOND - 1).plusMinutes(2))\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_RESPONSE_TIMESTAMP%%\",\n+            TIMESTAMP_FMT.print(FIRST_EVENT_TIME)\n+        );\n+        spec = StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_ADDED%%\",\n+            Long.toString(getSumOfEventSequence(EVENTS_PER_SECOND) * TOTAL_NUMBER_OF_SECOND)\n+        );\n+        return StringUtils.replace(\n+            spec,\n+            \"%%TIMESERIES_NUMEVENTS%%\",\n+            Integer.toString(EVENTS_PER_SECOND * TOTAL_NUMBER_OF_SECOND)\n+        );\n+      }\n+      catch (Exception e) {\n+        throw new RuntimeException(e);\n+      }\n+    };\n+  }\n+\n+  @AfterMethod\n+  public void teardown()\n+  {\n+    try {\n+      kinesisEventWriter.flush();\n+      indexer.shutdownSupervisor(supervisorId);\n+      unloader(fullDatasourceName);\n+      kinesisAdminClient.deleteStream(streamName);\n+    }\n+    catch (Exception e) {\n+      // Best effort cleanup\n+    }\n+  }\n+\n+  @Test\n+  public void testKineseIndexDataWithLegacyParserStableState() throws Exception", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTMzOTM3Ng=="}, "originalCommit": {"oid": "d7637d53ff7fdee5ff28b15c49178b176bbf3a39"}, "originalPosition": 225}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2686, "cost": 1, "resetAt": "2021-11-12T11:18:39Z"}}}