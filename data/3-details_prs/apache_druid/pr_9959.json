{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDI1NzI0NzQ4", "number": 9959, "title": "Fix Subquery could not be converted to groupBy query", "bodyText": "Fix Subquery could not be converted to groupBy query\nDescription\nThis fix the issue at #9949\nBefore 0.18, subquery for a DruidOuterQueryRel can only be a groupBy. Hence, we force subquery to a groupBy and fails if the subquery cannot be converted to a groupBy. However, starting from 0.18, subquery of a DruidOuterQueryRel can be any type of query (timeseries, scan, topN, etc.). In fact, even if a query can be a groupBy, it can be more performant to actually convert the query to other type such as timeseries.\nThis PR removes the forcing of subquery of a DruidOuterQueryRel to groupBy and instead uses the method DruidQuery#getQuery().\nThis PR also address a related issue with timeseries subquery. DruidQuery.toTimeseriesQuery translates a dimension based on a timestamp_floor expression into a 'granularity'. This is not reflected in the druidQuery's output row signature. Existing code adds a \"__time\" in the output row signature to solve this. However, when DruidOuterQueryRel tries to aggregate on a timeseries subquery that is grouped by timestamp_floor expression, it fails. This is because the DruidOuterQueryRel expects a dimension (i.e. d0) but the timeseries output row signature has \"__time\" instead. This PR fixes this issue by introducing dimension field to the timeseries query. The dimension field will only be set if the timeseries is being group by timestamp. The dimension field will then be set with the correct dimension output name from the grouping. The dimension field is then use to set the timeseries query output row signature correctly.\nThis PR has:\n\n been self-reviewed.\n added documentation for new or modified features or behaviors.\n added Javadocs for most classes and all non-trivial methods. Linked related entities via Javadoc links.\n added or updated version, license, or notice information in licenses.yaml\n added comments explaining the \"why\" and the intent of the code wherever would not be obvious for an unfamiliar reader.\n added unit tests or modified existing tests to cover new code paths.\n added integration tests.\n been tested in a test Druid cluster.", "createdAt": "2020-06-01T02:59:30Z", "url": "https://github.com/apache/druid/pull/9959", "merged": true, "mergeCommit": {"oid": "790e9482ea18d87d59eeeeab4ceec14e4b1e192d"}, "closed": true, "closedAt": "2020-06-03T23:46:29Z", "author": {"login": "maytasm"}, "timelineItems": {"totalCount": 16, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcmBGUugH2gAyNDI1NzI0NzQ4OmMzNTI0MmEzNzg2YWRjYmZiYzkwZjFiMjJlZjEwMTdiM2YzY2ExMGM=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcnyUERAFqTQyNDAxMDA0MQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "c35242a3786adcbfbc90f1b22ef1017b3f3ca10c", "author": {"user": {"login": "maytasm", "name": "Maytas Monsereenusorn"}}, "url": "https://github.com/apache/druid/commit/c35242a3786adcbfbc90f1b22ef1017b3f3ca10c", "committedDate": "2020-05-29T11:52:01Z", "message": "Fix join"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e9d549ab1c6895c3f3e4dd5af02021a75884c035", "author": {"user": {"login": "maytasm", "name": "Maytas Monsereenusorn"}}, "url": "https://github.com/apache/druid/commit/e9d549ab1c6895c3f3e4dd5af02021a75884c035", "committedDate": "2020-05-31T15:06:42Z", "message": "Fix Subquery could not be converted to groupBy query"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7fbffc2cb429431b12972a378751d5c31e06b6a7", "author": {"user": {"login": "maytasm", "name": "Maytas Monsereenusorn"}}, "url": "https://github.com/apache/druid/commit/7fbffc2cb429431b12972a378751d5c31e06b6a7", "committedDate": "2020-06-01T02:45:44Z", "message": "Fix Subquery could not be converted to groupBy query"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIyMDQwNzk2", "url": "https://github.com/apache/druid/pull/9959#pullrequestreview-422040796", "createdAt": "2020-06-01T17:31:15Z", "commit": {"oid": "7fbffc2cb429431b12972a378751d5c31e06b6a7"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMVQxNzozMToxNVrOGdTfqA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMVQxNzozMToxNVrOGdTfqA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzM4MTI4OA==", "bodyText": "I think you diagnosed the bug right but the fix is a bit sketchy. If the Timeseries query accepts a DimensionSpec but then only uses it in the array signature, the following problems occur:\n\nThe input field, extractionFn, and decoration logic of the DimensionSpec are ignored.\nThe type might not actually be correct here; it will use the type from the DimensionSpec, but that might not match the actual type of the field, because the query engine isn't enforcing it.\nThe array signature should also match the maps returned from normal map-based responses, but this won't.\n\nI think the idea of a special parameter to the Timeseries query that makes the time column have a different name is a good idea, though. Maybe instead this would work:\n\nAdd an undocumented timeseries context parameter like timestampResultField that adds a new field containing the timestamp as a long, with the given name, to both the map and array responses.\nModify the SQL layer to generate this context parameter for timeseries queries when there is a time floor dimension.", "url": "https://github.com/apache/druid/pull/9959#discussion_r433381288", "createdAt": "2020-06-01T17:31:15Z", "author": {"login": "gianm"}, "path": "processing/src/main/java/org/apache/druid/query/timeseries/TimeseriesQueryQueryToolChest.java", "diffHunk": "@@ -404,11 +407,16 @@ public boolean isCacheable(TimeseriesQuery query, boolean willMergeRunners)\n   @Override\n   public RowSignature resultArraySignature(TimeseriesQuery query)\n   {\n-    return RowSignature.builder()\n-                       .addTimeColumn()\n-                       .addAggregators(query.getAggregatorSpecs())\n-                       .addPostAggregators(query.getPostAggregatorSpecs())\n-                       .build();\n+\n+    RowSignature.Builder rowSignatureBuilder = RowSignature.builder();\n+    if (query.getDimensionSpec() != null) {\n+      rowSignatureBuilder.addDimensions(Collections.singletonList(query.getDimensionSpec()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7fbffc2cb429431b12972a378751d5c31e06b6a7"}, "originalPosition": 27}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4aec5f65c53f80ebacc03f51df2a23bf8b4186d9", "author": {"user": {"login": "maytasm", "name": "Maytas Monsereenusorn"}}, "url": "https://github.com/apache/druid/commit/4aec5f65c53f80ebacc03f51df2a23bf8b4186d9", "committedDate": "2020-06-03T04:47:20Z", "message": "Fix Subquery could not be converted to groupBy query"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2b6fbd30a8272b3451e7fdc51fbbea1b8c2f3cac", "author": {"user": {"login": "maytasm", "name": "Maytas Monsereenusorn"}}, "url": "https://github.com/apache/druid/commit/2b6fbd30a8272b3451e7fdc51fbbea1b8c2f3cac", "committedDate": "2020-06-03T05:20:33Z", "message": "Fix Subquery could not be converted to groupBy query"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7af85ca9867df65962ffd9e24e86b7a2303a7bdc", "author": {"user": {"login": "maytasm", "name": "Maytas Monsereenusorn"}}, "url": "https://github.com/apache/druid/commit/7af85ca9867df65962ffd9e24e86b7a2303a7bdc", "committedDate": "2020-06-03T06:25:09Z", "message": "Fix Subquery could not be converted to groupBy query"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1b769953ce6a32b0998b7f30de386447bef51b2a", "author": {"user": {"login": "maytasm", "name": "Maytas Monsereenusorn"}}, "url": "https://github.com/apache/druid/commit/1b769953ce6a32b0998b7f30de386447bef51b2a", "committedDate": "2020-06-03T07:09:42Z", "message": "Fix Subquery could not be converted to groupBy query"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "688878433a579efa34c61582ffa7e188fd2dbf2f", "author": {"user": {"login": "maytasm", "name": "Maytas Monsereenusorn"}}, "url": "https://github.com/apache/druid/commit/688878433a579efa34c61582ffa7e188fd2dbf2f", "committedDate": "2020-06-03T07:43:14Z", "message": "Fix Subquery could not be converted to groupBy query"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "11d082761739f010652c188fcd0e15f94eb07e1c", "author": {"user": {"login": "maytasm", "name": "Maytas Monsereenusorn"}}, "url": "https://github.com/apache/druid/commit/11d082761739f010652c188fcd0e15f94eb07e1c", "committedDate": "2020-06-03T09:31:01Z", "message": "Fix Subquery could not be converted to groupBy query"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7c11456fe1a622c0d3202e0c0ed1675bc6220338", "author": {"user": {"login": "maytasm", "name": "Maytas Monsereenusorn"}}, "url": "https://github.com/apache/druid/commit/7c11456fe1a622c0d3202e0c0ed1675bc6220338", "committedDate": "2020-06-03T12:14:58Z", "message": "add tests"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIzODA3NTA2", "url": "https://github.com/apache/druid/pull/9959#pullrequestreview-423807506", "createdAt": "2020-06-03T18:09:43Z", "commit": {"oid": "7c11456fe1a622c0d3202e0c0ed1675bc6220338"}, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wM1QxODowOTo0M1rOGenoKw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wM1QxODozNjo1MFrOGeokGA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc1OTcyMw==", "bodyText": "nit: there's an unmatched parenthesis here.", "url": "https://github.com/apache/druid/pull/9959#discussion_r434759723", "createdAt": "2020-06-03T18:09:43Z", "author": {"login": "gianm"}, "path": "processing/src/test/java/org/apache/druid/query/groupby/GroupByTimeseriesQueryRunnerTest.java", "diffHunk": "@@ -235,4 +235,11 @@ public void testTimeseriesWithFilterOnNonExistentDimension()\n     // Skip this test because the timeseries test expects a day that doesn't have a filter match to be filled in,\n     // but group by just doesn't return a value if the filter doesn't match.\n   }\n+\n+  @Override\n+  public void testTimeseriesWithTimestampResultFieldContext()\n+  {\n+    // Skip this test because the timeseries test expects an extra column to be created (map from the timestamp_floor", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c11456fe1a622c0d3202e0c0ed1675bc6220338"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc2MTIzNQ==", "bodyText": "\"testResultArraySignatureWithTimestampResultField\" would be a better name, because that's the feature we're testing from the TimeseriesQuery point of view (the fact that it's useful for SQL time floor groupings is more of a concern of the SQL layer).", "url": "https://github.com/apache/druid/pull/9959#discussion_r434761235", "createdAt": "2020-06-03T18:12:32Z", "author": {"login": "gianm"}, "path": "processing/src/test/java/org/apache/druid/query/timeseries/TimeseriesQueryQueryToolChestTest.java", "diffHunk": "@@ -388,6 +389,33 @@ public void testResultArraySignature()\n     );\n   }\n \n+  @Test\n+  public void testResultArraySignatureWithFloorTime()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c11456fe1a622c0d3202e0c0ed1675bc6220338"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc2MTMzNQ==", "bodyText": "\"testResultArraySignatureWithoutTimestampResultField\" would be a better name.", "url": "https://github.com/apache/druid/pull/9959#discussion_r434761335", "createdAt": "2020-06-03T18:12:43Z", "author": {"login": "gianm"}, "path": "processing/src/test/java/org/apache/druid/query/timeseries/TimeseriesQueryQueryToolChestTest.java", "diffHunk": "@@ -364,7 +365,7 @@ public void testResultLevelCacheKeyWithGrandTotal()\n   }\n \n   @Test\n-  public void testResultArraySignature()\n+  public void testResultArraySignatureWithoutFloorTime()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c11456fe1a622c0d3202e0c0ed1675bc6220338"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc2NDE4NQ==", "bodyText": "You should include a test that verifies behavior for the resultsAsArrays result type as well.", "url": "https://github.com/apache/druid/pull/9959#discussion_r434764185", "createdAt": "2020-06-03T18:17:53Z", "author": {"login": "gianm"}, "path": "processing/src/test/java/org/apache/druid/query/timeseries/TimeseriesQueryRunnerTest.java", "diffHunk": "@@ -2471,6 +2472,123 @@ public void testTimeseriesWithBoundFilter1()\n     TestHelper.assertExpectedResults(expectedResults, results);\n   }\n \n+  @Test\n+  public void testTimeseriesWithTimestampResultFieldContext()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c11456fe1a622c0d3202e0c0ed1675bc6220338"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc3MjM2MA==", "bodyText": "I think we usually don't do import static like this, but if checkstyle was ok with it, then you can keep it.", "url": "https://github.com/apache/druid/pull/9959#discussion_r434772360", "createdAt": "2020-06-03T18:32:04Z", "author": {"login": "gianm"}, "path": "extensions-core/datasketches/src/test/java/org/apache/druid/query/aggregation/datasketches/hll/sql/HllSketchSqlAggregatorTest.java", "diffHunk": "@@ -90,6 +94,8 @@\n import java.util.List;\n import java.util.Map;\n \n+import static org.apache.druid.sql.calcite.BaseCalciteQueryTest.TIMESERIES_CONTEXT_DEFAULT;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c11456fe1a622c0d3202e0c0ed1675bc6220338"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc3NDI0Mg==", "bodyText": "This comment doesn't make a lot of sense to me. How about something like this instead:\n\nIf \"timestampResultField\" is set, we must include a copy of the timestamp in the result. This is used by the SQL layer when it generates a Timeseries query for a group-by-time-floor SQL query. The SQL layer expects the result of the time-floor to have a specific name that is not going to be \"__time\".", "url": "https://github.com/apache/druid/pull/9959#discussion_r434774242", "createdAt": "2020-06-03T18:35:19Z", "author": {"login": "gianm"}, "path": "processing/src/main/java/org/apache/druid/query/timeseries/TimeseriesQueryQueryToolChest.java", "diffHunk": "@@ -447,13 +454,21 @@ public RowSignature resultArraySignature(TimeseriesQuery query)\n     return result -> {\n       final TimeseriesResultValue holder = result.getValue();\n       final Map<String, Object> values = new HashMap<>(holder.getBaseObject());\n-      if (calculatePostAggs && !query.getPostAggregatorSpecs().isEmpty()) {\n-        // put non finalized aggregators for calculating dependent post Aggregators\n-        for (AggregatorFactory agg : query.getAggregatorSpecs()) {\n-          values.put(agg.getName(), holder.getMetric(agg.getName()));\n+      if (calculatePostAggs) {\n+        if (!query.getPostAggregatorSpecs().isEmpty()) {\n+          // put non finalized aggregators for calculating dependent post Aggregators\n+          for (AggregatorFactory agg : query.getAggregatorSpecs()) {\n+            values.put(agg.getName(), holder.getMetric(agg.getName()));\n+          }\n+          for (PostAggregator postAgg : query.getPostAggregatorSpecs()) {\n+            values.put(postAgg.getName(), postAgg.compute(values));\n+          }\n         }\n-        for (PostAggregator postAgg : query.getPostAggregatorSpecs()) {\n-          values.put(postAgg.getName(), postAgg.compute(values));\n+        // Timeseries query has timestamp_floor expression on the timestamp dimension so we need to\n+        // map the results to another dimension using the name (String) supplied by context key", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c11456fe1a622c0d3202e0c0ed1675bc6220338"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDc3NTA2NA==", "bodyText": "I think this could be clearer. How about:\n\n\"timestampResultField\" is an undocumented parameter used internally by the SQL layer. It is necessary because when the SQL layer generates a Timeseries query for a group-by-time-floor SQL query, it expects the result of the time-floor to have a specific name. That name is provided using this parameter.", "url": "https://github.com/apache/druid/pull/9959#discussion_r434775064", "createdAt": "2020-06-03T18:36:50Z", "author": {"login": "gianm"}, "path": "processing/src/main/java/org/apache/druid/query/timeseries/TimeseriesQuery.java", "diffHunk": "@@ -50,6 +50,12 @@\n {\n   public static final String CTX_GRAND_TOTAL = \"grandTotal\";\n   public static final String SKIP_EMPTY_BUCKETS = \"skipEmptyBuckets\";\n+  // This context parameter is an undocumented parameter, used internally, to allow timeseries query with", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7c11456fe1a622c0d3202e0c0ed1675bc6220338"}, "originalPosition": 4}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "eff405be76ceff3079cc342e5f8293b3ae2500e1", "author": {"user": {"login": "maytasm", "name": "Maytas Monsereenusorn"}}, "url": "https://github.com/apache/druid/commit/eff405be76ceff3079cc342e5f8293b3ae2500e1", "committedDate": "2020-06-03T20:47:49Z", "message": "address comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIzOTI3MTg4", "url": "https://github.com/apache/druid/pull/9959#pullrequestreview-423927188", "createdAt": "2020-06-03T20:55:59Z", "commit": {"oid": "eff405be76ceff3079cc342e5f8293b3ae2500e1"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "865abd8bdbb8ba0bc0ce3ff5c9eb7dd3ba38f589", "author": {"user": {"login": "maytasm", "name": "Maytas Monsereenusorn"}}, "url": "https://github.com/apache/druid/commit/865abd8bdbb8ba0bc0ce3ff5c9eb7dd3ba38f589", "committedDate": "2020-06-03T22:16:43Z", "message": "fix failing tests"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI0MDEwMDQx", "url": "https://github.com/apache/druid/pull/9959#pullrequestreview-424010041", "createdAt": "2020-06-03T23:46:18Z", "commit": {"oid": "865abd8bdbb8ba0bc0ce3ff5c9eb7dd3ba38f589"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2436, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}