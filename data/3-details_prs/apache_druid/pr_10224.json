{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDU4NjgxNzQ1", "number": 10224, "title": "Segment backed broadcast join IndexedTable", "bodyText": "Description\nRelated to #9953, this PR adds a simple naive implementation of an IndexedTable backed by Druid segments ingested with some extra information to identify which columns are 'join keys' at ingestion time, through the use of a custom segmentizer factory, via the changes done in #9957:\n      \"indexSpec\": {\n        \"segmentLoader\": {\n          \"type\": \"broadcastJoinableMMapSegmentFactory\",\n          \"keyColumns\": [\"col1\", \"col2\", \"col3\"]\n        }\n      }\n\nThis is probably longer term done better as being part of ColumnCapabilities, maybe a isJoinKey method, but since there might be other optimizations/customizations to the segment we are writing out to use for joins, I wanted to defer this change to future work to determine if there is a better segment format for this use case.\nThe implementation is based on and similar to RowBasedIndexedTable, but is fed with a QueryableIndexSegment which is scanned and the key columns are read to create the value indexes of the key columns, which are stored in heap memory in a list of hashmaps. The intention is that these will only be created for datasources that are configured to have a 'broadcast' load rule, which will propagate the entire dataset across the cluster, allowing the table to be used for more efficient joins.\nThe SegmentManager has been modified to extend DataSourceState to also contain a map of SegmentId to another newly added class in this PR, ReferenceCountingIndexedTable (related #9982), which ties the lifecycle of these tables to the segment that is backing them.\nA new BroadcastTableJoinableFactory has been added which is injected with the SegmentManager to allow fetching the indexed tables from these broadcast segments to construct into a Joinable, binding to GlobalTableDatasource introduced in #10020.\nSince it is an extension point, I have also reworked JoinableFactory a bit to allow binding multiple implementations to the same DataSource class, and so now is handled with 2 bindings, a MapBinder<Class<? extends JoinableFactory>, Class<? extends DataSource>> and a Multibinder<JoinableFactory> to provide MapJoinableFactory so it can build a SetMultimap<Class<? extends DataSource>, JoinableFactory>, which it will now try each factory when building a Joinable, returning the first that produces results.\nUnit tests and an integration test have been added to test this functionality, and the integration test also should cover much of the broadcast changes done in service of #9953.\nThis PR adds no new documentation yet, since the functionality should still be considered experimental, but I'll consider how to best document it before the next release and do it in a future follow-up PR.\nAlso note that there are currently some limitations with BroadcastTableJoinableFactory, most obviously that it only supports joins to single segment datasources. The SegmentManager itself does not care and will load any number of segments and tables, but joinable construction will fail. Part of the reason for this limitation is that I'm not certain the best way to resolve this, we could either make a composite IndexedTable that can in essence 'page' through it's sub-tables, or, we make a version of the join matcher that can handle a collection of tables, (or something else entirely?). It needs further investigation.\n\nThis PR has:\n\n been self-reviewed.\n\n using the concurrency checklist (Remove this item if the PR doesn't have any relation to concurrency.)\n\n\n added documentation for new or modified features or behaviors.\n added Javadocs for most classes and all non-trivial methods. Linked related entities via Javadoc links.\n added comments explaining the \"why\" and the intent of the code wherever would not be obvious for an unfamiliar reader.\n added unit tests or modified existing tests to cover new code paths, ensuring the threshold for code coverage is met.\n added integration tests.\n been tested in a test Druid cluster.\n\n\nKey changed/added classes in this PR\n\nBroadcastSegmentIndexedTable\nReferenceCountingIndexedTable\nBroadcastTableJoinableFactory\nBroadcastJoinableMMappedQueryableSegmentizerFactory\nSegmentManager\nMapJoinableFactory", "createdAt": "2020-07-29T20:43:31Z", "url": "https://github.com/apache/druid/pull/10224", "merged": true, "mergeCommit": {"oid": "7620b0c54e31ed466adf149b2b7fbd815c4c70ce"}, "closed": true, "closedAt": "2020-08-20T21:12:40Z", "author": {"login": "clintropolis"}, "timelineItems": {"totalCount": 21, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc5qXfPAH2gAyNDU4NjgxNzQ1OmJhZDY3MWIzOGU1MDE1ZTdhM2I1YWJlMGJlNGNkMGQ4OThhM2NiODA=", "endCursor": "Y3Vyc29yOnYyOpPPAAABc_4cNAAH2gAyNDU4NjgxNzQ1OjIzMDk5NWYxODQ1YjIzMDBlOGJkYjM1YTUwMGNjMzhmMDM1NWZjMTc=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "bad671b38e5015e7a3b5abe0be4cd0d898a3cb80", "author": {"user": {"login": "clintropolis", "name": "Clint Wylie"}}, "url": "https://github.com/apache/druid/commit/bad671b38e5015e7a3b5abe0be4cd0d898a3cb80", "committedDate": "2020-07-29T12:41:26Z", "message": "Segment backed broadcast join IndexedTable"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4574c5f801d907dc10bab85e3006ab8e500db0b4", "author": {"user": {"login": "clintropolis", "name": "Clint Wylie"}}, "url": "https://github.com/apache/druid/commit/4574c5f801d907dc10bab85e3006ab8e500db0b4", "committedDate": "2020-07-29T20:39:11Z", "message": "fix comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "86717ea3d16c7b28c587311a5136c4deb8311efb", "author": {"user": {"login": "clintropolis", "name": "Clint Wylie"}}, "url": "https://github.com/apache/druid/commit/86717ea3d16c7b28c587311a5136c4deb8311efb", "committedDate": "2020-07-30T01:41:08Z", "message": "fix tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "77552c3d3b4939fb99766f15565698f051f0a899", "author": {"user": {"login": "clintropolis", "name": "Clint Wylie"}}, "url": "https://github.com/apache/druid/commit/77552c3d3b4939fb99766f15565698f051f0a899", "committedDate": "2020-07-30T01:50:51Z", "message": "sharing is caring"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fa164df4ce2de3aab94328e74c56942625259f6a", "author": {"user": {"login": "clintropolis", "name": "Clint Wylie"}}, "url": "https://github.com/apache/druid/commit/fa164df4ce2de3aab94328e74c56942625259f6a", "committedDate": "2020-07-30T07:40:12Z", "message": "fix test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "744c4a6631aa7d65b39e609056920d20baa31100", "author": {"user": {"login": "clintropolis", "name": "Clint Wylie"}}, "url": "https://github.com/apache/druid/commit/744c4a6631aa7d65b39e609056920d20baa31100", "committedDate": "2020-07-30T10:11:40Z", "message": "i hope this doesnt fix it"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6b4621a619b369a05cd828404afcbe9cc36ebaaf", "author": {"user": {"login": "clintropolis", "name": "Clint Wylie"}}, "url": "https://github.com/apache/druid/commit/6b4621a619b369a05cd828404afcbe9cc36ebaaf", "committedDate": "2020-07-30T18:19:52Z", "message": "filter by schema to maybe fix test"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU5NTU0NTQy", "url": "https://github.com/apache/druid/pull/10224#pullrequestreview-459554542", "createdAt": "2020-08-01T05:21:27Z", "commit": {"oid": "6b4621a619b369a05cd828404afcbe9cc36ebaaf"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQwNToyMToyN1rOG6butQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMVQwNjo1MjowNVrOG6cJOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzkyNDkxNw==", "bodyText": "Should these be debug logs?", "url": "https://github.com/apache/druid/pull/10224#discussion_r463924917", "createdAt": "2020-08-01T05:21:27Z", "author": {"login": "jihoonson"}, "path": "processing/src/main/java/org/apache/druid/segment/join/table/BroadcastSegmentIndexedTable.java", "diffHunk": "@@ -0,0 +1,218 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join.table;\n+\n+import it.unimi.dsi.fastutil.ints.IntArrayList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.java.util.common.IAE;\n+import org.apache.druid.java.util.common.granularity.Granularities;\n+import org.apache.druid.java.util.common.guava.Sequence;\n+import org.apache.druid.java.util.common.guava.Sequences;\n+import org.apache.druid.java.util.common.logger.Logger;\n+import org.apache.druid.segment.BaseObjectColumnValueSelector;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.Cursor;\n+import org.apache.druid.segment.DimensionHandlerUtils;\n+import org.apache.druid.segment.QueryableIndex;\n+import org.apache.druid.segment.QueryableIndexSegment;\n+import org.apache.druid.segment.QueryableIndexStorageAdapter;\n+import org.apache.druid.segment.SimpleAscendingOffset;\n+import org.apache.druid.segment.VirtualColumns;\n+import org.apache.druid.segment.column.ColumnHolder;\n+import org.apache.druid.segment.column.RowSignature;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.filter.Filters;\n+import org.joda.time.chrono.ISOChronology;\n+\n+import javax.annotation.Nullable;\n+import java.io.Closeable;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+public class BroadcastSegmentIndexedTable implements IndexedTable\n+{\n+  private static final Logger LOG = new Logger(BroadcastSegmentIndexedTable.class);\n+\n+  private final QueryableIndexSegment segment;\n+  private final QueryableIndexStorageAdapter adapter;\n+  private final QueryableIndex queryableIndex;\n+  private final Set<String> keyColumns;\n+  private final RowSignature rowSignature;\n+  private final String version;\n+  private final List<Map<Object, IntList>> keyColumnsIndex;\n+\n+  public BroadcastSegmentIndexedTable(final QueryableIndexSegment theSegment, final Set<String> keyColumns, final String version)\n+  {\n+    this.keyColumns = keyColumns;\n+    this.version = version;\n+    this.segment = theSegment;\n+    this.adapter = (QueryableIndexStorageAdapter) segment.asStorageAdapter();\n+    this.queryableIndex = segment.asQueryableIndex();\n+\n+    RowSignature.Builder sigBuilder = RowSignature.builder();\n+    sigBuilder.add(ColumnHolder.TIME_COLUMN_NAME, ValueType.LONG);\n+    for (String column : queryableIndex.getColumnNames()) {\n+      sigBuilder.add(column, adapter.getColumnCapabilities(column).getType());\n+    }\n+    this.rowSignature = sigBuilder.build();\n+\n+    // initialize keycolumn index maps\n+    this.keyColumnsIndex = new ArrayList<>(rowSignature.size());\n+    final List<String> keyColumnNames = new ArrayList<>(keyColumns.size());\n+    for (int i = 0; i < rowSignature.size(); i++) {\n+      final Map<Object, IntList> m;\n+      final String columnName = rowSignature.getColumnName(i);\n+      if (keyColumns.contains(columnName)) {\n+        m = new HashMap<>();\n+        keyColumnNames.add(columnName);\n+      } else {\n+        m = null;\n+      }\n+      keyColumnsIndex.add(m);\n+    }\n+\n+    // sort of like the dump segment tool, but build key column indexes when reading the segment\n+    final Sequence<Cursor> cursors = adapter.makeCursors(\n+        Filters.toFilter(null),\n+        queryableIndex.getDataInterval().withChronology(ISOChronology.getInstanceUTC()),\n+        VirtualColumns.EMPTY,\n+        Granularities.ALL,\n+        false,\n+        null\n+    );\n+\n+    final Sequence<Integer> sequence = Sequences.map(\n+        cursors,\n+        cursor -> {\n+          int rowNumber = 0;\n+          ColumnSelectorFactory columnSelectorFactory = cursor.getColumnSelectorFactory();\n+\n+          // this should really be optimized to use dimension selectors where possible to populate indexes from bitmap\n+          // indexes, but, an optimization for another day\n+          final List<BaseObjectColumnValueSelector> selectors = keyColumnNames\n+              .stream()\n+              .map(columnSelectorFactory::makeColumnValueSelector)\n+              .collect(Collectors.toList());\n+\n+          while (!cursor.isDone()) {\n+            for (int keyColumnSelectorIndex = 0; keyColumnSelectorIndex < selectors.size(); keyColumnSelectorIndex++) {\n+              final String keyColumnName = keyColumnNames.get(keyColumnSelectorIndex);\n+              final int columnPosition = rowSignature.indexOf(keyColumnName);\n+              final Map<Object, IntList> keyColumnValueIndex = keyColumnsIndex.get(columnPosition);\n+\n+              final Object value = selectors.get(keyColumnSelectorIndex).getObject();\n+              final ValueType keyType = rowSignature.getColumnType(keyColumnName)\n+                                                    .orElse(IndexedTableJoinMatcher.DEFAULT_KEY_TYPE);\n+              // is this actually necessary or is value already cool? (RowBasedIndexedTable cargo cult represent)\n+              final Object key = DimensionHandlerUtils.convertObjectToType(value, keyType);\n+\n+              if (key != null) {\n+                final IntList array = keyColumnValueIndex.computeIfAbsent(key, k -> new IntArrayList());\n+                array.add(rowNumber);\n+              }\n+            }\n+\n+            if (rowNumber % 100_000 == 0) {\n+              if (rowNumber == 0) {\n+                LOG.info(\"Indexed first row for table %s\", theSegment.getId());\n+              } else {\n+                LOG.info(\"Indexed row %s for table %s\", rowNumber, theSegment.getId());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b4621a619b369a05cd828404afcbe9cc36ebaaf"}, "originalPosition": 141}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzkyNjE5OQ==", "bodyText": "Unused variable.", "url": "https://github.com/apache/druid/pull/10224#discussion_r463926199", "createdAt": "2020-08-01T05:38:56Z", "author": {"login": "jihoonson"}, "path": "server/src/main/java/org/apache/druid/server/SegmentManager.java", "diffHunk": "@@ -155,13 +172,44 @@ public boolean isSegmentCached(final DataSegment segment)\n    */\n   public Optional<VersionedIntervalTimeline<String, ReferenceCountingSegment>> getTimeline(DataSourceAnalysis analysis)\n   {\n-    final TableDataSource tableDataSource =\n-        analysis.getBaseTableDataSource()\n-                .orElseThrow(() -> new ISE(\"Cannot handle datasource: %s\", analysis.getDataSource()));\n-\n+    final TableDataSource tableDataSource = getTableDataSource(analysis);\n     return Optional.ofNullable(dataSources.get(tableDataSource.getName())).map(DataSourceState::getTimeline);\n   }\n \n+  public List<ReferenceCountingIndexedTable> getIndexedTables(\n+      DataSourceAnalysis analysis,\n+      JoinConditionAnalysis joinCondition", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b4621a619b369a05cd828404afcbe9cc36ebaaf"}, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzkyNjc3Mw==", "bodyText": "nit: you don't have to materialize segments here. Instead, you can call map on the stream directly in the below.", "url": "https://github.com/apache/druid/pull/10224#discussion_r463926773", "createdAt": "2020-08-01T05:46:20Z", "author": {"login": "jihoonson"}, "path": "server/src/main/java/org/apache/druid/server/SegmentManager.java", "diffHunk": "@@ -155,13 +172,44 @@ public boolean isSegmentCached(final DataSegment segment)\n    */\n   public Optional<VersionedIntervalTimeline<String, ReferenceCountingSegment>> getTimeline(DataSourceAnalysis analysis)\n   {\n-    final TableDataSource tableDataSource =\n-        analysis.getBaseTableDataSource()\n-                .orElseThrow(() -> new ISE(\"Cannot handle datasource: %s\", analysis.getDataSource()));\n-\n+    final TableDataSource tableDataSource = getTableDataSource(analysis);\n     return Optional.ofNullable(dataSources.get(tableDataSource.getName())).map(DataSourceState::getTimeline);\n   }\n \n+  public List<ReferenceCountingIndexedTable> getIndexedTables(\n+      DataSourceAnalysis analysis,\n+      JoinConditionAnalysis joinCondition\n+  )\n+  {\n+    return getTimeline(analysis).map(timeline -> {\n+      // join doesn't currently consider intervals, so just consider all segments\n+      final Collection<ReferenceCountingSegment> segments =\n+          timeline.lookup(Intervals.ETERNITY)\n+                  .stream()\n+                  .flatMap(x -> StreamSupport.stream(x.getObject().payloads().spliterator(), false))\n+                  .collect(Collectors.toList());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b4621a619b369a05cd828404afcbe9cc36ebaaf"}, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzkzMTcwNA==", "bodyText": "Seems unnecessary since this test extends InitializeNullHandlingTest.", "url": "https://github.com/apache/druid/pull/10224#discussion_r463931704", "createdAt": "2020-08-01T06:52:05Z", "author": {"login": "jihoonson"}, "path": "processing/src/test/java/org/apache/druid/segment/join/table/BroadcastSegmentIndexedTableTest.java", "diffHunk": "@@ -0,0 +1,274 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join.table;\n+\n+import com.fasterxml.jackson.databind.InjectableValues;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.common.config.NullHandling;\n+import org.apache.druid.jackson.DefaultObjectMapper;\n+import org.apache.druid.jackson.SegmentizerModule;\n+import org.apache.druid.java.util.common.DateTimes;\n+import org.apache.druid.java.util.common.IAE;\n+import org.apache.druid.java.util.common.Intervals;\n+import org.apache.druid.java.util.common.StringUtils;\n+import org.apache.druid.math.expr.ExprMacroTable;\n+import org.apache.druid.query.expression.TestExprMacroTable;\n+import org.apache.druid.segment.BaseObjectColumnValueSelector;\n+import org.apache.druid.segment.IndexIO;\n+import org.apache.druid.segment.IndexMerger;\n+import org.apache.druid.segment.IndexMergerV9;\n+import org.apache.druid.segment.IndexSpec;\n+import org.apache.druid.segment.QueryableIndexSegment;\n+import org.apache.druid.segment.SimpleAscendingOffset;\n+import org.apache.druid.segment.TestIndex;\n+import org.apache.druid.segment.column.ColumnHolder;\n+import org.apache.druid.segment.incremental.IncrementalIndex;\n+import org.apache.druid.segment.loading.MMappedQueryableSegmentizerFactory;\n+import org.apache.druid.segment.loading.SegmentLoadingException;\n+import org.apache.druid.segment.loading.SegmentizerFactory;\n+import org.apache.druid.segment.writeout.OffHeapMemorySegmentWriteOutMediumFactory;\n+import org.apache.druid.testing.InitializedNullHandlingTest;\n+import org.apache.druid.timeline.DataSegment;\n+import org.joda.time.Interval;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.ExpectedException;\n+import org.junit.rules.TemporaryFolder;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Set;\n+\n+public class BroadcastSegmentIndexedTableTest extends InitializedNullHandlingTest\n+{\n+  private static final String STRING_COL_1 = \"market\";\n+  private static final String LONG_COL_1 = \"longNumericNull\";\n+  private static final String DOUBLE_COL_1 = \"doubleNumericNull\";\n+  private static final String FLOAT_COL_1 = \"floatNumericNull\";\n+  private static final String STRING_COL_2 = \"partial_null_column\";\n+  private static final String MULTI_VALUE_COLUMN = \"placementish\";\n+  private static final String DIM_NOT_EXISTS = \"DIM_NOT_EXISTS\";\n+  private static final String DATASOURCE = \"DATASOURCE\";\n+\n+  @Rule\n+  public TemporaryFolder temporaryFolder = new TemporaryFolder();\n+  @Rule\n+  public ExpectedException expectedException = ExpectedException.none();\n+\n+  private QueryableIndexSegment backingSegment;\n+  private BroadcastSegmentIndexedTable broadcastTable;\n+  private List<String> columnNames;\n+  private final Set<String> keyColumns = ImmutableSet.<String>builder()\n+                                                     .add(STRING_COL_1)\n+                                                     .add(STRING_COL_2)\n+                                                     .add(LONG_COL_1)\n+                                                     .add(DOUBLE_COL_1)\n+                                                     .add(FLOAT_COL_1)\n+                                                     .add(MULTI_VALUE_COLUMN)\n+                                                     .add(DIM_NOT_EXISTS)\n+                                                     .build();\n+\n+  @Before\n+  public void setup() throws IOException, SegmentLoadingException\n+  {\n+    NullHandling.initializeForTests();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b4621a619b369a05cd828404afcbe9cc36ebaaf"}, "originalPosition": 98}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2724bbe2f90261375c4429867125e3cacef3be67", "author": {"user": {"login": "clintropolis", "name": "Clint Wylie"}}, "url": "https://github.com/apache/druid/commit/2724bbe2f90261375c4429867125e3cacef3be67", "committedDate": "2020-08-01T13:18:54Z", "message": "changes"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU5Njg1MjYw", "url": "https://github.com/apache/druid/pull/10224#pullrequestreview-459685260", "createdAt": "2020-08-02T22:56:15Z", "commit": {"oid": "2724bbe2f90261375c4429867125e3cacef3be67"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "188c760c11e1e5952d70c87f77e06e00b4cf9e4e", "author": {"user": {"login": "clintropolis", "name": "Clint Wylie"}}, "url": "https://github.com/apache/druid/commit/188c760c11e1e5952d70c87f77e06e00b4cf9e4e", "committedDate": "2020-08-04T13:03:32Z", "message": "close join stuffs so it does not leak, allow table to directly make selector factory"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0349d184da095a91740c737a1e19dc8dee81fd2e", "author": {"user": {"login": "clintropolis", "name": "Clint Wylie"}}, "url": "https://github.com/apache/druid/commit/0349d184da095a91740c737a1e19dc8dee81fd2e", "committedDate": "2020-08-04T19:33:58Z", "message": "oops"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDYyNzkxMjg3", "url": "https://github.com/apache/druid/pull/10224#pullrequestreview-462791287", "createdAt": "2020-08-06T18:54:10Z", "commit": {"oid": "0349d184da095a91740c737a1e19dc8dee81fd2e"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQxODo1NDoxMFrOG9AMig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQxOTowNToxMFrOG9AjsQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjYxOTUzMA==", "bodyText": "Should this sanity check be retained?", "url": "https://github.com/apache/druid/pull/10224#discussion_r466619530", "createdAt": "2020-08-06T18:54:10Z", "author": {"login": "jon-wei"}, "path": "processing/src/main/java/org/apache/druid/segment/join/table/RowBasedIndexedTable.java", "diffHunk": "@@ -69,10 +68,6 @@ public RowBasedIndexedTable(\n     this.keyColumns = keyColumns;\n     this.version = version;\n \n-    if (new HashSet<>(keyColumns).size() != keyColumns.size()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0349d184da095a91740c737a1e19dc8dee81fd2e"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjYyNTQ1Nw==", "bodyText": "Can you explain why this is an error condition? From the comment at https://github.com/apache/druid/pull/10224/files#diff-51b09b44a8330d19728379390eef60a0R35 it sounds like multiple valid should be okay", "url": "https://github.com/apache/druid/pull/10224#discussion_r466625457", "createdAt": "2020-08-06T19:05:10Z", "author": {"login": "jon-wei"}, "path": "processing/src/main/java/org/apache/druid/segment/join/MapJoinableFactory.java", "diffHunk": "@@ -19,49 +19,64 @@\n \n package org.apache.druid.segment.join;\n \n+import com.google.common.collect.HashMultimap;\n+import com.google.common.collect.SetMultimap;\n import com.google.inject.Inject;\n+import org.apache.druid.java.util.common.ISE;\n import org.apache.druid.query.DataSource;\n \n-import java.util.IdentityHashMap;\n import java.util.Map;\n import java.util.Optional;\n+import java.util.Set;\n \n /**\n  * A {@link JoinableFactory} that delegates to the appropriate factory based on the type of the datasource.\n  *\n- * Datasources can register a factory via a DruidBinder\n+ * Datasources can register a factory via a DruidBinder. Any number of factories can be bound to a datasource, the\n+ * 'first' that matches will be returned to the caller, or none if no matches.\n  */\n public class MapJoinableFactory implements JoinableFactory\n {\n-  private final Map<Class<? extends DataSource>, JoinableFactory> joinableFactories;\n+  private final SetMultimap<Class<? extends DataSource>, JoinableFactory> joinableFactories;\n \n   @Inject\n-  public MapJoinableFactory(Map<Class<? extends DataSource>, JoinableFactory> joinableFactories)\n+  public MapJoinableFactory(\n+      Set<JoinableFactory> factories,\n+      Map<Class<? extends JoinableFactory>, Class<? extends DataSource>> factoryToDataSource\n+  )\n   {\n-    // Accesses to IdentityHashMap should be faster than to HashMap or ImmutableMap.\n-    // Class doesn't override Object.equals().\n-    this.joinableFactories = new IdentityHashMap<>(joinableFactories);\n+    this.joinableFactories = HashMultimap.create();\n+    factories.forEach(joinableFactory -> {\n+      joinableFactories.put(factoryToDataSource.get(joinableFactory.getClass()), joinableFactory);\n+    });\n   }\n \n   @Override\n   public boolean isDirectlyJoinable(DataSource dataSource)\n   {\n-    JoinableFactory factory = joinableFactories.get(dataSource.getClass());\n-    if (factory == null) {\n-      return false;\n-    } else {\n-      return factory.isDirectlyJoinable(dataSource);\n+    Set<JoinableFactory> factories = joinableFactories.get(dataSource.getClass());\n+    for (JoinableFactory factory : factories) {\n+      if (factory.isDirectlyJoinable(dataSource)) {\n+        return true;\n+      }\n     }\n+    return false;\n   }\n \n   @Override\n   public Optional<Joinable> build(DataSource dataSource, JoinConditionAnalysis condition)\n   {\n-    JoinableFactory factory = joinableFactories.get(dataSource.getClass());\n-    if (factory == null) {\n-      return Optional.empty();\n-    } else {\n-      return factory.build(dataSource, condition);\n+    Set<JoinableFactory> factories = joinableFactories.get(dataSource.getClass());\n+    Optional<Joinable> maybeJoinable = Optional.empty();\n+    for (JoinableFactory factory : factories) {\n+      Optional<Joinable> candidate = factory.build(dataSource, condition);\n+      if (candidate.isPresent()) {\n+        if (maybeJoinable.isPresent()) {\n+          throw new ISE(\"Multiple joinable factories are valid for table[%s]\", dataSource);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0349d184da095a91740c737a1e19dc8dee81fd2e"}, "originalPosition": 74}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3c86a9461e797838e0be5cd1db1d6aa3ce3d2640", "author": {"user": {"login": "clintropolis", "name": "Clint Wylie"}}, "url": "https://github.com/apache/druid/commit/3c86a9461e797838e0be5cd1db1d6aa3ce3d2640", "committedDate": "2020-08-07T08:32:50Z", "message": "update comment"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDYzNTgxNzEx", "url": "https://github.com/apache/druid/pull/10224#pullrequestreview-463581711", "createdAt": "2020-08-07T20:07:34Z", "commit": {"oid": "3c86a9461e797838e0be5cd1db1d6aa3ce3d2640"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY3MTE2Njky", "url": "https://github.com/apache/druid/pull/10224#pullrequestreview-467116692", "createdAt": "2020-08-13T20:44:58Z", "commit": {"oid": "3c86a9461e797838e0be5cd1db1d6aa3ce3d2640"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xM1QyMDo0NDo1OVrOHAdA4g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xM1QyMTo1MDo1OVrOHAe8zA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDIzNzQxMA==", "bodyText": "super nit: would you add final for descending as well just to be consistent?", "url": "https://github.com/apache/druid/pull/10224#discussion_r470237410", "createdAt": "2020-08-13T20:44:59Z", "author": {"login": "jihoonson"}, "path": "processing/src/main/java/org/apache/druid/segment/join/HashJoinEngine.java", "diffHunk": "@@ -51,14 +52,16 @@ private HashJoinEngine()\n    * not be queryable through the returned Cursor. This happens even if the right-hand joinable doesn't actually have a\n    * column with this name.\n    */\n-  public static Cursor makeJoinCursor(final Cursor leftCursor, final JoinableClause joinableClause)\n+  public static Cursor makeJoinCursor(final Cursor leftCursor, final JoinableClause joinableClause, boolean descending, final Closer closer)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3c86a9461e797838e0be5cd1db1d6aa3ce3d2640"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDI2NjQ1Nw==", "bodyText": "Can we use try-with-resources instead of CloseQuiently? It would be more aligned with #10247 as well.", "url": "https://github.com/apache/druid/pull/10224#discussion_r470266457", "createdAt": "2020-08-13T21:44:34Z", "author": {"login": "jihoonson"}, "path": "processing/src/main/java/org/apache/druid/segment/join/table/IndexedTableJoinable.java", "diffHunk": "@@ -97,41 +103,49 @@ public JoinMatcher makeJoinMatcher(\n     if (filterColumnPosition < 0 || correlatedColumnPosition < 0) {\n       return Optional.empty();\n     }\n+    Closer closer = Closer.create();\n+    try {\n+      Set<String> correlatedValues = new HashSet<>();\n+      if (table.keyColumns().contains(searchColumnName)) {\n+        IndexedTable.Index index = table.columnIndex(filterColumnPosition);\n+        IndexedTable.Reader reader = table.columnReader(correlatedColumnPosition);\n+        closer.register(reader);\n+        IntList rowIndex = index.find(searchColumnValue);\n+        for (int i = 0; i < rowIndex.size(); i++) {\n+          int rowNum = rowIndex.getInt(i);\n+          String correlatedDimVal = Objects.toString(reader.read(rowNum), null);\n+          correlatedValues.add(correlatedDimVal);\n \n-    Set<String> correlatedValues = new HashSet<>();\n-    if (table.keyColumns().contains(searchColumnName)) {\n-      IndexedTable.Index index = table.columnIndex(filterColumnPosition);\n-      IndexedTable.Reader reader = table.columnReader(correlatedColumnPosition);\n-      IntList rowIndex = index.find(searchColumnValue);\n-      for (int i = 0; i < rowIndex.size(); i++) {\n-        int rowNum = rowIndex.getInt(i);\n-        String correlatedDimVal = Objects.toString(reader.read(rowNum), null);\n-        correlatedValues.add(correlatedDimVal);\n-\n-        if (correlatedValues.size() > maxCorrelationSetSize) {\n+          if (correlatedValues.size() > maxCorrelationSetSize) {\n+            return Optional.empty();\n+          }\n+        }\n+        return Optional.of(correlatedValues);\n+      } else {\n+        if (!allowNonKeyColumnSearch) {\n           return Optional.empty();\n         }\n-      }\n-      return Optional.of(correlatedValues);\n-    } else {\n-      if (!allowNonKeyColumnSearch) {\n-        return Optional.empty();\n-      }\n \n-      IndexedTable.Reader dimNameReader = table.columnReader(filterColumnPosition);\n-      IndexedTable.Reader correlatedColumnReader = table.columnReader(correlatedColumnPosition);\n-      for (int i = 0; i < table.numRows(); i++) {\n-        String dimVal = Objects.toString(dimNameReader.read(i), null);\n-        if (searchColumnValue.equals(dimVal)) {\n-          String correlatedDimVal = Objects.toString(correlatedColumnReader.read(i), null);\n-          correlatedValues.add(correlatedDimVal);\n-          if (correlatedValues.size() > maxCorrelationSetSize) {\n-            return Optional.empty();\n+        IndexedTable.Reader dimNameReader = table.columnReader(filterColumnPosition);\n+        IndexedTable.Reader correlatedColumnReader = table.columnReader(correlatedColumnPosition);\n+        closer.register(dimNameReader);\n+        closer.register(correlatedColumnReader);\n+        for (int i = 0; i < table.numRows(); i++) {\n+          String dimVal = Objects.toString(dimNameReader.read(i), null);\n+          if (searchColumnValue.equals(dimVal)) {\n+            String correlatedDimVal = Objects.toString(correlatedColumnReader.read(i), null);\n+            correlatedValues.add(correlatedDimVal);\n+            if (correlatedValues.size() > maxCorrelationSetSize) {\n+              return Optional.empty();\n+            }\n           }\n         }\n-      }\n \n-      return Optional.of(correlatedValues);\n+        return Optional.of(correlatedValues);\n+      }\n+    }\n+    finally {\n+      CloseQuietly.close(closer);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3c86a9461e797838e0be5cd1db1d6aa3ce3d2640"}, "originalPosition": 104}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDI2NzE4Mg==", "bodyText": "Should it return Optional.empty() instead?", "url": "https://github.com/apache/druid/pull/10224#discussion_r470267182", "createdAt": "2020-08-13T21:46:16Z", "author": {"login": "jihoonson"}, "path": "server/src/main/java/org/apache/druid/segment/join/BroadcastTableJoinableFactory.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join;\n+\n+import com.google.common.collect.Iterators;\n+import com.google.inject.Inject;\n+import org.apache.druid.java.util.common.ISE;\n+import org.apache.druid.query.DataSource;\n+import org.apache.druid.query.GlobalTableDataSource;\n+import org.apache.druid.query.planning.DataSourceAnalysis;\n+import org.apache.druid.segment.join.table.IndexedTableJoinable;\n+import org.apache.druid.segment.join.table.ReferenceCountingIndexedTable;\n+import org.apache.druid.server.SegmentManager;\n+\n+import java.util.Iterator;\n+import java.util.Optional;\n+\n+public class BroadcastTableJoinableFactory implements JoinableFactory\n+{\n+  private final SegmentManager segmentManager;\n+\n+  @Inject\n+  public BroadcastTableJoinableFactory(SegmentManager segmentManager)\n+  {\n+    this.segmentManager = segmentManager;\n+  }\n+\n+  @Override\n+  public boolean isDirectlyJoinable(DataSource dataSource)\n+  {\n+    GlobalTableDataSource broadcastDatasource = (GlobalTableDataSource) dataSource;\n+    return broadcastDatasource != null && segmentManager.hasIndexedTables(broadcastDatasource.getName());\n+  }\n+\n+  @Override\n+  public Optional<Joinable> build(\n+      DataSource dataSource,\n+      JoinConditionAnalysis condition\n+  )\n+  {\n+    GlobalTableDataSource broadcastDatasource = (GlobalTableDataSource) dataSource;\n+    if (condition.canHashJoin()) {\n+      DataSourceAnalysis analysis = DataSourceAnalysis.forDataSource(broadcastDatasource);\n+      return segmentManager.getIndexedTables(analysis).map(tables -> {\n+        Iterator<ReferenceCountingIndexedTable> tableIterator = tables.iterator();\n+        if (!tableIterator.hasNext()) {\n+          return null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3c86a9461e797838e0be5cd1db1d6aa3ce3d2640"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDI2OTEzMg==", "bodyText": "Hmm, should we use Closer to close oldTable and oldQueryable so that both can be closed even when any potential errors is thrown?", "url": "https://github.com/apache/druid/pull/10224#discussion_r470269132", "createdAt": "2020-08-13T21:50:59Z", "author": {"login": "jihoonson"}, "path": "server/src/main/java/org/apache/druid/server/SegmentManager.java", "diffHunk": "@@ -258,6 +316,11 @@ public void dropSegment(final DataSegment segment)\n \n               log.info(\"Attempting to close segment %s\", segment.getId());\n               oldQueryable.close();\n+\n+              final ReferenceCountingIndexedTable oldTable = dataSourceState.tablesLookup.remove(segment.getId());\n+              if (oldTable != null) {\n+                oldTable.close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3c86a9461e797838e0be5cd1db1d6aa3ce3d2640"}, "originalPosition": 137}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dfcb58473bc88536de4c941b28c23d697f1a9494", "author": {"user": {"login": "clintropolis", "name": "Clint Wylie"}}, "url": "https://github.com/apache/druid/commit/dfcb58473bc88536de4c941b28c23d697f1a9494", "committedDate": "2020-08-13T22:33:04Z", "message": "review stuffs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "680000a9965f5f82f4c15e3f56d7a396f2f43711", "author": {"user": {"login": "clintropolis", "name": "Clint Wylie"}}, "url": "https://github.com/apache/druid/commit/680000a9965f5f82f4c15e3f56d7a396f2f43711", "committedDate": "2020-08-13T22:33:14Z", "message": "Merge remote-tracking branch 'upstream/master' into simple-broadcast-join-implementation"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY3MTkzMjk5", "url": "https://github.com/apache/druid/pull/10224#pullrequestreview-467193299", "createdAt": "2020-08-13T23:22:15Z", "commit": {"oid": "680000a9965f5f82f4c15e3f56d7a396f2f43711"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY4MjU1MTgy", "url": "https://github.com/apache/druid/pull/10224#pullrequestreview-468255182", "createdAt": "2020-08-17T08:12:37Z", "commit": {"oid": "680000a9965f5f82f4c15e3f56d7a396f2f43711"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QwODoxMjozN1rOHBesqg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QwODoxMjozN1rOHBesqg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTMxMzU3OA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                if (column < 0 || rowSignature.getColumnName(0) == null) {\n          \n          \n            \n                if (column < 0 || rowSignature.getColumnName(column) == null) {", "url": "https://github.com/apache/druid/pull/10224#discussion_r471313578", "createdAt": "2020-08-17T08:12:37Z", "author": {"login": "abhishekagarwal87"}, "path": "processing/src/main/java/org/apache/druid/segment/join/table/BroadcastSegmentIndexedTable.java", "diffHunk": "@@ -0,0 +1,255 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.druid.segment.join.table;\n+\n+import com.google.common.base.Preconditions;\n+import it.unimi.dsi.fastutil.ints.IntArrayList;\n+import it.unimi.dsi.fastutil.ints.IntList;\n+import org.apache.druid.java.util.common.IAE;\n+import org.apache.druid.java.util.common.granularity.Granularities;\n+import org.apache.druid.java.util.common.guava.Sequence;\n+import org.apache.druid.java.util.common.guava.Sequences;\n+import org.apache.druid.java.util.common.io.Closer;\n+import org.apache.druid.java.util.common.logger.Logger;\n+import org.apache.druid.segment.BaseObjectColumnValueSelector;\n+import org.apache.druid.segment.ColumnSelectorFactory;\n+import org.apache.druid.segment.Cursor;\n+import org.apache.druid.segment.NilColumnValueSelector;\n+import org.apache.druid.segment.QueryableIndex;\n+import org.apache.druid.segment.QueryableIndexColumnSelectorFactory;\n+import org.apache.druid.segment.QueryableIndexSegment;\n+import org.apache.druid.segment.QueryableIndexStorageAdapter;\n+import org.apache.druid.segment.SimpleAscendingOffset;\n+import org.apache.druid.segment.VirtualColumns;\n+import org.apache.druid.segment.column.BaseColumn;\n+import org.apache.druid.segment.column.ColumnHolder;\n+import org.apache.druid.segment.column.RowSignature;\n+import org.apache.druid.segment.column.ValueType;\n+import org.apache.druid.segment.data.ReadableOffset;\n+import org.apache.druid.segment.filter.Filters;\n+import org.joda.time.chrono.ISOChronology;\n+\n+import javax.annotation.Nullable;\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+\n+public class BroadcastSegmentIndexedTable implements IndexedTable\n+{\n+  private static final Logger LOG = new Logger(BroadcastSegmentIndexedTable.class);\n+\n+  private final QueryableIndexSegment segment;\n+  private final QueryableIndexStorageAdapter adapter;\n+  private final QueryableIndex queryableIndex;\n+  private final Set<String> keyColumns;\n+  private final RowSignature rowSignature;\n+  private final String version;\n+  private final List<Map<Object, IntList>> keyColumnsIndex;\n+\n+  public BroadcastSegmentIndexedTable(final QueryableIndexSegment theSegment, final Set<String> keyColumns, final String version)\n+  {\n+    this.keyColumns = keyColumns;\n+    this.version = version;\n+    this.segment = Preconditions.checkNotNull(theSegment, \"Segment must not be null\");\n+    this.adapter = Preconditions.checkNotNull(\n+        (QueryableIndexStorageAdapter) segment.asStorageAdapter(),\n+        \"Segment[%s] must have a QueryableIndexStorageAdapter\",\n+        segment.getId()\n+    );\n+    this.queryableIndex = Preconditions.checkNotNull(\n+        segment.asQueryableIndex(),\n+        \"Segment[%s] must have a QueryableIndexSegment\",\n+        segment.getId()\n+    );\n+\n+    RowSignature.Builder sigBuilder = RowSignature.builder();\n+    sigBuilder.add(ColumnHolder.TIME_COLUMN_NAME, ValueType.LONG);\n+    for (String column : queryableIndex.getColumnNames()) {\n+      sigBuilder.add(column, adapter.getColumnCapabilities(column).getType());\n+    }\n+    this.rowSignature = sigBuilder.build();\n+\n+    // initialize keycolumn index maps\n+    this.keyColumnsIndex = new ArrayList<>(rowSignature.size());\n+    final List<String> keyColumnNames = new ArrayList<>(keyColumns.size());\n+    for (int i = 0; i < rowSignature.size(); i++) {\n+      final Map<Object, IntList> m;\n+      final String columnName = rowSignature.getColumnName(i);\n+      if (keyColumns.contains(columnName)) {\n+        m = new HashMap<>();\n+        keyColumnNames.add(columnName);\n+      } else {\n+        m = null;\n+      }\n+      keyColumnsIndex.add(m);\n+    }\n+\n+    // sort of like the dump segment tool, but build key column indexes when reading the segment\n+    final Sequence<Cursor> cursors = adapter.makeCursors(\n+        Filters.toFilter(null),\n+        queryableIndex.getDataInterval().withChronology(ISOChronology.getInstanceUTC()),\n+        VirtualColumns.EMPTY,\n+        Granularities.ALL,\n+        false,\n+        null\n+    );\n+\n+    final Sequence<Integer> sequence = Sequences.map(\n+        cursors,\n+        cursor -> {\n+          if (cursor == null) {\n+            return 0;\n+          }\n+          int rowNumber = 0;\n+          ColumnSelectorFactory columnSelectorFactory = cursor.getColumnSelectorFactory();\n+\n+          // this should really be optimized to use dimension selectors where possible to populate indexes from bitmap\n+          // indexes, but, an optimization for another day\n+          final List<BaseObjectColumnValueSelector> selectors = keyColumnNames\n+              .stream()\n+              .map(columnName -> {\n+                // multi-value dimensions are not currently supported\n+                if (adapter.getColumnCapabilities(columnName).hasMultipleValues().isMaybeTrue()) {\n+                  return NilColumnValueSelector.instance();\n+                }\n+                return columnSelectorFactory.makeColumnValueSelector(columnName);\n+              })\n+              .collect(Collectors.toList());\n+\n+          while (!cursor.isDone()) {\n+            for (int keyColumnSelectorIndex = 0; keyColumnSelectorIndex < selectors.size(); keyColumnSelectorIndex++) {\n+              final String keyColumnName = keyColumnNames.get(keyColumnSelectorIndex);\n+              final int columnPosition = rowSignature.indexOf(keyColumnName);\n+              final Map<Object, IntList> keyColumnValueIndex = keyColumnsIndex.get(columnPosition);\n+              final Object key = selectors.get(keyColumnSelectorIndex).getObject();\n+              if (key != null) {\n+                final IntList array = keyColumnValueIndex.computeIfAbsent(key, k -> new IntArrayList());\n+                array.add(rowNumber);\n+              }\n+            }\n+\n+            if (rowNumber % 100_000 == 0) {\n+              if (rowNumber == 0) {\n+                LOG.debug(\"Indexed first row for table %s\", theSegment.getId());\n+              } else {\n+                LOG.debug(\"Indexed row %s for table %s\", rowNumber, theSegment.getId());\n+              }\n+            }\n+            rowNumber++;\n+            cursor.advance();\n+          }\n+          return rowNumber;\n+        }\n+    );\n+\n+    Integer totalRows = sequence.accumulate(0, (accumulated, in) -> accumulated += in);\n+    LOG.info(\"Created BroadcastSegmentIndexedTable with %s rows.\", totalRows);\n+  }\n+\n+  @Override\n+  public String version()\n+  {\n+    return version;\n+  }\n+\n+  @Override\n+  public Set<String> keyColumns()\n+  {\n+    return keyColumns;\n+  }\n+\n+  @Override\n+  public RowSignature rowSignature()\n+  {\n+    return rowSignature;\n+  }\n+\n+  @Override\n+  public int numRows()\n+  {\n+    return adapter.getNumRows();\n+  }\n+\n+  @Override\n+  public Index columnIndex(int column)\n+  {\n+    return RowBasedIndexedTable.getKeyColumnIndex(column, keyColumnsIndex, rowSignature);\n+  }\n+\n+  @Override\n+  public Reader columnReader(int column)\n+  {\n+    if (column < 0 || rowSignature.getColumnName(0) == null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "680000a9965f5f82f4c15e3f56d7a396f2f43711"}, "originalPosition": 205}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "230995f1845b2300e8bdb35a500cc38f0355fc17", "author": {"user": {"login": "clintropolis", "name": "Clint Wylie"}}, "url": "https://github.com/apache/druid/commit/230995f1845b2300e8bdb35a500cc38f0355fc17", "committedDate": "2020-08-17T20:28:48Z", "message": "better check"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1894, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}