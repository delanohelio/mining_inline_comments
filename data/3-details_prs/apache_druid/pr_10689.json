{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTQyMTEzOTYz", "number": 10689, "title": "Multiphase segment merge for IndexMergerV9", "bodyText": "This PR introduces a new tuning config parameter, maxColumnsToMerge.\nThis functions as a limit on how many segments can be merged at the same time by the IndexMerger, to limit memory usage during the merge. When the column limit is exceeded across a set of segments, the IndexMerger will break the segments to be merged into smaller phases, and merge the smaller phases in a tree.\nA minimum of 2 segments will be merged at once, regardless of the limit. If there is only 1 segment being merged, the limit does not apply. (A warning is logged in these cases, but merging is allowed to proceed).\nCurrently only the native batch and parallel ingest task tuning config have this new parameter added, this PR does not add support for it to Kafka/Kinesis ingestion yet.\nThis PR has:\n\n been self-reviewed.\n added documentation for new or modified features or behaviors.\n added Javadocs for most classes and all non-trivial methods. Linked related entities via Javadoc links.\n added or updated version, license, or notice information in licenses.yaml\n added comments explaining the \"why\" and the intent of the code wherever would not be obvious for an unfamiliar reader.\n added unit tests or modified existing tests to cover new code paths, ensuring the threshold for code coverage is met.\n added integration tests.\n been tested in a test Druid cluster.", "createdAt": "2020-12-17T20:41:58Z", "url": "https://github.com/apache/druid/pull/10689", "merged": true, "mergeCommit": {"oid": "68bb038b314c26bcc57aa96e1078c22d2f24fd35"}, "closed": true, "closedAt": "2021-01-06T06:19:10Z", "author": {"login": "jon-wei"}, "timelineItems": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdnJpikAH2gAyNTQyMTEzOTYzOjZlZTIzNDBmNWFiMTIyN2Q1ZTYxNzc2ZGUxMzMzZTlmYjI5NTg3YTY=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdtTWj8AFqTU2MjIwNTgxNA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "6ee2340f5ab1227d5e61776de1333e9fb29587a6", "author": {"user": {"login": "jon-wei", "name": "Jonathan Wei"}}, "url": "https://github.com/apache/druid/commit/6ee2340f5ab1227d5e61776de1333e9fb29587a6", "committedDate": "2020-12-17T20:34:48Z", "message": "Multiphase merge for IndexMergerV9"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "25a8d5789a893e6257c066e9a6a72034d8d3cc25", "author": {"user": {"login": "jon-wei", "name": "Jonathan Wei"}}, "url": "https://github.com/apache/druid/commit/25a8d5789a893e6257c066e9a6a72034d8d3cc25", "committedDate": "2020-12-17T23:44:21Z", "message": "JSON fix"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "262f223fb71d6d4f2393d44d240cf300ed331108", "author": {"user": {"login": "jon-wei", "name": "Jonathan Wei"}}, "url": "https://github.com/apache/druid/commit/262f223fb71d6d4f2393d44d240cf300ed331108", "committedDate": "2020-12-18T03:05:12Z", "message": "Cleanup temp files"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "76458ecb77b0b18bb0fc0a36e4bf6c389abce3ca", "author": {"user": {"login": "jon-wei", "name": "Jonathan Wei"}}, "url": "https://github.com/apache/druid/commit/76458ecb77b0b18bb0fc0a36e4bf6c389abce3ca", "committedDate": "2020-12-18T03:26:52Z", "message": "Docs"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU2Njk0MjI3", "url": "https://github.com/apache/druid/pull/10689#pullrequestreview-556694227", "createdAt": "2020-12-21T22:07:49Z", "commit": {"oid": "76458ecb77b0b18bb0fc0a36e4bf6c389abce3ca"}, "state": "APPROVED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQyMjowNzo0OVrOIJnaVg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMVQyMjo0Mjo1MFrOIJoJOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njk1MzgxNA==", "bodyText": "Should this be a warn since we expected to always merge at least two segments regardless of column limit? The warning may be misleading as there is nothing to fix / change", "url": "https://github.com/apache/druid/pull/10689#discussion_r546953814", "createdAt": "2020-12-21T22:07:49Z", "author": {"login": "maytasm"}, "path": "processing/src/main/java/org/apache/druid/segment/IndexMergerV9.java", "diffHunk": "@@ -931,25 +936,158 @@ public File merge(\n       boolean rollup,\n       final AggregatorFactory[] metricAggs,\n       File outDir,\n-      IndexSpec indexSpec\n+      IndexSpec indexSpec,\n+      int maxColumnsToMerge\n   ) throws IOException\n   {\n-    return merge(indexes, rollup, metricAggs, outDir, indexSpec, new BaseProgressIndicator(), null);\n+    return multiphaseMerge(indexes, rollup, metricAggs, outDir, indexSpec, new BaseProgressIndicator(), null, maxColumnsToMerge);\n   }\n \n-  private File merge(\n+  private File multiphaseMerge(\n       List<IndexableAdapter> indexes,\n       final boolean rollup,\n       final AggregatorFactory[] metricAggs,\n       File outDir,\n       IndexSpec indexSpec,\n       ProgressIndicator progress,\n-      @Nullable SegmentWriteOutMediumFactory segmentWriteOutMediumFactory\n+      @Nullable SegmentWriteOutMediumFactory segmentWriteOutMediumFactory,\n+      int maxColumnsToMerge\n   ) throws IOException\n   {\n     FileUtils.deleteDirectory(outDir);\n     org.apache.commons.io.FileUtils.forceMkdir(outDir);\n \n+    List<File> tempDirs = new ArrayList<>();\n+\n+    if (maxColumnsToMerge == IndexMerger.UNLIMITED_MAX_COLUMNS_TO_MERGE) {\n+      return merge(\n+          indexes,\n+          rollup,\n+          metricAggs,\n+          outDir,\n+          indexSpec,\n+          progress,\n+          segmentWriteOutMediumFactory\n+      );\n+    }\n+\n+    List<List<IndexableAdapter>> currentPhases = getMergePhases(indexes, maxColumnsToMerge);\n+    List<File> currentOutputs = new ArrayList<>();\n+\n+    log.debug(\"base outDir: \" + outDir);\n+\n+    try {\n+      while (true) {\n+        for (List<IndexableAdapter> phase : currentPhases) {\n+          File phaseOutDir;\n+          if (currentPhases.size() == 1) {\n+            // use the given outDir on the final merge phase\n+            phaseOutDir = outDir;\n+          } else {\n+            phaseOutDir = FileUtils.createTempDir();\n+            tempDirs.add(phaseOutDir);\n+          }\n+          log.debug(\"phase outDir: \" + phaseOutDir);\n+\n+          File phaseOutput = merge(\n+              phase,\n+              rollup,\n+              metricAggs,\n+              phaseOutDir,\n+              indexSpec,\n+              progress,\n+              segmentWriteOutMediumFactory\n+          );\n+          currentOutputs.add(phaseOutput);\n+        }\n+        if (currentOutputs.size() == 1) {\n+          // we're done, we made a single File output\n+          return currentOutputs.get(0);\n+        } else {\n+          // convert Files to QueryableIndexIndexableAdapter and do another merge phase\n+          List<IndexableAdapter> qIndexAdapters = new ArrayList<>();\n+          for (File outputFile : currentOutputs) {\n+            QueryableIndex qIndex = indexIO.loadIndex(outputFile, true);\n+            qIndexAdapters.add(new QueryableIndexIndexableAdapter(qIndex));\n+          }\n+          currentPhases = getMergePhases(qIndexAdapters, maxColumnsToMerge);\n+          currentOutputs = new ArrayList<>();\n+        }\n+      }\n+    }\n+    finally {\n+      for (File tempDir : tempDirs) {\n+        if (tempDir.exists()) {\n+          try {\n+            FileUtils.deleteDirectory(tempDir);\n+          }\n+          catch (Exception e) {\n+            log.warn(e, \"Failed to remove directory[%s]\", tempDir);\n+          }\n+        }\n+      }\n+    }\n+  }\n+\n+  private List<List<IndexableAdapter>> getMergePhases(List<IndexableAdapter> indexes, int maxColumnsToMerge)\n+  {\n+    List<List<IndexableAdapter>> toMerge = new ArrayList<>();\n+    // always merge at least two segments regardless of column limit\n+    if (indexes.size() <= 2) {\n+      if (getIndexColumnCount(indexes) > maxColumnsToMerge) {\n+        log.warn(\"index pair has more columns than maxColumnsToMerge [%d].\", maxColumnsToMerge);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "76458ecb77b0b18bb0fc0a36e4bf6c389abce3ca"}, "originalPosition": 169}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njk2NTIwNw==", "bodyText": "Is it useful to log the iteration number of this loop?\nlike how many times have we done a pass so far?", "url": "https://github.com/apache/druid/pull/10689#discussion_r546965207", "createdAt": "2020-12-21T22:40:48Z", "author": {"login": "maytasm"}, "path": "processing/src/main/java/org/apache/druid/segment/IndexMergerV9.java", "diffHunk": "@@ -931,25 +936,158 @@ public File merge(\n       boolean rollup,\n       final AggregatorFactory[] metricAggs,\n       File outDir,\n-      IndexSpec indexSpec\n+      IndexSpec indexSpec,\n+      int maxColumnsToMerge\n   ) throws IOException\n   {\n-    return merge(indexes, rollup, metricAggs, outDir, indexSpec, new BaseProgressIndicator(), null);\n+    return multiphaseMerge(indexes, rollup, metricAggs, outDir, indexSpec, new BaseProgressIndicator(), null, maxColumnsToMerge);\n   }\n \n-  private File merge(\n+  private File multiphaseMerge(\n       List<IndexableAdapter> indexes,\n       final boolean rollup,\n       final AggregatorFactory[] metricAggs,\n       File outDir,\n       IndexSpec indexSpec,\n       ProgressIndicator progress,\n-      @Nullable SegmentWriteOutMediumFactory segmentWriteOutMediumFactory\n+      @Nullable SegmentWriteOutMediumFactory segmentWriteOutMediumFactory,\n+      int maxColumnsToMerge\n   ) throws IOException\n   {\n     FileUtils.deleteDirectory(outDir);\n     org.apache.commons.io.FileUtils.forceMkdir(outDir);\n \n+    List<File> tempDirs = new ArrayList<>();\n+\n+    if (maxColumnsToMerge == IndexMerger.UNLIMITED_MAX_COLUMNS_TO_MERGE) {\n+      return merge(\n+          indexes,\n+          rollup,\n+          metricAggs,\n+          outDir,\n+          indexSpec,\n+          progress,\n+          segmentWriteOutMediumFactory\n+      );\n+    }\n+\n+    List<List<IndexableAdapter>> currentPhases = getMergePhases(indexes, maxColumnsToMerge);\n+    List<File> currentOutputs = new ArrayList<>();\n+\n+    log.debug(\"base outDir: \" + outDir);\n+\n+    try {\n+      while (true) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "76458ecb77b0b18bb0fc0a36e4bf6c389abce3ca"}, "originalPosition": 111}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njk2NTM1NA==", "bodyText": "is it useful to log the size of currentPhases? It might help to see the progress as the number should decrease after each pass", "url": "https://github.com/apache/druid/pull/10689#discussion_r546965354", "createdAt": "2020-12-21T22:41:19Z", "author": {"login": "maytasm"}, "path": "processing/src/main/java/org/apache/druid/segment/IndexMergerV9.java", "diffHunk": "@@ -931,25 +936,158 @@ public File merge(\n       boolean rollup,\n       final AggregatorFactory[] metricAggs,\n       File outDir,\n-      IndexSpec indexSpec\n+      IndexSpec indexSpec,\n+      int maxColumnsToMerge\n   ) throws IOException\n   {\n-    return merge(indexes, rollup, metricAggs, outDir, indexSpec, new BaseProgressIndicator(), null);\n+    return multiphaseMerge(indexes, rollup, metricAggs, outDir, indexSpec, new BaseProgressIndicator(), null, maxColumnsToMerge);\n   }\n \n-  private File merge(\n+  private File multiphaseMerge(\n       List<IndexableAdapter> indexes,\n       final boolean rollup,\n       final AggregatorFactory[] metricAggs,\n       File outDir,\n       IndexSpec indexSpec,\n       ProgressIndicator progress,\n-      @Nullable SegmentWriteOutMediumFactory segmentWriteOutMediumFactory\n+      @Nullable SegmentWriteOutMediumFactory segmentWriteOutMediumFactory,\n+      int maxColumnsToMerge\n   ) throws IOException\n   {\n     FileUtils.deleteDirectory(outDir);\n     org.apache.commons.io.FileUtils.forceMkdir(outDir);\n \n+    List<File> tempDirs = new ArrayList<>();\n+\n+    if (maxColumnsToMerge == IndexMerger.UNLIMITED_MAX_COLUMNS_TO_MERGE) {\n+      return merge(\n+          indexes,\n+          rollup,\n+          metricAggs,\n+          outDir,\n+          indexSpec,\n+          progress,\n+          segmentWriteOutMediumFactory\n+      );\n+    }\n+\n+    List<List<IndexableAdapter>> currentPhases = getMergePhases(indexes, maxColumnsToMerge);\n+    List<File> currentOutputs = new ArrayList<>();\n+\n+    log.debug(\"base outDir: \" + outDir);\n+\n+    try {\n+      while (true) {\n+        for (List<IndexableAdapter> phase : currentPhases) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "76458ecb77b0b18bb0fc0a36e4bf6c389abce3ca"}, "originalPosition": 112}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Njk2NTgxNw==", "bodyText": "Should this be a warn since this can happen and is a expected / ok thing? The warning may be misleading as there is nothing to fix / change", "url": "https://github.com/apache/druid/pull/10689#discussion_r546965817", "createdAt": "2020-12-21T22:42:50Z", "author": {"login": "maytasm"}, "path": "processing/src/main/java/org/apache/druid/segment/IndexMergerV9.java", "diffHunk": "@@ -931,25 +936,158 @@ public File merge(\n       boolean rollup,\n       final AggregatorFactory[] metricAggs,\n       File outDir,\n-      IndexSpec indexSpec\n+      IndexSpec indexSpec,\n+      int maxColumnsToMerge\n   ) throws IOException\n   {\n-    return merge(indexes, rollup, metricAggs, outDir, indexSpec, new BaseProgressIndicator(), null);\n+    return multiphaseMerge(indexes, rollup, metricAggs, outDir, indexSpec, new BaseProgressIndicator(), null, maxColumnsToMerge);\n   }\n \n-  private File merge(\n+  private File multiphaseMerge(\n       List<IndexableAdapter> indexes,\n       final boolean rollup,\n       final AggregatorFactory[] metricAggs,\n       File outDir,\n       IndexSpec indexSpec,\n       ProgressIndicator progress,\n-      @Nullable SegmentWriteOutMediumFactory segmentWriteOutMediumFactory\n+      @Nullable SegmentWriteOutMediumFactory segmentWriteOutMediumFactory,\n+      int maxColumnsToMerge\n   ) throws IOException\n   {\n     FileUtils.deleteDirectory(outDir);\n     org.apache.commons.io.FileUtils.forceMkdir(outDir);\n \n+    List<File> tempDirs = new ArrayList<>();\n+\n+    if (maxColumnsToMerge == IndexMerger.UNLIMITED_MAX_COLUMNS_TO_MERGE) {\n+      return merge(\n+          indexes,\n+          rollup,\n+          metricAggs,\n+          outDir,\n+          indexSpec,\n+          progress,\n+          segmentWriteOutMediumFactory\n+      );\n+    }\n+\n+    List<List<IndexableAdapter>> currentPhases = getMergePhases(indexes, maxColumnsToMerge);\n+    List<File> currentOutputs = new ArrayList<>();\n+\n+    log.debug(\"base outDir: \" + outDir);\n+\n+    try {\n+      while (true) {\n+        for (List<IndexableAdapter> phase : currentPhases) {\n+          File phaseOutDir;\n+          if (currentPhases.size() == 1) {\n+            // use the given outDir on the final merge phase\n+            phaseOutDir = outDir;\n+          } else {\n+            phaseOutDir = FileUtils.createTempDir();\n+            tempDirs.add(phaseOutDir);\n+          }\n+          log.debug(\"phase outDir: \" + phaseOutDir);\n+\n+          File phaseOutput = merge(\n+              phase,\n+              rollup,\n+              metricAggs,\n+              phaseOutDir,\n+              indexSpec,\n+              progress,\n+              segmentWriteOutMediumFactory\n+          );\n+          currentOutputs.add(phaseOutput);\n+        }\n+        if (currentOutputs.size() == 1) {\n+          // we're done, we made a single File output\n+          return currentOutputs.get(0);\n+        } else {\n+          // convert Files to QueryableIndexIndexableAdapter and do another merge phase\n+          List<IndexableAdapter> qIndexAdapters = new ArrayList<>();\n+          for (File outputFile : currentOutputs) {\n+            QueryableIndex qIndex = indexIO.loadIndex(outputFile, true);\n+            qIndexAdapters.add(new QueryableIndexIndexableAdapter(qIndex));\n+          }\n+          currentPhases = getMergePhases(qIndexAdapters, maxColumnsToMerge);\n+          currentOutputs = new ArrayList<>();\n+        }\n+      }\n+    }\n+    finally {\n+      for (File tempDir : tempDirs) {\n+        if (tempDir.exists()) {\n+          try {\n+            FileUtils.deleteDirectory(tempDir);\n+          }\n+          catch (Exception e) {\n+            log.warn(e, \"Failed to remove directory[%s]\", tempDir);\n+          }\n+        }\n+      }\n+    }\n+  }\n+\n+  private List<List<IndexableAdapter>> getMergePhases(List<IndexableAdapter> indexes, int maxColumnsToMerge)\n+  {\n+    List<List<IndexableAdapter>> toMerge = new ArrayList<>();\n+    // always merge at least two segments regardless of column limit\n+    if (indexes.size() <= 2) {\n+      if (getIndexColumnCount(indexes) > maxColumnsToMerge) {\n+        log.warn(\"index pair has more columns than maxColumnsToMerge [%d].\", maxColumnsToMerge);\n+      }\n+      toMerge.add(indexes);\n+    } else {\n+      List<IndexableAdapter> currentPhase = new ArrayList<>();\n+      int currentColumnCount = 0;\n+      for (IndexableAdapter index : indexes) {\n+        int indexColumnCount = getIndexColumnCount(index);\n+        if (indexColumnCount > maxColumnsToMerge) {\n+          log.warn(\"index has more columns [%d] than maxColumnsToMerge [%d]!\", indexColumnCount, maxColumnsToMerge);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "76458ecb77b0b18bb0fc0a36e4bf6c389abce3ca"}, "originalPosition": 178}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1e90ea3e56a921585268e1a4a4a6039328a977ff", "author": {"user": {"login": "jon-wei", "name": "Jonathan Wei"}}, "url": "https://github.com/apache/druid/commit/1e90ea3e56a921585268e1a4a4a6039328a977ff", "committedDate": "2020-12-25T00:56:21Z", "message": "Address logging and add IT"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ccf61c32c1275cee9f254169b15dbccc207a0c53", "author": {"user": {"login": "jon-wei", "name": "Jonathan Wei"}}, "url": "https://github.com/apache/druid/commit/ccf61c32c1275cee9f254169b15dbccc207a0c53", "committedDate": "2020-12-25T03:06:00Z", "message": "Fix spelling and test unloader datasource name"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYyMjA1ODE0", "url": "https://github.com/apache/druid/pull/10689#pullrequestreview-562205814", "createdAt": "2021-01-05T23:16:40Z", "commit": {"oid": "ccf61c32c1275cee9f254169b15dbccc207a0c53"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3205, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}