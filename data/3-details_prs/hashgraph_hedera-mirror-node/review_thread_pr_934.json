{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDYyODg1MTg0", "number": 934, "reviewThreads": {"totalCount": 36, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQxOToyMDozM1rOEVInBA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNjoyNToxNFrOEXSaNw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwNTk2NjEyOnYy", "diffSide": "RIGHT", "path": "hedera-mirror-rest/__tests__/specs/stateproof-06-invalid-transaction-id.spec.json", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQxOToyMDozM1rOG7uGLw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQxOToyMDozM1rOG7uGLw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTI3NDQxNQ==", "bodyText": "incorrect description, should be invalid transaction ID. will fix", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r465274415", "createdAt": "2020-08-04T19:20:33Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-rest/__tests__/specs/stateproof-06-invalid-transaction-id.spec.json", "diffHunk": "@@ -0,0 +1,22 @@\n+{\n+  \"description\": \"Stateproof api calls with valid transaction ID but transaction not found\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c1bcc561cf3ea63c6d4d9370f464403954b997ea"}, "originalPosition": 2}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMDIyNzY3OnYy", "diffSide": "RIGHT", "path": "hedera-mirror-rest/__tests__/specs/stateproof-01-success-result.spec.json", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQxOTowODowOVrOG8W5lQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQyMTowMjoxN1rOG_JIJg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk0MjkzMw==", "bodyText": "compare md5sum of the base64-encoded file content instead of base64 strings which are large.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r465942933", "createdAt": "2020-08-05T19:08:09Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-rest/__tests__/specs/stateproof-01-success-result.spec.json", "diffHunk": "@@ -0,0 +1,25 @@\n+{\n+  \"description\": \"Stateproof api calls with valid transaction ID and success response\",\n+  \"setup\": {\n+    \"sqlscripts\": [\n+      \"data/db/stateproof/address_book.sql\",\n+      \"data/db/stateproof/address_book_entry.sql\",\n+      \"data/db/stateproof/record_file.sql\",\n+      \"data/db/stateproof/transaction.sql\"\n+    ]\n+  },\n+  \"url\": \"/api/v1/transactions/0.0.94139-1570800748-313194300/stateproof\",\n+  \"responseStatus\": 200,\n+  \"responseJson\": {\n+    \"record_file\": \"d204eae8c41027b039dba4841f8ef22d\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "482ad09f4e43d36d40c64828d4402ef52de96984"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODY5OTE2MA==", "bodyText": "Move this to the description on ln 2 so it's clear. Suggestion made above", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468699160", "createdAt": "2020-08-11T16:11:56Z", "author": {"login": "Nana-EC"}, "path": "hedera-mirror-rest/__tests__/specs/stateproof-01-success-result.spec.json", "diffHunk": "@@ -0,0 +1,25 @@\n+{\n+  \"description\": \"Stateproof api calls with valid transaction ID and success response\",\n+  \"setup\": {\n+    \"sqlscripts\": [\n+      \"data/db/stateproof/address_book.sql\",\n+      \"data/db/stateproof/address_book_entry.sql\",\n+      \"data/db/stateproof/record_file.sql\",\n+      \"data/db/stateproof/transaction.sql\"\n+    ]\n+  },\n+  \"url\": \"/api/v1/transactions/0.0.94139-1570800748-313194300/stateproof\",\n+  \"responseStatus\": 200,\n+  \"responseJson\": {\n+    \"record_file\": \"d204eae8c41027b039dba4841f8ef22d\",", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk0MjkzMw=="}, "originalCommit": {"oid": "482ad09f4e43d36d40c64828d4402ef52de96984"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg2MzAxNA==", "bodyText": "added extendedDescription for some stateproof test spec files to clarify the design and the expected output", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468863014", "createdAt": "2020-08-11T21:02:17Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-rest/__tests__/specs/stateproof-01-success-result.spec.json", "diffHunk": "@@ -0,0 +1,25 @@\n+{\n+  \"description\": \"Stateproof api calls with valid transaction ID and success response\",\n+  \"setup\": {\n+    \"sqlscripts\": [\n+      \"data/db/stateproof/address_book.sql\",\n+      \"data/db/stateproof/address_book_entry.sql\",\n+      \"data/db/stateproof/record_file.sql\",\n+      \"data/db/stateproof/transaction.sql\"\n+    ]\n+  },\n+  \"url\": \"/api/v1/transactions/0.0.94139-1570800748-313194300/stateproof\",\n+  \"responseStatus\": 200,\n+  \"responseJson\": {\n+    \"record_file\": \"d204eae8c41027b039dba4841f8ef22d\",", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTk0MjkzMw=="}, "originalCommit": {"oid": "482ad09f4e43d36d40c64828d4402ef52de96984"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMDYwNjI1OnYy", "diffSide": "RIGHT", "path": "docs/configuration.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQyMTowNTozMVrOG8altQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQyMzowMzo1MFrOG-iqCQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjAwMzM4MQ==", "bodyText": "\"Weather\" should be \"whether\" here.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r466003381", "createdAt": "2020-08-05T21:05:31Z", "author": {"login": "ijungmann"}, "path": "docs/configuration.md", "diffHunk": "@@ -149,21 +149,31 @@ merged into) the current configuration:\n The following table lists the available properties along with their default values. Unless you need to set a non-default\n value, it is recommended to only populate overridden properties in the custom `application.yml`.\n \n-| Name                                                 | Default                 | Description                                                                                    |\n-| ---------------------------------------------------- | ----------------------- | ---------------------------------------------------------------------------------------------- |\n-| `hedera.mirror.rest.db.host`                         | 127.0.0.1               | The IP or hostname used to connect to the database                                             |\n-| `hedera.mirror.rest.db.name`                         | mirror_node             | The name of the database                                                                       |\n-| `hedera.mirror.rest.db.password`                     | mirror_api_pass         | The database password the processor uses to connect. **Should be changed from default**        |\n-| `hedera.mirror.rest.db.port`                         | 5432                    | The port used to connect to the database                                                       |\n-| `hedera.mirror.rest.db.username`                     | mirror_api              | The username the processor uses to connect to the database                                     |\n-| `hedera.mirror.rest.includeHostInLink`               | false                   | Whether to include the hostname and port in the next link in the response                      |\n-| `hedera.mirror.rest.maxLimit`                        | 1000                    | The maximum size the limit parameter can be that controls the REST API response size           |\n-| `hedera.mirror.rest.log.level`                       | debug                   | The logging level. Can be trace, debug, info, warn, error or fatal.                            |\n-| `hedera.mirror.rest.port`                            | 5551                    | The REST API port                                                                              |\n-| `hedera.mirror.rest.includeHostInLink`               | false                   | Whether to include the host:port in the next links returned by the REST API                    |\n-| `hedera.mirror.rest.metrics.enabled`                 | true                    | Whether metrics are enabled for the REST API                                                   |\n-| `hedera.mirror.rest.metrics.config.authentication`   | true                    | Whether access to metrics for the REST API is authenticated                                    |\n-| `hedera.mirror.rest.metrics.config.username`         | mirror_api_metrics      | The REST API metrics username to access the dashboard                                          |\n-| `hedera.mirror.rest.metrics.config.password`         | mirror_api_metrics_pass | The REST API metrics password to access the dashboard                                          |\n-| `hedera.mirror.rest.metrics.config.uriPath`          | '/swagger'              | The REST API metrics uri path                                                                  |\n-| `hedera.mirror.rest.shard`                           | 0                       | The default shard number that this mirror node participates in                                 |\n+| Name                                                     | Default                 | Description                                                                                    |\n+| -------------------------------------------------------- | ----------------------- | ---------------------------------------------------------------------------------------------- |\n+| `hedera.mirror.rest.db.host`                             | 127.0.0.1               | The IP or hostname used to connect to the database                                             |\n+| `hedera.mirror.rest.db.name`                             | mirror_node             | The name of the database                                                                       |\n+| `hedera.mirror.rest.db.password`                         | mirror_api_pass         | The database password the processor uses to connect. **Should be changed from default**        |\n+| `hedera.mirror.rest.db.port`                             | 5432                    | The port used to connect to the database                                                       |\n+| `hedera.mirror.rest.db.username`                         | mirror_api              | The username the processor uses to connect to the database                                     |\n+| `hedera.mirror.rest.includeHostInLink`                   | false                   | Whether to include the hostname and port in the next link in the response                      |\n+| `hedera.mirror.rest.maxLimit`                            | 1000                    | The maximum size the limit parameter can be that controls the REST API response size           |\n+| `hedera.mirror.rest.log.level`                           | debug                   | The logging level. Can be trace, debug, info, warn, error or fatal.                            |\n+| `hedera.mirror.rest.port`                                | 5551                    | The REST API port                                                                              |\n+| `hedera.mirror.rest.includeHostInLink`                   | false                   | Whether to include the host:port in the next links returned by the REST API                    |\n+| `hedera.mirror.rest.metrics.enabled`                     | true                    | Whether metrics are enabled for the REST API                                                   |\n+| `hedera.mirror.rest.metrics.config.authentication`       | true                    | Whether access to metrics for the REST API is authenticated                                    |\n+| `hedera.mirror.rest.metrics.config.username`             | mirror_api_metrics      | The REST API metrics username to access the dashboard                                          |\n+| `hedera.mirror.rest.metrics.config.password`             | mirror_api_metrics_pass | The REST API metrics password to access the dashboard                                          |\n+| `hedera.mirror.rest.metrics.config.uriPath`              | '/swagger'              | The REST API metrics uri path                                                                  |\n+| `hedera.mirror.rest.shard`                               | 0                       | The default shard number that this mirror node participates in                                 |\n+| `hedera.mirror.rest.stateproof.enabled`                  | false                   | Weather to enable stateproof REST API or not                                                   |", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "482ad09f4e43d36d40c64828d4402ef52de96984"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODIzMjcxMw==", "bodyText": "corrected", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468232713", "createdAt": "2020-08-10T23:03:50Z", "author": {"login": "xin-hedera"}, "path": "docs/configuration.md", "diffHunk": "@@ -149,21 +149,31 @@ merged into) the current configuration:\n The following table lists the available properties along with their default values. Unless you need to set a non-default\n value, it is recommended to only populate overridden properties in the custom `application.yml`.\n \n-| Name                                                 | Default                 | Description                                                                                    |\n-| ---------------------------------------------------- | ----------------------- | ---------------------------------------------------------------------------------------------- |\n-| `hedera.mirror.rest.db.host`                         | 127.0.0.1               | The IP or hostname used to connect to the database                                             |\n-| `hedera.mirror.rest.db.name`                         | mirror_node             | The name of the database                                                                       |\n-| `hedera.mirror.rest.db.password`                     | mirror_api_pass         | The database password the processor uses to connect. **Should be changed from default**        |\n-| `hedera.mirror.rest.db.port`                         | 5432                    | The port used to connect to the database                                                       |\n-| `hedera.mirror.rest.db.username`                     | mirror_api              | The username the processor uses to connect to the database                                     |\n-| `hedera.mirror.rest.includeHostInLink`               | false                   | Whether to include the hostname and port in the next link in the response                      |\n-| `hedera.mirror.rest.maxLimit`                        | 1000                    | The maximum size the limit parameter can be that controls the REST API response size           |\n-| `hedera.mirror.rest.log.level`                       | debug                   | The logging level. Can be trace, debug, info, warn, error or fatal.                            |\n-| `hedera.mirror.rest.port`                            | 5551                    | The REST API port                                                                              |\n-| `hedera.mirror.rest.includeHostInLink`               | false                   | Whether to include the host:port in the next links returned by the REST API                    |\n-| `hedera.mirror.rest.metrics.enabled`                 | true                    | Whether metrics are enabled for the REST API                                                   |\n-| `hedera.mirror.rest.metrics.config.authentication`   | true                    | Whether access to metrics for the REST API is authenticated                                    |\n-| `hedera.mirror.rest.metrics.config.username`         | mirror_api_metrics      | The REST API metrics username to access the dashboard                                          |\n-| `hedera.mirror.rest.metrics.config.password`         | mirror_api_metrics_pass | The REST API metrics password to access the dashboard                                          |\n-| `hedera.mirror.rest.metrics.config.uriPath`          | '/swagger'              | The REST API metrics uri path                                                                  |\n-| `hedera.mirror.rest.shard`                           | 0                       | The default shard number that this mirror node participates in                                 |\n+| Name                                                     | Default                 | Description                                                                                    |\n+| -------------------------------------------------------- | ----------------------- | ---------------------------------------------------------------------------------------------- |\n+| `hedera.mirror.rest.db.host`                             | 127.0.0.1               | The IP or hostname used to connect to the database                                             |\n+| `hedera.mirror.rest.db.name`                             | mirror_node             | The name of the database                                                                       |\n+| `hedera.mirror.rest.db.password`                         | mirror_api_pass         | The database password the processor uses to connect. **Should be changed from default**        |\n+| `hedera.mirror.rest.db.port`                             | 5432                    | The port used to connect to the database                                                       |\n+| `hedera.mirror.rest.db.username`                         | mirror_api              | The username the processor uses to connect to the database                                     |\n+| `hedera.mirror.rest.includeHostInLink`                   | false                   | Whether to include the hostname and port in the next link in the response                      |\n+| `hedera.mirror.rest.maxLimit`                            | 1000                    | The maximum size the limit parameter can be that controls the REST API response size           |\n+| `hedera.mirror.rest.log.level`                           | debug                   | The logging level. Can be trace, debug, info, warn, error or fatal.                            |\n+| `hedera.mirror.rest.port`                                | 5551                    | The REST API port                                                                              |\n+| `hedera.mirror.rest.includeHostInLink`                   | false                   | Whether to include the host:port in the next links returned by the REST API                    |\n+| `hedera.mirror.rest.metrics.enabled`                     | true                    | Whether metrics are enabled for the REST API                                                   |\n+| `hedera.mirror.rest.metrics.config.authentication`       | true                    | Whether access to metrics for the REST API is authenticated                                    |\n+| `hedera.mirror.rest.metrics.config.username`             | mirror_api_metrics      | The REST API metrics username to access the dashboard                                          |\n+| `hedera.mirror.rest.metrics.config.password`             | mirror_api_metrics_pass | The REST API metrics password to access the dashboard                                          |\n+| `hedera.mirror.rest.metrics.config.uriPath`              | '/swagger'              | The REST API metrics uri path                                                                  |\n+| `hedera.mirror.rest.shard`                               | 0                       | The default shard number that this mirror node participates in                                 |\n+| `hedera.mirror.rest.stateproof.enabled`                  | false                   | Weather to enable stateproof REST API or not                                                   |", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjAwMzM4MQ=="}, "originalCommit": {"oid": "482ad09f4e43d36d40c64828d4402ef52de96984"}, "originalPosition": 40}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMzE5ODM2OnYy", "diffSide": "RIGHT", "path": "docs/configuration.md", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQxMzoxODozMlrOG8zGpg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQyMzowNDowMlrOG-iqSA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQwNTAzMA==", "bodyText": "nit: The cloud storage secret key", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r466405030", "createdAt": "2020-08-06T13:18:32Z", "author": {"login": "Nana-EC"}, "path": "docs/configuration.md", "diffHunk": "@@ -149,21 +149,31 @@ merged into) the current configuration:\n The following table lists the available properties along with their default values. Unless you need to set a non-default\n value, it is recommended to only populate overridden properties in the custom `application.yml`.\n \n-| Name                                                 | Default                 | Description                                                                                    |\n-| ---------------------------------------------------- | ----------------------- | ---------------------------------------------------------------------------------------------- |\n-| `hedera.mirror.rest.db.host`                         | 127.0.0.1               | The IP or hostname used to connect to the database                                             |\n-| `hedera.mirror.rest.db.name`                         | mirror_node             | The name of the database                                                                       |\n-| `hedera.mirror.rest.db.password`                     | mirror_api_pass         | The database password the processor uses to connect. **Should be changed from default**        |\n-| `hedera.mirror.rest.db.port`                         | 5432                    | The port used to connect to the database                                                       |\n-| `hedera.mirror.rest.db.username`                     | mirror_api              | The username the processor uses to connect to the database                                     |\n-| `hedera.mirror.rest.includeHostInLink`               | false                   | Whether to include the hostname and port in the next link in the response                      |\n-| `hedera.mirror.rest.maxLimit`                        | 1000                    | The maximum size the limit parameter can be that controls the REST API response size           |\n-| `hedera.mirror.rest.log.level`                       | debug                   | The logging level. Can be trace, debug, info, warn, error or fatal.                            |\n-| `hedera.mirror.rest.port`                            | 5551                    | The REST API port                                                                              |\n-| `hedera.mirror.rest.includeHostInLink`               | false                   | Whether to include the host:port in the next links returned by the REST API                    |\n-| `hedera.mirror.rest.metrics.enabled`                 | true                    | Whether metrics are enabled for the REST API                                                   |\n-| `hedera.mirror.rest.metrics.config.authentication`   | true                    | Whether access to metrics for the REST API is authenticated                                    |\n-| `hedera.mirror.rest.metrics.config.username`         | mirror_api_metrics      | The REST API metrics username to access the dashboard                                          |\n-| `hedera.mirror.rest.metrics.config.password`         | mirror_api_metrics_pass | The REST API metrics password to access the dashboard                                          |\n-| `hedera.mirror.rest.metrics.config.uriPath`          | '/swagger'              | The REST API metrics uri path                                                                  |\n-| `hedera.mirror.rest.shard`                           | 0                       | The default shard number that this mirror node participates in                                 |\n+| Name                                                     | Default                 | Description                                                                                    |\n+| -------------------------------------------------------- | ----------------------- | ---------------------------------------------------------------------------------------------- |\n+| `hedera.mirror.rest.db.host`                             | 127.0.0.1               | The IP or hostname used to connect to the database                                             |\n+| `hedera.mirror.rest.db.name`                             | mirror_node             | The name of the database                                                                       |\n+| `hedera.mirror.rest.db.password`                         | mirror_api_pass         | The database password the processor uses to connect. **Should be changed from default**        |\n+| `hedera.mirror.rest.db.port`                             | 5432                    | The port used to connect to the database                                                       |\n+| `hedera.mirror.rest.db.username`                         | mirror_api              | The username the processor uses to connect to the database                                     |\n+| `hedera.mirror.rest.includeHostInLink`                   | false                   | Whether to include the hostname and port in the next link in the response                      |\n+| `hedera.mirror.rest.maxLimit`                            | 1000                    | The maximum size the limit parameter can be that controls the REST API response size           |\n+| `hedera.mirror.rest.log.level`                           | debug                   | The logging level. Can be trace, debug, info, warn, error or fatal.                            |\n+| `hedera.mirror.rest.port`                                | 5551                    | The REST API port                                                                              |\n+| `hedera.mirror.rest.includeHostInLink`                   | false                   | Whether to include the host:port in the next links returned by the REST API                    |\n+| `hedera.mirror.rest.metrics.enabled`                     | true                    | Whether metrics are enabled for the REST API                                                   |\n+| `hedera.mirror.rest.metrics.config.authentication`       | true                    | Whether access to metrics for the REST API is authenticated                                    |\n+| `hedera.mirror.rest.metrics.config.username`             | mirror_api_metrics      | The REST API metrics username to access the dashboard                                          |\n+| `hedera.mirror.rest.metrics.config.password`             | mirror_api_metrics_pass | The REST API metrics password to access the dashboard                                          |\n+| `hedera.mirror.rest.metrics.config.uriPath`              | '/swagger'              | The REST API metrics uri path                                                                  |\n+| `hedera.mirror.rest.shard`                               | 0                       | The default shard number that this mirror node participates in                                 |\n+| `hedera.mirror.rest.stateproof.enabled`                  | false                   | Weather to enable stateproof REST API or not                                                   |\n+| `hedera.mirror.rest.stateproof.streams.network`          | DEMO                    | Which Hedera network to use. Can be either `DEMO`, `MAINNET`, `TESTNET` or `OTHER`             |\n+| `hedera.mirror.rest.stateproof.streams.cloudProvider`    | S3                      | The cloud provider to download files from. Either `S3` or `GCP`                                |\n+| `hedera.mirror.rest.stateproof.streams.endpointOverride` |                         | Can be specified to download streams from a source other than S3 and GCP. Should be S3 compatible |\n+| `hedera.mirror.rest.stateproof.streams.gcpProjectId` |                             | GCP project id to bill for requests to GCS bucket which has Requester Pays enabled.            |\n+| `hedera.mirror.rest.stateproof.streams.region`           | us-east-1               | The region associated with the bucket                                                          |\n+| `hedera.mirror.rest.stateproof.streams.accessKey`        | \"\"                      | The cloud storage access key                                                                   |\n+| `hedera.mirror.rest.stateproof.streams.secretKey`        | \"\"                      | The cloud storage access key                                                                   |", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "482ad09f4e43d36d40c64828d4402ef52de96984"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjcwMzE5OQ==", "bodyText": "good catch. will fix it!", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r466703199", "createdAt": "2020-08-06T21:45:17Z", "author": {"login": "xin-hedera"}, "path": "docs/configuration.md", "diffHunk": "@@ -149,21 +149,31 @@ merged into) the current configuration:\n The following table lists the available properties along with their default values. Unless you need to set a non-default\n value, it is recommended to only populate overridden properties in the custom `application.yml`.\n \n-| Name                                                 | Default                 | Description                                                                                    |\n-| ---------------------------------------------------- | ----------------------- | ---------------------------------------------------------------------------------------------- |\n-| `hedera.mirror.rest.db.host`                         | 127.0.0.1               | The IP or hostname used to connect to the database                                             |\n-| `hedera.mirror.rest.db.name`                         | mirror_node             | The name of the database                                                                       |\n-| `hedera.mirror.rest.db.password`                     | mirror_api_pass         | The database password the processor uses to connect. **Should be changed from default**        |\n-| `hedera.mirror.rest.db.port`                         | 5432                    | The port used to connect to the database                                                       |\n-| `hedera.mirror.rest.db.username`                     | mirror_api              | The username the processor uses to connect to the database                                     |\n-| `hedera.mirror.rest.includeHostInLink`               | false                   | Whether to include the hostname and port in the next link in the response                      |\n-| `hedera.mirror.rest.maxLimit`                        | 1000                    | The maximum size the limit parameter can be that controls the REST API response size           |\n-| `hedera.mirror.rest.log.level`                       | debug                   | The logging level. Can be trace, debug, info, warn, error or fatal.                            |\n-| `hedera.mirror.rest.port`                            | 5551                    | The REST API port                                                                              |\n-| `hedera.mirror.rest.includeHostInLink`               | false                   | Whether to include the host:port in the next links returned by the REST API                    |\n-| `hedera.mirror.rest.metrics.enabled`                 | true                    | Whether metrics are enabled for the REST API                                                   |\n-| `hedera.mirror.rest.metrics.config.authentication`   | true                    | Whether access to metrics for the REST API is authenticated                                    |\n-| `hedera.mirror.rest.metrics.config.username`         | mirror_api_metrics      | The REST API metrics username to access the dashboard                                          |\n-| `hedera.mirror.rest.metrics.config.password`         | mirror_api_metrics_pass | The REST API metrics password to access the dashboard                                          |\n-| `hedera.mirror.rest.metrics.config.uriPath`          | '/swagger'              | The REST API metrics uri path                                                                  |\n-| `hedera.mirror.rest.shard`                           | 0                       | The default shard number that this mirror node participates in                                 |\n+| Name                                                     | Default                 | Description                                                                                    |\n+| -------------------------------------------------------- | ----------------------- | ---------------------------------------------------------------------------------------------- |\n+| `hedera.mirror.rest.db.host`                             | 127.0.0.1               | The IP or hostname used to connect to the database                                             |\n+| `hedera.mirror.rest.db.name`                             | mirror_node             | The name of the database                                                                       |\n+| `hedera.mirror.rest.db.password`                         | mirror_api_pass         | The database password the processor uses to connect. **Should be changed from default**        |\n+| `hedera.mirror.rest.db.port`                             | 5432                    | The port used to connect to the database                                                       |\n+| `hedera.mirror.rest.db.username`                         | mirror_api              | The username the processor uses to connect to the database                                     |\n+| `hedera.mirror.rest.includeHostInLink`                   | false                   | Whether to include the hostname and port in the next link in the response                      |\n+| `hedera.mirror.rest.maxLimit`                            | 1000                    | The maximum size the limit parameter can be that controls the REST API response size           |\n+| `hedera.mirror.rest.log.level`                           | debug                   | The logging level. Can be trace, debug, info, warn, error or fatal.                            |\n+| `hedera.mirror.rest.port`                                | 5551                    | The REST API port                                                                              |\n+| `hedera.mirror.rest.includeHostInLink`                   | false                   | Whether to include the host:port in the next links returned by the REST API                    |\n+| `hedera.mirror.rest.metrics.enabled`                     | true                    | Whether metrics are enabled for the REST API                                                   |\n+| `hedera.mirror.rest.metrics.config.authentication`       | true                    | Whether access to metrics for the REST API is authenticated                                    |\n+| `hedera.mirror.rest.metrics.config.username`             | mirror_api_metrics      | The REST API metrics username to access the dashboard                                          |\n+| `hedera.mirror.rest.metrics.config.password`             | mirror_api_metrics_pass | The REST API metrics password to access the dashboard                                          |\n+| `hedera.mirror.rest.metrics.config.uriPath`              | '/swagger'              | The REST API metrics uri path                                                                  |\n+| `hedera.mirror.rest.shard`                               | 0                       | The default shard number that this mirror node participates in                                 |\n+| `hedera.mirror.rest.stateproof.enabled`                  | false                   | Weather to enable stateproof REST API or not                                                   |\n+| `hedera.mirror.rest.stateproof.streams.network`          | DEMO                    | Which Hedera network to use. Can be either `DEMO`, `MAINNET`, `TESTNET` or `OTHER`             |\n+| `hedera.mirror.rest.stateproof.streams.cloudProvider`    | S3                      | The cloud provider to download files from. Either `S3` or `GCP`                                |\n+| `hedera.mirror.rest.stateproof.streams.endpointOverride` |                         | Can be specified to download streams from a source other than S3 and GCP. Should be S3 compatible |\n+| `hedera.mirror.rest.stateproof.streams.gcpProjectId` |                             | GCP project id to bill for requests to GCS bucket which has Requester Pays enabled.            |\n+| `hedera.mirror.rest.stateproof.streams.region`           | us-east-1               | The region associated with the bucket                                                          |\n+| `hedera.mirror.rest.stateproof.streams.accessKey`        | \"\"                      | The cloud storage access key                                                                   |\n+| `hedera.mirror.rest.stateproof.streams.secretKey`        | \"\"                      | The cloud storage access key                                                                   |", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQwNTAzMA=="}, "originalCommit": {"oid": "482ad09f4e43d36d40c64828d4402ef52de96984"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODIzMjc3Ng==", "bodyText": "corrected.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468232776", "createdAt": "2020-08-10T23:04:02Z", "author": {"login": "xin-hedera"}, "path": "docs/configuration.md", "diffHunk": "@@ -149,21 +149,31 @@ merged into) the current configuration:\n The following table lists the available properties along with their default values. Unless you need to set a non-default\n value, it is recommended to only populate overridden properties in the custom `application.yml`.\n \n-| Name                                                 | Default                 | Description                                                                                    |\n-| ---------------------------------------------------- | ----------------------- | ---------------------------------------------------------------------------------------------- |\n-| `hedera.mirror.rest.db.host`                         | 127.0.0.1               | The IP or hostname used to connect to the database                                             |\n-| `hedera.mirror.rest.db.name`                         | mirror_node             | The name of the database                                                                       |\n-| `hedera.mirror.rest.db.password`                     | mirror_api_pass         | The database password the processor uses to connect. **Should be changed from default**        |\n-| `hedera.mirror.rest.db.port`                         | 5432                    | The port used to connect to the database                                                       |\n-| `hedera.mirror.rest.db.username`                     | mirror_api              | The username the processor uses to connect to the database                                     |\n-| `hedera.mirror.rest.includeHostInLink`               | false                   | Whether to include the hostname and port in the next link in the response                      |\n-| `hedera.mirror.rest.maxLimit`                        | 1000                    | The maximum size the limit parameter can be that controls the REST API response size           |\n-| `hedera.mirror.rest.log.level`                       | debug                   | The logging level. Can be trace, debug, info, warn, error or fatal.                            |\n-| `hedera.mirror.rest.port`                            | 5551                    | The REST API port                                                                              |\n-| `hedera.mirror.rest.includeHostInLink`               | false                   | Whether to include the host:port in the next links returned by the REST API                    |\n-| `hedera.mirror.rest.metrics.enabled`                 | true                    | Whether metrics are enabled for the REST API                                                   |\n-| `hedera.mirror.rest.metrics.config.authentication`   | true                    | Whether access to metrics for the REST API is authenticated                                    |\n-| `hedera.mirror.rest.metrics.config.username`         | mirror_api_metrics      | The REST API metrics username to access the dashboard                                          |\n-| `hedera.mirror.rest.metrics.config.password`         | mirror_api_metrics_pass | The REST API metrics password to access the dashboard                                          |\n-| `hedera.mirror.rest.metrics.config.uriPath`          | '/swagger'              | The REST API metrics uri path                                                                  |\n-| `hedera.mirror.rest.shard`                           | 0                       | The default shard number that this mirror node participates in                                 |\n+| Name                                                     | Default                 | Description                                                                                    |\n+| -------------------------------------------------------- | ----------------------- | ---------------------------------------------------------------------------------------------- |\n+| `hedera.mirror.rest.db.host`                             | 127.0.0.1               | The IP or hostname used to connect to the database                                             |\n+| `hedera.mirror.rest.db.name`                             | mirror_node             | The name of the database                                                                       |\n+| `hedera.mirror.rest.db.password`                         | mirror_api_pass         | The database password the processor uses to connect. **Should be changed from default**        |\n+| `hedera.mirror.rest.db.port`                             | 5432                    | The port used to connect to the database                                                       |\n+| `hedera.mirror.rest.db.username`                         | mirror_api              | The username the processor uses to connect to the database                                     |\n+| `hedera.mirror.rest.includeHostInLink`                   | false                   | Whether to include the hostname and port in the next link in the response                      |\n+| `hedera.mirror.rest.maxLimit`                            | 1000                    | The maximum size the limit parameter can be that controls the REST API response size           |\n+| `hedera.mirror.rest.log.level`                           | debug                   | The logging level. Can be trace, debug, info, warn, error or fatal.                            |\n+| `hedera.mirror.rest.port`                                | 5551                    | The REST API port                                                                              |\n+| `hedera.mirror.rest.includeHostInLink`                   | false                   | Whether to include the host:port in the next links returned by the REST API                    |\n+| `hedera.mirror.rest.metrics.enabled`                     | true                    | Whether metrics are enabled for the REST API                                                   |\n+| `hedera.mirror.rest.metrics.config.authentication`       | true                    | Whether access to metrics for the REST API is authenticated                                    |\n+| `hedera.mirror.rest.metrics.config.username`             | mirror_api_metrics      | The REST API metrics username to access the dashboard                                          |\n+| `hedera.mirror.rest.metrics.config.password`             | mirror_api_metrics_pass | The REST API metrics password to access the dashboard                                          |\n+| `hedera.mirror.rest.metrics.config.uriPath`              | '/swagger'              | The REST API metrics uri path                                                                  |\n+| `hedera.mirror.rest.shard`                               | 0                       | The default shard number that this mirror node participates in                                 |\n+| `hedera.mirror.rest.stateproof.enabled`                  | false                   | Weather to enable stateproof REST API or not                                                   |\n+| `hedera.mirror.rest.stateproof.streams.network`          | DEMO                    | Which Hedera network to use. Can be either `DEMO`, `MAINNET`, `TESTNET` or `OTHER`             |\n+| `hedera.mirror.rest.stateproof.streams.cloudProvider`    | S3                      | The cloud provider to download files from. Either `S3` or `GCP`                                |\n+| `hedera.mirror.rest.stateproof.streams.endpointOverride` |                         | Can be specified to download streams from a source other than S3 and GCP. Should be S3 compatible |\n+| `hedera.mirror.rest.stateproof.streams.gcpProjectId` |                             | GCP project id to bill for requests to GCS bucket which has Requester Pays enabled.            |\n+| `hedera.mirror.rest.stateproof.streams.region`           | us-east-1               | The region associated with the bucket                                                          |\n+| `hedera.mirror.rest.stateproof.streams.accessKey`        | \"\"                      | The cloud storage access key                                                                   |\n+| `hedera.mirror.rest.stateproof.streams.secretKey`        | \"\"                      | The cloud storage access key                                                                   |", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQwNTAzMA=="}, "originalCommit": {"oid": "482ad09f4e43d36d40c64828d4402ef52de96984"}, "originalPosition": 47}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMzIxMTAwOnYy", "diffSide": "RIGHT", "path": "docs/design/stateproofalpha.md", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQxMzoyMTozN1rOG8zObA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQyMzozMDoyNlrOG-jKcQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQwNzAyMA==", "bodyText": "might want to be explicit about the data. \"Record file containing transaction\", \"signature files\", \"history of address book up until the point\" etc", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r466407020", "createdAt": "2020-08-06T13:21:37Z", "author": {"login": "Nana-EC"}, "path": "docs/design/stateproofalpha.md", "diffHunk": "@@ -0,0 +1,61 @@\n+# State Proof Alpha Design\n+\n+## Purpose\n+\n+State Proof Alpha provides the data to prove a transaction is valid on Hedera Network. It's the interim solution\n+until [full state proof](https://www.hedera.com/blog/state-proofs-on-hedera) is implemented.\n+\n+## Goals\n+\n+- Provide a State Proof REST API for clients to retrieve data for a transaction to prove its validity", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "482ad09f4e43d36d40c64828d4402ef52de96984"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjcwMzExNA==", "bodyText": "yes, will update.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r466703114", "createdAt": "2020-08-06T21:45:04Z", "author": {"login": "xin-hedera"}, "path": "docs/design/stateproofalpha.md", "diffHunk": "@@ -0,0 +1,61 @@\n+# State Proof Alpha Design\n+\n+## Purpose\n+\n+State Proof Alpha provides the data to prove a transaction is valid on Hedera Network. It's the interim solution\n+until [full state proof](https://www.hedera.com/blog/state-proofs-on-hedera) is implemented.\n+\n+## Goals\n+\n+- Provide a State Proof REST API for clients to retrieve data for a transaction to prove its validity", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQwNzAyMA=="}, "originalCommit": {"oid": "482ad09f4e43d36d40c64828d4402ef52de96984"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODI0MTAwOQ==", "bodyText": "updated", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468241009", "createdAt": "2020-08-10T23:30:26Z", "author": {"login": "xin-hedera"}, "path": "docs/design/stateproofalpha.md", "diffHunk": "@@ -0,0 +1,61 @@\n+# State Proof Alpha Design\n+\n+## Purpose\n+\n+State Proof Alpha provides the data to prove a transaction is valid on Hedera Network. It's the interim solution\n+until [full state proof](https://www.hedera.com/blog/state-proofs-on-hedera) is implemented.\n+\n+## Goals\n+\n+- Provide a State Proof REST API for clients to retrieve data for a transaction to prove its validity", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQwNzAyMA=="}, "originalCommit": {"oid": "482ad09f4e43d36d40c64828d4402ef52de96984"}, "originalPosition": 10}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMzIxOTk0OnYy", "diffSide": "RIGHT", "path": "docs/design/stateproofalpha.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQxMzoyMzo0NFrOG8zT9A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQyMzowNToxNlrOG-ir9w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQwODQzNg==", "bodyText": "We might want to consider a key value pair here with the key as the time from which it is valid i.e. consensus_start", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r466408436", "createdAt": "2020-08-06T13:23:44Z", "author": {"login": "Nana-EC"}, "path": "docs/design/stateproofalpha.md", "diffHunk": "@@ -0,0 +1,61 @@\n+# State Proof Alpha Design\n+\n+## Purpose\n+\n+State Proof Alpha provides the data to prove a transaction is valid on Hedera Network. It's the interim solution\n+until [full state proof](https://www.hedera.com/blog/state-proofs-on-hedera) is implemented.\n+\n+## Goals\n+\n+- Provide a State Proof REST API for clients to retrieve data for a transaction to prove its validity\n+\n+\n+## REST API\n+\n+```\n+GET /transactions/:transactionId/stateproof\n+```\n+\n+where `transactionId` is in the format of `shard.realm.num-ssssssssss-nnnnnnnnn`, in which `ssss` are 10 digits seconds\n+and `nnn` are 9 digits nanoseconds of the valid start timestamp of the transaction.\n+\n+The response is in JSON:\n+\n+```json\n+{\n+    \"record_file\": \"record file content\",\n+    \"address_books\": [\n+      \"address book 1 content\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "482ad09f4e43d36d40c64828d4402ef52de96984"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODIzMzIwNw==", "bodyText": "the team discussed it offline, we feel the API meets the requirement and decided not to make the change.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468233207", "createdAt": "2020-08-10T23:05:16Z", "author": {"login": "xin-hedera"}, "path": "docs/design/stateproofalpha.md", "diffHunk": "@@ -0,0 +1,61 @@\n+# State Proof Alpha Design\n+\n+## Purpose\n+\n+State Proof Alpha provides the data to prove a transaction is valid on Hedera Network. It's the interim solution\n+until [full state proof](https://www.hedera.com/blog/state-proofs-on-hedera) is implemented.\n+\n+## Goals\n+\n+- Provide a State Proof REST API for clients to retrieve data for a transaction to prove its validity\n+\n+\n+## REST API\n+\n+```\n+GET /transactions/:transactionId/stateproof\n+```\n+\n+where `transactionId` is in the format of `shard.realm.num-ssssssssss-nnnnnnnnn`, in which `ssss` are 10 digits seconds\n+and `nnn` are 9 digits nanoseconds of the valid start timestamp of the transaction.\n+\n+The response is in JSON:\n+\n+```json\n+{\n+    \"record_file\": \"record file content\",\n+    \"address_books\": [\n+      \"address book 1 content\",", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQwODQzNg=="}, "originalCommit": {"oid": "482ad09f4e43d36d40c64828d4402ef52de96984"}, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMzM4ODE2OnYy", "diffSide": "RIGHT", "path": "hedera-mirror-rest/stateproof.js", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQxNDowMjo0NVrOG80-Jw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQyMzowNToyNlrOG-isKw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQzNTYyMw==", "bodyText": "old logic used by only accounts and balances I believe. Eventually we want to remove that.\nSkip the sqlQuery definition and go straight to pgSqlQuery as below\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              const pgSqlQuery = utils.convertMySqlStyleQueryToPostgres(sqlQuery, sqlParams);\n          \n          \n            \n              const pgSqlQuery = select consensus_ns from transaction where payer_account_id = $1 and valid_start_ns = $2 and result = 22;", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r466435623", "createdAt": "2020-08-06T14:02:45Z", "author": {"login": "Nana-EC"}, "path": "hedera-mirror-rest/stateproof.js", "diffHunk": "@@ -0,0 +1,265 @@\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ *\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+'use strict';\n+\n+const _ = require('lodash');\n+const utils = require('./utils');\n+const config = require('./config');\n+const constants = require('./constants');\n+const EntityId = require('./entityId');\n+const TransactionId = require('./transactionId');\n+const s3client = require('./s3client');\n+const { DbError } = require('./errors/dbError');\n+const { NotFoundError } = require('./errors/notFoundError');\n+const { FileDownloadError } = require('./errors/fileDownloadError');\n+\n+/**\n+ * Get the consensus_ns of the transaction. Throws exception if no such successful transaction found or multiple such\n+ * transactions found.\n+ * @param {TransactionId} transactionId\n+ * @returns {Promise<String>} consensus_ns of the successful transaction if found\n+ */\n+let getSuccessfulTransactionConsensusNs = async (transactionId) => {\n+  const sqlParams = [transactionId.getEntityId().getEncodedId(), transactionId.getValidStartNs()];\n+  const sqlQuery = `SELECT consensus_ns\n+       FROM transaction\n+       WHERE payer_account_id = ?\n+         AND valid_start_ns = ?\n+         AND result = 22`; // only the successful transaction\n+  const pgSqlQuery = utils.convertMySqlStyleQueryToPostgres(sqlQuery, sqlParams);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "482ad09f4e43d36d40c64828d4402ef52de96984"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjcwMjc3MA==", "bodyText": "thanks, will change it as suggested", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r466702770", "createdAt": "2020-08-06T21:44:18Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-rest/stateproof.js", "diffHunk": "@@ -0,0 +1,265 @@\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ *\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+'use strict';\n+\n+const _ = require('lodash');\n+const utils = require('./utils');\n+const config = require('./config');\n+const constants = require('./constants');\n+const EntityId = require('./entityId');\n+const TransactionId = require('./transactionId');\n+const s3client = require('./s3client');\n+const { DbError } = require('./errors/dbError');\n+const { NotFoundError } = require('./errors/notFoundError');\n+const { FileDownloadError } = require('./errors/fileDownloadError');\n+\n+/**\n+ * Get the consensus_ns of the transaction. Throws exception if no such successful transaction found or multiple such\n+ * transactions found.\n+ * @param {TransactionId} transactionId\n+ * @returns {Promise<String>} consensus_ns of the successful transaction if found\n+ */\n+let getSuccessfulTransactionConsensusNs = async (transactionId) => {\n+  const sqlParams = [transactionId.getEntityId().getEncodedId(), transactionId.getValidStartNs()];\n+  const sqlQuery = `SELECT consensus_ns\n+       FROM transaction\n+       WHERE payer_account_id = ?\n+         AND valid_start_ns = ?\n+         AND result = 22`; // only the successful transaction\n+  const pgSqlQuery = utils.convertMySqlStyleQueryToPostgres(sqlQuery, sqlParams);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQzNTYyMw=="}, "originalCommit": {"oid": "482ad09f4e43d36d40c64828d4402ef52de96984"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODIzMzI1OQ==", "bodyText": "updated.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468233259", "createdAt": "2020-08-10T23:05:26Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-rest/stateproof.js", "diffHunk": "@@ -0,0 +1,265 @@\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ *\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+'use strict';\n+\n+const _ = require('lodash');\n+const utils = require('./utils');\n+const config = require('./config');\n+const constants = require('./constants');\n+const EntityId = require('./entityId');\n+const TransactionId = require('./transactionId');\n+const s3client = require('./s3client');\n+const { DbError } = require('./errors/dbError');\n+const { NotFoundError } = require('./errors/notFoundError');\n+const { FileDownloadError } = require('./errors/fileDownloadError');\n+\n+/**\n+ * Get the consensus_ns of the transaction. Throws exception if no such successful transaction found or multiple such\n+ * transactions found.\n+ * @param {TransactionId} transactionId\n+ * @returns {Promise<String>} consensus_ns of the successful transaction if found\n+ */\n+let getSuccessfulTransactionConsensusNs = async (transactionId) => {\n+  const sqlParams = [transactionId.getEntityId().getEncodedId(), transactionId.getValidStartNs()];\n+  const sqlQuery = `SELECT consensus_ns\n+       FROM transaction\n+       WHERE payer_account_id = ?\n+         AND valid_start_ns = ?\n+         AND result = 22`; // only the successful transaction\n+  const pgSqlQuery = utils.convertMySqlStyleQueryToPostgres(sqlQuery, sqlParams);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQzNTYyMw=="}, "originalCommit": {"oid": "482ad09f4e43d36d40c64828d4402ef52de96984"}, "originalPosition": 47}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMzM5NzAwOnYy", "diffSide": "RIGHT", "path": "hedera-mirror-rest/stateproof.js", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQxNDowNDo0M1rOG81Ddg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQyMzowNTozOFrOG-isZQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQzNjk4Mg==", "bodyText": "Same query definition simplification comment here and below", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r466436982", "createdAt": "2020-08-06T14:04:43Z", "author": {"login": "Nana-EC"}, "path": "hedera-mirror-rest/stateproof.js", "diffHunk": "@@ -0,0 +1,265 @@\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ *\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+'use strict';\n+\n+const _ = require('lodash');\n+const utils = require('./utils');\n+const config = require('./config');\n+const constants = require('./constants');\n+const EntityId = require('./entityId');\n+const TransactionId = require('./transactionId');\n+const s3client = require('./s3client');\n+const { DbError } = require('./errors/dbError');\n+const { NotFoundError } = require('./errors/notFoundError');\n+const { FileDownloadError } = require('./errors/fileDownloadError');\n+\n+/**\n+ * Get the consensus_ns of the transaction. Throws exception if no such successful transaction found or multiple such\n+ * transactions found.\n+ * @param {TransactionId} transactionId\n+ * @returns {Promise<String>} consensus_ns of the successful transaction if found\n+ */\n+let getSuccessfulTransactionConsensusNs = async (transactionId) => {\n+  const sqlParams = [transactionId.getEntityId().getEncodedId(), transactionId.getValidStartNs()];\n+  const sqlQuery = `SELECT consensus_ns\n+       FROM transaction\n+       WHERE payer_account_id = ?\n+         AND valid_start_ns = ?\n+         AND result = 22`; // only the successful transaction\n+  const pgSqlQuery = utils.convertMySqlStyleQueryToPostgres(sqlQuery, sqlParams);\n+  if (logger.isTraceEnabled()) {\n+    logger.trace(`getSuccessfulTransactionConsensusNs: ${pgSqlQuery}, ${JSON.stringify(sqlParams)}`);\n+  }\n+\n+  let result;\n+  try {\n+    result = await pool.query(pgSqlQuery, sqlParams);\n+  } catch (err) {\n+    throw new DbError(err.message);\n+  }\n+\n+  const { rows } = result;\n+  if (_.isEmpty(rows)) {\n+    throw new NotFoundError('Transaction not found');\n+  } else if (rows.length > 1) {\n+    throw new DbError('Invalid state, more than one transactions found');\n+  }\n+\n+  return _.first(rows).consensus_ns;\n+};\n+\n+/**\n+ * Get the RCD file name where consensusNs is in the range [consensus_start, consensus_end]. Throws exception if no\n+ * such RCD file found.\n+ * @param {string} consensusNs consensus timestamp within the range of the RCD file to search\n+ * @returns {Promise<String>} RCD file name\n+ */\n+let getRCDFileNameByConsensusNs = async (consensusNs) => {\n+  const sqlParams = [consensusNs, consensusNs];\n+  const sqlQuery = `SELECT name\n+       FROM record_file\n+       WHERE consensus_start <= ?\n+         AND consensus_end >= ?`;\n+  const pgSqlQuery = utils.convertMySqlStyleQueryToPostgres(sqlQuery, sqlParams);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "482ad09f4e43d36d40c64828d4402ef52de96984"}, "originalPosition": 81}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjcwMjg0MA==", "bodyText": "sure! will change it.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r466702840", "createdAt": "2020-08-06T21:44:27Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-rest/stateproof.js", "diffHunk": "@@ -0,0 +1,265 @@\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ *\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+'use strict';\n+\n+const _ = require('lodash');\n+const utils = require('./utils');\n+const config = require('./config');\n+const constants = require('./constants');\n+const EntityId = require('./entityId');\n+const TransactionId = require('./transactionId');\n+const s3client = require('./s3client');\n+const { DbError } = require('./errors/dbError');\n+const { NotFoundError } = require('./errors/notFoundError');\n+const { FileDownloadError } = require('./errors/fileDownloadError');\n+\n+/**\n+ * Get the consensus_ns of the transaction. Throws exception if no such successful transaction found or multiple such\n+ * transactions found.\n+ * @param {TransactionId} transactionId\n+ * @returns {Promise<String>} consensus_ns of the successful transaction if found\n+ */\n+let getSuccessfulTransactionConsensusNs = async (transactionId) => {\n+  const sqlParams = [transactionId.getEntityId().getEncodedId(), transactionId.getValidStartNs()];\n+  const sqlQuery = `SELECT consensus_ns\n+       FROM transaction\n+       WHERE payer_account_id = ?\n+         AND valid_start_ns = ?\n+         AND result = 22`; // only the successful transaction\n+  const pgSqlQuery = utils.convertMySqlStyleQueryToPostgres(sqlQuery, sqlParams);\n+  if (logger.isTraceEnabled()) {\n+    logger.trace(`getSuccessfulTransactionConsensusNs: ${pgSqlQuery}, ${JSON.stringify(sqlParams)}`);\n+  }\n+\n+  let result;\n+  try {\n+    result = await pool.query(pgSqlQuery, sqlParams);\n+  } catch (err) {\n+    throw new DbError(err.message);\n+  }\n+\n+  const { rows } = result;\n+  if (_.isEmpty(rows)) {\n+    throw new NotFoundError('Transaction not found');\n+  } else if (rows.length > 1) {\n+    throw new DbError('Invalid state, more than one transactions found');\n+  }\n+\n+  return _.first(rows).consensus_ns;\n+};\n+\n+/**\n+ * Get the RCD file name where consensusNs is in the range [consensus_start, consensus_end]. Throws exception if no\n+ * such RCD file found.\n+ * @param {string} consensusNs consensus timestamp within the range of the RCD file to search\n+ * @returns {Promise<String>} RCD file name\n+ */\n+let getRCDFileNameByConsensusNs = async (consensusNs) => {\n+  const sqlParams = [consensusNs, consensusNs];\n+  const sqlQuery = `SELECT name\n+       FROM record_file\n+       WHERE consensus_start <= ?\n+         AND consensus_end >= ?`;\n+  const pgSqlQuery = utils.convertMySqlStyleQueryToPostgres(sqlQuery, sqlParams);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQzNjk4Mg=="}, "originalCommit": {"oid": "482ad09f4e43d36d40c64828d4402ef52de96984"}, "originalPosition": 81}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODIzMzMxNw==", "bodyText": "updated.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468233317", "createdAt": "2020-08-10T23:05:38Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-rest/stateproof.js", "diffHunk": "@@ -0,0 +1,265 @@\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ *\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+'use strict';\n+\n+const _ = require('lodash');\n+const utils = require('./utils');\n+const config = require('./config');\n+const constants = require('./constants');\n+const EntityId = require('./entityId');\n+const TransactionId = require('./transactionId');\n+const s3client = require('./s3client');\n+const { DbError } = require('./errors/dbError');\n+const { NotFoundError } = require('./errors/notFoundError');\n+const { FileDownloadError } = require('./errors/fileDownloadError');\n+\n+/**\n+ * Get the consensus_ns of the transaction. Throws exception if no such successful transaction found or multiple such\n+ * transactions found.\n+ * @param {TransactionId} transactionId\n+ * @returns {Promise<String>} consensus_ns of the successful transaction if found\n+ */\n+let getSuccessfulTransactionConsensusNs = async (transactionId) => {\n+  const sqlParams = [transactionId.getEntityId().getEncodedId(), transactionId.getValidStartNs()];\n+  const sqlQuery = `SELECT consensus_ns\n+       FROM transaction\n+       WHERE payer_account_id = ?\n+         AND valid_start_ns = ?\n+         AND result = 22`; // only the successful transaction\n+  const pgSqlQuery = utils.convertMySqlStyleQueryToPostgres(sqlQuery, sqlParams);\n+  if (logger.isTraceEnabled()) {\n+    logger.trace(`getSuccessfulTransactionConsensusNs: ${pgSqlQuery}, ${JSON.stringify(sqlParams)}`);\n+  }\n+\n+  let result;\n+  try {\n+    result = await pool.query(pgSqlQuery, sqlParams);\n+  } catch (err) {\n+    throw new DbError(err.message);\n+  }\n+\n+  const { rows } = result;\n+  if (_.isEmpty(rows)) {\n+    throw new NotFoundError('Transaction not found');\n+  } else if (rows.length > 1) {\n+    throw new DbError('Invalid state, more than one transactions found');\n+  }\n+\n+  return _.first(rows).consensus_ns;\n+};\n+\n+/**\n+ * Get the RCD file name where consensusNs is in the range [consensus_start, consensus_end]. Throws exception if no\n+ * such RCD file found.\n+ * @param {string} consensusNs consensus timestamp within the range of the RCD file to search\n+ * @returns {Promise<String>} RCD file name\n+ */\n+let getRCDFileNameByConsensusNs = async (consensusNs) => {\n+  const sqlParams = [consensusNs, consensusNs];\n+  const sqlQuery = `SELECT name\n+       FROM record_file\n+       WHERE consensus_start <= ?\n+         AND consensus_end >= ?`;\n+  const pgSqlQuery = utils.convertMySqlStyleQueryToPostgres(sqlQuery, sqlParams);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQzNjk4Mg=="}, "originalCommit": {"oid": "482ad09f4e43d36d40c64828d4402ef52de96984"}, "originalPosition": 81}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMzQwNTQ0OnYy", "diffSide": "RIGHT", "path": "hedera-mirror-rest/stateproof.js", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQxNDowNjo0MFrOG81ItQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQyMzowNjowOVrOG-is-w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQzODMyNQ==", "bodyText": "nit: files can be singular\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                throw new DbError('Invalid state, more than one RCD files found');\n          \n          \n            \n                throw new DbError('Invalid state, more than one RCD file found');", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r466438325", "createdAt": "2020-08-06T14:06:40Z", "author": {"login": "Nana-EC"}, "path": "hedera-mirror-rest/stateproof.js", "diffHunk": "@@ -0,0 +1,265 @@\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ *\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+'use strict';\n+\n+const _ = require('lodash');\n+const utils = require('./utils');\n+const config = require('./config');\n+const constants = require('./constants');\n+const EntityId = require('./entityId');\n+const TransactionId = require('./transactionId');\n+const s3client = require('./s3client');\n+const { DbError } = require('./errors/dbError');\n+const { NotFoundError } = require('./errors/notFoundError');\n+const { FileDownloadError } = require('./errors/fileDownloadError');\n+\n+/**\n+ * Get the consensus_ns of the transaction. Throws exception if no such successful transaction found or multiple such\n+ * transactions found.\n+ * @param {TransactionId} transactionId\n+ * @returns {Promise<String>} consensus_ns of the successful transaction if found\n+ */\n+let getSuccessfulTransactionConsensusNs = async (transactionId) => {\n+  const sqlParams = [transactionId.getEntityId().getEncodedId(), transactionId.getValidStartNs()];\n+  const sqlQuery = `SELECT consensus_ns\n+       FROM transaction\n+       WHERE payer_account_id = ?\n+         AND valid_start_ns = ?\n+         AND result = 22`; // only the successful transaction\n+  const pgSqlQuery = utils.convertMySqlStyleQueryToPostgres(sqlQuery, sqlParams);\n+  if (logger.isTraceEnabled()) {\n+    logger.trace(`getSuccessfulTransactionConsensusNs: ${pgSqlQuery}, ${JSON.stringify(sqlParams)}`);\n+  }\n+\n+  let result;\n+  try {\n+    result = await pool.query(pgSqlQuery, sqlParams);\n+  } catch (err) {\n+    throw new DbError(err.message);\n+  }\n+\n+  const { rows } = result;\n+  if (_.isEmpty(rows)) {\n+    throw new NotFoundError('Transaction not found');\n+  } else if (rows.length > 1) {\n+    throw new DbError('Invalid state, more than one transactions found');\n+  }\n+\n+  return _.first(rows).consensus_ns;\n+};\n+\n+/**\n+ * Get the RCD file name where consensusNs is in the range [consensus_start, consensus_end]. Throws exception if no\n+ * such RCD file found.\n+ * @param {string} consensusNs consensus timestamp within the range of the RCD file to search\n+ * @returns {Promise<String>} RCD file name\n+ */\n+let getRCDFileNameByConsensusNs = async (consensusNs) => {\n+  const sqlParams = [consensusNs, consensusNs];\n+  const sqlQuery = `SELECT name\n+       FROM record_file\n+       WHERE consensus_start <= ?\n+         AND consensus_end >= ?`;\n+  const pgSqlQuery = utils.convertMySqlStyleQueryToPostgres(sqlQuery, sqlParams);\n+  if (logger.isTraceEnabled()) {\n+    logger.trace(`getRCDFileNameByConsensusNs: ${pgSqlQuery}, ${JSON.stringify(sqlParams)}`);\n+  }\n+\n+  let result;\n+  try {\n+    result = await pool.query(pgSqlQuery, sqlParams);\n+  } catch (err) {\n+    throw new DbError(err.message);\n+  }\n+\n+  const { rows } = result;\n+  if (_.isEmpty(rows)) {\n+    throw new NotFoundError('No matching RCD file found');\n+  } else if (rows.length > 1) {\n+    throw new DbError('Invalid state, more than one RCD files found');", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "482ad09f4e43d36d40c64828d4402ef52de96984"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODIzMzQ2Nw==", "bodyText": "updated.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468233467", "createdAt": "2020-08-10T23:06:09Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-rest/stateproof.js", "diffHunk": "@@ -0,0 +1,265 @@\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ *\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+'use strict';\n+\n+const _ = require('lodash');\n+const utils = require('./utils');\n+const config = require('./config');\n+const constants = require('./constants');\n+const EntityId = require('./entityId');\n+const TransactionId = require('./transactionId');\n+const s3client = require('./s3client');\n+const { DbError } = require('./errors/dbError');\n+const { NotFoundError } = require('./errors/notFoundError');\n+const { FileDownloadError } = require('./errors/fileDownloadError');\n+\n+/**\n+ * Get the consensus_ns of the transaction. Throws exception if no such successful transaction found or multiple such\n+ * transactions found.\n+ * @param {TransactionId} transactionId\n+ * @returns {Promise<String>} consensus_ns of the successful transaction if found\n+ */\n+let getSuccessfulTransactionConsensusNs = async (transactionId) => {\n+  const sqlParams = [transactionId.getEntityId().getEncodedId(), transactionId.getValidStartNs()];\n+  const sqlQuery = `SELECT consensus_ns\n+       FROM transaction\n+       WHERE payer_account_id = ?\n+         AND valid_start_ns = ?\n+         AND result = 22`; // only the successful transaction\n+  const pgSqlQuery = utils.convertMySqlStyleQueryToPostgres(sqlQuery, sqlParams);\n+  if (logger.isTraceEnabled()) {\n+    logger.trace(`getSuccessfulTransactionConsensusNs: ${pgSqlQuery}, ${JSON.stringify(sqlParams)}`);\n+  }\n+\n+  let result;\n+  try {\n+    result = await pool.query(pgSqlQuery, sqlParams);\n+  } catch (err) {\n+    throw new DbError(err.message);\n+  }\n+\n+  const { rows } = result;\n+  if (_.isEmpty(rows)) {\n+    throw new NotFoundError('Transaction not found');\n+  } else if (rows.length > 1) {\n+    throw new DbError('Invalid state, more than one transactions found');\n+  }\n+\n+  return _.first(rows).consensus_ns;\n+};\n+\n+/**\n+ * Get the RCD file name where consensusNs is in the range [consensus_start, consensus_end]. Throws exception if no\n+ * such RCD file found.\n+ * @param {string} consensusNs consensus timestamp within the range of the RCD file to search\n+ * @returns {Promise<String>} RCD file name\n+ */\n+let getRCDFileNameByConsensusNs = async (consensusNs) => {\n+  const sqlParams = [consensusNs, consensusNs];\n+  const sqlQuery = `SELECT name\n+       FROM record_file\n+       WHERE consensus_start <= ?\n+         AND consensus_end >= ?`;\n+  const pgSqlQuery = utils.convertMySqlStyleQueryToPostgres(sqlQuery, sqlParams);\n+  if (logger.isTraceEnabled()) {\n+    logger.trace(`getRCDFileNameByConsensusNs: ${pgSqlQuery}, ${JSON.stringify(sqlParams)}`);\n+  }\n+\n+  let result;\n+  try {\n+    result = await pool.query(pgSqlQuery, sqlParams);\n+  } catch (err) {\n+    throw new DbError(err.message);\n+  }\n+\n+  const { rows } = result;\n+  if (_.isEmpty(rows)) {\n+    throw new NotFoundError('No matching RCD file found');\n+  } else if (rows.length > 1) {\n+    throw new DbError('Invalid state, more than one RCD files found');", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQzODMyNQ=="}, "originalCommit": {"oid": "482ad09f4e43d36d40c64828d4402ef52de96984"}, "originalPosition": 97}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMzU4NDc1OnYy", "diffSide": "RIGHT", "path": "hedera-mirror-rest/stateproof.js", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQxNDo0NjoxN1rOG823Dw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QxMzo1OToxNFrOG9a_aA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQ2NjU3NQ==", "bodyText": "q: do we care about latency right now? There might be potential to have these 3 calls (address book, record and sig files) run and parse in parallel. Especially since some record file might be larger than others.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r466466575", "createdAt": "2020-08-06T14:46:17Z", "author": {"login": "Nana-EC"}, "path": "hedera-mirror-rest/stateproof.js", "diffHunk": "@@ -0,0 +1,265 @@\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ *\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+'use strict';\n+\n+const _ = require('lodash');\n+const utils = require('./utils');\n+const config = require('./config');\n+const constants = require('./constants');\n+const EntityId = require('./entityId');\n+const TransactionId = require('./transactionId');\n+const s3client = require('./s3client');\n+const { DbError } = require('./errors/dbError');\n+const { NotFoundError } = require('./errors/notFoundError');\n+const { FileDownloadError } = require('./errors/fileDownloadError');\n+\n+/**\n+ * Get the consensus_ns of the transaction. Throws exception if no such successful transaction found or multiple such\n+ * transactions found.\n+ * @param {TransactionId} transactionId\n+ * @returns {Promise<String>} consensus_ns of the successful transaction if found\n+ */\n+let getSuccessfulTransactionConsensusNs = async (transactionId) => {\n+  const sqlParams = [transactionId.getEntityId().getEncodedId(), transactionId.getValidStartNs()];\n+  const sqlQuery = `SELECT consensus_ns\n+       FROM transaction\n+       WHERE payer_account_id = ?\n+         AND valid_start_ns = ?\n+         AND result = 22`; // only the successful transaction\n+  const pgSqlQuery = utils.convertMySqlStyleQueryToPostgres(sqlQuery, sqlParams);\n+  if (logger.isTraceEnabled()) {\n+    logger.trace(`getSuccessfulTransactionConsensusNs: ${pgSqlQuery}, ${JSON.stringify(sqlParams)}`);\n+  }\n+\n+  let result;\n+  try {\n+    result = await pool.query(pgSqlQuery, sqlParams);\n+  } catch (err) {\n+    throw new DbError(err.message);\n+  }\n+\n+  const { rows } = result;\n+  if (_.isEmpty(rows)) {\n+    throw new NotFoundError('Transaction not found');\n+  } else if (rows.length > 1) {\n+    throw new DbError('Invalid state, more than one transactions found');\n+  }\n+\n+  return _.first(rows).consensus_ns;\n+};\n+\n+/**\n+ * Get the RCD file name where consensusNs is in the range [consensus_start, consensus_end]. Throws exception if no\n+ * such RCD file found.\n+ * @param {string} consensusNs consensus timestamp within the range of the RCD file to search\n+ * @returns {Promise<String>} RCD file name\n+ */\n+let getRCDFileNameByConsensusNs = async (consensusNs) => {\n+  const sqlParams = [consensusNs, consensusNs];\n+  const sqlQuery = `SELECT name\n+       FROM record_file\n+       WHERE consensus_start <= ?\n+         AND consensus_end >= ?`;\n+  const pgSqlQuery = utils.convertMySqlStyleQueryToPostgres(sqlQuery, sqlParams);\n+  if (logger.isTraceEnabled()) {\n+    logger.trace(`getRCDFileNameByConsensusNs: ${pgSqlQuery}, ${JSON.stringify(sqlParams)}`);\n+  }\n+\n+  let result;\n+  try {\n+    result = await pool.query(pgSqlQuery, sqlParams);\n+  } catch (err) {\n+    throw new DbError(err.message);\n+  }\n+\n+  const { rows } = result;\n+  if (_.isEmpty(rows)) {\n+    throw new NotFoundError('No matching RCD file found');\n+  } else if (rows.length > 1) {\n+    throw new DbError('Invalid state, more than one RCD files found');\n+  }\n+\n+  return _.first(rows).name;\n+};\n+\n+/**\n+ * Get the chain of address books and node account IDs at or before consensusNs.\n+ * @param {String} consensusNs\n+ * @returns {Promise<Object>} List of base64 address book data in chronological order and list of node account IDs.\n+ */\n+let getAddressBooksAndNodeAccountIdsByConsensusNs = async (consensusNs) => {\n+  // Get the chain of address books whose consensus_timestamp <= consensusNs, also aggregate the corresponding\n+  // node account ids from table address_book_entry\n+  const sqlParams = [consensusNs];\n+  const sqlQuery = `SELECT\n+         file_data,\n+         node_count,\n+         string_agg(memo, ',') AS memos,\n+         string_agg(cast(abe.node_account_id AS VARCHAR), ',') AS node_account_ids\n+       FROM address_book ab\n+       LEFT JOIN address_book_entry abe\n+         ON ab.start_consensus_timestamp = abe.consensus_timestamp\n+       WHERE start_consensus_timestamp <= ?\n+         AND file_id = 102\n+       GROUP BY start_consensus_timestamp\n+       ORDER BY start_consensus_timestamp`;\n+  const pgSqlQuery = utils.convertMySqlStyleQueryToPostgres(sqlQuery, sqlParams);\n+  if (logger.isTraceEnabled()) {\n+    logger.trace(`getAddressBooksAndNodeAccountIDsByConsensusNs: ${pgSqlQuery}, ${JSON.stringify(sqlParams)}`);\n+  }\n+\n+  let addressBookQueryResult;\n+  try {\n+    addressBookQueryResult = await pool.query(pgSqlQuery, sqlParams);\n+  } catch (err) {\n+    throw new DbError(err.message);\n+  }\n+\n+  if (_.isEmpty(addressBookQueryResult.rows)) {\n+    throw new NotFoundError('No address book found');\n+  }\n+\n+  const { rows } = addressBookQueryResult;\n+  const lastAddressBook = _.last(rows);\n+\n+  let nodeAccountIds = [];\n+  if (lastAddressBook.node_account_ids) {\n+    nodeAccountIds = _.map(lastAddressBook.node_account_ids.split(','), (id) => EntityId.fromEncodedId(id).toString());\n+  } else if (lastAddressBook.memos) {\n+    nodeAccountIds = lastAddressBook.memos.split(',');\n+  }\n+\n+  if (nodeAccountIds.length !== parseInt(lastAddressBook.node_count, 10)) {\n+    throw new DbError('Number of nodes found mismatch node_count in latest address book');\n+  }\n+\n+  const addressBooks = _.map(rows, (row) => Buffer.from(row.file_data).toString('base64'));\n+  return {\n+    addressBooks,\n+    nodeAccountIds,\n+  };\n+};\n+\n+/**\n+ * Download the file objects (record stream file and signature files) from object storage service\n+ * @param partialFilePaths list of partial file path to download. partial file path is the path with bucket name and\n+ *                         record stream prefix stripped.\n+ * @returns {Promise<Array>} Array of file buffers\n+ */\n+let downloadRecordStreamFilesFromObjectStorage = async (...partialFilePaths) => {\n+  const streamsConfig = config.stateproof.streams;\n+  const s3Client = s3client.createS3Client();\n+\n+  const fileObjects = await Promise.all(_.map(partialFilePaths, async (partialFilePath) => {\n+    const params = {\n+      Bucket: streamsConfig.bucketName,\n+      Key: `${streamsConfig.record.prefix}${partialFilePath}`,\n+    };\n+\n+    return new Promise((resolve) => {\n+      let base64Data = '';\n+      s3Client.getObject(params)\n+        .createReadStream()\n+        .on('data', (chunk) => {\n+          base64Data += Buffer.from(chunk).toString('base64');\n+        })\n+        .on('end', () => {\n+          resolve({\n+            partialFilePath,\n+            base64Data,\n+          });\n+        })\n+        // error may happen for a couple of reasons: 1. the node does not have the requested file, 2. s3 transient error\n+        // so capture the error and return it, otherwise Promise.all will fail\n+        .on('error', (err) => {\n+          logger.error(`Failed to download ${JSON.stringify(params)}`, err);\n+          resolve({\n+            partialFilePath,\n+            err,\n+          });\n+        });\n+    });\n+  }));\n+\n+  return _.filter(fileObjects, (fileObject) => !fileObject.err);\n+};\n+\n+/**\n+ * Check if consensus can be reached given actualCount and expectedCount.\n+ * @param {Number} actualCount\n+ * @param {Number} totalCount\n+ * @returns {boolean} if consensus can be reached\n+ */\n+let canReachConsensus = (actualCount, totalCount) => actualCount >= Math.ceil(totalCount / 3.0);\n+\n+/**\n+ * Handler function for /transactions/:transaction_id/stateproof API.\n+ * @param {Request} req HTTP request object\n+ * @param {Response} res HTTP response object\n+ * @returns none\n+ */\n+const getStateProofForTransaction = async (req, res) => {\n+  const transactionId = TransactionId.fromString(req.params.id);\n+  const consensusNs = await getSuccessfulTransactionConsensusNs(transactionId);\n+  const rcdFileName = await getRCDFileNameByConsensusNs(consensusNs);\n+  const { addressBooks, nodeAccountIds } = await getAddressBooksAndNodeAccountIdsByConsensusNs(consensusNs);\n+\n+  const sigFileObjects = await downloadRecordStreamFilesFromObjectStorage(\n+    ..._.map(nodeAccountIds, (nodeAccountId) => `${nodeAccountId}/${rcdFileName}_sig`),\n+  );\n+\n+  if (!canReachConsensus(sigFileObjects.length, nodeAccountIds.length)) {\n+    throw new FileDownloadError(`Require at least 1/3 signature files to prove consensus, got ${sigFileObjects.length} `\n+      + `out of ${nodeAccountIds.length} for file ${rcdFileName}_sig`);\n+  }\n+\n+  // always download the record file from node 0.0.3\n+  const rcdFileObjects = await downloadRecordStreamFilesFromObjectStorage(`0.0.3/${rcdFileName}`);\n+  if (_.isEmpty(rcdFileObjects)) {\n+    throw new FileDownloadError(`Failed to download record file ${rcdFileName} from node 0.0.3`);\n+  }\n+\n+  const sigFilesMap = {};\n+  _.forEach(sigFileObjects, (sigFileObject) => {\n+    const nodeAccountIdStr = _.first(sigFileObject.partialFilePath.split('/'));\n+    sigFilesMap[nodeAccountIdStr] = sigFileObject.base64Data;\n+  });\n+\n+  res.locals[constants.responseDataLabel] = {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "482ad09f4e43d36d40c64828d4402ef52de96984"}, "originalPosition": 246}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjU1NjQ4MA==", "bodyText": "originally signature files and the record file are download in one downloadRecordStreamFilesFromObjectStorage call. later I refactored it to two calls, first signature files, then the record file, because:\n\nfile download may fail, and I need to check if we get enough signature files so the client can prove the consensus is reached\nfor the same reason that download may fail, we have to try downloading record file among the nodes we know. record file is large, we don't want to parallelize it\n\nwe can combine them since the chances of download failure is low, then the only other downside is the logic is not as clear.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r466556480", "createdAt": "2020-08-06T17:04:10Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-rest/stateproof.js", "diffHunk": "@@ -0,0 +1,265 @@\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ *\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+'use strict';\n+\n+const _ = require('lodash');\n+const utils = require('./utils');\n+const config = require('./config');\n+const constants = require('./constants');\n+const EntityId = require('./entityId');\n+const TransactionId = require('./transactionId');\n+const s3client = require('./s3client');\n+const { DbError } = require('./errors/dbError');\n+const { NotFoundError } = require('./errors/notFoundError');\n+const { FileDownloadError } = require('./errors/fileDownloadError');\n+\n+/**\n+ * Get the consensus_ns of the transaction. Throws exception if no such successful transaction found or multiple such\n+ * transactions found.\n+ * @param {TransactionId} transactionId\n+ * @returns {Promise<String>} consensus_ns of the successful transaction if found\n+ */\n+let getSuccessfulTransactionConsensusNs = async (transactionId) => {\n+  const sqlParams = [transactionId.getEntityId().getEncodedId(), transactionId.getValidStartNs()];\n+  const sqlQuery = `SELECT consensus_ns\n+       FROM transaction\n+       WHERE payer_account_id = ?\n+         AND valid_start_ns = ?\n+         AND result = 22`; // only the successful transaction\n+  const pgSqlQuery = utils.convertMySqlStyleQueryToPostgres(sqlQuery, sqlParams);\n+  if (logger.isTraceEnabled()) {\n+    logger.trace(`getSuccessfulTransactionConsensusNs: ${pgSqlQuery}, ${JSON.stringify(sqlParams)}`);\n+  }\n+\n+  let result;\n+  try {\n+    result = await pool.query(pgSqlQuery, sqlParams);\n+  } catch (err) {\n+    throw new DbError(err.message);\n+  }\n+\n+  const { rows } = result;\n+  if (_.isEmpty(rows)) {\n+    throw new NotFoundError('Transaction not found');\n+  } else if (rows.length > 1) {\n+    throw new DbError('Invalid state, more than one transactions found');\n+  }\n+\n+  return _.first(rows).consensus_ns;\n+};\n+\n+/**\n+ * Get the RCD file name where consensusNs is in the range [consensus_start, consensus_end]. Throws exception if no\n+ * such RCD file found.\n+ * @param {string} consensusNs consensus timestamp within the range of the RCD file to search\n+ * @returns {Promise<String>} RCD file name\n+ */\n+let getRCDFileNameByConsensusNs = async (consensusNs) => {\n+  const sqlParams = [consensusNs, consensusNs];\n+  const sqlQuery = `SELECT name\n+       FROM record_file\n+       WHERE consensus_start <= ?\n+         AND consensus_end >= ?`;\n+  const pgSqlQuery = utils.convertMySqlStyleQueryToPostgres(sqlQuery, sqlParams);\n+  if (logger.isTraceEnabled()) {\n+    logger.trace(`getRCDFileNameByConsensusNs: ${pgSqlQuery}, ${JSON.stringify(sqlParams)}`);\n+  }\n+\n+  let result;\n+  try {\n+    result = await pool.query(pgSqlQuery, sqlParams);\n+  } catch (err) {\n+    throw new DbError(err.message);\n+  }\n+\n+  const { rows } = result;\n+  if (_.isEmpty(rows)) {\n+    throw new NotFoundError('No matching RCD file found');\n+  } else if (rows.length > 1) {\n+    throw new DbError('Invalid state, more than one RCD files found');\n+  }\n+\n+  return _.first(rows).name;\n+};\n+\n+/**\n+ * Get the chain of address books and node account IDs at or before consensusNs.\n+ * @param {String} consensusNs\n+ * @returns {Promise<Object>} List of base64 address book data in chronological order and list of node account IDs.\n+ */\n+let getAddressBooksAndNodeAccountIdsByConsensusNs = async (consensusNs) => {\n+  // Get the chain of address books whose consensus_timestamp <= consensusNs, also aggregate the corresponding\n+  // node account ids from table address_book_entry\n+  const sqlParams = [consensusNs];\n+  const sqlQuery = `SELECT\n+         file_data,\n+         node_count,\n+         string_agg(memo, ',') AS memos,\n+         string_agg(cast(abe.node_account_id AS VARCHAR), ',') AS node_account_ids\n+       FROM address_book ab\n+       LEFT JOIN address_book_entry abe\n+         ON ab.start_consensus_timestamp = abe.consensus_timestamp\n+       WHERE start_consensus_timestamp <= ?\n+         AND file_id = 102\n+       GROUP BY start_consensus_timestamp\n+       ORDER BY start_consensus_timestamp`;\n+  const pgSqlQuery = utils.convertMySqlStyleQueryToPostgres(sqlQuery, sqlParams);\n+  if (logger.isTraceEnabled()) {\n+    logger.trace(`getAddressBooksAndNodeAccountIDsByConsensusNs: ${pgSqlQuery}, ${JSON.stringify(sqlParams)}`);\n+  }\n+\n+  let addressBookQueryResult;\n+  try {\n+    addressBookQueryResult = await pool.query(pgSqlQuery, sqlParams);\n+  } catch (err) {\n+    throw new DbError(err.message);\n+  }\n+\n+  if (_.isEmpty(addressBookQueryResult.rows)) {\n+    throw new NotFoundError('No address book found');\n+  }\n+\n+  const { rows } = addressBookQueryResult;\n+  const lastAddressBook = _.last(rows);\n+\n+  let nodeAccountIds = [];\n+  if (lastAddressBook.node_account_ids) {\n+    nodeAccountIds = _.map(lastAddressBook.node_account_ids.split(','), (id) => EntityId.fromEncodedId(id).toString());\n+  } else if (lastAddressBook.memos) {\n+    nodeAccountIds = lastAddressBook.memos.split(',');\n+  }\n+\n+  if (nodeAccountIds.length !== parseInt(lastAddressBook.node_count, 10)) {\n+    throw new DbError('Number of nodes found mismatch node_count in latest address book');\n+  }\n+\n+  const addressBooks = _.map(rows, (row) => Buffer.from(row.file_data).toString('base64'));\n+  return {\n+    addressBooks,\n+    nodeAccountIds,\n+  };\n+};\n+\n+/**\n+ * Download the file objects (record stream file and signature files) from object storage service\n+ * @param partialFilePaths list of partial file path to download. partial file path is the path with bucket name and\n+ *                         record stream prefix stripped.\n+ * @returns {Promise<Array>} Array of file buffers\n+ */\n+let downloadRecordStreamFilesFromObjectStorage = async (...partialFilePaths) => {\n+  const streamsConfig = config.stateproof.streams;\n+  const s3Client = s3client.createS3Client();\n+\n+  const fileObjects = await Promise.all(_.map(partialFilePaths, async (partialFilePath) => {\n+    const params = {\n+      Bucket: streamsConfig.bucketName,\n+      Key: `${streamsConfig.record.prefix}${partialFilePath}`,\n+    };\n+\n+    return new Promise((resolve) => {\n+      let base64Data = '';\n+      s3Client.getObject(params)\n+        .createReadStream()\n+        .on('data', (chunk) => {\n+          base64Data += Buffer.from(chunk).toString('base64');\n+        })\n+        .on('end', () => {\n+          resolve({\n+            partialFilePath,\n+            base64Data,\n+          });\n+        })\n+        // error may happen for a couple of reasons: 1. the node does not have the requested file, 2. s3 transient error\n+        // so capture the error and return it, otherwise Promise.all will fail\n+        .on('error', (err) => {\n+          logger.error(`Failed to download ${JSON.stringify(params)}`, err);\n+          resolve({\n+            partialFilePath,\n+            err,\n+          });\n+        });\n+    });\n+  }));\n+\n+  return _.filter(fileObjects, (fileObject) => !fileObject.err);\n+};\n+\n+/**\n+ * Check if consensus can be reached given actualCount and expectedCount.\n+ * @param {Number} actualCount\n+ * @param {Number} totalCount\n+ * @returns {boolean} if consensus can be reached\n+ */\n+let canReachConsensus = (actualCount, totalCount) => actualCount >= Math.ceil(totalCount / 3.0);\n+\n+/**\n+ * Handler function for /transactions/:transaction_id/stateproof API.\n+ * @param {Request} req HTTP request object\n+ * @param {Response} res HTTP response object\n+ * @returns none\n+ */\n+const getStateProofForTransaction = async (req, res) => {\n+  const transactionId = TransactionId.fromString(req.params.id);\n+  const consensusNs = await getSuccessfulTransactionConsensusNs(transactionId);\n+  const rcdFileName = await getRCDFileNameByConsensusNs(consensusNs);\n+  const { addressBooks, nodeAccountIds } = await getAddressBooksAndNodeAccountIdsByConsensusNs(consensusNs);\n+\n+  const sigFileObjects = await downloadRecordStreamFilesFromObjectStorage(\n+    ..._.map(nodeAccountIds, (nodeAccountId) => `${nodeAccountId}/${rcdFileName}_sig`),\n+  );\n+\n+  if (!canReachConsensus(sigFileObjects.length, nodeAccountIds.length)) {\n+    throw new FileDownloadError(`Require at least 1/3 signature files to prove consensus, got ${sigFileObjects.length} `\n+      + `out of ${nodeAccountIds.length} for file ${rcdFileName}_sig`);\n+  }\n+\n+  // always download the record file from node 0.0.3\n+  const rcdFileObjects = await downloadRecordStreamFilesFromObjectStorage(`0.0.3/${rcdFileName}`);\n+  if (_.isEmpty(rcdFileObjects)) {\n+    throw new FileDownloadError(`Failed to download record file ${rcdFileName} from node 0.0.3`);\n+  }\n+\n+  const sigFilesMap = {};\n+  _.forEach(sigFileObjects, (sigFileObject) => {\n+    const nodeAccountIdStr = _.first(sigFileObject.partialFilePath.split('/'));\n+    sigFilesMap[nodeAccountIdStr] = sigFileObject.base64Data;\n+  });\n+\n+  res.locals[constants.responseDataLabel] = {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQ2NjU3NQ=="}, "originalCommit": {"oid": "482ad09f4e43d36d40c64828d4402ef52de96984"}, "originalPosition": 246}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjY5OTk2NQ==", "bodyText": "forgot to mention that address book retrieval and signature files downloading have to be in lock step, since we need the node address IDs from the address book then we know which nodes to download the signature files from", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r466699965", "createdAt": "2020-08-06T21:37:21Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-rest/stateproof.js", "diffHunk": "@@ -0,0 +1,265 @@\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ *\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+'use strict';\n+\n+const _ = require('lodash');\n+const utils = require('./utils');\n+const config = require('./config');\n+const constants = require('./constants');\n+const EntityId = require('./entityId');\n+const TransactionId = require('./transactionId');\n+const s3client = require('./s3client');\n+const { DbError } = require('./errors/dbError');\n+const { NotFoundError } = require('./errors/notFoundError');\n+const { FileDownloadError } = require('./errors/fileDownloadError');\n+\n+/**\n+ * Get the consensus_ns of the transaction. Throws exception if no such successful transaction found or multiple such\n+ * transactions found.\n+ * @param {TransactionId} transactionId\n+ * @returns {Promise<String>} consensus_ns of the successful transaction if found\n+ */\n+let getSuccessfulTransactionConsensusNs = async (transactionId) => {\n+  const sqlParams = [transactionId.getEntityId().getEncodedId(), transactionId.getValidStartNs()];\n+  const sqlQuery = `SELECT consensus_ns\n+       FROM transaction\n+       WHERE payer_account_id = ?\n+         AND valid_start_ns = ?\n+         AND result = 22`; // only the successful transaction\n+  const pgSqlQuery = utils.convertMySqlStyleQueryToPostgres(sqlQuery, sqlParams);\n+  if (logger.isTraceEnabled()) {\n+    logger.trace(`getSuccessfulTransactionConsensusNs: ${pgSqlQuery}, ${JSON.stringify(sqlParams)}`);\n+  }\n+\n+  let result;\n+  try {\n+    result = await pool.query(pgSqlQuery, sqlParams);\n+  } catch (err) {\n+    throw new DbError(err.message);\n+  }\n+\n+  const { rows } = result;\n+  if (_.isEmpty(rows)) {\n+    throw new NotFoundError('Transaction not found');\n+  } else if (rows.length > 1) {\n+    throw new DbError('Invalid state, more than one transactions found');\n+  }\n+\n+  return _.first(rows).consensus_ns;\n+};\n+\n+/**\n+ * Get the RCD file name where consensusNs is in the range [consensus_start, consensus_end]. Throws exception if no\n+ * such RCD file found.\n+ * @param {string} consensusNs consensus timestamp within the range of the RCD file to search\n+ * @returns {Promise<String>} RCD file name\n+ */\n+let getRCDFileNameByConsensusNs = async (consensusNs) => {\n+  const sqlParams = [consensusNs, consensusNs];\n+  const sqlQuery = `SELECT name\n+       FROM record_file\n+       WHERE consensus_start <= ?\n+         AND consensus_end >= ?`;\n+  const pgSqlQuery = utils.convertMySqlStyleQueryToPostgres(sqlQuery, sqlParams);\n+  if (logger.isTraceEnabled()) {\n+    logger.trace(`getRCDFileNameByConsensusNs: ${pgSqlQuery}, ${JSON.stringify(sqlParams)}`);\n+  }\n+\n+  let result;\n+  try {\n+    result = await pool.query(pgSqlQuery, sqlParams);\n+  } catch (err) {\n+    throw new DbError(err.message);\n+  }\n+\n+  const { rows } = result;\n+  if (_.isEmpty(rows)) {\n+    throw new NotFoundError('No matching RCD file found');\n+  } else if (rows.length > 1) {\n+    throw new DbError('Invalid state, more than one RCD files found');\n+  }\n+\n+  return _.first(rows).name;\n+};\n+\n+/**\n+ * Get the chain of address books and node account IDs at or before consensusNs.\n+ * @param {String} consensusNs\n+ * @returns {Promise<Object>} List of base64 address book data in chronological order and list of node account IDs.\n+ */\n+let getAddressBooksAndNodeAccountIdsByConsensusNs = async (consensusNs) => {\n+  // Get the chain of address books whose consensus_timestamp <= consensusNs, also aggregate the corresponding\n+  // node account ids from table address_book_entry\n+  const sqlParams = [consensusNs];\n+  const sqlQuery = `SELECT\n+         file_data,\n+         node_count,\n+         string_agg(memo, ',') AS memos,\n+         string_agg(cast(abe.node_account_id AS VARCHAR), ',') AS node_account_ids\n+       FROM address_book ab\n+       LEFT JOIN address_book_entry abe\n+         ON ab.start_consensus_timestamp = abe.consensus_timestamp\n+       WHERE start_consensus_timestamp <= ?\n+         AND file_id = 102\n+       GROUP BY start_consensus_timestamp\n+       ORDER BY start_consensus_timestamp`;\n+  const pgSqlQuery = utils.convertMySqlStyleQueryToPostgres(sqlQuery, sqlParams);\n+  if (logger.isTraceEnabled()) {\n+    logger.trace(`getAddressBooksAndNodeAccountIDsByConsensusNs: ${pgSqlQuery}, ${JSON.stringify(sqlParams)}`);\n+  }\n+\n+  let addressBookQueryResult;\n+  try {\n+    addressBookQueryResult = await pool.query(pgSqlQuery, sqlParams);\n+  } catch (err) {\n+    throw new DbError(err.message);\n+  }\n+\n+  if (_.isEmpty(addressBookQueryResult.rows)) {\n+    throw new NotFoundError('No address book found');\n+  }\n+\n+  const { rows } = addressBookQueryResult;\n+  const lastAddressBook = _.last(rows);\n+\n+  let nodeAccountIds = [];\n+  if (lastAddressBook.node_account_ids) {\n+    nodeAccountIds = _.map(lastAddressBook.node_account_ids.split(','), (id) => EntityId.fromEncodedId(id).toString());\n+  } else if (lastAddressBook.memos) {\n+    nodeAccountIds = lastAddressBook.memos.split(',');\n+  }\n+\n+  if (nodeAccountIds.length !== parseInt(lastAddressBook.node_count, 10)) {\n+    throw new DbError('Number of nodes found mismatch node_count in latest address book');\n+  }\n+\n+  const addressBooks = _.map(rows, (row) => Buffer.from(row.file_data).toString('base64'));\n+  return {\n+    addressBooks,\n+    nodeAccountIds,\n+  };\n+};\n+\n+/**\n+ * Download the file objects (record stream file and signature files) from object storage service\n+ * @param partialFilePaths list of partial file path to download. partial file path is the path with bucket name and\n+ *                         record stream prefix stripped.\n+ * @returns {Promise<Array>} Array of file buffers\n+ */\n+let downloadRecordStreamFilesFromObjectStorage = async (...partialFilePaths) => {\n+  const streamsConfig = config.stateproof.streams;\n+  const s3Client = s3client.createS3Client();\n+\n+  const fileObjects = await Promise.all(_.map(partialFilePaths, async (partialFilePath) => {\n+    const params = {\n+      Bucket: streamsConfig.bucketName,\n+      Key: `${streamsConfig.record.prefix}${partialFilePath}`,\n+    };\n+\n+    return new Promise((resolve) => {\n+      let base64Data = '';\n+      s3Client.getObject(params)\n+        .createReadStream()\n+        .on('data', (chunk) => {\n+          base64Data += Buffer.from(chunk).toString('base64');\n+        })\n+        .on('end', () => {\n+          resolve({\n+            partialFilePath,\n+            base64Data,\n+          });\n+        })\n+        // error may happen for a couple of reasons: 1. the node does not have the requested file, 2. s3 transient error\n+        // so capture the error and return it, otherwise Promise.all will fail\n+        .on('error', (err) => {\n+          logger.error(`Failed to download ${JSON.stringify(params)}`, err);\n+          resolve({\n+            partialFilePath,\n+            err,\n+          });\n+        });\n+    });\n+  }));\n+\n+  return _.filter(fileObjects, (fileObject) => !fileObject.err);\n+};\n+\n+/**\n+ * Check if consensus can be reached given actualCount and expectedCount.\n+ * @param {Number} actualCount\n+ * @param {Number} totalCount\n+ * @returns {boolean} if consensus can be reached\n+ */\n+let canReachConsensus = (actualCount, totalCount) => actualCount >= Math.ceil(totalCount / 3.0);\n+\n+/**\n+ * Handler function for /transactions/:transaction_id/stateproof API.\n+ * @param {Request} req HTTP request object\n+ * @param {Response} res HTTP response object\n+ * @returns none\n+ */\n+const getStateProofForTransaction = async (req, res) => {\n+  const transactionId = TransactionId.fromString(req.params.id);\n+  const consensusNs = await getSuccessfulTransactionConsensusNs(transactionId);\n+  const rcdFileName = await getRCDFileNameByConsensusNs(consensusNs);\n+  const { addressBooks, nodeAccountIds } = await getAddressBooksAndNodeAccountIdsByConsensusNs(consensusNs);\n+\n+  const sigFileObjects = await downloadRecordStreamFilesFromObjectStorage(\n+    ..._.map(nodeAccountIds, (nodeAccountId) => `${nodeAccountId}/${rcdFileName}_sig`),\n+  );\n+\n+  if (!canReachConsensus(sigFileObjects.length, nodeAccountIds.length)) {\n+    throw new FileDownloadError(`Require at least 1/3 signature files to prove consensus, got ${sigFileObjects.length} `\n+      + `out of ${nodeAccountIds.length} for file ${rcdFileName}_sig`);\n+  }\n+\n+  // always download the record file from node 0.0.3\n+  const rcdFileObjects = await downloadRecordStreamFilesFromObjectStorage(`0.0.3/${rcdFileName}`);\n+  if (_.isEmpty(rcdFileObjects)) {\n+    throw new FileDownloadError(`Failed to download record file ${rcdFileName} from node 0.0.3`);\n+  }\n+\n+  const sigFilesMap = {};\n+  _.forEach(sigFileObjects, (sigFileObject) => {\n+    const nodeAccountIdStr = _.first(sigFileObject.partialFilePath.split('/'));\n+    sigFilesMap[nodeAccountIdStr] = sigFileObject.base64Data;\n+  });\n+\n+  res.locals[constants.responseDataLabel] = {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQ2NjU3NQ=="}, "originalCommit": {"oid": "482ad09f4e43d36d40c64828d4402ef52de96984"}, "originalPosition": 246}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzA1ODUzNg==", "bodyText": "Makes sense. Basically similar to what importer does.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r467058536", "createdAt": "2020-08-07T13:59:14Z", "author": {"login": "Nana-EC"}, "path": "hedera-mirror-rest/stateproof.js", "diffHunk": "@@ -0,0 +1,265 @@\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ *\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+'use strict';\n+\n+const _ = require('lodash');\n+const utils = require('./utils');\n+const config = require('./config');\n+const constants = require('./constants');\n+const EntityId = require('./entityId');\n+const TransactionId = require('./transactionId');\n+const s3client = require('./s3client');\n+const { DbError } = require('./errors/dbError');\n+const { NotFoundError } = require('./errors/notFoundError');\n+const { FileDownloadError } = require('./errors/fileDownloadError');\n+\n+/**\n+ * Get the consensus_ns of the transaction. Throws exception if no such successful transaction found or multiple such\n+ * transactions found.\n+ * @param {TransactionId} transactionId\n+ * @returns {Promise<String>} consensus_ns of the successful transaction if found\n+ */\n+let getSuccessfulTransactionConsensusNs = async (transactionId) => {\n+  const sqlParams = [transactionId.getEntityId().getEncodedId(), transactionId.getValidStartNs()];\n+  const sqlQuery = `SELECT consensus_ns\n+       FROM transaction\n+       WHERE payer_account_id = ?\n+         AND valid_start_ns = ?\n+         AND result = 22`; // only the successful transaction\n+  const pgSqlQuery = utils.convertMySqlStyleQueryToPostgres(sqlQuery, sqlParams);\n+  if (logger.isTraceEnabled()) {\n+    logger.trace(`getSuccessfulTransactionConsensusNs: ${pgSqlQuery}, ${JSON.stringify(sqlParams)}`);\n+  }\n+\n+  let result;\n+  try {\n+    result = await pool.query(pgSqlQuery, sqlParams);\n+  } catch (err) {\n+    throw new DbError(err.message);\n+  }\n+\n+  const { rows } = result;\n+  if (_.isEmpty(rows)) {\n+    throw new NotFoundError('Transaction not found');\n+  } else if (rows.length > 1) {\n+    throw new DbError('Invalid state, more than one transactions found');\n+  }\n+\n+  return _.first(rows).consensus_ns;\n+};\n+\n+/**\n+ * Get the RCD file name where consensusNs is in the range [consensus_start, consensus_end]. Throws exception if no\n+ * such RCD file found.\n+ * @param {string} consensusNs consensus timestamp within the range of the RCD file to search\n+ * @returns {Promise<String>} RCD file name\n+ */\n+let getRCDFileNameByConsensusNs = async (consensusNs) => {\n+  const sqlParams = [consensusNs, consensusNs];\n+  const sqlQuery = `SELECT name\n+       FROM record_file\n+       WHERE consensus_start <= ?\n+         AND consensus_end >= ?`;\n+  const pgSqlQuery = utils.convertMySqlStyleQueryToPostgres(sqlQuery, sqlParams);\n+  if (logger.isTraceEnabled()) {\n+    logger.trace(`getRCDFileNameByConsensusNs: ${pgSqlQuery}, ${JSON.stringify(sqlParams)}`);\n+  }\n+\n+  let result;\n+  try {\n+    result = await pool.query(pgSqlQuery, sqlParams);\n+  } catch (err) {\n+    throw new DbError(err.message);\n+  }\n+\n+  const { rows } = result;\n+  if (_.isEmpty(rows)) {\n+    throw new NotFoundError('No matching RCD file found');\n+  } else if (rows.length > 1) {\n+    throw new DbError('Invalid state, more than one RCD files found');\n+  }\n+\n+  return _.first(rows).name;\n+};\n+\n+/**\n+ * Get the chain of address books and node account IDs at or before consensusNs.\n+ * @param {String} consensusNs\n+ * @returns {Promise<Object>} List of base64 address book data in chronological order and list of node account IDs.\n+ */\n+let getAddressBooksAndNodeAccountIdsByConsensusNs = async (consensusNs) => {\n+  // Get the chain of address books whose consensus_timestamp <= consensusNs, also aggregate the corresponding\n+  // node account ids from table address_book_entry\n+  const sqlParams = [consensusNs];\n+  const sqlQuery = `SELECT\n+         file_data,\n+         node_count,\n+         string_agg(memo, ',') AS memos,\n+         string_agg(cast(abe.node_account_id AS VARCHAR), ',') AS node_account_ids\n+       FROM address_book ab\n+       LEFT JOIN address_book_entry abe\n+         ON ab.start_consensus_timestamp = abe.consensus_timestamp\n+       WHERE start_consensus_timestamp <= ?\n+         AND file_id = 102\n+       GROUP BY start_consensus_timestamp\n+       ORDER BY start_consensus_timestamp`;\n+  const pgSqlQuery = utils.convertMySqlStyleQueryToPostgres(sqlQuery, sqlParams);\n+  if (logger.isTraceEnabled()) {\n+    logger.trace(`getAddressBooksAndNodeAccountIDsByConsensusNs: ${pgSqlQuery}, ${JSON.stringify(sqlParams)}`);\n+  }\n+\n+  let addressBookQueryResult;\n+  try {\n+    addressBookQueryResult = await pool.query(pgSqlQuery, sqlParams);\n+  } catch (err) {\n+    throw new DbError(err.message);\n+  }\n+\n+  if (_.isEmpty(addressBookQueryResult.rows)) {\n+    throw new NotFoundError('No address book found');\n+  }\n+\n+  const { rows } = addressBookQueryResult;\n+  const lastAddressBook = _.last(rows);\n+\n+  let nodeAccountIds = [];\n+  if (lastAddressBook.node_account_ids) {\n+    nodeAccountIds = _.map(lastAddressBook.node_account_ids.split(','), (id) => EntityId.fromEncodedId(id).toString());\n+  } else if (lastAddressBook.memos) {\n+    nodeAccountIds = lastAddressBook.memos.split(',');\n+  }\n+\n+  if (nodeAccountIds.length !== parseInt(lastAddressBook.node_count, 10)) {\n+    throw new DbError('Number of nodes found mismatch node_count in latest address book');\n+  }\n+\n+  const addressBooks = _.map(rows, (row) => Buffer.from(row.file_data).toString('base64'));\n+  return {\n+    addressBooks,\n+    nodeAccountIds,\n+  };\n+};\n+\n+/**\n+ * Download the file objects (record stream file and signature files) from object storage service\n+ * @param partialFilePaths list of partial file path to download. partial file path is the path with bucket name and\n+ *                         record stream prefix stripped.\n+ * @returns {Promise<Array>} Array of file buffers\n+ */\n+let downloadRecordStreamFilesFromObjectStorage = async (...partialFilePaths) => {\n+  const streamsConfig = config.stateproof.streams;\n+  const s3Client = s3client.createS3Client();\n+\n+  const fileObjects = await Promise.all(_.map(partialFilePaths, async (partialFilePath) => {\n+    const params = {\n+      Bucket: streamsConfig.bucketName,\n+      Key: `${streamsConfig.record.prefix}${partialFilePath}`,\n+    };\n+\n+    return new Promise((resolve) => {\n+      let base64Data = '';\n+      s3Client.getObject(params)\n+        .createReadStream()\n+        .on('data', (chunk) => {\n+          base64Data += Buffer.from(chunk).toString('base64');\n+        })\n+        .on('end', () => {\n+          resolve({\n+            partialFilePath,\n+            base64Data,\n+          });\n+        })\n+        // error may happen for a couple of reasons: 1. the node does not have the requested file, 2. s3 transient error\n+        // so capture the error and return it, otherwise Promise.all will fail\n+        .on('error', (err) => {\n+          logger.error(`Failed to download ${JSON.stringify(params)}`, err);\n+          resolve({\n+            partialFilePath,\n+            err,\n+          });\n+        });\n+    });\n+  }));\n+\n+  return _.filter(fileObjects, (fileObject) => !fileObject.err);\n+};\n+\n+/**\n+ * Check if consensus can be reached given actualCount and expectedCount.\n+ * @param {Number} actualCount\n+ * @param {Number} totalCount\n+ * @returns {boolean} if consensus can be reached\n+ */\n+let canReachConsensus = (actualCount, totalCount) => actualCount >= Math.ceil(totalCount / 3.0);\n+\n+/**\n+ * Handler function for /transactions/:transaction_id/stateproof API.\n+ * @param {Request} req HTTP request object\n+ * @param {Response} res HTTP response object\n+ * @returns none\n+ */\n+const getStateProofForTransaction = async (req, res) => {\n+  const transactionId = TransactionId.fromString(req.params.id);\n+  const consensusNs = await getSuccessfulTransactionConsensusNs(transactionId);\n+  const rcdFileName = await getRCDFileNameByConsensusNs(consensusNs);\n+  const { addressBooks, nodeAccountIds } = await getAddressBooksAndNodeAccountIdsByConsensusNs(consensusNs);\n+\n+  const sigFileObjects = await downloadRecordStreamFilesFromObjectStorage(\n+    ..._.map(nodeAccountIds, (nodeAccountId) => `${nodeAccountId}/${rcdFileName}_sig`),\n+  );\n+\n+  if (!canReachConsensus(sigFileObjects.length, nodeAccountIds.length)) {\n+    throw new FileDownloadError(`Require at least 1/3 signature files to prove consensus, got ${sigFileObjects.length} `\n+      + `out of ${nodeAccountIds.length} for file ${rcdFileName}_sig`);\n+  }\n+\n+  // always download the record file from node 0.0.3\n+  const rcdFileObjects = await downloadRecordStreamFilesFromObjectStorage(`0.0.3/${rcdFileName}`);\n+  if (_.isEmpty(rcdFileObjects)) {\n+    throw new FileDownloadError(`Failed to download record file ${rcdFileName} from node 0.0.3`);\n+  }\n+\n+  const sigFilesMap = {};\n+  _.forEach(sigFileObjects, (sigFileObject) => {\n+    const nodeAccountIdStr = _.first(sigFileObject.partialFilePath.split('/'));\n+    sigFilesMap[nodeAccountIdStr] = sigFileObject.base64Data;\n+  });\n+\n+  res.locals[constants.responseDataLabel] = {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQ2NjU3NQ=="}, "originalCommit": {"oid": "482ad09f4e43d36d40c64828d4402ef52de96984"}, "originalPosition": 246}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxMzU5NTkzOnYy", "diffSide": "RIGHT", "path": "hedera-mirror-rest/__tests__/config.test.js", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQxNDo0ODo0NlrOG82-PQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQyMzozMDoxMFrOG-jKEQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQ2ODQxMw==", "bodyText": "Isn't some of this a duplication of stuff from the config.js? If anything should be calling that method to ensure we're testing that and not duplicating logic that could get out of sync in tests", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r466468413", "createdAt": "2020-08-06T14:48:46Z", "author": {"login": "Nana-EC"}, "path": "hedera-mirror-rest/__tests__/config.test.js", "diffHunk": "@@ -137,15 +137,177 @@ describe('Load environment configuration:', () => {\n });\n \n describe('Custom CONFIG_NAME:', () => {\n-  test('${CONFIG_PATH}/${CONFIG_NAME}.yml', () => {\n+  const loadConfigFromCustomObject = (custom) => {\n     fs.writeFileSync(path.join(tempDir, 'config.yml'), yaml.safeDump(custom));\n     process.env = {CONFIG_NAME: 'config', CONFIG_PATH: tempDir};\n-    const config = require('../config');\n+    return require('../config');\n+  }\n+\n+  test('${CONFIG_PATH}/${CONFIG_NAME}.yml', () => {\n+    const config = loadConfigFromCustomObject(custom);\n \n     expect(config.shard).toBe(custom.hedera.mirror.rest.shard);\n     expect(config.maxLimit).toBe(custom.hedera.mirror.rest.maxLimit);\n     expect(config.log).toBeUndefined();\n   });\n+\n+  const getDefaultStreamsConfigWithOptionalOverrideByNetwork = (network, override) => {\n+    let streamsConfig = {\n+      network,\n+      cloudProvider: 'S3',\n+      region: 'us-east-1',\n+      record: {\n+        prefix: 'recordstreams/record'\n+      }\n+    };\n+\n+    let invalidNetwork = false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "482ad09f4e43d36d40c64828d4402ef52de96984"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjcwMjM5NQ==", "bodyText": "I can replace the function in config.test.js with a group of hardcoded expected stateproof configuration objects, but it won't look good.\nMy other thought is if configuration parsing logic for stateproof changes in the future, we need to update the test cases in case the expected output changes.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r466702395", "createdAt": "2020-08-06T21:43:23Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-rest/__tests__/config.test.js", "diffHunk": "@@ -137,15 +137,177 @@ describe('Load environment configuration:', () => {\n });\n \n describe('Custom CONFIG_NAME:', () => {\n-  test('${CONFIG_PATH}/${CONFIG_NAME}.yml', () => {\n+  const loadConfigFromCustomObject = (custom) => {\n     fs.writeFileSync(path.join(tempDir, 'config.yml'), yaml.safeDump(custom));\n     process.env = {CONFIG_NAME: 'config', CONFIG_PATH: tempDir};\n-    const config = require('../config');\n+    return require('../config');\n+  }\n+\n+  test('${CONFIG_PATH}/${CONFIG_NAME}.yml', () => {\n+    const config = loadConfigFromCustomObject(custom);\n \n     expect(config.shard).toBe(custom.hedera.mirror.rest.shard);\n     expect(config.maxLimit).toBe(custom.hedera.mirror.rest.maxLimit);\n     expect(config.log).toBeUndefined();\n   });\n+\n+  const getDefaultStreamsConfigWithOptionalOverrideByNetwork = (network, override) => {\n+    let streamsConfig = {\n+      network,\n+      cloudProvider: 'S3',\n+      region: 'us-east-1',\n+      record: {\n+        prefix: 'recordstreams/record'\n+      }\n+    };\n+\n+    let invalidNetwork = false;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQ2ODQxMw=="}, "originalCommit": {"oid": "482ad09f4e43d36d40c64828d4402ef52de96984"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODAwNTk1MA==", "bodyText": "Made a comment for reuse in the config.js file itself to clarify my suggestion", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468005950", "createdAt": "2020-08-10T15:50:20Z", "author": {"login": "Nana-EC"}, "path": "hedera-mirror-rest/__tests__/config.test.js", "diffHunk": "@@ -137,15 +137,177 @@ describe('Load environment configuration:', () => {\n });\n \n describe('Custom CONFIG_NAME:', () => {\n-  test('${CONFIG_PATH}/${CONFIG_NAME}.yml', () => {\n+  const loadConfigFromCustomObject = (custom) => {\n     fs.writeFileSync(path.join(tempDir, 'config.yml'), yaml.safeDump(custom));\n     process.env = {CONFIG_NAME: 'config', CONFIG_PATH: tempDir};\n-    const config = require('../config');\n+    return require('../config');\n+  }\n+\n+  test('${CONFIG_PATH}/${CONFIG_NAME}.yml', () => {\n+    const config = loadConfigFromCustomObject(custom);\n \n     expect(config.shard).toBe(custom.hedera.mirror.rest.shard);\n     expect(config.maxLimit).toBe(custom.hedera.mirror.rest.maxLimit);\n     expect(config.log).toBeUndefined();\n   });\n+\n+  const getDefaultStreamsConfigWithOptionalOverrideByNetwork = (network, override) => {\n+    let streamsConfig = {\n+      network,\n+      cloudProvider: 'S3',\n+      region: 'us-east-1',\n+      record: {\n+        prefix: 'recordstreams/record'\n+      }\n+    };\n+\n+    let invalidNetwork = false;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQ2ODQxMw=="}, "originalCommit": {"oid": "482ad09f4e43d36d40c64828d4402ef52de96984"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODI0MDkxMw==", "bodyText": "addressed it under other comments", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468240913", "createdAt": "2020-08-10T23:30:10Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-rest/__tests__/config.test.js", "diffHunk": "@@ -137,15 +137,177 @@ describe('Load environment configuration:', () => {\n });\n \n describe('Custom CONFIG_NAME:', () => {\n-  test('${CONFIG_PATH}/${CONFIG_NAME}.yml', () => {\n+  const loadConfigFromCustomObject = (custom) => {\n     fs.writeFileSync(path.join(tempDir, 'config.yml'), yaml.safeDump(custom));\n     process.env = {CONFIG_NAME: 'config', CONFIG_PATH: tempDir};\n-    const config = require('../config');\n+    return require('../config');\n+  }\n+\n+  test('${CONFIG_PATH}/${CONFIG_NAME}.yml', () => {\n+    const config = loadConfigFromCustomObject(custom);\n \n     expect(config.shard).toBe(custom.hedera.mirror.rest.shard);\n     expect(config.maxLimit).toBe(custom.hedera.mirror.rest.maxLimit);\n     expect(config.log).toBeUndefined();\n   });\n+\n+  const getDefaultStreamsConfigWithOptionalOverrideByNetwork = (network, override) => {\n+    let streamsConfig = {\n+      network,\n+      cloudProvider: 'S3',\n+      region: 'us-east-1',\n+      record: {\n+        prefix: 'recordstreams/record'\n+      }\n+    };\n+\n+    let invalidNetwork = false;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjQ2ODQxMw=="}, "originalCommit": {"oid": "482ad09f4e43d36d40c64828d4402ef52de96984"}, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxNDk4NTMyOnYy", "diffSide": "RIGHT", "path": "docs/configuration.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQyMToxMjo0NFrOG9EdIQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQyMzowNjoyNlrOG-itUA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjY4OTMxMw==", "bodyText": "nit: Would prefer to sort config properties like the rest of the file.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r466689313", "createdAt": "2020-08-06T21:12:44Z", "author": {"login": "steven-sheehy"}, "path": "docs/configuration.md", "diffHunk": "@@ -149,21 +149,31 @@ merged into) the current configuration:\n The following table lists the available properties along with their default values. Unless you need to set a non-default\n value, it is recommended to only populate overridden properties in the custom `application.yml`.\n \n-| Name                                                 | Default                 | Description                                                                                    |\n-| ---------------------------------------------------- | ----------------------- | ---------------------------------------------------------------------------------------------- |\n-| `hedera.mirror.rest.db.host`                         | 127.0.0.1               | The IP or hostname used to connect to the database                                             |\n-| `hedera.mirror.rest.db.name`                         | mirror_node             | The name of the database                                                                       |\n-| `hedera.mirror.rest.db.password`                     | mirror_api_pass         | The database password the processor uses to connect. **Should be changed from default**        |\n-| `hedera.mirror.rest.db.port`                         | 5432                    | The port used to connect to the database                                                       |\n-| `hedera.mirror.rest.db.username`                     | mirror_api              | The username the processor uses to connect to the database                                     |\n-| `hedera.mirror.rest.includeHostInLink`               | false                   | Whether to include the hostname and port in the next link in the response                      |\n-| `hedera.mirror.rest.maxLimit`                        | 1000                    | The maximum size the limit parameter can be that controls the REST API response size           |\n-| `hedera.mirror.rest.log.level`                       | debug                   | The logging level. Can be trace, debug, info, warn, error or fatal.                            |\n-| `hedera.mirror.rest.port`                            | 5551                    | The REST API port                                                                              |\n-| `hedera.mirror.rest.includeHostInLink`               | false                   | Whether to include the host:port in the next links returned by the REST API                    |\n-| `hedera.mirror.rest.metrics.enabled`                 | true                    | Whether metrics are enabled for the REST API                                                   |\n-| `hedera.mirror.rest.metrics.config.authentication`   | true                    | Whether access to metrics for the REST API is authenticated                                    |\n-| `hedera.mirror.rest.metrics.config.username`         | mirror_api_metrics      | The REST API metrics username to access the dashboard                                          |\n-| `hedera.mirror.rest.metrics.config.password`         | mirror_api_metrics_pass | The REST API metrics password to access the dashboard                                          |\n-| `hedera.mirror.rest.metrics.config.uriPath`          | '/swagger'              | The REST API metrics uri path                                                                  |\n-| `hedera.mirror.rest.shard`                           | 0                       | The default shard number that this mirror node participates in                                 |\n+| Name                                                     | Default                 | Description                                                                                    |\n+| -------------------------------------------------------- | ----------------------- | ---------------------------------------------------------------------------------------------- |\n+| `hedera.mirror.rest.db.host`                             | 127.0.0.1               | The IP or hostname used to connect to the database                                             |\n+| `hedera.mirror.rest.db.name`                             | mirror_node             | The name of the database                                                                       |\n+| `hedera.mirror.rest.db.password`                         | mirror_api_pass         | The database password the processor uses to connect. **Should be changed from default**        |\n+| `hedera.mirror.rest.db.port`                             | 5432                    | The port used to connect to the database                                                       |\n+| `hedera.mirror.rest.db.username`                         | mirror_api              | The username the processor uses to connect to the database                                     |\n+| `hedera.mirror.rest.includeHostInLink`                   | false                   | Whether to include the hostname and port in the next link in the response                      |\n+| `hedera.mirror.rest.maxLimit`                            | 1000                    | The maximum size the limit parameter can be that controls the REST API response size           |\n+| `hedera.mirror.rest.log.level`                           | debug                   | The logging level. Can be trace, debug, info, warn, error or fatal.                            |\n+| `hedera.mirror.rest.port`                                | 5551                    | The REST API port                                                                              |\n+| `hedera.mirror.rest.includeHostInLink`                   | false                   | Whether to include the host:port in the next links returned by the REST API                    |\n+| `hedera.mirror.rest.metrics.enabled`                     | true                    | Whether metrics are enabled for the REST API                                                   |\n+| `hedera.mirror.rest.metrics.config.authentication`       | true                    | Whether access to metrics for the REST API is authenticated                                    |\n+| `hedera.mirror.rest.metrics.config.username`             | mirror_api_metrics      | The REST API metrics username to access the dashboard                                          |\n+| `hedera.mirror.rest.metrics.config.password`             | mirror_api_metrics_pass | The REST API metrics password to access the dashboard                                          |\n+| `hedera.mirror.rest.metrics.config.uriPath`              | '/swagger'              | The REST API metrics uri path                                                                  |\n+| `hedera.mirror.rest.shard`                               | 0                       | The default shard number that this mirror node participates in                                 |\n+| `hedera.mirror.rest.stateproof.enabled`                  | false                   | Weather to enable stateproof REST API or not                                                   |\n+| `hedera.mirror.rest.stateproof.streams.network`          | DEMO                    | Which Hedera network to use. Can be either `DEMO`, `MAINNET`, `TESTNET` or `OTHER`             |", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "482ad09f4e43d36d40c64828d4402ef52de96984"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODIzMzU1Mg==", "bodyText": "updated the order.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468233552", "createdAt": "2020-08-10T23:06:26Z", "author": {"login": "xin-hedera"}, "path": "docs/configuration.md", "diffHunk": "@@ -149,21 +149,31 @@ merged into) the current configuration:\n The following table lists the available properties along with their default values. Unless you need to set a non-default\n value, it is recommended to only populate overridden properties in the custom `application.yml`.\n \n-| Name                                                 | Default                 | Description                                                                                    |\n-| ---------------------------------------------------- | ----------------------- | ---------------------------------------------------------------------------------------------- |\n-| `hedera.mirror.rest.db.host`                         | 127.0.0.1               | The IP or hostname used to connect to the database                                             |\n-| `hedera.mirror.rest.db.name`                         | mirror_node             | The name of the database                                                                       |\n-| `hedera.mirror.rest.db.password`                     | mirror_api_pass         | The database password the processor uses to connect. **Should be changed from default**        |\n-| `hedera.mirror.rest.db.port`                         | 5432                    | The port used to connect to the database                                                       |\n-| `hedera.mirror.rest.db.username`                     | mirror_api              | The username the processor uses to connect to the database                                     |\n-| `hedera.mirror.rest.includeHostInLink`               | false                   | Whether to include the hostname and port in the next link in the response                      |\n-| `hedera.mirror.rest.maxLimit`                        | 1000                    | The maximum size the limit parameter can be that controls the REST API response size           |\n-| `hedera.mirror.rest.log.level`                       | debug                   | The logging level. Can be trace, debug, info, warn, error or fatal.                            |\n-| `hedera.mirror.rest.port`                            | 5551                    | The REST API port                                                                              |\n-| `hedera.mirror.rest.includeHostInLink`               | false                   | Whether to include the host:port in the next links returned by the REST API                    |\n-| `hedera.mirror.rest.metrics.enabled`                 | true                    | Whether metrics are enabled for the REST API                                                   |\n-| `hedera.mirror.rest.metrics.config.authentication`   | true                    | Whether access to metrics for the REST API is authenticated                                    |\n-| `hedera.mirror.rest.metrics.config.username`         | mirror_api_metrics      | The REST API metrics username to access the dashboard                                          |\n-| `hedera.mirror.rest.metrics.config.password`         | mirror_api_metrics_pass | The REST API metrics password to access the dashboard                                          |\n-| `hedera.mirror.rest.metrics.config.uriPath`          | '/swagger'              | The REST API metrics uri path                                                                  |\n-| `hedera.mirror.rest.shard`                           | 0                       | The default shard number that this mirror node participates in                                 |\n+| Name                                                     | Default                 | Description                                                                                    |\n+| -------------------------------------------------------- | ----------------------- | ---------------------------------------------------------------------------------------------- |\n+| `hedera.mirror.rest.db.host`                             | 127.0.0.1               | The IP or hostname used to connect to the database                                             |\n+| `hedera.mirror.rest.db.name`                             | mirror_node             | The name of the database                                                                       |\n+| `hedera.mirror.rest.db.password`                         | mirror_api_pass         | The database password the processor uses to connect. **Should be changed from default**        |\n+| `hedera.mirror.rest.db.port`                             | 5432                    | The port used to connect to the database                                                       |\n+| `hedera.mirror.rest.db.username`                         | mirror_api              | The username the processor uses to connect to the database                                     |\n+| `hedera.mirror.rest.includeHostInLink`                   | false                   | Whether to include the hostname and port in the next link in the response                      |\n+| `hedera.mirror.rest.maxLimit`                            | 1000                    | The maximum size the limit parameter can be that controls the REST API response size           |\n+| `hedera.mirror.rest.log.level`                           | debug                   | The logging level. Can be trace, debug, info, warn, error or fatal.                            |\n+| `hedera.mirror.rest.port`                                | 5551                    | The REST API port                                                                              |\n+| `hedera.mirror.rest.includeHostInLink`                   | false                   | Whether to include the host:port in the next links returned by the REST API                    |\n+| `hedera.mirror.rest.metrics.enabled`                     | true                    | Whether metrics are enabled for the REST API                                                   |\n+| `hedera.mirror.rest.metrics.config.authentication`       | true                    | Whether access to metrics for the REST API is authenticated                                    |\n+| `hedera.mirror.rest.metrics.config.username`             | mirror_api_metrics      | The REST API metrics username to access the dashboard                                          |\n+| `hedera.mirror.rest.metrics.config.password`             | mirror_api_metrics_pass | The REST API metrics password to access the dashboard                                          |\n+| `hedera.mirror.rest.metrics.config.uriPath`              | '/swagger'              | The REST API metrics uri path                                                                  |\n+| `hedera.mirror.rest.shard`                               | 0                       | The default shard number that this mirror node participates in                                 |\n+| `hedera.mirror.rest.stateproof.enabled`                  | false                   | Weather to enable stateproof REST API or not                                                   |\n+| `hedera.mirror.rest.stateproof.streams.network`          | DEMO                    | Which Hedera network to use. Can be either `DEMO`, `MAINNET`, `TESTNET` or `OTHER`             |", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjY4OTMxMw=="}, "originalCommit": {"oid": "482ad09f4e43d36d40c64828d4402ef52de96984"}, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxNTEwODU3OnYy", "diffSide": "RIGHT", "path": "hedera-mirror-rest/.eslintrc.json", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQyMTo1ODozNVrOG9ForQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQyMzoxMjo1N1rOG-i1Iw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjcwODY1Mw==", "bodyText": "Some styling rules might conflict with prettier. Please look into https://prettier.io/docs/en/integrating-with-linters.html", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r466708653", "createdAt": "2020-08-06T21:58:35Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-rest/.eslintrc.json", "diffHunk": "@@ -0,0 +1,37 @@\n+{", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "482ad09f4e43d36d40c64828d4402ef52de96984"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODIzNTU1NQ==", "bodyText": "aded prettier and fixed styling issues per perttier rules", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468235555", "createdAt": "2020-08-10T23:12:57Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-rest/.eslintrc.json", "diffHunk": "@@ -0,0 +1,37 @@\n+{", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjcwODY1Mw=="}, "originalCommit": {"oid": "482ad09f4e43d36d40c64828d4402ef52de96984"}, "originalPosition": 1}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxNTE5MzgwOnYy", "diffSide": "RIGHT", "path": "hedera-mirror-rest/config/application.yml", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQyMjozNToyOFrOG9Gb9w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQyMzoxMTowOFrOG-iy3w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjcyMTc4Mw==", "bodyText": "I think we can just hardcode this. At this point, it's impossible for these streams to change prefixes as it will break the entire ecosystem.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r466721783", "createdAt": "2020-08-06T22:35:28Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-rest/config/application.yml", "diffHunk": "@@ -21,3 +21,16 @@ hedera:\n           username: metrics\n           uriPath: '/swagger'\n       shard: 0\n+      stateproof:\n+        enabled: false\n+        streams:\n+          network: 'DEMO'\n+          cloudProvider: 'S3'\n+          endpointOverride:\n+          gcpProjectId:\n+          region: 'us-east-1'\n+          accessKey:\n+          secretKey:\n+          bucketName:\n+          record:\n+            prefix: 'recordstreams/record'", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "482ad09f4e43d36d40c64828d4402ef52de96984"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODIzNDk3NQ==", "bodyText": "removed it from configuration files & code, added it as a constant in constants.js", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468234975", "createdAt": "2020-08-10T23:11:08Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-rest/config/application.yml", "diffHunk": "@@ -21,3 +21,16 @@ hedera:\n           username: metrics\n           uriPath: '/swagger'\n       shard: 0\n+      stateproof:\n+        enabled: false\n+        streams:\n+          network: 'DEMO'\n+          cloudProvider: 'S3'\n+          endpointOverride:\n+          gcpProjectId:\n+          region: 'us-east-1'\n+          accessKey:\n+          secretKey:\n+          bucketName:\n+          record:\n+            prefix: 'recordstreams/record'", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjcyMTc4Mw=="}, "originalCommit": {"oid": "482ad09f4e43d36d40c64828d4402ef52de96984"}, "originalPosition": 16}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxNTIwMTY0OnYy", "diffSide": "RIGHT", "path": "hedera-mirror-rest/config.js", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQyMjozOToyNVrOG9Gg-Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQyMzoxMjoyOVrOG-i0lg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjcyMzA2NQ==", "bodyText": "We shouldn't default these again in the code. The default is already in the application.yaml. If the user overrides that with an explicit null or empty value that's fine. If the field is required, we should simply check if it's populated at its source of use (which would be in s3client.js) and throw an error. I think any remaining s3 specific logic here should also move to s3client.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r466723065", "createdAt": "2020-08-06T22:39:25Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-rest/config.js", "diffHunk": "@@ -113,12 +114,84 @@ function convertType(value) {\n   return parsedValue;\n }\n \n+function getConfig() {\n+  return config.hedera && config.hedera.mirror ? config.hedera.mirror.rest : config;\n+}\n+\n+function parseStateProofStreamsConfig() {\n+  const config = getConfig();\n+  if (!config.stateproof) {\n+    config.stateproof = {\n+      enabled: false\n+    }\n+  } else if (!config.stateproof.streams || !config.stateproof.streams.network) {\n+    config.stateproof.streams = Object.assign({\n+      network: 'DEMO',\n+    }, config.stateproof.streams);\n+  }\n+\n+  const stateProofConfig = config.stateproof;\n+  const streamsConfig = stateProofConfig.streams;\n+\n+  if (!stateProofConfig.enabled) {\n+    return;\n+  }\n+\n+  // set default bucketName depending on network\n+  switch (streamsConfig.network) {\n+    case 'DEMO':\n+      if (!streamsConfig.bucketName) {\n+        streamsConfig.bucketName = 'hedera-demo-streams';\n+      }\n+      break;\n+    case 'MAINNET':\n+      if (!streamsConfig.bucketName) {\n+        streamsConfig.bucketName = 'hedera-stable-mainnet-streams';\n+      }\n+      break;\n+    case 'TESTNET':\n+      if (!streamsConfig.bucketName) {\n+        streamsConfig.bucketName = 'hedera-stable-testnet-streams';\n+      }\n+      break;\n+    case 'OTHER':\n+      break;\n+    default:\n+      const message = `unknown network ${streamsConfig.network}`;\n+      console.log(message);\n+      throw new InvalidConfigError(message);\n+  }\n+\n+  if (!streamsConfig.cloudProvider) {\n+    streamsConfig.cloudProvider = 'S3';", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "482ad09f4e43d36d40c64828d4402ef52de96984"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzI1MjA1Mg==", "bodyText": "Sure I'll change how to handle the default. But I prefer to throw exception on those required fields here so if any is missing, we fail early instead of throwing exception when the API is invoked.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r467252052", "createdAt": "2020-08-07T20:23:37Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-rest/config.js", "diffHunk": "@@ -113,12 +114,84 @@ function convertType(value) {\n   return parsedValue;\n }\n \n+function getConfig() {\n+  return config.hedera && config.hedera.mirror ? config.hedera.mirror.rest : config;\n+}\n+\n+function parseStateProofStreamsConfig() {\n+  const config = getConfig();\n+  if (!config.stateproof) {\n+    config.stateproof = {\n+      enabled: false\n+    }\n+  } else if (!config.stateproof.streams || !config.stateproof.streams.network) {\n+    config.stateproof.streams = Object.assign({\n+      network: 'DEMO',\n+    }, config.stateproof.streams);\n+  }\n+\n+  const stateProofConfig = config.stateproof;\n+  const streamsConfig = stateProofConfig.streams;\n+\n+  if (!stateProofConfig.enabled) {\n+    return;\n+  }\n+\n+  // set default bucketName depending on network\n+  switch (streamsConfig.network) {\n+    case 'DEMO':\n+      if (!streamsConfig.bucketName) {\n+        streamsConfig.bucketName = 'hedera-demo-streams';\n+      }\n+      break;\n+    case 'MAINNET':\n+      if (!streamsConfig.bucketName) {\n+        streamsConfig.bucketName = 'hedera-stable-mainnet-streams';\n+      }\n+      break;\n+    case 'TESTNET':\n+      if (!streamsConfig.bucketName) {\n+        streamsConfig.bucketName = 'hedera-stable-testnet-streams';\n+      }\n+      break;\n+    case 'OTHER':\n+      break;\n+    default:\n+      const message = `unknown network ${streamsConfig.network}`;\n+      console.log(message);\n+      throw new InvalidConfigError(message);\n+  }\n+\n+  if (!streamsConfig.cloudProvider) {\n+    streamsConfig.cloudProvider = 'S3';", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjcyMzA2NQ=="}, "originalCommit": {"oid": "482ad09f4e43d36d40c64828d4402ef52de96984"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODIzNTQxNA==", "bodyText": "updated along with suggestions by Nana.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468235414", "createdAt": "2020-08-10T23:12:29Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-rest/config.js", "diffHunk": "@@ -113,12 +114,84 @@ function convertType(value) {\n   return parsedValue;\n }\n \n+function getConfig() {\n+  return config.hedera && config.hedera.mirror ? config.hedera.mirror.rest : config;\n+}\n+\n+function parseStateProofStreamsConfig() {\n+  const config = getConfig();\n+  if (!config.stateproof) {\n+    config.stateproof = {\n+      enabled: false\n+    }\n+  } else if (!config.stateproof.streams || !config.stateproof.streams.network) {\n+    config.stateproof.streams = Object.assign({\n+      network: 'DEMO',\n+    }, config.stateproof.streams);\n+  }\n+\n+  const stateProofConfig = config.stateproof;\n+  const streamsConfig = stateProofConfig.streams;\n+\n+  if (!stateProofConfig.enabled) {\n+    return;\n+  }\n+\n+  // set default bucketName depending on network\n+  switch (streamsConfig.network) {\n+    case 'DEMO':\n+      if (!streamsConfig.bucketName) {\n+        streamsConfig.bucketName = 'hedera-demo-streams';\n+      }\n+      break;\n+    case 'MAINNET':\n+      if (!streamsConfig.bucketName) {\n+        streamsConfig.bucketName = 'hedera-stable-mainnet-streams';\n+      }\n+      break;\n+    case 'TESTNET':\n+      if (!streamsConfig.bucketName) {\n+        streamsConfig.bucketName = 'hedera-stable-testnet-streams';\n+      }\n+      break;\n+    case 'OTHER':\n+      break;\n+    default:\n+      const message = `unknown network ${streamsConfig.network}`;\n+      console.log(message);\n+      throw new InvalidConfigError(message);\n+  }\n+\n+  if (!streamsConfig.cloudProvider) {\n+    streamsConfig.cloudProvider = 'S3';", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjcyMzA2NQ=="}, "originalCommit": {"oid": "482ad09f4e43d36d40c64828d4402ef52de96984"}, "originalPosition": 61}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxODEzNTA5OnYy", "diffSide": "RIGHT", "path": "hedera-mirror-rest/__tests__/integrationDomainOps.js", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QxNzoyNDoxMVrOG9h6Cg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQyMzoyMDozM1rOG-i-WA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzE3MTg1MA==", "bodyText": "sql related methods would be more appropriate in integrationDbOps", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r467171850", "createdAt": "2020-08-07T17:24:11Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-rest/__tests__/integrationDomainOps.js", "diffHunk": "@@ -225,6 +238,13 @@ const addTopicMessage = async function (message) {\n   );\n };\n \n+const addSqlScript = async function (sqlScript) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ac0b8533e72ce4ab7d122f0b1ea3269d5538a71e"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzI0NDY0Mw==", "bodyText": "it's because the data we try to dump in can be big & has raw bytes. also it's easier to update the data as we can do pg_dump, and less error prone.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r467244643", "createdAt": "2020-08-07T20:04:34Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-rest/__tests__/integrationDomainOps.js", "diffHunk": "@@ -225,6 +238,13 @@ const addTopicMessage = async function (message) {\n   );\n };\n \n+const addSqlScript = async function (sqlScript) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzE3MTg1MA=="}, "originalCommit": {"oid": "ac0b8533e72ce4ab7d122f0b1ea3269d5538a71e"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzI1MzA0MA==", "bodyText": "Eh? I'm saying it's fine it's just should be moved to a different file. This file is for domain related functions.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r467253040", "createdAt": "2020-08-07T20:25:53Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-rest/__tests__/integrationDomainOps.js", "diffHunk": "@@ -225,6 +238,13 @@ const addTopicMessage = async function (message) {\n   );\n };\n \n+const addSqlScript = async function (sqlScript) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzE3MTg1MA=="}, "originalCommit": {"oid": "ac0b8533e72ce4ab7d122f0b1ea3269d5538a71e"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODIzNzkxMg==", "bodyText": "moved it to integration.test.js", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468237912", "createdAt": "2020-08-10T23:20:33Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-rest/__tests__/integrationDomainOps.js", "diffHunk": "@@ -225,6 +238,13 @@ const addTopicMessage = async function (message) {\n   );\n };\n \n+const addSqlScript = async function (sqlScript) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzE3MTg1MA=="}, "originalCommit": {"oid": "ac0b8533e72ce4ab7d122f0b1ea3269d5538a71e"}, "originalPosition": 39}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxODE2NTY1OnYy", "diffSide": "RIGHT", "path": "hedera-mirror-rest/__tests__/specs/stateproof-06-invalid-transaction-id.spec.json", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QxNzozNDoxMFrOG9iNMA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQyMzoxNDoyMVrOG-i2xw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzE3Njc1Mg==", "bodyText": "This seems pretty restrictive. I don't think we should force clients to send exactly 10 digits for second and 9 for nanos. I think we currently pad it to return in the response, but no need to be so restrictive for request. Padding numbers with zeros to make it work is unnecessary work for the client: /api/v1/transactions/0.0.94139-0011965562-000313194/stateproof. We should parse the seconds and nanos to numbers and accept them if they parse properly and within range of 0 to max second/nano.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r467176752", "createdAt": "2020-08-07T17:34:10Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-rest/__tests__/specs/stateproof-06-invalid-transaction-id.spec.json", "diffHunk": "@@ -0,0 +1,22 @@\n+{\n+  \"description\": \"Stateproof api calls with invalid transaction ID\",\n+  \"setup\": {\n+    \"sqlscripts\": [\n+      \"data/db/stateproof/address_book.sql\",\n+      \"data/db/stateproof/address_book_entry.sql\",\n+      \"data/db/stateproof/record_file.sql\",\n+      \"data/db/stateproof/transaction.sql\"\n+    ]\n+  },\n+  \"url\": \"/api/v1/transactions/0.0.94139-11965562-313194/stateproof\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ac0b8533e72ce4ab7d122f0b1ea3269d5538a71e"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzI0MzYyOA==", "bodyText": "the /transactions/:transactionId API has the same restriction. we can loosen the it since the change is backward compatible.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r467243628", "createdAt": "2020-08-07T20:01:59Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-rest/__tests__/specs/stateproof-06-invalid-transaction-id.spec.json", "diffHunk": "@@ -0,0 +1,22 @@\n+{\n+  \"description\": \"Stateproof api calls with invalid transaction ID\",\n+  \"setup\": {\n+    \"sqlscripts\": [\n+      \"data/db/stateproof/address_book.sql\",\n+      \"data/db/stateproof/address_book_entry.sql\",\n+      \"data/db/stateproof/record_file.sql\",\n+      \"data/db/stateproof/transaction.sql\"\n+    ]\n+  },\n+  \"url\": \"/api/v1/transactions/0.0.94139-11965562-313194/stateproof\",", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzE3Njc1Mg=="}, "originalCommit": {"oid": "ac0b8533e72ce4ab7d122f0b1ea3269d5538a71e"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODIzNTk3NQ==", "bodyText": "made it less restricve, seconds can be from 1 digit to 19 digit with overflow detection, nanos can be from 1 to 9 digits", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468235975", "createdAt": "2020-08-10T23:14:21Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-rest/__tests__/specs/stateproof-06-invalid-transaction-id.spec.json", "diffHunk": "@@ -0,0 +1,22 @@\n+{\n+  \"description\": \"Stateproof api calls with invalid transaction ID\",\n+  \"setup\": {\n+    \"sqlscripts\": [\n+      \"data/db/stateproof/address_book.sql\",\n+      \"data/db/stateproof/address_book_entry.sql\",\n+      \"data/db/stateproof/record_file.sql\",\n+      \"data/db/stateproof/transaction.sql\"\n+    ]\n+  },\n+  \"url\": \"/api/v1/transactions/0.0.94139-11965562-313194/stateproof\",", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzE3Njc1Mg=="}, "originalCommit": {"oid": "ac0b8533e72ce4ab7d122f0b1ea3269d5538a71e"}, "originalPosition": 11}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxODE5NTc4OnYy", "diffSide": "RIGHT", "path": "hedera-mirror-rest/s3client.js", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QxNzo0Mzo1N1rOG9ifpw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQyMzoxNTozN1rOG-i4dA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzE4MTQ3OQ==", "bodyText": "Has this been tested with GCS and S3? Service accounts and personal accounts with requester pays?", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r467181479", "createdAt": "2020-08-07T17:43:57Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-rest/s3client.js", "diffHunk": "@@ -0,0 +1,122 @@\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ *\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+'use strict';\n+\n+const AWS = require('aws-sdk');\n+const querystring = require('querystring');\n+const config = require('./config');\n+const { InvalidConfigError } = require('./errors/invalidConfigError');\n+\n+class S3Client {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ac0b8533e72ce4ab7d122f0b1ea3269d5538a71e"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODIzNjQwNA==", "bodyText": "now it's fully tested, also added the RequestPayer: 'requester' to s3 params", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468236404", "createdAt": "2020-08-10T23:15:37Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-rest/s3client.js", "diffHunk": "@@ -0,0 +1,122 @@\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ *\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+'use strict';\n+\n+const AWS = require('aws-sdk');\n+const querystring = require('querystring');\n+const config = require('./config');\n+const { InvalidConfigError } = require('./errors/invalidConfigError');\n+\n+class S3Client {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzE4MTQ3OQ=="}, "originalCommit": {"oid": "ac0b8533e72ce4ab7d122f0b1ea3269d5538a71e"}, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxODM1NTI1OnYy", "diffSide": "RIGHT", "path": "hedera-mirror-rest/stateproof.js", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QxODozNzo0MlrOG9kC9Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQyMzoxNjo0MlrOG-i50Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzIwNjkwMQ==", "bodyText": "This query does not use an index and is slow:\nmirror_node=> explain analyze SELECT name       FROM t_record_files       WHERE consensus_start <= 1596824850191950000         AND consensus_end >= 1596824850191950000;\n                                                     QUERY PLAN\n---------------------------------------------------------------------------------------------------------------------\n Seq Scan on t_record_files  (cost=0.00..338922.52 rows=36 width=79) (actual time=1742.940..1743.050 rows=1 loops=1)\n   Filter: ((consensus_start <= '1596824850191950000'::bigint) AND (consensus_end >= '1596824850191950000'::bigint))\n   Rows Removed by Filter: 5603497\n Planning time: 0.089 ms\n Execution time: 1743.074 ms", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r467206901", "createdAt": "2020-08-07T18:37:42Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-rest/stateproof.js", "diffHunk": "@@ -0,0 +1,261 @@\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ *\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+'use strict';\n+\n+const _ = require('lodash');\n+const config = require('./config');\n+const constants = require('./constants');\n+const EntityId = require('./entityId');\n+const TransactionId = require('./transactionId');\n+const s3client = require('./s3client');\n+const { DbError } = require('./errors/dbError');\n+const { NotFoundError } = require('./errors/notFoundError');\n+const { FileDownloadError } = require('./errors/fileDownloadError');\n+\n+/**\n+ * Get the consensus_ns of the transaction. Throws exception if no such successful transaction found or multiple such\n+ * transactions found.\n+ * @param {TransactionId} transactionId\n+ * @returns {Promise<String>} consensus_ns of the successful transaction if found\n+ */\n+let getSuccessfulTransactionConsensusNs = async (transactionId) => {\n+  const sqlParams = [transactionId.getEntityId().getEncodedId(), transactionId.getValidStartNs()];\n+  const sqlQuery = `SELECT consensus_ns\n+       FROM transaction\n+       WHERE payer_account_id = $1\n+         AND valid_start_ns = $2\n+         AND result = 22`; // only the successful transaction\n+  if (logger.isTraceEnabled()) {\n+    logger.trace(`getSuccessfulTransactionConsensusNs: ${sqlQuery}, ${JSON.stringify(sqlParams)}`);\n+  }\n+\n+  let result;\n+  try {\n+    result = await pool.query(sqlQuery, sqlParams);\n+  } catch (err) {\n+    throw new DbError(err.message);\n+  }\n+\n+  const { rows } = result;\n+  if (_.isEmpty(rows)) {\n+    throw new NotFoundError('Transaction not found');\n+  } else if (rows.length > 1) {\n+    throw new DbError('Invalid state, more than one transaction found');\n+  }\n+\n+  return _.first(rows).consensus_ns;\n+};\n+\n+/**\n+ * Get the RCD file name where consensusNs is in the range [consensus_start, consensus_end]. Throws exception if no\n+ * such RCD file found.\n+ * @param {string} consensusNs consensus timestamp within the range of the RCD file to search\n+ * @returns {Promise<String>} RCD file name\n+ */\n+let getRCDFileNameByConsensusNs = async (consensusNs) => {\n+  const sqlParams = [consensusNs];\n+  const sqlQuery = `SELECT name", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ac0b8533e72ce4ab7d122f0b1ea3269d5538a71e"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzI0NTIwNQ==", "bodyText": "do we want to just add the foreign key in transaction table to track the name of the corresponding record file?", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r467245205", "createdAt": "2020-08-07T20:05:59Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-rest/stateproof.js", "diffHunk": "@@ -0,0 +1,261 @@\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ *\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+'use strict';\n+\n+const _ = require('lodash');\n+const config = require('./config');\n+const constants = require('./constants');\n+const EntityId = require('./entityId');\n+const TransactionId = require('./transactionId');\n+const s3client = require('./s3client');\n+const { DbError } = require('./errors/dbError');\n+const { NotFoundError } = require('./errors/notFoundError');\n+const { FileDownloadError } = require('./errors/fileDownloadError');\n+\n+/**\n+ * Get the consensus_ns of the transaction. Throws exception if no such successful transaction found or multiple such\n+ * transactions found.\n+ * @param {TransactionId} transactionId\n+ * @returns {Promise<String>} consensus_ns of the successful transaction if found\n+ */\n+let getSuccessfulTransactionConsensusNs = async (transactionId) => {\n+  const sqlParams = [transactionId.getEntityId().getEncodedId(), transactionId.getValidStartNs()];\n+  const sqlQuery = `SELECT consensus_ns\n+       FROM transaction\n+       WHERE payer_account_id = $1\n+         AND valid_start_ns = $2\n+         AND result = 22`; // only the successful transaction\n+  if (logger.isTraceEnabled()) {\n+    logger.trace(`getSuccessfulTransactionConsensusNs: ${sqlQuery}, ${JSON.stringify(sqlParams)}`);\n+  }\n+\n+  let result;\n+  try {\n+    result = await pool.query(sqlQuery, sqlParams);\n+  } catch (err) {\n+    throw new DbError(err.message);\n+  }\n+\n+  const { rows } = result;\n+  if (_.isEmpty(rows)) {\n+    throw new NotFoundError('Transaction not found');\n+  } else if (rows.length > 1) {\n+    throw new DbError('Invalid state, more than one transaction found');\n+  }\n+\n+  return _.first(rows).consensus_ns;\n+};\n+\n+/**\n+ * Get the RCD file name where consensusNs is in the range [consensus_start, consensus_end]. Throws exception if no\n+ * such RCD file found.\n+ * @param {string} consensusNs consensus timestamp within the range of the RCD file to search\n+ * @returns {Promise<String>} RCD file name\n+ */\n+let getRCDFileNameByConsensusNs = async (consensusNs) => {\n+  const sqlParams = [consensusNs];\n+  const sqlQuery = `SELECT name", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzIwNjkwMQ=="}, "originalCommit": {"oid": "ac0b8533e72ce4ab7d122f0b1ea3269d5538a71e"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzI1MzYzNg==", "bodyText": "Definitely don't add any foreign keys to transaction. It will greatly slow down importer. You can just add another index on record_file for the timestamps.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r467253636", "createdAt": "2020-08-07T20:27:25Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-rest/stateproof.js", "diffHunk": "@@ -0,0 +1,261 @@\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ *\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+'use strict';\n+\n+const _ = require('lodash');\n+const config = require('./config');\n+const constants = require('./constants');\n+const EntityId = require('./entityId');\n+const TransactionId = require('./transactionId');\n+const s3client = require('./s3client');\n+const { DbError } = require('./errors/dbError');\n+const { NotFoundError } = require('./errors/notFoundError');\n+const { FileDownloadError } = require('./errors/fileDownloadError');\n+\n+/**\n+ * Get the consensus_ns of the transaction. Throws exception if no such successful transaction found or multiple such\n+ * transactions found.\n+ * @param {TransactionId} transactionId\n+ * @returns {Promise<String>} consensus_ns of the successful transaction if found\n+ */\n+let getSuccessfulTransactionConsensusNs = async (transactionId) => {\n+  const sqlParams = [transactionId.getEntityId().getEncodedId(), transactionId.getValidStartNs()];\n+  const sqlQuery = `SELECT consensus_ns\n+       FROM transaction\n+       WHERE payer_account_id = $1\n+         AND valid_start_ns = $2\n+         AND result = 22`; // only the successful transaction\n+  if (logger.isTraceEnabled()) {\n+    logger.trace(`getSuccessfulTransactionConsensusNs: ${sqlQuery}, ${JSON.stringify(sqlParams)}`);\n+  }\n+\n+  let result;\n+  try {\n+    result = await pool.query(sqlQuery, sqlParams);\n+  } catch (err) {\n+    throw new DbError(err.message);\n+  }\n+\n+  const { rows } = result;\n+  if (_.isEmpty(rows)) {\n+    throw new NotFoundError('Transaction not found');\n+  } else if (rows.length > 1) {\n+    throw new DbError('Invalid state, more than one transaction found');\n+  }\n+\n+  return _.first(rows).consensus_ns;\n+};\n+\n+/**\n+ * Get the RCD file name where consensusNs is in the range [consensus_start, consensus_end]. Throws exception if no\n+ * such RCD file found.\n+ * @param {string} consensusNs consensus timestamp within the range of the RCD file to search\n+ * @returns {Promise<String>} RCD file name\n+ */\n+let getRCDFileNameByConsensusNs = async (consensusNs) => {\n+  const sqlParams = [consensusNs];\n+  const sqlQuery = `SELECT name", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzIwNjkwMQ=="}, "originalCommit": {"oid": "ac0b8533e72ce4ab7d122f0b1ea3269d5538a71e"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODIzNjc1Mw==", "bodyText": "add index on record_file.consensus_end. it suffices with limit 1 to find the record file containing a transaction, and it's the fastest way.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468236753", "createdAt": "2020-08-10T23:16:42Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-rest/stateproof.js", "diffHunk": "@@ -0,0 +1,261 @@\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ *\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+'use strict';\n+\n+const _ = require('lodash');\n+const config = require('./config');\n+const constants = require('./constants');\n+const EntityId = require('./entityId');\n+const TransactionId = require('./transactionId');\n+const s3client = require('./s3client');\n+const { DbError } = require('./errors/dbError');\n+const { NotFoundError } = require('./errors/notFoundError');\n+const { FileDownloadError } = require('./errors/fileDownloadError');\n+\n+/**\n+ * Get the consensus_ns of the transaction. Throws exception if no such successful transaction found or multiple such\n+ * transactions found.\n+ * @param {TransactionId} transactionId\n+ * @returns {Promise<String>} consensus_ns of the successful transaction if found\n+ */\n+let getSuccessfulTransactionConsensusNs = async (transactionId) => {\n+  const sqlParams = [transactionId.getEntityId().getEncodedId(), transactionId.getValidStartNs()];\n+  const sqlQuery = `SELECT consensus_ns\n+       FROM transaction\n+       WHERE payer_account_id = $1\n+         AND valid_start_ns = $2\n+         AND result = 22`; // only the successful transaction\n+  if (logger.isTraceEnabled()) {\n+    logger.trace(`getSuccessfulTransactionConsensusNs: ${sqlQuery}, ${JSON.stringify(sqlParams)}`);\n+  }\n+\n+  let result;\n+  try {\n+    result = await pool.query(sqlQuery, sqlParams);\n+  } catch (err) {\n+    throw new DbError(err.message);\n+  }\n+\n+  const { rows } = result;\n+  if (_.isEmpty(rows)) {\n+    throw new NotFoundError('Transaction not found');\n+  } else if (rows.length > 1) {\n+    throw new DbError('Invalid state, more than one transaction found');\n+  }\n+\n+  return _.first(rows).consensus_ns;\n+};\n+\n+/**\n+ * Get the RCD file name where consensusNs is in the range [consensus_start, consensus_end]. Throws exception if no\n+ * such RCD file found.\n+ * @param {string} consensusNs consensus timestamp within the range of the RCD file to search\n+ * @returns {Promise<String>} RCD file name\n+ */\n+let getRCDFileNameByConsensusNs = async (consensusNs) => {\n+  const sqlParams = [consensusNs];\n+  const sqlQuery = `SELECT name", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzIwNjkwMQ=="}, "originalCommit": {"oid": "ac0b8533e72ce4ab7d122f0b1ea3269d5538a71e"}, "originalPosition": 75}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyMTI5MjkxOnYy", "diffSide": "RIGHT", "path": "docs/design/images/state-proof-alpha-sequence.svg", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wOVQxNzoyNzowNVrOG98i8w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQyMzoxNjo1MlrOG-i6Ew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzYwODMwNw==", "bodyText": "nit: Small typo\ndownload the recrod", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r467608307", "createdAt": "2020-08-09T17:27:05Z", "author": {"login": "ijungmann"}, "path": "docs/design/images/state-proof-alpha-sequence.svg", "diffHunk": "@@ -0,0 +1 @@\n+<svg version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"1703\" height=\"944\"><defs/><g><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g><rect fill=\"white\" stroke=\"none\" x=\"0\" y=\"0\" width=\"1703\" height=\"944\"/></g><g><text fill=\"black\" stroke=\"none\" font-family=\"sans-serif\" font-size=\"16.5pt\" font-style=\"normal\" font-weight=\"normal\" text-decoration=\"normal\" x=\"614.903727359601\" y=\"26.3876361\" text-anchor=\"start\" dominant-baseline=\"alphabetic\" xml:space=\"preserve\">State\u00a0Proof\u00a0Alpha\u00a0REST\u00a0API\u00a0Sequence\u00a0Diagram</text></g><g/><g><path fill=\"none\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 27.536029151660156 138.71100709899997 L 27.536029151660156 944.4134960190001\" stroke-miterlimit=\"10\" stroke-width=\"1.4659797833333332\" stroke-dasharray=\"13.532121076923076,5.863919133333333\"/><path fill=\"none\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 475.3419745034831 138.71100709899997 L 475.3419745034831 944.4134960190001\" stroke-miterlimit=\"10\" stroke-width=\"1.4659797833333332\" stroke-dasharray=\"13.532121076923076,5.863919133333333\"/><path fill=\"none\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 1452.0596019842123 138.71100709899997 L 1452.0596019842123 944.4134960190001\" stroke-miterlimit=\"10\" stroke-width=\"1.4659797833333332\" stroke-dasharray=\"13.532121076923076,5.863919133333333\"/><path fill=\"none\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 1666.2059523456708 138.71100709899997 L 1666.2059523456708 944.4134960190001\" stroke-miterlimit=\"10\" stroke-width=\"1.4659797833333332\" stroke-dasharray=\"13.532121076923076,5.863919133333333\"/></g><g><g><path fill=\"white\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 37.563330869660156 64.29787329699998 A 10.027301717999999 10.027301717999999 0 1 1 37.56332585600971 64.2878459969532 M 27.536029151660156 74.32517501499997 L 27.536029151660156 95.78711904299996 M 14.869963823660157 82.06554827099998 L 40.202094479660154 82.06554827099998 M 27.536029151660156 95.78711904299996 L 14.869963823660157 115.84172247899997 M 27.536029151660156 95.78711904299996 L 40.202094479660154 115.84172247899997\" stroke-miterlimit=\"10\" stroke-width=\"2.990598758\" stroke-dasharray=\"\"/></g><g><g/><text fill=\"black\" stroke=\"none\" font-family=\"sans-serif\" font-size=\"11pt\" font-style=\"normal\" font-weight=\"normal\" text-decoration=\"normal\" x=\"8.7958787\" y=\"133.43347987899998\" text-anchor=\"start\" dominant-baseline=\"alphabetic\" xml:space=\"preserve\">Client</text></g><path fill=\"none\" stroke=\"none\"/><g><path fill=\"white\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 434.6658140257526 91.21326211899998 L 516.0181349812135 91.21326211899998 L 516.0181349812135 138.71100709899997 L 434.6658140257526 138.71100709899997 L 434.6658140257526 91.21326211899998 Z\" stroke-miterlimit=\"10\" stroke-width=\"2.814681184\" stroke-dasharray=\"\"/></g><g><g/><text fill=\"black\" stroke=\"none\" font-family=\"sans-serif\" font-size=\"11pt\" font-style=\"normal\" font-weight=\"normal\" text-decoration=\"normal\" x=\"453.7528708047526\" y=\"121.119249699\" text-anchor=\"start\" dominant-baseline=\"alphabetic\" xml:space=\"preserve\">Server</text></g><path fill=\"none\" stroke=\"none\"/><g><path fill=\"white\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 1401.5946002589233 91.21326211899998 L 1502.5246037095014 91.21326211899998 L 1502.5246037095014 138.71100709899997 L 1401.5946002589233 138.71100709899997 L 1401.5946002589233 91.21326211899998 Z\" stroke-miterlimit=\"10\" stroke-width=\"2.814681184\" stroke-dasharray=\"\"/></g><g><g/><text fill=\"black\" stroke=\"none\" font-family=\"sans-serif\" font-size=\"11pt\" font-style=\"normal\" font-weight=\"normal\" text-decoration=\"normal\" x=\"1420.6816570379233\" y=\"121.119249699\" text-anchor=\"start\" dominant-baseline=\"alphabetic\" xml:space=\"preserve\">Database</text></g><path fill=\"none\" stroke=\"none\"/><g><path fill=\"white\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 1638.1532583596395 91.21326211899998 L 1694.258646331702 91.21326211899998 L 1694.258646331702 138.71100709899997 L 1638.1532583596395 138.71100709899997 L 1638.1532583596395 91.21326211899998 Z\" stroke-miterlimit=\"10\" stroke-width=\"2.814681184\" stroke-dasharray=\"\"/></g><g><g/><text fill=\"black\" stroke=\"none\" font-family=\"sans-serif\" font-size=\"11pt\" font-style=\"normal\" font-weight=\"normal\" text-decoration=\"normal\" x=\"1657.2403151386395\" y=\"121.119249699\" text-anchor=\"start\" dominant-baseline=\"alphabetic\" xml:space=\"preserve\">S3</text></g></g><g><g><g><rect fill=\"white\" stroke=\"none\" x=\"109.46242388651693\" y=\"173.89452189899995\" width=\"283.9531558821094\" height=\"22.86928462\"/></g><text fill=\"black\" stroke=\"none\" font-family=\"sans-serif\" font-size=\"11pt\" font-style=\"normal\" font-weight=\"normal\" text-decoration=\"normal\" x=\"112.10118749651693\" y=\"189.72710355899997\" text-anchor=\"start\" dominant-baseline=\"alphabetic\" xml:space=\"preserve\">GET\u00a0/transactions/:transactionId/stateproof</text></g><g><path fill=\"none\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 27.536029151660156 196.76380651899996 L 472.4100149368164 196.76380651899996\" stroke-miterlimit=\"10\" stroke-width=\"1.4659797833333332\" stroke-dasharray=\"\"/><g transform=\"translate(475.3419745034831,196.76380651899996) translate(-475.3419745034831,-196.76380651899996)\"><path fill=\"black\" stroke=\"none\" paint-order=\"stroke fill markers\" d=\" M 460.6821766701497 189.43390760233328 L 475.3419745034831 196.76380651899996 L 460.6821766701497 204.09370543566664 Z\"/></g></g><g><g><rect fill=\"white\" stroke=\"none\" x=\"496.1588874268164\" y=\"223.15144261899997\" width=\"150.3239902326953\" height=\"22.86928462\"/></g><text fill=\"black\" stroke=\"none\" font-family=\"sans-serif\" font-size=\"11pt\" font-style=\"normal\" font-weight=\"normal\" text-decoration=\"normal\" x=\"498.79765103681643\" y=\"238.98402427899998\" text-anchor=\"start\" dominant-baseline=\"alphabetic\" xml:space=\"preserve\">validate\u00a0transaction\u00a0ID</text></g><g><path fill=\"none\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 475.3419745034831 246.02072723899997 L 545.709004103483 246.02072723899997 L 545.709004103483 268.89001185899997 L 478.2739340701497 268.89001185899997\" stroke-miterlimit=\"10\" stroke-width=\"1.4659797833333332\" stroke-dasharray=\"\"/><g transform=\"translate(475.3419745034831,268.89001185899997) translate(-475.3419745034831,-268.89001185899997)\"><path fill=\"black\" stroke=\"none\" paint-order=\"stroke fill markers\" d=\" M 490.00177233681643 261.5601129423333 L 475.3419745034831 268.89001185899997 L 490.00177233681643 276.2199107756666 Z\"/></g></g><g><g><rect fill=\"white\" stroke=\"none\" x=\"732.8910956787696\" y=\"295.277647959\" width=\"461.6193851301563\" height=\"22.86928462\"/></g><text fill=\"black\" stroke=\"none\" font-family=\"sans-serif\" font-size=\"11pt\" font-style=\"normal\" font-weight=\"normal\" text-decoration=\"normal\" x=\"735.5298592887696\" y=\"311.110229619\" text-anchor=\"start\" dominant-baseline=\"alphabetic\" xml:space=\"preserve\">query\u00a0transaction\u00a0table\u00a0for\u00a0consensus_ns\u00a0of\u00a0the\u00a0successful\u00a0transaction</text></g><g><path fill=\"none\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 475.3419745034831 318.14693257899995 L 1449.1276424175458 318.14693257899995\" stroke-miterlimit=\"10\" stroke-width=\"1.4659797833333332\" stroke-dasharray=\"\"/><g transform=\"translate(1452.0596019842123,318.14693257899995) translate(-1452.0596019842123,-318.14693257899995)\"><path fill=\"black\" stroke=\"none\" paint-order=\"stroke fill markers\" d=\" M 1437.399804150879 310.8170336623333 L 1452.0596019842123 318.14693257899995 L 1437.399804150879 325.4768314956666 Z\"/></g></g><g><g><rect fill=\"white\" stroke=\"none\" x=\"855.9332251953712\" y=\"344.53456867899996\" width=\"215.53512609695312\" height=\"22.86928462\"/></g><text fill=\"black\" stroke=\"none\" font-family=\"sans-serif\" font-size=\"11pt\" font-style=\"normal\" font-weight=\"normal\" text-decoration=\"normal\" x=\"858.5719888053711\" y=\"360.367150339\" text-anchor=\"start\" dominant-baseline=\"alphabetic\" xml:space=\"preserve\">consensus_ns\u00a0of\u00a0the\u00a0transaction</text></g><g><path fill=\"none\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 1452.0596019842123 367.40385329899993 L 478.2739340701497 367.40385329899993\" stroke-miterlimit=\"10\" stroke-width=\"1.4659797833333332\" stroke-dasharray=\"7.0367029599999995\"/><g transform=\"translate(475.3419745034831,367.40385329899993) translate(-475.3419745034831,-367.40385329899993)\"><path fill=\"black\" stroke=\"none\" paint-order=\"stroke fill markers\" d=\" M 490.00177233681643 360.0739543823333 L 475.3419745034831 367.40385329899993 L 490.00177233681643 374.7337522156666 Z\"/></g></g><g><g><rect fill=\"white\" stroke=\"none\" x=\"635.5037970947852\" y=\"393.79148939899994\" width=\"656.393982298125\" height=\"22.86928462\"/></g><text fill=\"black\" stroke=\"none\" font-family=\"sans-serif\" font-size=\"11pt\" font-style=\"normal\" font-weight=\"normal\" text-decoration=\"normal\" x=\"638.1425607047852\" y=\"409.62407105899996\" text-anchor=\"start\" dominant-baseline=\"alphabetic\" xml:space=\"preserve\">query\u00a0record_file\u00a0table\u00a0for\u00a0the\u00a0RCD\u00a0file\u00a0where\u00a0consensus_start\u00a0&lt;=\u00a0consensus_ns\u00a0&lt;=\u00a0consensus_end</text></g><g><path fill=\"none\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 475.3419745034831 416.6607740189999 L 1449.1276424175458 416.6607740189999\" stroke-miterlimit=\"10\" stroke-width=\"1.4659797833333332\" stroke-dasharray=\"\"/><g transform=\"translate(1452.0596019842123,416.6607740189999) translate(-1452.0596019842123,-416.6607740189999)\"><path fill=\"black\" stroke=\"none\" paint-order=\"stroke fill markers\" d=\" M 1437.399804150879 409.33087510233327 L 1452.0596019842123 416.6607740189999 L 1437.399804150879 423.99067293566657 Z\"/></g></g><g><g><rect fill=\"white\" stroke=\"none\" x=\"913.4027610230079\" y=\"443.0484101189999\" width=\"100.59605444167968\" height=\"22.86928462\"/></g><text fill=\"black\" stroke=\"none\" font-family=\"sans-serif\" font-size=\"11pt\" font-style=\"normal\" font-weight=\"normal\" text-decoration=\"normal\" x=\"916.0415246330078\" y=\"458.88099177899994\" text-anchor=\"start\" dominant-baseline=\"alphabetic\" xml:space=\"preserve\">RCD\u00a0file\u00a0name</text></g><g><path fill=\"none\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 1452.0596019842123 465.9176947389999 L 478.2739340701497 465.9176947389999\" stroke-miterlimit=\"10\" stroke-width=\"1.4659797833333332\" stroke-dasharray=\"7.0367029599999995\"/><g transform=\"translate(475.3419745034831,465.9176947389999) translate(-475.3419745034831,-465.9176947389999)\"><path fill=\"black\" stroke=\"none\" paint-order=\"stroke fill markers\" d=\" M 490.00177233681643 458.58779582233325 L 475.3419745034831 465.9176947389999 L 490.00177233681643 473.24759365566655 Z\"/></g></g><g><g><rect fill=\"white\" stroke=\"none\" x=\"496.1588874268164\" y=\"492.30533083899996\" width=\"935.0838016340625\" height=\"22.86928462\"/></g><text fill=\"black\" stroke=\"none\" font-family=\"sans-serif\" font-size=\"11pt\" font-style=\"normal\" font-weight=\"normal\" text-decoration=\"normal\" x=\"498.79765103681643\" y=\"508.137912499\" text-anchor=\"start\" dominant-baseline=\"alphabetic\" xml:space=\"preserve\">query\u00a0address_book\u00a0table\u00a0and\u00a0address_book_entry\u00a0table\u00a0(start_consensus_timestamp\u00a0&lt;=\u00a0consensus_ns)\u00a0order\u00a0by\u00a0start_consensus_timestamp</text></g><g><path fill=\"none\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 475.3419745034831 515.1746154589999 L 1449.1276424175458 515.1746154589999\" stroke-miterlimit=\"10\" stroke-width=\"1.4659797833333332\" stroke-dasharray=\"\"/><g transform=\"translate(1452.0596019842123,515.1746154589999) translate(-1452.0596019842123,-515.1746154589999)\"><path fill=\"black\" stroke=\"none\" paint-order=\"stroke fill markers\" d=\" M 1437.399804150879 507.8447165423333 L 1452.0596019842123 515.1746154589999 L 1437.399804150879 522.5045143756666 Z\"/></g></g><g><g><rect fill=\"white\" stroke=\"none\" x=\"708.4172187256446\" y=\"541.562251559\" width=\"510.5671390364063\" height=\"22.86928462\"/></g><text fill=\"black\" stroke=\"none\" font-family=\"sans-serif\" font-size=\"11pt\" font-style=\"normal\" font-weight=\"normal\" text-decoration=\"normal\" x=\"711.0559823356446\" y=\"557.3948332189999\" text-anchor=\"start\" dominant-baseline=\"alphabetic\" xml:space=\"preserve\">address\u00a0books\u00a0and\u00a0corresponding\u00a0nodes\u00a0(file_data,\u00a0node_count,\u00a0list\u00a0of\u00a0nodes)</text></g><g><path fill=\"none\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 1452.0596019842123 564.431536179 L 478.2739340701497 564.431536179\" stroke-miterlimit=\"10\" stroke-width=\"1.4659797833333332\" stroke-dasharray=\"7.0367029599999995\"/><g transform=\"translate(475.3419745034831,564.431536179) translate(-475.3419745034831,-564.431536179)\"><path fill=\"black\" stroke=\"none\" paint-order=\"stroke fill markers\" d=\" M 490.00177233681643 557.1016372623333 L 475.3419745034831 564.431536179 L 490.00177233681643 571.7614350956667 Z\"/></g></g><g><g><rect fill=\"white\" stroke=\"none\" x=\"877.444525986452\" y=\"590.819172279\" width=\"386.65887487625\" height=\"22.86928462\"/></g><text fill=\"black\" stroke=\"none\" font-family=\"sans-serif\" font-size=\"11pt\" font-style=\"normal\" font-weight=\"normal\" text-decoration=\"normal\" x=\"880.083289596452\" y=\"606.651753939\" text-anchor=\"start\" dominant-baseline=\"alphabetic\" xml:space=\"preserve\">download\u00a0signature\u00a0files\u00a0from\u00a0nodes\u00a0in\u00a0latest\u00a0address\u00a0book</text></g><g><path fill=\"none\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 475.3419745034831 613.688456899 L 1663.2739927790042 613.688456899\" stroke-miterlimit=\"10\" stroke-width=\"1.4659797833333332\" stroke-dasharray=\"\"/><g transform=\"translate(1666.2059523456708,613.688456899) translate(-1666.2059523456708,-613.688456899)\"><path fill=\"black\" stroke=\"none\" paint-order=\"stroke fill markers\" d=\" M 1651.5461545123374 606.3585579823333 L 1666.2059523456708 613.688456899 L 1651.5461545123374 621.0183558156667 Z\"/></g></g><g><g><rect fill=\"white\" stroke=\"none\" x=\"954.0407631690692\" y=\"640.076092999\" width=\"233.46640051101562\" height=\"22.86928462\"/></g><text fill=\"black\" stroke=\"none\" font-family=\"sans-serif\" font-size=\"11pt\" font-style=\"normal\" font-weight=\"normal\" text-decoration=\"normal\" x=\"956.6795267790692\" y=\"655.908674659\" text-anchor=\"start\" dominant-baseline=\"alphabetic\" xml:space=\"preserve\">content\u00a0of\u00a0requested\u00a0signature\u00a0files</text></g><g><path fill=\"none\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 1666.2059523456708 662.945377619 L 478.2739340701497 662.945377619\" stroke-miterlimit=\"10\" stroke-width=\"1.4659797833333332\" stroke-dasharray=\"7.0367029599999995\"/><g transform=\"translate(475.3419745034831,662.945377619) translate(-475.3419745034831,-662.945377619)\"><path fill=\"black\" stroke=\"none\" paint-order=\"stroke fill markers\" d=\" M 490.00177233681643 655.6154787023333 L 475.3419745034831 662.945377619 L 490.00177233681643 670.2752765356668 Z\"/></g></g><g><g><rect fill=\"white\" stroke=\"none\" x=\"496.1588874268164\" y=\"689.3330137190001\" width=\"458.3553470442188\" height=\"22.86928462\"/></g><text fill=\"black\" stroke=\"none\" font-family=\"sans-serif\" font-size=\"11pt\" font-style=\"normal\" font-weight=\"normal\" text-decoration=\"normal\" x=\"498.79765103681643\" y=\"705.165595379\" text-anchor=\"start\" dominant-baseline=\"alphabetic\" xml:space=\"preserve\">check\u00a0if\u00a0the\u00a0number\u00a0of\u00a0signature\u00a0files\u00a0can\u00a0prove\u00a0consensus\u00a0is\u00a0reached</text></g><g><path fill=\"none\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 475.3419745034831 712.202298339 L 545.709004103483 712.202298339 L 545.709004103483 735.071582959 L 478.2739340701497 735.071582959\" stroke-miterlimit=\"10\" stroke-width=\"1.4659797833333332\" stroke-dasharray=\"\"/><g transform=\"translate(475.3419745034831,735.071582959) translate(-475.3419745034831,-735.071582959)\"><path fill=\"black\" stroke=\"none\" paint-order=\"stroke fill markers\" d=\" M 490.00177233681643 727.7416840423333 L 475.3419745034831 735.071582959 L 490.00177233681643 742.4014818756667 Z\"/></g></g><g><g><rect fill=\"white\" stroke=\"none\" x=\"990.3077462012958\" y=\"761.459219059\" width=\"160.9324344465625\" height=\"22.86928462\"/></g><text fill=\"black\" stroke=\"none\" font-family=\"sans-serif\" font-size=\"11pt\" font-style=\"normal\" font-weight=\"normal\" text-decoration=\"normal\" x=\"992.9465098112958\" y=\"777.291800719\" text-anchor=\"start\" dominant-baseline=\"alphabetic\" xml:space=\"preserve\">download\u00a0the\u00a0recrod\u00a0file</text></g><g><path fill=\"none\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 475.3419745034831 784.328503679 L 1663.2739927790042 784.328503679\" stroke-miterlimit=\"10\" stroke-width=\"1.4659797833333332\" stroke-dasharray=\"\"/><g transform=\"translate(1666.2059523456708,784.328503679) translate(-1666.2059523456708,-784.328503679)\"><path fill=\"black\" stroke=\"none\" paint-order=\"stroke fill markers\" d=\" M 1651.5461545123374 776.9986047623333 L 1666.2059523456708 784.328503679 L 1651.5461545123374 791.6584025956668 Z\"/></g></g><g><g><rect fill=\"white\" stroke=\"none\" x=\"989.495291977663\" y=\"810.7161397790001\" width=\"162.55734289382812\" height=\"22.86928462\"/></g><text fill=\"black\" stroke=\"none\" font-family=\"sans-serif\" font-size=\"11pt\" font-style=\"normal\" font-weight=\"normal\" text-decoration=\"normal\" x=\"992.1340555876629\" y=\"826.548721439\" text-anchor=\"start\" dominant-baseline=\"alphabetic\" xml:space=\"preserve\">content\u00a0of\u00a0the\u00a0record\u00a0file</text></g><g><path fill=\"none\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 1666.2059523456708 833.5854243990001 L 478.2739340701497 833.5854243990001\" stroke-miterlimit=\"10\" stroke-width=\"1.4659797833333332\" stroke-dasharray=\"7.0367029599999995\"/><g transform=\"translate(475.3419745034831,833.5854243990001) translate(-475.3419745034831,-833.5854243990001)\"><path fill=\"black\" stroke=\"none\" paint-order=\"stroke fill markers\" d=\" M 490.00177233681643 826.2555254823334 L 475.3419745034831 833.5854243990001 L 490.00177233681643 840.9153233156668 Z\"/></g></g><g><g><rect fill=\"white\" stroke=\"none\" x=\"48.35294207499349\" y=\"859.9730604990001\" width=\"406.1721195051563\" height=\"22.86928462\"/></g><text fill=\"black\" stroke=\"none\" font-family=\"sans-serif\" font-size=\"11pt\" font-style=\"normal\" font-weight=\"normal\" text-decoration=\"normal\" x=\"50.99170568499349\" y=\"875.8056421590001\" text-anchor=\"start\" dominant-baseline=\"alphabetic\" xml:space=\"preserve\">JSON\u00a0response\u00a0(record\u00a0file\u00a0+\u00a0address\u00a0books\u00a0+\u00a0signature\u00a0files)</text></g><g><path fill=\"none\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 475.3419745034831 882.8423451190001 L 30.467988718326822 882.8423451190001\" stroke-miterlimit=\"10\" stroke-width=\"1.4659797833333332\" stroke-dasharray=\"7.0367029599999995\"/><g transform=\"translate(27.536029151660156,882.8423451190001) translate(-27.536029151660156,-882.8423451190001)\"><path fill=\"black\" stroke=\"none\" paint-order=\"stroke fill markers\" d=\" M 42.19582698499349 875.5124462023334 L 27.536029151660156 882.8423451190001 L 42.19582698499349 890.1722440356668 Z\"/></g></g></g><g/><g/><g/><g/></g></svg>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ac0b8533e72ce4ab7d122f0b1ea3269d5538a71e"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODIzNjgxOQ==", "bodyText": "updated", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468236819", "createdAt": "2020-08-10T23:16:52Z", "author": {"login": "xin-hedera"}, "path": "docs/design/images/state-proof-alpha-sequence.svg", "diffHunk": "@@ -0,0 +1 @@\n+<svg version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"1703\" height=\"944\"><defs/><g><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g><rect fill=\"white\" stroke=\"none\" x=\"0\" y=\"0\" width=\"1703\" height=\"944\"/></g><g><text fill=\"black\" stroke=\"none\" font-family=\"sans-serif\" font-size=\"16.5pt\" font-style=\"normal\" font-weight=\"normal\" text-decoration=\"normal\" x=\"614.903727359601\" y=\"26.3876361\" text-anchor=\"start\" dominant-baseline=\"alphabetic\" xml:space=\"preserve\">State\u00a0Proof\u00a0Alpha\u00a0REST\u00a0API\u00a0Sequence\u00a0Diagram</text></g><g/><g><path fill=\"none\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 27.536029151660156 138.71100709899997 L 27.536029151660156 944.4134960190001\" stroke-miterlimit=\"10\" stroke-width=\"1.4659797833333332\" stroke-dasharray=\"13.532121076923076,5.863919133333333\"/><path fill=\"none\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 475.3419745034831 138.71100709899997 L 475.3419745034831 944.4134960190001\" stroke-miterlimit=\"10\" stroke-width=\"1.4659797833333332\" stroke-dasharray=\"13.532121076923076,5.863919133333333\"/><path fill=\"none\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 1452.0596019842123 138.71100709899997 L 1452.0596019842123 944.4134960190001\" stroke-miterlimit=\"10\" stroke-width=\"1.4659797833333332\" stroke-dasharray=\"13.532121076923076,5.863919133333333\"/><path fill=\"none\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 1666.2059523456708 138.71100709899997 L 1666.2059523456708 944.4134960190001\" stroke-miterlimit=\"10\" stroke-width=\"1.4659797833333332\" stroke-dasharray=\"13.532121076923076,5.863919133333333\"/></g><g><g><path fill=\"white\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 37.563330869660156 64.29787329699998 A 10.027301717999999 10.027301717999999 0 1 1 37.56332585600971 64.2878459969532 M 27.536029151660156 74.32517501499997 L 27.536029151660156 95.78711904299996 M 14.869963823660157 82.06554827099998 L 40.202094479660154 82.06554827099998 M 27.536029151660156 95.78711904299996 L 14.869963823660157 115.84172247899997 M 27.536029151660156 95.78711904299996 L 40.202094479660154 115.84172247899997\" stroke-miterlimit=\"10\" stroke-width=\"2.990598758\" stroke-dasharray=\"\"/></g><g><g/><text fill=\"black\" stroke=\"none\" font-family=\"sans-serif\" font-size=\"11pt\" font-style=\"normal\" font-weight=\"normal\" text-decoration=\"normal\" x=\"8.7958787\" y=\"133.43347987899998\" text-anchor=\"start\" dominant-baseline=\"alphabetic\" xml:space=\"preserve\">Client</text></g><path fill=\"none\" stroke=\"none\"/><g><path fill=\"white\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 434.6658140257526 91.21326211899998 L 516.0181349812135 91.21326211899998 L 516.0181349812135 138.71100709899997 L 434.6658140257526 138.71100709899997 L 434.6658140257526 91.21326211899998 Z\" stroke-miterlimit=\"10\" stroke-width=\"2.814681184\" stroke-dasharray=\"\"/></g><g><g/><text fill=\"black\" stroke=\"none\" font-family=\"sans-serif\" font-size=\"11pt\" font-style=\"normal\" font-weight=\"normal\" text-decoration=\"normal\" x=\"453.7528708047526\" y=\"121.119249699\" text-anchor=\"start\" dominant-baseline=\"alphabetic\" xml:space=\"preserve\">Server</text></g><path fill=\"none\" stroke=\"none\"/><g><path fill=\"white\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 1401.5946002589233 91.21326211899998 L 1502.5246037095014 91.21326211899998 L 1502.5246037095014 138.71100709899997 L 1401.5946002589233 138.71100709899997 L 1401.5946002589233 91.21326211899998 Z\" stroke-miterlimit=\"10\" stroke-width=\"2.814681184\" stroke-dasharray=\"\"/></g><g><g/><text fill=\"black\" stroke=\"none\" font-family=\"sans-serif\" font-size=\"11pt\" font-style=\"normal\" font-weight=\"normal\" text-decoration=\"normal\" x=\"1420.6816570379233\" y=\"121.119249699\" text-anchor=\"start\" dominant-baseline=\"alphabetic\" xml:space=\"preserve\">Database</text></g><path fill=\"none\" stroke=\"none\"/><g><path fill=\"white\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 1638.1532583596395 91.21326211899998 L 1694.258646331702 91.21326211899998 L 1694.258646331702 138.71100709899997 L 1638.1532583596395 138.71100709899997 L 1638.1532583596395 91.21326211899998 Z\" stroke-miterlimit=\"10\" stroke-width=\"2.814681184\" stroke-dasharray=\"\"/></g><g><g/><text fill=\"black\" stroke=\"none\" font-family=\"sans-serif\" font-size=\"11pt\" font-style=\"normal\" font-weight=\"normal\" text-decoration=\"normal\" x=\"1657.2403151386395\" y=\"121.119249699\" text-anchor=\"start\" dominant-baseline=\"alphabetic\" xml:space=\"preserve\">S3</text></g></g><g><g><g><rect fill=\"white\" stroke=\"none\" x=\"109.46242388651693\" y=\"173.89452189899995\" width=\"283.9531558821094\" height=\"22.86928462\"/></g><text fill=\"black\" stroke=\"none\" font-family=\"sans-serif\" font-size=\"11pt\" font-style=\"normal\" font-weight=\"normal\" text-decoration=\"normal\" x=\"112.10118749651693\" y=\"189.72710355899997\" text-anchor=\"start\" dominant-baseline=\"alphabetic\" xml:space=\"preserve\">GET\u00a0/transactions/:transactionId/stateproof</text></g><g><path fill=\"none\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 27.536029151660156 196.76380651899996 L 472.4100149368164 196.76380651899996\" stroke-miterlimit=\"10\" stroke-width=\"1.4659797833333332\" stroke-dasharray=\"\"/><g transform=\"translate(475.3419745034831,196.76380651899996) translate(-475.3419745034831,-196.76380651899996)\"><path fill=\"black\" stroke=\"none\" paint-order=\"stroke fill markers\" d=\" M 460.6821766701497 189.43390760233328 L 475.3419745034831 196.76380651899996 L 460.6821766701497 204.09370543566664 Z\"/></g></g><g><g><rect fill=\"white\" stroke=\"none\" x=\"496.1588874268164\" y=\"223.15144261899997\" width=\"150.3239902326953\" height=\"22.86928462\"/></g><text fill=\"black\" stroke=\"none\" font-family=\"sans-serif\" font-size=\"11pt\" font-style=\"normal\" font-weight=\"normal\" text-decoration=\"normal\" x=\"498.79765103681643\" y=\"238.98402427899998\" text-anchor=\"start\" dominant-baseline=\"alphabetic\" xml:space=\"preserve\">validate\u00a0transaction\u00a0ID</text></g><g><path fill=\"none\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 475.3419745034831 246.02072723899997 L 545.709004103483 246.02072723899997 L 545.709004103483 268.89001185899997 L 478.2739340701497 268.89001185899997\" stroke-miterlimit=\"10\" stroke-width=\"1.4659797833333332\" stroke-dasharray=\"\"/><g transform=\"translate(475.3419745034831,268.89001185899997) translate(-475.3419745034831,-268.89001185899997)\"><path fill=\"black\" stroke=\"none\" paint-order=\"stroke fill markers\" d=\" M 490.00177233681643 261.5601129423333 L 475.3419745034831 268.89001185899997 L 490.00177233681643 276.2199107756666 Z\"/></g></g><g><g><rect fill=\"white\" stroke=\"none\" x=\"732.8910956787696\" y=\"295.277647959\" width=\"461.6193851301563\" height=\"22.86928462\"/></g><text fill=\"black\" stroke=\"none\" font-family=\"sans-serif\" font-size=\"11pt\" font-style=\"normal\" font-weight=\"normal\" text-decoration=\"normal\" x=\"735.5298592887696\" y=\"311.110229619\" text-anchor=\"start\" dominant-baseline=\"alphabetic\" xml:space=\"preserve\">query\u00a0transaction\u00a0table\u00a0for\u00a0consensus_ns\u00a0of\u00a0the\u00a0successful\u00a0transaction</text></g><g><path fill=\"none\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 475.3419745034831 318.14693257899995 L 1449.1276424175458 318.14693257899995\" stroke-miterlimit=\"10\" stroke-width=\"1.4659797833333332\" stroke-dasharray=\"\"/><g transform=\"translate(1452.0596019842123,318.14693257899995) translate(-1452.0596019842123,-318.14693257899995)\"><path fill=\"black\" stroke=\"none\" paint-order=\"stroke fill markers\" d=\" M 1437.399804150879 310.8170336623333 L 1452.0596019842123 318.14693257899995 L 1437.399804150879 325.4768314956666 Z\"/></g></g><g><g><rect fill=\"white\" stroke=\"none\" x=\"855.9332251953712\" y=\"344.53456867899996\" width=\"215.53512609695312\" height=\"22.86928462\"/></g><text fill=\"black\" stroke=\"none\" font-family=\"sans-serif\" font-size=\"11pt\" font-style=\"normal\" font-weight=\"normal\" text-decoration=\"normal\" x=\"858.5719888053711\" y=\"360.367150339\" text-anchor=\"start\" dominant-baseline=\"alphabetic\" xml:space=\"preserve\">consensus_ns\u00a0of\u00a0the\u00a0transaction</text></g><g><path fill=\"none\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 1452.0596019842123 367.40385329899993 L 478.2739340701497 367.40385329899993\" stroke-miterlimit=\"10\" stroke-width=\"1.4659797833333332\" stroke-dasharray=\"7.0367029599999995\"/><g transform=\"translate(475.3419745034831,367.40385329899993) translate(-475.3419745034831,-367.40385329899993)\"><path fill=\"black\" stroke=\"none\" paint-order=\"stroke fill markers\" d=\" M 490.00177233681643 360.0739543823333 L 475.3419745034831 367.40385329899993 L 490.00177233681643 374.7337522156666 Z\"/></g></g><g><g><rect fill=\"white\" stroke=\"none\" x=\"635.5037970947852\" y=\"393.79148939899994\" width=\"656.393982298125\" height=\"22.86928462\"/></g><text fill=\"black\" stroke=\"none\" font-family=\"sans-serif\" font-size=\"11pt\" font-style=\"normal\" font-weight=\"normal\" text-decoration=\"normal\" x=\"638.1425607047852\" y=\"409.62407105899996\" text-anchor=\"start\" dominant-baseline=\"alphabetic\" xml:space=\"preserve\">query\u00a0record_file\u00a0table\u00a0for\u00a0the\u00a0RCD\u00a0file\u00a0where\u00a0consensus_start\u00a0&lt;=\u00a0consensus_ns\u00a0&lt;=\u00a0consensus_end</text></g><g><path fill=\"none\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 475.3419745034831 416.6607740189999 L 1449.1276424175458 416.6607740189999\" stroke-miterlimit=\"10\" stroke-width=\"1.4659797833333332\" stroke-dasharray=\"\"/><g transform=\"translate(1452.0596019842123,416.6607740189999) translate(-1452.0596019842123,-416.6607740189999)\"><path fill=\"black\" stroke=\"none\" paint-order=\"stroke fill markers\" d=\" M 1437.399804150879 409.33087510233327 L 1452.0596019842123 416.6607740189999 L 1437.399804150879 423.99067293566657 Z\"/></g></g><g><g><rect fill=\"white\" stroke=\"none\" x=\"913.4027610230079\" y=\"443.0484101189999\" width=\"100.59605444167968\" height=\"22.86928462\"/></g><text fill=\"black\" stroke=\"none\" font-family=\"sans-serif\" font-size=\"11pt\" font-style=\"normal\" font-weight=\"normal\" text-decoration=\"normal\" x=\"916.0415246330078\" y=\"458.88099177899994\" text-anchor=\"start\" dominant-baseline=\"alphabetic\" xml:space=\"preserve\">RCD\u00a0file\u00a0name</text></g><g><path fill=\"none\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 1452.0596019842123 465.9176947389999 L 478.2739340701497 465.9176947389999\" stroke-miterlimit=\"10\" stroke-width=\"1.4659797833333332\" stroke-dasharray=\"7.0367029599999995\"/><g transform=\"translate(475.3419745034831,465.9176947389999) translate(-475.3419745034831,-465.9176947389999)\"><path fill=\"black\" stroke=\"none\" paint-order=\"stroke fill markers\" d=\" M 490.00177233681643 458.58779582233325 L 475.3419745034831 465.9176947389999 L 490.00177233681643 473.24759365566655 Z\"/></g></g><g><g><rect fill=\"white\" stroke=\"none\" x=\"496.1588874268164\" y=\"492.30533083899996\" width=\"935.0838016340625\" height=\"22.86928462\"/></g><text fill=\"black\" stroke=\"none\" font-family=\"sans-serif\" font-size=\"11pt\" font-style=\"normal\" font-weight=\"normal\" text-decoration=\"normal\" x=\"498.79765103681643\" y=\"508.137912499\" text-anchor=\"start\" dominant-baseline=\"alphabetic\" xml:space=\"preserve\">query\u00a0address_book\u00a0table\u00a0and\u00a0address_book_entry\u00a0table\u00a0(start_consensus_timestamp\u00a0&lt;=\u00a0consensus_ns)\u00a0order\u00a0by\u00a0start_consensus_timestamp</text></g><g><path fill=\"none\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 475.3419745034831 515.1746154589999 L 1449.1276424175458 515.1746154589999\" stroke-miterlimit=\"10\" stroke-width=\"1.4659797833333332\" stroke-dasharray=\"\"/><g transform=\"translate(1452.0596019842123,515.1746154589999) translate(-1452.0596019842123,-515.1746154589999)\"><path fill=\"black\" stroke=\"none\" paint-order=\"stroke fill markers\" d=\" M 1437.399804150879 507.8447165423333 L 1452.0596019842123 515.1746154589999 L 1437.399804150879 522.5045143756666 Z\"/></g></g><g><g><rect fill=\"white\" stroke=\"none\" x=\"708.4172187256446\" y=\"541.562251559\" width=\"510.5671390364063\" height=\"22.86928462\"/></g><text fill=\"black\" stroke=\"none\" font-family=\"sans-serif\" font-size=\"11pt\" font-style=\"normal\" font-weight=\"normal\" text-decoration=\"normal\" x=\"711.0559823356446\" y=\"557.3948332189999\" text-anchor=\"start\" dominant-baseline=\"alphabetic\" xml:space=\"preserve\">address\u00a0books\u00a0and\u00a0corresponding\u00a0nodes\u00a0(file_data,\u00a0node_count,\u00a0list\u00a0of\u00a0nodes)</text></g><g><path fill=\"none\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 1452.0596019842123 564.431536179 L 478.2739340701497 564.431536179\" stroke-miterlimit=\"10\" stroke-width=\"1.4659797833333332\" stroke-dasharray=\"7.0367029599999995\"/><g transform=\"translate(475.3419745034831,564.431536179) translate(-475.3419745034831,-564.431536179)\"><path fill=\"black\" stroke=\"none\" paint-order=\"stroke fill markers\" d=\" M 490.00177233681643 557.1016372623333 L 475.3419745034831 564.431536179 L 490.00177233681643 571.7614350956667 Z\"/></g></g><g><g><rect fill=\"white\" stroke=\"none\" x=\"877.444525986452\" y=\"590.819172279\" width=\"386.65887487625\" height=\"22.86928462\"/></g><text fill=\"black\" stroke=\"none\" font-family=\"sans-serif\" font-size=\"11pt\" font-style=\"normal\" font-weight=\"normal\" text-decoration=\"normal\" x=\"880.083289596452\" y=\"606.651753939\" text-anchor=\"start\" dominant-baseline=\"alphabetic\" xml:space=\"preserve\">download\u00a0signature\u00a0files\u00a0from\u00a0nodes\u00a0in\u00a0latest\u00a0address\u00a0book</text></g><g><path fill=\"none\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 475.3419745034831 613.688456899 L 1663.2739927790042 613.688456899\" stroke-miterlimit=\"10\" stroke-width=\"1.4659797833333332\" stroke-dasharray=\"\"/><g transform=\"translate(1666.2059523456708,613.688456899) translate(-1666.2059523456708,-613.688456899)\"><path fill=\"black\" stroke=\"none\" paint-order=\"stroke fill markers\" d=\" M 1651.5461545123374 606.3585579823333 L 1666.2059523456708 613.688456899 L 1651.5461545123374 621.0183558156667 Z\"/></g></g><g><g><rect fill=\"white\" stroke=\"none\" x=\"954.0407631690692\" y=\"640.076092999\" width=\"233.46640051101562\" height=\"22.86928462\"/></g><text fill=\"black\" stroke=\"none\" font-family=\"sans-serif\" font-size=\"11pt\" font-style=\"normal\" font-weight=\"normal\" text-decoration=\"normal\" x=\"956.6795267790692\" y=\"655.908674659\" text-anchor=\"start\" dominant-baseline=\"alphabetic\" xml:space=\"preserve\">content\u00a0of\u00a0requested\u00a0signature\u00a0files</text></g><g><path fill=\"none\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 1666.2059523456708 662.945377619 L 478.2739340701497 662.945377619\" stroke-miterlimit=\"10\" stroke-width=\"1.4659797833333332\" stroke-dasharray=\"7.0367029599999995\"/><g transform=\"translate(475.3419745034831,662.945377619) translate(-475.3419745034831,-662.945377619)\"><path fill=\"black\" stroke=\"none\" paint-order=\"stroke fill markers\" d=\" M 490.00177233681643 655.6154787023333 L 475.3419745034831 662.945377619 L 490.00177233681643 670.2752765356668 Z\"/></g></g><g><g><rect fill=\"white\" stroke=\"none\" x=\"496.1588874268164\" y=\"689.3330137190001\" width=\"458.3553470442188\" height=\"22.86928462\"/></g><text fill=\"black\" stroke=\"none\" font-family=\"sans-serif\" font-size=\"11pt\" font-style=\"normal\" font-weight=\"normal\" text-decoration=\"normal\" x=\"498.79765103681643\" y=\"705.165595379\" text-anchor=\"start\" dominant-baseline=\"alphabetic\" xml:space=\"preserve\">check\u00a0if\u00a0the\u00a0number\u00a0of\u00a0signature\u00a0files\u00a0can\u00a0prove\u00a0consensus\u00a0is\u00a0reached</text></g><g><path fill=\"none\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 475.3419745034831 712.202298339 L 545.709004103483 712.202298339 L 545.709004103483 735.071582959 L 478.2739340701497 735.071582959\" stroke-miterlimit=\"10\" stroke-width=\"1.4659797833333332\" stroke-dasharray=\"\"/><g transform=\"translate(475.3419745034831,735.071582959) translate(-475.3419745034831,-735.071582959)\"><path fill=\"black\" stroke=\"none\" paint-order=\"stroke fill markers\" d=\" M 490.00177233681643 727.7416840423333 L 475.3419745034831 735.071582959 L 490.00177233681643 742.4014818756667 Z\"/></g></g><g><g><rect fill=\"white\" stroke=\"none\" x=\"990.3077462012958\" y=\"761.459219059\" width=\"160.9324344465625\" height=\"22.86928462\"/></g><text fill=\"black\" stroke=\"none\" font-family=\"sans-serif\" font-size=\"11pt\" font-style=\"normal\" font-weight=\"normal\" text-decoration=\"normal\" x=\"992.9465098112958\" y=\"777.291800719\" text-anchor=\"start\" dominant-baseline=\"alphabetic\" xml:space=\"preserve\">download\u00a0the\u00a0recrod\u00a0file</text></g><g><path fill=\"none\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 475.3419745034831 784.328503679 L 1663.2739927790042 784.328503679\" stroke-miterlimit=\"10\" stroke-width=\"1.4659797833333332\" stroke-dasharray=\"\"/><g transform=\"translate(1666.2059523456708,784.328503679) translate(-1666.2059523456708,-784.328503679)\"><path fill=\"black\" stroke=\"none\" paint-order=\"stroke fill markers\" d=\" M 1651.5461545123374 776.9986047623333 L 1666.2059523456708 784.328503679 L 1651.5461545123374 791.6584025956668 Z\"/></g></g><g><g><rect fill=\"white\" stroke=\"none\" x=\"989.495291977663\" y=\"810.7161397790001\" width=\"162.55734289382812\" height=\"22.86928462\"/></g><text fill=\"black\" stroke=\"none\" font-family=\"sans-serif\" font-size=\"11pt\" font-style=\"normal\" font-weight=\"normal\" text-decoration=\"normal\" x=\"992.1340555876629\" y=\"826.548721439\" text-anchor=\"start\" dominant-baseline=\"alphabetic\" xml:space=\"preserve\">content\u00a0of\u00a0the\u00a0record\u00a0file</text></g><g><path fill=\"none\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 1666.2059523456708 833.5854243990001 L 478.2739340701497 833.5854243990001\" stroke-miterlimit=\"10\" stroke-width=\"1.4659797833333332\" stroke-dasharray=\"7.0367029599999995\"/><g transform=\"translate(475.3419745034831,833.5854243990001) translate(-475.3419745034831,-833.5854243990001)\"><path fill=\"black\" stroke=\"none\" paint-order=\"stroke fill markers\" d=\" M 490.00177233681643 826.2555254823334 L 475.3419745034831 833.5854243990001 L 490.00177233681643 840.9153233156668 Z\"/></g></g><g><g><rect fill=\"white\" stroke=\"none\" x=\"48.35294207499349\" y=\"859.9730604990001\" width=\"406.1721195051563\" height=\"22.86928462\"/></g><text fill=\"black\" stroke=\"none\" font-family=\"sans-serif\" font-size=\"11pt\" font-style=\"normal\" font-weight=\"normal\" text-decoration=\"normal\" x=\"50.99170568499349\" y=\"875.8056421590001\" text-anchor=\"start\" dominant-baseline=\"alphabetic\" xml:space=\"preserve\">JSON\u00a0response\u00a0(record\u00a0file\u00a0+\u00a0address\u00a0books\u00a0+\u00a0signature\u00a0files)</text></g><g><path fill=\"none\" stroke=\"black\" paint-order=\"fill stroke markers\" d=\" M 475.3419745034831 882.8423451190001 L 30.467988718326822 882.8423451190001\" stroke-miterlimit=\"10\" stroke-width=\"1.4659797833333332\" stroke-dasharray=\"7.0367029599999995\"/><g transform=\"translate(27.536029151660156,882.8423451190001) translate(-27.536029151660156,-882.8423451190001)\"><path fill=\"black\" stroke=\"none\" paint-order=\"stroke fill markers\" d=\" M 42.19582698499349 875.5124462023334 L 27.536029151660156 882.8423451190001 L 42.19582698499349 890.1722440356668 Z\"/></g></g></g><g/><g/><g/><g/></g></svg>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzYwODMwNw=="}, "originalCommit": {"oid": "ac0b8533e72ce4ab7d122f0b1ea3269d5538a71e"}, "originalPosition": 1}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyMzk5ODQwOnYy", "diffSide": "RIGHT", "path": "hedera-mirror-rest/config.js", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQxNTo0ODo1OVrOG-Uw5Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQyMzoxNzozN1rOG-i6_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODAwNTA5Mw==", "bodyText": "break this switch that sets the bucketName into its own method that returns a bucketName.\nThen it can be reused by tests and can reduce code duplication", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468005093", "createdAt": "2020-08-10T15:48:59Z", "author": {"login": "Nana-EC"}, "path": "hedera-mirror-rest/config.js", "diffHunk": "@@ -113,12 +116,82 @@ function convertType(value) {\n   return parsedValue;\n }\n \n+function getConfig() {\n+  return config.hedera && config.hedera.mirror ? config.hedera.mirror.rest : config;\n+}\n+\n+function parseStateProofStreamsConfig() {\n+  const config = getConfig();\n+  if (!config.stateproof) {\n+    config.stateproof = {\n+      enabled: false,\n+    };\n+  } else if (!config.stateproof.streams || !config.stateproof.streams.network) {\n+    config.stateproof.streams = { network: 'DEMO', ...config.stateproof.streams };\n+  }\n+\n+  const stateProofConfig = config.stateproof;\n+  const streamsConfig = stateProofConfig.streams;\n+\n+  if (!stateProofConfig.enabled) {\n+    return;\n+  }\n+\n+  // set default bucketName depending on network\n+  switch (streamsConfig.network) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ac0b8533e72ce4ab7d122f0b1ea3269d5538a71e"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODIzNzA1Mw==", "bodyText": "changed it to an object so now there is no switch ... case...", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468237053", "createdAt": "2020-08-10T23:17:37Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-rest/config.js", "diffHunk": "@@ -113,12 +116,82 @@ function convertType(value) {\n   return parsedValue;\n }\n \n+function getConfig() {\n+  return config.hedera && config.hedera.mirror ? config.hedera.mirror.rest : config;\n+}\n+\n+function parseStateProofStreamsConfig() {\n+  const config = getConfig();\n+  if (!config.stateproof) {\n+    config.stateproof = {\n+      enabled: false,\n+    };\n+  } else if (!config.stateproof.streams || !config.stateproof.streams.network) {\n+    config.stateproof.streams = { network: 'DEMO', ...config.stateproof.streams };\n+  }\n+\n+  const stateProofConfig = config.stateproof;\n+  const streamsConfig = stateProofConfig.streams;\n+\n+  if (!stateProofConfig.enabled) {\n+    return;\n+  }\n+\n+  // set default bucketName depending on network\n+  switch (streamsConfig.network) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODAwNTA5Mw=="}, "originalCommit": {"oid": "ac0b8533e72ce4ab7d122f0b1ea3269d5538a71e"}, "originalPosition": 69}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyNDAxNjk5OnYy", "diffSide": "RIGHT", "path": "hedera-mirror-rest/s3client.js", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQxNTo1MzoyNFrOG-U8IA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQyMzoxNzo1N1rOG-i7VA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODAwNzk2OA==", "bodyText": "Export the hardcoded cloudProvider strings S3 and GCP for cleaner reference in other parts of code base such as tests.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468007968", "createdAt": "2020-08-10T15:53:24Z", "author": {"login": "Nana-EC"}, "path": "hedera-mirror-rest/s3client.js", "diffHunk": "@@ -0,0 +1,122 @@\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ *\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+'use strict';\n+\n+const AWS = require('aws-sdk');\n+const querystring = require('querystring');\n+const config = require('./config');\n+const { InvalidConfigError } = require('./errors/invalidConfigError');\n+\n+class S3Client {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ac0b8533e72ce4ab7d122f0b1ea3269d5538a71e"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODIzNzE0MA==", "bodyText": "extracted string values to constants.js", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468237140", "createdAt": "2020-08-10T23:17:57Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-rest/s3client.js", "diffHunk": "@@ -0,0 +1,122 @@\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ *\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+'use strict';\n+\n+const AWS = require('aws-sdk');\n+const querystring = require('querystring');\n+const config = require('./config');\n+const { InvalidConfigError } = require('./errors/invalidConfigError');\n+\n+class S3Client {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODAwNzk2OA=="}, "originalCommit": {"oid": "ac0b8533e72ce4ab7d122f0b1ea3269d5538a71e"}, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyNDA4MTEwOnYy", "diffSide": "RIGHT", "path": "hedera-mirror-rest/__tests__/s3client.test.js", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQxNjowOToyOVrOG-Vi-g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQyMzoxODowNlrOG-i7dg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODAxNzkxNA==", "bodyText": "Pull the following strings from their respective files or from the constants.js after moving them there. Just so it's easier to manage should any changes need to be made\n\n'S3'\n'GCP'\n'recordstreams/record'\n'us-east-3'\n'https://s3.amazonaws.com'\n'https://storage.googleapis.com'", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468017914", "createdAt": "2020-08-10T16:09:29Z", "author": {"login": "Nana-EC"}, "path": "hedera-mirror-rest/__tests__/s3client.test.js", "diffHunk": "@@ -0,0 +1,219 @@\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ *\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+'use strict';\n+\n+const log4js = require('log4js');\n+const AWSMock = require('aws-sdk-mock');\n+const querystring = require('querystring');\n+const { createS3Client } = require('../s3client');\n+const config = require('../config');\n+\n+// create a minimal global logger for createS3Client to log errors.\n+global.logger = log4js.getLogger();\n+\n+const defaultValidStreamsConfig = {\n+  cloudProvider: 'S3',", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ac0b8533e72ce4ab7d122f0b1ea3269d5538a71e"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODIzNzE3NA==", "bodyText": "extracted string values to constants.js", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468237174", "createdAt": "2020-08-10T23:18:06Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-rest/__tests__/s3client.test.js", "diffHunk": "@@ -0,0 +1,219 @@\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ *\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+'use strict';\n+\n+const log4js = require('log4js');\n+const AWSMock = require('aws-sdk-mock');\n+const querystring = require('querystring');\n+const { createS3Client } = require('../s3client');\n+const config = require('../config');\n+\n+// create a minimal global logger for createS3Client to log errors.\n+global.logger = log4js.getLogger();\n+\n+const defaultValidStreamsConfig = {\n+  cloudProvider: 'S3',", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODAxNzkxNA=="}, "originalCommit": {"oid": "ac0b8533e72ce4ab7d122f0b1ea3269d5538a71e"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyODQwOTg0OnYy", "diffSide": "RIGHT", "path": "docs/design/stateproofalpha.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNTo1MjoyNVrOG--V3g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQyMDoxOTo1OVrOG_Hw9w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODY4NjMwMg==", "bodyText": "You can't validate address books are in chronological order if all you have is the file contents. If you had the start time you could.\nSince you said you are not adding the start time here you'd have to update it. I still think we should have it but I'm okay with that being out of scope for this PR.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468686302", "createdAt": "2020-08-11T15:52:25Z", "author": {"login": "Nana-EC"}, "path": "docs/design/stateproofalpha.md", "diffHunk": "@@ -0,0 +1,62 @@\n+# State Proof Alpha Design\n+\n+## Purpose\n+\n+State Proof Alpha provides the data to prove a transaction is valid on Hedera Network. It's the interim solution\n+until [full state proof](https://www.hedera.com/blog/state-proofs-on-hedera) is implemented.\n+\n+## Goals\n+\n+- Provide a State Proof REST API for clients to retrieve the record file containing the transaction, the corresponding\n+signature files, and history of address books up until the point for a transaction to prove its validity\n+\n+\n+## REST API\n+\n+```\n+GET /transactions/:transactionId/stateproof\n+```\n+\n+where `transactionId` is in the format of `shard.realm.num-ssssssssss-nnnnnnnnn`, in which `ssss` are 10 digits seconds\n+and `nnn` are 9 digits nanoseconds of the valid start timestamp of the transaction.\n+\n+The response is in JSON:\n+\n+```json\n+{\n+    \"record_file\": \"record file content\",\n+    \"address_books\": [\n+      \"address book 1 content\",\n+      \"address book 2 content\",\n+      \"...\",\n+      \"address book n content\"\n+    ],\n+    \"signature_files\": {\n+      \"0.0.3\": \"signature file content of node 0.0.3\",\n+      \"0.0.4\": \"signature file content of node 0.0.4\",\n+      \"0.0.n\": \"signature file content of node 0.0.n\"\n+    }\n+}\n+```\n+\n+- All file content is in base64 encoding\n+- Address books are in chronological order\n+\n+Upon receiving the JSON response, a client proves the transaction is valid as follows:\n+\n+1. Validate the address books in chronological order", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2c3e3913e6a42af2973ecacbeb3db15c3f7c0e8"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg0MDY5NQ==", "bodyText": "address book needs enhancement so it can be validated by a client. We will track it with a separate ticket.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468840695", "createdAt": "2020-08-11T20:19:59Z", "author": {"login": "xin-hedera"}, "path": "docs/design/stateproofalpha.md", "diffHunk": "@@ -0,0 +1,62 @@\n+# State Proof Alpha Design\n+\n+## Purpose\n+\n+State Proof Alpha provides the data to prove a transaction is valid on Hedera Network. It's the interim solution\n+until [full state proof](https://www.hedera.com/blog/state-proofs-on-hedera) is implemented.\n+\n+## Goals\n+\n+- Provide a State Proof REST API for clients to retrieve the record file containing the transaction, the corresponding\n+signature files, and history of address books up until the point for a transaction to prove its validity\n+\n+\n+## REST API\n+\n+```\n+GET /transactions/:transactionId/stateproof\n+```\n+\n+where `transactionId` is in the format of `shard.realm.num-ssssssssss-nnnnnnnnn`, in which `ssss` are 10 digits seconds\n+and `nnn` are 9 digits nanoseconds of the valid start timestamp of the transaction.\n+\n+The response is in JSON:\n+\n+```json\n+{\n+    \"record_file\": \"record file content\",\n+    \"address_books\": [\n+      \"address book 1 content\",\n+      \"address book 2 content\",\n+      \"...\",\n+      \"address book n content\"\n+    ],\n+    \"signature_files\": {\n+      \"0.0.3\": \"signature file content of node 0.0.3\",\n+      \"0.0.4\": \"signature file content of node 0.0.4\",\n+      \"0.0.n\": \"signature file content of node 0.0.n\"\n+    }\n+}\n+```\n+\n+- All file content is in base64 encoding\n+- Address books are in chronological order\n+\n+Upon receiving the JSON response, a client proves the transaction is valid as follows:\n+\n+1. Validate the address books in chronological order", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODY4NjMwMg=="}, "originalCommit": {"oid": "e2c3e3913e6a42af2973ecacbeb3db15c3f7c0e8"}, "originalPosition": 47}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyODQzMjQ2OnYy", "diffSide": "RIGHT", "path": "hedera-mirror-rest/__tests__/data/db/stateproof/address_book.sql", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNTo1Nzo1OFrOG--kVg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNTo1Nzo1OFrOG--kVg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODY5MDAwNg==", "bodyText": "nit: can remove if not needed", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468690006", "createdAt": "2020-08-11T15:57:58Z", "author": {"login": "Nana-EC"}, "path": "hedera-mirror-rest/__tests__/data/db/stateproof/address_book.sql", "diffHunk": "@@ -0,0 +1,30 @@\n+--\n+-- PostgreSQL database dump\n+--\n+\n+-- Dumped from database version 9.6.18\n+-- Dumped by pg_dump version 12.3\n+\n+SET statement_timeout = 0;\n+SET lock_timeout = 0;\n+SET idle_in_transaction_session_timeout = 0;\n+SET client_encoding = 'UTF8';\n+SET standard_conforming_strings = on;\n+-- SELECT pg_catalog.set_config('search_path', '', false);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2c3e3913e6a42af2973ecacbeb3db15c3f7c0e8"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyODQzMzc1OnYy", "diffSide": "RIGHT", "path": "hedera-mirror-rest/__tests__/data/db/stateproof/address_book_entry.sql", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNTo1ODoxNlrOG--lJQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQyMDoxNjo0M1rOG_Hqkw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODY5MDIxMw==", "bodyText": "nit: can remove if not needed", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468690213", "createdAt": "2020-08-11T15:58:16Z", "author": {"login": "Nana-EC"}, "path": "hedera-mirror-rest/__tests__/data/db/stateproof/address_book_entry.sql", "diffHunk": "@@ -0,0 +1,40 @@\n+--\n+-- PostgreSQL database dump\n+--\n+\n+-- Dumped from database version 9.6.18\n+-- Dumped by pg_dump version 12.3\n+\n+SET statement_timeout = 0;\n+SET lock_timeout = 0;\n+SET idle_in_transaction_session_timeout = 0;\n+SET client_encoding = 'UTF8';\n+SET standard_conforming_strings = on;\n+-- SELECT pg_catalog.set_config('search_path', '', false);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2c3e3913e6a42af2973ecacbeb3db15c3f7c0e8"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODczODQwNg==", "bodyText": "it's intentional and I should have added comment for it.\nthe line commented out removes the search_path public globally which causes SQL queries in stateproof.js to fail with the error message relation transaction can't be found\nit's auto generated by pg_dump and there is no option in pg_dump to disable it", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468738406", "createdAt": "2020-08-11T17:15:20Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-rest/__tests__/data/db/stateproof/address_book_entry.sql", "diffHunk": "@@ -0,0 +1,40 @@\n+--\n+-- PostgreSQL database dump\n+--\n+\n+-- Dumped from database version 9.6.18\n+-- Dumped by pg_dump version 12.3\n+\n+SET statement_timeout = 0;\n+SET lock_timeout = 0;\n+SET idle_in_transaction_session_timeout = 0;\n+SET client_encoding = 'UTF8';\n+SET standard_conforming_strings = on;\n+-- SELECT pg_catalog.set_config('search_path', '', false);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODY5MDIxMw=="}, "originalCommit": {"oid": "e2c3e3913e6a42af2973ecacbeb3db15c3f7c0e8"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODgzOTA1OQ==", "bodyText": "Understood", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468839059", "createdAt": "2020-08-11T20:16:43Z", "author": {"login": "Nana-EC"}, "path": "hedera-mirror-rest/__tests__/data/db/stateproof/address_book_entry.sql", "diffHunk": "@@ -0,0 +1,40 @@\n+--\n+-- PostgreSQL database dump\n+--\n+\n+-- Dumped from database version 9.6.18\n+-- Dumped by pg_dump version 12.3\n+\n+SET statement_timeout = 0;\n+SET lock_timeout = 0;\n+SET idle_in_transaction_session_timeout = 0;\n+SET client_encoding = 'UTF8';\n+SET standard_conforming_strings = on;\n+-- SELECT pg_catalog.set_config('search_path', '', false);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODY5MDIxMw=="}, "originalCommit": {"oid": "e2c3e3913e6a42af2973ecacbeb3db15c3f7c0e8"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyODQzNTE2OnYy", "diffSide": "RIGHT", "path": "hedera-mirror-rest/__tests__/data/db/stateproof/record_file.sql", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNTo1ODozN1rOG--mEw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNTo1ODozN1rOG--mEw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODY5MDQ1MQ==", "bodyText": "nit: remove if not needed", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468690451", "createdAt": "2020-08-11T15:58:37Z", "author": {"login": "Nana-EC"}, "path": "hedera-mirror-rest/__tests__/data/db/stateproof/record_file.sql", "diffHunk": "@@ -0,0 +1,32 @@\n+--\n+-- PostgreSQL database dump\n+--\n+\n+-- Dumped from database version 9.6.18\n+-- Dumped by pg_dump version 12.3\n+\n+SET statement_timeout = 0;\n+SET lock_timeout = 0;\n+SET idle_in_transaction_session_timeout = 0;\n+SET client_encoding = 'UTF8';\n+SET standard_conforming_strings = on;\n+-- SELECT pg_catalog.set_config('search_path', '', false);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2c3e3913e6a42af2973ecacbeb3db15c3f7c0e8"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyODQzNTk2OnYy", "diffSide": "RIGHT", "path": "hedera-mirror-rest/__tests__/data/db/stateproof/transaction.sql", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNTo1ODo1MVrOG--mlA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNTo1ODo1MVrOG--mlA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODY5MDU4MA==", "bodyText": "nit: remove if not needed", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468690580", "createdAt": "2020-08-11T15:58:51Z", "author": {"login": "Nana-EC"}, "path": "hedera-mirror-rest/__tests__/data/db/stateproof/transaction.sql", "diffHunk": "@@ -0,0 +1,54 @@\n+--\n+-- PostgreSQL database dump\n+--\n+\n+-- Dumped from database version 9.6.18\n+-- Dumped by pg_dump version 12.3\n+\n+SET statement_timeout = 0;\n+SET lock_timeout = 0;\n+SET idle_in_transaction_session_timeout = 0;\n+SET client_encoding = 'UTF8';\n+SET standard_conforming_strings = on;\n+-- SELECT pg_catalog.set_config('search_path', '', false);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2c3e3913e6a42af2973ecacbeb3db15c3f7c0e8"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyODQ3MzY3OnYy", "diffSide": "RIGHT", "path": "hedera-mirror-rest/__tests__/integrationDomainOps.js", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNjowODowMlrOG---BA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNjowODowMlrOG---BA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODY5NjU4MA==", "bodyText": "nit: fs and path added but I don't see usage. Remove if not needed", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468696580", "createdAt": "2020-08-11T16:08:02Z", "author": {"login": "Nana-EC"}, "path": "hedera-mirror-rest/__tests__/integrationDomainOps.js", "diffHunk": "@@ -19,7 +19,9 @@\n  */\n 'use strict';\n \n+const fs = require('fs');", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2c3e3913e6a42af2973ecacbeb3db15c3f7c0e8"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyODQ4ODMyOnYy", "diffSide": "RIGHT", "path": "hedera-mirror-rest/__tests__/specs/stateproof-01-success-result.spec.json", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNjoxMTo0MlrOG-_HeQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNjoxMTo0MlrOG-_HeQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODY5OTAwMQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              \"description\": \"Stateproof api calls with valid transaction ID and success response\",\n          \n          \n            \n              \"description\": \"Stateproof api calls with valid transaction ID and success response. md5sum of the base64-encoded file contents are used instead of base64 strings which are large.\",", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468699001", "createdAt": "2020-08-11T16:11:42Z", "author": {"login": "Nana-EC"}, "path": "hedera-mirror-rest/__tests__/specs/stateproof-01-success-result.spec.json", "diffHunk": "@@ -0,0 +1,25 @@\n+{\n+  \"description\": \"Stateproof api calls with valid transaction ID and success response\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2c3e3913e6a42af2973ecacbeb3db15c3f7c0e8"}, "originalPosition": 2}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyODUwNTYxOnYy", "diffSide": "RIGHT", "path": "hedera-mirror-rest/config.js", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNjoxNTo1OFrOG-_SIA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQyMToxNjo0N1rOG_Jimg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODcwMTcyOA==", "bodyText": "no need for this if you're setting a default above. If anything make sure you have a test case that the default gets set and then you don't need this.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468701728", "createdAt": "2020-08-11T16:15:58Z", "author": {"login": "Nana-EC"}, "path": "hedera-mirror-rest/config.js", "diffHunk": "@@ -113,12 +117,42 @@ function convertType(value) {\n   return parsedValue;\n }\n \n+function getConfig() {\n+  return config.hedera && config.hedera.mirror ? config.hedera.mirror.rest : config;\n+}\n+\n+function parseStateProofStreamsConfig() {\n+  const {stateproof} = getConfig();\n+  if (!stateproof || !stateproof.enabled) {\n+    return;\n+  }\n+\n+  const {streams: streamsConfig} = stateproof;\n+  // set default bucketName depending on network\n+  if (!Object.values(networks).includes(streamsConfig.network)) {\n+    throw new InvalidConfigError(`unknown network ${streamsConfig.network}`);\n+  }\n+\n+  if (!streamsConfig.bucketName) {\n+    streamsConfig.bucketName = defaultBucketNames[streamsConfig.network];\n+  }\n+\n+  if (!streamsConfig.bucketName) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2c3e3913e6a42af2973ecacbeb3db15c3f7c0e8"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODgzOTI1NQ==", "bodyText": "If they choose network=OTHER it has a default of null. So this check still needed", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468839255", "createdAt": "2020-08-11T20:17:08Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-rest/config.js", "diffHunk": "@@ -113,12 +117,42 @@ function convertType(value) {\n   return parsedValue;\n }\n \n+function getConfig() {\n+  return config.hedera && config.hedera.mirror ? config.hedera.mirror.rest : config;\n+}\n+\n+function parseStateProofStreamsConfig() {\n+  const {stateproof} = getConfig();\n+  if (!stateproof || !stateproof.enabled) {\n+    return;\n+  }\n+\n+  const {streams: streamsConfig} = stateproof;\n+  // set default bucketName depending on network\n+  if (!Object.values(networks).includes(streamsConfig.network)) {\n+    throw new InvalidConfigError(`unknown network ${streamsConfig.network}`);\n+  }\n+\n+  if (!streamsConfig.bucketName) {\n+    streamsConfig.bucketName = defaultBucketNames[streamsConfig.network];\n+  }\n+\n+  if (!streamsConfig.bucketName) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODcwMTcyOA=="}, "originalCommit": {"oid": "e2c3e3913e6a42af2973ecacbeb3db15c3f7c0e8"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg2OTc4Ng==", "bodyText": "Maybe add a comment highlighting this is for the OTHER network scenario", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468869786", "createdAt": "2020-08-11T21:16:47Z", "author": {"login": "Nana-EC"}, "path": "hedera-mirror-rest/config.js", "diffHunk": "@@ -113,12 +117,42 @@ function convertType(value) {\n   return parsedValue;\n }\n \n+function getConfig() {\n+  return config.hedera && config.hedera.mirror ? config.hedera.mirror.rest : config;\n+}\n+\n+function parseStateProofStreamsConfig() {\n+  const {stateproof} = getConfig();\n+  if (!stateproof || !stateproof.enabled) {\n+    return;\n+  }\n+\n+  const {streams: streamsConfig} = stateproof;\n+  // set default bucketName depending on network\n+  if (!Object.values(networks).includes(streamsConfig.network)) {\n+    throw new InvalidConfigError(`unknown network ${streamsConfig.network}`);\n+  }\n+\n+  if (!streamsConfig.bucketName) {\n+    streamsConfig.bucketName = defaultBucketNames[streamsConfig.network];\n+  }\n+\n+  if (!streamsConfig.bucketName) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODcwMTcyOA=="}, "originalCommit": {"oid": "e2c3e3913e6a42af2973ecacbeb3db15c3f7c0e8"}, "originalPosition": 77}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyODUxODg2OnYy", "diffSide": "RIGHT", "path": "hedera-mirror-rest/errors/fileDownloadError.js", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNjoxOToxMFrOG-_aNw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNjoxOToxMFrOG-_aNw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODcwMzc5OQ==", "bodyText": "nit: would be useful to have filename substituted into the errorMessage for earlier debugging. Especially in the case where k of n files (where k < n) failed to download.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468703799", "createdAt": "2020-08-11T16:19:10Z", "author": {"login": "Nana-EC"}, "path": "hedera-mirror-rest/errors/fileDownloadError.js", "diffHunk": "@@ -0,0 +1,34 @@\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ *\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+'use strict';\n+\n+const FileDownloadErrorMessage = 'Failed to download file';", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2c3e3913e6a42af2973ecacbeb3db15c3f7c0e8"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyODUyMTE5OnYy", "diffSide": "RIGHT", "path": "hedera-mirror-rest/errors/invalidConfigError.js", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNjoxOTo0NFrOG-_bow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNjoxOTo0NFrOG-_bow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODcwNDE2Mw==", "bodyText": "nit: would be useful to say which config value was invalid", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468704163", "createdAt": "2020-08-11T16:19:44Z", "author": {"login": "Nana-EC"}, "path": "hedera-mirror-rest/errors/invalidConfigError.js", "diffHunk": "@@ -0,0 +1,34 @@\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ *\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+'use strict';\n+\n+const InvalidConfigErrorMessage = 'Invalid config';", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2c3e3913e6a42af2973ecacbeb3db15c3f7c0e8"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyODUzNzczOnYy", "diffSide": "RIGHT", "path": "hedera-mirror-rest/stateproof.js", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNjoyMzo0NVrOG-_loA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQyMTowMDo0M1rOG_JE-Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODcwNjcyMA==", "bodyText": "nit: might be good to say for which consensusNs and therefore which transactionId.\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                throw new NotFoundError('No matching RCD file found');\n          \n          \n            \n                throw new NotFoundError(`No matching RCD file found with ${consensusNs} is in the range`);", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468706720", "createdAt": "2020-08-11T16:23:45Z", "author": {"login": "Nana-EC"}, "path": "hedera-mirror-rest/stateproof.js", "diffHunk": "@@ -0,0 +1,265 @@\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ *\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+'use strict';\n+\n+const _ = require('lodash');\n+const config = require('./config');\n+const constants = require('./constants');\n+const EntityId = require('./entityId');\n+const TransactionId = require('./transactionId');\n+const s3client = require('./s3client');\n+const {DbError} = require('./errors/dbError');\n+const {NotFoundError} = require('./errors/notFoundError');\n+const {FileDownloadError} = require('./errors/fileDownloadError');\n+\n+/**\n+ * Get the consensus_ns of the transaction. Throws exception if no such successful transaction found or multiple such\n+ * transactions found.\n+ * @param {TransactionId} transactionId\n+ * @returns {Promise<String>} consensus_ns of the successful transaction if found\n+ */\n+let getSuccessfulTransactionConsensusNs = async (transactionId) => {\n+  const sqlParams = [transactionId.getEntityId().getEncodedId(), transactionId.getValidStartNs()];\n+  const sqlQuery = `SELECT consensus_ns\n+       FROM transaction\n+       WHERE payer_account_id = $1\n+         AND valid_start_ns = $2\n+         AND result = 22`; // only the successful transaction\n+  if (logger.isTraceEnabled()) {\n+    logger.trace(`getSuccessfulTransactionConsensusNs: ${sqlQuery}, ${JSON.stringify(sqlParams)}`);\n+  }\n+\n+  let result;\n+  try {\n+    result = await pool.query(sqlQuery, sqlParams);\n+  } catch (err) {\n+    throw new DbError(err.message);\n+  }\n+\n+  const {rows} = result;\n+  if (_.isEmpty(rows)) {\n+    throw new NotFoundError('Transaction not found');\n+  } else if (rows.length > 1) {\n+    throw new DbError('Invalid state, more than one transaction found');\n+  }\n+\n+  return _.first(rows).consensus_ns;\n+};\n+\n+/**\n+ * Get the RCD file name where consensusNs is in the range [consensus_start, consensus_end]. Throws exception if no\n+ * such RCD file found.\n+ * @param {string} consensusNs consensus timestamp within the range of the RCD file to search\n+ * @returns {Promise<String>} RCD file name\n+ */\n+let getRCDFileNameByConsensusNs = async (consensusNs) => {\n+  const sqlParams = [consensusNs];\n+  const sqlQuery = `SELECT name\n+       FROM record_file\n+       WHERE consensus_end >= $1\n+       LIMIT 1`;\n+  if (logger.isTraceEnabled()) {\n+    logger.trace(`getRCDFileNameByConsensusNs: ${sqlQuery}, ${JSON.stringify(sqlParams)}`);\n+  }\n+\n+  let result;\n+  try {\n+    result = await pool.query(sqlQuery, sqlParams);\n+  } catch (err) {\n+    throw new DbError(err.message);\n+  }\n+\n+  const {rows} = result;\n+  if (_.isEmpty(rows)) {\n+    throw new NotFoundError('No matching RCD file found');", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2c3e3913e6a42af2973ecacbeb3db15c3f7c0e8"}, "originalPosition": 92}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg2MjIwMQ==", "bodyText": "updated as suggested", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468862201", "createdAt": "2020-08-11T21:00:43Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-rest/stateproof.js", "diffHunk": "@@ -0,0 +1,265 @@\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ *\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+'use strict';\n+\n+const _ = require('lodash');\n+const config = require('./config');\n+const constants = require('./constants');\n+const EntityId = require('./entityId');\n+const TransactionId = require('./transactionId');\n+const s3client = require('./s3client');\n+const {DbError} = require('./errors/dbError');\n+const {NotFoundError} = require('./errors/notFoundError');\n+const {FileDownloadError} = require('./errors/fileDownloadError');\n+\n+/**\n+ * Get the consensus_ns of the transaction. Throws exception if no such successful transaction found or multiple such\n+ * transactions found.\n+ * @param {TransactionId} transactionId\n+ * @returns {Promise<String>} consensus_ns of the successful transaction if found\n+ */\n+let getSuccessfulTransactionConsensusNs = async (transactionId) => {\n+  const sqlParams = [transactionId.getEntityId().getEncodedId(), transactionId.getValidStartNs()];\n+  const sqlQuery = `SELECT consensus_ns\n+       FROM transaction\n+       WHERE payer_account_id = $1\n+         AND valid_start_ns = $2\n+         AND result = 22`; // only the successful transaction\n+  if (logger.isTraceEnabled()) {\n+    logger.trace(`getSuccessfulTransactionConsensusNs: ${sqlQuery}, ${JSON.stringify(sqlParams)}`);\n+  }\n+\n+  let result;\n+  try {\n+    result = await pool.query(sqlQuery, sqlParams);\n+  } catch (err) {\n+    throw new DbError(err.message);\n+  }\n+\n+  const {rows} = result;\n+  if (_.isEmpty(rows)) {\n+    throw new NotFoundError('Transaction not found');\n+  } else if (rows.length > 1) {\n+    throw new DbError('Invalid state, more than one transaction found');\n+  }\n+\n+  return _.first(rows).consensus_ns;\n+};\n+\n+/**\n+ * Get the RCD file name where consensusNs is in the range [consensus_start, consensus_end]. Throws exception if no\n+ * such RCD file found.\n+ * @param {string} consensusNs consensus timestamp within the range of the RCD file to search\n+ * @returns {Promise<String>} RCD file name\n+ */\n+let getRCDFileNameByConsensusNs = async (consensusNs) => {\n+  const sqlParams = [consensusNs];\n+  const sqlQuery = `SELECT name\n+       FROM record_file\n+       WHERE consensus_end >= $1\n+       LIMIT 1`;\n+  if (logger.isTraceEnabled()) {\n+    logger.trace(`getRCDFileNameByConsensusNs: ${sqlQuery}, ${JSON.stringify(sqlParams)}`);\n+  }\n+\n+  let result;\n+  try {\n+    result = await pool.query(sqlQuery, sqlParams);\n+  } catch (err) {\n+    throw new DbError(err.message);\n+  }\n+\n+  const {rows} = result;\n+  if (_.isEmpty(rows)) {\n+    throw new NotFoundError('No matching RCD file found');", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODcwNjcyMA=="}, "originalCommit": {"oid": "e2c3e3913e6a42af2973ecacbeb3db15c3f7c0e8"}, "originalPosition": 92}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyODU0MTI0OnYy", "diffSide": "RIGHT", "path": "hedera-mirror-rest/stateproof.js", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNjoyNDo0M1rOG-_n4g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQyMTowMDo1OFrOG_JFdA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODcwNzI5OA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              // Get the chain of address books whose consensus_timestamp <= consensusNs, also aggregate the corresponding\n          \n          \n            \n              // Get the chain of address books whose start_consensus_timestamp <= consensusNs, also aggregate the corresponding", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468707298", "createdAt": "2020-08-11T16:24:43Z", "author": {"login": "Nana-EC"}, "path": "hedera-mirror-rest/stateproof.js", "diffHunk": "@@ -0,0 +1,265 @@\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ *\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+'use strict';\n+\n+const _ = require('lodash');\n+const config = require('./config');\n+const constants = require('./constants');\n+const EntityId = require('./entityId');\n+const TransactionId = require('./transactionId');\n+const s3client = require('./s3client');\n+const {DbError} = require('./errors/dbError');\n+const {NotFoundError} = require('./errors/notFoundError');\n+const {FileDownloadError} = require('./errors/fileDownloadError');\n+\n+/**\n+ * Get the consensus_ns of the transaction. Throws exception if no such successful transaction found or multiple such\n+ * transactions found.\n+ * @param {TransactionId} transactionId\n+ * @returns {Promise<String>} consensus_ns of the successful transaction if found\n+ */\n+let getSuccessfulTransactionConsensusNs = async (transactionId) => {\n+  const sqlParams = [transactionId.getEntityId().getEncodedId(), transactionId.getValidStartNs()];\n+  const sqlQuery = `SELECT consensus_ns\n+       FROM transaction\n+       WHERE payer_account_id = $1\n+         AND valid_start_ns = $2\n+         AND result = 22`; // only the successful transaction\n+  if (logger.isTraceEnabled()) {\n+    logger.trace(`getSuccessfulTransactionConsensusNs: ${sqlQuery}, ${JSON.stringify(sqlParams)}`);\n+  }\n+\n+  let result;\n+  try {\n+    result = await pool.query(sqlQuery, sqlParams);\n+  } catch (err) {\n+    throw new DbError(err.message);\n+  }\n+\n+  const {rows} = result;\n+  if (_.isEmpty(rows)) {\n+    throw new NotFoundError('Transaction not found');\n+  } else if (rows.length > 1) {\n+    throw new DbError('Invalid state, more than one transaction found');\n+  }\n+\n+  return _.first(rows).consensus_ns;\n+};\n+\n+/**\n+ * Get the RCD file name where consensusNs is in the range [consensus_start, consensus_end]. Throws exception if no\n+ * such RCD file found.\n+ * @param {string} consensusNs consensus timestamp within the range of the RCD file to search\n+ * @returns {Promise<String>} RCD file name\n+ */\n+let getRCDFileNameByConsensusNs = async (consensusNs) => {\n+  const sqlParams = [consensusNs];\n+  const sqlQuery = `SELECT name\n+       FROM record_file\n+       WHERE consensus_end >= $1\n+       LIMIT 1`;\n+  if (logger.isTraceEnabled()) {\n+    logger.trace(`getRCDFileNameByConsensusNs: ${sqlQuery}, ${JSON.stringify(sqlParams)}`);\n+  }\n+\n+  let result;\n+  try {\n+    result = await pool.query(sqlQuery, sqlParams);\n+  } catch (err) {\n+    throw new DbError(err.message);\n+  }\n+\n+  const {rows} = result;\n+  if (_.isEmpty(rows)) {\n+    throw new NotFoundError('No matching RCD file found');\n+  }\n+\n+  return _.first(rows).name;\n+};\n+\n+/**\n+ * Get the chain of address books and node account IDs at or before consensusNs.\n+ * @param {String} consensusNs\n+ * @returns {Promise<Object>} List of base64 address book data in chronological order and list of node account IDs.\n+ */\n+let getAddressBooksAndNodeAccountIdsByConsensusNs = async (consensusNs) => {\n+  // Get the chain of address books whose consensus_timestamp <= consensusNs, also aggregate the corresponding", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2c3e3913e6a42af2973ecacbeb3db15c3f7c0e8"}, "originalPosition": 104}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg2MjMyNA==", "bodyText": "updated as suggested", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468862324", "createdAt": "2020-08-11T21:00:58Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-rest/stateproof.js", "diffHunk": "@@ -0,0 +1,265 @@\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ *\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+'use strict';\n+\n+const _ = require('lodash');\n+const config = require('./config');\n+const constants = require('./constants');\n+const EntityId = require('./entityId');\n+const TransactionId = require('./transactionId');\n+const s3client = require('./s3client');\n+const {DbError} = require('./errors/dbError');\n+const {NotFoundError} = require('./errors/notFoundError');\n+const {FileDownloadError} = require('./errors/fileDownloadError');\n+\n+/**\n+ * Get the consensus_ns of the transaction. Throws exception if no such successful transaction found or multiple such\n+ * transactions found.\n+ * @param {TransactionId} transactionId\n+ * @returns {Promise<String>} consensus_ns of the successful transaction if found\n+ */\n+let getSuccessfulTransactionConsensusNs = async (transactionId) => {\n+  const sqlParams = [transactionId.getEntityId().getEncodedId(), transactionId.getValidStartNs()];\n+  const sqlQuery = `SELECT consensus_ns\n+       FROM transaction\n+       WHERE payer_account_id = $1\n+         AND valid_start_ns = $2\n+         AND result = 22`; // only the successful transaction\n+  if (logger.isTraceEnabled()) {\n+    logger.trace(`getSuccessfulTransactionConsensusNs: ${sqlQuery}, ${JSON.stringify(sqlParams)}`);\n+  }\n+\n+  let result;\n+  try {\n+    result = await pool.query(sqlQuery, sqlParams);\n+  } catch (err) {\n+    throw new DbError(err.message);\n+  }\n+\n+  const {rows} = result;\n+  if (_.isEmpty(rows)) {\n+    throw new NotFoundError('Transaction not found');\n+  } else if (rows.length > 1) {\n+    throw new DbError('Invalid state, more than one transaction found');\n+  }\n+\n+  return _.first(rows).consensus_ns;\n+};\n+\n+/**\n+ * Get the RCD file name where consensusNs is in the range [consensus_start, consensus_end]. Throws exception if no\n+ * such RCD file found.\n+ * @param {string} consensusNs consensus timestamp within the range of the RCD file to search\n+ * @returns {Promise<String>} RCD file name\n+ */\n+let getRCDFileNameByConsensusNs = async (consensusNs) => {\n+  const sqlParams = [consensusNs];\n+  const sqlQuery = `SELECT name\n+       FROM record_file\n+       WHERE consensus_end >= $1\n+       LIMIT 1`;\n+  if (logger.isTraceEnabled()) {\n+    logger.trace(`getRCDFileNameByConsensusNs: ${sqlQuery}, ${JSON.stringify(sqlParams)}`);\n+  }\n+\n+  let result;\n+  try {\n+    result = await pool.query(sqlQuery, sqlParams);\n+  } catch (err) {\n+    throw new DbError(err.message);\n+  }\n+\n+  const {rows} = result;\n+  if (_.isEmpty(rows)) {\n+    throw new NotFoundError('No matching RCD file found');\n+  }\n+\n+  return _.first(rows).name;\n+};\n+\n+/**\n+ * Get the chain of address books and node account IDs at or before consensusNs.\n+ * @param {String} consensusNs\n+ * @returns {Promise<Object>} List of base64 address book data in chronological order and list of node account IDs.\n+ */\n+let getAddressBooksAndNodeAccountIdsByConsensusNs = async (consensusNs) => {\n+  // Get the chain of address books whose consensus_timestamp <= consensusNs, also aggregate the corresponding", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODcwNzI5OA=="}, "originalCommit": {"oid": "e2c3e3913e6a42af2973ecacbeb3db15c3f7c0e8"}, "originalPosition": 104}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkyODU0MzI3OnYy", "diffSide": "RIGHT", "path": "hedera-mirror-rest/stateproof.js", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQxNjoyNToxNFrOG-_pPw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQyMTowMTowNFrOG_JFnw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODcwNzY0Nw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              // node account ids from table address_book_entry\n          \n          \n            \n              // memo and node account ids from table address_book_entry", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468707647", "createdAt": "2020-08-11T16:25:14Z", "author": {"login": "Nana-EC"}, "path": "hedera-mirror-rest/stateproof.js", "diffHunk": "@@ -0,0 +1,265 @@\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ *\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+'use strict';\n+\n+const _ = require('lodash');\n+const config = require('./config');\n+const constants = require('./constants');\n+const EntityId = require('./entityId');\n+const TransactionId = require('./transactionId');\n+const s3client = require('./s3client');\n+const {DbError} = require('./errors/dbError');\n+const {NotFoundError} = require('./errors/notFoundError');\n+const {FileDownloadError} = require('./errors/fileDownloadError');\n+\n+/**\n+ * Get the consensus_ns of the transaction. Throws exception if no such successful transaction found or multiple such\n+ * transactions found.\n+ * @param {TransactionId} transactionId\n+ * @returns {Promise<String>} consensus_ns of the successful transaction if found\n+ */\n+let getSuccessfulTransactionConsensusNs = async (transactionId) => {\n+  const sqlParams = [transactionId.getEntityId().getEncodedId(), transactionId.getValidStartNs()];\n+  const sqlQuery = `SELECT consensus_ns\n+       FROM transaction\n+       WHERE payer_account_id = $1\n+         AND valid_start_ns = $2\n+         AND result = 22`; // only the successful transaction\n+  if (logger.isTraceEnabled()) {\n+    logger.trace(`getSuccessfulTransactionConsensusNs: ${sqlQuery}, ${JSON.stringify(sqlParams)}`);\n+  }\n+\n+  let result;\n+  try {\n+    result = await pool.query(sqlQuery, sqlParams);\n+  } catch (err) {\n+    throw new DbError(err.message);\n+  }\n+\n+  const {rows} = result;\n+  if (_.isEmpty(rows)) {\n+    throw new NotFoundError('Transaction not found');\n+  } else if (rows.length > 1) {\n+    throw new DbError('Invalid state, more than one transaction found');\n+  }\n+\n+  return _.first(rows).consensus_ns;\n+};\n+\n+/**\n+ * Get the RCD file name where consensusNs is in the range [consensus_start, consensus_end]. Throws exception if no\n+ * such RCD file found.\n+ * @param {string} consensusNs consensus timestamp within the range of the RCD file to search\n+ * @returns {Promise<String>} RCD file name\n+ */\n+let getRCDFileNameByConsensusNs = async (consensusNs) => {\n+  const sqlParams = [consensusNs];\n+  const sqlQuery = `SELECT name\n+       FROM record_file\n+       WHERE consensus_end >= $1\n+       LIMIT 1`;\n+  if (logger.isTraceEnabled()) {\n+    logger.trace(`getRCDFileNameByConsensusNs: ${sqlQuery}, ${JSON.stringify(sqlParams)}`);\n+  }\n+\n+  let result;\n+  try {\n+    result = await pool.query(sqlQuery, sqlParams);\n+  } catch (err) {\n+    throw new DbError(err.message);\n+  }\n+\n+  const {rows} = result;\n+  if (_.isEmpty(rows)) {\n+    throw new NotFoundError('No matching RCD file found');\n+  }\n+\n+  return _.first(rows).name;\n+};\n+\n+/**\n+ * Get the chain of address books and node account IDs at or before consensusNs.\n+ * @param {String} consensusNs\n+ * @returns {Promise<Object>} List of base64 address book data in chronological order and list of node account IDs.\n+ */\n+let getAddressBooksAndNodeAccountIdsByConsensusNs = async (consensusNs) => {\n+  // Get the chain of address books whose consensus_timestamp <= consensusNs, also aggregate the corresponding\n+  // node account ids from table address_book_entry", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2c3e3913e6a42af2973ecacbeb3db15c3f7c0e8"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg2MjM2Nw==", "bodyText": "updated as suggested", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/934#discussion_r468862367", "createdAt": "2020-08-11T21:01:04Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-rest/stateproof.js", "diffHunk": "@@ -0,0 +1,265 @@\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ *\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+'use strict';\n+\n+const _ = require('lodash');\n+const config = require('./config');\n+const constants = require('./constants');\n+const EntityId = require('./entityId');\n+const TransactionId = require('./transactionId');\n+const s3client = require('./s3client');\n+const {DbError} = require('./errors/dbError');\n+const {NotFoundError} = require('./errors/notFoundError');\n+const {FileDownloadError} = require('./errors/fileDownloadError');\n+\n+/**\n+ * Get the consensus_ns of the transaction. Throws exception if no such successful transaction found or multiple such\n+ * transactions found.\n+ * @param {TransactionId} transactionId\n+ * @returns {Promise<String>} consensus_ns of the successful transaction if found\n+ */\n+let getSuccessfulTransactionConsensusNs = async (transactionId) => {\n+  const sqlParams = [transactionId.getEntityId().getEncodedId(), transactionId.getValidStartNs()];\n+  const sqlQuery = `SELECT consensus_ns\n+       FROM transaction\n+       WHERE payer_account_id = $1\n+         AND valid_start_ns = $2\n+         AND result = 22`; // only the successful transaction\n+  if (logger.isTraceEnabled()) {\n+    logger.trace(`getSuccessfulTransactionConsensusNs: ${sqlQuery}, ${JSON.stringify(sqlParams)}`);\n+  }\n+\n+  let result;\n+  try {\n+    result = await pool.query(sqlQuery, sqlParams);\n+  } catch (err) {\n+    throw new DbError(err.message);\n+  }\n+\n+  const {rows} = result;\n+  if (_.isEmpty(rows)) {\n+    throw new NotFoundError('Transaction not found');\n+  } else if (rows.length > 1) {\n+    throw new DbError('Invalid state, more than one transaction found');\n+  }\n+\n+  return _.first(rows).consensus_ns;\n+};\n+\n+/**\n+ * Get the RCD file name where consensusNs is in the range [consensus_start, consensus_end]. Throws exception if no\n+ * such RCD file found.\n+ * @param {string} consensusNs consensus timestamp within the range of the RCD file to search\n+ * @returns {Promise<String>} RCD file name\n+ */\n+let getRCDFileNameByConsensusNs = async (consensusNs) => {\n+  const sqlParams = [consensusNs];\n+  const sqlQuery = `SELECT name\n+       FROM record_file\n+       WHERE consensus_end >= $1\n+       LIMIT 1`;\n+  if (logger.isTraceEnabled()) {\n+    logger.trace(`getRCDFileNameByConsensusNs: ${sqlQuery}, ${JSON.stringify(sqlParams)}`);\n+  }\n+\n+  let result;\n+  try {\n+    result = await pool.query(sqlQuery, sqlParams);\n+  } catch (err) {\n+    throw new DbError(err.message);\n+  }\n+\n+  const {rows} = result;\n+  if (_.isEmpty(rows)) {\n+    throw new NotFoundError('No matching RCD file found');\n+  }\n+\n+  return _.first(rows).name;\n+};\n+\n+/**\n+ * Get the chain of address books and node account IDs at or before consensusNs.\n+ * @param {String} consensusNs\n+ * @returns {Promise<Object>} List of base64 address book data in chronological order and list of node account IDs.\n+ */\n+let getAddressBooksAndNodeAccountIdsByConsensusNs = async (consensusNs) => {\n+  // Get the chain of address books whose consensus_timestamp <= consensusNs, also aggregate the corresponding\n+  // node account ids from table address_book_entry", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODcwNzY0Nw=="}, "originalCommit": {"oid": "e2c3e3913e6a42af2973ecacbeb3db15c3f7c0e8"}, "originalPosition": 105}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 932, "cost": 1, "resetAt": "2021-11-12T20:28:25Z"}}}