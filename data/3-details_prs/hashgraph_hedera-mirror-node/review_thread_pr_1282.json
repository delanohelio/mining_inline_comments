{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTI0ODA5NDk1", "number": 1282, "reviewThreads": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQyMDozNjozMVrOE7tBZw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QxNToyMTozM1rOE8Q6Cw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMxMDM5MDc5OnYy", "diffSide": "RIGHT", "path": "hedera-mirror-grpc/src/main/java/com/hedera/mirror/grpc/retriever/RetrieverProperties.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQyMDozNjozMVrOH3f75A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQyMTo0MDozNVrOH3hsCw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzk1Njk2NA==", "bodyText": "Can we add a DurationMin?", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1282#discussion_r527956964", "createdAt": "2020-11-20T20:36:31Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-grpc/src/main/java/com/hedera/mirror/grpc/retriever/RetrieverProperties.java", "diffHunk": "@@ -45,4 +45,13 @@\n \n     @NotNull\n     private Duration timeout = Duration.ofSeconds(60L);\n+\n+    @Min(1000)\n+    private int unthrottledMaxPageSize = 5000;\n+\n+    @NotNull", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c573c3e5790b9aeca9c2ade50ae812f12ba150b7"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzk4NTY3NQ==", "bodyText": "sure", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1282#discussion_r527985675", "createdAt": "2020-11-20T21:40:35Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-grpc/src/main/java/com/hedera/mirror/grpc/retriever/RetrieverProperties.java", "diffHunk": "@@ -45,4 +45,13 @@\n \n     @NotNull\n     private Duration timeout = Duration.ofSeconds(60L);\n+\n+    @Min(1000)\n+    private int unthrottledMaxPageSize = 5000;\n+\n+    @NotNull", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzk1Njk2NA=="}, "originalCommit": {"oid": "c573c3e5790b9aeca9c2ade50ae812f12ba150b7"}, "originalPosition": 8}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMxMDM5MzgzOnYy", "diffSide": "RIGHT", "path": "hedera-mirror-grpc/src/main/java/com/hedera/mirror/grpc/retriever/RetrieverProperties.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQyMDozNzozM1rOH3f9qA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQyMTo0MDo0MlrOH3hsMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzk1NzQxNg==", "bodyText": "Can we add a nested object to group these and simplify the naming?", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1282#discussion_r527957416", "createdAt": "2020-11-20T20:37:33Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-grpc/src/main/java/com/hedera/mirror/grpc/retriever/RetrieverProperties.java", "diffHunk": "@@ -45,4 +45,13 @@\n \n     @NotNull\n     private Duration timeout = Duration.ofSeconds(60L);\n+\n+    @Min(1000)\n+    private int unthrottledMaxPageSize = 5000;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c573c3e5790b9aeca9c2ade50ae812f12ba150b7"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzk4NTcxMw==", "bodyText": "will do", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1282#discussion_r527985713", "createdAt": "2020-11-20T21:40:42Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-grpc/src/main/java/com/hedera/mirror/grpc/retriever/RetrieverProperties.java", "diffHunk": "@@ -45,4 +45,13 @@\n \n     @NotNull\n     private Duration timeout = Duration.ofSeconds(60L);\n+\n+    @Min(1000)\n+    private int unthrottledMaxPageSize = 5000;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzk1NzQxNg=="}, "originalCommit": {"oid": "c573c3e5790b9aeca9c2ade50ae812f12ba150b7"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMxMDQ1NzIyOnYy", "diffSide": "RIGHT", "path": "hedera-mirror-grpc/src/main/java/com/hedera/mirror/grpc/retriever/PollingTopicMessageRetriever.java", "isResolved": true, "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQyMDo1OTo1NlrOH3gj1w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQyMzoxMzozMlrOH3jtoA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzk2NzE5MQ==", "bodyText": "Is there a scenario where missing messages could return less than page size and not be complete?", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1282#discussion_r527967191", "createdAt": "2020-11-20T20:59:56Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-grpc/src/main/java/com/hedera/mirror/grpc/retriever/PollingTopicMessageRetriever.java", "diffHunk": "@@ -98,19 +98,45 @@ public PollingTopicMessageRetriever(RetrieverProperties retrieverProperties,\n     private class PollingContext {\n \n         private final TopicMessageFilter filter;\n+        private final boolean throttled;\n+        private final Duration frequency;\n+        private final int maxPageSize;\n+        private final long numRepeats;\n         private final AtomicLong pageSize = new AtomicLong(0L);\n         private final Stopwatch stopwatch = Stopwatch.createStarted();\n         private final AtomicLong total = new AtomicLong(0L);\n         private volatile TopicMessage last;\n \n+        public PollingContext(TopicMessageFilter filter, boolean throttled) {\n+            this.filter = filter;\n+            this.throttled = throttled;\n+\n+            if (throttled) {\n+                numRepeats = Long.MAX_VALUE;\n+                frequency = retrieverProperties.getPollingFrequency();\n+                maxPageSize = retrieverProperties.getMaxPageSize();\n+            } else {\n+                numRepeats = retrieverProperties.getUnthrottledMaxPolls();\n+                frequency = retrieverProperties.getUnthrottledPollingFrequency();\n+                maxPageSize = retrieverProperties.getUnthrottledMaxPageSize();\n+            }\n+        }\n+\n         /**\n          * Checks if this publisher is complete by comparing if the number of results in the last page was less than the\n-         * page size. This avoids the extra query if we were to just check if last page was empty.\n+         * page size or if the limit has reached if it's set. This avoids the extra query if we were to just check\n+         * if last page was empty.\n          *\n          * @return whether all historic messages have been returned\n          */\n         boolean isComplete() {\n-            return pageSize.get() < retrieverProperties.getMaxPageSize();\n+            boolean limitHit = filter.hasLimit() && filter.getLimit() == total.get();\n+\n+            if (throttled) {\n+                return pageSize.get() < retrieverProperties.getMaxPageSize() || limitHit;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c573c3e5790b9aeca9c2ade50ae812f12ba150b7"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzk4NjUzNw==", "bodyText": "yes. when tps is low, and the listener misses messages of multiple record files, one poll might get the missing messages of one record file from db, the number of messages might be less than the page size and still we need more polls to fill in the gap", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1282#discussion_r527986537", "createdAt": "2020-11-20T21:42:42Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-grpc/src/main/java/com/hedera/mirror/grpc/retriever/PollingTopicMessageRetriever.java", "diffHunk": "@@ -98,19 +98,45 @@ public PollingTopicMessageRetriever(RetrieverProperties retrieverProperties,\n     private class PollingContext {\n \n         private final TopicMessageFilter filter;\n+        private final boolean throttled;\n+        private final Duration frequency;\n+        private final int maxPageSize;\n+        private final long numRepeats;\n         private final AtomicLong pageSize = new AtomicLong(0L);\n         private final Stopwatch stopwatch = Stopwatch.createStarted();\n         private final AtomicLong total = new AtomicLong(0L);\n         private volatile TopicMessage last;\n \n+        public PollingContext(TopicMessageFilter filter, boolean throttled) {\n+            this.filter = filter;\n+            this.throttled = throttled;\n+\n+            if (throttled) {\n+                numRepeats = Long.MAX_VALUE;\n+                frequency = retrieverProperties.getPollingFrequency();\n+                maxPageSize = retrieverProperties.getMaxPageSize();\n+            } else {\n+                numRepeats = retrieverProperties.getUnthrottledMaxPolls();\n+                frequency = retrieverProperties.getUnthrottledPollingFrequency();\n+                maxPageSize = retrieverProperties.getUnthrottledMaxPageSize();\n+            }\n+        }\n+\n         /**\n          * Checks if this publisher is complete by comparing if the number of results in the last page was less than the\n-         * page size. This avoids the extra query if we were to just check if last page was empty.\n+         * page size or if the limit has reached if it's set. This avoids the extra query if we were to just check\n+         * if last page was empty.\n          *\n          * @return whether all historic messages have been returned\n          */\n         boolean isComplete() {\n-            return pageSize.get() < retrieverProperties.getMaxPageSize();\n+            boolean limitHit = filter.hasLimit() && filter.getLimit() == total.get();\n+\n+            if (throttled) {\n+                return pageSize.get() < retrieverProperties.getMaxPageSize() || limitHit;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzk2NzE5MQ=="}, "originalCommit": {"oid": "c573c3e5790b9aeca9c2ade50ae812f12ba150b7"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODAwMDE3Mg==", "bodyText": "I don't think that's true in practice as we use transactions to commit the entire record at once and we don't send to redis until that transaction is complete. So there should be an invariant that all messages before the message that triggers the missing messages flow are already in the database. But probably fine to keep this to be extra safe.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1282#discussion_r528000172", "createdAt": "2020-11-20T22:16:26Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-grpc/src/main/java/com/hedera/mirror/grpc/retriever/PollingTopicMessageRetriever.java", "diffHunk": "@@ -98,19 +98,45 @@ public PollingTopicMessageRetriever(RetrieverProperties retrieverProperties,\n     private class PollingContext {\n \n         private final TopicMessageFilter filter;\n+        private final boolean throttled;\n+        private final Duration frequency;\n+        private final int maxPageSize;\n+        private final long numRepeats;\n         private final AtomicLong pageSize = new AtomicLong(0L);\n         private final Stopwatch stopwatch = Stopwatch.createStarted();\n         private final AtomicLong total = new AtomicLong(0L);\n         private volatile TopicMessage last;\n \n+        public PollingContext(TopicMessageFilter filter, boolean throttled) {\n+            this.filter = filter;\n+            this.throttled = throttled;\n+\n+            if (throttled) {\n+                numRepeats = Long.MAX_VALUE;\n+                frequency = retrieverProperties.getPollingFrequency();\n+                maxPageSize = retrieverProperties.getMaxPageSize();\n+            } else {\n+                numRepeats = retrieverProperties.getUnthrottledMaxPolls();\n+                frequency = retrieverProperties.getUnthrottledPollingFrequency();\n+                maxPageSize = retrieverProperties.getUnthrottledMaxPageSize();\n+            }\n+        }\n+\n         /**\n          * Checks if this publisher is complete by comparing if the number of results in the last page was less than the\n-         * page size. This avoids the extra query if we were to just check if last page was empty.\n+         * page size or if the limit has reached if it's set. This avoids the extra query if we were to just check\n+         * if last page was empty.\n          *\n          * @return whether all historic messages have been returned\n          */\n         boolean isComplete() {\n-            return pageSize.get() < retrieverProperties.getMaxPageSize();\n+            boolean limitHit = filter.hasLimit() && filter.getLimit() == total.get();\n+\n+            if (throttled) {\n+                return pageSize.get() < retrieverProperties.getMaxPageSize() || limitHit;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzk2NzE5MQ=="}, "originalCommit": {"oid": "c573c3e5790b9aeca9c2ade50ae812f12ba150b7"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODAwNzY4Nw==", "bodyText": "umm, my understanding is we first publish all topic messages to the channel, then commit the db transaction.\nSqlEntityListener:\n\n  \n    \n      hedera-mirror-node/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java\n    \n    \n        Lines 183 to 199\n      in\n      a7d4932\n    \n    \n    \n    \n\n        \n          \n           private void executeBatches() { \n        \n\n        \n          \n               Connection connection = null; \n        \n\n        \n          \n            \n        \n\n        \n          \n               try { \n        \n\n        \n          \n                   connection = DataSourceUtils.getConnection(dataSource); \n        \n\n        \n          \n                   Stopwatch stopwatch = Stopwatch.createStarted(); \n        \n\n        \n          \n                   transactionPgCopy.copy(transactions, connection); \n        \n\n        \n          \n                   cryptoTransferPgCopy.copy(cryptoTransfers, connection); \n        \n\n        \n          \n                   nonFeeTransferPgCopy.copy(nonFeeTransfers, connection); \n        \n\n        \n          \n                   fileDataPgCopy.copy(fileData, connection); \n        \n\n        \n          \n                   contractResultPgCopy.copy(contractResults, connection); \n        \n\n        \n          \n                   liveHashPgCopy.copy(liveHashes, connection); \n        \n\n        \n          \n                   topicMessagePgCopy.copy(topicMessages, connection); \n        \n\n        \n          \n                   tokenTransferPgCopy.copy(tokenTransfers, connection); \n        \n\n        \n          \n                   persistEntities(); \n        \n\n        \n          \n                   log.info(\"Completed batch inserts in {}\", stopwatch); \n        \n\n        \n          \n                   eventPublisher.publishEvent(new EntityBatchSaveEvent(this)); \n        \n    \n  \n\n\nRedisEntityListener:\n\n  \n    \n      hedera-mirror-node/hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/redis/RedisEntityListener.java\n    \n    \n        Lines 83 to 92\n      in\n      a7d4932\n    \n    \n    \n    \n\n        \n          \n           @Override \n        \n\n        \n          \n           @EventListener \n        \n\n        \n          \n           public void onSave(EntityBatchSaveEvent event) { \n        \n\n        \n          \n               try { \n        \n\n        \n          \n                   if (isEnabled()) { \n        \n\n        \n          \n                       Stopwatch stopwatch = Stopwatch.createStarted(); \n        \n\n        \n          \n                       timer.record(() -> redisOperations.executePipelined(callback())); \n        \n\n        \n          \n                       log.info(\"Finished notifying {} messages in {}\", topicMessages.size(), stopwatch); \n        \n\n        \n          \n                   } \n        \n\n        \n          \n               } catch (Exception e) {", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1282#discussion_r528007687", "createdAt": "2020-11-20T22:38:01Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-grpc/src/main/java/com/hedera/mirror/grpc/retriever/PollingTopicMessageRetriever.java", "diffHunk": "@@ -98,19 +98,45 @@ public PollingTopicMessageRetriever(RetrieverProperties retrieverProperties,\n     private class PollingContext {\n \n         private final TopicMessageFilter filter;\n+        private final boolean throttled;\n+        private final Duration frequency;\n+        private final int maxPageSize;\n+        private final long numRepeats;\n         private final AtomicLong pageSize = new AtomicLong(0L);\n         private final Stopwatch stopwatch = Stopwatch.createStarted();\n         private final AtomicLong total = new AtomicLong(0L);\n         private volatile TopicMessage last;\n \n+        public PollingContext(TopicMessageFilter filter, boolean throttled) {\n+            this.filter = filter;\n+            this.throttled = throttled;\n+\n+            if (throttled) {\n+                numRepeats = Long.MAX_VALUE;\n+                frequency = retrieverProperties.getPollingFrequency();\n+                maxPageSize = retrieverProperties.getMaxPageSize();\n+            } else {\n+                numRepeats = retrieverProperties.getUnthrottledMaxPolls();\n+                frequency = retrieverProperties.getUnthrottledPollingFrequency();\n+                maxPageSize = retrieverProperties.getUnthrottledMaxPageSize();\n+            }\n+        }\n+\n         /**\n          * Checks if this publisher is complete by comparing if the number of results in the last page was less than the\n-         * page size. This avoids the extra query if we were to just check if last page was empty.\n+         * page size or if the limit has reached if it's set. This avoids the extra query if we were to just check\n+         * if last page was empty.\n          *\n          * @return whether all historic messages have been returned\n          */\n         boolean isComplete() {\n-            return pageSize.get() < retrieverProperties.getMaxPageSize();\n+            boolean limitHit = filter.hasLimit() && filter.getLimit() == total.get();\n+\n+            if (throttled) {\n+                return pageSize.get() < retrieverProperties.getMaxPageSize() || limitHit;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzk2NzE5MQ=="}, "originalCommit": {"oid": "c573c3e5790b9aeca9c2ade50ae812f12ba150b7"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODAwOTI0OA==", "bodyText": "No, it's the exact opposite. Invoking eventPublisher.publishEvent(new EntityBatchSaveEvent(this)) after persisting to db will directly call RedisEntityListener.onSave().", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1282#discussion_r528009248", "createdAt": "2020-11-20T22:42:43Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-grpc/src/main/java/com/hedera/mirror/grpc/retriever/PollingTopicMessageRetriever.java", "diffHunk": "@@ -98,19 +98,45 @@ public PollingTopicMessageRetriever(RetrieverProperties retrieverProperties,\n     private class PollingContext {\n \n         private final TopicMessageFilter filter;\n+        private final boolean throttled;\n+        private final Duration frequency;\n+        private final int maxPageSize;\n+        private final long numRepeats;\n         private final AtomicLong pageSize = new AtomicLong(0L);\n         private final Stopwatch stopwatch = Stopwatch.createStarted();\n         private final AtomicLong total = new AtomicLong(0L);\n         private volatile TopicMessage last;\n \n+        public PollingContext(TopicMessageFilter filter, boolean throttled) {\n+            this.filter = filter;\n+            this.throttled = throttled;\n+\n+            if (throttled) {\n+                numRepeats = Long.MAX_VALUE;\n+                frequency = retrieverProperties.getPollingFrequency();\n+                maxPageSize = retrieverProperties.getMaxPageSize();\n+            } else {\n+                numRepeats = retrieverProperties.getUnthrottledMaxPolls();\n+                frequency = retrieverProperties.getUnthrottledPollingFrequency();\n+                maxPageSize = retrieverProperties.getUnthrottledMaxPageSize();\n+            }\n+        }\n+\n         /**\n          * Checks if this publisher is complete by comparing if the number of results in the last page was less than the\n-         * page size. This avoids the extra query if we were to just check if last page was empty.\n+         * page size or if the limit has reached if it's set. This avoids the extra query if we were to just check\n+         * if last page was empty.\n          *\n          * @return whether all historic messages have been returned\n          */\n         boolean isComplete() {\n-            return pageSize.get() < retrieverProperties.getMaxPageSize();\n+            boolean limitHit = filter.hasLimit() && filter.getLimit() == total.get();\n+\n+            if (throttled) {\n+                return pageSize.get() < retrieverProperties.getMaxPageSize() || limitHit;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzk2NzE5MQ=="}, "originalCommit": {"oid": "c573c3e5790b9aeca9c2ade50ae812f12ba150b7"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODAxMDIyMw==", "bodyText": "Also note that SqlEntityListener has @Order(0) on it, so it will be invoked before @Order(3) RedisEntityListener via the CompositeEntityListener", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1282#discussion_r528010223", "createdAt": "2020-11-20T22:45:36Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-grpc/src/main/java/com/hedera/mirror/grpc/retriever/PollingTopicMessageRetriever.java", "diffHunk": "@@ -98,19 +98,45 @@ public PollingTopicMessageRetriever(RetrieverProperties retrieverProperties,\n     private class PollingContext {\n \n         private final TopicMessageFilter filter;\n+        private final boolean throttled;\n+        private final Duration frequency;\n+        private final int maxPageSize;\n+        private final long numRepeats;\n         private final AtomicLong pageSize = new AtomicLong(0L);\n         private final Stopwatch stopwatch = Stopwatch.createStarted();\n         private final AtomicLong total = new AtomicLong(0L);\n         private volatile TopicMessage last;\n \n+        public PollingContext(TopicMessageFilter filter, boolean throttled) {\n+            this.filter = filter;\n+            this.throttled = throttled;\n+\n+            if (throttled) {\n+                numRepeats = Long.MAX_VALUE;\n+                frequency = retrieverProperties.getPollingFrequency();\n+                maxPageSize = retrieverProperties.getMaxPageSize();\n+            } else {\n+                numRepeats = retrieverProperties.getUnthrottledMaxPolls();\n+                frequency = retrieverProperties.getUnthrottledPollingFrequency();\n+                maxPageSize = retrieverProperties.getUnthrottledMaxPageSize();\n+            }\n+        }\n+\n         /**\n          * Checks if this publisher is complete by comparing if the number of results in the last page was less than the\n-         * page size. This avoids the extra query if we were to just check if last page was empty.\n+         * page size or if the limit has reached if it's set. This avoids the extra query if we were to just check\n+         * if last page was empty.\n          *\n          * @return whether all historic messages have been returned\n          */\n         boolean isComplete() {\n-            return pageSize.get() < retrieverProperties.getMaxPageSize();\n+            boolean limitHit = filter.hasLimit() && filter.getLimit() == total.get();\n+\n+            if (throttled) {\n+                return pageSize.get() < retrieverProperties.getMaxPageSize() || limitHit;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzk2NzE5MQ=="}, "originalCommit": {"oid": "c573c3e5790b9aeca9c2ade50ae812f12ba150b7"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODAxNjAwNQ==", "bodyText": "my opinion is the transaction COMMIT happens after all messages are published to redis.\n2020-11-20 22:58:45,754 INFO  [scheduling-3] c.h.m.i.p.r.e.s.SqlEntityListener Inserted 4 entities in 32.72 ms\n2020-11-20 22:58:45,754 INFO  [scheduling-3] c.h.m.i.p.r.e.s.SqlEntityListener Completed batch inserts in 40.80 ms\n2020-11-20 22:58:45,778 INFO  [scheduling-3] c.h.m.i.p.r.e.r.RedisEntityListener Finished notifying 0 messages in 22.80 ms\n2020-11-20 22:58:45,781 DEBUG [scheduling-3] o.s.o.j.JpaTransactionManager Found thread-bound EntityManager [SessionImpl(2014749906<open>)] for JPA transaction\n2020-11-20 22:58:45,781 DEBUG [scheduling-3] o.s.o.j.JpaTransactionManager Participating in existing transaction\n2020-11-20 22:58:45,784 DEBUG [scheduling-3] o.s.o.j.JpaTransactionManager Found thread-bound EntityManager [SessionImpl(2014749906<open>)] for JPA transaction\n2020-11-20 22:58:45,784 DEBUG [scheduling-3] o.s.o.j.JpaTransactionManager Participating in existing transaction\nHibernate: \n    update\n        t_application_status \n    set\n        status_value=? \n    where\n        status_code=?\n2020-11-20 22:58:45,788 INFO  [scheduling-3] c.h.m.i.p.r.RecordFileParser Finished parsing 1 transactions from record file /var/lib/hedera-mirror-importer/recordstreams/valid/2019-10-11T13_35_39.807083001Z.rcd in 106ms (9/s). Success: true\n2020-11-20 22:58:45,788 DEBUG [scheduling-3] o.s.o.j.JpaTransactionManager Initiating transaction commit\n2020-11-20 22:58:45,789 DEBUG [scheduling-3] o.s.o.j.JpaTransactionManager Committing JPA transaction on EntityManager [SessionImpl(2014749906<open>)]\n2020-11-20 22:58:45,794 DEBUG [scheduling-3] o.s.o.j.JpaTransactionManager Closing JPA EntityManager [SessionImpl(2014749906<open>)] after transaction```", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1282#discussion_r528016005", "createdAt": "2020-11-20T23:03:32Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-grpc/src/main/java/com/hedera/mirror/grpc/retriever/PollingTopicMessageRetriever.java", "diffHunk": "@@ -98,19 +98,45 @@ public PollingTopicMessageRetriever(RetrieverProperties retrieverProperties,\n     private class PollingContext {\n \n         private final TopicMessageFilter filter;\n+        private final boolean throttled;\n+        private final Duration frequency;\n+        private final int maxPageSize;\n+        private final long numRepeats;\n         private final AtomicLong pageSize = new AtomicLong(0L);\n         private final Stopwatch stopwatch = Stopwatch.createStarted();\n         private final AtomicLong total = new AtomicLong(0L);\n         private volatile TopicMessage last;\n \n+        public PollingContext(TopicMessageFilter filter, boolean throttled) {\n+            this.filter = filter;\n+            this.throttled = throttled;\n+\n+            if (throttled) {\n+                numRepeats = Long.MAX_VALUE;\n+                frequency = retrieverProperties.getPollingFrequency();\n+                maxPageSize = retrieverProperties.getMaxPageSize();\n+            } else {\n+                numRepeats = retrieverProperties.getUnthrottledMaxPolls();\n+                frequency = retrieverProperties.getUnthrottledPollingFrequency();\n+                maxPageSize = retrieverProperties.getUnthrottledMaxPageSize();\n+            }\n+        }\n+\n         /**\n          * Checks if this publisher is complete by comparing if the number of results in the last page was less than the\n-         * page size. This avoids the extra query if we were to just check if last page was empty.\n+         * page size or if the limit has reached if it's set. This avoids the extra query if we were to just check\n+         * if last page was empty.\n          *\n          * @return whether all historic messages have been returned\n          */\n         boolean isComplete() {\n-            return pageSize.get() < retrieverProperties.getMaxPageSize();\n+            boolean limitHit = filter.hasLimit() && filter.getLimit() == total.get();\n+\n+            if (throttled) {\n+                return pageSize.get() < retrieverProperties.getMaxPageSize() || limitHit;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzk2NzE5MQ=="}, "originalCommit": {"oid": "c573c3e5790b9aeca9c2ade50ae812f12ba150b7"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODAxODg0OA==", "bodyText": "True, I guess the commit doesn't occur until the outer wrapped @Transactional method completes.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1282#discussion_r528018848", "createdAt": "2020-11-20T23:13:32Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-grpc/src/main/java/com/hedera/mirror/grpc/retriever/PollingTopicMessageRetriever.java", "diffHunk": "@@ -98,19 +98,45 @@ public PollingTopicMessageRetriever(RetrieverProperties retrieverProperties,\n     private class PollingContext {\n \n         private final TopicMessageFilter filter;\n+        private final boolean throttled;\n+        private final Duration frequency;\n+        private final int maxPageSize;\n+        private final long numRepeats;\n         private final AtomicLong pageSize = new AtomicLong(0L);\n         private final Stopwatch stopwatch = Stopwatch.createStarted();\n         private final AtomicLong total = new AtomicLong(0L);\n         private volatile TopicMessage last;\n \n+        public PollingContext(TopicMessageFilter filter, boolean throttled) {\n+            this.filter = filter;\n+            this.throttled = throttled;\n+\n+            if (throttled) {\n+                numRepeats = Long.MAX_VALUE;\n+                frequency = retrieverProperties.getPollingFrequency();\n+                maxPageSize = retrieverProperties.getMaxPageSize();\n+            } else {\n+                numRepeats = retrieverProperties.getUnthrottledMaxPolls();\n+                frequency = retrieverProperties.getUnthrottledPollingFrequency();\n+                maxPageSize = retrieverProperties.getUnthrottledMaxPageSize();\n+            }\n+        }\n+\n         /**\n          * Checks if this publisher is complete by comparing if the number of results in the last page was less than the\n-         * page size. This avoids the extra query if we were to just check if last page was empty.\n+         * page size or if the limit has reached if it's set. This avoids the extra query if we were to just check\n+         * if last page was empty.\n          *\n          * @return whether all historic messages have been returned\n          */\n         boolean isComplete() {\n-            return pageSize.get() < retrieverProperties.getMaxPageSize();\n+            boolean limitHit = filter.hasLimit() && filter.getLimit() == total.get();\n+\n+            if (throttled) {\n+                return pageSize.get() < retrieverProperties.getMaxPageSize() || limitHit;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzk2NzE5MQ=="}, "originalCommit": {"oid": "c573c3e5790b9aeca9c2ade50ae812f12ba150b7"}, "originalPosition": 79}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMxMDUyNjA1OnYy", "diffSide": "RIGHT", "path": "docs/configuration.md", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQyMToyNDo1MVrOH3hNvA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQyMTo1NDozMVrOH3iB2w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzk3NzkxNg==", "bodyText": "This equals 250K TPS. Perhaps we should lower the limits a bit. Also, 5K might be a bit high for page size depending upon how large the messages are. At 6K message size a 5K poll would return 30MB+ of data. Perhaps we should keep max page size at 1000 and just increase polling frequency?", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1282#discussion_r527977916", "createdAt": "2020-11-20T21:24:51Z", "author": {"login": "steven-sheehy"}, "path": "docs/configuration.md", "diffHunk": "@@ -174,9 +174,12 @@ value, it is recommended to only populate overridden properties in the custom `a\n | `hedera.mirror.grpc.port`                                   | 5600             | The GRPC API port                                                                              |\n | `hedera.mirror.grpc.retriever.enabled`                      | true             | Whether to retrieve historical massages or not                                                 |\n | `hedera.mirror.grpc.retriever.maxPageSize`                  | 1000             | The maximum number of messages the retriever can return in a single call to the database       |\n-| `hedera.mirror.grpc.retriever.pollingFrequency`             | 2s               | How often to polling for historical messages. Can accept duration units like `50ms`, `10s` etc |\n+| `hedera.mirror.grpc.retriever.pollingFrequency`             | 2s               | How often to poll for historical messages. Can accept duration units like `50ms`, `10s` etc    |\n | `hedera.mirror.grpc.retriever.threadMultiplier`             | 4                | Multiplied by the CPU count to calculate the number of retriever threads                       |\n | `hedera.mirror.grpc.retriever.timeout`                      | 60s              | How long to wait between emission of messages before returning an error                        |\n+| `hedera.mirror.grpc.retriever.unthrottledMaxPageSize`       | 5000             | The maximum number of messages the retriever can return in a single call to the database when unthrottled |", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c573c3e5790b9aeca9c2ade50ae812f12ba150b7"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzk5MTI1OQ==", "bodyText": "it depends on how fast the db is and how fast our whole flux pipeline is. 20ms is how long we wait after the previous flux sequence is drained, it will not get to 50 db queries per second when each or some of queries return a lot of data.\nThe numbers I saw were around 20k/s with importer ingesting at 10k tps.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1282#discussion_r527991259", "createdAt": "2020-11-20T21:54:31Z", "author": {"login": "xin-hedera"}, "path": "docs/configuration.md", "diffHunk": "@@ -174,9 +174,12 @@ value, it is recommended to only populate overridden properties in the custom `a\n | `hedera.mirror.grpc.port`                                   | 5600             | The GRPC API port                                                                              |\n | `hedera.mirror.grpc.retriever.enabled`                      | true             | Whether to retrieve historical massages or not                                                 |\n | `hedera.mirror.grpc.retriever.maxPageSize`                  | 1000             | The maximum number of messages the retriever can return in a single call to the database       |\n-| `hedera.mirror.grpc.retriever.pollingFrequency`             | 2s               | How often to polling for historical messages. Can accept duration units like `50ms`, `10s` etc |\n+| `hedera.mirror.grpc.retriever.pollingFrequency`             | 2s               | How often to poll for historical messages. Can accept duration units like `50ms`, `10s` etc    |\n | `hedera.mirror.grpc.retriever.threadMultiplier`             | 4                | Multiplied by the CPU count to calculate the number of retriever threads                       |\n | `hedera.mirror.grpc.retriever.timeout`                      | 60s              | How long to wait between emission of messages before returning an error                        |\n+| `hedera.mirror.grpc.retriever.unthrottledMaxPageSize`       | 5000             | The maximum number of messages the retriever can return in a single call to the database when unthrottled |", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzk3NzkxNg=="}, "originalCommit": {"oid": "c573c3e5790b9aeca9c2ade50ae812f12ba150b7"}, "originalPosition": 8}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMxMDU0ODQxOnYy", "diffSide": "RIGHT", "path": "hedera-mirror-grpc/src/main/java/com/hedera/mirror/grpc/retriever/PollingTopicMessageRetriever.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQyMTozMTowMFrOH3hcJg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQyMjowODoxN1rOH3iYjA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzk4MTYwNg==", "bodyText": "What happens when unthrottled max polls is reached but there are still messages? PollingTopicMessageRetriever will complete but will TopicMessageServiceImpl ever complete? Will it error? We should add a test if possible.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1282#discussion_r527981606", "createdAt": "2020-11-20T21:31:00Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-grpc/src/main/java/com/hedera/mirror/grpc/retriever/PollingTopicMessageRetriever.java", "diffHunk": "@@ -98,19 +98,45 @@ public PollingTopicMessageRetriever(RetrieverProperties retrieverProperties,\n     private class PollingContext {\n \n         private final TopicMessageFilter filter;\n+        private final boolean throttled;\n+        private final Duration frequency;\n+        private final int maxPageSize;\n+        private final long numRepeats;\n         private final AtomicLong pageSize = new AtomicLong(0L);\n         private final Stopwatch stopwatch = Stopwatch.createStarted();\n         private final AtomicLong total = new AtomicLong(0L);\n         private volatile TopicMessage last;\n \n+        public PollingContext(TopicMessageFilter filter, boolean throttled) {\n+            this.filter = filter;\n+            this.throttled = throttled;\n+\n+            if (throttled) {\n+                numRepeats = Long.MAX_VALUE;\n+                frequency = retrieverProperties.getPollingFrequency();\n+                maxPageSize = retrieverProperties.getMaxPageSize();\n+            } else {\n+                numRepeats = retrieverProperties.getUnthrottledMaxPolls();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c573c3e5790b9aeca9c2ade50ae812f12ba150b7"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzk5MjUwMA==", "bodyText": "TopicMessageServiceImpl will error with IllegalStateException \"Encountered out of order messages\". I'll add a test for this scenario.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1282#discussion_r527992500", "createdAt": "2020-11-20T21:57:15Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-grpc/src/main/java/com/hedera/mirror/grpc/retriever/PollingTopicMessageRetriever.java", "diffHunk": "@@ -98,19 +98,45 @@ public PollingTopicMessageRetriever(RetrieverProperties retrieverProperties,\n     private class PollingContext {\n \n         private final TopicMessageFilter filter;\n+        private final boolean throttled;\n+        private final Duration frequency;\n+        private final int maxPageSize;\n+        private final long numRepeats;\n         private final AtomicLong pageSize = new AtomicLong(0L);\n         private final Stopwatch stopwatch = Stopwatch.createStarted();\n         private final AtomicLong total = new AtomicLong(0L);\n         private volatile TopicMessage last;\n \n+        public PollingContext(TopicMessageFilter filter, boolean throttled) {\n+            this.filter = filter;\n+            this.throttled = throttled;\n+\n+            if (throttled) {\n+                numRepeats = Long.MAX_VALUE;\n+                frequency = retrieverProperties.getPollingFrequency();\n+                maxPageSize = retrieverProperties.getMaxPageSize();\n+            } else {\n+                numRepeats = retrieverProperties.getUnthrottledMaxPolls();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzk4MTYwNg=="}, "originalCommit": {"oid": "c573c3e5790b9aeca9c2ade50ae812f12ba150b7"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzk5NzA2OA==", "bodyText": "I see, because we always have the current message which triggered the missing message flow and concat that, it should generate that error always. I think we do have a test for that already.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1282#discussion_r527997068", "createdAt": "2020-11-20T22:08:17Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-grpc/src/main/java/com/hedera/mirror/grpc/retriever/PollingTopicMessageRetriever.java", "diffHunk": "@@ -98,19 +98,45 @@ public PollingTopicMessageRetriever(RetrieverProperties retrieverProperties,\n     private class PollingContext {\n \n         private final TopicMessageFilter filter;\n+        private final boolean throttled;\n+        private final Duration frequency;\n+        private final int maxPageSize;\n+        private final long numRepeats;\n         private final AtomicLong pageSize = new AtomicLong(0L);\n         private final Stopwatch stopwatch = Stopwatch.createStarted();\n         private final AtomicLong total = new AtomicLong(0L);\n         private volatile TopicMessage last;\n \n+        public PollingContext(TopicMessageFilter filter, boolean throttled) {\n+            this.filter = filter;\n+            this.throttled = throttled;\n+\n+            if (throttled) {\n+                numRepeats = Long.MAX_VALUE;\n+                frequency = retrieverProperties.getPollingFrequency();\n+                maxPageSize = retrieverProperties.getMaxPageSize();\n+            } else {\n+                numRepeats = retrieverProperties.getUnthrottledMaxPolls();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzk4MTYwNg=="}, "originalCommit": {"oid": "c573c3e5790b9aeca9c2ade50ae812f12ba150b7"}, "originalPosition": 60}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMxMDU1MDIzOnYy", "diffSide": "RIGHT", "path": "hedera-mirror-grpc/src/main/java/com/hedera/mirror/grpc/retriever/PollingTopicMessageRetriever.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQyMTozMTo0M1rOH3hdUA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQyMzoxNzo0NVrOH3jyUw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzk4MTkwNA==", "bodyText": "Should the throttled have a lower value than Long.MAX_VALUE\nIt's likely in the unthrottled cases the value would be less than that, especially with a default of 12", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1282#discussion_r527981904", "createdAt": "2020-11-20T21:31:43Z", "author": {"login": "Nana-EC"}, "path": "hedera-mirror-grpc/src/main/java/com/hedera/mirror/grpc/retriever/PollingTopicMessageRetriever.java", "diffHunk": "@@ -98,19 +98,45 @@ public PollingTopicMessageRetriever(RetrieverProperties retrieverProperties,\n     private class PollingContext {\n \n         private final TopicMessageFilter filter;\n+        private final boolean throttled;\n+        private final Duration frequency;\n+        private final int maxPageSize;\n+        private final long numRepeats;\n         private final AtomicLong pageSize = new AtomicLong(0L);\n         private final Stopwatch stopwatch = Stopwatch.createStarted();\n         private final AtomicLong total = new AtomicLong(0L);\n         private volatile TopicMessage last;\n \n+        public PollingContext(TopicMessageFilter filter, boolean throttled) {\n+            this.filter = filter;\n+            this.throttled = throttled;\n+\n+            if (throttled) {\n+                numRepeats = Long.MAX_VALUE;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c573c3e5790b9aeca9c2ade50ae812f12ba150b7"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzk4OTI3NA==", "bodyText": "when throttled, the repeats of Long.MAX_VALUE matches the old behavior.\nthe old behavior is, the retriever is used to obtain historical messages at a throttled speed, e.g., 500/s\n\nif there are enough historical messages in db, we should let it repeat forever\nif the polling ends up getting all historical messages in db, a query from the db would return less than max page size rows, the context.isComplete() will be true, and the whole repeat will stop & the flux completes, then in TopicMessageService, the flux moves on to incomingMessages", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1282#discussion_r527989274", "createdAt": "2020-11-20T21:49:23Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-grpc/src/main/java/com/hedera/mirror/grpc/retriever/PollingTopicMessageRetriever.java", "diffHunk": "@@ -98,19 +98,45 @@ public PollingTopicMessageRetriever(RetrieverProperties retrieverProperties,\n     private class PollingContext {\n \n         private final TopicMessageFilter filter;\n+        private final boolean throttled;\n+        private final Duration frequency;\n+        private final int maxPageSize;\n+        private final long numRepeats;\n         private final AtomicLong pageSize = new AtomicLong(0L);\n         private final Stopwatch stopwatch = Stopwatch.createStarted();\n         private final AtomicLong total = new AtomicLong(0L);\n         private volatile TopicMessage last;\n \n+        public PollingContext(TopicMessageFilter filter, boolean throttled) {\n+            this.filter = filter;\n+            this.throttled = throttled;\n+\n+            if (throttled) {\n+                numRepeats = Long.MAX_VALUE;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzk4MTkwNA=="}, "originalCommit": {"oid": "c573c3e5790b9aeca9c2ade50ae812f12ba150b7"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODAyMDA1MQ==", "bodyText": "Yep, I realize the old behavior had this. Just noting that in a throttled case you might expect it to be less than the unthrottled case. That's fine though", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1282#discussion_r528020051", "createdAt": "2020-11-20T23:17:45Z", "author": {"login": "Nana-EC"}, "path": "hedera-mirror-grpc/src/main/java/com/hedera/mirror/grpc/retriever/PollingTopicMessageRetriever.java", "diffHunk": "@@ -98,19 +98,45 @@ public PollingTopicMessageRetriever(RetrieverProperties retrieverProperties,\n     private class PollingContext {\n \n         private final TopicMessageFilter filter;\n+        private final boolean throttled;\n+        private final Duration frequency;\n+        private final int maxPageSize;\n+        private final long numRepeats;\n         private final AtomicLong pageSize = new AtomicLong(0L);\n         private final Stopwatch stopwatch = Stopwatch.createStarted();\n         private final AtomicLong total = new AtomicLong(0L);\n         private volatile TopicMessage last;\n \n+        public PollingContext(TopicMessageFilter filter, boolean throttled) {\n+            this.filter = filter;\n+            this.throttled = throttled;\n+\n+            if (throttled) {\n+                numRepeats = Long.MAX_VALUE;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzk4MTkwNA=="}, "originalCommit": {"oid": "c573c3e5790b9aeca9c2ade50ae812f12ba150b7"}, "originalPosition": 56}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMxNjI2NzA5OnYy", "diffSide": "RIGHT", "path": "hedera-mirror-grpc/src/main/java/com/hedera/mirror/grpc/retriever/RetrieverProperties.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QxNToyMDo1MFrOH4SMsQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QxNToyMDo1MFrOH4SMsQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODc4MDQ2NQ==", "bodyText": "@NotNull", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1282#discussion_r528780465", "createdAt": "2020-11-23T15:20:50Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-grpc/src/main/java/com/hedera/mirror/grpc/retriever/RetrieverProperties.java", "diffHunk": "@@ -45,4 +46,19 @@\n \n     @NotNull\n     private Duration timeout = Duration.ofSeconds(60L);\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "67302f30f3e66fa97be63e48ccb095b7ddbf8015"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMxNjI3MDE5OnYy", "diffSide": "RIGHT", "path": "hedera-mirror-grpc/src/main/java/com/hedera/mirror/grpc/retriever/RetrieverProperties.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QxNToyMTozM1rOH4SOwg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QxNToyMTozM1rOH4SOwg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODc4MDk5NA==", "bodyText": "@NotNull", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1282#discussion_r528780994", "createdAt": "2020-11-23T15:21:33Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-grpc/src/main/java/com/hedera/mirror/grpc/retriever/RetrieverProperties.java", "diffHunk": "@@ -45,4 +46,19 @@\n \n     @NotNull\n     private Duration timeout = Duration.ofSeconds(60L);\n+\n+    private UnthrottledProperties unthrottled = new UnthrottledProperties();\n+\n+    @Data\n+    public static class UnthrottledProperties {\n+\n+        @Min(1000)\n+        private int maxPageSize = 5000;\n+\n+        @Min(4)\n+        private long maxPolls = 12;\n+\n+        @DurationMin(millis = 10)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "67302f30f3e66fa97be63e48ccb095b7ddbf8015"}, "originalPosition": 24}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1454, "cost": 1, "resetAt": "2021-11-12T20:28:25Z"}}}