{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTQzNzU4ODY5", "number": 1382, "title": "Refactor Record File Reader", "bodyText": "Detailed description:\n\nAdd interface RecordFileReader\nImplement RecordFileReaderImplV1 and RecordFileReaderImplV2 for version 1 and version 2 record files\nImplement CompositeRecordFileReader\n\nWhich issue(s) this PR fixes:\nFixes #1369\nSpecial notes for your reviewer:\nChecklist\n\n Documentation added\n Tests updated", "createdAt": "2020-12-21T22:30:30Z", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1382", "merged": true, "mergeCommit": {"oid": "a56ea83364b2c8e38746a5a5048555dad80741d3"}, "closed": true, "closedAt": "2021-01-05T15:24:39Z", "author": {"login": "xin-hedera"}, "timelineItems": {"totalCount": 18, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdoaw5ogH2gAyNTQzNzU4ODY5OjA1NDlkMjkzNTM4NzRlODVlYzE3MjFjOTZlNmE5YWY1OGY2ODYwOGM=", "endCursor": "Y3Vyc29yOnYyOpPPAAABds-P4lAFqTU2MTM5ODg1Nw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "0549d29353874e85ec1721c96e6a9af58f68608c", "author": {"user": {"login": "xin-hedera", "name": "Xin Li"}}, "url": "https://github.com/hashgraph/hedera-mirror-node/commit/0549d29353874e85ec1721c96e6a9af58f68608c", "committedDate": "2020-12-21T19:05:09Z", "message": "implement record file reader\n\nSigned-off-by: Xin Li <xin.li@swirlds.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d4e18a4e27be2a5565ef23dcc21c68c42bd57f8b", "author": {"user": {"login": "xin-hedera", "name": "Xin Li"}}, "url": "https://github.com/hashgraph/hedera-mirror-node/commit/d4e18a4e27be2a5565ef23dcc21c68c42bd57f8b", "committedDate": "2020-12-21T21:50:35Z", "message": "test cases\n\nSigned-off-by: Xin Li <xin.li@swirlds.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f83f7a7003d66c66bdf79680cfc28f2d75266de9", "author": {"user": {"login": "xin-hedera", "name": "Xin Li"}}, "url": "https://github.com/hashgraph/hedera-mirror-node/commit/f83f7a7003d66c66bdf79680cfc28f2d75266de9", "committedDate": "2020-12-21T22:24:46Z", "message": "minor changes\n\nSigned-off-by: Xin Li <xin.li@swirlds.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "84dd1ae99eedb9e2e86b49e5c35af8eeb437724f", "author": {"user": {"login": "xin-hedera", "name": "Xin Li"}}, "url": "https://github.com/hashgraph/hedera-mirror-node/commit/84dd1ae99eedb9e2e86b49e5c35af8eeb437724f", "committedDate": "2020-12-21T23:13:59Z", "message": "address sonar code smells\n\nSigned-off-by: Xin Li <xin.li@swirlds.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "944ae01598e3bfcc5b986a4eeb6f12be98d68db6", "author": {"user": {"login": "xin-hedera", "name": "Xin Li"}}, "url": "https://github.com/hashgraph/hedera-mirror-node/commit/944ae01598e3bfcc5b986a4eeb6f12be98d68db6", "committedDate": "2020-12-22T17:20:03Z", "message": "more sonar smells\n\nSigned-off-by: Xin Li <xin.li@swirlds.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU3MjMyMzk4", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1382#pullrequestreview-557232398", "createdAt": "2020-12-22T17:09:27Z", "commit": {"oid": "84dd1ae99eedb9e2e86b49e5c35af8eeb437724f"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQxNzowOToyN1rOIKCX1g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQxNzozNDo1M1rOIKDIvA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzM5NTU0Mg==", "bodyText": "nit: Add method comments, brief overview of what to expect from the header", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1382#discussion_r547395542", "createdAt": "2020-12-22T17:09:27Z", "author": {"login": "Nana-EC"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/reader/record/AbstractRecordFileReader.java", "diffHunk": "@@ -0,0 +1,154 @@\n+package com.hedera.mirror.importer.reader.record;\n+\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ * \u200b\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ * \u200b\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+import com.google.common.primitives.Ints;\n+import java.io.DataInputStream;\n+import java.io.IOException;\n+import java.util.function.Consumer;\n+import lombok.NonNull;\n+import lombok.RequiredArgsConstructor;\n+import org.apache.commons.codec.binary.Hex;\n+import org.apache.commons.io.FilenameUtils;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import com.hedera.mirror.importer.domain.RecordFile;\n+import com.hedera.mirror.importer.domain.StreamFileData;\n+import com.hedera.mirror.importer.exception.InvalidRecordFileException;\n+import com.hedera.mirror.importer.exception.RecordFileReaderException;\n+import com.hedera.mirror.importer.parser.domain.RecordItem;\n+\n+@RequiredArgsConstructor\n+public abstract class AbstractRecordFileReader implements RecordFileReader {\n+\n+    protected static final String HASH_ALGORITHM = \"SHA-384\";\n+    protected static final int HASH_SIZE = 48; // 48-byte SHA-384 hash\n+    protected static final byte RECORD_FILE_MARKER_PREV_HASH = 1;\n+    protected static final byte RECORD_FILE_MARKER_RECORD = 2;\n+\n+    protected final Logger log = LogManager.getLogger(getClass());\n+    private final int readerVersion;\n+\n+    @Override\n+    public RecordFile read(@NonNull StreamFileData streamFileData, Consumer<RecordItem> itemConsumer) {\n+        try (DataInputStream dis = new DataInputStream(streamFileData.getBufferedInputStream())) {\n+            RecordFile recordFile = new RecordFile();\n+            RecordFileDigest digest = getRecordFileDigest();\n+\n+            recordFile.setName(FilenameUtils.getName(streamFileData.getFilename()));\n+            readHeader(dis, digest, recordFile);\n+            readBody(dis, digest, itemConsumer, recordFile);\n+            recordFile.setFileHash(Hex.encodeHexString(digest.digest()));\n+\n+            return recordFile;\n+        } catch (RecordFileReaderException e) {\n+            throw e;\n+        }  catch (Exception e) {\n+            throw new RecordFileReaderException(\"Error reading record file \" + streamFileData.getFilename(), e);\n+        }\n+    }\n+\n+    protected abstract RecordFileDigest getRecordFileDigest();\n+\n+    private void readHeader(DataInputStream dis, RecordFileDigest digest, RecordFile recordFile) throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "84dd1ae99eedb9e2e86b49e5c35af8eeb437724f"}, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzM5NTYyNw==", "bodyText": "nit: Add method comments, brief overview of what to expect from the body", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1382#discussion_r547395627", "createdAt": "2020-12-22T17:09:38Z", "author": {"login": "Nana-EC"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/reader/record/AbstractRecordFileReader.java", "diffHunk": "@@ -0,0 +1,154 @@\n+package com.hedera.mirror.importer.reader.record;\n+\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ * \u200b\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ * \u200b\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+import com.google.common.primitives.Ints;\n+import java.io.DataInputStream;\n+import java.io.IOException;\n+import java.util.function.Consumer;\n+import lombok.NonNull;\n+import lombok.RequiredArgsConstructor;\n+import org.apache.commons.codec.binary.Hex;\n+import org.apache.commons.io.FilenameUtils;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import com.hedera.mirror.importer.domain.RecordFile;\n+import com.hedera.mirror.importer.domain.StreamFileData;\n+import com.hedera.mirror.importer.exception.InvalidRecordFileException;\n+import com.hedera.mirror.importer.exception.RecordFileReaderException;\n+import com.hedera.mirror.importer.parser.domain.RecordItem;\n+\n+@RequiredArgsConstructor\n+public abstract class AbstractRecordFileReader implements RecordFileReader {\n+\n+    protected static final String HASH_ALGORITHM = \"SHA-384\";\n+    protected static final int HASH_SIZE = 48; // 48-byte SHA-384 hash\n+    protected static final byte RECORD_FILE_MARKER_PREV_HASH = 1;\n+    protected static final byte RECORD_FILE_MARKER_RECORD = 2;\n+\n+    protected final Logger log = LogManager.getLogger(getClass());\n+    private final int readerVersion;\n+\n+    @Override\n+    public RecordFile read(@NonNull StreamFileData streamFileData, Consumer<RecordItem> itemConsumer) {\n+        try (DataInputStream dis = new DataInputStream(streamFileData.getBufferedInputStream())) {\n+            RecordFile recordFile = new RecordFile();\n+            RecordFileDigest digest = getRecordFileDigest();\n+\n+            recordFile.setName(FilenameUtils.getName(streamFileData.getFilename()));\n+            readHeader(dis, digest, recordFile);\n+            readBody(dis, digest, itemConsumer, recordFile);\n+            recordFile.setFileHash(Hex.encodeHexString(digest.digest()));\n+\n+            return recordFile;\n+        } catch (RecordFileReaderException e) {\n+            throw e;\n+        }  catch (Exception e) {\n+            throw new RecordFileReaderException(\"Error reading record file \" + streamFileData.getFilename(), e);\n+        }\n+    }\n+\n+    protected abstract RecordFileDigest getRecordFileDigest();\n+\n+    private void readHeader(DataInputStream dis, RecordFileDigest digest, RecordFile recordFile) throws IOException {\n+        // record file version\n+        int version = dis.readInt();\n+        checkField(version, readerVersion, \"record file version\", recordFile.getName());\n+\n+        int hapiVersion = dis.readInt();\n+\n+        // previous record file hash\n+        byte marker = dis.readByte();\n+        checkField(marker, RECORD_FILE_MARKER_PREV_HASH, \"RECORD_FILE_MARKER_PREV_HASH\", recordFile.getName());\n+        byte[] prevHash = dis.readNBytes(HASH_SIZE);\n+        checkField(prevHash.length, HASH_SIZE, \"previous hash size\", recordFile.getName());\n+\n+        digest.updateHeader(Ints.toByteArray(version));\n+        digest.updateHeader(Ints.toByteArray(hapiVersion));\n+        digest.updateHeader(marker);\n+        digest.updateHeader(prevHash);\n+\n+        recordFile.setRecordFormatVersion(version);\n+        recordFile.setPreviousHash(Hex.encodeHexString(prevHash));\n+    }\n+\n+    private void readBody(DataInputStream dis, RecordFileDigest digest, Consumer<RecordItem> itemConsumer,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "84dd1ae99eedb9e2e86b49e5c35af8eeb437724f"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzQwODA2MA==", "bodyText": "q: I see the BufferedInputStream creation repeated in a few places. Do you think it's worth centralizing that here by making this non final and a LazyGetter.\nSo you'd create a new StreamFileData object passing in a File instead of fileName, it could then set the fileName in the constructor and then on demand getting could return bufferedInputStream", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1382#discussion_r547408060", "createdAt": "2020-12-22T17:34:53Z", "author": {"login": "Nana-EC"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/domain/StreamFileData.java", "diffHunk": "@@ -20,11 +20,11 @@\n  * \u200d\n  */\n \n-import java.io.InputStream;\n+import java.io.BufferedInputStream;\n import lombok.Value;\n \n @Value\n public class StreamFileData {\n     private final String filename;\n-    private final InputStream inputStream;\n+    private final BufferedInputStream bufferedInputStream;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "84dd1ae99eedb9e2e86b49e5c35af8eeb437724f"}, "originalPosition": 18}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU3MjIyMjgy", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1382#pullrequestreview-557222282", "createdAt": "2020-12-22T16:53:25Z", "commit": {"oid": "84dd1ae99eedb9e2e86b49e5c35af8eeb437724f"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQxNjo1MzoyNVrOIKB42A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQxODozNjoxNFrOIKFGbA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzM4NzYwOA==", "bodyText": "Might be better to make this and its subclass stream agnostic for reuse with events v5 and new balance file. Maybe StreamFileReaderException and InvalidStreamFileException.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1382#discussion_r547387608", "createdAt": "2020-12-22T16:53:25Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/exception/RecordFileReaderException.java", "diffHunk": "@@ -0,0 +1,34 @@\n+package com.hedera.mirror.importer.exception;\n+\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ * \u200b\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ * \u200b\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+public class RecordFileReaderException extends ImporterException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "84dd1ae99eedb9e2e86b49e5c35af8eeb437724f"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzM4ODg2MA==", "bodyText": "It would be better for RecordFileReader to be responsible for opening the BufferedInputStream as it already does for DataInputStream. Otherwise this duplicates code and leaks details of RecordFileReader with every client having to know that it needs a BufferedInputStream because internally it's doing a lot of small reads. StreamFileData should just store an InputStream.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1382#discussion_r547388860", "createdAt": "2020-12-22T16:55:51Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/migration/V1_32_0__Missing_StreamFile_Record.java", "diffHunk": "@@ -108,7 +114,10 @@ private StreamFile readStreamFile(File file, StreamType streamType) {\n                     .name(file.getName())\n                     .build();\n         } else if (streamType == StreamType.RECORD) {\n-            streamFile = Utility.parseRecordFile(file.getPath(), null);\n+            try (BufferedInputStream bis = new BufferedInputStream(new FileInputStream(file))) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "84dd1ae99eedb9e2e86b49e5c35af8eeb437724f"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzQwMjc2MA==", "bodyText": "Think it might be better to create a method in Utility that opens the input stream quietly instead of leaking IOExceptions everywhere:\npublic static InputStream openQuietly(File file) {\n  try {\n    return new FileInputStream(file);\n  } catch (IOException e) {\n    throw new FileOperationException(\"Unable to open file \" + file.getPath(), e);\n  }\n}", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1382#discussion_r547402760", "createdAt": "2020-12-22T17:23:56Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/downloader/record/RecordFileDownloader.java", "diffHunk": "@@ -71,7 +78,11 @@ public void download() {\n      */\n     @Override\n     protected StreamFile readStreamFile(File file) {\n-        return Utility.parseRecordFile(file.getPath(), null);\n+        try (BufferedInputStream bis = new BufferedInputStream(new FileInputStream(file))) {\n+            return recordFileReader.read(new StreamFileData(file.getAbsolutePath(), bis), null);\n+        } catch (IOException e) {\n+            throw new FileOperationException(\"Unable to open record file \" + file.getPath(), e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "84dd1ae99eedb9e2e86b49e5c35af8eeb437724f"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzQwNDA4Nw==", "bodyText": "Maybe we should add another default method to RecordFileReader that only has StreamFileData and internally calls the overloaded method with null? e.g. recordFileReader.read(streamFileData)", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1382#discussion_r547404087", "createdAt": "2020-12-22T17:26:37Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/migration/V1_32_0__Missing_StreamFile_Record.java", "diffHunk": "@@ -108,7 +114,10 @@ private StreamFile readStreamFile(File file, StreamType streamType) {\n                     .name(file.getName())\n                     .build();\n         } else if (streamType == StreamType.RECORD) {\n-            streamFile = Utility.parseRecordFile(file.getPath(), null);\n+            try (BufferedInputStream bis = new BufferedInputStream(new FileInputStream(file))) {\n+                StreamFileData streamFileData = new StreamFileData(file.getAbsolutePath(), bis);\n+                streamFile = recordFileReader.read(streamFileData, null);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "84dd1ae99eedb9e2e86b49e5c35af8eeb437724f"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzQxOTQ3OQ==", "bodyText": "String description should be regular English like the above record file version. It's also redundant to say \"record file\" again within the RecordFileReader. \"RECORD_FILE_MARKER_PREV_HASH\" -> \"previous hash marker\".\nSimilar note for other check fields.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1382#discussion_r547419479", "createdAt": "2020-12-22T17:58:14Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/reader/record/AbstractRecordFileReader.java", "diffHunk": "@@ -0,0 +1,155 @@\n+package com.hedera.mirror.importer.reader.record;\n+\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ * \u200b\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ * \u200b\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+import com.google.common.primitives.Ints;\n+import java.io.DataInputStream;\n+import java.io.IOException;\n+import java.util.function.Consumer;\n+import lombok.NonNull;\n+import lombok.RequiredArgsConstructor;\n+import org.apache.commons.codec.binary.Hex;\n+import org.apache.commons.io.FilenameUtils;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import com.hedera.mirror.importer.domain.RecordFile;\n+import com.hedera.mirror.importer.domain.StreamFileData;\n+import com.hedera.mirror.importer.exception.ImporterException;\n+import com.hedera.mirror.importer.exception.InvalidRecordFileException;\n+import com.hedera.mirror.importer.exception.RecordFileReaderException;\n+import com.hedera.mirror.importer.parser.domain.RecordItem;\n+\n+@RequiredArgsConstructor\n+public abstract class AbstractRecordFileReader implements RecordFileReader {\n+\n+    protected static final String HASH_ALGORITHM = \"SHA-384\";\n+    protected static final int HASH_SIZE = 48; // 48-byte SHA-384 hash\n+    protected static final byte RECORD_FILE_MARKER_PREV_HASH = 1;\n+    protected static final byte RECORD_FILE_MARKER_RECORD = 2;\n+\n+    protected final Logger log = LogManager.getLogger(getClass());\n+    private final int readerVersion;\n+\n+    @Override\n+    public RecordFile read(@NonNull StreamFileData streamFileData, Consumer<RecordItem> itemConsumer) {\n+        try (DataInputStream dis = new DataInputStream(streamFileData.getBufferedInputStream())) {\n+            RecordFile recordFile = new RecordFile();\n+            RecordFileDigest digest = getRecordFileDigest();\n+\n+            recordFile.setName(FilenameUtils.getName(streamFileData.getFilename()));\n+            readHeader(dis, digest, recordFile);\n+            readBody(dis, digest, itemConsumer, recordFile);\n+            recordFile.setFileHash(Hex.encodeHexString(digest.digest()));\n+\n+            return recordFile;\n+        } catch (ImporterException e) {\n+            throw e;\n+        }  catch (Exception e) {\n+            throw new RecordFileReaderException(\"Error reading record file \" + streamFileData.getFilename(), e);\n+        }\n+    }\n+\n+    protected abstract RecordFileDigest getRecordFileDigest();\n+\n+    private void readHeader(DataInputStream dis, RecordFileDigest digest, RecordFile recordFile) throws IOException {\n+        // record file version\n+        int version = dis.readInt();\n+        checkField(version, readerVersion, \"record file version\", recordFile.getName());\n+\n+        int hapiVersion = dis.readInt();\n+\n+        // previous record file hash\n+        byte marker = dis.readByte();\n+        checkField(marker, RECORD_FILE_MARKER_PREV_HASH, \"RECORD_FILE_MARKER_PREV_HASH\", recordFile.getName());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "944ae01598e3bfcc5b986a4eeb6f12be98d68db6"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzQyMTY4Ng==", "bodyText": "Can drop the RECORD_FILE_ prefix since it's now within a record file specific class.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1382#discussion_r547421686", "createdAt": "2020-12-22T18:03:22Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/reader/record/AbstractRecordFileReader.java", "diffHunk": "@@ -0,0 +1,155 @@\n+package com.hedera.mirror.importer.reader.record;\n+\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ * \u200b\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ * \u200b\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+import com.google.common.primitives.Ints;\n+import java.io.DataInputStream;\n+import java.io.IOException;\n+import java.util.function.Consumer;\n+import lombok.NonNull;\n+import lombok.RequiredArgsConstructor;\n+import org.apache.commons.codec.binary.Hex;\n+import org.apache.commons.io.FilenameUtils;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import com.hedera.mirror.importer.domain.RecordFile;\n+import com.hedera.mirror.importer.domain.StreamFileData;\n+import com.hedera.mirror.importer.exception.ImporterException;\n+import com.hedera.mirror.importer.exception.InvalidRecordFileException;\n+import com.hedera.mirror.importer.exception.RecordFileReaderException;\n+import com.hedera.mirror.importer.parser.domain.RecordItem;\n+\n+@RequiredArgsConstructor\n+public abstract class AbstractRecordFileReader implements RecordFileReader {\n+\n+    protected static final String HASH_ALGORITHM = \"SHA-384\";\n+    protected static final int HASH_SIZE = 48; // 48-byte SHA-384 hash\n+    protected static final byte RECORD_FILE_MARKER_PREV_HASH = 1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "944ae01598e3bfcc5b986a4eeb6f12be98d68db6"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzQzOTUzMw==", "bodyText": "Use Path instead of format for Windows compatability.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1382#discussion_r547439533", "createdAt": "2020-12-22T18:34:35Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/reader/record/RecordFileReaderTest.java", "diffHunk": "@@ -0,0 +1,242 @@\n+package com.hedera.mirror.importer.reader.record;\n+\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ * \u200b\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ * \u200b\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+\n+import java.io.BufferedInputStream;\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.commons.io.FileUtils;\n+import org.junit.jupiter.api.Assertions;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.DynamicTest;\n+import org.junit.jupiter.api.TestFactory;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import com.hedera.mirror.importer.FileCopier;\n+import com.hedera.mirror.importer.domain.RecordFile;\n+import com.hedera.mirror.importer.domain.StreamFileData;\n+import com.hedera.mirror.importer.exception.InvalidRecordFileException;\n+import com.hedera.mirror.importer.parser.domain.RecordItem;\n+\n+@ExtendWith(MockitoExtension.class)\n+abstract class RecordFileReaderTest {\n+    private final static String pathPrefix = \"data/recordstreams\";\n+\n+    protected FileCopier fileCopier;\n+    protected RecordFileReader recordFileReader;\n+    protected List<RecordFile> allRecordFiles;\n+\n+    @TempDir\n+    Path dataPath;\n+\n+    private static void corruptFile(Path p) {\n+        try {\n+            File file = p.toFile();\n+            if (file.isFile()) {\n+                FileUtils.writeStringToFile(file, \"corrupt\", \"UTF-8\", true);\n+            }\n+        } catch (Exception e) {\n+            throw new RuntimeException(e);\n+        }\n+    }\n+\n+    private static void truncateFile(Path p) {\n+        try {\n+            File file = p.toFile();\n+            if (file.isFile()) {\n+                FileChannel outChan = new FileOutputStream(file, true).getChannel();\n+                if (outChan.size() <= 48) {\n+                    outChan.truncate(outChan.size() / 2);\n+                } else {\n+                    outChan.truncate(48);\n+                }\n+                outChan.close();\n+            }\n+        } catch (Exception e) {\n+            throw new RuntimeException(e);\n+        }\n+    }\n+\n+    @BeforeEach\n+    void setup() {\n+        fileCopier = FileCopier\n+                .create(Path.of(getClass().getClassLoader().getResource(pathPrefix).getPath()), dataPath);\n+        recordFileReader = getRecordFileReader();\n+\n+        RecordFile recordFileV1_1 = new RecordFile(1561990380317763000L, 1561990399074934000L, null,\n+                \"2019-07-01T14:13:00.317763Z.rcd\", null, null,\n+                \"333d6940254659533fd6b939033e59c57fe8f4ff78375d1e687c032918aa0b7b8179c7fd403754274a8c91e0b6c0195a\",\n+                \"f423447a3d5a531a07426070e511555283daae063706242590949116f717a0524e4dd18f9d64e66c73982d475401db04\",\n+                null, 15L, 1);\n+        RecordFile recordFileV1_2 = new RecordFile(1561991340302068000L, 1561991353226225001L, null,\n+                \"2019-07-01T14:29:00.302068Z.rcd\", null, null,\n+                \"1faf198f8fdbefa59bde191f214d73acdc4f5c0f434677a7edf9591b129e21aea90a5b3119d2802cee522e7be6bc8830\",\n+                recordFileV1_1.getFileHash(), null, 69L, 1);\n+        RecordFile recordFileV2_1 = new RecordFile(1567188600419072000L, 1567188604906443001L, null,\n+                \"2019-08-30T18_10_00.419072Z.rcd\", null, null,\n+                \"591558e059bd1629ee386c4e35a6875b4c67a096718f5d225772a651042715189414df7db5588495efb2a85dc4a0ffda\",\n+                \"000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\",\n+                null, 19L, 2);\n+        RecordFile recordFileV2_2 = new RecordFile(1567188605249678000L, 1567188609705382001L, null,\n+                \"2019-08-30T18_10_05.249678Z.rcd\", null, null,\n+                \"5ed51baeff204eb6a2a68b76bbaadcb9b6e7074676c1746b99681d075bef009e8d57699baaa6342feec4e83726582d36\",\n+                recordFileV2_1.getFileHash(), null, 15L, 2);\n+        allRecordFiles = List.of(recordFileV1_1, recordFileV1_2, recordFileV2_1, recordFileV2_2);\n+    }\n+\n+    @TestFactory\n+    Stream<DynamicTest> readValidFileWithConsumer() {\n+        String template = \"read valid version %d file %s\";\n+\n+        return DynamicTest.stream(\n+                getFilteredFiles(false),\n+                (recordFile) -> String.format(template, recordFile.getRecordFormatVersion(), recordFile.getName()),\n+                (recordFile) -> {\n+                    String filename = recordFile.getName();\n+                    Consumer<RecordItem> itemConsumer = mock(Consumer.class);\n+\n+                    // given\n+                    fileCopier.from(getSubPath(recordFile.getRecordFormatVersion())).filterFiles(filename).copy();\n+                    File inputFile = fileCopier.getTo().resolve(filename).toFile();\n+\n+                    // when\n+                    RecordFile actual;\n+                    try (BufferedInputStream bis = new BufferedInputStream(new FileInputStream(inputFile))) {\n+                        StreamFileData streamFileData = new StreamFileData(inputFile.getAbsolutePath(), bis);\n+                        actual = recordFileReader.read(streamFileData, itemConsumer);\n+                    }\n+\n+                    // then\n+                    assertThat(actual).isEqualTo(recordFile);\n+                    ArgumentCaptor<RecordItem> captor = ArgumentCaptor.forClass(RecordItem.class);\n+                    verify(itemConsumer, times(recordFile.getCount().intValue())).accept(captor.capture());\n+                    RecordItem[] recordItems = captor.getAllValues().toArray(new RecordItem[0]);\n+                    assertThat(recordItems[0].getConsensusTimestamp()).isEqualTo(recordFile.getConsensusStart());\n+                    assertThat(recordItems[recordItems.length - 1].getConsensusTimestamp()).isEqualTo(recordFile.getConsensusEnd());\n+                });\n+    }\n+\n+    @TestFactory\n+    Stream<DynamicTest> readValidFileWithoutConsumer() {\n+        String template = \"read valid version %d file %s\";\n+\n+        return DynamicTest.stream(\n+                getFilteredFiles(false),\n+                (recordFile) -> String.format(template, recordFile.getRecordFormatVersion(), recordFile.getName()),\n+                (recordFile) -> {\n+                    String filename = recordFile.getName();\n+\n+                    // given\n+                    fileCopier.from(getSubPath(recordFile.getRecordFormatVersion())).filterFiles(filename).copy();\n+                    File inputFile = fileCopier.getTo().resolve(filename).toFile();\n+\n+                    // when\n+                    RecordFile actual;\n+                    try (BufferedInputStream bis = new BufferedInputStream(new FileInputStream(inputFile))) {\n+                        StreamFileData streamFileData = new StreamFileData(inputFile.getAbsolutePath(), bis);\n+                        actual = recordFileReader.read(streamFileData, null);\n+                    }\n+\n+                    // then\n+                    assertThat(actual).isEqualTo(recordFile);\n+                });\n+    }\n+\n+    @TestFactory\n+    Stream<DynamicTest> readInvalidFileWithGarbageAppended() {\n+        String template = \"read corrupted version %d file %s\";\n+\n+        return DynamicTest.stream(\n+                getFilteredFiles(false),\n+                (recordFile) -> String.format(template, recordFile.getRecordFormatVersion(), recordFile.getName()),\n+                (recordFile) -> {\n+                    String filename = recordFile.getName();\n+\n+                    // given\n+                    fileCopier.from(getSubPath(recordFile.getRecordFormatVersion())).filterFiles(filename).copy();\n+                    File inputFile = fileCopier.getTo().resolve(filename).toFile();\n+                    Files.walk(dataPath).forEach(RecordFileReaderTest::corruptFile);\n+\n+                    // when\n+                    try (BufferedInputStream bis = new BufferedInputStream(new FileInputStream(inputFile))) {\n+                        StreamFileData streamFileData = new StreamFileData(inputFile.getAbsolutePath(), bis);\n+                        Assertions.assertThrows(InvalidRecordFileException.class,\n+                                () -> recordFileReader.read(streamFileData, null));\n+                    }\n+                });\n+    }\n+\n+    @TestFactory\n+    Stream<DynamicTest> readInvalidFileWithDataTruncated() {\n+        String template = \"read incomplete version %d file %s\";\n+\n+        return DynamicTest.stream(\n+                getFilteredFiles(false),\n+                (recordFile) -> String.format(template, recordFile.getRecordFormatVersion(), recordFile.getName()),\n+                (recordFile) -> {\n+                    String filename = recordFile.getName();\n+\n+                    // given\n+                    fileCopier.from(getSubPath(recordFile.getRecordFormatVersion())).filterFiles(filename).copy();\n+                    File inputFile = fileCopier.getTo().resolve(filename).toFile();\n+                    Files.walk(dataPath).forEach(RecordFileReaderTest::truncateFile);\n+\n+                    // when\n+                    try (BufferedInputStream bis = new BufferedInputStream(new FileInputStream(inputFile))) {\n+                        StreamFileData streamFileData = new StreamFileData(inputFile.getAbsolutePath(), bis);\n+                        Assertions.assertThrows(InvalidRecordFileException.class,\n+                                () -> recordFileReader.read(streamFileData, null));\n+                    }\n+                });\n+    }\n+\n+    protected Iterator<RecordFile> getFilteredFiles(boolean negate) {\n+        return allRecordFiles.stream()\n+                .filter((recordFile) -> negate ^ filterFile(recordFile.getRecordFormatVersion()))\n+                .collect(Collectors.toList())\n+                .iterator();\n+    }\n+\n+    protected String getSubPath(int version) {\n+        return String.format(\"v%d/record0.0.3\", version);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "944ae01598e3bfcc5b986a4eeb6f12be98d68db6"}, "originalPosition": 236}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzQ0MDIzNg==", "bodyText": "Use Path", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1382#discussion_r547440236", "createdAt": "2020-12-22T18:36:14Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/reader/record/RecordFileReaderTest.java", "diffHunk": "@@ -0,0 +1,242 @@\n+package com.hedera.mirror.importer.reader.record;\n+\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ * \u200b\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ * \u200b\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+\n+import java.io.BufferedInputStream;\n+import java.io.File;\n+import java.io.FileInputStream;\n+import java.io.FileOutputStream;\n+import java.nio.channels.FileChannel;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.commons.io.FileUtils;\n+import org.junit.jupiter.api.Assertions;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.DynamicTest;\n+import org.junit.jupiter.api.TestFactory;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import com.hedera.mirror.importer.FileCopier;\n+import com.hedera.mirror.importer.domain.RecordFile;\n+import com.hedera.mirror.importer.domain.StreamFileData;\n+import com.hedera.mirror.importer.exception.InvalidRecordFileException;\n+import com.hedera.mirror.importer.parser.domain.RecordItem;\n+\n+@ExtendWith(MockitoExtension.class)\n+abstract class RecordFileReaderTest {\n+    private final static String pathPrefix = \"data/recordstreams\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "944ae01598e3bfcc5b986a4eeb6f12be98d68db6"}, "originalPosition": 58}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU3MjkwNzEx", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1382#pullrequestreview-557290711", "createdAt": "2020-12-22T18:44:27Z", "commit": {"oid": "944ae01598e3bfcc5b986a4eeb6f12be98d68db6"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQxODo0NDoyOFrOIKFUHQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yMlQxODo0NDoyOFrOIKFUHQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NzQ0Mzc0MQ==", "bodyText": "Since the passed in InputStream will be closed already by this CompositeRecordFileReader, we can make it part of the RecordFileReader contract/documentation that it will be responsible for closing and clients don't need to use a separate try with resources.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1382#discussion_r547443741", "createdAt": "2020-12-22T18:44:28Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/reader/record/CompositeRecordFileReader.java", "diffHunk": "@@ -0,0 +1,75 @@\n+package com.hedera.mirror.importer.reader.record;\n+\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ * \u200b\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ * \u200b\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+import java.io.DataInputStream;\n+import java.io.IOException;\n+import java.util.function.Consumer;\n+import javax.inject.Named;\n+import lombok.NonNull;\n+import lombok.RequiredArgsConstructor;\n+import lombok.extern.log4j.Log4j2;\n+import org.springframework.context.annotation.Primary;\n+\n+import com.hedera.mirror.importer.domain.RecordFile;\n+import com.hedera.mirror.importer.domain.StreamFileData;\n+import com.hedera.mirror.importer.exception.InvalidRecordFileException;\n+import com.hedera.mirror.importer.exception.RecordFileReaderException;\n+import com.hedera.mirror.importer.parser.domain.RecordItem;\n+\n+@Named\n+@Primary\n+@Log4j2\n+@RequiredArgsConstructor\n+public class CompositeRecordFileReader implements RecordFileReader {\n+\n+    private final RecordFileReaderImplV1 version1Reader;\n+    private final RecordFileReaderImplV2 version2Reader;\n+\n+    @Override\n+    public RecordFile read(@NonNull StreamFileData streamFileData, Consumer<RecordItem> itemConsumer) {\n+        try (DataInputStream dis = new DataInputStream(streamFileData.getBufferedInputStream())) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "944ae01598e3bfcc5b986a4eeb6f12be98d68db6"}, "originalPosition": 49}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d4967fe79dd9916a44389d82b3b0051227233515", "author": {"user": {"login": "xin-hedera", "name": "Xin Li"}}, "url": "https://github.com/hashgraph/hedera-mirror-node/commit/d4967fe79dd9916a44389d82b3b0051227233515", "committedDate": "2020-12-23T17:02:58Z", "message": "address review feedback\n\nSigned-off-by: Xin Li <xin.li@swirlds.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6115e66dad9cd1b40777d8c5a77c22d3387b06f2", "author": {"user": {"login": "xin-hedera", "name": "Xin Li"}}, "url": "https://github.com/hashgraph/hedera-mirror-node/commit/6115e66dad9cd1b40777d8c5a77c22d3387b06f2", "committedDate": "2020-12-23T17:18:26Z", "message": "address code smells\n\nSigned-off-by: Xin Li <xin.li@swirlds.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU4MjEzMDM0", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1382#pullrequestreview-558213034", "createdAt": "2020-12-23T20:24:36Z", "commit": {"oid": "6115e66dad9cd1b40777d8c5a77c22d3387b06f2"}, "state": "DISMISSED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU5MjkzMzE5", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1382#pullrequestreview-559293319", "createdAt": "2020-12-28T20:32:57Z", "commit": {"oid": "6115e66dad9cd1b40777d8c5a77c22d3387b06f2"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yOFQyMDozMjo1OFrOIMBgaA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yOFQyMToxNTozMFrOIMCKMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTQ3ODUwNA==", "bodyText": "This isn't the \"previous hash size\", it's the \"previous hash\" itself.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1382#discussion_r549478504", "createdAt": "2020-12-28T20:32:58Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/reader/record/AbstractRecordFileReader.java", "diffHunk": "@@ -0,0 +1,178 @@\n+package com.hedera.mirror.importer.reader.record;\n+\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ * \u200b\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ * \u200b\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+import com.google.common.primitives.Ints;\n+import java.io.BufferedInputStream;\n+import java.io.DataInputStream;\n+import java.io.IOException;\n+import java.util.function.Consumer;\n+import lombok.NonNull;\n+import lombok.RequiredArgsConstructor;\n+import org.apache.commons.codec.binary.Hex;\n+import org.apache.commons.io.FilenameUtils;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import com.hedera.mirror.importer.domain.RecordFile;\n+import com.hedera.mirror.importer.domain.StreamFileData;\n+import com.hedera.mirror.importer.exception.ImporterException;\n+import com.hedera.mirror.importer.exception.InvalidStreamFileException;\n+import com.hedera.mirror.importer.exception.StreamFileReaderException;\n+import com.hedera.mirror.importer.parser.domain.RecordItem;\n+\n+@RequiredArgsConstructor\n+public abstract class AbstractRecordFileReader implements RecordFileReader {\n+\n+    protected static final String HASH_ALGORITHM = \"SHA-384\";\n+    protected static final int HASH_SIZE = 48; // 48-byte SHA-384 hash\n+    protected static final byte PREV_HASH_MARKER = 1;\n+    protected static final byte RECORD_MARKER = 2;\n+\n+    protected final Logger log = LogManager.getLogger(getClass());\n+    private final int readerVersion;\n+\n+    @Override\n+    public RecordFile read(@NonNull StreamFileData streamFileData, Consumer<RecordItem> itemConsumer) {\n+        try (DataInputStream dis = new DataInputStream(new BufferedInputStream(streamFileData.getInputStream()))) {\n+            RecordFile recordFile = new RecordFile();\n+            RecordFileDigest digest = getRecordFileDigest();\n+\n+            recordFile.setName(FilenameUtils.getName(streamFileData.getFilename()));\n+            readHeader(dis, digest, recordFile);\n+            readBody(dis, digest, itemConsumer, recordFile);\n+            recordFile.setFileHash(Hex.encodeHexString(digest.digest()));\n+\n+            return recordFile;\n+        } catch (ImporterException e) {\n+            throw e;\n+        }  catch (Exception e) {\n+            throw new StreamFileReaderException(\"Error reading record file \" + streamFileData.getFilename(), e);\n+        }\n+    }\n+\n+    protected abstract RecordFileDigest getRecordFileDigest();\n+\n+    /**\n+     * Reads the record file header, updates the message digest with data from the header, and sets corresponding\n+     * {@link RecordFile} fields. {@code dis} should point at the beginning of the stream. The header should contain\n+     * file version, HAPI version, and the previous file hash.\n+     *\n+     * @param dis the {@link DataInputStream} of the record file\n+     * @param digest the {@link RecordFileDigest} to update the digest with\n+     * @param recordFile the {@link RecordFile} object\n+     * @throws IOException\n+     */\n+    private void readHeader(DataInputStream dis, RecordFileDigest digest, RecordFile recordFile) throws IOException {\n+        // record file version\n+        int version = dis.readInt();\n+        checkField(version, readerVersion, \"record file version\", recordFile.getName());\n+\n+        int hapiVersion = dis.readInt();\n+\n+        // previous record file hash\n+        byte marker = dis.readByte();\n+        checkField(marker, PREV_HASH_MARKER, \"previous hash marker\", recordFile.getName());\n+        byte[] prevHash = dis.readNBytes(HASH_SIZE);\n+        checkField(prevHash.length, HASH_SIZE, \"previous hash size\", recordFile.getName());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6115e66dad9cd1b40777d8c5a77c22d3387b06f2"}, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTQ4MzI5Nw==", "bodyText": "Could use readNBytes to be consistent with hash reading and collapse last 3 lines to 1.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1382#discussion_r549483297", "createdAt": "2020-12-28T20:51:53Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/reader/record/AbstractRecordFileReader.java", "diffHunk": "@@ -0,0 +1,178 @@\n+package com.hedera.mirror.importer.reader.record;\n+\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ * \u200b\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ * \u200b\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+import com.google.common.primitives.Ints;\n+import java.io.BufferedInputStream;\n+import java.io.DataInputStream;\n+import java.io.IOException;\n+import java.util.function.Consumer;\n+import lombok.NonNull;\n+import lombok.RequiredArgsConstructor;\n+import org.apache.commons.codec.binary.Hex;\n+import org.apache.commons.io.FilenameUtils;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+\n+import com.hedera.mirror.importer.domain.RecordFile;\n+import com.hedera.mirror.importer.domain.StreamFileData;\n+import com.hedera.mirror.importer.exception.ImporterException;\n+import com.hedera.mirror.importer.exception.InvalidStreamFileException;\n+import com.hedera.mirror.importer.exception.StreamFileReaderException;\n+import com.hedera.mirror.importer.parser.domain.RecordItem;\n+\n+@RequiredArgsConstructor\n+public abstract class AbstractRecordFileReader implements RecordFileReader {\n+\n+    protected static final String HASH_ALGORITHM = \"SHA-384\";\n+    protected static final int HASH_SIZE = 48; // 48-byte SHA-384 hash\n+    protected static final byte PREV_HASH_MARKER = 1;\n+    protected static final byte RECORD_MARKER = 2;\n+\n+    protected final Logger log = LogManager.getLogger(getClass());\n+    private final int readerVersion;\n+\n+    @Override\n+    public RecordFile read(@NonNull StreamFileData streamFileData, Consumer<RecordItem> itemConsumer) {\n+        try (DataInputStream dis = new DataInputStream(new BufferedInputStream(streamFileData.getInputStream()))) {\n+            RecordFile recordFile = new RecordFile();\n+            RecordFileDigest digest = getRecordFileDigest();\n+\n+            recordFile.setName(FilenameUtils.getName(streamFileData.getFilename()));\n+            readHeader(dis, digest, recordFile);\n+            readBody(dis, digest, itemConsumer, recordFile);\n+            recordFile.setFileHash(Hex.encodeHexString(digest.digest()));\n+\n+            return recordFile;\n+        } catch (ImporterException e) {\n+            throw e;\n+        }  catch (Exception e) {\n+            throw new StreamFileReaderException(\"Error reading record file \" + streamFileData.getFilename(), e);\n+        }\n+    }\n+\n+    protected abstract RecordFileDigest getRecordFileDigest();\n+\n+    /**\n+     * Reads the record file header, updates the message digest with data from the header, and sets corresponding\n+     * {@link RecordFile} fields. {@code dis} should point at the beginning of the stream. The header should contain\n+     * file version, HAPI version, and the previous file hash.\n+     *\n+     * @param dis the {@link DataInputStream} of the record file\n+     * @param digest the {@link RecordFileDigest} to update the digest with\n+     * @param recordFile the {@link RecordFile} object\n+     * @throws IOException\n+     */\n+    private void readHeader(DataInputStream dis, RecordFileDigest digest, RecordFile recordFile) throws IOException {\n+        // record file version\n+        int version = dis.readInt();\n+        checkField(version, readerVersion, \"record file version\", recordFile.getName());\n+\n+        int hapiVersion = dis.readInt();\n+\n+        // previous record file hash\n+        byte marker = dis.readByte();\n+        checkField(marker, PREV_HASH_MARKER, \"previous hash marker\", recordFile.getName());\n+        byte[] prevHash = dis.readNBytes(HASH_SIZE);\n+        checkField(prevHash.length, HASH_SIZE, \"previous hash size\", recordFile.getName());\n+\n+        digest.updateHeader(Ints.toByteArray(version));\n+        digest.updateHeader(Ints.toByteArray(hapiVersion));\n+        digest.updateHeader(marker);\n+        digest.updateHeader(prevHash);\n+\n+        recordFile.setRecordFormatVersion(version);\n+        recordFile.setPreviousHash(Hex.encodeHexString(prevHash));\n+    }\n+\n+    /**\n+     * Reads the record file body, updates the message digest with data from the body, and sets corresponding\n+     * {@link RecordFile} fields. {@code dis} should point at the beginning of the body. The body should contain\n+     * a variable number of transaction and record pairs ordered by consensus timestamp. The body may also contain\n+     * metadata to mark the boundary of the pairs.\n+     *\n+     * @param dis the {@link DataInputStream} of the record file\n+     * @param digest the {@link RecordFileDigest} to update the digest with\n+     * @param itemConsumer the {@link Consumer} to process individual {@link RecordItem}s\n+     * @param recordFile the {@link RecordFile} object\n+     * @throws IOException\n+     */\n+    private void readBody(DataInputStream dis, RecordFileDigest digest, Consumer<RecordItem> itemConsumer,\n+            RecordFile recordFile) throws IOException {\n+        long count = 0;\n+        long consensusStart = 0;\n+        long consensusEnd = 0;\n+\n+        while (dis.available() != 0) {\n+            byte marker = dis.readByte();\n+            checkField(marker, RECORD_MARKER, \"record marker\", recordFile.getName());\n+\n+            byte[] transactionBytes = readLengthAndBytes(dis);\n+            byte[] recordBytes = readLengthAndBytes(dis);\n+\n+            digest.updateBody(marker);\n+            digest.updateBody(Ints.toByteArray(transactionBytes.length));\n+            digest.updateBody(transactionBytes);\n+            digest.updateBody(Ints.toByteArray(recordBytes.length));\n+            digest.updateBody(recordBytes);\n+\n+            boolean isFirstTransaction = count == 0;\n+            boolean isLastTransaction = dis.available() == 0;\n+\n+            // We need the first and last transaction timestamps for metrics\n+            if (itemConsumer != null || isFirstTransaction || isLastTransaction) {\n+                RecordItem recordItem = new RecordItem(transactionBytes, recordBytes);\n+\n+                if (itemConsumer != null) {\n+                    itemConsumer.accept(recordItem);\n+                }\n+\n+                if (isFirstTransaction) {\n+                    consensusStart = recordItem.getConsensusTimestamp();\n+                }\n+\n+                if (isLastTransaction) {\n+                    consensusEnd = recordItem.getConsensusTimestamp();\n+                }\n+            }\n+\n+            count++;\n+        }\n+\n+        recordFile.setConsensusStart(consensusStart);\n+        recordFile.setConsensusEnd(consensusEnd);\n+        recordFile.setCount(count);\n+    }\n+\n+    private byte[] readLengthAndBytes(DataInputStream dis) throws IOException {\n+        int len = dis.readInt();\n+        byte[] bytes = new byte[len];\n+        dis.readFully(bytes);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6115e66dad9cd1b40777d8c5a77c22d3387b06f2"}, "originalPosition": 168}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTQ4ODQ1NQ==", "bodyText": "Bit confusing to call updateHeader() for an updateBody(). Would either replace with md.update(input) or create a new method private void update(byte... input) that they call.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1382#discussion_r549488455", "createdAt": "2020-12-28T21:12:52Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/reader/record/RecordFileReaderImplV1.java", "diffHunk": "@@ -0,0 +1,78 @@\n+package com.hedera.mirror.importer.reader.record;\n+\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ * \u200b\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ * \u200b\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+import java.security.MessageDigest;\n+import java.security.NoSuchAlgorithmException;\n+import javax.inject.Named;\n+\n+import com.hedera.mirror.importer.exception.StreamFileReaderException;\n+\n+@Named\n+public class RecordFileReaderImplV1 extends AbstractRecordFileReader {\n+\n+    public RecordFileReaderImplV1() {\n+        super(1);\n+    }\n+\n+    @Override\n+    protected RecordFileDigest getRecordFileDigest() {\n+        try {\n+            return new RecordFileDigestV1();\n+        } catch (NoSuchAlgorithmException e) {\n+            throw new StreamFileReaderException(\"Unable to instantiate RecordFileDigestV1\" , e);\n+        }\n+    }\n+\n+    private static class RecordFileDigestV1 implements RecordFileDigest {\n+\n+        private final MessageDigest md;\n+\n+        RecordFileDigestV1() throws NoSuchAlgorithmException {\n+            md = MessageDigest.getInstance(HASH_ALGORITHM);\n+        }\n+\n+        @Override\n+        public void updateHeader(byte input) {\n+            md.update(input);\n+        }\n+\n+        @Override\n+        public void updateHeader(byte[] input) {\n+            md.update(input);\n+        }\n+\n+        @Override\n+        public void updateBody(byte input) {\n+            updateHeader(input);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6115e66dad9cd1b40777d8c5a77c22d3387b06f2"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0OTQ4OTIwMA==", "bodyText": "nit: A parameterized test with so many if/else and booleans parameters is harder to follow then separate tests in my opinion. Not saying you have to change it, just want to make the observation.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1382#discussion_r549489200", "createdAt": "2020-12-28T21:15:30Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/domain/StreamFileDataTest.java", "diffHunk": "@@ -0,0 +1,69 @@\n+package com.hedera.mirror.importer.domain;\n+\n+/*-\n+ *\n+ *  Hedera Mirror Node\n+ *  \u200b\n+ *  Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ *  \u200b\n+ *  Licensed under the Apache License, Version 2.0 (the \"License\");\n+ *  you may not use this file except in compliance with the License.\n+ *  You may obtain a copy of the License at\n+ *\n+ *       http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ *  Unless required by applicable law or agreed to in writing, software\n+ *  distributed under the License is distributed on an \"AS IS\" BASIS,\n+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ *  See the License for the specific language governing permissions and\n+ *  limitations under the License.\n+ *\n+ */\n+\n+import static org.assertj.core.api.Assertions.assertThat;\n+import static org.junit.jupiter.api.Assertions.*;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Path;\n+import org.apache.commons.io.FileUtils;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.junit.jupiter.params.ParameterizedTest;\n+import org.junit.jupiter.params.provider.CsvSource;\n+\n+class StreamFileDataTest {\n+\n+    @TempDir\n+    Path dataPath;\n+\n+    @ParameterizedTest(name = \"create StreamFileData from {3}\")\n+    @CsvSource({\n+            \"true, false, false, empty file should return valid StreamFileData object\",\n+            \"true, true, false, file with content should return valid StreamFileData object\",\n+            \"false, false, false, non-existent file expect exception\",\n+            \"false, false, true, directory expect exception\",\n+    })\n+    void from(boolean createFile, boolean writeData, boolean createDirectory, String testName) throws IOException {\n+        File file = FileUtils.getFile(dataPath.toFile(), \"testfile\");\n+\n+        if (createFile) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6115e66dad9cd1b40777d8c5a77c22d3387b06f2"}, "originalPosition": 50}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "123df7c100272cefec1c0fc4ab8a8437f1a37d8c", "author": {"user": {"login": "xin-hedera", "name": "Xin Li"}}, "url": "https://github.com/hashgraph/hedera-mirror-node/commit/123df7c100272cefec1c0fc4ab8a8437f1a37d8c", "committedDate": "2021-01-04T17:00:08Z", "message": "address review feedback\n\nSigned-off-by: Xin Li <xin.li@swirlds.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "23dabc11a84842b43a544610a4c14bdaa80b5e7e", "author": {"user": {"login": "xin-hedera", "name": "Xin Li"}}, "url": "https://github.com/hashgraph/hedera-mirror-node/commit/23dabc11a84842b43a544610a4c14bdaa80b5e7e", "committedDate": "2021-01-04T20:09:11Z", "message": "Merge branch 'master' into record-file-reader\n\nSigned-off-by: Xin Li <xin.li@swirlds.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYxMzI3NjAw", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1382#pullrequestreview-561327600", "createdAt": "2021-01-04T20:37:48Z", "commit": {"oid": "23dabc11a84842b43a544610a4c14bdaa80b5e7e"}, "state": "DISMISSED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "362c3c5ba086ccf5d699c442eb23c0a99ff29ad5", "author": {"user": {"login": "xin-hedera", "name": "Xin Li"}}, "url": "https://github.com/hashgraph/hedera-mirror-node/commit/362c3c5ba086ccf5d699c442eb23c0a99ff29ad5", "committedDate": "2021-01-04T21:53:33Z", "message": "Merge branch 'master' into record-file-reader\n\nSigned-off-by: Xin Li <xin.li@hedera.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYxMzc2NTcw", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1382#pullrequestreview-561376570", "createdAt": "2021-01-04T21:57:45Z", "commit": {"oid": "23dabc11a84842b43a544610a4c14bdaa80b5e7e"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYxMzk4ODU3", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1382#pullrequestreview-561398857", "createdAt": "2021-01-04T22:41:22Z", "commit": {"oid": "362c3c5ba086ccf5d699c442eb23c0a99ff29ad5"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3455, "cost": 1, "resetAt": "2021-11-01T14:51:55Z"}}}