{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTIyNzg1MzU4", "number": 1279, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQxOToxMDowOVrOE6uT3A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQxOToxOToyM1rOE6uiDw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwMDExNjEyOnYy", "diffSide": "RIGHT", "path": "charts/hedera-mirror-common/values.yaml", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQxOToxMDowOVrOH197Pw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMzoyNjowNFrOH2LTGQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjM1MTE2Nw==", "bodyText": "should this port be configureable on it's own and easy to reference by others sections of the code or is okay to have it hard coded here?", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1279#discussion_r526351167", "createdAt": "2020-11-18T19:10:09Z", "author": {"login": "Nana-EC"}, "path": "charts/hedera-mirror-common/values.yaml", "diffHunk": "@@ -9,13 +9,111 @@ loki:\n   enabled: true\n   loki:\n     config:\n+      ruler:\n+        alertmanager_url: http://{{ .Release.Name }}-prometheus-alertmanager:9093", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "43c5188707241816d8c88a6dea0b96c2858b2a36"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ3MDU2MQ==", "bodyText": "It's the default port within the alertmanager chart. It does have a value within that chart but child values are not available within parent charts. So I'd have to redefine it here and then reference that redefinition.\nTechnically the prometheus-alertmanager part is also customizable. At some point you can't account for every customization and have to assume defaults. Didn't think it's worth the effort.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1279#discussion_r526470561", "createdAt": "2020-11-18T22:38:39Z", "author": {"login": "steven-sheehy"}, "path": "charts/hedera-mirror-common/values.yaml", "diffHunk": "@@ -9,13 +9,111 @@ loki:\n   enabled: true\n   loki:\n     config:\n+      ruler:\n+        alertmanager_url: http://{{ .Release.Name }}-prometheus-alertmanager:9093", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjM1MTE2Nw=="}, "originalCommit": {"oid": "43c5188707241816d8c88a6dea0b96c2858b2a36"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU3MDI2NQ==", "bodyText": "That's fine", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1279#discussion_r526570265", "createdAt": "2020-11-19T03:26:04Z", "author": {"login": "Nana-EC"}, "path": "charts/hedera-mirror-common/values.yaml", "diffHunk": "@@ -9,13 +9,111 @@ loki:\n   enabled: true\n   loki:\n     config:\n+      ruler:\n+        alertmanager_url: http://{{ .Release.Name }}-prometheus-alertmanager:9093", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjM1MTE2Nw=="}, "originalCommit": {"oid": "43c5188707241816d8c88a6dea0b96c2858b2a36"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwMDE1MjQ3OnYy", "diffSide": "RIGHT", "path": "charts/hedera-mirror-common/values.yaml", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQxOToxOToyM1rOH1-RFg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMzoyNzoxMlrOH2LUbg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjM1Njc1OA==", "bodyText": "String matching on logs seems brittle, as it can change between versions and there's no check to ensure this would be updated.\nIs it possible to apply an exception type filter here instead or in addition to some of these?\nWe might need to update some of the code in that case.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1279#discussion_r526356758", "createdAt": "2020-11-18T19:19:23Z", "author": {"login": "Nana-EC"}, "path": "charts/hedera-mirror-common/values.yaml", "diffHunk": "@@ -9,13 +9,111 @@ loki:\n   enabled: true\n   loki:\n     config:\n+      ruler:\n+        alertmanager_url: http://{{ .Release.Name }}-prometheus-alertmanager:9093\n+        enable_alertmanager_v2: true\n+        enable_api: true\n+        ring:\n+          kvstore:\n+            store: inmemory\n+        rule_path: /tmp/loki\n+        storage:\n+          type: local\n+          local:\n+            directory: /loki/rules\n       table_manager:\n         retention_deletes_enabled: true\n         retention_period: 2184h\n+    extraVolumeMounts:\n+      - name: rules\n+        mountPath: /loki/rules/fake\n+      - name: tmp\n+        mountPath: /tmp/loki\n+    extraVolumes:\n+      - name: rules\n+        configMap:\n+          defaultMode: 420\n+          name: loki-rules\n+      - name: tmp\n+        emptyDir: {}\n     networkPolicy:\n       enabled: true\n     persistence:\n       enabled: true\n+      size: 100Gi\n+    prometheusRules:\n+      # TODO: Enhance Loki to support watching for PrometheusRules via the Kubernetes API so we can declare these within their chart\n+      GrpcLogErrors:\n+        annotations:\n+          description: \"Logs for {{ $labels.namespace }}/{{ $labels.pod }} have reached {{ $value }} error messages/s in a 3m period\"\n+          summary: High rate of errors in logs\n+        enabled: true\n+        expr: >\n+          sum(rate({app_kubernetes_io_component=\"grpc\"}\n+            | regexp `(?P<timestamp>\\S+) (?P<level>\\S+) (?P<thread>\\S+) (?P<class>\\S+) (?P<message>.+)`\n+            | level = \"ERROR\"\n+            != \"reactor.core.publisher\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "43c5188707241816d8c88a6dea0b96c2858b2a36"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjQ2NTgxNw==", "bodyText": "See the note in the description:\n\nNote that the log alerts can probably be cleaned up quite a bit but I chose to keep them mostly the same with what we have for now\n\nI didn't create these alerts, they are existing and are what we notify off of in production. I'm not even sure how most of these ended up here as they're not logs that we explicitly print. So the argument of brittleness is still there with the existing approach but at least now they'll be checked in with the source code and versioned.\n\nIs it possible to apply an exception type filter here instead or in addition to some of these?\n\nI'm not sure what you mean. These are error level logs so they're usually the result of an exception already. I could add an |= \"Exception\" if that's what you're saying but that might miss logs that are error level and not exceptions. Again, it's not my alert so I'm not sure what scenarios this is covering so I just copied it.\nI think one of the problems with the existing alerts is that it didn't parse out the log level and java stacktraces are multi-line. So stacktraces might count multiple times towards the log metric for what is actually the same log statement. Hence why some of these strings might not be needed anymore since they might've been an element within the stacktrace.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1279#discussion_r526465817", "createdAt": "2020-11-18T22:28:51Z", "author": {"login": "steven-sheehy"}, "path": "charts/hedera-mirror-common/values.yaml", "diffHunk": "@@ -9,13 +9,111 @@ loki:\n   enabled: true\n   loki:\n     config:\n+      ruler:\n+        alertmanager_url: http://{{ .Release.Name }}-prometheus-alertmanager:9093\n+        enable_alertmanager_v2: true\n+        enable_api: true\n+        ring:\n+          kvstore:\n+            store: inmemory\n+        rule_path: /tmp/loki\n+        storage:\n+          type: local\n+          local:\n+            directory: /loki/rules\n       table_manager:\n         retention_deletes_enabled: true\n         retention_period: 2184h\n+    extraVolumeMounts:\n+      - name: rules\n+        mountPath: /loki/rules/fake\n+      - name: tmp\n+        mountPath: /tmp/loki\n+    extraVolumes:\n+      - name: rules\n+        configMap:\n+          defaultMode: 420\n+          name: loki-rules\n+      - name: tmp\n+        emptyDir: {}\n     networkPolicy:\n       enabled: true\n     persistence:\n       enabled: true\n+      size: 100Gi\n+    prometheusRules:\n+      # TODO: Enhance Loki to support watching for PrometheusRules via the Kubernetes API so we can declare these within their chart\n+      GrpcLogErrors:\n+        annotations:\n+          description: \"Logs for {{ $labels.namespace }}/{{ $labels.pod }} have reached {{ $value }} error messages/s in a 3m period\"\n+          summary: High rate of errors in logs\n+        enabled: true\n+        expr: >\n+          sum(rate({app_kubernetes_io_component=\"grpc\"}\n+            | regexp `(?P<timestamp>\\S+) (?P<level>\\S+) (?P<thread>\\S+) (?P<class>\\S+) (?P<message>.+)`\n+            | level = \"ERROR\"\n+            != \"reactor.core.publisher\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjM1Njc1OA=="}, "originalCommit": {"oid": "43c5188707241816d8c88a6dea0b96c2858b2a36"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU3MDYwNg==", "bodyText": "Understood.\nLooks like we can do some more customization as needed in the future.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1279#discussion_r526570606", "createdAt": "2020-11-19T03:27:12Z", "author": {"login": "Nana-EC"}, "path": "charts/hedera-mirror-common/values.yaml", "diffHunk": "@@ -9,13 +9,111 @@ loki:\n   enabled: true\n   loki:\n     config:\n+      ruler:\n+        alertmanager_url: http://{{ .Release.Name }}-prometheus-alertmanager:9093\n+        enable_alertmanager_v2: true\n+        enable_api: true\n+        ring:\n+          kvstore:\n+            store: inmemory\n+        rule_path: /tmp/loki\n+        storage:\n+          type: local\n+          local:\n+            directory: /loki/rules\n       table_manager:\n         retention_deletes_enabled: true\n         retention_period: 2184h\n+    extraVolumeMounts:\n+      - name: rules\n+        mountPath: /loki/rules/fake\n+      - name: tmp\n+        mountPath: /tmp/loki\n+    extraVolumes:\n+      - name: rules\n+        configMap:\n+          defaultMode: 420\n+          name: loki-rules\n+      - name: tmp\n+        emptyDir: {}\n     networkPolicy:\n       enabled: true\n     persistence:\n       enabled: true\n+      size: 100Gi\n+    prometheusRules:\n+      # TODO: Enhance Loki to support watching for PrometheusRules via the Kubernetes API so we can declare these within their chart\n+      GrpcLogErrors:\n+        annotations:\n+          description: \"Logs for {{ $labels.namespace }}/{{ $labels.pod }} have reached {{ $value }} error messages/s in a 3m period\"\n+          summary: High rate of errors in logs\n+        enabled: true\n+        expr: >\n+          sum(rate({app_kubernetes_io_component=\"grpc\"}\n+            | regexp `(?P<timestamp>\\S+) (?P<level>\\S+) (?P<thread>\\S+) (?P<class>\\S+) (?P<message>.+)`\n+            | level = \"ERROR\"\n+            != \"reactor.core.publisher\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjM1Njc1OA=="}, "originalCommit": {"oid": "43c5188707241816d8c88a6dea0b96c2858b2a36"}, "originalPosition": 47}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1446, "cost": 1, "resetAt": "2021-11-12T20:28:25Z"}}}