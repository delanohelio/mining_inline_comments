{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzc5MTg5MTg1", "number": 553, "reviewThreads": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxNzo0MzoxOVrODjLMpg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QxODoxODoyMFrODjj4uw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM4MjEwMjE0OnYy", "diffSide": "RIGHT", "path": "docs/design/parser.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxNzo0MzoxOVrOFu1jLA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxNzo0MzoxOVrOFu1jLA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDY1NjE3Mg==", "bodyText": "Should add transaction record bytes as well", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/553#discussion_r384656172", "createdAt": "2020-02-26T17:43:19Z", "author": {"login": "steven-sheehy"}, "path": "docs/design/parser.md", "diffHunk": "@@ -0,0 +1,172 @@\n+# Parser design\n+\n+## Problems in current design\n+\n+SQL Database client is tightly coupled with transaction & record's processor which makes:\n+\n+-   ingesting mirror node date into other types of database like Cassandra, Bigtable, etc. very hard\n+-   benchmarking only parser's or only database ingestion performance in impossible\n+\n+## Goal\n+\n+1. Decouple parsing of stream from ingestion into a database\n+1. Abstractions should support measuring (a) parser's performance and (b) database ingestion performance, in isolation\n+\n+## Non-goals\n+\n+-   Change importer from filesystem based to in-memory streaming\n+-   Parsing multiple rcd/balance/etc files in parallel. Parser is far from being bottleneck, there is no need to optimize it\n+-   Accommodate possibility of publishing transactions/topic messages/etc to GRPC server directly\n+-   Support writing to multiple databases from single importer\n+-   Update balance file parser code immediately\n+\n+## Architecture\n+\n+#### Data Flow\n+\n+![Data Flow](images/parser-events-hander-data-flow.png)\n+\n+-   Record files --> RecordFileReader --> RecordFileParser --> RecordItemParser --> RecordStreamEventsHandler --> DB\n+\n+#### Control Flow\n+\n+![Control Flow](images/parser-events-hander-control-flow.png)\n+\n+### EventsHandler\n+\n+```java\n+public interface StreamEventsHandler {\n+    void onBatchStart(String batchName) throws ImporterException;\n+    void onBatchComplete(String batchName) throws ImporterException;\n+    void onError(Throwable e);\n+}\n+\n+public interface RecordStreamEventsHandler extends StreamEventsHandler {\n+    void onTransaction(c.h.m.i.d.Transaction) throws ImporterException;\n+    void onEntity(c.h.m.i.d.Entities) throws ImporterException;\n+    void onEntityUpdate(c.h.m.i.d.Entities) throws ImporterException;\n+    void onCryptoTransferList(c.h.m.i.d.CryptoTransfer) throws ImporterException;\n+    void onTopicMessage(c.h.m.i.d.TopicMessage) throws ImporterException;\n+}\n+\n+public interface BalanceEventsHandler extends StreamEventsHandler {\n+    void onBalance(c.h.m.i.d.Balance) throws ImporterException;\n+}\n+```\n+\n+1. There will be following implementations for `RecordStreamEventsHandler`:\n+    1. `PostgresWritingRecordStreamEventsHandler`:\n+        - For writing stream data to Postgres database\n+        - For `data-generator` to test database insert performance in isolation (from parser)\n+    1. `NullRecordStreamEventsHandler`: Discards all events and do nothing.\n+        - For micro-benchmarking parser performance\n+    1. `StreamFileWriterRecordStreamEventsHandler`: Package stream data into .rcd/balance/etc file.\n+        - For `data-generator` to generate custom stream files for testing: end-to-end importer perf test, parser + db\n+          perf test, isolated parser micro-benchmark, etc\n+\n+### RecordItemParser\n+\n+```java\n+public class RecordItemParser {\n+    private final RecordStreamEventsHandler RecordStreamEventsHandler;  // injected dependency\n+\n+    public void onRecordItem(RecordItem recordItem) throws ImporterException {\n+        // process recordItem\n+    }\n+}\n+```\n+\n+```java\n+@Value\n+public class RecordItem {\n+    private final Transaction transaction;\n+    private final TransactionRecord record;\n+    private final byte[] transactionRawBytes;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "496383c55255481fe5bc9ee85b39a01d21d5cb19"}, "originalPosition": 84}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM4MjEzMzgwOnYy", "diffSide": "RIGHT", "path": "docs/design/parser.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxNzo1MjoxNlrOFu12vw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxNzo1MjoxNlrOFu12vw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDY2MTE4Mw==", "bodyText": "transactionBytes to match field in our domain", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/553#discussion_r384661183", "createdAt": "2020-02-26T17:52:16Z", "author": {"login": "steven-sheehy"}, "path": "docs/design/parser.md", "diffHunk": "@@ -0,0 +1,172 @@\n+# Parser design\n+\n+## Problems in current design\n+\n+SQL Database client is tightly coupled with transaction & record's processor which makes:\n+\n+-   ingesting mirror node date into other types of database like Cassandra, Bigtable, etc. very hard\n+-   benchmarking only parser's or only database ingestion performance in impossible\n+\n+## Goal\n+\n+1. Decouple parsing of stream from ingestion into a database\n+1. Abstractions should support measuring (a) parser's performance and (b) database ingestion performance, in isolation\n+\n+## Non-goals\n+\n+-   Change importer from filesystem based to in-memory streaming\n+-   Parsing multiple rcd/balance/etc files in parallel. Parser is far from being bottleneck, there is no need to optimize it\n+-   Accommodate possibility of publishing transactions/topic messages/etc to GRPC server directly\n+-   Support writing to multiple databases from single importer\n+-   Update balance file parser code immediately\n+\n+## Architecture\n+\n+#### Data Flow\n+\n+![Data Flow](images/parser-events-hander-data-flow.png)\n+\n+-   Record files --> RecordFileReader --> RecordFileParser --> RecordItemParser --> RecordStreamEventsHandler --> DB\n+\n+#### Control Flow\n+\n+![Control Flow](images/parser-events-hander-control-flow.png)\n+\n+### EventsHandler\n+\n+```java\n+public interface StreamEventsHandler {\n+    void onBatchStart(String batchName) throws ImporterException;\n+    void onBatchComplete(String batchName) throws ImporterException;\n+    void onError(Throwable e);\n+}\n+\n+public interface RecordStreamEventsHandler extends StreamEventsHandler {\n+    void onTransaction(c.h.m.i.d.Transaction) throws ImporterException;\n+    void onEntity(c.h.m.i.d.Entities) throws ImporterException;\n+    void onEntityUpdate(c.h.m.i.d.Entities) throws ImporterException;\n+    void onCryptoTransferList(c.h.m.i.d.CryptoTransfer) throws ImporterException;\n+    void onTopicMessage(c.h.m.i.d.TopicMessage) throws ImporterException;\n+}\n+\n+public interface BalanceEventsHandler extends StreamEventsHandler {\n+    void onBalance(c.h.m.i.d.Balance) throws ImporterException;\n+}\n+```\n+\n+1. There will be following implementations for `RecordStreamEventsHandler`:\n+    1. `PostgresWritingRecordStreamEventsHandler`:\n+        - For writing stream data to Postgres database\n+        - For `data-generator` to test database insert performance in isolation (from parser)\n+    1. `NullRecordStreamEventsHandler`: Discards all events and do nothing.\n+        - For micro-benchmarking parser performance\n+    1. `StreamFileWriterRecordStreamEventsHandler`: Package stream data into .rcd/balance/etc file.\n+        - For `data-generator` to generate custom stream files for testing: end-to-end importer perf test, parser + db\n+          perf test, isolated parser micro-benchmark, etc\n+\n+### RecordItemParser\n+\n+```java\n+public class RecordItemParser {\n+    private final RecordStreamEventsHandler RecordStreamEventsHandler;  // injected dependency\n+\n+    public void onRecordItem(RecordItem recordItem) throws ImporterException {\n+        // process recordItem\n+    }\n+}\n+```\n+\n+```java\n+@Value\n+public class RecordItem {\n+    private final Transaction transaction;\n+    private final TransactionRecord record;\n+    private final byte[] transactionRawBytes;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "496383c55255481fe5bc9ee85b39a01d21d5cb19"}, "originalPosition": 84}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM4MzAzODE0OnYy", "diffSide": "RIGHT", "path": "docs/design/parser.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQyMjoyMTozNFrOFu-hwg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQyMjoyMTozNFrOFu-hwg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDgwMzI2Ng==", "bodyText": "Instead of Foo can we just show Record in the diagram, remove the extra text flow below and add a note that a similar flow will exist for balance and event?", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/553#discussion_r384803266", "createdAt": "2020-02-26T22:21:34Z", "author": {"login": "steven-sheehy"}, "path": "docs/design/parser.md", "diffHunk": "@@ -0,0 +1,220 @@\n+# Parser design\n+\n+## Problems in current design\n+\n+SQL Database client is tightly coupled with transaction & record's processor which makes:\n+\n+-   ingesting mirror node date into other types of database like Cassandra, Bigtable, etc. very hard\n+-   benchmarking only parser's or only database ingestion performance in impossible\n+\n+## Goal\n+\n+1. Decouple parsing of stream from ingestion into a database\n+1. Abstractions should support measuring (a) parser's performance and (b) database ingestion performance, in isolation\n+\n+## Non-goals\n+\n+-   Change importer from filesystem based to in-memory streaming\n+-   Parsing multiple rcd/balance/etc files in parallel. Parser is far from being bottleneck, there is no need to optimize it\n+-   Accommodate possibility of publishing transactions/topic messages/etc to GRPC server directly\n+-   Support writing to multiple databases from single importer\n+-   Update balance file parser code immediately\n+\n+## Architecture\n+\n+#### Data Flow\n+\n+![Data Flow](images/parser-events-hander-data-flow.png)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0c3c12990351821c01cde4321675ac45a47c6d34"}, "originalPosition": 27}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM4NjA3MjMwOnYy", "diffSide": "RIGHT", "path": "docs/design/parser.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QxNzo1NDozNVrOFvbQNw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QxNzo1NDozNVrOFvbQNw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTI3MzkxMQ==", "bodyText": "Add a non-goal that we are not attempting to make mirror node be ran without PostgreSQL. It will still require it to store application state.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/553#discussion_r385273911", "createdAt": "2020-02-27T17:54:35Z", "author": {"login": "steven-sheehy"}, "path": "docs/design/parser.md", "diffHunk": "@@ -0,0 +1,238 @@\n+# Parser design\n+\n+## Problems in current design\n+\n+SQL Database client is tightly coupled with transaction & record's processor which makes:\n+\n+-   ingesting mirror node date into other types of database like Cassandra, Bigtable, etc. very hard\n+-   benchmarking only parser's or only database ingestion performance in impossible\n+\n+## Goal\n+\n+1. Decouple parsing of stream from ingestion into a database\n+1. Abstractions should support measuring (a) parser's performance and (b) database ingestion performance, in isolation\n+\n+## Non-goals\n+\n+-   Change importer from filesystem based to in-memory streaming\n+-   Parsing multiple rcd/balance/etc files in parallel. Parser is far from being bottleneck, there is no need to optimize it\n+-   Accommodate possibility of publishing transactions/topic messages/etc to GRPC server directly\n+-   Support writing to multiple databases from single importer\n+-   Update balance file parser code immediately", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "849bda79d3adeb0dc68938d7e0bae6d7fb20622d"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM4NjEwODAwOnYy", "diffSide": "RIGHT", "path": "docs/design/parser.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QxODowNTo0MlrOFvbnPw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QyMzowNjoyOVrOFvkVSg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTI3OTgwNw==", "bodyText": "These 3 methods should be removed. Coupling the parser to the handler is not a good idea as the handler doesn't care if it comes from a file or gossip nor that it is batch together or not. We won't be able to batch tens of thousands of transactions in a single transaction either, so item listener will have to have separate batching mechanism.\nonError is not necessary either. We don't currently have a parse error and notify recordfilelogger about it. We just notify about new transactions that reached consensus.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/553#discussion_r385279807", "createdAt": "2020-02-27T18:05:42Z", "author": {"login": "steven-sheehy"}, "path": "docs/design/parser.md", "diffHunk": "@@ -0,0 +1,238 @@\n+# Parser design\n+\n+## Problems in current design\n+\n+SQL Database client is tightly coupled with transaction & record's processor which makes:\n+\n+-   ingesting mirror node date into other types of database like Cassandra, Bigtable, etc. very hard\n+-   benchmarking only parser's or only database ingestion performance in impossible\n+\n+## Goal\n+\n+1. Decouple parsing of stream from ingestion into a database\n+1. Abstractions should support measuring (a) parser's performance and (b) database ingestion performance, in isolation\n+\n+## Non-goals\n+\n+-   Change importer from filesystem based to in-memory streaming\n+-   Parsing multiple rcd/balance/etc files in parallel. Parser is far from being bottleneck, there is no need to optimize it\n+-   Accommodate possibility of publishing transactions/topic messages/etc to GRPC server directly\n+-   Support writing to multiple databases from single importer\n+-   Update balance file parser code immediately\n+\n+## Architecture\n+\n+#### Data Flow\n+\n+![Data Flow](images/parser-events-hander-data-flow.png)\n+\n+-   Record files --> RecordFileReader --> RecordFileListener --> RecordItemListener --> RecordStreamEventsHandler --> DB\n+\n+#### Control Flow\n+\n+![Control Flow](images/parser-events-hander-control-flow.png)\n+\n+### EventsHandler\n+\n+```java\n+package com.hedera.mirror.importer.parser.domain;\n+\n+public class StreamFileInfo {\n+    String filename;\n+    String fileHash;\n+    String prevFileHash;\n+}\n+```\n+\n+```java\n+package com.hedera.mirror.importer.parser;\n+\n+public interface StreamEventsHandler {\n+    void onFileStart(StreamFileInfo streamFileInfo) throws ImporterException;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "849bda79d3adeb0dc68938d7e0bae6d7fb20622d"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTQyMjY2Ng==", "bodyText": "resolving since we discussed this in the meeting.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/553#discussion_r385422666", "createdAt": "2020-02-27T23:06:29Z", "author": {"login": "apeksharma"}, "path": "docs/design/parser.md", "diffHunk": "@@ -0,0 +1,238 @@\n+# Parser design\n+\n+## Problems in current design\n+\n+SQL Database client is tightly coupled with transaction & record's processor which makes:\n+\n+-   ingesting mirror node date into other types of database like Cassandra, Bigtable, etc. very hard\n+-   benchmarking only parser's or only database ingestion performance in impossible\n+\n+## Goal\n+\n+1. Decouple parsing of stream from ingestion into a database\n+1. Abstractions should support measuring (a) parser's performance and (b) database ingestion performance, in isolation\n+\n+## Non-goals\n+\n+-   Change importer from filesystem based to in-memory streaming\n+-   Parsing multiple rcd/balance/etc files in parallel. Parser is far from being bottleneck, there is no need to optimize it\n+-   Accommodate possibility of publishing transactions/topic messages/etc to GRPC server directly\n+-   Support writing to multiple databases from single importer\n+-   Update balance file parser code immediately\n+\n+## Architecture\n+\n+#### Data Flow\n+\n+![Data Flow](images/parser-events-hander-data-flow.png)\n+\n+-   Record files --> RecordFileReader --> RecordFileListener --> RecordItemListener --> RecordStreamEventsHandler --> DB\n+\n+#### Control Flow\n+\n+![Control Flow](images/parser-events-hander-control-flow.png)\n+\n+### EventsHandler\n+\n+```java\n+package com.hedera.mirror.importer.parser.domain;\n+\n+public class StreamFileInfo {\n+    String filename;\n+    String fileHash;\n+    String prevFileHash;\n+}\n+```\n+\n+```java\n+package com.hedera.mirror.importer.parser;\n+\n+public interface StreamEventsHandler {\n+    void onFileStart(StreamFileInfo streamFileInfo) throws ImporterException;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTI3OTgwNw=="}, "originalCommit": {"oid": "849bda79d3adeb0dc68938d7e0bae6d7fb20622d"}, "originalPosition": 51}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM4NjExODQyOnYy", "diffSide": "RIGHT", "path": "docs/design/parser.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QxODowOTowOVrOFvbtvA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QxODowOTowOVrOFvbtvA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTI4MTQ2OA==", "bodyText": "Would be nice to have marker interface to share among different item types", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/553#discussion_r385281468", "createdAt": "2020-02-27T18:09:09Z", "author": {"login": "steven-sheehy"}, "path": "docs/design/parser.md", "diffHunk": "@@ -0,0 +1,238 @@\n+# Parser design\n+\n+## Problems in current design\n+\n+SQL Database client is tightly coupled with transaction & record's processor which makes:\n+\n+-   ingesting mirror node date into other types of database like Cassandra, Bigtable, etc. very hard\n+-   benchmarking only parser's or only database ingestion performance in impossible\n+\n+## Goal\n+\n+1. Decouple parsing of stream from ingestion into a database\n+1. Abstractions should support measuring (a) parser's performance and (b) database ingestion performance, in isolation\n+\n+## Non-goals\n+\n+-   Change importer from filesystem based to in-memory streaming\n+-   Parsing multiple rcd/balance/etc files in parallel. Parser is far from being bottleneck, there is no need to optimize it\n+-   Accommodate possibility of publishing transactions/topic messages/etc to GRPC server directly\n+-   Support writing to multiple databases from single importer\n+-   Update balance file parser code immediately\n+\n+## Architecture\n+\n+#### Data Flow\n+\n+![Data Flow](images/parser-events-hander-data-flow.png)\n+\n+-   Record files --> RecordFileReader --> RecordFileListener --> RecordItemListener --> RecordStreamEventsHandler --> DB\n+\n+#### Control Flow\n+\n+![Control Flow](images/parser-events-hander-control-flow.png)\n+\n+### EventsHandler\n+\n+```java\n+package com.hedera.mirror.importer.parser.domain;\n+\n+public class StreamFileInfo {\n+    String filename;\n+    String fileHash;\n+    String prevFileHash;\n+}\n+```\n+\n+```java\n+package com.hedera.mirror.importer.parser;\n+\n+public interface StreamEventsHandler {\n+    void onFileStart(StreamFileInfo streamFileInfo) throws ImporterException;\n+    void onFileComplete(StreamFileInfo streamFileInfo) throws ImporterException;\n+    void onError();\n+}\n+```\n+\n+```java\n+package com.hedera.mirror.importer.parser.record;\n+\n+public interface RecordStreamEventsHandler extends StreamEventsHandler {\n+    void onTransaction(c.h.m.i.d.Transaction transaction) throws ImporterException;\n+    void onCryptoTransferList(c.h.m.i.d.CryptoTransfer cryptoTransfer) throws ImporterException;\n+    void onNonFeeTransfer(c.h.m.i.d.NonFeeTransfer nonFeeTransfer) throws ImporterException;\n+    void onTopicMessage(c.h.m.i.d.TopicMessage topicMessage) throws ImporterException;\n+    void onContractResult(c.h.m.i.d.ContractResult contractResult) throws ImporterException;\n+    void onFileData(c.h.m.i.d.FileData fileData) throws ImporterException;\n+    void onLiveHash(c.h.m.i.d.LiveHash liveHash) throws ImporterException;\n+}\n+```\n+\n+```java\n+package com.hedera.mirror.importer.parser.balance;\n+\n+public interface BalanceEventsHandler extends StreamEventsHandler {\n+    void onBalance(c.h.m.i.d.Balance balance) throws ImporterException;\n+}\n+```\n+\n+1. There will be following implementations for `RecordStreamEventsHandler`:\n+    1. `PostgresWritingRecordStreamEventsHandler`:\n+        - For writing stream data to Postgres database\n+        - For `data-generator` to test database insert performance in isolation (from parser)\n+    1. `NullRecordStreamEventsHandler`: Discards all events and do nothing.\n+        - For micro-benchmarking parser performance\n+    1. `StreamFileWriterRecordStreamEventsHandler`: Package stream data into .rcd/balance/etc file.\n+        - For `data-generator` to generate custom stream files for testing: end-to-end importer perf test, parser + db\n+          perf test, isolated parser micro-benchmark, etc\n+\n+Note that there are no functions for entities. Updating entities in batch in not possible right now since\n+`t_transactions` table refers to entity ids. For entities, first, schema changes are needed to remove entity ids,\n+then `onEntity` and `onEntityUpdate` functions will be added to insert/update entities in bulk. For the purpose of\n+immediate refactor, we can leave entities in `RecordItemParser` (until perf optimizations via schema change in\n+milestone 2).\n+\n+### StreamItemListener\n+\n+```java\n+package com.hedera.mirror.importer.parser;\n+\n+public interface StreamItemListener<T> {\n+    void onItem(T item) throws ImporterException;\n+}\n+```\n+\n+#### RecordItemListener\n+\n+```java\n+package com.hedera.mirror.importer.parser.record;\n+\n+public interface RecordItemListener extends StreamItemListener<RecordItem> {\n+}\n+```\n+\n+```java\n+package com.hedera.mirror.importer.parser.domain;\n+\n+@Value\n+public class RecordItem {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "849bda79d3adeb0dc68938d7e0bae6d7fb20622d"}, "originalPosition": 118}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM4NjE0NzE1OnYy", "diffSide": "RIGHT", "path": "docs/design/parser.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QxODoxODoyMFrOFvcALg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QxODoxODoyMFrOFvcALg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTI4NjE5MA==", "bodyText": "Not a fan of this name since Events is mixed with gossip events. Maybe parsed something to indicate its converted from proto to our domain? ParsedItemHandler?", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/553#discussion_r385286190", "createdAt": "2020-02-27T18:18:20Z", "author": {"login": "steven-sheehy"}, "path": "docs/design/parser.md", "diffHunk": "@@ -0,0 +1,238 @@\n+# Parser design\n+\n+## Problems in current design\n+\n+SQL Database client is tightly coupled with transaction & record's processor which makes:\n+\n+-   ingesting mirror node date into other types of database like Cassandra, Bigtable, etc. very hard\n+-   benchmarking only parser's or only database ingestion performance in impossible\n+\n+## Goal\n+\n+1. Decouple parsing of stream from ingestion into a database\n+1. Abstractions should support measuring (a) parser's performance and (b) database ingestion performance, in isolation\n+\n+## Non-goals\n+\n+-   Change importer from filesystem based to in-memory streaming\n+-   Parsing multiple rcd/balance/etc files in parallel. Parser is far from being bottleneck, there is no need to optimize it\n+-   Accommodate possibility of publishing transactions/topic messages/etc to GRPC server directly\n+-   Support writing to multiple databases from single importer\n+-   Update balance file parser code immediately\n+\n+## Architecture\n+\n+#### Data Flow\n+\n+![Data Flow](images/parser-events-hander-data-flow.png)\n+\n+-   Record files --> RecordFileReader --> RecordFileListener --> RecordItemListener --> RecordStreamEventsHandler --> DB\n+\n+#### Control Flow\n+\n+![Control Flow](images/parser-events-hander-control-flow.png)\n+\n+### EventsHandler\n+\n+```java\n+package com.hedera.mirror.importer.parser.domain;\n+\n+public class StreamFileInfo {\n+    String filename;\n+    String fileHash;\n+    String prevFileHash;\n+}\n+```\n+\n+```java\n+package com.hedera.mirror.importer.parser;\n+\n+public interface StreamEventsHandler {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "849bda79d3adeb0dc68938d7e0bae6d7fb20622d"}, "originalPosition": 50}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1173, "cost": 1, "resetAt": "2021-11-12T20:28:25Z"}}}