{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzc5MTg5MTg1", "number": 553, "title": "Parser re-design", "bodyText": "Detailed description:\nQuick link to doc: https://github.com/hashgraph/hedera-mirror-node/blob/parser_design/docs/design/parser.md\nWhich issue(s) this PR fixes:\nFixes #554\nSpecial notes for your reviewer:\nChecklist\n\n Documentation added\n Tests updated", "createdAt": "2020-02-24T19:47:55Z", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/553", "merged": true, "mergeCommit": {"oid": "f6727632f69d54556ae672929620591b9406569e"}, "closed": true, "closedAt": "2020-02-28T17:38:32Z", "author": {"login": "apeksharma"}, "timelineItems": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcIDVWtgBqjMwNzI4NDYwMjU=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcIzgssgFqTM2NjU2OTExNw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "640488a0a1fe54f99ce8f0e30181e1bd69fcd62a", "author": {"user": {"login": "apeksharma", "name": "Apekshit Sharma"}}, "url": "https://github.com/hashgraph/hedera-mirror-node/commit/640488a0a1fe54f99ce8f0e30181e1bd69fcd62a", "committedDate": "2020-02-24T19:46:49Z", "message": "parser design"}, "afterCommit": {"oid": "2e18c0d768f115e8038c572631ce62744e63a425", "author": {"user": {"login": "apeksharma", "name": "Apekshit Sharma"}}, "url": "https://github.com/hashgraph/hedera-mirror-node/commit/2e18c0d768f115e8038c572631ce62744e63a425", "committedDate": "2020-02-26T09:29:43Z", "message": "Address review comments\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY1MDg5NTU5", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/553#pullrequestreview-365089559", "createdAt": "2020-02-26T17:17:59Z", "commit": {"oid": "496383c55255481fe5bc9ee85b39a01d21d5cb19"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQxNzo0MzoxOVrOFu1jLA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yN1QxODoxODoyMFrOFvcALg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDY1NjE3Mg==", "bodyText": "Should add transaction record bytes as well", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/553#discussion_r384656172", "createdAt": "2020-02-26T17:43:19Z", "author": {"login": "steven-sheehy"}, "path": "docs/design/parser.md", "diffHunk": "@@ -0,0 +1,172 @@\n+# Parser design\n+\n+## Problems in current design\n+\n+SQL Database client is tightly coupled with transaction & record's processor which makes:\n+\n+-   ingesting mirror node date into other types of database like Cassandra, Bigtable, etc. very hard\n+-   benchmarking only parser's or only database ingestion performance in impossible\n+\n+## Goal\n+\n+1. Decouple parsing of stream from ingestion into a database\n+1. Abstractions should support measuring (a) parser's performance and (b) database ingestion performance, in isolation\n+\n+## Non-goals\n+\n+-   Change importer from filesystem based to in-memory streaming\n+-   Parsing multiple rcd/balance/etc files in parallel. Parser is far from being bottleneck, there is no need to optimize it\n+-   Accommodate possibility of publishing transactions/topic messages/etc to GRPC server directly\n+-   Support writing to multiple databases from single importer\n+-   Update balance file parser code immediately\n+\n+## Architecture\n+\n+#### Data Flow\n+\n+![Data Flow](images/parser-events-hander-data-flow.png)\n+\n+-   Record files --> RecordFileReader --> RecordFileParser --> RecordItemParser --> RecordStreamEventsHandler --> DB\n+\n+#### Control Flow\n+\n+![Control Flow](images/parser-events-hander-control-flow.png)\n+\n+### EventsHandler\n+\n+```java\n+public interface StreamEventsHandler {\n+    void onBatchStart(String batchName) throws ImporterException;\n+    void onBatchComplete(String batchName) throws ImporterException;\n+    void onError(Throwable e);\n+}\n+\n+public interface RecordStreamEventsHandler extends StreamEventsHandler {\n+    void onTransaction(c.h.m.i.d.Transaction) throws ImporterException;\n+    void onEntity(c.h.m.i.d.Entities) throws ImporterException;\n+    void onEntityUpdate(c.h.m.i.d.Entities) throws ImporterException;\n+    void onCryptoTransferList(c.h.m.i.d.CryptoTransfer) throws ImporterException;\n+    void onTopicMessage(c.h.m.i.d.TopicMessage) throws ImporterException;\n+}\n+\n+public interface BalanceEventsHandler extends StreamEventsHandler {\n+    void onBalance(c.h.m.i.d.Balance) throws ImporterException;\n+}\n+```\n+\n+1. There will be following implementations for `RecordStreamEventsHandler`:\n+    1. `PostgresWritingRecordStreamEventsHandler`:\n+        - For writing stream data to Postgres database\n+        - For `data-generator` to test database insert performance in isolation (from parser)\n+    1. `NullRecordStreamEventsHandler`: Discards all events and do nothing.\n+        - For micro-benchmarking parser performance\n+    1. `StreamFileWriterRecordStreamEventsHandler`: Package stream data into .rcd/balance/etc file.\n+        - For `data-generator` to generate custom stream files for testing: end-to-end importer perf test, parser + db\n+          perf test, isolated parser micro-benchmark, etc\n+\n+### RecordItemParser\n+\n+```java\n+public class RecordItemParser {\n+    private final RecordStreamEventsHandler RecordStreamEventsHandler;  // injected dependency\n+\n+    public void onRecordItem(RecordItem recordItem) throws ImporterException {\n+        // process recordItem\n+    }\n+}\n+```\n+\n+```java\n+@Value\n+public class RecordItem {\n+    private final Transaction transaction;\n+    private final TransactionRecord record;\n+    private final byte[] transactionRawBytes;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "496383c55255481fe5bc9ee85b39a01d21d5cb19"}, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDY2MTE4Mw==", "bodyText": "transactionBytes to match field in our domain", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/553#discussion_r384661183", "createdAt": "2020-02-26T17:52:16Z", "author": {"login": "steven-sheehy"}, "path": "docs/design/parser.md", "diffHunk": "@@ -0,0 +1,172 @@\n+# Parser design\n+\n+## Problems in current design\n+\n+SQL Database client is tightly coupled with transaction & record's processor which makes:\n+\n+-   ingesting mirror node date into other types of database like Cassandra, Bigtable, etc. very hard\n+-   benchmarking only parser's or only database ingestion performance in impossible\n+\n+## Goal\n+\n+1. Decouple parsing of stream from ingestion into a database\n+1. Abstractions should support measuring (a) parser's performance and (b) database ingestion performance, in isolation\n+\n+## Non-goals\n+\n+-   Change importer from filesystem based to in-memory streaming\n+-   Parsing multiple rcd/balance/etc files in parallel. Parser is far from being bottleneck, there is no need to optimize it\n+-   Accommodate possibility of publishing transactions/topic messages/etc to GRPC server directly\n+-   Support writing to multiple databases from single importer\n+-   Update balance file parser code immediately\n+\n+## Architecture\n+\n+#### Data Flow\n+\n+![Data Flow](images/parser-events-hander-data-flow.png)\n+\n+-   Record files --> RecordFileReader --> RecordFileParser --> RecordItemParser --> RecordStreamEventsHandler --> DB\n+\n+#### Control Flow\n+\n+![Control Flow](images/parser-events-hander-control-flow.png)\n+\n+### EventsHandler\n+\n+```java\n+public interface StreamEventsHandler {\n+    void onBatchStart(String batchName) throws ImporterException;\n+    void onBatchComplete(String batchName) throws ImporterException;\n+    void onError(Throwable e);\n+}\n+\n+public interface RecordStreamEventsHandler extends StreamEventsHandler {\n+    void onTransaction(c.h.m.i.d.Transaction) throws ImporterException;\n+    void onEntity(c.h.m.i.d.Entities) throws ImporterException;\n+    void onEntityUpdate(c.h.m.i.d.Entities) throws ImporterException;\n+    void onCryptoTransferList(c.h.m.i.d.CryptoTransfer) throws ImporterException;\n+    void onTopicMessage(c.h.m.i.d.TopicMessage) throws ImporterException;\n+}\n+\n+public interface BalanceEventsHandler extends StreamEventsHandler {\n+    void onBalance(c.h.m.i.d.Balance) throws ImporterException;\n+}\n+```\n+\n+1. There will be following implementations for `RecordStreamEventsHandler`:\n+    1. `PostgresWritingRecordStreamEventsHandler`:\n+        - For writing stream data to Postgres database\n+        - For `data-generator` to test database insert performance in isolation (from parser)\n+    1. `NullRecordStreamEventsHandler`: Discards all events and do nothing.\n+        - For micro-benchmarking parser performance\n+    1. `StreamFileWriterRecordStreamEventsHandler`: Package stream data into .rcd/balance/etc file.\n+        - For `data-generator` to generate custom stream files for testing: end-to-end importer perf test, parser + db\n+          perf test, isolated parser micro-benchmark, etc\n+\n+### RecordItemParser\n+\n+```java\n+public class RecordItemParser {\n+    private final RecordStreamEventsHandler RecordStreamEventsHandler;  // injected dependency\n+\n+    public void onRecordItem(RecordItem recordItem) throws ImporterException {\n+        // process recordItem\n+    }\n+}\n+```\n+\n+```java\n+@Value\n+public class RecordItem {\n+    private final Transaction transaction;\n+    private final TransactionRecord record;\n+    private final byte[] transactionRawBytes;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "496383c55255481fe5bc9ee85b39a01d21d5cb19"}, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDgwMzI2Ng==", "bodyText": "Instead of Foo can we just show Record in the diagram, remove the extra text flow below and add a note that a similar flow will exist for balance and event?", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/553#discussion_r384803266", "createdAt": "2020-02-26T22:21:34Z", "author": {"login": "steven-sheehy"}, "path": "docs/design/parser.md", "diffHunk": "@@ -0,0 +1,220 @@\n+# Parser design\n+\n+## Problems in current design\n+\n+SQL Database client is tightly coupled with transaction & record's processor which makes:\n+\n+-   ingesting mirror node date into other types of database like Cassandra, Bigtable, etc. very hard\n+-   benchmarking only parser's or only database ingestion performance in impossible\n+\n+## Goal\n+\n+1. Decouple parsing of stream from ingestion into a database\n+1. Abstractions should support measuring (a) parser's performance and (b) database ingestion performance, in isolation\n+\n+## Non-goals\n+\n+-   Change importer from filesystem based to in-memory streaming\n+-   Parsing multiple rcd/balance/etc files in parallel. Parser is far from being bottleneck, there is no need to optimize it\n+-   Accommodate possibility of publishing transactions/topic messages/etc to GRPC server directly\n+-   Support writing to multiple databases from single importer\n+-   Update balance file parser code immediately\n+\n+## Architecture\n+\n+#### Data Flow\n+\n+![Data Flow](images/parser-events-hander-data-flow.png)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0c3c12990351821c01cde4321675ac45a47c6d34"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTI3MzkxMQ==", "bodyText": "Add a non-goal that we are not attempting to make mirror node be ran without PostgreSQL. It will still require it to store application state.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/553#discussion_r385273911", "createdAt": "2020-02-27T17:54:35Z", "author": {"login": "steven-sheehy"}, "path": "docs/design/parser.md", "diffHunk": "@@ -0,0 +1,238 @@\n+# Parser design\n+\n+## Problems in current design\n+\n+SQL Database client is tightly coupled with transaction & record's processor which makes:\n+\n+-   ingesting mirror node date into other types of database like Cassandra, Bigtable, etc. very hard\n+-   benchmarking only parser's or only database ingestion performance in impossible\n+\n+## Goal\n+\n+1. Decouple parsing of stream from ingestion into a database\n+1. Abstractions should support measuring (a) parser's performance and (b) database ingestion performance, in isolation\n+\n+## Non-goals\n+\n+-   Change importer from filesystem based to in-memory streaming\n+-   Parsing multiple rcd/balance/etc files in parallel. Parser is far from being bottleneck, there is no need to optimize it\n+-   Accommodate possibility of publishing transactions/topic messages/etc to GRPC server directly\n+-   Support writing to multiple databases from single importer\n+-   Update balance file parser code immediately", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "849bda79d3adeb0dc68938d7e0bae6d7fb20622d"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTI3OTgwNw==", "bodyText": "These 3 methods should be removed. Coupling the parser to the handler is not a good idea as the handler doesn't care if it comes from a file or gossip nor that it is batch together or not. We won't be able to batch tens of thousands of transactions in a single transaction either, so item listener will have to have separate batching mechanism.\nonError is not necessary either. We don't currently have a parse error and notify recordfilelogger about it. We just notify about new transactions that reached consensus.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/553#discussion_r385279807", "createdAt": "2020-02-27T18:05:42Z", "author": {"login": "steven-sheehy"}, "path": "docs/design/parser.md", "diffHunk": "@@ -0,0 +1,238 @@\n+# Parser design\n+\n+## Problems in current design\n+\n+SQL Database client is tightly coupled with transaction & record's processor which makes:\n+\n+-   ingesting mirror node date into other types of database like Cassandra, Bigtable, etc. very hard\n+-   benchmarking only parser's or only database ingestion performance in impossible\n+\n+## Goal\n+\n+1. Decouple parsing of stream from ingestion into a database\n+1. Abstractions should support measuring (a) parser's performance and (b) database ingestion performance, in isolation\n+\n+## Non-goals\n+\n+-   Change importer from filesystem based to in-memory streaming\n+-   Parsing multiple rcd/balance/etc files in parallel. Parser is far from being bottleneck, there is no need to optimize it\n+-   Accommodate possibility of publishing transactions/topic messages/etc to GRPC server directly\n+-   Support writing to multiple databases from single importer\n+-   Update balance file parser code immediately\n+\n+## Architecture\n+\n+#### Data Flow\n+\n+![Data Flow](images/parser-events-hander-data-flow.png)\n+\n+-   Record files --> RecordFileReader --> RecordFileListener --> RecordItemListener --> RecordStreamEventsHandler --> DB\n+\n+#### Control Flow\n+\n+![Control Flow](images/parser-events-hander-control-flow.png)\n+\n+### EventsHandler\n+\n+```java\n+package com.hedera.mirror.importer.parser.domain;\n+\n+public class StreamFileInfo {\n+    String filename;\n+    String fileHash;\n+    String prevFileHash;\n+}\n+```\n+\n+```java\n+package com.hedera.mirror.importer.parser;\n+\n+public interface StreamEventsHandler {\n+    void onFileStart(StreamFileInfo streamFileInfo) throws ImporterException;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "849bda79d3adeb0dc68938d7e0bae6d7fb20622d"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTI4MTQ2OA==", "bodyText": "Would be nice to have marker interface to share among different item types", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/553#discussion_r385281468", "createdAt": "2020-02-27T18:09:09Z", "author": {"login": "steven-sheehy"}, "path": "docs/design/parser.md", "diffHunk": "@@ -0,0 +1,238 @@\n+# Parser design\n+\n+## Problems in current design\n+\n+SQL Database client is tightly coupled with transaction & record's processor which makes:\n+\n+-   ingesting mirror node date into other types of database like Cassandra, Bigtable, etc. very hard\n+-   benchmarking only parser's or only database ingestion performance in impossible\n+\n+## Goal\n+\n+1. Decouple parsing of stream from ingestion into a database\n+1. Abstractions should support measuring (a) parser's performance and (b) database ingestion performance, in isolation\n+\n+## Non-goals\n+\n+-   Change importer from filesystem based to in-memory streaming\n+-   Parsing multiple rcd/balance/etc files in parallel. Parser is far from being bottleneck, there is no need to optimize it\n+-   Accommodate possibility of publishing transactions/topic messages/etc to GRPC server directly\n+-   Support writing to multiple databases from single importer\n+-   Update balance file parser code immediately\n+\n+## Architecture\n+\n+#### Data Flow\n+\n+![Data Flow](images/parser-events-hander-data-flow.png)\n+\n+-   Record files --> RecordFileReader --> RecordFileListener --> RecordItemListener --> RecordStreamEventsHandler --> DB\n+\n+#### Control Flow\n+\n+![Control Flow](images/parser-events-hander-control-flow.png)\n+\n+### EventsHandler\n+\n+```java\n+package com.hedera.mirror.importer.parser.domain;\n+\n+public class StreamFileInfo {\n+    String filename;\n+    String fileHash;\n+    String prevFileHash;\n+}\n+```\n+\n+```java\n+package com.hedera.mirror.importer.parser;\n+\n+public interface StreamEventsHandler {\n+    void onFileStart(StreamFileInfo streamFileInfo) throws ImporterException;\n+    void onFileComplete(StreamFileInfo streamFileInfo) throws ImporterException;\n+    void onError();\n+}\n+```\n+\n+```java\n+package com.hedera.mirror.importer.parser.record;\n+\n+public interface RecordStreamEventsHandler extends StreamEventsHandler {\n+    void onTransaction(c.h.m.i.d.Transaction transaction) throws ImporterException;\n+    void onCryptoTransferList(c.h.m.i.d.CryptoTransfer cryptoTransfer) throws ImporterException;\n+    void onNonFeeTransfer(c.h.m.i.d.NonFeeTransfer nonFeeTransfer) throws ImporterException;\n+    void onTopicMessage(c.h.m.i.d.TopicMessage topicMessage) throws ImporterException;\n+    void onContractResult(c.h.m.i.d.ContractResult contractResult) throws ImporterException;\n+    void onFileData(c.h.m.i.d.FileData fileData) throws ImporterException;\n+    void onLiveHash(c.h.m.i.d.LiveHash liveHash) throws ImporterException;\n+}\n+```\n+\n+```java\n+package com.hedera.mirror.importer.parser.balance;\n+\n+public interface BalanceEventsHandler extends StreamEventsHandler {\n+    void onBalance(c.h.m.i.d.Balance balance) throws ImporterException;\n+}\n+```\n+\n+1. There will be following implementations for `RecordStreamEventsHandler`:\n+    1. `PostgresWritingRecordStreamEventsHandler`:\n+        - For writing stream data to Postgres database\n+        - For `data-generator` to test database insert performance in isolation (from parser)\n+    1. `NullRecordStreamEventsHandler`: Discards all events and do nothing.\n+        - For micro-benchmarking parser performance\n+    1. `StreamFileWriterRecordStreamEventsHandler`: Package stream data into .rcd/balance/etc file.\n+        - For `data-generator` to generate custom stream files for testing: end-to-end importer perf test, parser + db\n+          perf test, isolated parser micro-benchmark, etc\n+\n+Note that there are no functions for entities. Updating entities in batch in not possible right now since\n+`t_transactions` table refers to entity ids. For entities, first, schema changes are needed to remove entity ids,\n+then `onEntity` and `onEntityUpdate` functions will be added to insert/update entities in bulk. For the purpose of\n+immediate refactor, we can leave entities in `RecordItemParser` (until perf optimizations via schema change in\n+milestone 2).\n+\n+### StreamItemListener\n+\n+```java\n+package com.hedera.mirror.importer.parser;\n+\n+public interface StreamItemListener<T> {\n+    void onItem(T item) throws ImporterException;\n+}\n+```\n+\n+#### RecordItemListener\n+\n+```java\n+package com.hedera.mirror.importer.parser.record;\n+\n+public interface RecordItemListener extends StreamItemListener<RecordItem> {\n+}\n+```\n+\n+```java\n+package com.hedera.mirror.importer.parser.domain;\n+\n+@Value\n+public class RecordItem {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "849bda79d3adeb0dc68938d7e0bae6d7fb20622d"}, "originalPosition": 118}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTI4NjE5MA==", "bodyText": "Not a fan of this name since Events is mixed with gossip events. Maybe parsed something to indicate its converted from proto to our domain? ParsedItemHandler?", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/553#discussion_r385286190", "createdAt": "2020-02-27T18:18:20Z", "author": {"login": "steven-sheehy"}, "path": "docs/design/parser.md", "diffHunk": "@@ -0,0 +1,238 @@\n+# Parser design\n+\n+## Problems in current design\n+\n+SQL Database client is tightly coupled with transaction & record's processor which makes:\n+\n+-   ingesting mirror node date into other types of database like Cassandra, Bigtable, etc. very hard\n+-   benchmarking only parser's or only database ingestion performance in impossible\n+\n+## Goal\n+\n+1. Decouple parsing of stream from ingestion into a database\n+1. Abstractions should support measuring (a) parser's performance and (b) database ingestion performance, in isolation\n+\n+## Non-goals\n+\n+-   Change importer from filesystem based to in-memory streaming\n+-   Parsing multiple rcd/balance/etc files in parallel. Parser is far from being bottleneck, there is no need to optimize it\n+-   Accommodate possibility of publishing transactions/topic messages/etc to GRPC server directly\n+-   Support writing to multiple databases from single importer\n+-   Update balance file parser code immediately\n+\n+## Architecture\n+\n+#### Data Flow\n+\n+![Data Flow](images/parser-events-hander-data-flow.png)\n+\n+-   Record files --> RecordFileReader --> RecordFileListener --> RecordItemListener --> RecordStreamEventsHandler --> DB\n+\n+#### Control Flow\n+\n+![Control Flow](images/parser-events-hander-control-flow.png)\n+\n+### EventsHandler\n+\n+```java\n+package com.hedera.mirror.importer.parser.domain;\n+\n+public class StreamFileInfo {\n+    String filename;\n+    String fileHash;\n+    String prevFileHash;\n+}\n+```\n+\n+```java\n+package com.hedera.mirror.importer.parser;\n+\n+public interface StreamEventsHandler {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "849bda79d3adeb0dc68938d7e0bae6d7fb20622d"}, "originalPosition": 50}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8d7f465bc3bcea9665c4ef64640c2f4a6795617c", "author": {"user": {"login": "apeksharma", "name": "Apekshit Sharma"}}, "url": "https://github.com/hashgraph/hedera-mirror-node/commit/8d7f465bc3bcea9665c4ef64640c2f4a6795617c", "committedDate": "2020-02-27T23:07:26Z", "message": "parser design\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b590a80b8a82c72f1eb983d192800b1a949e867d", "author": {"user": {"login": "apeksharma", "name": "Apekshit Sharma"}}, "url": "https://github.com/hashgraph/hedera-mirror-node/commit/b590a80b8a82c72f1eb983d192800b1a949e867d", "committedDate": "2020-02-27T23:07:26Z", "message": "Address review comments\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e9726fea33106483a96235e70c48a94d4c539e42", "author": {"user": {"login": "apeksharma", "name": "Apekshit Sharma"}}, "url": "https://github.com/hashgraph/hedera-mirror-node/commit/e9726fea33106483a96235e70c48a94d4c539e42", "committedDate": "2020-02-27T23:07:26Z", "message": "remove redundant class diagram\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "144893f950e02d57d0bd9898150900672af02378", "author": {"user": {"login": "apeksharma", "name": "Apekshit Sharma"}}, "url": "https://github.com/hashgraph/hedera-mirror-node/commit/144893f950e02d57d0bd9898150900672af02378", "committedDate": "2020-02-27T23:07:27Z", "message": "add interfaces\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ae706cf82414618ceda55c988f5f86476c6ab293", "author": {"user": {"login": "apeksharma", "name": "Apekshit Sharma"}}, "url": "https://github.com/hashgraph/hedera-mirror-node/commit/ae706cf82414618ceda55c988f5f86476c6ab293", "committedDate": "2020-02-27T23:07:27Z", "message": "add package names\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8c01a18519bf30a74a16dccf8bd9d54843a82202", "author": {"user": {"login": "apeksharma", "name": "Apekshit Sharma"}}, "url": "https://github.com/hashgraph/hedera-mirror-node/commit/8c01a18519bf30a74a16dccf8bd9d54843a82202", "committedDate": "2020-02-27T23:07:27Z", "message": "add generics and StreamItemListener. Add StreamFile domain\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bab8e6db0050d5a63fbd10709ae20aacf4a4486d", "author": {"user": {"login": "apeksharma", "name": "Apekshit Sharma"}}, "url": "https://github.com/hashgraph/hedera-mirror-node/commit/bab8e6db0050d5a63fbd10709ae20aacf4a4486d", "committedDate": "2020-02-27T23:07:28Z", "message": "update images\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "50a7320012383a01fc0edaa36f9a620bec700b76", "author": {"user": {"login": "apeksharma", "name": "Apekshit Sharma"}}, "url": "https://github.com/hashgraph/hedera-mirror-node/commit/50a7320012383a01fc0edaa36f9a620bec700b76", "committedDate": "2020-02-27T23:07:28Z", "message": "remove entity functions from RecordStreamEventsHandler\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "debc7f91c19c87fe99c36783fefbe6a6703b3386", "author": {"user": {"login": "apeksharma", "name": "Apekshit Sharma"}}, "url": "https://github.com/hashgraph/hedera-mirror-node/commit/debc7f91c19c87fe99c36783fefbe6a6703b3386", "committedDate": "2020-02-27T23:07:28Z", "message": "address review comments\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c12b94fa95aa92bf4cf473847c84427b93a55817", "author": {"user": {"login": "apeksharma", "name": "Apekshit Sharma"}}, "url": "https://github.com/hashgraph/hedera-mirror-node/commit/c12b94fa95aa92bf4cf473847c84427b93a55817", "committedDate": "2020-02-28T00:28:21Z", "message": "add links to tasks' tickets\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c6f240d9d57ac096ed31528cfc2df77855fca4df", "author": {"user": {"login": "apeksharma", "name": "Apekshit Sharma"}}, "url": "https://github.com/hashgraph/hedera-mirror-node/commit/c6f240d9d57ac096ed31528cfc2df77855fca4df", "committedDate": "2020-02-27T23:06:58Z", "message": "address review comments\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>"}, "afterCommit": {"oid": "c12b94fa95aa92bf4cf473847c84427b93a55817", "author": {"user": {"login": "apeksharma", "name": "Apekshit Sharma"}}, "url": "https://github.com/hashgraph/hedera-mirror-node/commit/c12b94fa95aa92bf4cf473847c84427b93a55817", "committedDate": "2020-02-28T00:28:21Z", "message": "add links to tasks' tickets\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzY2NTY5MTE3", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/553#pullrequestreview-366569117", "createdAt": "2020-02-28T17:38:22Z", "commit": {"oid": "c12b94fa95aa92bf4cf473847c84427b93a55817"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3274, "cost": 1, "resetAt": "2021-11-01T14:51:55Z"}}}