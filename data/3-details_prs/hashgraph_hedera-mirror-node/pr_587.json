{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg1Mjk2Nzkx", "number": 587, "title": "Update RecordFileParser.loadRecordFile() to match design", "bodyText": "Detailed description:\nMost RFP tests are at parse() level, so not much test changes.\nWhen we separate fs stuff from RFP, tests will be updated to test just loadRecordFile().\nWhich issue(s) this PR fixes:\nPartially addresses #568. All FS code in 2 functions now, can be moved to RecordFileReader later.\nSpecial notes for your reviewer:\nAddress the comment\u00a0here: #585 (comment)\nChecklist\n\n Documentation added\n Tests updated", "createdAt": "2020-03-08T18:21:01Z", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587", "merged": true, "mergeCommit": {"oid": "f5a687c7379ded14142720e45c294624f64a281f"}, "closed": true, "closedAt": "2020-03-12T17:28:23Z", "author": {"login": "apeksharma"}, "timelineItems": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcLtr66gH2gAyMzg1Mjk2NzkxOmMwOGY2NzE1ZjdjNGMwZjhiNjE1YTg4YTQ5MjRlMzIwZWQ4OTM1ZDE=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcM8a4FAFqTM3MzU2ODQxMw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "c08f6715f7c4c0f8b615a88a4924e320ed8935d1", "author": {"user": {"login": "apeksharma", "name": "Apekshit Sharma"}}, "url": "https://github.com/hashgraph/hedera-mirror-node/commit/c08f6715f7c4c0f8b615a88a4924e320ed8935d1", "committedDate": "2020-03-08T18:32:57Z", "message": "Update RecordFileParser.loadRecordFile() to match design\n\nMost RFP tests are at parse() level, so not much test changes.\nWhen we separate fs stuff from RFP, tests will be updated to test just loadRecordFile().\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "40b7b304c15c59fbf5fc9c11a6419bdcd111b76e", "author": {"user": {"login": "apeksharma", "name": "Apekshit Sharma"}}, "url": "https://github.com/hashgraph/hedera-mirror-node/commit/40b7b304c15c59fbf5fc9c11a6419bdcd111b76e", "committedDate": "2020-03-08T18:10:05Z", "message": "Update RecordFileParser.loadRecordFile() to match design\n\nMost RFP tests are at parse() level, so not much test changes.\nWhen we separate fs stuff from RFP, tests will be updated to test just loadRecordFile()."}, "afterCommit": {"oid": "c08f6715f7c4c0f8b615a88a4924e320ed8935d1", "author": {"user": {"login": "apeksharma", "name": "Apekshit Sharma"}}, "url": "https://github.com/hashgraph/hedera-mirror-node/commit/c08f6715f7c4c0f8b615a88a4924e320ed8935d1", "committedDate": "2020-03-08T18:32:57Z", "message": "Update RecordFileParser.loadRecordFile() to match design\n\nMost RFP tests are at parse() level, so not much test changes.\nWhen we separate fs stuff from RFP, tests will be updated to test just loadRecordFile().\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcxMjgwNzcy", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#pullrequestreview-371280772", "createdAt": "2020-03-09T15:24:42Z", "commit": {"oid": "c08f6715f7c4c0f8b615a88a4924e320ed8935d1"}, "state": "DISMISSED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQxNToyNDo0MlrOFztVVw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQxNjowMzozMVrOFzu8ag==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc2NDQzOQ==", "bodyText": "nit: Combine declaration and assignment", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r389764439", "createdAt": "2020-03-09T15:24:42Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -139,25 +143,16 @@ public static String readPrevFileHash(String fileName) {\n     /**\n      * Given a service record name, read and parse and return as a list of service record pair\n      *\n-     * @param streamFileData       containing information about file to be processed\n-     * @param expectedPrevFileHash the hash of the previous record file in the series\n-     * @param thisFileHash         the hash of this file\n-     * @return return boolean indicating method success\n-     * @throws Exception\n+     * @param streamFileData containing information about file to be processed\n      */\n-    public boolean loadRecordFile(StreamFileData streamFileData, String thisFileHash, String expectedPrevFileHash) {\n+    public void loadRecordFile(StreamFileData streamFileData) {\n         String fileName = streamFileData.getFilename();\n+        String expectedPrevFileHash = applicationStatusRepository.findByStatusCode(\n+                ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n         Optional<RecordFile> recordFile;\n-        try {\n-            recordFile = recordStreamFileListener.onStart(streamFileData);\n-            if (recordFile.isEmpty()) {\n-                return true; // skip file\n-            }\n-            recordFile.get().setFileHash(thisFileHash);\n-            recordFile.get().setPreviousHash(expectedPrevFileHash);\n-        } catch (ImporterException e) {\n-            log.error(\"Error processing file \" + fileName, e);\n-            return false;\n+        recordFile = recordStreamFileListener.onStart(streamFileData);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c08f6715f7c4c0f8b615a88a4924e320ed8935d1"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc2NTI3Mg==", "bodyText": "Change to catch Exception since you're only rethrowing IOException and could miss a RuntimeException.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r389765272", "createdAt": "2020-03-09T15:25:53Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -287,27 +270,24 @@ public boolean loadRecordFile(StreamFileData streamFileData, String thisFileHash\n      * @throws Exception\n      */\n     private void loadRecordFiles(List<String> fileNames) {\n-        String prevFileHash = applicationStatusRepository\n-                .findByStatusCode(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n         Collections.sort(fileNames);\n-\n         for (String name : fileNames) {\n             if (ShutdownHelper.isStopping()) {\n                 return;\n             }\n-            String thisFileHash = Hex.encodeHexString(Utility.getFileHash(name));\n             InputStream fileInputStream;\n             try {\n                 fileInputStream = new FileInputStream(new File(name));\n             } catch (FileNotFoundException e) {\n                 log.warn(\"File does not exist {}\", name);\n                 return;\n             }\n-            StreamFileData streamFileData = new StreamFileData(name, fileInputStream);\n-            if (loadRecordFile(streamFileData, thisFileHash, prevFileHash)) {\n-                prevFileHash = thisFileHash;\n+            try {\n+                loadRecordFile(new StreamFileData(name, fileInputStream));\n                 Utility.moveFileToParsedDir(name, \"/parsedRecordFiles/\");\n-            } else {\n+            } catch (ImporterException e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c08f6715f7c4c0f8b615a88a4924e320ed8935d1"}, "originalPosition": 151}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc2NzYxOQ==", "bodyText": "Since this is returning here on error, you might as well move the catch up even higher to parse() and consolidate all error handling in one spot.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r389767619", "createdAt": "2020-03-09T15:29:14Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -287,27 +270,24 @@ public boolean loadRecordFile(StreamFileData streamFileData, String thisFileHash\n      * @throws Exception\n      */\n     private void loadRecordFiles(List<String> fileNames) {\n-        String prevFileHash = applicationStatusRepository\n-                .findByStatusCode(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n         Collections.sort(fileNames);\n-\n         for (String name : fileNames) {\n             if (ShutdownHelper.isStopping()) {\n                 return;\n             }\n-            String thisFileHash = Hex.encodeHexString(Utility.getFileHash(name));\n             InputStream fileInputStream;\n             try {\n                 fileInputStream = new FileInputStream(new File(name));\n             } catch (FileNotFoundException e) {\n                 log.warn(\"File does not exist {}\", name);\n                 return;\n             }\n-            StreamFileData streamFileData = new StreamFileData(name, fileInputStream);\n-            if (loadRecordFile(streamFileData, thisFileHash, prevFileHash)) {\n-                prevFileHash = thisFileHash;\n+            try {\n+                loadRecordFile(new StreamFileData(name, fileInputStream));\n                 Utility.moveFileToParsedDir(name, \"/parsedRecordFiles/\");\n-            } else {\n+            } catch (ImporterException e) {\n+                log.error(\"Error parsing file {}\", name, e);\n+                recordStreamFileListener.onError();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c08f6715f7c4c0f8b615a88a4924e320ed8935d1"}, "originalPosition": 153}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc3MTk2OQ==", "bodyText": "Please change back to Exception (catch and rethrow ImporterException first) since you will miss unchecked exceptions. That or remove this catch and catch Exception in layer above, but then you miss out on formatted timing message. That may not be a big deal since we have metrics and timings for errors is probably not important.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r389771969", "createdAt": "2020-03-09T15:35:43Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -247,38 +237,31 @@ public boolean loadRecordFile(StreamFileData streamFileData, String thisFileHash\n                             break;\n \n                         default:\n-                            log.error(\"Unknown record file delimiter {} for file {}\", typeDelimiter, fileName);\n-                            recordStreamFileListener.onError();\n-                            return false;\n+                            throw new ParserException(String.format(\n+                                    \"Unknown record file delimiter %s for file %s\", typeDelimiter, fileName));\n                     }\n-                } catch (Exception e) {\n-                    log.error(\"Exception {}\", e);\n-                    recordStreamFileListener.onError();\n-                    return false;\n-                }\n             }\n \n+            String thisFileHash = Hex.encodeHexString(Utility.getFileHash(fileName));\n+            recordFile.get().setFileHash(thisFileHash);\n+            recordFile.get().setPreviousHash(expectedPrevFileHash);\n             log.trace(\"Calculated file hash for the current file {}\", thisFileHash);\n             recordStreamFileListener.onEnd(recordFile.get());\n \n             if (!Utility.hashIsEmpty(thisFileHash)) {\n                 applicationStatusRepository\n                         .updateStatusValue(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, thisFileHash);\n             }\n-            success = true;\n-        } catch (Exception e) {\n-            log.error(\"Error parsing record file {} after {}\", fileName, stopwatch, e);\n-            recordStreamFileListener.onError();\n+        } catch (IOException e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c08f6715f7c4c0f8b615a88a4924e320ed8935d1"}, "originalPosition": 109}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc3MzQ2NA==", "bodyText": "This whole block has an extra indentation after try/catch removal.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r389773464", "createdAt": "2020-03-09T15:37:56Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -167,12 +162,8 @@ public boolean loadRecordFile(StreamFileData streamFileData, String thisFileHash\n         try (DataInputStream dis = new DataInputStream(streamFileData.getInputStream())) {\n             recordFileVersion = dis.readInt();\n             int version = dis.readInt();\n-\n             log.info(\"Loading version {} record file: {}\", recordFileVersion, fileName);\n-\n             while (dis.available() != 0) {\n-\n-                try {\n                     byte typeDelimiter = dis.readByte();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c08f6715f7c4c0f8b615a88a4924e320ed8935d1"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc3NTMxMg==", "bodyText": "This metric is now always unsuccessful since you don't set success to true.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r389775312", "createdAt": "2020-03-09T15:40:41Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -247,38 +237,31 @@ public boolean loadRecordFile(StreamFileData streamFileData, String thisFileHash\n                             break;\n \n                         default:\n-                            log.error(\"Unknown record file delimiter {} for file {}\", typeDelimiter, fileName);\n-                            recordStreamFileListener.onError();\n-                            return false;\n+                            throw new ParserException(String.format(\n+                                    \"Unknown record file delimiter %s for file %s\", typeDelimiter, fileName));\n                     }\n-                } catch (Exception e) {\n-                    log.error(\"Exception {}\", e);\n-                    recordStreamFileListener.onError();\n-                    return false;\n-                }\n             }\n \n+            String thisFileHash = Hex.encodeHexString(Utility.getFileHash(fileName));\n+            recordFile.get().setFileHash(thisFileHash);\n+            recordFile.get().setPreviousHash(expectedPrevFileHash);\n             log.trace(\"Calculated file hash for the current file {}\", thisFileHash);\n             recordStreamFileListener.onEnd(recordFile.get());\n \n             if (!Utility.hashIsEmpty(thisFileHash)) {\n                 applicationStatusRepository\n                         .updateStatusValue(ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH, thisFileHash);\n             }\n-            success = true;\n-        } catch (Exception e) {\n-            log.error(\"Error parsing record file {} after {}\", fileName, stopwatch, e);\n-            recordStreamFileListener.onError();\n+        } catch (IOException e) {\n+            throw new ParserException(String.format(\"Error parsing record file %s after %s\", fileName, stopwatch), e);\n         } finally {\n             log.info(\"Finished parsing {} transactions from record file {} in {}\", counter, fileName, stopwatch);\n-\n             parseDurationMetric.tag(\"type\", \"record\")\n                     .tag(\"success\", success.toString())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c08f6715f7c4c0f8b615a88a4924e320ed8935d1"}, "originalPosition": 115}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc3ODUxMw==", "bodyText": "Can you enhance this to not Hex.encodeHexString(readFileHash) twice if previous is empty?", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r389778513", "createdAt": "2020-03-09T15:45:22Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -167,12 +162,8 @@ public boolean loadRecordFile(StreamFileData streamFileData, String thisFileHash\n         try (DataInputStream dis = new DataInputStream(streamFileData.getInputStream())) {\n             recordFileVersion = dis.readInt();\n             int version = dis.readInt();\n-\n             log.info(\"Loading version {} record file: {}\", recordFileVersion, fileName);\n-\n             while (dis.available() != 0) {\n-\n-                try {\n                     byte typeDelimiter = dis.readByte();\n \n                     switch (typeDelimiter) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c08f6715f7c4c0f8b615a88a4924e320ed8935d1"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc5MDgyNg==", "bodyText": "Can you add a test for when processed hash is empty in db? Ops does this quite a bit to reset environments.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r389790826", "createdAt": "2020-03-09T16:03:31Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/RecordFileParserTest.java", "diffHunk": "@@ -165,7 +165,9 @@ void invalidFile() throws Exception {\n         recordFileParser.parse();\n \n         // then\n-        assertNoneProcessed();\n+        assertParsedFiles();\n+        verifyNoInteractions(recordItemListener);\n+        verify(recordStreamFileListener).onError();\n     }\n ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c08f6715f7c4c0f8b615a88a4924e320ed8935d1"}, "originalPosition": 18}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7c1f4fdfd64778a6b4b6dc3594029eec4b668237", "author": {"user": {"login": "apeksharma", "name": "Apekshit Sharma"}}, "url": "https://github.com/hashgraph/hedera-mirror-node/commit/7c1f4fdfd64778a6b4b6dc3594029eec4b668237", "committedDate": "2020-03-11T21:08:15Z", "message": "address review comments\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e556179de4e99e8077a60a7fb380bf8504b3a703", "author": {"user": {"login": "apeksharma", "name": "Apekshit Sharma"}}, "url": "https://github.com/hashgraph/hedera-mirror-node/commit/e556179de4e99e8077a60a7fb380bf8504b3a703", "committedDate": "2020-03-11T22:20:39Z", "message": "add @cacheput\n\nSigned-off-by: Apekshit Sharma <apekshit.sharma@hedera.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzczNTY4NDEz", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#pullrequestreview-373568413", "createdAt": "2020-03-12T13:47:07Z", "commit": {"oid": "e556179de4e99e8077a60a7fb380bf8504b3a703"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMlQxMzo0NzowN1rOF1fQ5w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMlQxMzo0NzowN1rOF1fQ5w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTYzMTA3OQ==", "bodyText": "This section seems like one of those bloated sections. It's not easy to get a view of all that needs to be done and it's not possible to test each case separately.\nCould we make each case call a method that handles the given scenario (e.g. readPreviousHash(), readRecord()/readTransaction() and readSignature()).\nThese are then more isolated and can be tested and more easily managed.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/587#discussion_r391631079", "createdAt": "2020-03-12T13:47:07Z", "author": {"login": "Nana-EC"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/RecordFileParser.java", "diffHunk": "@@ -139,125 +138,105 @@ public static String readPrevFileHash(String fileName) {\n     /**\n      * Given a service record name, read and parse and return as a list of service record pair\n      *\n-     * @param streamFileData       containing information about file to be processed\n-     * @param expectedPrevFileHash the hash of the previous record file in the series\n-     * @param thisFileHash         the hash of this file\n-     * @return return boolean indicating method success\n-     * @throws Exception\n+     * @param streamFileData containing information about file to be processed\n      */\n-    public boolean loadRecordFile(StreamFileData streamFileData, String thisFileHash, String expectedPrevFileHash) {\n+    public void loadRecordFile(StreamFileData streamFileData) throws IOException {\n+        Stopwatch stopwatch = Stopwatch.createStarted();\n         String fileName = streamFileData.getFilename();\n-        Optional<RecordFile> recordFile;\n-        try {\n-            recordFile = recordStreamFileListener.onStart(streamFileData);\n-            if (recordFile.isEmpty()) {\n-                return true; // skip file\n-            }\n-            recordFile.get().setFileHash(thisFileHash);\n-            recordFile.get().setPreviousHash(expectedPrevFileHash);\n-        } catch (ImporterException e) {\n-            log.error(\"Error processing file \" + fileName, e);\n-            return false;\n+        String expectedPrevFileHash = applicationStatusRepository.findByStatusCode(\n+                ApplicationStatusCode.LAST_PROCESSED_RECORD_HASH);\n+        Optional<RecordFile> recordFile = recordStreamFileListener.onStart(streamFileData);\n+        if (recordFile.isEmpty()) {\n+            return; // skip file\n         }\n         long counter = 0;\n-        Stopwatch stopwatch = Stopwatch.createStarted();\n         Integer recordFileVersion = 0;\n         Boolean success = false;\n \n         try (DataInputStream dis = new DataInputStream(streamFileData.getInputStream())) {\n             recordFileVersion = dis.readInt();\n             int version = dis.readInt();\n-\n             log.info(\"Loading version {} record file: {}\", recordFileVersion, fileName);\n-\n             while (dis.available() != 0) {\n-\n-                try {\n-                    byte typeDelimiter = dis.readByte();\n-\n-                    switch (typeDelimiter) {\n-                        case FileDelimiter.RECORD_TYPE_PREV_HASH:\n-                            byte[] readFileHash = new byte[48];\n-                            dis.read(readFileHash);\n-\n-                            if (Utility.hashIsEmpty(expectedPrevFileHash)) {\n-                                log.error(\"Previous file hash not available\");\n-                                expectedPrevFileHash = Hex.encodeHexString(readFileHash);\n+                byte typeDelimiter = dis.readByte();\n+\n+                switch (typeDelimiter) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e556179de4e99e8077a60a7fb380bf8504b3a703"}, "originalPosition": 87}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3310, "cost": 1, "resetAt": "2021-11-01T14:51:55Z"}}}