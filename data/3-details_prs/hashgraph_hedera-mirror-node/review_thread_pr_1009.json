{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDc3MjIwMzA1", "number": 1009, "reviewThreads": {"totalCount": 37, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQxNjoyMDowNlrOEfiDfA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQyMzoxNToyMFrOEiUurQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAxNDk5MjYwOnYy", "diffSide": "RIGHT", "path": "hedera-mirror-importer/src/main/resources/db/migration/V1.29.0__store_verification_node_in_stream_file_tables.sql", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQxNjoyMDowNlrOHL3CtQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQxNjoyMDowNlrOHL3CtQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjE5ODE5Nw==", "bodyText": "for dev postgresql db, rows in record_file 3,148,259, rows in transaction 850,528,026, updateRecordFileCount costs 1885200.557 ms", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r482198197", "createdAt": "2020-09-02T16:20:06Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-importer/src/main/resources/db/migration/V1.29.0__store_verification_node_in_stream_file_tables.sql", "diffHunk": "@@ -0,0 +1,71 @@\n+-- set the number of transactions for historic record_file records\n+create or replace function updateRecordFileCount() returns void as\n+$$\n+declare\n+\ttxnCursor          refcursor;\n+\trecordFile         record;\n+\tconsensusStart     bigint;\n+\tconsensusEnd       bigint;\n+\tcurrentNs          bigint;\n+\ttxnCount           bigint;\n+begin\n+\topen txnCursor no scroll for select consensus_ns from transaction order by consensus_ns;\n+\tcurrentNs := 0;\n+\n+\tfor recordFile in\n+\t\tselect consensus_start,consensus_end\n+\t\tfrom record_file\n+\t\torder by consensus_end\n+\t\tloop\n+\t\t\ttxnCount := 0;\n+\t\t\tconsensusStart := recordFile.consensus_start;\n+\t\t\tconsensusEnd := recordFile.consensus_end;\n+\n+\t\t\tif currentNs is NOT NULL and currentNs >= consensusStart then\n+\t\t\t\ttxnCount := 1;\n+\t\t\tend if;\n+\n+\t\t\twhile true\n+\t\t\t\tloop\n+\t\t\t\t\tfetch txnCursor into currentNs;\n+\t\t\t\t\tif currentNs is NULL or currentNs > consensusEnd then\n+\t\t\t\t\t    update record_file\n+\t\t\t\t\t        set count = txnCount\n+\t\t\t\t\t    where consensus_end = consensusEnd;\n+\t\t\t\t\t\texit; -- exit the while loop\n+\t\t\t\t\tend if;\n+\t\t\t\t\tif currentNs >= consensusStart then\n+\t\t\t\t\t\ttxnCount := txnCount + 1;\n+\t\t\t\t\tend if;\n+\t\t\t\tend loop;\n+\t\tend loop;\n+end\n+$$ language plpgsql;\n+\n+-- add node_account_id to record_file table\n+alter table if exists record_file\n+    add column node_account_id entity_id not null default 3;\n+alter table if exists record_file\n+    alter column node_account_id drop default;\n+\n+-- add count to record_file table\n+alter table if exists record_file\n+    add column count bigint;\n+\n+select updateRecordFileCount();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c7e6f7f853a231395dd3620aa6e4cb43e82d663f"}, "originalPosition": 55}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAxNzA1NjgwOnYy", "diffSide": "RIGHT", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/domain/EventFile.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQyMjozNToxMlrOHMMevA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxMzo0MjoyN1rOHMnMMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjU0OTQzNg==", "bodyText": "Missing the convert\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                private EntityId nodeAccountId;\n          \n          \n            \n               @Convert(converter = AccountIdConverter.class)\n          \n          \n            \n                private EntityId nodeAccountId;", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r482549436", "createdAt": "2020-09-02T22:35:12Z", "author": {"login": "Nana-EC"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/domain/EventFile.java", "diffHunk": "@@ -37,4 +37,8 @@\n     private String previousHash;\n \n     private int fileVersion;\n+\n+    private EntityId nodeAccountId;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b0690c2a6a9513aea8be98884958f0adfe4b035"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjk4NzA1Ng==", "bodyText": "good catch. the reason there is no converter is EventFile is not an Entity class yet and there is not event_file table. But I agree it's better to add it.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r482987056", "createdAt": "2020-09-03T13:42:27Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/domain/EventFile.java", "diffHunk": "@@ -37,4 +37,8 @@\n     private String previousHash;\n \n     private int fileVersion;\n+\n+    private EntityId nodeAccountId;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjU0OTQzNg=="}, "originalCommit": {"oid": "6b0690c2a6a9513aea8be98884958f0adfe4b035"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAxNzA3MDUyOnYy", "diffSide": "RIGHT", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/domain/StreamFile.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQyMjozNzoxMVrOHMMnwg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxMzo0MzoxNlrOHMnOcw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjU1MTc0Ng==", "bodyText": "based on the logic so far shouldn't Long getCount() also be a member?", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r482551746", "createdAt": "2020-09-02T22:37:11Z", "author": {"login": "Nana-EC"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/domain/StreamFile.java", "diffHunk": "@@ -0,0 +1,32 @@\n+package com.hedera.mirror.importer.domain;\n+\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ * \u200b\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ * \u200b\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+import lombok.NonNull;\n+\n+public interface StreamFile {\n+\n+    String getName();\n+\n+    String getFileHash();\n+\n+    void setNodeAccountId(@NonNull EntityId nodeAccountId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b0690c2a6a9513aea8be98884958f0adfe4b035"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjk4NzYzNQ==", "bodyText": "The three getters/setters in the interface are needed by the abstract base class Downloader while getCount is not.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r482987635", "createdAt": "2020-09-03T13:43:16Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/domain/StreamFile.java", "diffHunk": "@@ -0,0 +1,32 @@\n+package com.hedera.mirror.importer.domain;\n+\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ * \u200b\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ * \u200b\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+import lombok.NonNull;\n+\n+public interface StreamFile {\n+\n+    String getName();\n+\n+    String getFileHash();\n+\n+    void setNodeAccountId(@NonNull EntityId nodeAccountId);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjU1MTc0Ng=="}, "originalCommit": {"oid": "6b0690c2a6a9513aea8be98884958f0adfe4b035"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAxNzE4OTU1OnYy", "diffSide": "RIGHT", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/downloader/Downloader.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQyMjo1NDowNFrOHMN3jQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxMzo0ODowOFrOHMncgg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjU3MjE3Mw==", "bodyText": "nit:\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                log.warn(\"Failed to verify data file from node {} corresponding to {}. Will retry another node\",\n          \n          \n            \n                                log.warn(\"Failed to verify signature of data file from node {} corresponding to {}. Will retry another node\",", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r482572173", "createdAt": "2020-09-02T22:54:04Z", "author": {"login": "Nana-EC"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/downloader/Downloader.java", "diffHunk": "@@ -385,38 +389,34 @@ private void verifySigsAndDownloadDataFiles(Multimap<String, FileStreamSignature\n                 }\n \n                 try {\n-                    File signedDataFile = downloadSignedDataFile(signature.getFile(), signature.getNode());\n+                    File signedDataFile = downloadSignedDataFile(signature.getFile(), signature.getNodeAccountIdString());\n                     if (signedDataFile == null) {\n                         continue;\n                     }\n \n-                    if (verifyDataFile(signedDataFile, signature.getHash())) {\n-                        if (Utility.isStreamFileAfterInstant(sigFilename, endDate)) {\n-                            downloaderProperties.setEnabled(false);\n-                            log.warn(\"Disabled polling after downloading all files <= endDate ({})\", endDate);\n-                            return;\n-                        }\n+                    StreamFile streamFile = readAndVerifyDataFile(signedDataFile, signature.getHashAsHex());\n+                    streamFile.setNodeAccountId(signature.getNodeAccountId());\n \n-                        // move the file to the valid directory\n-                        File destination = validPath.resolve(signedDataFile.getName()).toFile();\n-                        if (moveFile(signedDataFile, destination)) {\n-                            if (lastValidDownloadedFileHashKey != null) {\n-                                applicationStatusRepository.updateStatusValue(lastValidDownloadedFileHashKey,\n-                                        signature.getHashAsHex());\n-                            }\n-                            applicationStatusRepository\n-                                    .updateStatusValue(lastValidDownloadedFileKey, destination.getName());\n-                            valid = true;\n-                            signatures.forEach(this::moveSignatureFile);\n-                            break;\n-                        }\n-                    } else {\n-                        log.warn(\"Verification of data file {} from node {} failed. Will retry another node\",\n-                                signedDataFile.getName(), signature.getNode());\n+                    if (Utility.isStreamFileAfterInstant(sigFilename, endDate)) {\n+                        downloaderProperties.setEnabled(false);\n+                        log.warn(\"Disabled polling after downloading all files <= endDate ({})\", endDate);\n+                        return;\n                     }\n+\n+                    // move the file to the valid directory\n+                    File destination = validPath.resolve(signedDataFile.getName()).toFile();\n+                    moveFile(signedDataFile, destination);\n+                    signatures.forEach(this::moveSignatureFile);\n+\n+                    updateApplicationStatus(streamFile);\n+                    valid = true;\n+                    break;\n+                } catch (HashMismatchException e) {\n+                    log.warn(\"Failed to verify data file from node {} corresponding to {}. Will retry another node\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b0690c2a6a9513aea8be98884958f0adfe4b035"}, "originalPosition": 229}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjk5MTIzNA==", "bodyText": "I think the log message is appropriate since here it's hash mismatch, not the signature's in the sig files.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r482991234", "createdAt": "2020-09-03T13:48:08Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/downloader/Downloader.java", "diffHunk": "@@ -385,38 +389,34 @@ private void verifySigsAndDownloadDataFiles(Multimap<String, FileStreamSignature\n                 }\n \n                 try {\n-                    File signedDataFile = downloadSignedDataFile(signature.getFile(), signature.getNode());\n+                    File signedDataFile = downloadSignedDataFile(signature.getFile(), signature.getNodeAccountIdString());\n                     if (signedDataFile == null) {\n                         continue;\n                     }\n \n-                    if (verifyDataFile(signedDataFile, signature.getHash())) {\n-                        if (Utility.isStreamFileAfterInstant(sigFilename, endDate)) {\n-                            downloaderProperties.setEnabled(false);\n-                            log.warn(\"Disabled polling after downloading all files <= endDate ({})\", endDate);\n-                            return;\n-                        }\n+                    StreamFile streamFile = readAndVerifyDataFile(signedDataFile, signature.getHashAsHex());\n+                    streamFile.setNodeAccountId(signature.getNodeAccountId());\n \n-                        // move the file to the valid directory\n-                        File destination = validPath.resolve(signedDataFile.getName()).toFile();\n-                        if (moveFile(signedDataFile, destination)) {\n-                            if (lastValidDownloadedFileHashKey != null) {\n-                                applicationStatusRepository.updateStatusValue(lastValidDownloadedFileHashKey,\n-                                        signature.getHashAsHex());\n-                            }\n-                            applicationStatusRepository\n-                                    .updateStatusValue(lastValidDownloadedFileKey, destination.getName());\n-                            valid = true;\n-                            signatures.forEach(this::moveSignatureFile);\n-                            break;\n-                        }\n-                    } else {\n-                        log.warn(\"Verification of data file {} from node {} failed. Will retry another node\",\n-                                signedDataFile.getName(), signature.getNode());\n+                    if (Utility.isStreamFileAfterInstant(sigFilename, endDate)) {\n+                        downloaderProperties.setEnabled(false);\n+                        log.warn(\"Disabled polling after downloading all files <= endDate ({})\", endDate);\n+                        return;\n                     }\n+\n+                    // move the file to the valid directory\n+                    File destination = validPath.resolve(signedDataFile.getName()).toFile();\n+                    moveFile(signedDataFile, destination);\n+                    signatures.forEach(this::moveSignatureFile);\n+\n+                    updateApplicationStatus(streamFile);\n+                    valid = true;\n+                    break;\n+                } catch (HashMismatchException e) {\n+                    log.warn(\"Failed to verify data file from node {} corresponding to {}. Will retry another node\",", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjU3MjE3Mw=="}, "originalCommit": {"oid": "6b0690c2a6a9513aea8be98884958f0adfe4b035"}, "originalPosition": 229}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAxNzI3MDAyOnYy", "diffSide": "RIGHT", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/domain/AccountBalanceFile.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQyMzowOTo0M1rOHMOs0g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQyMzowOTo0M1rOHMOs0g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjU4NTgxMA==", "bodyText": "The @Id should be the consensusTimestamp", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r482585810", "createdAt": "2020-09-02T23:09:43Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/domain/AccountBalanceFile.java", "diffHunk": "@@ -0,0 +1,53 @@\n+package com.hedera.mirror.importer.domain;\n+\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ * \u200b\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ * \u200b\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+import javax.persistence.Convert;\n+import javax.persistence.Entity;\n+import javax.persistence.Id;\n+import lombok.AllArgsConstructor;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import com.hedera.mirror.importer.converter.AccountIdConverter;\n+\n+@Data\n+@Entity\n+@AllArgsConstructor\n+@NoArgsConstructor\n+public class AccountBalanceFile implements StreamFile {\n+\n+    @Id\n+    private String name;\n+\n+    private Long consensusTimestamp;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b0690c2a6a9513aea8be98884958f0adfe4b035"}, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAxNzI3MzYxOnYy", "diffSide": "RIGHT", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/domain/AccountBalanceFile.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQyMzoxMDozM1rOHMOvBw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQyMzoxMDozM1rOHMOvBw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjU4NjM3NQ==", "bodyText": "nit: Would prefer fields sorted alphabetically.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r482586375", "createdAt": "2020-09-02T23:10:33Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/domain/AccountBalanceFile.java", "diffHunk": "@@ -0,0 +1,53 @@\n+package com.hedera.mirror.importer.domain;\n+\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ * \u200b\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ * \u200b\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+import javax.persistence.Convert;\n+import javax.persistence.Entity;\n+import javax.persistence.Id;\n+import lombok.AllArgsConstructor;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import com.hedera.mirror.importer.converter.AccountIdConverter;\n+\n+@Data\n+@Entity\n+@AllArgsConstructor\n+@NoArgsConstructor\n+public class AccountBalanceFile implements StreamFile {\n+\n+    @Id\n+    private String name;\n+\n+    private Long consensusTimestamp;\n+\n+    private Long loadStart;\n+\n+    private Long loadEnd;\n+\n+    private String fileHash;\n+\n+    @Convert(converter = AccountIdConverter.class)\n+    private EntityId nodeAccountId;\n+\n+    private Long count;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b0690c2a6a9513aea8be98884958f0adfe4b035"}, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAxNzI3ODMyOnYy", "diffSide": "RIGHT", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/downloader/Downloader.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQyMzoxMTo0NVrOHMOySg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxMzo1MToxOFrOHMnlSw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjU4NzIxMA==", "bodyText": "Here's a suggestion. If we refactored this like the the following would it allow you to use @transactional and simplify the code instead of having to use the transactionManager directly\nDownloader.java\npublic Multimap<String, FileStreamSignature> downloadNextBatch() {\n     ....(current code minus call to verifySigsAndDownloadDataFiles()) ...\n\n     return sigFilesMap;\n}\n\n@Transactional\npublic void verifyBatch() {\n            // Verify signature files and download corresponding files of valid signature files\n            verifySigsAndDownloadDataFiles(sigFilesMap);\n}\n\nRecordFileDownloader.java\n    @Leader\n    @Scheduled(fixedRateString = \"${hedera.mirror.importer.downloader.record.frequency:500}\")\n    public void download() {\n        downloadNextBatch();\n        verifyBatch();\n    }\n\nThis was the download and the verify logic is broken up making it easier to manage and test.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r482587210", "createdAt": "2020-09-02T23:11:45Z", "author": {"login": "Nana-EC"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/downloader/Downloader.java", "diffHunk": "@@ -451,7 +451,33 @@ private File downloadSignedDataFile(File sigFile, String nodeAccountId) {\n         return null;\n     }\n \n-    protected abstract boolean verifyDataFile(File file, byte[] signedHash);\n+    /**\n+     * Updates last valid downloaded file and last valid downloaded file hash key in database if applicable. Also saves\n+     * the stream file to its corresponding database table.\n+     * @param streamFile the verified stream file\n+     */\n+    private void updateApplicationStatus(StreamFile streamFile) {\n+        DefaultTransactionDefinition def = new DefaultTransactionDefinition();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b0690c2a6a9513aea8be98884958f0adfe4b035"}, "originalPosition": 249}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjk5MzQ4Mw==", "bodyText": "according to spring doc, it won't work because by default @Transactional is in proxy mode. here even though verifyBatch() is a public method, but calling it inside download() is self-invocation, which means the proxy used to add the Transactional mechanism is bypassed.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r482993483", "createdAt": "2020-09-03T13:51:18Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/downloader/Downloader.java", "diffHunk": "@@ -451,7 +451,33 @@ private File downloadSignedDataFile(File sigFile, String nodeAccountId) {\n         return null;\n     }\n \n-    protected abstract boolean verifyDataFile(File file, byte[] signedHash);\n+    /**\n+     * Updates last valid downloaded file and last valid downloaded file hash key in database if applicable. Also saves\n+     * the stream file to its corresponding database table.\n+     * @param streamFile the verified stream file\n+     */\n+    private void updateApplicationStatus(StreamFile streamFile) {\n+        DefaultTransactionDefinition def = new DefaultTransactionDefinition();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjU4NzIxMA=="}, "originalCommit": {"oid": "6b0690c2a6a9513aea8be98884958f0adfe4b035"}, "originalPosition": 249}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAxNzMxNjI2OnYy", "diffSide": "RIGHT", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/domain/AccountBalanceFile.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQyMzoyMTowN1rOHMPLfw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxNzozNzozMFrOHMw8YA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjU5MzY2Mw==", "bodyText": "Is it possible to add a version field to denote version 1 vs 2?", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r482593663", "createdAt": "2020-09-02T23:21:07Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/domain/AccountBalanceFile.java", "diffHunk": "@@ -0,0 +1,53 @@\n+package com.hedera.mirror.importer.domain;\n+\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ * \u200b\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ * \u200b\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+import javax.persistence.Convert;\n+import javax.persistence.Entity;\n+import javax.persistence.Id;\n+import lombok.AllArgsConstructor;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import com.hedera.mirror.importer.converter.AccountIdConverter;\n+\n+@Data\n+@Entity\n+@AllArgsConstructor\n+@NoArgsConstructor\n+public class AccountBalanceFile implements StreamFile {\n+\n+    @Id\n+    private String name;\n+\n+    private Long consensusTimestamp;\n+\n+    private Long loadStart;\n+\n+    private Long loadEnd;\n+\n+    private String fileHash;\n+\n+    @Convert(converter = AccountIdConverter.class)\n+    private EntityId nodeAccountId;\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b0690c2a6a9513aea8be98884958f0adfe4b035"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzE0Njg0OA==", "bodyText": "I'm not aware of different versions of account balance file. So I would assume till now, it's all version 1 account balance files.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r483146848", "createdAt": "2020-09-03T17:37:30Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/domain/AccountBalanceFile.java", "diffHunk": "@@ -0,0 +1,53 @@\n+package com.hedera.mirror.importer.domain;\n+\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ * \u200b\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ * \u200b\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+import javax.persistence.Convert;\n+import javax.persistence.Entity;\n+import javax.persistence.Id;\n+import lombok.AllArgsConstructor;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import com.hedera.mirror.importer.converter.AccountIdConverter;\n+\n+@Data\n+@Entity\n+@AllArgsConstructor\n+@NoArgsConstructor\n+public class AccountBalanceFile implements StreamFile {\n+\n+    @Id\n+    private String name;\n+\n+    private Long consensusTimestamp;\n+\n+    private Long loadStart;\n+\n+    private Long loadEnd;\n+\n+    private String fileHash;\n+\n+    @Convert(converter = AccountIdConverter.class)\n+    private EntityId nodeAccountId;\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjU5MzY2Mw=="}, "originalCommit": {"oid": "6b0690c2a6a9513aea8be98884958f0adfe4b035"}, "originalPosition": 51}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAxNzMyMTUzOnYy", "diffSide": "RIGHT", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/downloader/event/EventFileDownloader.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQyMzoyMjoyNVrOHMPPBg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxMzo1Mjo0NlrOHMnpvA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjU5NDU2Ng==", "bodyText": "Should be current hashes not previous\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        throw new HashMismatchException(fileName, expectedPrevFileHash, eventFile.getPreviousHash());\n          \n          \n            \n                        throw new HashMismatchException(fileName, verifiedHash, eventFile.getFileHash());", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r482594566", "createdAt": "2020-09-02T23:22:25Z", "author": {"login": "Nana-EC"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/downloader/event/EventFileDownloader.java", "diffHunk": "@@ -59,34 +61,33 @@ public void download() {\n     }\n \n     /**\n-     * Checks that hash of data file matches the verified hash and that data file is next in line based on previous file\n-     * hash. Returns false if any condition is false.\n+     * Reads the event file and checks that the file hash matches the verified hash and that data file is next in\n+     * line based on previous file hash.\n+     * @param file event file object\n+     * @param verifiedHash the verified hash in hex\n+     * @return StreamFile object\n      */\n     @Override\n-    protected boolean verifyDataFile(File file, byte[] verifiedHash) {\n+    protected StreamFile readAndVerifyDataFile(File file, String verifiedHash) {\n         String expectedPrevFileHash = applicationStatusRepository.findByStatusCode(lastValidDownloadedFileHashKey);\n         String fileName = file.getName();\n+        Instant verifyHashAfter = downloaderProperties.getMirrorProperties().getVerifyHashAfter();\n \n-        try {\n-            EventFile eventFile = eventFileReader.read(file);\n+        EventFile eventFile = eventFileReader.read(file);\n \n-            if (!verifyHashChain(eventFile.getPreviousHash(), expectedPrevFileHash,\n-                    downloaderProperties.getMirrorProperties().getVerifyHashAfter(), fileName)) {\n-                log.error(\"PreviousHash mismatch for file {}. Expected = {}, Actual = {}\", fileName,\n-                        expectedPrevFileHash, eventFile.getPreviousHash());\n-                return false;\n-            }\n+        if (!verifyHashChain(eventFile.getPreviousHash(), expectedPrevFileHash, verifyHashAfter, fileName)) {\n+            throw new HashMismatchException(fileName, expectedPrevFileHash, eventFile.getPreviousHash());\n+        }\n \n-            String expectedFileHash = Hex.encodeHexString(verifiedHash);\n-            if (!eventFile.getFileHash().contentEquals(expectedFileHash)) {\n-                log.error(\"File {}'s hash mismatch. Expected = {}, Actual = {}\", fileName, expectedFileHash,\n-                        eventFile.getFileHash());\n-                return false;\n-            }\n-        } catch (ImporterException e) {\n-            log.error(e);\n-            return false;\n+        if (!eventFile.getFileHash().contentEquals(verifiedHash)) {\n+            throw new HashMismatchException(fileName, expectedPrevFileHash, eventFile.getPreviousHash());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b0690c2a6a9513aea8be98884958f0adfe4b035"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjk5NDYyMA==", "bodyText": "good catch. will correct it.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r482994620", "createdAt": "2020-09-03T13:52:46Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/downloader/event/EventFileDownloader.java", "diffHunk": "@@ -59,34 +61,33 @@ public void download() {\n     }\n \n     /**\n-     * Checks that hash of data file matches the verified hash and that data file is next in line based on previous file\n-     * hash. Returns false if any condition is false.\n+     * Reads the event file and checks that the file hash matches the verified hash and that data file is next in\n+     * line based on previous file hash.\n+     * @param file event file object\n+     * @param verifiedHash the verified hash in hex\n+     * @return StreamFile object\n      */\n     @Override\n-    protected boolean verifyDataFile(File file, byte[] verifiedHash) {\n+    protected StreamFile readAndVerifyDataFile(File file, String verifiedHash) {\n         String expectedPrevFileHash = applicationStatusRepository.findByStatusCode(lastValidDownloadedFileHashKey);\n         String fileName = file.getName();\n+        Instant verifyHashAfter = downloaderProperties.getMirrorProperties().getVerifyHashAfter();\n \n-        try {\n-            EventFile eventFile = eventFileReader.read(file);\n+        EventFile eventFile = eventFileReader.read(file);\n \n-            if (!verifyHashChain(eventFile.getPreviousHash(), expectedPrevFileHash,\n-                    downloaderProperties.getMirrorProperties().getVerifyHashAfter(), fileName)) {\n-                log.error(\"PreviousHash mismatch for file {}. Expected = {}, Actual = {}\", fileName,\n-                        expectedPrevFileHash, eventFile.getPreviousHash());\n-                return false;\n-            }\n+        if (!verifyHashChain(eventFile.getPreviousHash(), expectedPrevFileHash, verifyHashAfter, fileName)) {\n+            throw new HashMismatchException(fileName, expectedPrevFileHash, eventFile.getPreviousHash());\n+        }\n \n-            String expectedFileHash = Hex.encodeHexString(verifiedHash);\n-            if (!eventFile.getFileHash().contentEquals(expectedFileHash)) {\n-                log.error(\"File {}'s hash mismatch. Expected = {}, Actual = {}\", fileName, expectedFileHash,\n-                        eventFile.getFileHash());\n-                return false;\n-            }\n-        } catch (ImporterException e) {\n-            log.error(e);\n-            return false;\n+        if (!eventFile.getFileHash().contentEquals(verifiedHash)) {\n+            throw new HashMismatchException(fileName, expectedPrevFileHash, eventFile.getPreviousHash());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjU5NDU2Ng=="}, "originalCommit": {"oid": "6b0690c2a6a9513aea8be98884958f0adfe4b035"}, "originalPosition": 75}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAxNzMzMTYxOnYy", "diffSide": "RIGHT", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/balance/AccountBalancesFileLoader.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQyMzoyNDo1N1rOHMPVrw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxNDoxODoxOVrOHMozxQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjU5NjI3MQ==", "bodyText": "q: would it be easier for you to just use repositories at this point? We're trying to move towards that where possible.\nWould simplify this class and hopefully shouldn't break too many tests", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r482596271", "createdAt": "2020-09-02T23:24:57Z", "author": {"login": "Nana-EC"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/balance/AccountBalancesFileLoader.java", "diffHunk": "@@ -54,6 +56,14 @@\n     private static final String UPDATE_SET_STATEMENT = \"update account_balance_sets set is_complete = ?, \" +\n             \"processing_end_timestamp = now() at time zone 'utc' where consensus_timestamp = ? and is_complete = \" +\n             \"false;\";\n+    private static final String UPDATE_ACCOUNT_BALANCE_FILE_STATEMENT = \"update account_balance_file \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b0690c2a6a9513aea8be98884958f0adfe4b035"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzAxMzU3Mw==", "bodyText": "during the last refactor effort the prepared statement is left as is since I couldn't optimize the repository way to match the original performance. I'd prefer to address the performance in a separate ticket.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r483013573", "createdAt": "2020-09-03T14:18:19Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/balance/AccountBalancesFileLoader.java", "diffHunk": "@@ -54,6 +56,14 @@\n     private static final String UPDATE_SET_STATEMENT = \"update account_balance_sets set is_complete = ?, \" +\n             \"processing_end_timestamp = now() at time zone 'utc' where consensus_timestamp = ? and is_complete = \" +\n             \"false;\";\n+    private static final String UPDATE_ACCOUNT_BALANCE_FILE_STATEMENT = \"update account_balance_file \" +", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjU5NjI3MQ=="}, "originalCommit": {"oid": "6b0690c2a6a9513aea8be98884958f0adfe4b035"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAxNzMzNTQyOnYy", "diffSide": "RIGHT", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/downloader/Downloader.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQyMzoyNTo1N1rOHMPYSQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxNzo1Mzo1M1rOHMxfgQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjU5NjkzNw==", "bodyText": "Since we can't use @Transactional here, the next best thing is TransactionTemplate. Use something like TransactionTemplate.execute(s -> {updateApplicationStatus(sf);return null;})", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r482596937", "createdAt": "2020-09-02T23:25:57Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/downloader/Downloader.java", "diffHunk": "@@ -451,7 +451,33 @@ private File downloadSignedDataFile(File sigFile, String nodeAccountId) {\n         return null;\n     }\n \n-    protected abstract boolean verifyDataFile(File file, byte[] signedHash);\n+    /**\n+     * Updates last valid downloaded file and last valid downloaded file hash key in database if applicable. Also saves\n+     * the stream file to its corresponding database table.\n+     * @param streamFile the verified stream file\n+     */\n+    private void updateApplicationStatus(StreamFile streamFile) {\n+        DefaultTransactionDefinition def = new DefaultTransactionDefinition();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b0690c2a6a9513aea8be98884958f0adfe4b035"}, "originalPosition": 249}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzE1NTg0MQ==", "bodyText": "sure. will switch to TransactionTemplate inside updateApplicationStatus", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r483155841", "createdAt": "2020-09-03T17:53:53Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/downloader/Downloader.java", "diffHunk": "@@ -451,7 +451,33 @@ private File downloadSignedDataFile(File sigFile, String nodeAccountId) {\n         return null;\n     }\n \n-    protected abstract boolean verifyDataFile(File file, byte[] signedHash);\n+    /**\n+     * Updates last valid downloaded file and last valid downloaded file hash key in database if applicable. Also saves\n+     * the stream file to its corresponding database table.\n+     * @param streamFile the verified stream file\n+     */\n+    private void updateApplicationStatus(StreamFile streamFile) {\n+        DefaultTransactionDefinition def = new DefaultTransactionDefinition();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjU5NjkzNw=="}, "originalCommit": {"oid": "6b0690c2a6a9513aea8be98884958f0adfe4b035"}, "originalPosition": 249}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAxNzM1OTUwOnYy", "diffSide": "RIGHT", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/pubsub/PubSubRecordStreamFileListener.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQyMzozNjo1MVrOHMPmVA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxMzo1Nzo0M1rOHMn4sw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjYwMDUzMg==", "bodyText": "Q: Why do we save the recordFile earlier after downloading if we're still passing the object along and eventually hitting the db for its table here as before?\nIs there a separation of design we're going for? Just asking in favor of minimizing db calls.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r482600532", "createdAt": "2020-09-02T23:36:51Z", "author": {"login": "Nana-EC"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/pubsub/PubSubRecordStreamFileListener.java", "diffHunk": "@@ -40,11 +42,19 @@\n \n     @Override\n     public void onStart(StreamFileData streamFileData) throws ImporterException {\n+        String fileName = FilenameUtils.getName(streamFileData.getFilename());\n+        if (recordFileRepository.findByName(fileName).size() != 1) {\n+            throw new MissingFileException(\"File not found in the database: \" + fileName);\n+        }\n     }\n \n     @Override\n     public void onEnd(RecordFile recordFile) throws ImporterException {\n-        recordFileRepository.save(recordFile);\n+        int count = recordFileRepository.updateLoadStats(recordFile.getName(), recordFile.getLoadStart(), recordFile.getLoadEnd());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b0690c2a6a9513aea8be98884958f0adfe4b035"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mjk5ODQ1MQ==", "bodyText": "it's the requirement of the ticket and the way we chose to implement the logic.\nonly in downloader we know the node from which sig file is verified to reach consensus & corresponding data file is downloaded and verified. We need a mechanism to either persist the node info or pass it to parser. We chose to persist the node info of the stream file in downloader thus we have a db record insert in downloader and update (load stats and other info depending on type of file) in parser.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r482998451", "createdAt": "2020-09-03T13:57:43Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/pubsub/PubSubRecordStreamFileListener.java", "diffHunk": "@@ -40,11 +42,19 @@\n \n     @Override\n     public void onStart(StreamFileData streamFileData) throws ImporterException {\n+        String fileName = FilenameUtils.getName(streamFileData.getFilename());\n+        if (recordFileRepository.findByName(fileName).size() != 1) {\n+            throw new MissingFileException(\"File not found in the database: \" + fileName);\n+        }\n     }\n \n     @Override\n     public void onEnd(RecordFile recordFile) throws ImporterException {\n-        recordFileRepository.save(recordFile);\n+        int count = recordFileRepository.updateLoadStats(recordFile.getName(), recordFile.getLoadStart(), recordFile.getLoadEnd());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjYwMDUzMg=="}, "originalCommit": {"oid": "6b0690c2a6a9513aea8be98884958f0adfe4b035"}, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyMDU0MjI3OnYy", "diffSide": "RIGHT", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/downloader/Downloader.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxNjoxMDoyNlrOHMt0HQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxNjoxMDoyNlrOHMt0HQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzA5NTU4MQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                                        signature.getNodeAccountId(), signature.getFile().getName(), e);\n          \n          \n            \n                                        signature.getNodeAccountIdString(), signature.getFile().getName(), e);", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r483095581", "createdAt": "2020-09-03T16:10:26Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/downloader/Downloader.java", "diffHunk": "@@ -385,38 +389,34 @@ private void verifySigsAndDownloadDataFiles(Multimap<String, FileStreamSignature\n                 }\n \n                 try {\n-                    File signedDataFile = downloadSignedDataFile(signature.getFile(), signature.getNode());\n+                    File signedDataFile = downloadSignedDataFile(signature.getFile(), signature.getNodeAccountIdString());\n                     if (signedDataFile == null) {\n                         continue;\n                     }\n \n-                    if (verifyDataFile(signedDataFile, signature.getHash())) {\n-                        if (Utility.isStreamFileAfterInstant(sigFilename, endDate)) {\n-                            downloaderProperties.setEnabled(false);\n-                            log.warn(\"Disabled polling after downloading all files <= endDate ({})\", endDate);\n-                            return;\n-                        }\n+                    StreamFile streamFile = readAndVerifyDataFile(signedDataFile, signature.getHashAsHex());\n+                    streamFile.setNodeAccountId(signature.getNodeAccountId());\n \n-                        // move the file to the valid directory\n-                        File destination = validPath.resolve(signedDataFile.getName()).toFile();\n-                        if (moveFile(signedDataFile, destination)) {\n-                            if (lastValidDownloadedFileHashKey != null) {\n-                                applicationStatusRepository.updateStatusValue(lastValidDownloadedFileHashKey,\n-                                        signature.getHashAsHex());\n-                            }\n-                            applicationStatusRepository\n-                                    .updateStatusValue(lastValidDownloadedFileKey, destination.getName());\n-                            valid = true;\n-                            signatures.forEach(this::moveSignatureFile);\n-                            break;\n-                        }\n-                    } else {\n-                        log.warn(\"Verification of data file {} from node {} failed. Will retry another node\",\n-                                signedDataFile.getName(), signature.getNode());\n+                    if (Utility.isStreamFileAfterInstant(sigFilename, endDate)) {\n+                        downloaderProperties.setEnabled(false);\n+                        log.warn(\"Disabled polling after downloading all files <= endDate ({})\", endDate);\n+                        return;\n                     }\n+\n+                    // move the file to the valid directory\n+                    File destination = validPath.resolve(signedDataFile.getName()).toFile();\n+                    moveFile(signedDataFile, destination);\n+                    signatures.forEach(this::moveSignatureFile);\n+\n+                    updateApplicationStatus(streamFile);\n+                    valid = true;\n+                    break;\n+                } catch (HashMismatchException e) {\n+                    log.warn(\"Failed to verify data file from node {} corresponding to {}. Will retry another node\",\n+                            signature.getNodeAccountId(), signature.getFile().getName(), e);\n                 } catch (Exception e) {\n                     log.error(\"Error downloading data file from node {} corresponding to {}. Will retry another node\",\n-                            signature.getNode(), signature.getFile().getName(), e);\n+                            signature.getNodeAccountId(), signature.getFile().getName(), e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b0690c2a6a9513aea8be98884958f0adfe4b035"}, "originalPosition": 234}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyMDU1MTIzOnYy", "diffSide": "RIGHT", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/downloader/balance/AccountBalancesDownloader.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxNjoxMjozNVrOHMt5rQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxNzo1MTowMFrOHMxZJw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzA5NzAwNQ==", "bodyText": "This can be pulled to parent if you create a StreamFileRepository interface. Though maybe this has to wait until we have an EventFileRepository?", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r483097005", "createdAt": "2020-09-03T16:12:35Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/downloader/balance/AccountBalancesDownloader.java", "diffHunk": "@@ -22,37 +22,65 @@\n \n import io.micrometer.core.instrument.MeterRegistry;\n import java.io.File;\n-import java.util.Arrays;\n import javax.inject.Named;\n import lombok.extern.log4j.Log4j2;\n import org.springframework.scheduling.annotation.Scheduled;\n+import org.springframework.transaction.PlatformTransactionManager;\n import software.amazon.awssdk.services.s3.S3AsyncClient;\n \n import com.hedera.mirror.importer.addressbook.AddressBookService;\n+import com.hedera.mirror.importer.domain.AccountBalanceFile;\n+import com.hedera.mirror.importer.domain.StreamFile;\n import com.hedera.mirror.importer.downloader.Downloader;\n+import com.hedera.mirror.importer.exception.HashMismatchException;\n import com.hedera.mirror.importer.leader.Leader;\n+import com.hedera.mirror.importer.repository.AccountBalanceFileRepository;\n import com.hedera.mirror.importer.repository.ApplicationStatusRepository;\n import com.hedera.mirror.importer.util.Utility;\n \n @Log4j2\n @Named\n public class AccountBalancesDownloader extends Downloader {\n \n+    private AccountBalanceFileRepository accountBalanceFileRepository;\n+\n     public AccountBalancesDownloader(\n             S3AsyncClient s3Client, ApplicationStatusRepository applicationStatusRepository,\n             AddressBookService addressBookService, BalanceDownloaderProperties downloaderProperties,\n-            MeterRegistry meterRegistry) {\n-        super(s3Client, applicationStatusRepository, addressBookService, downloaderProperties, meterRegistry);\n+            PlatformTransactionManager platformTransactionManager, MeterRegistry meterRegistry, AccountBalanceFileRepository accountBalanceFileRepository) {\n+        super(s3Client, applicationStatusRepository, addressBookService, downloaderProperties, platformTransactionManager, meterRegistry);\n+        this.accountBalanceFileRepository = accountBalanceFileRepository;\n+    }\n+\n+    /**\n+     * Reads the account balance file and checks that the file hash matches the verified hash.\n+     * @param file account balance file object\n+     * @param verifiedHash the verified hash in hex\n+     * @return StreamFile object\n+     */\n+    @Override\n+    protected StreamFile readAndVerifyDataFile(File file, String verifiedHash) {\n+        String fileHash = Utility.getBalanceFileHash(file.getPath());\n+        if (!verifiedHash.contentEquals(fileHash)) {\n+            throw new HashMismatchException(file.getName(), verifiedHash, fileHash);\n+        }\n+\n+        AccountBalanceFile accountBalanceFile = new AccountBalanceFile();\n+        accountBalanceFile.setName(file.getName());\n+        accountBalanceFile.setConsensusTimestamp(Utility.getTimestampFromFilename(file.getName()));\n+        accountBalanceFile.setFileHash(fileHash);\n+        accountBalanceFile.setCount(0L);\n+        return accountBalanceFile;\n+    }\n+\n+    @Override\n+    protected void saveStreamFileRecord(StreamFile streamFile) {\n+        accountBalanceFileRepository.save((AccountBalanceFile)streamFile);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b0690c2a6a9513aea8be98884958f0adfe4b035"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzE1NDIxNQ==", "bodyText": "Yeah prefer to wait till we have an EventFileRepository.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r483154215", "createdAt": "2020-09-03T17:51:00Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/downloader/balance/AccountBalancesDownloader.java", "diffHunk": "@@ -22,37 +22,65 @@\n \n import io.micrometer.core.instrument.MeterRegistry;\n import java.io.File;\n-import java.util.Arrays;\n import javax.inject.Named;\n import lombok.extern.log4j.Log4j2;\n import org.springframework.scheduling.annotation.Scheduled;\n+import org.springframework.transaction.PlatformTransactionManager;\n import software.amazon.awssdk.services.s3.S3AsyncClient;\n \n import com.hedera.mirror.importer.addressbook.AddressBookService;\n+import com.hedera.mirror.importer.domain.AccountBalanceFile;\n+import com.hedera.mirror.importer.domain.StreamFile;\n import com.hedera.mirror.importer.downloader.Downloader;\n+import com.hedera.mirror.importer.exception.HashMismatchException;\n import com.hedera.mirror.importer.leader.Leader;\n+import com.hedera.mirror.importer.repository.AccountBalanceFileRepository;\n import com.hedera.mirror.importer.repository.ApplicationStatusRepository;\n import com.hedera.mirror.importer.util.Utility;\n \n @Log4j2\n @Named\n public class AccountBalancesDownloader extends Downloader {\n \n+    private AccountBalanceFileRepository accountBalanceFileRepository;\n+\n     public AccountBalancesDownloader(\n             S3AsyncClient s3Client, ApplicationStatusRepository applicationStatusRepository,\n             AddressBookService addressBookService, BalanceDownloaderProperties downloaderProperties,\n-            MeterRegistry meterRegistry) {\n-        super(s3Client, applicationStatusRepository, addressBookService, downloaderProperties, meterRegistry);\n+            PlatformTransactionManager platformTransactionManager, MeterRegistry meterRegistry, AccountBalanceFileRepository accountBalanceFileRepository) {\n+        super(s3Client, applicationStatusRepository, addressBookService, downloaderProperties, platformTransactionManager, meterRegistry);\n+        this.accountBalanceFileRepository = accountBalanceFileRepository;\n+    }\n+\n+    /**\n+     * Reads the account balance file and checks that the file hash matches the verified hash.\n+     * @param file account balance file object\n+     * @param verifiedHash the verified hash in hex\n+     * @return StreamFile object\n+     */\n+    @Override\n+    protected StreamFile readAndVerifyDataFile(File file, String verifiedHash) {\n+        String fileHash = Utility.getBalanceFileHash(file.getPath());\n+        if (!verifiedHash.contentEquals(fileHash)) {\n+            throw new HashMismatchException(file.getName(), verifiedHash, fileHash);\n+        }\n+\n+        AccountBalanceFile accountBalanceFile = new AccountBalanceFile();\n+        accountBalanceFile.setName(file.getName());\n+        accountBalanceFile.setConsensusTimestamp(Utility.getTimestampFromFilename(file.getName()));\n+        accountBalanceFile.setFileHash(fileHash);\n+        accountBalanceFile.setCount(0L);\n+        return accountBalanceFile;\n+    }\n+\n+    @Override\n+    protected void saveStreamFileRecord(StreamFile streamFile) {\n+        accountBalanceFileRepository.save((AccountBalanceFile)streamFile);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzA5NzAwNQ=="}, "originalCommit": {"oid": "6b0690c2a6a9513aea8be98884958f0adfe4b035"}, "originalPosition": 60}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyMDYzMTEzOnYy", "diffSide": "RIGHT", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/downloader/record/RecordFileDownloader.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxNjozMjo1MVrOHMurzg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QyMTowNjowM1rOHM3e0A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzEwOTgzOA==", "bodyText": "Would be better if Utility.verifyHashChain() is removed from Utility.parseRecordFile() and moved to Downloader. There's no need to re-verify hash chain again in parser and it simplifies Utility.parseRecordFile(). It's also more consistent with EventFileDownloader and paves the way for a future RecordFileReader.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r483109838", "createdAt": "2020-09-03T16:32:51Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/downloader/record/RecordFileDownloader.java", "diffHunk": "@@ -57,28 +62,32 @@ public void download() {\n     }\n \n     /**\n-     * Checks that hash of data file matches the verified hash and that data file is next in line based on previous file\n-     * hash. Returns false if any condition is false.\n+     * Reads the data file and checks that hash of data file matches the verified hash and that data file is next in\n+     * line based on previous file hash.\n+     * @param file data file object\n+     * @param verifiedHash the verified hash in hex\n+     * @return StreamFile object\n      */\n     @Override\n-    protected boolean verifyDataFile(File file, byte[] verifiedHash) {\n+    protected StreamFile readAndVerifyDataFile(File file, String verifiedHash) {\n         String expectedPrevFileHash = applicationStatusRepository.findByStatusCode(lastValidDownloadedFileHashKey);\n-        try {\n-            RecordFile recordFile = Utility.parseRecordFile(file.getPath(), expectedPrevFileHash,\n-                    downloaderProperties.getMirrorProperties().getVerifyHashAfter(), null);\n-            if (!recordFile.getFileHash().contentEquals(Hex.encodeHexString(verifiedHash))) {\n-                return false;\n-            }\n+        RecordFile recordFile = Utility.parseRecordFile(file.getPath(), expectedPrevFileHash,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b0690c2a6a9513aea8be98884958f0adfe4b035"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzI1Mzk2OA==", "bodyText": "yes and we can further pull the hash chain and hash verification into the base class.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r483253968", "createdAt": "2020-09-03T21:06:03Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/downloader/record/RecordFileDownloader.java", "diffHunk": "@@ -57,28 +62,32 @@ public void download() {\n     }\n \n     /**\n-     * Checks that hash of data file matches the verified hash and that data file is next in line based on previous file\n-     * hash. Returns false if any condition is false.\n+     * Reads the data file and checks that hash of data file matches the verified hash and that data file is next in\n+     * line based on previous file hash.\n+     * @param file data file object\n+     * @param verifiedHash the verified hash in hex\n+     * @return StreamFile object\n      */\n     @Override\n-    protected boolean verifyDataFile(File file, byte[] verifiedHash) {\n+    protected StreamFile readAndVerifyDataFile(File file, String verifiedHash) {\n         String expectedPrevFileHash = applicationStatusRepository.findByStatusCode(lastValidDownloadedFileHashKey);\n-        try {\n-            RecordFile recordFile = Utility.parseRecordFile(file.getPath(), expectedPrevFileHash,\n-                    downloaderProperties.getMirrorProperties().getVerifyHashAfter(), null);\n-            if (!recordFile.getFileHash().contentEquals(Hex.encodeHexString(verifiedHash))) {\n-                return false;\n-            }\n+        RecordFile recordFile = Utility.parseRecordFile(file.getPath(), expectedPrevFileHash,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzEwOTgzOA=="}, "originalCommit": {"oid": "6b0690c2a6a9513aea8be98884958f0adfe4b035"}, "originalPosition": 58}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyMDYzNTgxOnYy", "diffSide": "RIGHT", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/exception/MissingFileException.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxNjozNDowOFrOHMuu0A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxNjozNDowOFrOHMuu0A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzExMDYwOA==", "bodyText": "Remove unused constructors increase code coverage. YAGNI", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r483110608", "createdAt": "2020-09-03T16:34:08Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/exception/MissingFileException.java", "diffHunk": "@@ -0,0 +1,38 @@\n+package com.hedera.mirror.importer.exception;\n+\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ * \u200b\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ * \u200b\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+public class MissingFileException extends ImporterException {\n+\n+    private static final long serialVersionUID = -3538381075104588657L;\n+\n+    public MissingFileException(String message) {\n+        super(message);\n+    }\n+\n+    public MissingFileException(Throwable throwable) {\n+        super(throwable);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b0690c2a6a9513aea8be98884958f0adfe4b035"}, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyMDY1MjcxOnYy", "diffSide": "RIGHT", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/balance/AccountBalancesFileLoader.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxNjozODowNVrOHMu4sA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxNjozODowNVrOHMu4sA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzExMzEzNg==", "bodyText": "We should use DataSourceUtils.getConnection(dataSource) and DataSourceUtils.releaseConnection(connection, dataSource) like we do in SqlEntityListener. Then put @Transactional on loadAccountBalances(). This also needs a rollback test.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r483113136", "createdAt": "2020-09-03T16:38:05Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/balance/AccountBalancesFileLoader.java", "diffHunk": "@@ -94,14 +109,19 @@ public boolean loadAccountBalances(@NonNull File balanceFile, DateRangeFilter da\n         int insertedCount = 0;\n         boolean complete = false;\n         Stopwatch stopwatch = Stopwatch.createStarted();\n+        Instant startTime = Instant.now();\n \n         try (Connection connection = dataSource.getConnection();\n              PreparedStatement insertSetStatement = connection.prepareStatement(INSERT_SET_STATEMENT);\n              PreparedStatement insertBalanceStatement = connection.prepareStatement(INSERT_BALANCE_STATEMENT);\n              PreparedStatement updateSetStatement = connection.prepareStatement(UPDATE_SET_STATEMENT);\n+             PreparedStatement updateAccountBalanceFileStatement = connection.prepareStatement(UPDATE_ACCOUNT_BALANCE_FILE_STATEMENT);\n              Stream<AccountBalance> stream = balanceFileReader.read(balanceFile)) {\n             long consensusTimestamp = -1;\n             List<AccountBalance> accountBalanceList = new ArrayList<>();\n+            boolean skip = false;\n+\n+            connection.setAutoCommit(false);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b0690c2a6a9513aea8be98884958f0adfe4b035"}, "originalPosition": 61}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyMDY2NDQyOnYy", "diffSide": "RIGHT", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxNjo0MDo1N1rOHMu_4A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxNjo0MDo1N1rOHMu_4A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzExNDk3Ng==", "bodyText": "It would be preferable that onStart() return the RecordFile and onEnd() just recordFileRepository.save(recordFile).", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r483114976", "createdAt": "2020-09-03T16:40:57Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListener.java", "diffHunk": "@@ -130,13 +132,21 @@ public boolean isEnabled() {\n \n     @Override\n     public void onStart(StreamFileData streamFileData) {\n+        String fileName = FilenameUtils.getName(streamFileData.getFilename());\n+        if (recordFileRepository.findByName(fileName).size() != 1) {\n+            throw new MissingFileException(\"File not found in the database: \" + fileName);\n+        }\n+\n         cleanup();\n     }\n \n     @Override\n     public void onEnd(RecordFile recordFile) {\n         executeBatches();\n-        recordFileRepository.save(recordFile);\n+        int count = recordFileRepository.updateLoadStats(recordFile.getName(), recordFile.getLoadStart(), recordFile.getLoadEnd());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b0690c2a6a9513aea8be98884958f0adfe4b035"}, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyMDY3MTc4OnYy", "diffSide": "RIGHT", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/repository/AccountBalanceFileRepository.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxNjo0Mjo1NFrOHMvEbQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxNjo0Mjo1NFrOHMvEbQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzExNjE0MQ==", "bodyText": "Id type should be Long since consensusTimestamp is the appropriate ID.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r483116141", "createdAt": "2020-09-03T16:42:54Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/repository/AccountBalanceFileRepository.java", "diffHunk": "@@ -0,0 +1,28 @@\n+package com.hedera.mirror.importer.repository;\n+\n+/*-\n+ * \u200c\n+ * Hedera Mirror Node\n+ * \u200b\n+ * Copyright (C) 2019 - 2020 Hedera Hashgraph, LLC\n+ * \u200b\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *      http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ * \u200d\n+ */\n+\n+import org.springframework.data.repository.CrudRepository;\n+\n+import com.hedera.mirror.importer.domain.AccountBalanceFile;\n+\n+public interface AccountBalanceFileRepository extends CrudRepository<AccountBalanceFile, String> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b0690c2a6a9513aea8be98884958f0adfe4b035"}, "originalPosition": 27}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyMDY3MzQ4OnYy", "diffSide": "RIGHT", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/repository/RecordFileRepository.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxNjo0MzoyNFrOHMvFig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxNjo0MzoyNFrOHMvFig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzExNjQyNg==", "bodyText": "Can remove with other suggestion", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r483116426", "createdAt": "2020-09-03T16:43:24Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/repository/RecordFileRepository.java", "diffHunk": "@@ -21,10 +21,20 @@\n  */\n \n import java.util.List;\n+import org.springframework.data.jpa.repository.Modifying;\n+import org.springframework.data.jpa.repository.Query;\n import org.springframework.data.repository.CrudRepository;\n+import org.springframework.data.repository.query.Param;\n+import org.springframework.transaction.annotation.Transactional;\n \n import com.hedera.mirror.importer.domain.RecordFile;\n \n public interface RecordFileRepository extends CrudRepository<RecordFile, Long> {\n+\n     List<RecordFile> findByName(String name);\n+\n+    @Transactional\n+    @Modifying\n+    @Query(\"UPDATE RecordFile SET loadStart = :loadStart, loadEnd = :loadEnd WHERE name = :name\")\n+    int updateLoadStats(@Param(\"name\") String name, @Param(\"loadStart\") Long loadStart, @Param(\"loadEnd\") Long loadEnd);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b0690c2a6a9513aea8be98884958f0adfe4b035"}, "originalPosition": 19}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyMDcxOTk3OnYy", "diffSide": "RIGHT", "path": "hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/balance/AccountBalancesFileLoaderTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxNjo1NTo1NlrOHMvijw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxNjo1NTo1NlrOHMvijw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzEyMzg1NQ==", "bodyText": "We should have a post assert to validate count, loadstart, etc. are updated.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r483123855", "createdAt": "2020-09-03T16:55:56Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/balance/AccountBalancesFileLoaderTest.java", "diffHunk": "@@ -80,6 +87,10 @@ void setup() {\n                 .filterFiles(balanceFile.getFilename())\n                 .to(streamType.getPath(), streamType.getValid());\n         testFile = fileCopier.getTo().resolve(balanceFile.getFilename()).toFile();\n+\n+        EntityId nodeAccountId = EntityId.of(TestUtils.toAccountId(\"0.0.3\"));\n+        AccountBalanceFile accountBalanceFile = new AccountBalanceFile(balanceFile.getFilename(), balanceFile.getConsensusTimestamp(), 0L, 0L, \"\", nodeAccountId, 0L);\n+        accountBalanceFileRepository.save(accountBalanceFile);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b0690c2a6a9513aea8be98884958f0adfe4b035"}, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyMDcyNjU4OnYy", "diffSide": "RIGHT", "path": "hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListenerTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxNjo1Nzo1MFrOHMvmyg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxNjo1Nzo1MFrOHMvmyg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzEyNDkzOA==", "bodyText": "Wrong method name", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r483124938", "createdAt": "2020-09-03T16:57:50Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListenerTest.java", "diffHunk": "@@ -245,9 +251,22 @@ void testRecordFile() {\n     }\n \n     private String completeFileAndCommit() {\n-        String newFileHash = UUID.randomUUID().toString();\n-        sqlEntityListener.onEnd(new RecordFile(1L, 2L, null, fileName, 0L, 0L, newFileHash, \"fileHash0\", 0));\n-        return newFileHash;\n+        sqlEntityListener.onEnd(recordFile);\n+        return recordFile.getFileHash();\n+    }\n+\n+    private RecordFile insertAccountBalanceFile(String filename, String fileHash, String prevHash) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b0690c2a6a9513aea8be98884958f0adfe4b035"}, "originalPosition": 43}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyMDczMDAyOnYy", "diffSide": "RIGHT", "path": "hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListenerTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxNjo1ODo0NFrOHMvo1g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxNjo1ODo0NFrOHMvo1g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzEyNTQ2Mg==", "bodyText": "Should have a missing record file test", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r483125462", "createdAt": "2020-09-03T16:58:44Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/test/java/com/hedera/mirror/importer/parser/record/entity/sql/SqlEntityListenerTest.java", "diffHunk": "@@ -72,9 +73,13 @@\n     private final SqlProperties sqlProperties;\n \n     private String fileName = \"2019-08-30T18_10_00.419072Z.rcd\";\n+    private RecordFile recordFile;\n \n     @BeforeEach\n     final void beforeEach() {\n+        String newFileHash = UUID.randomUUID().toString();\n+        recordFile = insertAccountBalanceFile(fileName, newFileHash, \"fileHash0\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b0690c2a6a9513aea8be98884958f0adfe4b035"}, "originalPosition": 17}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyMDc0NjI3OnYy", "diffSide": "RIGHT", "path": "hedera-mirror-importer/src/main/resources/db/migration/V1.29.0__store_verification_node_in_stream_file_tables.sql", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxNzowMzoxN1rOHMvzHw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxNzowMzoxN1rOHMvzHw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzEyODA5NQ==", "bodyText": "Should probably be not null", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r483128095", "createdAt": "2020-09-03T17:03:17Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/resources/db/migration/V1.29.0__store_verification_node_in_stream_file_tables.sql", "diffHunk": "@@ -0,0 +1,71 @@\n+-- set the number of transactions for historic record_file records\n+create or replace function updateRecordFileCount() returns void as\n+$$\n+declare\n+\ttxnCursor          refcursor;\n+\trecordFile         record;\n+\tconsensusStart     bigint;\n+\tconsensusEnd       bigint;\n+\tcurrentNs          bigint;\n+\ttxnCount           bigint;\n+begin\n+\topen txnCursor no scroll for select consensus_ns from transaction order by consensus_ns;\n+\tcurrentNs := 0;\n+\n+\tfor recordFile in\n+\t\tselect consensus_start,consensus_end\n+\t\tfrom record_file\n+\t\torder by consensus_end\n+\t\tloop\n+\t\t\ttxnCount := 0;\n+\t\t\tconsensusStart := recordFile.consensus_start;\n+\t\t\tconsensusEnd := recordFile.consensus_end;\n+\n+\t\t\tif currentNs is NOT NULL and currentNs >= consensusStart then\n+\t\t\t\ttxnCount := 1;\n+\t\t\tend if;\n+\n+\t\t\twhile true\n+\t\t\t\tloop\n+\t\t\t\t\tfetch txnCursor into currentNs;\n+\t\t\t\t\tif currentNs is NULL or currentNs > consensusEnd then\n+\t\t\t\t\t    update record_file\n+\t\t\t\t\t        set count = txnCount\n+\t\t\t\t\t    where consensus_end = consensusEnd;\n+\t\t\t\t\t\texit; -- exit the while loop\n+\t\t\t\t\tend if;\n+\t\t\t\t\tif currentNs >= consensusStart then\n+\t\t\t\t\t\ttxnCount := txnCount + 1;\n+\t\t\t\t\tend if;\n+\t\t\t\tend loop;\n+\t\tend loop;\n+end\n+$$ language plpgsql;\n+\n+-- add node_account_id to record_file table\n+alter table if exists record_file\n+    add column node_account_id entity_id not null default 3;\n+alter table if exists record_file\n+    alter column node_account_id drop default;\n+\n+-- add count to record_file table\n+alter table if exists record_file\n+    add column count bigint;\n+\n+select updateRecordFileCount();\n+\n+alter table if exists record_file\n+    alter column count set not null;\n+\n+drop function if exists updateRecordFileCount();\n+\n+-- account_balance_file table\n+create table if not exists account_balance_file (\n+    name                varchar(250) primary key,\n+    consensus_timestamp nanos_timestamp not null,\n+    count               bigint not null,\n+    load_start          bigint,\n+    load_end            bigint,\n+    file_hash           varchar(96),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b0690c2a6a9513aea8be98884958f0adfe4b035"}, "originalPosition": 69}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyMDc0NzkzOnYy", "diffSide": "RIGHT", "path": "hedera-mirror-importer/src/main/resources/db/migration/V1.29.0__store_verification_node_in_stream_file_tables.sql", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxNzowMzo1MFrOHMv0NQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxNzowMzo1MFrOHMv0NQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzEyODM3Mw==", "bodyText": "consensus_timestamp should be primary key. Name should probably be unique.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r483128373", "createdAt": "2020-09-03T17:03:50Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/resources/db/migration/V1.29.0__store_verification_node_in_stream_file_tables.sql", "diffHunk": "@@ -0,0 +1,71 @@\n+-- set the number of transactions for historic record_file records\n+create or replace function updateRecordFileCount() returns void as\n+$$\n+declare\n+\ttxnCursor          refcursor;\n+\trecordFile         record;\n+\tconsensusStart     bigint;\n+\tconsensusEnd       bigint;\n+\tcurrentNs          bigint;\n+\ttxnCount           bigint;\n+begin\n+\topen txnCursor no scroll for select consensus_ns from transaction order by consensus_ns;\n+\tcurrentNs := 0;\n+\n+\tfor recordFile in\n+\t\tselect consensus_start,consensus_end\n+\t\tfrom record_file\n+\t\torder by consensus_end\n+\t\tloop\n+\t\t\ttxnCount := 0;\n+\t\t\tconsensusStart := recordFile.consensus_start;\n+\t\t\tconsensusEnd := recordFile.consensus_end;\n+\n+\t\t\tif currentNs is NOT NULL and currentNs >= consensusStart then\n+\t\t\t\ttxnCount := 1;\n+\t\t\tend if;\n+\n+\t\t\twhile true\n+\t\t\t\tloop\n+\t\t\t\t\tfetch txnCursor into currentNs;\n+\t\t\t\t\tif currentNs is NULL or currentNs > consensusEnd then\n+\t\t\t\t\t    update record_file\n+\t\t\t\t\t        set count = txnCount\n+\t\t\t\t\t    where consensus_end = consensusEnd;\n+\t\t\t\t\t\texit; -- exit the while loop\n+\t\t\t\t\tend if;\n+\t\t\t\t\tif currentNs >= consensusStart then\n+\t\t\t\t\t\ttxnCount := txnCount + 1;\n+\t\t\t\t\tend if;\n+\t\t\t\tend loop;\n+\t\tend loop;\n+end\n+$$ language plpgsql;\n+\n+-- add node_account_id to record_file table\n+alter table if exists record_file\n+    add column node_account_id entity_id not null default 3;\n+alter table if exists record_file\n+    alter column node_account_id drop default;\n+\n+-- add count to record_file table\n+alter table if exists record_file\n+    add column count bigint;\n+\n+select updateRecordFileCount();\n+\n+alter table if exists record_file\n+    alter column count set not null;\n+\n+drop function if exists updateRecordFileCount();\n+\n+-- account_balance_file table\n+create table if not exists account_balance_file (\n+    name                varchar(250) primary key,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b0690c2a6a9513aea8be98884958f0adfe4b035"}, "originalPosition": 64}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyMDc1MzE3OnYy", "diffSide": "RIGHT", "path": "hedera-mirror-importer/src/main/resources/db/migration/V1.29.0__store_verification_node_in_stream_file_tables.sql", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxNzowNToxNlrOHMv3cQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QxNzoxNzo1MVrOHMwSag==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzEyOTIwMQ==", "bodyText": "Should we populate past data using account_balance_sets?", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r483129201", "createdAt": "2020-09-03T17:05:16Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/resources/db/migration/V1.29.0__store_verification_node_in_stream_file_tables.sql", "diffHunk": "@@ -0,0 +1,71 @@\n+-- set the number of transactions for historic record_file records\n+create or replace function updateRecordFileCount() returns void as\n+$$\n+declare\n+\ttxnCursor          refcursor;\n+\trecordFile         record;\n+\tconsensusStart     bigint;\n+\tconsensusEnd       bigint;\n+\tcurrentNs          bigint;\n+\ttxnCount           bigint;\n+begin\n+\topen txnCursor no scroll for select consensus_ns from transaction order by consensus_ns;\n+\tcurrentNs := 0;\n+\n+\tfor recordFile in\n+\t\tselect consensus_start,consensus_end\n+\t\tfrom record_file\n+\t\torder by consensus_end\n+\t\tloop\n+\t\t\ttxnCount := 0;\n+\t\t\tconsensusStart := recordFile.consensus_start;\n+\t\t\tconsensusEnd := recordFile.consensus_end;\n+\n+\t\t\tif currentNs is NOT NULL and currentNs >= consensusStart then\n+\t\t\t\ttxnCount := 1;\n+\t\t\tend if;\n+\n+\t\t\twhile true\n+\t\t\t\tloop\n+\t\t\t\t\tfetch txnCursor into currentNs;\n+\t\t\t\t\tif currentNs is NULL or currentNs > consensusEnd then\n+\t\t\t\t\t    update record_file\n+\t\t\t\t\t        set count = txnCount\n+\t\t\t\t\t    where consensus_end = consensusEnd;\n+\t\t\t\t\t\texit; -- exit the while loop\n+\t\t\t\t\tend if;\n+\t\t\t\t\tif currentNs >= consensusStart then\n+\t\t\t\t\t\ttxnCount := txnCount + 1;\n+\t\t\t\t\tend if;\n+\t\t\t\tend loop;\n+\t\tend loop;\n+end\n+$$ language plpgsql;\n+\n+-- add node_account_id to record_file table\n+alter table if exists record_file\n+    add column node_account_id entity_id not null default 3;\n+alter table if exists record_file\n+    alter column node_account_id drop default;\n+\n+-- add count to record_file table\n+alter table if exists record_file\n+    add column count bigint;\n+\n+select updateRecordFileCount();\n+\n+alter table if exists record_file\n+    alter column count set not null;\n+\n+drop function if exists updateRecordFileCount();\n+\n+-- account_balance_file table\n+create table if not exists account_balance_file (", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b0690c2a6a9513aea8be98884958f0adfe4b035"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzEzNjEwNg==", "bodyText": "yes we could, but we can't get file_hash for the old account balance files.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r483136106", "createdAt": "2020-09-03T17:17:51Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-importer/src/main/resources/db/migration/V1.29.0__store_verification_node_in_stream_file_tables.sql", "diffHunk": "@@ -0,0 +1,71 @@\n+-- set the number of transactions for historic record_file records\n+create or replace function updateRecordFileCount() returns void as\n+$$\n+declare\n+\ttxnCursor          refcursor;\n+\trecordFile         record;\n+\tconsensusStart     bigint;\n+\tconsensusEnd       bigint;\n+\tcurrentNs          bigint;\n+\ttxnCount           bigint;\n+begin\n+\topen txnCursor no scroll for select consensus_ns from transaction order by consensus_ns;\n+\tcurrentNs := 0;\n+\n+\tfor recordFile in\n+\t\tselect consensus_start,consensus_end\n+\t\tfrom record_file\n+\t\torder by consensus_end\n+\t\tloop\n+\t\t\ttxnCount := 0;\n+\t\t\tconsensusStart := recordFile.consensus_start;\n+\t\t\tconsensusEnd := recordFile.consensus_end;\n+\n+\t\t\tif currentNs is NOT NULL and currentNs >= consensusStart then\n+\t\t\t\ttxnCount := 1;\n+\t\t\tend if;\n+\n+\t\t\twhile true\n+\t\t\t\tloop\n+\t\t\t\t\tfetch txnCursor into currentNs;\n+\t\t\t\t\tif currentNs is NULL or currentNs > consensusEnd then\n+\t\t\t\t\t    update record_file\n+\t\t\t\t\t        set count = txnCount\n+\t\t\t\t\t    where consensus_end = consensusEnd;\n+\t\t\t\t\t\texit; -- exit the while loop\n+\t\t\t\t\tend if;\n+\t\t\t\t\tif currentNs >= consensusStart then\n+\t\t\t\t\t\ttxnCount := txnCount + 1;\n+\t\t\t\t\tend if;\n+\t\t\t\tend loop;\n+\t\tend loop;\n+end\n+$$ language plpgsql;\n+\n+-- add node_account_id to record_file table\n+alter table if exists record_file\n+    add column node_account_id entity_id not null default 3;\n+alter table if exists record_file\n+    alter column node_account_id drop default;\n+\n+-- add count to record_file table\n+alter table if exists record_file\n+    add column count bigint;\n+\n+select updateRecordFileCount();\n+\n+alter table if exists record_file\n+    alter column count set not null;\n+\n+drop function if exists updateRecordFileCount();\n+\n+-- account_balance_file table\n+create table if not exists account_balance_file (", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzEyOTIwMQ=="}, "originalCommit": {"oid": "6b0690c2a6a9513aea8be98884958f0adfe4b035"}, "originalPosition": 63}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNTQ4NDYwOnYy", "diffSide": "RIGHT", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/downloader/Downloader.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQyMTo1Mzo1OVrOHNcdaQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQyMTo0MjozMlrOHQGxEg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1OTgxNw==", "bodyText": "You can just inject the TransactionTemplate directly. Spring Boot already creates one as a bean.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r483859817", "createdAt": "2020-09-04T21:53:59Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/downloader/Downloader.java", "diffHunk": "@@ -96,11 +102,12 @@\n \n     public Downloader(S3AsyncClient s3Client, ApplicationStatusRepository applicationStatusRepository,\n                       AddressBookService addressBookService, DownloaderProperties downloaderProperties,\n-                      MeterRegistry meterRegistry) {\n+                      PlatformTransactionManager platformTransactionManager, MeterRegistry meterRegistry) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2109d887aa7b2d42e10f16f0ada5d4430e623d61"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjY1MDEzMA==", "bodyText": "changed to inject TransactionTemplate", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r486650130", "createdAt": "2020-09-10T21:42:32Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/downloader/Downloader.java", "diffHunk": "@@ -96,11 +102,12 @@\n \n     public Downloader(S3AsyncClient s3Client, ApplicationStatusRepository applicationStatusRepository,\n                       AddressBookService addressBookService, DownloaderProperties downloaderProperties,\n-                      MeterRegistry meterRegistry) {\n+                      PlatformTransactionManager platformTransactionManager, MeterRegistry meterRegistry) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1OTgxNw=="}, "originalCommit": {"oid": "2109d887aa7b2d42e10f16f0ada5d4430e623d61"}, "originalPosition": 45}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNTQ5Nzg5OnYy", "diffSide": "RIGHT", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/repository/RecordFileRepository.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQyMjowMToxOVrOHNck9w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQyMTo0Mjo0OVrOHQGxmQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg2MTc1MQ==", "bodyText": "Name has a unique constraint, so this can be changed to return an Optional<RecordFile> and cleanup the logic in the calling classes.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r483861751", "createdAt": "2020-09-04T22:01:19Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/repository/RecordFileRepository.java", "diffHunk": "@@ -26,5 +26,6 @@\n import com.hedera.mirror.importer.domain.RecordFile;\n \n public interface RecordFileRepository extends CrudRepository<RecordFile, Long> {\n+\n     List<RecordFile> findByName(String name);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2109d887aa7b2d42e10f16f0ada5d4430e623d61"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjY1MDI2NQ==", "bodyText": "changed to Optional<RecordFile>", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r486650265", "createdAt": "2020-09-10T21:42:49Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/repository/RecordFileRepository.java", "diffHunk": "@@ -26,5 +26,6 @@\n import com.hedera.mirror.importer.domain.RecordFile;\n \n public interface RecordFileRepository extends CrudRepository<RecordFile, Long> {\n+\n     List<RecordFile> findByName(String name);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg2MTc1MQ=="}, "originalCommit": {"oid": "2109d887aa7b2d42e10f16f0ada5d4430e623d61"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNTUwNTM5OnYy", "diffSide": "RIGHT", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/balance/BalanceFileParser.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQyMjowNTo0NVrOHNcpLg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQyMjo1Njo0NFrOHQIe3A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg2MjgzMA==", "bodyText": "We shouldn't catch this exception as it will skip the balance file and move on to the next even for transient errors like database down.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r483862830", "createdAt": "2020-09-04T22:05:45Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/balance/BalanceFileParser.java", "diffHunk": "@@ -77,12 +77,15 @@ public void parse() {\n     }\n \n     private void parseBalanceFile(File balanceFile, DateRangeFilter dateRangeFilter) {\n-        if (accountBalancesFileLoader.loadAccountBalances(balanceFile, dateRangeFilter)) {\n+        try {\n+            accountBalancesFileLoader.loadAccountBalances(balanceFile, dateRangeFilter);\n             if (parserProperties.isKeepFiles()) {\n                 Utility.archiveFile(balanceFile, parserProperties.getParsedPath());\n             } else {\n                 FileUtils.deleteQuietly(balanceFile);\n             }\n+        } catch (Exception ex) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2109d887aa7b2d42e10f16f0ada5d4430e623d61"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjY1MTMxMg==", "bodyText": "my thought is since account balance files are not hash chained so in case of transient database issue, we try the best to process as many files in a batch and pick up what's left in the next scheduled run", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r486651312", "createdAt": "2020-09-10T21:45:16Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/balance/BalanceFileParser.java", "diffHunk": "@@ -77,12 +77,15 @@ public void parse() {\n     }\n \n     private void parseBalanceFile(File balanceFile, DateRangeFilter dateRangeFilter) {\n-        if (accountBalancesFileLoader.loadAccountBalances(balanceFile, dateRangeFilter)) {\n+        try {\n+            accountBalancesFileLoader.loadAccountBalances(balanceFile, dateRangeFilter);\n             if (parserProperties.isKeepFiles()) {\n                 Utility.archiveFile(balanceFile, parserProperties.getParsedPath());\n             } else {\n                 FileUtils.deleteQuietly(balanceFile);\n             }\n+        } catch (Exception ex) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg2MjgzMA=="}, "originalCommit": {"oid": "2109d887aa7b2d42e10f16f0ada5d4430e623d61"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjY3ODIzNg==", "bodyText": "Agreed", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r486678236", "createdAt": "2020-09-10T22:56:44Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/balance/BalanceFileParser.java", "diffHunk": "@@ -77,12 +77,15 @@ public void parse() {\n     }\n \n     private void parseBalanceFile(File balanceFile, DateRangeFilter dateRangeFilter) {\n-        if (accountBalancesFileLoader.loadAccountBalances(balanceFile, dateRangeFilter)) {\n+        try {\n+            accountBalancesFileLoader.loadAccountBalances(balanceFile, dateRangeFilter);\n             if (parserProperties.isKeepFiles()) {\n                 Utility.archiveFile(balanceFile, parserProperties.getParsedPath());\n             } else {\n                 FileUtils.deleteQuietly(balanceFile);\n             }\n+        } catch (Exception ex) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg2MjgzMA=="}, "originalCommit": {"oid": "2109d887aa7b2d42e10f16f0ada5d4430e623d61"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAzMzg0MzM3OnYy", "diffSide": "RIGHT", "path": "hedera-mirror-importer/src/main/resources/db/migration/V1.29.0__store_verification_node_in_stream_file_tables.sql", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxNjo0MDoyOFrOHOlfgg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQyMTo0NToyNVrOHQG16w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA1NjM4Ng==", "bodyText": "We can populate load_start and load_end from account_balance_sets.processing_start_timestamp and account_balance_sets.processing_end_timestamp.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r485056386", "createdAt": "2020-09-08T16:40:28Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/resources/db/migration/V1.29.0__store_verification_node_in_stream_file_tables.sql", "diffHunk": "@@ -0,0 +1,104 @@\n+-- set the number of transactions for historic record_file records\n+create or replace function updateRecordFileCount() returns void as\n+$$\n+declare\n+\ttxnCursor          refcursor;\n+\trecordFile         record;\n+\tconsensusStart     bigint;\n+\tconsensusEnd       bigint;\n+\tcurrentNs          bigint;\n+\ttxnCount           bigint;\n+begin\n+\topen txnCursor no scroll for select consensus_ns from transaction order by consensus_ns;\n+\tcurrentNs := 0;\n+\n+\tfor recordFile in\n+\t\tselect consensus_start,consensus_end\n+\t\tfrom record_file\n+\t\torder by consensus_end\n+\t\tloop\n+\t\t\ttxnCount := 0;\n+\t\t\tconsensusStart := recordFile.consensus_start;\n+\t\t\tconsensusEnd := recordFile.consensus_end;\n+\n+\t\t\tif currentNs is NOT NULL and currentNs >= consensusStart then\n+\t\t\t\ttxnCount := 1;\n+\t\t\tend if;\n+\n+\t\t\twhile true\n+\t\t\t\tloop\n+\t\t\t\t\tfetch txnCursor into currentNs;\n+\t\t\t\t\tif currentNs is NULL or currentNs > consensusEnd then\n+\t\t\t\t\t    update record_file\n+\t\t\t\t\t        set count = txnCount\n+\t\t\t\t\t    where consensus_end = consensusEnd;\n+\t\t\t\t\t\texit; -- exit the while loop\n+\t\t\t\t\tend if;\n+\t\t\t\t\tif currentNs >= consensusStart then\n+\t\t\t\t\t\ttxnCount := txnCount + 1;\n+\t\t\t\t\tend if;\n+\t\t\t\tend loop;\n+\t\tend loop;\n+end\n+$$ language plpgsql;\n+\n+-- add node_account_id to record_file table\n+alter table if exists record_file\n+    add column node_account_id entity_id not null default 3;\n+alter table if exists record_file\n+    alter column node_account_id drop default;\n+\n+-- add count to record_file table\n+alter table if exists record_file\n+    add column count bigint;\n+\n+select updateRecordFileCount();\n+\n+alter table if exists record_file\n+    alter column count set not null;\n+\n+drop function if exists updateRecordFileCount();\n+\n+-- account_balance_file table\n+create table if not exists account_balance_file (\n+    consensus_timestamp bigint primary key,\n+    count               bigint not null,\n+    load_start          bigint,\n+    load_end            bigint,\n+    file_hash           varchar(96),\n+\tname                varchar(250) not null,\n+    node_account_id     entity_id not null\n+);\n+\n+create unique index if not exists account_balance_file__name on account_balance_file(name);\n+\n+-- get balance filename from its consensus timestamp\n+create or replace function getBalanceFilenameFromTimestamp(timestampNs bigint) returns varchar as\n+$$\n+declare\n+    timestampString varchar;\n+    seconds         bigint;\n+    nanos           bigint;\n+begin\n+    seconds := timestampNs / 1000000000;\n+    timestampString := to_char(to_timestamp(seconds), 'YYYY-MM-DD\"T\"HH24_MI_SS');\n+    nanos := timestampNs % 1000000000;\n+    if nanos != 0 then\n+        timestampString := timestampString || '.' || trim(trailing '0' from lpad(cast(nanos as varchar), 9, '0'));\n+\tend if;\n+    return timestampString || 'Z_Balances.csv';\n+end\n+$$ language plpgsql;\n+\n+-- process past data from account_balance_sets into account_balance_file\n+insert into account_balance_file\n+    (consensus_timestamp, count, name, node_account_id)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2109d887aa7b2d42e10f16f0ada5d4430e623d61"}, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjY1MTM3MQ==", "bodyText": "made the change", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r486651371", "createdAt": "2020-09-10T21:45:25Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-importer/src/main/resources/db/migration/V1.29.0__store_verification_node_in_stream_file_tables.sql", "diffHunk": "@@ -0,0 +1,104 @@\n+-- set the number of transactions for historic record_file records\n+create or replace function updateRecordFileCount() returns void as\n+$$\n+declare\n+\ttxnCursor          refcursor;\n+\trecordFile         record;\n+\tconsensusStart     bigint;\n+\tconsensusEnd       bigint;\n+\tcurrentNs          bigint;\n+\ttxnCount           bigint;\n+begin\n+\topen txnCursor no scroll for select consensus_ns from transaction order by consensus_ns;\n+\tcurrentNs := 0;\n+\n+\tfor recordFile in\n+\t\tselect consensus_start,consensus_end\n+\t\tfrom record_file\n+\t\torder by consensus_end\n+\t\tloop\n+\t\t\ttxnCount := 0;\n+\t\t\tconsensusStart := recordFile.consensus_start;\n+\t\t\tconsensusEnd := recordFile.consensus_end;\n+\n+\t\t\tif currentNs is NOT NULL and currentNs >= consensusStart then\n+\t\t\t\ttxnCount := 1;\n+\t\t\tend if;\n+\n+\t\t\twhile true\n+\t\t\t\tloop\n+\t\t\t\t\tfetch txnCursor into currentNs;\n+\t\t\t\t\tif currentNs is NULL or currentNs > consensusEnd then\n+\t\t\t\t\t    update record_file\n+\t\t\t\t\t        set count = txnCount\n+\t\t\t\t\t    where consensus_end = consensusEnd;\n+\t\t\t\t\t\texit; -- exit the while loop\n+\t\t\t\t\tend if;\n+\t\t\t\t\tif currentNs >= consensusStart then\n+\t\t\t\t\t\ttxnCount := txnCount + 1;\n+\t\t\t\t\tend if;\n+\t\t\t\tend loop;\n+\t\tend loop;\n+end\n+$$ language plpgsql;\n+\n+-- add node_account_id to record_file table\n+alter table if exists record_file\n+    add column node_account_id entity_id not null default 3;\n+alter table if exists record_file\n+    alter column node_account_id drop default;\n+\n+-- add count to record_file table\n+alter table if exists record_file\n+    add column count bigint;\n+\n+select updateRecordFileCount();\n+\n+alter table if exists record_file\n+    alter column count set not null;\n+\n+drop function if exists updateRecordFileCount();\n+\n+-- account_balance_file table\n+create table if not exists account_balance_file (\n+    consensus_timestamp bigint primary key,\n+    count               bigint not null,\n+    load_start          bigint,\n+    load_end            bigint,\n+    file_hash           varchar(96),\n+\tname                varchar(250) not null,\n+    node_account_id     entity_id not null\n+);\n+\n+create unique index if not exists account_balance_file__name on account_balance_file(name);\n+\n+-- get balance filename from its consensus timestamp\n+create or replace function getBalanceFilenameFromTimestamp(timestampNs bigint) returns varchar as\n+$$\n+declare\n+    timestampString varchar;\n+    seconds         bigint;\n+    nanos           bigint;\n+begin\n+    seconds := timestampNs / 1000000000;\n+    timestampString := to_char(to_timestamp(seconds), 'YYYY-MM-DD\"T\"HH24_MI_SS');\n+    nanos := timestampNs % 1000000000;\n+    if nanos != 0 then\n+        timestampString := timestampString || '.' || trim(trailing '0' from lpad(cast(nanos as varchar), 9, '0'));\n+\tend if;\n+    return timestampString || 'Z_Balances.csv';\n+end\n+$$ language plpgsql;\n+\n+-- process past data from account_balance_sets into account_balance_file\n+insert into account_balance_file\n+    (consensus_timestamp, count, name, node_account_id)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA1NjM4Ng=="}, "originalCommit": {"oid": "2109d887aa7b2d42e10f16f0ada5d4430e623d61"}, "originalPosition": 95}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAzNDA3MTk1OnYy", "diffSide": "LEFT", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/balance/AccountBalancesFileLoader.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxNzo0NDoxMlrOHOnrag==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQyMjoxODo0MFrOHQHrCw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA5MjIwMg==", "bodyText": "This looks like a change in behavior. Previously if not complete then it would not move the file and continue to retry it. Now it is skipping it. We should probably throw an exception above, which causes a rollback and will retry the file later.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r485092202", "createdAt": "2020-09-08T17:44:12Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/balance/AccountBalancesFileLoader.java", "diffHunk": "@@ -110,48 +128,52 @@ public boolean loadAccountBalances(@NonNull File balanceFile, DateRangeFilter da\n                     consensusTimestamp = accountBalance.getId().getConsensusTimestamp();\n                     if (timestampFromFileName != consensusTimestamp) {\n                         // The assumption is that the dataset has been validated via signatures and running hashes,\n-                        // so it is\n-                        // the \"next\" dataset, and the consensus timestamp in it is correct.\n-                        // The fact that the filename timestamp and timestamp in the file differ should still be\n-                        // investigated.\n-                        log.error(\"Account balance dataset timestamp mismatch! Processing can continue, but this must\" +\n-                                        \" be \" +\n-                                        \"investigated! Dataset {} internal timestamp {} filename timestamp {}.\",\n+                        // so it is the \"next\" dataset, and the consensus timestamp in it is correct. The fact that\n+                        // the filename timestamp and timestamp in the file differ should still be investigated.\n+                        log.error(\"Account balance dataset timestamp mismatch! Processing can continue, but this \" +\n+                                        \"must be investigated! Dataset {} internal timestamp {} filename timestamp {}.\",\n                                 fileName, consensusTimestamp, timestampFromFileName);\n                     }\n \n                     if (dateRangeFilter != null && !dateRangeFilter.filter(consensusTimestamp)) {\n                         log.warn(\"Account balances file {} not in configured date range {}, skip it\",\n                                 fileName, dateRangeFilter);\n-                        complete = true;\n-                        break;\n+                        skip = true;\n+                    } else {\n+                        insertAccountBalanceSet(insertSetStatement, consensusTimestamp);\n                     }\n-\n-                    insertAccountBalanceSet(insertSetStatement, consensusTimestamp);\n                 }\n \n                 validCount++;\n-                accountBalanceList.add(accountBalance);\n-                insertedCount += tryInsertBatchAccountBalance(insertBalanceStatement, accountBalanceList,\n-                        insertBatchSize);\n+\n+                if (!skip) {\n+                    accountBalanceList.add(accountBalance);\n+                    insertedCount += tryInsertBatchAccountBalance(insertBalanceStatement, accountBalanceList,\n+                            insertBatchSize);\n+                }\n             }\n \n-            insertedCount += tryInsertBatchAccountBalance(insertBalanceStatement, accountBalanceList, 1);\n-            complete = (insertedCount == validCount);\n-            updateAccountBalanceSet(updateSetStatement, complete, consensusTimestamp);\n-        } catch (InvalidDatasetException | SQLException ex) {\n-            log.error(\"Failed to load account balances file \" + fileName, ex);\n-        }\n+            if (!skip) {\n+                insertedCount += tryInsertBatchAccountBalance(insertBalanceStatement, accountBalanceList, 1);\n+                complete = (insertedCount == validCount);\n+            } else {\n+                complete = true;\n+            }\n \n-        if (complete) {\n-            log.info(\"Successfully processed account balances file {} with {} out of {} records inserted in {}\",\n-                    fileName, insertedCount, validCount, stopwatch);\n-        } else {\n-            log.error(\"ERRORS processing account balances file {} with {} out of {} records inserted in {}\", fileName,\n-                    insertedCount, validCount, stopwatch);\n+            updateAccountBalanceSet(updateSetStatement, complete, consensusTimestamp);\n+            updateAccountBalanceFile(updateAccountBalanceFileStatement, consensusTimestamp, validCount,\n+                    startTime.getEpochSecond(), Instant.now().getEpochSecond(), fileName);\n+\n+            if (complete) {\n+                log.info(\"Successfully processed account balances file {} with {} out of {} records inserted in {}\",\n+                        fileName, insertedCount, validCount, stopwatch);\n+            } else {\n+                log.error(\"ERRORS processing account balances file {} with {} records parsed so far in {}\",\n+                        fileName, validCount, stopwatch);\n+            }\n+        } finally {\n+            DataSourceUtils.releaseConnection(connection, dataSource);\n         }\n-\n-        return complete;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2109d887aa7b2d42e10f16f0ada5d4430e623d61"}, "originalPosition": 168}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjY2NDk3MQ==", "bodyText": "refactored. after changing tryInsertBatchAccountBalance to throw under SQL execution failure, the original condition complete = (insertedCount == validCount) would always be true so unnecessary\nNow in loadAccountBalances, any db error would eventually cause ParserSQLException so spring will roll back the transaction", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r486664971", "createdAt": "2020-09-10T22:18:40Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/balance/AccountBalancesFileLoader.java", "diffHunk": "@@ -110,48 +128,52 @@ public boolean loadAccountBalances(@NonNull File balanceFile, DateRangeFilter da\n                     consensusTimestamp = accountBalance.getId().getConsensusTimestamp();\n                     if (timestampFromFileName != consensusTimestamp) {\n                         // The assumption is that the dataset has been validated via signatures and running hashes,\n-                        // so it is\n-                        // the \"next\" dataset, and the consensus timestamp in it is correct.\n-                        // The fact that the filename timestamp and timestamp in the file differ should still be\n-                        // investigated.\n-                        log.error(\"Account balance dataset timestamp mismatch! Processing can continue, but this must\" +\n-                                        \" be \" +\n-                                        \"investigated! Dataset {} internal timestamp {} filename timestamp {}.\",\n+                        // so it is the \"next\" dataset, and the consensus timestamp in it is correct. The fact that\n+                        // the filename timestamp and timestamp in the file differ should still be investigated.\n+                        log.error(\"Account balance dataset timestamp mismatch! Processing can continue, but this \" +\n+                                        \"must be investigated! Dataset {} internal timestamp {} filename timestamp {}.\",\n                                 fileName, consensusTimestamp, timestampFromFileName);\n                     }\n \n                     if (dateRangeFilter != null && !dateRangeFilter.filter(consensusTimestamp)) {\n                         log.warn(\"Account balances file {} not in configured date range {}, skip it\",\n                                 fileName, dateRangeFilter);\n-                        complete = true;\n-                        break;\n+                        skip = true;\n+                    } else {\n+                        insertAccountBalanceSet(insertSetStatement, consensusTimestamp);\n                     }\n-\n-                    insertAccountBalanceSet(insertSetStatement, consensusTimestamp);\n                 }\n \n                 validCount++;\n-                accountBalanceList.add(accountBalance);\n-                insertedCount += tryInsertBatchAccountBalance(insertBalanceStatement, accountBalanceList,\n-                        insertBatchSize);\n+\n+                if (!skip) {\n+                    accountBalanceList.add(accountBalance);\n+                    insertedCount += tryInsertBatchAccountBalance(insertBalanceStatement, accountBalanceList,\n+                            insertBatchSize);\n+                }\n             }\n \n-            insertedCount += tryInsertBatchAccountBalance(insertBalanceStatement, accountBalanceList, 1);\n-            complete = (insertedCount == validCount);\n-            updateAccountBalanceSet(updateSetStatement, complete, consensusTimestamp);\n-        } catch (InvalidDatasetException | SQLException ex) {\n-            log.error(\"Failed to load account balances file \" + fileName, ex);\n-        }\n+            if (!skip) {\n+                insertedCount += tryInsertBatchAccountBalance(insertBalanceStatement, accountBalanceList, 1);\n+                complete = (insertedCount == validCount);\n+            } else {\n+                complete = true;\n+            }\n \n-        if (complete) {\n-            log.info(\"Successfully processed account balances file {} with {} out of {} records inserted in {}\",\n-                    fileName, insertedCount, validCount, stopwatch);\n-        } else {\n-            log.error(\"ERRORS processing account balances file {} with {} out of {} records inserted in {}\", fileName,\n-                    insertedCount, validCount, stopwatch);\n+            updateAccountBalanceSet(updateSetStatement, complete, consensusTimestamp);\n+            updateAccountBalanceFile(updateAccountBalanceFileStatement, consensusTimestamp, validCount,\n+                    startTime.getEpochSecond(), Instant.now().getEpochSecond(), fileName);\n+\n+            if (complete) {\n+                log.info(\"Successfully processed account balances file {} with {} out of {} records inserted in {}\",\n+                        fileName, insertedCount, validCount, stopwatch);\n+            } else {\n+                log.error(\"ERRORS processing account balances file {} with {} records parsed so far in {}\",\n+                        fileName, validCount, stopwatch);\n+            }\n+        } finally {\n+            DataSourceUtils.releaseConnection(connection, dataSource);\n         }\n-\n-        return complete;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA5MjIwMg=="}, "originalCommit": {"oid": "2109d887aa7b2d42e10f16f0ada5d4430e623d61"}, "originalPosition": 168}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAzNDA3ODgyOnYy", "diffSide": "RIGHT", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/balance/AccountBalancesFileLoader.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxNzo0NjoyMFrOHOnvng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQyMjoxNToyOFrOHQHkzQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA5MzI3OA==", "bodyText": "We can probably invert this and just throw an exception if failed instead of using counts to track if failed.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r485093278", "createdAt": "2020-09-08T17:46:20Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/balance/AccountBalancesFileLoader.java", "diffHunk": "@@ -160,43 +182,29 @@ private void insertAccountBalanceSet(PreparedStatement insertSetStatement, long\n     }\n \n     private int tryInsertBatchAccountBalance(PreparedStatement insertBalanceStatement,\n-                                             List<AccountBalance> accountBalanceList, int threshold) {\n+                                             List<AccountBalance> accountBalanceList, int threshold) throws SQLException {\n         if (accountBalanceList.size() < threshold) {\n             return 0;\n         }\n \n-        int batchSize = 0;\n         for (var accountBalance : accountBalanceList) {\n             AccountBalance.Id id = accountBalance.getId();\n-            try {\n-                insertBalanceStatement.setLong(F_INSERT_BALANCE.CONSENSUS_TIMESTAMP.ordinal(),\n-                        id.getConsensusTimestamp());\n-                insertBalanceStatement.setShort(F_INSERT_BALANCE.ACCOUNT_REALM_NUM.ordinal(),\n-                        (short) id.getAccountRealmNum());\n-                insertBalanceStatement.setInt(F_INSERT_BALANCE.ACCOUNT_NUM.ordinal(), id.getAccountNum());\n-                insertBalanceStatement.setLong(F_INSERT_BALANCE.BALANCE.ordinal(), accountBalance.getBalance());\n-                insertBalanceStatement.addBatch();\n-                batchSize++;\n-            } catch (SQLException ex) {\n-                log.error(\"Failed to add account balance to the batch\", ex);\n-            }\n+            insertBalanceStatement.setLong(F_INSERT_BALANCE.CONSENSUS_TIMESTAMP.ordinal(), id.getConsensusTimestamp());\n+            insertBalanceStatement.setShort(F_INSERT_BALANCE.ACCOUNT_REALM_NUM.ordinal(),\n+                    (short) id.getAccountRealmNum());\n+            insertBalanceStatement.setInt(F_INSERT_BALANCE.ACCOUNT_NUM.ordinal(), id.getAccountNum());\n+            insertBalanceStatement.setLong(F_INSERT_BALANCE.BALANCE.ordinal(), accountBalance.getBalance());\n+            insertBalanceStatement.addBatch();\n         }\n \n         accountBalanceList.clear();\n-        if (batchSize == 0) {\n-            return 0;\n-        }\n \n         int insertedCount = 0;\n-        try {\n-            var result = insertBalanceStatement.executeBatch();\n-            for (int code : result) {\n-                if (code != Statement.EXECUTE_FAILED) {\n-                    insertedCount++;\n-                }\n+        var result = insertBalanceStatement.executeBatch();\n+        for (int code : result) {\n+            if (code != Statement.EXECUTE_FAILED) {\n+                insertedCount++;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2109d887aa7b2d42e10f16f0ada5d4430e623d61"}, "originalPosition": 220}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjY2MzM3Mw==", "bodyText": "removed unnecessary count, inverted the condition and now it throws ParserSQLException if the underlying db driver will continue execution on failure of a statement", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r486663373", "createdAt": "2020-09-10T22:15:28Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/balance/AccountBalancesFileLoader.java", "diffHunk": "@@ -160,43 +182,29 @@ private void insertAccountBalanceSet(PreparedStatement insertSetStatement, long\n     }\n \n     private int tryInsertBatchAccountBalance(PreparedStatement insertBalanceStatement,\n-                                             List<AccountBalance> accountBalanceList, int threshold) {\n+                                             List<AccountBalance> accountBalanceList, int threshold) throws SQLException {\n         if (accountBalanceList.size() < threshold) {\n             return 0;\n         }\n \n-        int batchSize = 0;\n         for (var accountBalance : accountBalanceList) {\n             AccountBalance.Id id = accountBalance.getId();\n-            try {\n-                insertBalanceStatement.setLong(F_INSERT_BALANCE.CONSENSUS_TIMESTAMP.ordinal(),\n-                        id.getConsensusTimestamp());\n-                insertBalanceStatement.setShort(F_INSERT_BALANCE.ACCOUNT_REALM_NUM.ordinal(),\n-                        (short) id.getAccountRealmNum());\n-                insertBalanceStatement.setInt(F_INSERT_BALANCE.ACCOUNT_NUM.ordinal(), id.getAccountNum());\n-                insertBalanceStatement.setLong(F_INSERT_BALANCE.BALANCE.ordinal(), accountBalance.getBalance());\n-                insertBalanceStatement.addBatch();\n-                batchSize++;\n-            } catch (SQLException ex) {\n-                log.error(\"Failed to add account balance to the batch\", ex);\n-            }\n+            insertBalanceStatement.setLong(F_INSERT_BALANCE.CONSENSUS_TIMESTAMP.ordinal(), id.getConsensusTimestamp());\n+            insertBalanceStatement.setShort(F_INSERT_BALANCE.ACCOUNT_REALM_NUM.ordinal(),\n+                    (short) id.getAccountRealmNum());\n+            insertBalanceStatement.setInt(F_INSERT_BALANCE.ACCOUNT_NUM.ordinal(), id.getAccountNum());\n+            insertBalanceStatement.setLong(F_INSERT_BALANCE.BALANCE.ordinal(), accountBalance.getBalance());\n+            insertBalanceStatement.addBatch();\n         }\n \n         accountBalanceList.clear();\n-        if (batchSize == 0) {\n-            return 0;\n-        }\n \n         int insertedCount = 0;\n-        try {\n-            var result = insertBalanceStatement.executeBatch();\n-            for (int code : result) {\n-                if (code != Statement.EXECUTE_FAILED) {\n-                    insertedCount++;\n-                }\n+        var result = insertBalanceStatement.executeBatch();\n+        for (int code : result) {\n+            if (code != Statement.EXECUTE_FAILED) {\n+                insertedCount++;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA5MzI3OA=="}, "originalCommit": {"oid": "2109d887aa7b2d42e10f16f0ada5d4430e623d61"}, "originalPosition": 220}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAzNDA5Nzc5OnYy", "diffSide": "RIGHT", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/downloader/Downloader.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxNzo1MTozOVrOHOn69A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQyMjoxMzoxNFrOHQHhkg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA5NjE4MA==", "bodyText": "It would be cleaner to separate read from verify and to pass the full objects instead of individual fields to verify.\nStreamFile streamFile = readStreamFile(signedDataFile);\nstreamFile.setNodeAccountId(signature.getNodeAccountId());\n\nverify(streamFile, signature);", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r485096180", "createdAt": "2020-09-08T17:51:39Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/downloader/Downloader.java", "diffHunk": "@@ -385,38 +389,34 @@ private void verifySigsAndDownloadDataFiles(Multimap<String, FileStreamSignature\n                 }\n \n                 try {\n-                    File signedDataFile = downloadSignedDataFile(signature.getFile(), signature.getNode());\n+                    File signedDataFile = downloadSignedDataFile(signature.getFile(), signature.getNodeAccountIdString());\n                     if (signedDataFile == null) {\n                         continue;\n                     }\n \n-                    if (verifyDataFile(signedDataFile, signature.getHash())) {\n-                        if (Utility.isStreamFileAfterInstant(sigFilename, endDate)) {\n-                            downloaderProperties.setEnabled(false);\n-                            log.warn(\"Disabled polling after downloading all files <= endDate ({})\", endDate);\n-                            return;\n-                        }\n+                    StreamFile streamFile = readAndVerifyStreamFile(signedDataFile, signature.getHashAsHex());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2109d887aa7b2d42e10f16f0ada5d4430e623d61"}, "originalPosition": 202}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjY2MjU0Ng==", "bodyText": "made the suggested change", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r486662546", "createdAt": "2020-09-10T22:13:14Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/downloader/Downloader.java", "diffHunk": "@@ -385,38 +389,34 @@ private void verifySigsAndDownloadDataFiles(Multimap<String, FileStreamSignature\n                 }\n \n                 try {\n-                    File signedDataFile = downloadSignedDataFile(signature.getFile(), signature.getNode());\n+                    File signedDataFile = downloadSignedDataFile(signature.getFile(), signature.getNodeAccountIdString());\n                     if (signedDataFile == null) {\n                         continue;\n                     }\n \n-                    if (verifyDataFile(signedDataFile, signature.getHash())) {\n-                        if (Utility.isStreamFileAfterInstant(sigFilename, endDate)) {\n-                            downloaderProperties.setEnabled(false);\n-                            log.warn(\"Disabled polling after downloading all files <= endDate ({})\", endDate);\n-                            return;\n-                        }\n+                    StreamFile streamFile = readAndVerifyStreamFile(signedDataFile, signature.getHashAsHex());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA5NjE4MA=="}, "originalCommit": {"oid": "2109d887aa7b2d42e10f16f0ada5d4430e623d61"}, "originalPosition": 202}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAzNDExMjc5OnYy", "diffSide": "RIGHT", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/downloader/Downloader.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxNzo1NTo1OFrOHOoD7Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQyMjoxNDowMVrOHQHirA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA5ODQ3Nw==", "bodyText": "I think moveFile() should be within the transaction at the end so if it fails the database updates are rolled back as well.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r485098477", "createdAt": "2020-09-08T17:55:58Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/downloader/Downloader.java", "diffHunk": "@@ -385,38 +389,34 @@ private void verifySigsAndDownloadDataFiles(Multimap<String, FileStreamSignature\n                 }\n \n                 try {\n-                    File signedDataFile = downloadSignedDataFile(signature.getFile(), signature.getNode());\n+                    File signedDataFile = downloadSignedDataFile(signature.getFile(), signature.getNodeAccountIdString());\n                     if (signedDataFile == null) {\n                         continue;\n                     }\n \n-                    if (verifyDataFile(signedDataFile, signature.getHash())) {\n-                        if (Utility.isStreamFileAfterInstant(sigFilename, endDate)) {\n-                            downloaderProperties.setEnabled(false);\n-                            log.warn(\"Disabled polling after downloading all files <= endDate ({})\", endDate);\n-                            return;\n-                        }\n+                    StreamFile streamFile = readAndVerifyStreamFile(signedDataFile, signature.getHashAsHex());\n+                    streamFile.setNodeAccountId(signature.getNodeAccountId());\n \n-                        // move the file to the valid directory\n-                        File destination = validPath.resolve(signedDataFile.getName()).toFile();\n-                        if (moveFile(signedDataFile, destination)) {\n-                            if (lastValidDownloadedFileHashKey != null) {\n-                                applicationStatusRepository.updateStatusValue(lastValidDownloadedFileHashKey,\n-                                        signature.getHashAsHex());\n-                            }\n-                            applicationStatusRepository\n-                                    .updateStatusValue(lastValidDownloadedFileKey, destination.getName());\n-                            valid = true;\n-                            signatures.forEach(this::moveSignatureFile);\n-                            break;\n-                        }\n-                    } else {\n-                        log.warn(\"Verification of data file {} from node {} failed. Will retry another node\",\n-                                signedDataFile.getName(), signature.getNode());\n+                    if (Utility.isStreamFileAfterInstant(sigFilename, endDate)) {\n+                        downloaderProperties.setEnabled(false);\n+                        log.warn(\"Disabled polling after downloading all files <= endDate ({})\", endDate);\n+                        return;\n                     }\n+\n+                    // move the file to the valid directory\n+                    File destination = validPath.resolve(signedDataFile.getName()).toFile();\n+                    moveFile(signedDataFile, destination);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2109d887aa7b2d42e10f16f0ada5d4430e623d61"}, "originalPosition": 229}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjY2MjgyOA==", "bodyText": "moveFile is now called inside transactionTemplate's callback", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r486662828", "createdAt": "2020-09-10T22:14:01Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/downloader/Downloader.java", "diffHunk": "@@ -385,38 +389,34 @@ private void verifySigsAndDownloadDataFiles(Multimap<String, FileStreamSignature\n                 }\n \n                 try {\n-                    File signedDataFile = downloadSignedDataFile(signature.getFile(), signature.getNode());\n+                    File signedDataFile = downloadSignedDataFile(signature.getFile(), signature.getNodeAccountIdString());\n                     if (signedDataFile == null) {\n                         continue;\n                     }\n \n-                    if (verifyDataFile(signedDataFile, signature.getHash())) {\n-                        if (Utility.isStreamFileAfterInstant(sigFilename, endDate)) {\n-                            downloaderProperties.setEnabled(false);\n-                            log.warn(\"Disabled polling after downloading all files <= endDate ({})\", endDate);\n-                            return;\n-                        }\n+                    StreamFile streamFile = readAndVerifyStreamFile(signedDataFile, signature.getHashAsHex());\n+                    streamFile.setNodeAccountId(signature.getNodeAccountId());\n \n-                        // move the file to the valid directory\n-                        File destination = validPath.resolve(signedDataFile.getName()).toFile();\n-                        if (moveFile(signedDataFile, destination)) {\n-                            if (lastValidDownloadedFileHashKey != null) {\n-                                applicationStatusRepository.updateStatusValue(lastValidDownloadedFileHashKey,\n-                                        signature.getHashAsHex());\n-                            }\n-                            applicationStatusRepository\n-                                    .updateStatusValue(lastValidDownloadedFileKey, destination.getName());\n-                            valid = true;\n-                            signatures.forEach(this::moveSignatureFile);\n-                            break;\n-                        }\n-                    } else {\n-                        log.warn(\"Verification of data file {} from node {} failed. Will retry another node\",\n-                                signedDataFile.getName(), signature.getNode());\n+                    if (Utility.isStreamFileAfterInstant(sigFilename, endDate)) {\n+                        downloaderProperties.setEnabled(false);\n+                        log.warn(\"Disabled polling after downloading all files <= endDate ({})\", endDate);\n+                        return;\n                     }\n+\n+                    // move the file to the valid directory\n+                    File destination = validPath.resolve(signedDataFile.getName()).toFile();\n+                    moveFile(signedDataFile, destination);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA5ODQ3Nw=="}, "originalCommit": {"oid": "2109d887aa7b2d42e10f16f0ada5d4430e623d61"}, "originalPosition": 229}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAzNDEyNTE2OnYy", "diffSide": "RIGHT", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/downloader/Downloader.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxNzo1OTo1MlrOHOoLzg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQyMjoxNDoxOVrOHQHjJw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTEwMDQ5NA==", "bodyText": "This is a change in behavior as it won't try another node now. We shouldn't catch and rollback here manually. Let TransactionTemplate automatically rollback on exception and let the exception bubble up so it can retry the next node.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r485100494", "createdAt": "2020-09-08T17:59:52Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/downloader/Downloader.java", "diffHunk": "@@ -451,7 +451,50 @@ private File downloadSignedDataFile(File sigFile, String nodeAccountId) {\n         return null;\n     }\n \n-    protected abstract boolean verifyDataFile(File file, byte[] signedHash);\n+    private StreamFile readAndVerifyStreamFile(File file, String verifiedHash) {\n+        String fileName = file.getName();\n+        StreamFile streamFile = readStreamFile(file);\n+\n+        if (lastValidDownloadedFileHashKey != null) {\n+            String expectedPrevFileHash = applicationStatusRepository.findByStatusCode(lastValidDownloadedFileHashKey);\n+            Instant verifyHashAfter = downloaderProperties.getMirrorProperties().getVerifyHashAfter();\n+            if (!verifyHashChain(streamFile.getPreviousHash(), expectedPrevFileHash, verifyHashAfter, fileName)) {\n+                throw new HashMismatchException(fileName, expectedPrevFileHash, streamFile.getPreviousHash());\n+            }\n+        }\n+\n+        if (!streamFile.getFileHash().contentEquals(verifiedHash)) {\n+            throw new HashMismatchException(fileName, verifiedHash, streamFile.getFileHash());\n+        }\n+\n+        return streamFile;\n+    }\n+\n+    /**\n+     * Updates last valid downloaded file and last valid downloaded file hash key in database if applicable. Also saves\n+     * the stream file to its corresponding database table.\n+     * @param streamFile the verified stream file\n+     */\n+    private void updateApplicationStatus(StreamFile streamFile) {\n+        transactionTemplate.executeWithoutResult(status -> {\n+            try {\n+                if (lastValidDownloadedFileHashKey != null) {\n+                    applicationStatusRepository\n+                            .updateStatusValue(lastValidDownloadedFileHashKey, streamFile.getFileHash());\n+                }\n+                applicationStatusRepository.updateStatusValue(lastValidDownloadedFileKey, streamFile.getName());\n+\n+                saveStreamFileRecord(streamFile);\n+            } catch (Exception ex) {\n+                log.error(\"Roll back the transaction due to error\", ex);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2109d887aa7b2d42e10f16f0ada5d4430e623d61"}, "originalPosition": 285}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjUwNjMwOA==", "bodyText": "The catch and log here is intended to log the original exception so we have the complete stack trace. I'll run it manually to see if it's not needed and the TransactionException thrown by TransactionTemplate has all info.\nThe logic here does not change the behavior because the setRollBackOnly call will cause transactionTemplate to throw TransactionException.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r486506308", "createdAt": "2020-09-10T17:16:27Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/downloader/Downloader.java", "diffHunk": "@@ -451,7 +451,50 @@ private File downloadSignedDataFile(File sigFile, String nodeAccountId) {\n         return null;\n     }\n \n-    protected abstract boolean verifyDataFile(File file, byte[] signedHash);\n+    private StreamFile readAndVerifyStreamFile(File file, String verifiedHash) {\n+        String fileName = file.getName();\n+        StreamFile streamFile = readStreamFile(file);\n+\n+        if (lastValidDownloadedFileHashKey != null) {\n+            String expectedPrevFileHash = applicationStatusRepository.findByStatusCode(lastValidDownloadedFileHashKey);\n+            Instant verifyHashAfter = downloaderProperties.getMirrorProperties().getVerifyHashAfter();\n+            if (!verifyHashChain(streamFile.getPreviousHash(), expectedPrevFileHash, verifyHashAfter, fileName)) {\n+                throw new HashMismatchException(fileName, expectedPrevFileHash, streamFile.getPreviousHash());\n+            }\n+        }\n+\n+        if (!streamFile.getFileHash().contentEquals(verifiedHash)) {\n+            throw new HashMismatchException(fileName, verifiedHash, streamFile.getFileHash());\n+        }\n+\n+        return streamFile;\n+    }\n+\n+    /**\n+     * Updates last valid downloaded file and last valid downloaded file hash key in database if applicable. Also saves\n+     * the stream file to its corresponding database table.\n+     * @param streamFile the verified stream file\n+     */\n+    private void updateApplicationStatus(StreamFile streamFile) {\n+        transactionTemplate.executeWithoutResult(status -> {\n+            try {\n+                if (lastValidDownloadedFileHashKey != null) {\n+                    applicationStatusRepository\n+                            .updateStatusValue(lastValidDownloadedFileHashKey, streamFile.getFileHash());\n+                }\n+                applicationStatusRepository.updateStatusValue(lastValidDownloadedFileKey, streamFile.getName());\n+\n+                saveStreamFileRecord(streamFile);\n+            } catch (Exception ex) {\n+                log.error(\"Roll back the transaction due to error\", ex);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTEwMDQ5NA=="}, "originalCommit": {"oid": "2109d887aa7b2d42e10f16f0ada5d4430e623d61"}, "originalPosition": 285}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjY2Mjk1MQ==", "bodyText": "removed the catch and log", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r486662951", "createdAt": "2020-09-10T22:14:19Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/downloader/Downloader.java", "diffHunk": "@@ -451,7 +451,50 @@ private File downloadSignedDataFile(File sigFile, String nodeAccountId) {\n         return null;\n     }\n \n-    protected abstract boolean verifyDataFile(File file, byte[] signedHash);\n+    private StreamFile readAndVerifyStreamFile(File file, String verifiedHash) {\n+        String fileName = file.getName();\n+        StreamFile streamFile = readStreamFile(file);\n+\n+        if (lastValidDownloadedFileHashKey != null) {\n+            String expectedPrevFileHash = applicationStatusRepository.findByStatusCode(lastValidDownloadedFileHashKey);\n+            Instant verifyHashAfter = downloaderProperties.getMirrorProperties().getVerifyHashAfter();\n+            if (!verifyHashChain(streamFile.getPreviousHash(), expectedPrevFileHash, verifyHashAfter, fileName)) {\n+                throw new HashMismatchException(fileName, expectedPrevFileHash, streamFile.getPreviousHash());\n+            }\n+        }\n+\n+        if (!streamFile.getFileHash().contentEquals(verifiedHash)) {\n+            throw new HashMismatchException(fileName, verifiedHash, streamFile.getFileHash());\n+        }\n+\n+        return streamFile;\n+    }\n+\n+    /**\n+     * Updates last valid downloaded file and last valid downloaded file hash key in database if applicable. Also saves\n+     * the stream file to its corresponding database table.\n+     * @param streamFile the verified stream file\n+     */\n+    private void updateApplicationStatus(StreamFile streamFile) {\n+        transactionTemplate.executeWithoutResult(status -> {\n+            try {\n+                if (lastValidDownloadedFileHashKey != null) {\n+                    applicationStatusRepository\n+                            .updateStatusValue(lastValidDownloadedFileHashKey, streamFile.getFileHash());\n+                }\n+                applicationStatusRepository.updateStatusValue(lastValidDownloadedFileKey, streamFile.getName());\n+\n+                saveStreamFileRecord(streamFile);\n+            } catch (Exception ex) {\n+                log.error(\"Roll back the transaction due to error\", ex);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTEwMDQ5NA=="}, "originalCommit": {"oid": "2109d887aa7b2d42e10f16f0ada5d4430e623d61"}, "originalPosition": 285}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA0NDAzNjU0OnYy", "diffSide": "RIGHT", "path": "hedera-mirror-importer/src/test/resources/db/scripts/cleanup_V1.28.1.sql", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQyMTo0MDoxNFrOHQGtFw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQyMTo0MDoxNFrOHQGtFw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjY0OTExMQ==", "bodyText": "moved the sql file from main resources to test resources since it's only needed by the java migration test file", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r486649111", "createdAt": "2020-09-10T21:40:14Z", "author": {"login": "xin-hedera"}, "path": "hedera-mirror-importer/src/test/resources/db/scripts/cleanup_V1.28.1.sql", "diffHunk": "@@ -0,0 +1,15 @@\n+TRUNCATE TABLE account_balance_sets RESTART IDENTITY CASCADE;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fc9b13b8385c5d7b802f2bc7e4c746bc134ac104"}, "originalPosition": 1}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA0NDI2NjY5OnYy", "diffSide": "RIGHT", "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/balance/AccountBalancesFileLoader.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQyMzoxNToyMFrOHQI13Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQyMzoxNToyMFrOHQI13Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjY4NDEyNQ==", "bodyText": "Looks like insertAccountBalanceSet is conditional but updateAccountBalanceSet is unconditional. Latter should probably be inside if statement.", "url": "https://github.com/hashgraph/hedera-mirror-node/pull/1009#discussion_r486684125", "createdAt": "2020-09-10T23:15:20Z", "author": {"login": "steven-sheehy"}, "path": "hedera-mirror-importer/src/main/java/com/hedera/mirror/importer/parser/balance/AccountBalancesFileLoader.java", "diffHunk": "@@ -110,101 +127,95 @@ public boolean loadAccountBalances(@NonNull File balanceFile, DateRangeFilter da\n                     consensusTimestamp = accountBalance.getId().getConsensusTimestamp();\n                     if (timestampFromFileName != consensusTimestamp) {\n                         // The assumption is that the dataset has been validated via signatures and running hashes,\n-                        // so it is\n-                        // the \"next\" dataset, and the consensus timestamp in it is correct.\n-                        // The fact that the filename timestamp and timestamp in the file differ should still be\n-                        // investigated.\n-                        log.error(\"Account balance dataset timestamp mismatch! Processing can continue, but this must\" +\n-                                        \" be \" +\n-                                        \"investigated! Dataset {} internal timestamp {} filename timestamp {}.\",\n+                        // so it is the \"next\" dataset, and the consensus timestamp in it is correct. The fact that\n+                        // the filename timestamp and timestamp in the file differ should still be investigated.\n+                        log.error(\"Account balance dataset timestamp mismatch! Processing can continue, but this \" +\n+                                        \"must be investigated! Dataset {} internal timestamp {} filename timestamp {}.\",\n                                 fileName, consensusTimestamp, timestampFromFileName);\n                     }\n \n                     if (dateRangeFilter != null && !dateRangeFilter.filter(consensusTimestamp)) {\n                         log.warn(\"Account balances file {} not in configured date range {}, skip it\",\n                                 fileName, dateRangeFilter);\n-                        complete = true;\n-                        break;\n+                        skip = true;\n+                    } else {\n+                        insertAccountBalanceSet(insertSetStatement, consensusTimestamp);\n                     }\n-\n-                    insertAccountBalanceSet(insertSetStatement, consensusTimestamp);\n                 }\n \n                 validCount++;\n-                accountBalanceList.add(accountBalance);\n-                insertedCount += tryInsertBatchAccountBalance(insertBalanceStatement, accountBalanceList,\n-                        insertBatchSize);\n+\n+                if (!skip) {\n+                    accountBalanceList.add(accountBalance);\n+                    tryInsertBatchAccountBalance(insertBalanceStatement, accountBalanceList, insertBatchSize);\n+                }\n             }\n \n-            insertedCount += tryInsertBatchAccountBalance(insertBalanceStatement, accountBalanceList, 1);\n-            complete = (insertedCount == validCount);\n-            updateAccountBalanceSet(updateSetStatement, complete, consensusTimestamp);\n-        } catch (InvalidDatasetException | SQLException ex) {\n-            log.error(\"Failed to load account balances file \" + fileName, ex);\n-        }\n+            if (!skip) {\n+                tryInsertBatchAccountBalance(insertBalanceStatement, accountBalanceList, 1);\n+            }\n+            updateAccountBalanceSet(updateSetStatement, consensusTimestamp);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f409a3265f933197ecb1a02f0cea405eb5649265"}, "originalPosition": 144}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1612, "cost": 1, "resetAt": "2021-11-12T20:28:25Z"}}}