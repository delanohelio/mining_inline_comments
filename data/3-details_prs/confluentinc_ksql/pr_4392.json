{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzY3NjY2NTcz", "number": 4392, "title": "feat: Adds lag reporting and API for use in lag aware routing as described in KLIP 12", "bodyText": "Description\nThis creates a Service which sends state store changelog topic lags retrieved from KafkaStreams to all of the nodes in the cluster.  It also has an API which can be used by pull request logic for making routing decisions.\nTesting done\nAdded unit tests for LagReportingAgent which tests APIs.  Also added a functional test LagReportingAgentFunctionalTest which actually sets up a two node cluster, sends lags, and verifies those reported with those read directly from Kafka.\nWill also do additional manual testing according to this document: #4360\nReviewer checklist\n\n Ensure docs are updated if necessary. (eg. if a user visible feature is being added or changed).\n Ensure relevant issues are linked (description should include text like \"Fixes #\")", "createdAt": "2020-01-27T19:36:52Z", "url": "https://github.com/confluentinc/ksql/pull/4392", "merged": true, "mergeCommit": {"oid": "cb9ae2922323a663db629be1f0ee717be03ed347"}, "closed": true, "closedAt": "2020-01-30T02:08:05Z", "author": {"login": "AlanConfluent"}, "timelineItems": {"totalCount": 24, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABb-1S_sgFqTM0OTUyMDUzMg==", "endCursor": "Y3Vyc29yOnYyOpPPAAABb_QAHfAH2gAyMzY3NjY2NTczOjYyMDFkMTRkMjczYjExNTI3YzZhOGIwODk3MzhmYTc4NWU1MmE3NTI=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ5NTIwNTMy", "url": "https://github.com/confluentinc/ksql/pull/4392#pullrequestreview-349520532", "createdAt": "2020-01-28T16:31:14Z", "commit": {"oid": "d3e4f951c670028b925593aa13f654440e50ae3f"}, "state": "APPROVED", "comments": {"totalCount": 13, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOFQxNjozMToxNFrOFir3Qw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOFQxODowMTo0MVrOFiu_KA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTkxNDU2Mw==", "bodyText": "I think I had the same comment on Vicky's PR, but I feel like we should avoid exposing the KafkaStreams object here as that's an \"implementation detail\" of the query metadata. If we want to expose specific parts of the metadata, we should do it through strongly typed methods (like the getAllMetadata method below)\nThis will also make this object much easier to mock and test.", "url": "https://github.com/confluentinc/ksql/pull/4392#discussion_r371914563", "createdAt": "2020-01-28T16:31:14Z", "author": {"login": "agavra"}, "path": "ksql-engine/src/main/java/io/confluent/ksql/util/QueryMetadata.java", "diffHunk": "@@ -132,6 +132,10 @@ public Topology getTopology() {\n     return topology;\n   }\n \n+  public KafkaStreams getKafkaStreams() {\n+    return kafkaStreams;\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3e4f951c670028b925593aa13f654440e50ae3f"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTkxODUzMA==", "bodyText": "nit: I want to say that the right implementation is to leverage Map#replaceAll(BiFunction<K,V>) so that we avoid the pattern of iterating and updating keys in the map simultaneously (at least at an API level, I understand the keys aren't actually changing). Also would be nice to have a HostStatusEntity#copyWithStatus(boolean isAlive) to make this code a little crisper", "url": "https://github.com/confluentinc/ksql/pull/4392#discussion_r371918530", "createdAt": "2020-01-28T16:37:24Z", "author": {"login": "agavra"}, "path": "ksql-rest-app/src/main/java/io/confluent/ksql/rest/server/HeartbeatAgent.java", "diffHunk": "@@ -237,19 +241,25 @@ private void processHeartbeats(final long windowStart, final long windowEnd) {\n       if (receivedHeartbeats.isEmpty()) {\n         hostsStatus.forEach((host, status) -> {\n           if (!host.equals(localHostString)) {\n-            status.setHostAlive(false);\n+            hostsStatus.put(host, new HostStatusEntity(status.getHostInfoEntity(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3e4f951c670028b925593aa13f654440e50ae3f"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTkyMDU4Mw==", "bodyText": "same comment as above (and one more time below), but to make life easier we could just use computeIfPresent to make it clear that the key isn't changing", "url": "https://github.com/confluentinc/ksql/pull/4392#discussion_r371920583", "createdAt": "2020-01-28T16:40:42Z", "author": {"login": "agavra"}, "path": "ksql-rest-app/src/main/java/io/confluent/ksql/rest/server/HeartbeatAgent.java", "diffHunk": "@@ -237,19 +241,25 @@ private void processHeartbeats(final long windowStart, final long windowEnd) {\n       if (receivedHeartbeats.isEmpty()) {\n         hostsStatus.forEach((host, status) -> {\n           if (!host.equals(localHostString)) {\n-            status.setHostAlive(false);\n+            hostsStatus.put(host, new HostStatusEntity(status.getHostInfoEntity(),\n+                                                       false,\n+                                                       status.getLastStatusUpdateMs()));\n           }\n         });\n       }\n \n-      for (String host: hostsStatus.keySet()) {\n+      for (Entry<String, HostStatusEntity> entry: hostsStatus.entrySet()) {\n+        final String host = entry.getKey();\n+        final HostStatusEntity status = entry.getValue();\n         if (host.equals(localHostString)) {\n           continue;\n         }\n         final TreeMap<Long, HeartbeatInfo> heartbeats = receivedHeartbeats.get(host);\n         //For previously discovered hosts, if they have not received any heartbeats, mark them dead\n         if (heartbeats == null || heartbeats.isEmpty()) {\n-          hostsStatus.get(host).setHostAlive(false);\n+          hostsStatus.put(host, new HostStatusEntity(status.getHostInfoEntity(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3e4f951c670028b925593aa13f654440e50ae3f"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTkzMTYzMg==", "bodyText": "nit: if we just have one service, I don't think we need to add a service manager - but if you are thinking of adding more in the future we can leave it as is", "url": "https://github.com/confluentinc/ksql/pull/4392#discussion_r371931632", "createdAt": "2020-01-28T16:58:36Z", "author": {"login": "agavra"}, "path": "ksql-rest-app/src/main/java/io/confluent/ksql/rest/server/LagReportingAgent.java", "diffHunk": "@@ -0,0 +1,394 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.server;\n+\n+import static java.util.Objects.requireNonNull;\n+\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+import com.google.common.util.concurrent.AbstractScheduledService;\n+import com.google.common.util.concurrent.ServiceManager;\n+import io.confluent.ksql.engine.KsqlEngine;\n+import io.confluent.ksql.rest.entity.HostInfoEntity;\n+import io.confluent.ksql.rest.entity.HostStatusEntity;\n+import io.confluent.ksql.rest.entity.LagInfoEntity;\n+import io.confluent.ksql.rest.entity.LagReportingRequest;\n+import io.confluent.ksql.rest.entity.QueryStateStoreId;\n+import io.confluent.ksql.rest.server.HeartbeatAgent.HostStatusListener;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.util.Pair;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.net.URI;\n+import java.net.URL;\n+import java.time.Clock;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Map.Entry;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.streams.LagInfo;\n+import org.apache.kafka.streams.errors.StreamsException;\n+import org.apache.kafka.streams.state.HostInfo;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Agent responsible for sending and receiving lag information across the cluster and providing\n+ * aggregate stats, usable during query time.\n+ */\n+public final class LagReportingAgent implements HostStatusListener {\n+  private static final int SERVICE_TIMEOUT_SEC = 2;\n+  private static final int NUM_THREADS_EXECUTOR = 1;\n+  private static final int SEND_LAG_DELAY_MS = 100;\n+  private static final HostLagInfo EMPTY_HOST_LAG_INFO = new HostLagInfo(Collections.emptyMap(), 0);\n+  private static final Logger LOG = LoggerFactory.getLogger(LagReportingAgent.class);\n+\n+  private final KsqlEngine engine;\n+  private final ScheduledExecutorService scheduledExecutorService;\n+  private final ServiceContext serviceContext;\n+  private final LagReportingConfig config;\n+  private final ServiceManager serviceManager;\n+  private final Clock clock;\n+\n+  private final Map<HostInfo, HostLagInfo> receivedLagInfo;\n+  private final AtomicReference<Set<HostInfo>> aliveHostsRef;\n+\n+  private URL localURL;\n+\n+  /**\n+   * Builder for creating an instance of LagReportingAgent.\n+   * @return\n+   */\n+  public static LagReportingAgent.Builder builder() {\n+    return new LagReportingAgent.Builder();\n+  }\n+\n+  /**\n+   * Lag related agent for both sending out lag for localhost as well as receiving lag reports for\n+   * other nodes in the cluster.\n+   * @param engine The ksql engine to access streams for inferring the cluster and getting local\n+   *               lags metrics\n+   * @param serviceContext Service context for issuing ksql requests\n+   * @param config The LagReportingConfig for configuring this agent\n+   * @param clock Clock for reporting lag\n+   */\n+  private LagReportingAgent(\n+      final KsqlEngine engine,\n+      final ScheduledExecutorService scheduledExecutorService,\n+      final ServiceContext serviceContext,\n+      final LagReportingConfig config,\n+      final Clock clock) {\n+    this.engine = requireNonNull(engine, \"engine\");\n+    this.scheduledExecutorService = scheduledExecutorService;\n+    this.serviceContext = requireNonNull(serviceContext, \"serviceContext\");\n+    this.config = requireNonNull(config, \"configuration parameters\");\n+    this.clock = clock;\n+    this.serviceManager = new ServiceManager(Arrays.asList(new SendLagService()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3e4f951c670028b925593aa13f654440e50ae3f"}, "originalPosition": 109}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTkzNDIyNg==", "bodyText": "I feel like we should rename LagReportingRequest to LagReportingMessage or LagReportingEvent. In my mind, a LagReportingRequest would get a response that contains the lag info. Please correct my if I'm not understanding some terminology (or what's going on \ud83d\ude04)", "url": "https://github.com/confluentinc/ksql/pull/4392#discussion_r371934226", "createdAt": "2020-01-28T17:03:03Z", "author": {"login": "agavra"}, "path": "ksql-rest-app/src/main/java/io/confluent/ksql/rest/server/LagReportingAgent.java", "diffHunk": "@@ -0,0 +1,394 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.server;\n+\n+import static java.util.Objects.requireNonNull;\n+\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+import com.google.common.util.concurrent.AbstractScheduledService;\n+import com.google.common.util.concurrent.ServiceManager;\n+import io.confluent.ksql.engine.KsqlEngine;\n+import io.confluent.ksql.rest.entity.HostInfoEntity;\n+import io.confluent.ksql.rest.entity.HostStatusEntity;\n+import io.confluent.ksql.rest.entity.LagInfoEntity;\n+import io.confluent.ksql.rest.entity.LagReportingRequest;\n+import io.confluent.ksql.rest.entity.QueryStateStoreId;\n+import io.confluent.ksql.rest.server.HeartbeatAgent.HostStatusListener;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.util.Pair;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.net.URI;\n+import java.net.URL;\n+import java.time.Clock;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Map.Entry;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.streams.LagInfo;\n+import org.apache.kafka.streams.errors.StreamsException;\n+import org.apache.kafka.streams.state.HostInfo;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Agent responsible for sending and receiving lag information across the cluster and providing\n+ * aggregate stats, usable during query time.\n+ */\n+public final class LagReportingAgent implements HostStatusListener {\n+  private static final int SERVICE_TIMEOUT_SEC = 2;\n+  private static final int NUM_THREADS_EXECUTOR = 1;\n+  private static final int SEND_LAG_DELAY_MS = 100;\n+  private static final HostLagInfo EMPTY_HOST_LAG_INFO = new HostLagInfo(Collections.emptyMap(), 0);\n+  private static final Logger LOG = LoggerFactory.getLogger(LagReportingAgent.class);\n+\n+  private final KsqlEngine engine;\n+  private final ScheduledExecutorService scheduledExecutorService;\n+  private final ServiceContext serviceContext;\n+  private final LagReportingConfig config;\n+  private final ServiceManager serviceManager;\n+  private final Clock clock;\n+\n+  private final Map<HostInfo, HostLagInfo> receivedLagInfo;\n+  private final AtomicReference<Set<HostInfo>> aliveHostsRef;\n+\n+  private URL localURL;\n+\n+  /**\n+   * Builder for creating an instance of LagReportingAgent.\n+   * @return\n+   */\n+  public static LagReportingAgent.Builder builder() {\n+    return new LagReportingAgent.Builder();\n+  }\n+\n+  /**\n+   * Lag related agent for both sending out lag for localhost as well as receiving lag reports for\n+   * other nodes in the cluster.\n+   * @param engine The ksql engine to access streams for inferring the cluster and getting local\n+   *               lags metrics\n+   * @param serviceContext Service context for issuing ksql requests\n+   * @param config The LagReportingConfig for configuring this agent\n+   * @param clock Clock for reporting lag\n+   */\n+  private LagReportingAgent(\n+      final KsqlEngine engine,\n+      final ScheduledExecutorService scheduledExecutorService,\n+      final ServiceContext serviceContext,\n+      final LagReportingConfig config,\n+      final Clock clock) {\n+    this.engine = requireNonNull(engine, \"engine\");\n+    this.scheduledExecutorService = scheduledExecutorService;\n+    this.serviceContext = requireNonNull(serviceContext, \"serviceContext\");\n+    this.config = requireNonNull(config, \"configuration parameters\");\n+    this.clock = clock;\n+    this.serviceManager = new ServiceManager(Arrays.asList(new SendLagService()));\n+    this.receivedLagInfo = new ConcurrentHashMap<>();\n+    this.aliveHostsRef = new AtomicReference<>(Collections.emptySet());\n+  }\n+\n+  void setLocalAddress(final String applicationServer) {\n+    try {\n+      this.localURL = new URL(applicationServer);\n+    } catch (final Exception e) {\n+      throw new IllegalStateException(\"Failed to convert remote host info to URL.\"\n+          + \" remoteInfo: \" + applicationServer);\n+    }\n+  }\n+\n+  void startAgent() {\n+    try {\n+      serviceManager.startAsync().awaitHealthy(SERVICE_TIMEOUT_SEC, TimeUnit.SECONDS);\n+    } catch (TimeoutException | IllegalStateException e) {\n+      LOG.error(\"Failed to start heartbeat services with exception \" + e.getMessage(), e);\n+    }\n+  }\n+\n+  void stopAgent() {\n+    try {\n+      serviceManager.stopAsync().awaitStopped(SERVICE_TIMEOUT_SEC, TimeUnit.SECONDS);\n+    } catch (TimeoutException | IllegalStateException e) {\n+      LOG.error(\"Failed to stop heartbeat services with exception \" + e.getMessage(), e);\n+    } finally {\n+      scheduledExecutorService.shutdownNow();\n+    }\n+  }\n+\n+  /**\n+   * Stores the host lag received from a remote Ksql server.\n+   * @param lagReportingRequest The host lag information sent directly from the other node.\n+   */\n+  public void receiveHostLag(final LagReportingRequest lagReportingRequest) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3e4f951c670028b925593aa13f654440e50ae3f"}, "originalPosition": 145}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTk0MDMxMQ==", "bodyText": "does this loop just turn the lagReportingRequest.getStoreToPartitionToLagMap into an immutable map? if so, could we just:\nlagReportingRequest\n    .getStoreToPartitionToLagMap\n    .forEach((id, partitions) -> hostMapBuilder.put(id, ImmutableMap.copyOf(partitions));", "url": "https://github.com/confluentinc/ksql/pull/4392#discussion_r371940311", "createdAt": "2020-01-28T17:13:26Z", "author": {"login": "agavra"}, "path": "ksql-rest-app/src/main/java/io/confluent/ksql/rest/server/LagReportingAgent.java", "diffHunk": "@@ -0,0 +1,394 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.server;\n+\n+import static java.util.Objects.requireNonNull;\n+\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+import com.google.common.util.concurrent.AbstractScheduledService;\n+import com.google.common.util.concurrent.ServiceManager;\n+import io.confluent.ksql.engine.KsqlEngine;\n+import io.confluent.ksql.rest.entity.HostInfoEntity;\n+import io.confluent.ksql.rest.entity.HostStatusEntity;\n+import io.confluent.ksql.rest.entity.LagInfoEntity;\n+import io.confluent.ksql.rest.entity.LagReportingRequest;\n+import io.confluent.ksql.rest.entity.QueryStateStoreId;\n+import io.confluent.ksql.rest.server.HeartbeatAgent.HostStatusListener;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.util.Pair;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.net.URI;\n+import java.net.URL;\n+import java.time.Clock;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Map.Entry;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.streams.LagInfo;\n+import org.apache.kafka.streams.errors.StreamsException;\n+import org.apache.kafka.streams.state.HostInfo;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Agent responsible for sending and receiving lag information across the cluster and providing\n+ * aggregate stats, usable during query time.\n+ */\n+public final class LagReportingAgent implements HostStatusListener {\n+  private static final int SERVICE_TIMEOUT_SEC = 2;\n+  private static final int NUM_THREADS_EXECUTOR = 1;\n+  private static final int SEND_LAG_DELAY_MS = 100;\n+  private static final HostLagInfo EMPTY_HOST_LAG_INFO = new HostLagInfo(Collections.emptyMap(), 0);\n+  private static final Logger LOG = LoggerFactory.getLogger(LagReportingAgent.class);\n+\n+  private final KsqlEngine engine;\n+  private final ScheduledExecutorService scheduledExecutorService;\n+  private final ServiceContext serviceContext;\n+  private final LagReportingConfig config;\n+  private final ServiceManager serviceManager;\n+  private final Clock clock;\n+\n+  private final Map<HostInfo, HostLagInfo> receivedLagInfo;\n+  private final AtomicReference<Set<HostInfo>> aliveHostsRef;\n+\n+  private URL localURL;\n+\n+  /**\n+   * Builder for creating an instance of LagReportingAgent.\n+   * @return\n+   */\n+  public static LagReportingAgent.Builder builder() {\n+    return new LagReportingAgent.Builder();\n+  }\n+\n+  /**\n+   * Lag related agent for both sending out lag for localhost as well as receiving lag reports for\n+   * other nodes in the cluster.\n+   * @param engine The ksql engine to access streams for inferring the cluster and getting local\n+   *               lags metrics\n+   * @param serviceContext Service context for issuing ksql requests\n+   * @param config The LagReportingConfig for configuring this agent\n+   * @param clock Clock for reporting lag\n+   */\n+  private LagReportingAgent(\n+      final KsqlEngine engine,\n+      final ScheduledExecutorService scheduledExecutorService,\n+      final ServiceContext serviceContext,\n+      final LagReportingConfig config,\n+      final Clock clock) {\n+    this.engine = requireNonNull(engine, \"engine\");\n+    this.scheduledExecutorService = scheduledExecutorService;\n+    this.serviceContext = requireNonNull(serviceContext, \"serviceContext\");\n+    this.config = requireNonNull(config, \"configuration parameters\");\n+    this.clock = clock;\n+    this.serviceManager = new ServiceManager(Arrays.asList(new SendLagService()));\n+    this.receivedLagInfo = new ConcurrentHashMap<>();\n+    this.aliveHostsRef = new AtomicReference<>(Collections.emptySet());\n+  }\n+\n+  void setLocalAddress(final String applicationServer) {\n+    try {\n+      this.localURL = new URL(applicationServer);\n+    } catch (final Exception e) {\n+      throw new IllegalStateException(\"Failed to convert remote host info to URL.\"\n+          + \" remoteInfo: \" + applicationServer);\n+    }\n+  }\n+\n+  void startAgent() {\n+    try {\n+      serviceManager.startAsync().awaitHealthy(SERVICE_TIMEOUT_SEC, TimeUnit.SECONDS);\n+    } catch (TimeoutException | IllegalStateException e) {\n+      LOG.error(\"Failed to start heartbeat services with exception \" + e.getMessage(), e);\n+    }\n+  }\n+\n+  void stopAgent() {\n+    try {\n+      serviceManager.stopAsync().awaitStopped(SERVICE_TIMEOUT_SEC, TimeUnit.SECONDS);\n+    } catch (TimeoutException | IllegalStateException e) {\n+      LOG.error(\"Failed to stop heartbeat services with exception \" + e.getMessage(), e);\n+    } finally {\n+      scheduledExecutorService.shutdownNow();\n+    }\n+  }\n+\n+  /**\n+   * Stores the host lag received from a remote Ksql server.\n+   * @param lagReportingRequest The host lag information sent directly from the other node.\n+   */\n+  public void receiveHostLag(final LagReportingRequest lagReportingRequest) {\n+    final long updateTimeMs = lagReportingRequest.getLastLagUpdateMs();\n+    final HostInfoEntity hostInfoEntity = lagReportingRequest.getHostInfo();\n+    final HostInfo hostInfo = new HostInfo(hostInfoEntity.getHost(), hostInfoEntity.getPort());\n+\n+    ImmutableMap.Builder<QueryStateStoreId, Map<Integer, LagInfoEntity>> hostMapBuilder\n+        = ImmutableMap.builder();\n+    for (Map.Entry<QueryStateStoreId, Map<Integer, LagInfoEntity>> storeEntry", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3e4f951c670028b925593aa13f654440e50ae3f"}, "originalPosition": 152}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTk0NjkxMg==", "bodyText": "thoughts on adding some logging here to indicate current lags? might be helpful for debugging", "url": "https://github.com/confluentinc/ksql/pull/4392#discussion_r371946912", "createdAt": "2020-01-28T17:25:21Z", "author": {"login": "agavra"}, "path": "ksql-rest-app/src/main/java/io/confluent/ksql/rest/server/LagReportingAgent.java", "diffHunk": "@@ -0,0 +1,394 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.server;\n+\n+import static java.util.Objects.requireNonNull;\n+\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+import com.google.common.util.concurrent.AbstractScheduledService;\n+import com.google.common.util.concurrent.ServiceManager;\n+import io.confluent.ksql.engine.KsqlEngine;\n+import io.confluent.ksql.rest.entity.HostInfoEntity;\n+import io.confluent.ksql.rest.entity.HostStatusEntity;\n+import io.confluent.ksql.rest.entity.LagInfoEntity;\n+import io.confluent.ksql.rest.entity.LagReportingRequest;\n+import io.confluent.ksql.rest.entity.QueryStateStoreId;\n+import io.confluent.ksql.rest.server.HeartbeatAgent.HostStatusListener;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.util.Pair;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.net.URI;\n+import java.net.URL;\n+import java.time.Clock;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Map.Entry;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.streams.LagInfo;\n+import org.apache.kafka.streams.errors.StreamsException;\n+import org.apache.kafka.streams.state.HostInfo;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Agent responsible for sending and receiving lag information across the cluster and providing\n+ * aggregate stats, usable during query time.\n+ */\n+public final class LagReportingAgent implements HostStatusListener {\n+  private static final int SERVICE_TIMEOUT_SEC = 2;\n+  private static final int NUM_THREADS_EXECUTOR = 1;\n+  private static final int SEND_LAG_DELAY_MS = 100;\n+  private static final HostLagInfo EMPTY_HOST_LAG_INFO = new HostLagInfo(Collections.emptyMap(), 0);\n+  private static final Logger LOG = LoggerFactory.getLogger(LagReportingAgent.class);\n+\n+  private final KsqlEngine engine;\n+  private final ScheduledExecutorService scheduledExecutorService;\n+  private final ServiceContext serviceContext;\n+  private final LagReportingConfig config;\n+  private final ServiceManager serviceManager;\n+  private final Clock clock;\n+\n+  private final Map<HostInfo, HostLagInfo> receivedLagInfo;\n+  private final AtomicReference<Set<HostInfo>> aliveHostsRef;\n+\n+  private URL localURL;\n+\n+  /**\n+   * Builder for creating an instance of LagReportingAgent.\n+   * @return\n+   */\n+  public static LagReportingAgent.Builder builder() {\n+    return new LagReportingAgent.Builder();\n+  }\n+\n+  /**\n+   * Lag related agent for both sending out lag for localhost as well as receiving lag reports for\n+   * other nodes in the cluster.\n+   * @param engine The ksql engine to access streams for inferring the cluster and getting local\n+   *               lags metrics\n+   * @param serviceContext Service context for issuing ksql requests\n+   * @param config The LagReportingConfig for configuring this agent\n+   * @param clock Clock for reporting lag\n+   */\n+  private LagReportingAgent(\n+      final KsqlEngine engine,\n+      final ScheduledExecutorService scheduledExecutorService,\n+      final ServiceContext serviceContext,\n+      final LagReportingConfig config,\n+      final Clock clock) {\n+    this.engine = requireNonNull(engine, \"engine\");\n+    this.scheduledExecutorService = scheduledExecutorService;\n+    this.serviceContext = requireNonNull(serviceContext, \"serviceContext\");\n+    this.config = requireNonNull(config, \"configuration parameters\");\n+    this.clock = clock;\n+    this.serviceManager = new ServiceManager(Arrays.asList(new SendLagService()));\n+    this.receivedLagInfo = new ConcurrentHashMap<>();\n+    this.aliveHostsRef = new AtomicReference<>(Collections.emptySet());\n+  }\n+\n+  void setLocalAddress(final String applicationServer) {\n+    try {\n+      this.localURL = new URL(applicationServer);\n+    } catch (final Exception e) {\n+      throw new IllegalStateException(\"Failed to convert remote host info to URL.\"\n+          + \" remoteInfo: \" + applicationServer);\n+    }\n+  }\n+\n+  void startAgent() {\n+    try {\n+      serviceManager.startAsync().awaitHealthy(SERVICE_TIMEOUT_SEC, TimeUnit.SECONDS);\n+    } catch (TimeoutException | IllegalStateException e) {\n+      LOG.error(\"Failed to start heartbeat services with exception \" + e.getMessage(), e);\n+    }\n+  }\n+\n+  void stopAgent() {\n+    try {\n+      serviceManager.stopAsync().awaitStopped(SERVICE_TIMEOUT_SEC, TimeUnit.SECONDS);\n+    } catch (TimeoutException | IllegalStateException e) {\n+      LOG.error(\"Failed to stop heartbeat services with exception \" + e.getMessage(), e);\n+    } finally {\n+      scheduledExecutorService.shutdownNow();\n+    }\n+  }\n+\n+  /**\n+   * Stores the host lag received from a remote Ksql server.\n+   * @param lagReportingRequest The host lag information sent directly from the other node.\n+   */\n+  public void receiveHostLag(final LagReportingRequest lagReportingRequest) {\n+    final long updateTimeMs = lagReportingRequest.getLastLagUpdateMs();\n+    final HostInfoEntity hostInfoEntity = lagReportingRequest.getHostInfo();\n+    final HostInfo hostInfo = new HostInfo(hostInfoEntity.getHost(), hostInfoEntity.getPort());\n+\n+    ImmutableMap.Builder<QueryStateStoreId, Map<Integer, LagInfoEntity>> hostMapBuilder\n+        = ImmutableMap.builder();\n+    for (Map.Entry<QueryStateStoreId, Map<Integer, LagInfoEntity>> storeEntry\n+        : lagReportingRequest.getStoreToPartitionToLagMap().entrySet()) {\n+      final QueryStateStoreId queryStateStoreId = storeEntry.getKey();\n+      final Map<Integer, LagInfoEntity> partitionMap = storeEntry.getValue();\n+\n+      ImmutableMap.Builder<Integer, LagInfoEntity> partitionsBuilder = ImmutableMap.builder();\n+\n+      // Go through each new partition and add lag info\n+      for (final Map.Entry<Integer, LagInfoEntity> partitionEntry : partitionMap.entrySet()) {\n+        final Integer partition = partitionEntry.getKey();\n+        final LagInfoEntity lagInfo = partitionEntry.getValue();\n+        partitionsBuilder.put(partition, lagInfo);\n+      }\n+\n+      hostMapBuilder.put(queryStateStoreId, partitionsBuilder.build());\n+    }\n+\n+    Map<QueryStateStoreId, Map<Integer, LagInfoEntity>> hostMap = hostMapBuilder.build();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3e4f951c670028b925593aa13f654440e50ae3f"}, "originalPosition": 169}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTk1MDY5Ng==", "bodyText": "nit: seems like a common pattern. maybe we should have a HostStatuSentity#toHostInfo method", "url": "https://github.com/confluentinc/ksql/pull/4392#discussion_r371950696", "createdAt": "2020-01-28T17:32:26Z", "author": {"login": "agavra"}, "path": "ksql-rest-app/src/main/java/io/confluent/ksql/rest/server/LagReportingAgent.java", "diffHunk": "@@ -0,0 +1,394 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.server;\n+\n+import static java.util.Objects.requireNonNull;\n+\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+import com.google.common.util.concurrent.AbstractScheduledService;\n+import com.google.common.util.concurrent.ServiceManager;\n+import io.confluent.ksql.engine.KsqlEngine;\n+import io.confluent.ksql.rest.entity.HostInfoEntity;\n+import io.confluent.ksql.rest.entity.HostStatusEntity;\n+import io.confluent.ksql.rest.entity.LagInfoEntity;\n+import io.confluent.ksql.rest.entity.LagReportingRequest;\n+import io.confluent.ksql.rest.entity.QueryStateStoreId;\n+import io.confluent.ksql.rest.server.HeartbeatAgent.HostStatusListener;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.util.Pair;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.net.URI;\n+import java.net.URL;\n+import java.time.Clock;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Map.Entry;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.streams.LagInfo;\n+import org.apache.kafka.streams.errors.StreamsException;\n+import org.apache.kafka.streams.state.HostInfo;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Agent responsible for sending and receiving lag information across the cluster and providing\n+ * aggregate stats, usable during query time.\n+ */\n+public final class LagReportingAgent implements HostStatusListener {\n+  private static final int SERVICE_TIMEOUT_SEC = 2;\n+  private static final int NUM_THREADS_EXECUTOR = 1;\n+  private static final int SEND_LAG_DELAY_MS = 100;\n+  private static final HostLagInfo EMPTY_HOST_LAG_INFO = new HostLagInfo(Collections.emptyMap(), 0);\n+  private static final Logger LOG = LoggerFactory.getLogger(LagReportingAgent.class);\n+\n+  private final KsqlEngine engine;\n+  private final ScheduledExecutorService scheduledExecutorService;\n+  private final ServiceContext serviceContext;\n+  private final LagReportingConfig config;\n+  private final ServiceManager serviceManager;\n+  private final Clock clock;\n+\n+  private final Map<HostInfo, HostLagInfo> receivedLagInfo;\n+  private final AtomicReference<Set<HostInfo>> aliveHostsRef;\n+\n+  private URL localURL;\n+\n+  /**\n+   * Builder for creating an instance of LagReportingAgent.\n+   * @return\n+   */\n+  public static LagReportingAgent.Builder builder() {\n+    return new LagReportingAgent.Builder();\n+  }\n+\n+  /**\n+   * Lag related agent for both sending out lag for localhost as well as receiving lag reports for\n+   * other nodes in the cluster.\n+   * @param engine The ksql engine to access streams for inferring the cluster and getting local\n+   *               lags metrics\n+   * @param serviceContext Service context for issuing ksql requests\n+   * @param config The LagReportingConfig for configuring this agent\n+   * @param clock Clock for reporting lag\n+   */\n+  private LagReportingAgent(\n+      final KsqlEngine engine,\n+      final ScheduledExecutorService scheduledExecutorService,\n+      final ServiceContext serviceContext,\n+      final LagReportingConfig config,\n+      final Clock clock) {\n+    this.engine = requireNonNull(engine, \"engine\");\n+    this.scheduledExecutorService = scheduledExecutorService;\n+    this.serviceContext = requireNonNull(serviceContext, \"serviceContext\");\n+    this.config = requireNonNull(config, \"configuration parameters\");\n+    this.clock = clock;\n+    this.serviceManager = new ServiceManager(Arrays.asList(new SendLagService()));\n+    this.receivedLagInfo = new ConcurrentHashMap<>();\n+    this.aliveHostsRef = new AtomicReference<>(Collections.emptySet());\n+  }\n+\n+  void setLocalAddress(final String applicationServer) {\n+    try {\n+      this.localURL = new URL(applicationServer);\n+    } catch (final Exception e) {\n+      throw new IllegalStateException(\"Failed to convert remote host info to URL.\"\n+          + \" remoteInfo: \" + applicationServer);\n+    }\n+  }\n+\n+  void startAgent() {\n+    try {\n+      serviceManager.startAsync().awaitHealthy(SERVICE_TIMEOUT_SEC, TimeUnit.SECONDS);\n+    } catch (TimeoutException | IllegalStateException e) {\n+      LOG.error(\"Failed to start heartbeat services with exception \" + e.getMessage(), e);\n+    }\n+  }\n+\n+  void stopAgent() {\n+    try {\n+      serviceManager.stopAsync().awaitStopped(SERVICE_TIMEOUT_SEC, TimeUnit.SECONDS);\n+    } catch (TimeoutException | IllegalStateException e) {\n+      LOG.error(\"Failed to stop heartbeat services with exception \" + e.getMessage(), e);\n+    } finally {\n+      scheduledExecutorService.shutdownNow();\n+    }\n+  }\n+\n+  /**\n+   * Stores the host lag received from a remote Ksql server.\n+   * @param lagReportingRequest The host lag information sent directly from the other node.\n+   */\n+  public void receiveHostLag(final LagReportingRequest lagReportingRequest) {\n+    final long updateTimeMs = lagReportingRequest.getLastLagUpdateMs();\n+    final HostInfoEntity hostInfoEntity = lagReportingRequest.getHostInfo();\n+    final HostInfo hostInfo = new HostInfo(hostInfoEntity.getHost(), hostInfoEntity.getPort());\n+\n+    ImmutableMap.Builder<QueryStateStoreId, Map<Integer, LagInfoEntity>> hostMapBuilder\n+        = ImmutableMap.builder();\n+    for (Map.Entry<QueryStateStoreId, Map<Integer, LagInfoEntity>> storeEntry\n+        : lagReportingRequest.getStoreToPartitionToLagMap().entrySet()) {\n+      final QueryStateStoreId queryStateStoreId = storeEntry.getKey();\n+      final Map<Integer, LagInfoEntity> partitionMap = storeEntry.getValue();\n+\n+      ImmutableMap.Builder<Integer, LagInfoEntity> partitionsBuilder = ImmutableMap.builder();\n+\n+      // Go through each new partition and add lag info\n+      for (final Map.Entry<Integer, LagInfoEntity> partitionEntry : partitionMap.entrySet()) {\n+        final Integer partition = partitionEntry.getKey();\n+        final LagInfoEntity lagInfo = partitionEntry.getValue();\n+        partitionsBuilder.put(partition, lagInfo);\n+      }\n+\n+      hostMapBuilder.put(queryStateStoreId, partitionsBuilder.build());\n+    }\n+\n+    Map<QueryStateStoreId, Map<Integer, LagInfoEntity>> hostMap = hostMapBuilder.build();\n+    HostLagInfo hostLagInfo = new HostLagInfo(hostMap, updateTimeMs);\n+    receivedLagInfo.compute(hostInfo, (hi, previousHostLagInfo) ->\n+        previousHostLagInfo != null && previousHostLagInfo.getUpdateTimeMs() > updateTimeMs ?\n+            previousHostLagInfo : hostLagInfo);\n+  }\n+\n+  /**\n+   * Returns lag information for all of the \"alive\" hosts for a given state store and partition.\n+   * @param queryStateStoreId The lag info key\n+   * @param partition The partition of that state\n+   * @return A map which is keyed by host and contains lag information\n+   */\n+  public Map<HostInfo, LagInfoEntity> getHostsPartitionLagInfo(\n+      final Set<HostInfo> hosts, final QueryStateStoreId queryStateStoreId, final int partition) {\n+    ImmutableMap.Builder<HostInfo, LagInfoEntity> builder = ImmutableMap.builder();\n+    Set<HostInfo> aliveHosts = aliveHostsRef.get();\n+    for (HostInfo host : hosts) {\n+      LagInfoEntity lagInfo = receivedLagInfo.getOrDefault(host, EMPTY_HOST_LAG_INFO).getLagInfo()\n+          .getOrDefault(queryStateStoreId, Collections.emptyMap())\n+          .getOrDefault(partition, null);\n+      if (aliveHosts.contains(host) && lagInfo != null) {\n+        builder.put(host, lagInfo);\n+      }\n+    }\n+    return builder.build();\n+  }\n+\n+  /**\n+   * Returns a map of storeName -> partition -> LagInfoEntity.  Meant for being exposed in testing\n+   * and debug resources.\n+   */\n+  public Map<HostInfoEntity, Map<QueryStateStoreId, Map<Integer, LagInfoEntity>>> listAllLags() {\n+    ImmutableMap.Builder<HostInfoEntity, Map<QueryStateStoreId, Map<Integer, LagInfoEntity>>>\n+        builder = ImmutableMap.builder();\n+    for (Entry<HostInfo, HostLagInfo> e : receivedLagInfo.entrySet()) {\n+      final HostInfo hostInfo = e.getKey();\n+      builder.put(new HostInfoEntity(hostInfo.host(), hostInfo.port()),\n+          e.getValue().getLagInfo());\n+    }\n+    return builder.build();\n+  }\n+\n+  @Override\n+  public void onHostStatusUpdated(final Map<String, HostStatusEntity> hostsStatusMap) {\n+    aliveHostsRef.set(hostsStatusMap.values().stream()\n+        .filter(HostStatusEntity::getHostAlive)\n+        .map(HostStatusEntity::getHostInfoEntity)\n+        .map(hostInfoEntity -> new HostInfo(hostInfoEntity.getHost(), hostInfoEntity.getPort()))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3e4f951c670028b925593aa13f654440e50ae3f"}, "originalPosition": 217}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTk1MTk0MA==", "bodyText": "a fun simplification:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                for (HostInfo host : hosts) {\n          \n          \n            \n                for (HostInfo host : Sets.intersection(hosts, aliveHosts)) {", "url": "https://github.com/confluentinc/ksql/pull/4392#discussion_r371951940", "createdAt": "2020-01-28T17:34:45Z", "author": {"login": "agavra"}, "path": "ksql-rest-app/src/main/java/io/confluent/ksql/rest/server/LagReportingAgent.java", "diffHunk": "@@ -0,0 +1,394 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.server;\n+\n+import static java.util.Objects.requireNonNull;\n+\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+import com.google.common.util.concurrent.AbstractScheduledService;\n+import com.google.common.util.concurrent.ServiceManager;\n+import io.confluent.ksql.engine.KsqlEngine;\n+import io.confluent.ksql.rest.entity.HostInfoEntity;\n+import io.confluent.ksql.rest.entity.HostStatusEntity;\n+import io.confluent.ksql.rest.entity.LagInfoEntity;\n+import io.confluent.ksql.rest.entity.LagReportingRequest;\n+import io.confluent.ksql.rest.entity.QueryStateStoreId;\n+import io.confluent.ksql.rest.server.HeartbeatAgent.HostStatusListener;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.util.Pair;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.net.URI;\n+import java.net.URL;\n+import java.time.Clock;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Map.Entry;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.streams.LagInfo;\n+import org.apache.kafka.streams.errors.StreamsException;\n+import org.apache.kafka.streams.state.HostInfo;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Agent responsible for sending and receiving lag information across the cluster and providing\n+ * aggregate stats, usable during query time.\n+ */\n+public final class LagReportingAgent implements HostStatusListener {\n+  private static final int SERVICE_TIMEOUT_SEC = 2;\n+  private static final int NUM_THREADS_EXECUTOR = 1;\n+  private static final int SEND_LAG_DELAY_MS = 100;\n+  private static final HostLagInfo EMPTY_HOST_LAG_INFO = new HostLagInfo(Collections.emptyMap(), 0);\n+  private static final Logger LOG = LoggerFactory.getLogger(LagReportingAgent.class);\n+\n+  private final KsqlEngine engine;\n+  private final ScheduledExecutorService scheduledExecutorService;\n+  private final ServiceContext serviceContext;\n+  private final LagReportingConfig config;\n+  private final ServiceManager serviceManager;\n+  private final Clock clock;\n+\n+  private final Map<HostInfo, HostLagInfo> receivedLagInfo;\n+  private final AtomicReference<Set<HostInfo>> aliveHostsRef;\n+\n+  private URL localURL;\n+\n+  /**\n+   * Builder for creating an instance of LagReportingAgent.\n+   * @return\n+   */\n+  public static LagReportingAgent.Builder builder() {\n+    return new LagReportingAgent.Builder();\n+  }\n+\n+  /**\n+   * Lag related agent for both sending out lag for localhost as well as receiving lag reports for\n+   * other nodes in the cluster.\n+   * @param engine The ksql engine to access streams for inferring the cluster and getting local\n+   *               lags metrics\n+   * @param serviceContext Service context for issuing ksql requests\n+   * @param config The LagReportingConfig for configuring this agent\n+   * @param clock Clock for reporting lag\n+   */\n+  private LagReportingAgent(\n+      final KsqlEngine engine,\n+      final ScheduledExecutorService scheduledExecutorService,\n+      final ServiceContext serviceContext,\n+      final LagReportingConfig config,\n+      final Clock clock) {\n+    this.engine = requireNonNull(engine, \"engine\");\n+    this.scheduledExecutorService = scheduledExecutorService;\n+    this.serviceContext = requireNonNull(serviceContext, \"serviceContext\");\n+    this.config = requireNonNull(config, \"configuration parameters\");\n+    this.clock = clock;\n+    this.serviceManager = new ServiceManager(Arrays.asList(new SendLagService()));\n+    this.receivedLagInfo = new ConcurrentHashMap<>();\n+    this.aliveHostsRef = new AtomicReference<>(Collections.emptySet());\n+  }\n+\n+  void setLocalAddress(final String applicationServer) {\n+    try {\n+      this.localURL = new URL(applicationServer);\n+    } catch (final Exception e) {\n+      throw new IllegalStateException(\"Failed to convert remote host info to URL.\"\n+          + \" remoteInfo: \" + applicationServer);\n+    }\n+  }\n+\n+  void startAgent() {\n+    try {\n+      serviceManager.startAsync().awaitHealthy(SERVICE_TIMEOUT_SEC, TimeUnit.SECONDS);\n+    } catch (TimeoutException | IllegalStateException e) {\n+      LOG.error(\"Failed to start heartbeat services with exception \" + e.getMessage(), e);\n+    }\n+  }\n+\n+  void stopAgent() {\n+    try {\n+      serviceManager.stopAsync().awaitStopped(SERVICE_TIMEOUT_SEC, TimeUnit.SECONDS);\n+    } catch (TimeoutException | IllegalStateException e) {\n+      LOG.error(\"Failed to stop heartbeat services with exception \" + e.getMessage(), e);\n+    } finally {\n+      scheduledExecutorService.shutdownNow();\n+    }\n+  }\n+\n+  /**\n+   * Stores the host lag received from a remote Ksql server.\n+   * @param lagReportingRequest The host lag information sent directly from the other node.\n+   */\n+  public void receiveHostLag(final LagReportingRequest lagReportingRequest) {\n+    final long updateTimeMs = lagReportingRequest.getLastLagUpdateMs();\n+    final HostInfoEntity hostInfoEntity = lagReportingRequest.getHostInfo();\n+    final HostInfo hostInfo = new HostInfo(hostInfoEntity.getHost(), hostInfoEntity.getPort());\n+\n+    ImmutableMap.Builder<QueryStateStoreId, Map<Integer, LagInfoEntity>> hostMapBuilder\n+        = ImmutableMap.builder();\n+    for (Map.Entry<QueryStateStoreId, Map<Integer, LagInfoEntity>> storeEntry\n+        : lagReportingRequest.getStoreToPartitionToLagMap().entrySet()) {\n+      final QueryStateStoreId queryStateStoreId = storeEntry.getKey();\n+      final Map<Integer, LagInfoEntity> partitionMap = storeEntry.getValue();\n+\n+      ImmutableMap.Builder<Integer, LagInfoEntity> partitionsBuilder = ImmutableMap.builder();\n+\n+      // Go through each new partition and add lag info\n+      for (final Map.Entry<Integer, LagInfoEntity> partitionEntry : partitionMap.entrySet()) {\n+        final Integer partition = partitionEntry.getKey();\n+        final LagInfoEntity lagInfo = partitionEntry.getValue();\n+        partitionsBuilder.put(partition, lagInfo);\n+      }\n+\n+      hostMapBuilder.put(queryStateStoreId, partitionsBuilder.build());\n+    }\n+\n+    Map<QueryStateStoreId, Map<Integer, LagInfoEntity>> hostMap = hostMapBuilder.build();\n+    HostLagInfo hostLagInfo = new HostLagInfo(hostMap, updateTimeMs);\n+    receivedLagInfo.compute(hostInfo, (hi, previousHostLagInfo) ->\n+        previousHostLagInfo != null && previousHostLagInfo.getUpdateTimeMs() > updateTimeMs ?\n+            previousHostLagInfo : hostLagInfo);\n+  }\n+\n+  /**\n+   * Returns lag information for all of the \"alive\" hosts for a given state store and partition.\n+   * @param queryStateStoreId The lag info key\n+   * @param partition The partition of that state\n+   * @return A map which is keyed by host and contains lag information\n+   */\n+  public Map<HostInfo, LagInfoEntity> getHostsPartitionLagInfo(\n+      final Set<HostInfo> hosts, final QueryStateStoreId queryStateStoreId, final int partition) {\n+    ImmutableMap.Builder<HostInfo, LagInfoEntity> builder = ImmutableMap.builder();\n+    Set<HostInfo> aliveHosts = aliveHostsRef.get();\n+    for (HostInfo host : hosts) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3e4f951c670028b925593aa13f654440e50ae3f"}, "originalPosition": 186}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTk1NDAzNw==", "bodyText": "nit: can be simplified (same below):\n.collect(Collectors.toMap(\n   e -> QueryStateStoreId.of(getQueryApplicationId(), e.getKey()), \n   e -> e.getValue()\n))", "url": "https://github.com/confluentinc/ksql/pull/4392#discussion_r371954037", "createdAt": "2020-01-28T17:39:01Z", "author": {"login": "agavra"}, "path": "ksql-rest-app/src/main/java/io/confluent/ksql/rest/server/LagReportingAgent.java", "diffHunk": "@@ -0,0 +1,394 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.server;\n+\n+import static java.util.Objects.requireNonNull;\n+\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+import com.google.common.util.concurrent.AbstractScheduledService;\n+import com.google.common.util.concurrent.ServiceManager;\n+import io.confluent.ksql.engine.KsqlEngine;\n+import io.confluent.ksql.rest.entity.HostInfoEntity;\n+import io.confluent.ksql.rest.entity.HostStatusEntity;\n+import io.confluent.ksql.rest.entity.LagInfoEntity;\n+import io.confluent.ksql.rest.entity.LagReportingRequest;\n+import io.confluent.ksql.rest.entity.QueryStateStoreId;\n+import io.confluent.ksql.rest.server.HeartbeatAgent.HostStatusListener;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.util.Pair;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.net.URI;\n+import java.net.URL;\n+import java.time.Clock;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Map.Entry;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.streams.LagInfo;\n+import org.apache.kafka.streams.errors.StreamsException;\n+import org.apache.kafka.streams.state.HostInfo;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Agent responsible for sending and receiving lag information across the cluster and providing\n+ * aggregate stats, usable during query time.\n+ */\n+public final class LagReportingAgent implements HostStatusListener {\n+  private static final int SERVICE_TIMEOUT_SEC = 2;\n+  private static final int NUM_THREADS_EXECUTOR = 1;\n+  private static final int SEND_LAG_DELAY_MS = 100;\n+  private static final HostLagInfo EMPTY_HOST_LAG_INFO = new HostLagInfo(Collections.emptyMap(), 0);\n+  private static final Logger LOG = LoggerFactory.getLogger(LagReportingAgent.class);\n+\n+  private final KsqlEngine engine;\n+  private final ScheduledExecutorService scheduledExecutorService;\n+  private final ServiceContext serviceContext;\n+  private final LagReportingConfig config;\n+  private final ServiceManager serviceManager;\n+  private final Clock clock;\n+\n+  private final Map<HostInfo, HostLagInfo> receivedLagInfo;\n+  private final AtomicReference<Set<HostInfo>> aliveHostsRef;\n+\n+  private URL localURL;\n+\n+  /**\n+   * Builder for creating an instance of LagReportingAgent.\n+   * @return\n+   */\n+  public static LagReportingAgent.Builder builder() {\n+    return new LagReportingAgent.Builder();\n+  }\n+\n+  /**\n+   * Lag related agent for both sending out lag for localhost as well as receiving lag reports for\n+   * other nodes in the cluster.\n+   * @param engine The ksql engine to access streams for inferring the cluster and getting local\n+   *               lags metrics\n+   * @param serviceContext Service context for issuing ksql requests\n+   * @param config The LagReportingConfig for configuring this agent\n+   * @param clock Clock for reporting lag\n+   */\n+  private LagReportingAgent(\n+      final KsqlEngine engine,\n+      final ScheduledExecutorService scheduledExecutorService,\n+      final ServiceContext serviceContext,\n+      final LagReportingConfig config,\n+      final Clock clock) {\n+    this.engine = requireNonNull(engine, \"engine\");\n+    this.scheduledExecutorService = scheduledExecutorService;\n+    this.serviceContext = requireNonNull(serviceContext, \"serviceContext\");\n+    this.config = requireNonNull(config, \"configuration parameters\");\n+    this.clock = clock;\n+    this.serviceManager = new ServiceManager(Arrays.asList(new SendLagService()));\n+    this.receivedLagInfo = new ConcurrentHashMap<>();\n+    this.aliveHostsRef = new AtomicReference<>(Collections.emptySet());\n+  }\n+\n+  void setLocalAddress(final String applicationServer) {\n+    try {\n+      this.localURL = new URL(applicationServer);\n+    } catch (final Exception e) {\n+      throw new IllegalStateException(\"Failed to convert remote host info to URL.\"\n+          + \" remoteInfo: \" + applicationServer);\n+    }\n+  }\n+\n+  void startAgent() {\n+    try {\n+      serviceManager.startAsync().awaitHealthy(SERVICE_TIMEOUT_SEC, TimeUnit.SECONDS);\n+    } catch (TimeoutException | IllegalStateException e) {\n+      LOG.error(\"Failed to start heartbeat services with exception \" + e.getMessage(), e);\n+    }\n+  }\n+\n+  void stopAgent() {\n+    try {\n+      serviceManager.stopAsync().awaitStopped(SERVICE_TIMEOUT_SEC, TimeUnit.SECONDS);\n+    } catch (TimeoutException | IllegalStateException e) {\n+      LOG.error(\"Failed to stop heartbeat services with exception \" + e.getMessage(), e);\n+    } finally {\n+      scheduledExecutorService.shutdownNow();\n+    }\n+  }\n+\n+  /**\n+   * Stores the host lag received from a remote Ksql server.\n+   * @param lagReportingRequest The host lag information sent directly from the other node.\n+   */\n+  public void receiveHostLag(final LagReportingRequest lagReportingRequest) {\n+    final long updateTimeMs = lagReportingRequest.getLastLagUpdateMs();\n+    final HostInfoEntity hostInfoEntity = lagReportingRequest.getHostInfo();\n+    final HostInfo hostInfo = new HostInfo(hostInfoEntity.getHost(), hostInfoEntity.getPort());\n+\n+    ImmutableMap.Builder<QueryStateStoreId, Map<Integer, LagInfoEntity>> hostMapBuilder\n+        = ImmutableMap.builder();\n+    for (Map.Entry<QueryStateStoreId, Map<Integer, LagInfoEntity>> storeEntry\n+        : lagReportingRequest.getStoreToPartitionToLagMap().entrySet()) {\n+      final QueryStateStoreId queryStateStoreId = storeEntry.getKey();\n+      final Map<Integer, LagInfoEntity> partitionMap = storeEntry.getValue();\n+\n+      ImmutableMap.Builder<Integer, LagInfoEntity> partitionsBuilder = ImmutableMap.builder();\n+\n+      // Go through each new partition and add lag info\n+      for (final Map.Entry<Integer, LagInfoEntity> partitionEntry : partitionMap.entrySet()) {\n+        final Integer partition = partitionEntry.getKey();\n+        final LagInfoEntity lagInfo = partitionEntry.getValue();\n+        partitionsBuilder.put(partition, lagInfo);\n+      }\n+\n+      hostMapBuilder.put(queryStateStoreId, partitionsBuilder.build());\n+    }\n+\n+    Map<QueryStateStoreId, Map<Integer, LagInfoEntity>> hostMap = hostMapBuilder.build();\n+    HostLagInfo hostLagInfo = new HostLagInfo(hostMap, updateTimeMs);\n+    receivedLagInfo.compute(hostInfo, (hi, previousHostLagInfo) ->\n+        previousHostLagInfo != null && previousHostLagInfo.getUpdateTimeMs() > updateTimeMs ?\n+            previousHostLagInfo : hostLagInfo);\n+  }\n+\n+  /**\n+   * Returns lag information for all of the \"alive\" hosts for a given state store and partition.\n+   * @param queryStateStoreId The lag info key\n+   * @param partition The partition of that state\n+   * @return A map which is keyed by host and contains lag information\n+   */\n+  public Map<HostInfo, LagInfoEntity> getHostsPartitionLagInfo(\n+      final Set<HostInfo> hosts, final QueryStateStoreId queryStateStoreId, final int partition) {\n+    ImmutableMap.Builder<HostInfo, LagInfoEntity> builder = ImmutableMap.builder();\n+    Set<HostInfo> aliveHosts = aliveHostsRef.get();\n+    for (HostInfo host : hosts) {\n+      LagInfoEntity lagInfo = receivedLagInfo.getOrDefault(host, EMPTY_HOST_LAG_INFO).getLagInfo()\n+          .getOrDefault(queryStateStoreId, Collections.emptyMap())\n+          .getOrDefault(partition, null);\n+      if (aliveHosts.contains(host) && lagInfo != null) {\n+        builder.put(host, lagInfo);\n+      }\n+    }\n+    return builder.build();\n+  }\n+\n+  /**\n+   * Returns a map of storeName -> partition -> LagInfoEntity.  Meant for being exposed in testing\n+   * and debug resources.\n+   */\n+  public Map<HostInfoEntity, Map<QueryStateStoreId, Map<Integer, LagInfoEntity>>> listAllLags() {\n+    ImmutableMap.Builder<HostInfoEntity, Map<QueryStateStoreId, Map<Integer, LagInfoEntity>>>\n+        builder = ImmutableMap.builder();\n+    for (Entry<HostInfo, HostLagInfo> e : receivedLagInfo.entrySet()) {\n+      final HostInfo hostInfo = e.getKey();\n+      builder.put(new HostInfoEntity(hostInfo.host(), hostInfo.port()),\n+          e.getValue().getLagInfo());\n+    }\n+    return builder.build();\n+  }\n+\n+  @Override\n+  public void onHostStatusUpdated(final Map<String, HostStatusEntity> hostsStatusMap) {\n+    aliveHostsRef.set(hostsStatusMap.values().stream()\n+        .filter(HostStatusEntity::getHostAlive)\n+        .map(HostStatusEntity::getHostInfoEntity)\n+        .map(hostInfoEntity -> new HostInfo(hostInfoEntity.getHost(), hostInfoEntity.getPort()))\n+        .collect(ImmutableSet.toImmutableSet()));\n+  }\n+\n+  /**\n+   * Broadcast lags to remote hosts.\n+   *\n+   * <p>This is an asynchronous RPC and we do not handle the response returned from the remote\n+   * server.</p>\n+   */\n+  class SendLagService extends AbstractScheduledService {\n+\n+    @Override\n+    protected void runOneIteration() {\n+      final List<PersistentQueryMetadata> currentQueries = engine.getPersistentQueries();\n+      if (currentQueries.isEmpty()) {\n+        return;\n+      }\n+\n+      final Map<QueryStateStoreId, Map<Integer, LagInfo>> localLagMap\n+          = currentQueries.stream()\n+          .map(this::getLocalLagMap)\n+          .filter(Objects::nonNull)\n+          .flatMap(map -> map.entrySet().stream())\n+          .collect(Collectors.toMap(Entry::getKey, Entry::getValue));\n+\n+      final LagReportingRequest request = createLagReportingRequest(localLagMap);\n+\n+      Set<HostInfo> aliveHosts = aliveHostsRef.get();\n+      for (HostInfo hostInfo: aliveHosts) {\n+        try {\n+          final URI remoteUri = buildRemoteUri(localURL, hostInfo.host(), hostInfo.port());\n+          LOG.debug(\"Sending lag to host {} at {}\", hostInfo.host(), clock.millis());\n+          serviceContext.getKsqlClient().makeAsyncLagReportRequest(remoteUri, request);\n+        } catch (Throwable t) {\n+          LOG.error(\"Request to server: \" + hostInfo.host() + \":\" + hostInfo.port()\n+              + \" failed with exception: \" + t.getMessage(), t);\n+        }\n+      }\n+    }\n+\n+    /**\n+     * Fetches the lag map from PersistentQueryMetadata, getting it from the underlying\n+     * KafkaStreams.\n+     */\n+    private Map<QueryStateStoreId, Map<Integer, LagInfo>> getLocalLagMap(\n+        PersistentQueryMetadata persistentQueryMetadata) {\n+      Map<QueryStateStoreId, Map<Integer, LagInfo>> getLagMap = null;\n+      try {\n+        getLagMap = persistentQueryMetadata.getKafkaStreams()\n+            .allLocalStorePartitionLags().entrySet().stream()\n+            .map(e -> Pair.of(QueryStateStoreId.of(persistentQueryMetadata.getQueryApplicationId(),\n+                                                   e.getKey()),\n+                              e.getValue()))\n+            .collect(Collectors.toMap(Pair::getLeft, Pair::getRight));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3e4f951c670028b925593aa13f654440e50ae3f"}, "originalPosition": 271}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTk1NjE3NA==", "bodyText": "did you intended to collapse the top layer (i.e. not include the hostInfoEntity as a key?)", "url": "https://github.com/confluentinc/ksql/pull/4392#discussion_r371956174", "createdAt": "2020-01-28T17:43:11Z", "author": {"login": "agavra"}, "path": "ksql-rest-app/src/main/java/io/confluent/ksql/rest/server/LagReportingAgent.java", "diffHunk": "@@ -0,0 +1,394 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.server;\n+\n+import static java.util.Objects.requireNonNull;\n+\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+import com.google.common.util.concurrent.AbstractScheduledService;\n+import com.google.common.util.concurrent.ServiceManager;\n+import io.confluent.ksql.engine.KsqlEngine;\n+import io.confluent.ksql.rest.entity.HostInfoEntity;\n+import io.confluent.ksql.rest.entity.HostStatusEntity;\n+import io.confluent.ksql.rest.entity.LagInfoEntity;\n+import io.confluent.ksql.rest.entity.LagReportingRequest;\n+import io.confluent.ksql.rest.entity.QueryStateStoreId;\n+import io.confluent.ksql.rest.server.HeartbeatAgent.HostStatusListener;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.util.Pair;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.net.URI;\n+import java.net.URL;\n+import java.time.Clock;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Map.Entry;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicReference;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.streams.LagInfo;\n+import org.apache.kafka.streams.errors.StreamsException;\n+import org.apache.kafka.streams.state.HostInfo;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Agent responsible for sending and receiving lag information across the cluster and providing\n+ * aggregate stats, usable during query time.\n+ */\n+public final class LagReportingAgent implements HostStatusListener {\n+  private static final int SERVICE_TIMEOUT_SEC = 2;\n+  private static final int NUM_THREADS_EXECUTOR = 1;\n+  private static final int SEND_LAG_DELAY_MS = 100;\n+  private static final HostLagInfo EMPTY_HOST_LAG_INFO = new HostLagInfo(Collections.emptyMap(), 0);\n+  private static final Logger LOG = LoggerFactory.getLogger(LagReportingAgent.class);\n+\n+  private final KsqlEngine engine;\n+  private final ScheduledExecutorService scheduledExecutorService;\n+  private final ServiceContext serviceContext;\n+  private final LagReportingConfig config;\n+  private final ServiceManager serviceManager;\n+  private final Clock clock;\n+\n+  private final Map<HostInfo, HostLagInfo> receivedLagInfo;\n+  private final AtomicReference<Set<HostInfo>> aliveHostsRef;\n+\n+  private URL localURL;\n+\n+  /**\n+   * Builder for creating an instance of LagReportingAgent.\n+   * @return\n+   */\n+  public static LagReportingAgent.Builder builder() {\n+    return new LagReportingAgent.Builder();\n+  }\n+\n+  /**\n+   * Lag related agent for both sending out lag for localhost as well as receiving lag reports for\n+   * other nodes in the cluster.\n+   * @param engine The ksql engine to access streams for inferring the cluster and getting local\n+   *               lags metrics\n+   * @param serviceContext Service context for issuing ksql requests\n+   * @param config The LagReportingConfig for configuring this agent\n+   * @param clock Clock for reporting lag\n+   */\n+  private LagReportingAgent(\n+      final KsqlEngine engine,\n+      final ScheduledExecutorService scheduledExecutorService,\n+      final ServiceContext serviceContext,\n+      final LagReportingConfig config,\n+      final Clock clock) {\n+    this.engine = requireNonNull(engine, \"engine\");\n+    this.scheduledExecutorService = scheduledExecutorService;\n+    this.serviceContext = requireNonNull(serviceContext, \"serviceContext\");\n+    this.config = requireNonNull(config, \"configuration parameters\");\n+    this.clock = clock;\n+    this.serviceManager = new ServiceManager(Arrays.asList(new SendLagService()));\n+    this.receivedLagInfo = new ConcurrentHashMap<>();\n+    this.aliveHostsRef = new AtomicReference<>(Collections.emptySet());\n+  }\n+\n+  void setLocalAddress(final String applicationServer) {\n+    try {\n+      this.localURL = new URL(applicationServer);\n+    } catch (final Exception e) {\n+      throw new IllegalStateException(\"Failed to convert remote host info to URL.\"\n+          + \" remoteInfo: \" + applicationServer);\n+    }\n+  }\n+\n+  void startAgent() {\n+    try {\n+      serviceManager.startAsync().awaitHealthy(SERVICE_TIMEOUT_SEC, TimeUnit.SECONDS);\n+    } catch (TimeoutException | IllegalStateException e) {\n+      LOG.error(\"Failed to start heartbeat services with exception \" + e.getMessage(), e);\n+    }\n+  }\n+\n+  void stopAgent() {\n+    try {\n+      serviceManager.stopAsync().awaitStopped(SERVICE_TIMEOUT_SEC, TimeUnit.SECONDS);\n+    } catch (TimeoutException | IllegalStateException e) {\n+      LOG.error(\"Failed to stop heartbeat services with exception \" + e.getMessage(), e);\n+    } finally {\n+      scheduledExecutorService.shutdownNow();\n+    }\n+  }\n+\n+  /**\n+   * Stores the host lag received from a remote Ksql server.\n+   * @param lagReportingRequest The host lag information sent directly from the other node.\n+   */\n+  public void receiveHostLag(final LagReportingRequest lagReportingRequest) {\n+    final long updateTimeMs = lagReportingRequest.getLastLagUpdateMs();\n+    final HostInfoEntity hostInfoEntity = lagReportingRequest.getHostInfo();\n+    final HostInfo hostInfo = new HostInfo(hostInfoEntity.getHost(), hostInfoEntity.getPort());\n+\n+    ImmutableMap.Builder<QueryStateStoreId, Map<Integer, LagInfoEntity>> hostMapBuilder\n+        = ImmutableMap.builder();\n+    for (Map.Entry<QueryStateStoreId, Map<Integer, LagInfoEntity>> storeEntry\n+        : lagReportingRequest.getStoreToPartitionToLagMap().entrySet()) {\n+      final QueryStateStoreId queryStateStoreId = storeEntry.getKey();\n+      final Map<Integer, LagInfoEntity> partitionMap = storeEntry.getValue();\n+\n+      ImmutableMap.Builder<Integer, LagInfoEntity> partitionsBuilder = ImmutableMap.builder();\n+\n+      // Go through each new partition and add lag info\n+      for (final Map.Entry<Integer, LagInfoEntity> partitionEntry : partitionMap.entrySet()) {\n+        final Integer partition = partitionEntry.getKey();\n+        final LagInfoEntity lagInfo = partitionEntry.getValue();\n+        partitionsBuilder.put(partition, lagInfo);\n+      }\n+\n+      hostMapBuilder.put(queryStateStoreId, partitionsBuilder.build());\n+    }\n+\n+    Map<QueryStateStoreId, Map<Integer, LagInfoEntity>> hostMap = hostMapBuilder.build();\n+    HostLagInfo hostLagInfo = new HostLagInfo(hostMap, updateTimeMs);\n+    receivedLagInfo.compute(hostInfo, (hi, previousHostLagInfo) ->\n+        previousHostLagInfo != null && previousHostLagInfo.getUpdateTimeMs() > updateTimeMs ?\n+            previousHostLagInfo : hostLagInfo);\n+  }\n+\n+  /**\n+   * Returns lag information for all of the \"alive\" hosts for a given state store and partition.\n+   * @param queryStateStoreId The lag info key\n+   * @param partition The partition of that state\n+   * @return A map which is keyed by host and contains lag information\n+   */\n+  public Map<HostInfo, LagInfoEntity> getHostsPartitionLagInfo(\n+      final Set<HostInfo> hosts, final QueryStateStoreId queryStateStoreId, final int partition) {\n+    ImmutableMap.Builder<HostInfo, LagInfoEntity> builder = ImmutableMap.builder();\n+    Set<HostInfo> aliveHosts = aliveHostsRef.get();\n+    for (HostInfo host : hosts) {\n+      LagInfoEntity lagInfo = receivedLagInfo.getOrDefault(host, EMPTY_HOST_LAG_INFO).getLagInfo()\n+          .getOrDefault(queryStateStoreId, Collections.emptyMap())\n+          .getOrDefault(partition, null);\n+      if (aliveHosts.contains(host) && lagInfo != null) {\n+        builder.put(host, lagInfo);\n+      }\n+    }\n+    return builder.build();\n+  }\n+\n+  /**\n+   * Returns a map of storeName -> partition -> LagInfoEntity.  Meant for being exposed in testing", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3e4f951c670028b925593aa13f654440e50ae3f"}, "originalPosition": 198}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTk2MDM0NA==", "bodyText": "I think it might make sense to follow the same pattern we have for the heartbeat API and not add a verb to the /lag endpoint (i.e. we just POST /lag) to keep it RESTFUL", "url": "https://github.com/confluentinc/ksql/pull/4392#discussion_r371960344", "createdAt": "2020-01-28T17:51:21Z", "author": {"login": "agavra"}, "path": "ksql-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/LagReportingResource.java", "diffHunk": "@@ -0,0 +1,46 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.server.resources;\n+\n+import io.confluent.ksql.rest.entity.LagReportingRequest;\n+import io.confluent.ksql.rest.entity.LagReportingResponse;\n+import io.confluent.ksql.rest.entity.Versions;\n+import io.confluent.ksql.rest.server.LagReportingAgent;\n+import javax.ws.rs.Consumes;\n+import javax.ws.rs.POST;\n+import javax.ws.rs.Path;\n+import javax.ws.rs.Produces;\n+import javax.ws.rs.core.MediaType;\n+import javax.ws.rs.core.Response;\n+\n+@Path(\"/lag\")\n+@Consumes({Versions.KSQL_V1_JSON, MediaType.APPLICATION_JSON})\n+@Produces({Versions.KSQL_V1_JSON, MediaType.APPLICATION_JSON})\n+public class LagReportingResource {\n+\n+  private LagReportingAgent lagReportingAgent;\n+\n+  public LagReportingResource(final LagReportingAgent lagReportingAgent) {\n+    this.lagReportingAgent = lagReportingAgent;\n+  }\n+\n+  @Path(\"/report\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3e4f951c670028b925593aa13f654440e50ae3f"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MTk2NTczNg==", "bodyText": "nit: this might be a pain, but I think these tests would be easier to read and maintain if we had properly named constants for all of these ints", "url": "https://github.com/confluentinc/ksql/pull/4392#discussion_r371965736", "createdAt": "2020-01-28T18:01:41Z", "author": {"login": "agavra"}, "path": "ksql-rest-app/src/test/java/io/confluent/ksql/rest/server/LagReportingAgentTest.java", "diffHunk": "@@ -0,0 +1,280 @@\n+package io.confluent.ksql.rest.server;\n+\n+import static org.junit.Assert.assertEquals;\n+import static org.mockito.Mockito.eq;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.ImmutableSet;\n+import io.confluent.ksql.engine.KsqlEngine;\n+import io.confluent.ksql.rest.entity.HostInfoEntity;\n+import io.confluent.ksql.rest.entity.HostStatusEntity;\n+import io.confluent.ksql.rest.entity.LagInfoEntity;\n+import io.confluent.ksql.rest.entity.LagReportingRequest;\n+import io.confluent.ksql.rest.entity.QueryStateStoreId;\n+import io.confluent.ksql.rest.server.LagReportingAgent.Builder;\n+import io.confluent.ksql.rest.server.LagReportingAgent.SendLagService;\n+import io.confluent.ksql.services.ServiceContext;\n+import io.confluent.ksql.services.SimpleKsqlClient;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import java.net.URI;\n+import java.time.Clock;\n+import java.util.Map;\n+import java.util.Set;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.apache.kafka.streams.LagInfo;\n+import org.apache.kafka.streams.state.HostInfo;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.mockito.Mock;\n+import org.mockito.junit.MockitoJUnitRunner;\n+\n+@RunWith(MockitoJUnitRunner.class)\n+public class LagReportingAgentTest {\n+  private static long TIME_NOW_MS = 100;\n+  private static final String LOCALHOST_URL = \"http://localhost:8088\";\n+  private static HostInfoEntity LOCALHOST_INFO = new HostInfoEntity(\"localhost\", 8088);\n+\n+  private static HostInfoEntity HOST1 = new HostInfoEntity(\"host1\", 1234);\n+  private static HostInfoEntity HOST2 = new HostInfoEntity(\"host2\", 1234);\n+  private static HostInfo HI1 = new HostInfo(\"host1\", 1234);\n+  private static HostInfo HI2 = new HostInfo(\"host2\", 1234);\n+  private static Set<HostInfo> HOSTS = ImmutableSet.of(HI1, HI2);\n+  private static HostStatusEntity HOST1_STATUS_ALIVE = new HostStatusEntity(HOST1, true, 0L);\n+  private static HostStatusEntity HOST2_STATUS_ALIVE = new HostStatusEntity(HOST2, true, 0L);\n+  private static HostStatusEntity HOST1_STATUS_DEAD = new HostStatusEntity(HOST1, false, 0L);\n+  private static HostStatusEntity HOST2_STATUS_DEAD = new HostStatusEntity(HOST2, false, 0L);\n+\n+  private static Map<String, HostStatusEntity> HOSTS_ALIVE\n+      = ImmutableMap.<String, HostStatusEntity>builder()\n+      .put(HOST1.toString(), HOST1_STATUS_ALIVE)\n+      .put(HOST2.toString(), HOST2_STATUS_ALIVE)\n+      .build();\n+\n+  private static Map<String, HostStatusEntity> HOSTS_HOST1_DEAD\n+      = ImmutableMap.<String, HostStatusEntity>builder()\n+      .put(HOST1.toString(), HOST1_STATUS_DEAD)\n+      .put(HOST2.toString(), HOST2_STATUS_ALIVE)\n+      .build();\n+\n+  private static Map<String, HostStatusEntity> HOSTS_HOST2_DEAD\n+      = ImmutableMap.<String, HostStatusEntity>builder()\n+      .put(HOST1.toString(), HOST1_STATUS_ALIVE)\n+      .put(HOST2.toString(), HOST2_STATUS_DEAD)\n+      .build();\n+\n+  private static final String QUERY_ID0 = \"query0\";\n+  private static final String QUERY_ID1 = \"query1\";\n+  private static final String STATE_STORE0 = \"a\";\n+  private static final String STATE_STORE1 = \"b\";\n+  private static final QueryStateStoreId QUERY_STORE_A =\n+      QueryStateStoreId.of(QUERY_ID0, STATE_STORE0);\n+  private static final QueryStateStoreId QUERY_STORE_B =\n+      QueryStateStoreId.of(QUERY_ID1, STATE_STORE1);\n+\n+  private static final Map<QueryStateStoreId, Map<Integer, LagInfoEntity>> LAG_MAP1\n+      = ImmutableMap.<QueryStateStoreId, Map<Integer, LagInfoEntity>>builder()\n+      .put(QUERY_STORE_A, ImmutableMap.<Integer, LagInfoEntity>builder()\n+          .put(1, new LagInfoEntity(1, 10, 9))\n+          .put(3, new LagInfoEntity(3, 10, 7))\n+          .build())\n+      .put(QUERY_STORE_B, ImmutableMap.<Integer, LagInfoEntity>builder()\n+          .put(4, new LagInfoEntity(6, 10, 4))\n+          .build())\n+      .build();\n+\n+  private static final Map<QueryStateStoreId, Map<Integer, LagInfoEntity>> LAG_MAP2\n+      = ImmutableMap.<QueryStateStoreId, Map<Integer, LagInfoEntity>>builder()\n+      .put(QUERY_STORE_A, ImmutableMap.<Integer, LagInfoEntity>builder()\n+          .put(1, new LagInfoEntity(4, 10, 6))\n+          .build())\n+      .put(QUERY_STORE_B, ImmutableMap.<Integer, LagInfoEntity>builder()\n+          .put(4, new LagInfoEntity(7, 10, 3))\n+          .build())\n+      .build();\n+\n+  @Mock\n+  private PersistentQueryMetadata query0;\n+  @Mock\n+  private PersistentQueryMetadata query1;\n+  @Mock\n+  private KafkaStreams kafkaStreams0;\n+  @Mock\n+  private KafkaStreams kafkaStreams1;\n+  @Mock\n+  private ServiceContext serviceContext;\n+  @Mock\n+  private KsqlEngine ksqlEngine;\n+  @Mock\n+  private SimpleKsqlClient ksqlClient;\n+  @Mock\n+  private LagInfo lagInfo0;\n+  @Mock\n+  private LagInfo lagInfo1;\n+  @Mock\n+  private Clock clock;\n+\n+  private LagReportingAgent lagReportingAgent;\n+\n+\n+  @Before\n+  public void setUp() {\n+    when(serviceContext.getKsqlClient()).thenReturn(ksqlClient);\n+\n+    Builder builder = LagReportingAgent.builder();\n+    lagReportingAgent = builder\n+        .clock(clock)\n+        .build(ksqlEngine, serviceContext);\n+    lagReportingAgent.setLocalAddress(LOCALHOST_URL);\n+  }\n+\n+  @Test\n+  public void shouldReceiveLags() {\n+    // When:\n+    lagReportingAgent.receiveHostLag(hostLag(HOST1, LAG_MAP1, 100));\n+    lagReportingAgent.receiveHostLag(hostLag(HOST2, LAG_MAP2, 200));\n+    lagReportingAgent.onHostStatusUpdated(HOSTS_ALIVE);\n+\n+    // Then:\n+    Map<HostInfo, LagInfoEntity> hostPartitionLagList\n+        = lagReportingAgent.getHostsPartitionLagInfo(HOSTS, QueryStateStoreId.of(\"query0\", \"a\"), 1);\n+    assertEquals(2, hostPartitionLagList.size());\n+    assertEquals(1, hostPartitionLagList.get(HI1).getCurrentOffsetPosition());\n+    assertEquals(10, hostPartitionLagList.get(HI1).getEndOffsetPosition());\n+    assertEquals(9, hostPartitionLagList.get(HI1).getOffsetLag());\n+    assertEquals(4, hostPartitionLagList.get(HI2).getCurrentOffsetPosition());\n+    assertEquals(10, hostPartitionLagList.get(HI2).getEndOffsetPosition());\n+    assertEquals(6, hostPartitionLagList.get(HI2).getOffsetLag());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d3e4f951c670028b925593aa13f654440e50ae3f"}, "originalPosition": 150}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "93276a4e8a1874e1520be8d4c2620addd8d7df14", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/93276a4e8a1874e1520be8d4c2620addd8d7df14", "committedDate": "2020-01-29T22:00:32Z", "message": "feat: Adds lag reporting and API for use in lag aware routing as described in KLIP-12"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a3a29a0aa0f455a5ab3a09f9b8c6357755171bb4", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/a3a29a0aa0f455a5ab3a09f9b8c6357755171bb4", "committedDate": "2020-01-29T22:00:32Z", "message": "Uses new heartbeat listener"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ec5453909a6f9767e1f4a9a801e6302e40ca1667", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/ec5453909a6f9767e1f4a9a801e6302e40ca1667", "committedDate": "2020-01-29T22:00:32Z", "message": "Fixes style issues"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a6cb9870f2793cd4437a195318d4a9df381ed012", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/a6cb9870f2793cd4437a195318d4a9df381ed012", "committedDate": "2020-01-29T22:00:32Z", "message": "Remove prev warning removals"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e93ac04a82162493357e2566f738410c39e2e4c0", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/e93ac04a82162493357e2566f738410c39e2e4c0", "committedDate": "2020-01-29T22:00:32Z", "message": "Adds lagagent as a listener"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "82090fec74b2f3fbbf24e24064227a47c80f256f", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/82090fec74b2f3fbbf24e24064227a47c80f256f", "committedDate": "2020-01-29T22:00:32Z", "message": "Introduces simple LagCache"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "356ad508850ac96278a6509f09f44d8337a4bf66", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/356ad508850ac96278a6509f09f44d8337a4bf66", "committedDate": "2020-01-29T22:00:32Z", "message": "Some comments and simple changes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1e836b4aeaddbe057e849ad799851851c02467cf", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/1e836b4aeaddbe057e849ad799851851c02467cf", "committedDate": "2020-01-29T22:00:32Z", "message": "Only allows LagReportingAgent if HeartbeatAgent is enabled"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ccb70a97548e32cfbcfdfbbaca02fc5199bea606", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/ccb70a97548e32cfbcfdfbbaca02fc5199bea606", "committedDate": "2020-01-29T22:00:32Z", "message": "Adds Lag Reporting Functional test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "81f22e1475c2b96d25fdcd08ce68ebb01b5ffd11", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/81f22e1475c2b96d25fdcd08ce68ebb01b5ffd11", "committedDate": "2020-01-29T22:00:32Z", "message": "Style fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2ea201e0b2c4dad01784fdf61cf2da27cc85a7ca", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/2ea201e0b2c4dad01784fdf61cf2da27cc85a7ca", "committedDate": "2020-01-29T22:00:32Z", "message": "Adds LagInfoKey to keep track of lags"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "459360e4c8c2a898db9a8fae0edf58abd04df13c", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/459360e4c8c2a898db9a8fae0edf58abd04df13c", "committedDate": "2020-01-29T22:00:32Z", "message": "Style again"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4a4626ca708923973b7db8c5ad57a2bfd4a3b426", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/4a4626ca708923973b7db8c5ad57a2bfd4a3b426", "committedDate": "2020-01-29T22:00:33Z", "message": "Refactors to key by host"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e1b7d24c12993d66df884d8877161c68fb6ebd06", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/e1b7d24c12993d66df884d8877161c68fb6ebd06", "committedDate": "2020-01-29T22:00:33Z", "message": "Feedback"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "77d94fe6b0f3dd39ae46615318c47a94075098f8", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/77d94fe6b0f3dd39ae46615318c47a94075098f8", "committedDate": "2020-01-29T22:00:33Z", "message": "Feedback round 1"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "12603548682243e38577770e0badfd6bd6a9163d", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/12603548682243e38577770e0badfd6bd6a9163d", "committedDate": "2020-01-29T22:00:33Z", "message": "More feedback about consolidating cluster status"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1781831e03e3c047f1e3f61877debe08df05cbf9", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/1781831e03e3c047f1e3f61877debe08df05cbf9", "committedDate": "2020-01-29T22:00:33Z", "message": "Renamed HeartbeatListener to HostStatusListener"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "65b21a88c82c548bdf552baf36706af8515f5449", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/65b21a88c82c548bdf552baf36706af8515f5449", "committedDate": "2020-01-29T22:00:33Z", "message": "Adds empty set of live hosts to begin with"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e9e7d3ce0425d30560d7500e5c6f030b22a86928", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/e9e7d3ce0425d30560d7500e5c6f030b22a86928", "committedDate": "2020-01-29T22:00:33Z", "message": "Moves the null check so it's after getLocalLagMap"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f35a7bc1b66a327dbff1a52c0d775dce32d77fcd", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/f35a7bc1b66a327dbff1a52c0d775dce32d77fcd", "committedDate": "2020-01-29T22:00:33Z", "message": "Feedback from Almog"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d3e4f951c670028b925593aa13f654440e50ae3f", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/d3e4f951c670028b925593aa13f654440e50ae3f", "committedDate": "2020-01-28T01:12:08Z", "message": "Moves the null check so it's after getLocalLagMap"}, "afterCommit": {"oid": "f35a7bc1b66a327dbff1a52c0d775dce32d77fcd", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/f35a7bc1b66a327dbff1a52c0d775dce32d77fcd", "committedDate": "2020-01-29T22:00:33Z", "message": "Feedback from Almog"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ee30b2a4415b6e5fa20e33f7d61c8da9f5771b8a", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/ee30b2a4415b6e5fa20e33f7d61c8da9f5771b8a", "committedDate": "2020-01-30T01:00:14Z", "message": "Adds lags to ClusterStatusResponse.equals"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6201d14d273b11527c6a8b089738fa785e52a752", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/6201d14d273b11527c6a8b089738fa785e52a752", "committedDate": "2020-01-30T01:10:46Z", "message": "Changes separator to # rather than $"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 156, "cost": 1, "resetAt": "2021-11-01T13:07:16Z"}}}