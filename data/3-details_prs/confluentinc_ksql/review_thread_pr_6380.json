{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDk5NTU4OTYx", "number": 6380, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QyMjo1Njo0NlrOErYvZQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQwMTowMTowMVrOEraNwg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzOTI5NTczOnYy", "diffSide": "LEFT", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/schema/ksql/inference/DefaultSchemaInjector.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QyMjo1Njo0NlrOHeIXNw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QyMjo1Njo0NlrOHeIXNw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTM1NjM0Mw==", "bodyText": "This previous code had the following behavior: if VALUE_SCHEMA_ID was explicitly supplied by the user, then the create properties were not updated with the schema ID returned from the topic schema supplier. The new behavior is to always update the create properties with the schema ID returned from the topic schema supplier. Unless I'm mistaken, the topic schema supplier implementation always returns the same schema ID that was supplied, if relevant. Even if this changes in the future (not sure why it would), I think the new behavior is more accurate since the create properties after the injector runs reflect exactly what the engine is going to execute.", "url": "https://github.com/confluentinc/ksql/pull/6380#discussion_r501356343", "createdAt": "2020-10-07T22:56:46Z", "author": {"login": "vcrfxia"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/schema/ksql/inference/DefaultSchemaInjector.java", "diffHunk": "@@ -91,94 +94,167 @@ public DefaultSchemaInjector(final TopicSchemaSupplier schemaSupplier) {\n   private Optional<ConfiguredStatement<CreateSource>> forCreateStatement(\n       final ConfiguredStatement<CreateSource> statement\n   ) {\n-    if (hasValueElements(statement) || !valueFormatSupportsSchemaInference(statement)) {\n+    final Optional<SchemaAndId> keySchema = getKeySchema(statement);\n+    final Optional<SchemaAndId> valueSchema = getValueSchema(statement);\n+    if (!keySchema.isPresent() && !valueSchema.isPresent()) {\n       return Optional.empty();\n     }\n \n-    final SchemaAndId valueSchema = getValueSchema(statement);\n-    final CreateSource withSchema = addSchemaFields(statement, valueSchema);\n+    final CreateSource withSchema = addSchemaFields(statement, keySchema, valueSchema);\n     final PreparedStatement<CreateSource> prepared = buildPreparedStatement(withSchema);\n     final ConfiguredStatement<CreateSource> configured = ConfiguredStatement\n         .of(prepared, statement.getSessionConfig());\n \n     return Optional.of(configured);\n   }\n \n-  private SchemaAndId getValueSchema(\n+  private Optional<SchemaAndId> getKeySchema(\n       final ConfiguredStatement<CreateSource> statement\n   ) {\n     final CreateSourceProperties props = statement.getStatement().getProperties();\n+    final FormatInfo keyFormat = SourcePropertiesUtil.getKeyFormat(props);\n \n-    final FormatInfo expectedValueFormat = SourcePropertiesUtil.getValueFormat(props);\n+    if (hasKeyElements(statement) || !formatSupportsSchemaInference(keyFormat)) {\n+      return Optional.empty();\n+    }\n+\n+    return Optional.of(getSchema(\n+        props.getKafkaTopic(),\n+        props.getKeySchemaId(),\n+        keyFormat,\n+        statement.getStatementText(),\n+        true\n+    ));\n+  }\n+\n+  private Optional<SchemaAndId> getValueSchema(\n+      final ConfiguredStatement<CreateSource> statement\n+  ) {\n+    final CreateSourceProperties props = statement.getStatement().getProperties();\n+    final FormatInfo valueFormat = SourcePropertiesUtil.getValueFormat(props);\n \n-    final SchemaResult result = schemaSupplier\n-        .getValueSchema(props.getKafkaTopic(), props.getSchemaId(), expectedValueFormat);\n+    if (hasValueElements(statement) || !formatSupportsSchemaInference(valueFormat)) {\n+      return Optional.empty();\n+    }\n+\n+    return Optional.of(getSchema(\n+        props.getKafkaTopic(),\n+        props.getValueSchemaId(),\n+        valueFormat,\n+        statement.getStatementText(),\n+        false\n+    ));\n+  }\n+\n+  private SchemaAndId getSchema(\n+      final String topicName,\n+      final Optional<Integer> schemaId,\n+      final FormatInfo expectedFormat,\n+      final String statementText,\n+      final boolean isKey\n+  ) {\n+    final SchemaResult result = isKey\n+        ? schemaSupplier.getKeySchema(topicName, schemaId, expectedFormat)\n+        : schemaSupplier.getValueSchema(topicName, schemaId, expectedFormat);\n \n     if (result.failureReason.isPresent()) {\n       final Exception cause = result.failureReason.get();\n       throw new KsqlStatementException(\n           cause.getMessage(),\n-          statement.getStatementText(),\n+          statementText,\n           cause);\n     }\n \n     return result.schemaAndId.get();\n   }\n \n-  private static boolean hasValueElements(\n+  private static boolean hasKeyElements(\n       final ConfiguredStatement<CreateSource> statement\n   ) {\n     return statement.getStatement().getElements().stream()\n-        .anyMatch(e -> e.getNamespace().equals(Namespace.VALUE));\n+        .anyMatch(e -> e.getNamespace().isKey());\n   }\n \n-  private static boolean valueFormatSupportsSchemaInference(\n+  private static boolean hasValueElements(\n       final ConfiguredStatement<CreateSource> statement\n   ) {\n-    final FormatInfo valueFormat = SourcePropertiesUtil\n-        .getValueFormat(statement.getStatement().getProperties());\n+    return statement.getStatement().getElements().stream()\n+        .anyMatch(e -> !e.getNamespace().isKey());\n+  }\n \n-    return FormatFactory.of(valueFormat).supportsFeature(SerdeFeature.SCHEMA_INFERENCE);\n+  private static boolean formatSupportsSchemaInference(final FormatInfo format) {\n+    return FormatFactory.of(format).supportsFeature(SerdeFeature.SCHEMA_INFERENCE);\n   }\n \n   private static CreateSource addSchemaFields(\n       final ConfiguredStatement<CreateSource> preparedStatement,\n-      final SchemaAndId schema\n+      final Optional<SchemaAndId> keySchema,\n+      final Optional<SchemaAndId> valueSchema\n   ) {\n-    final TableElements elements = buildElements(schema.columns, preparedStatement);\n+    final TableElements elements = buildElements(preparedStatement, keySchema, valueSchema);\n \n     final CreateSource statement = preparedStatement.getStatement();\n     final CreateSourceProperties properties = statement.getProperties();\n \n-    if (properties.getSchemaId().isPresent()) {\n-      return statement.copyWith(elements, properties);\n-    }\n-    return statement.copyWith(elements, properties.withSchemaId(schema.id));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0f168f0deedd0a103c3b2a36ce9dd3ea8024086"}, "originalPosition": 166}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzOTQ4OTc2OnYy", "diffSide": "RIGHT", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/schema/ksql/inference/DefaultSchemaInjector.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQwMDozNDoxM1rOHeKHZw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQxMjo1MTowNlrOHec_nw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTM4NTA2Mw==", "bodyText": "I think that if we're going down the route of structs-as-keys, then this should not flatten into multiple table elements (I have yet to look at the SchemaSupplier code, I suspect that's what should be handling this). To ensure this, for now I think this should assert that there is no more than one key column.", "url": "https://github.com/confluentinc/ksql/pull/6380#discussion_r501385063", "createdAt": "2020-10-08T00:34:13Z", "author": {"login": "agavra"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/schema/ksql/inference/DefaultSchemaInjector.java", "diffHunk": "@@ -91,94 +94,167 @@ public DefaultSchemaInjector(final TopicSchemaSupplier schemaSupplier) {\n   private Optional<ConfiguredStatement<CreateSource>> forCreateStatement(\n       final ConfiguredStatement<CreateSource> statement\n   ) {\n-    if (hasValueElements(statement) || !valueFormatSupportsSchemaInference(statement)) {\n+    final Optional<SchemaAndId> keySchema = getKeySchema(statement);\n+    final Optional<SchemaAndId> valueSchema = getValueSchema(statement);\n+    if (!keySchema.isPresent() && !valueSchema.isPresent()) {\n       return Optional.empty();\n     }\n \n-    final SchemaAndId valueSchema = getValueSchema(statement);\n-    final CreateSource withSchema = addSchemaFields(statement, valueSchema);\n+    final CreateSource withSchema = addSchemaFields(statement, keySchema, valueSchema);\n     final PreparedStatement<CreateSource> prepared = buildPreparedStatement(withSchema);\n     final ConfiguredStatement<CreateSource> configured = ConfiguredStatement\n         .of(prepared, statement.getSessionConfig());\n \n     return Optional.of(configured);\n   }\n \n-  private SchemaAndId getValueSchema(\n+  private Optional<SchemaAndId> getKeySchema(\n       final ConfiguredStatement<CreateSource> statement\n   ) {\n     final CreateSourceProperties props = statement.getStatement().getProperties();\n+    final FormatInfo keyFormat = SourcePropertiesUtil.getKeyFormat(props);\n \n-    final FormatInfo expectedValueFormat = SourcePropertiesUtil.getValueFormat(props);\n+    if (hasKeyElements(statement) || !formatSupportsSchemaInference(keyFormat)) {\n+      return Optional.empty();\n+    }\n+\n+    return Optional.of(getSchema(\n+        props.getKafkaTopic(),\n+        props.getKeySchemaId(),\n+        keyFormat,\n+        statement.getStatementText(),\n+        true\n+    ));\n+  }\n+\n+  private Optional<SchemaAndId> getValueSchema(\n+      final ConfiguredStatement<CreateSource> statement\n+  ) {\n+    final CreateSourceProperties props = statement.getStatement().getProperties();\n+    final FormatInfo valueFormat = SourcePropertiesUtil.getValueFormat(props);\n \n-    final SchemaResult result = schemaSupplier\n-        .getValueSchema(props.getKafkaTopic(), props.getSchemaId(), expectedValueFormat);\n+    if (hasValueElements(statement) || !formatSupportsSchemaInference(valueFormat)) {\n+      return Optional.empty();\n+    }\n+\n+    return Optional.of(getSchema(\n+        props.getKafkaTopic(),\n+        props.getValueSchemaId(),\n+        valueFormat,\n+        statement.getStatementText(),\n+        false\n+    ));\n+  }\n+\n+  private SchemaAndId getSchema(\n+      final String topicName,\n+      final Optional<Integer> schemaId,\n+      final FormatInfo expectedFormat,\n+      final String statementText,\n+      final boolean isKey\n+  ) {\n+    final SchemaResult result = isKey\n+        ? schemaSupplier.getKeySchema(topicName, schemaId, expectedFormat)\n+        : schemaSupplier.getValueSchema(topicName, schemaId, expectedFormat);\n \n     if (result.failureReason.isPresent()) {\n       final Exception cause = result.failureReason.get();\n       throw new KsqlStatementException(\n           cause.getMessage(),\n-          statement.getStatementText(),\n+          statementText,\n           cause);\n     }\n \n     return result.schemaAndId.get();\n   }\n \n-  private static boolean hasValueElements(\n+  private static boolean hasKeyElements(\n       final ConfiguredStatement<CreateSource> statement\n   ) {\n     return statement.getStatement().getElements().stream()\n-        .anyMatch(e -> e.getNamespace().equals(Namespace.VALUE));\n+        .anyMatch(e -> e.getNamespace().isKey());\n   }\n \n-  private static boolean valueFormatSupportsSchemaInference(\n+  private static boolean hasValueElements(\n       final ConfiguredStatement<CreateSource> statement\n   ) {\n-    final FormatInfo valueFormat = SourcePropertiesUtil\n-        .getValueFormat(statement.getStatement().getProperties());\n+    return statement.getStatement().getElements().stream()\n+        .anyMatch(e -> !e.getNamespace().isKey());\n+  }\n \n-    return FormatFactory.of(valueFormat).supportsFeature(SerdeFeature.SCHEMA_INFERENCE);\n+  private static boolean formatSupportsSchemaInference(final FormatInfo format) {\n+    return FormatFactory.of(format).supportsFeature(SerdeFeature.SCHEMA_INFERENCE);\n   }\n \n   private static CreateSource addSchemaFields(\n       final ConfiguredStatement<CreateSource> preparedStatement,\n-      final SchemaAndId schema\n+      final Optional<SchemaAndId> keySchema,\n+      final Optional<SchemaAndId> valueSchema\n   ) {\n-    final TableElements elements = buildElements(schema.columns, preparedStatement);\n+    final TableElements elements = buildElements(preparedStatement, keySchema, valueSchema);\n \n     final CreateSource statement = preparedStatement.getStatement();\n     final CreateSourceProperties properties = statement.getProperties();\n \n-    if (properties.getSchemaId().isPresent()) {\n-      return statement.copyWith(elements, properties);\n-    }\n-    return statement.copyWith(elements, properties.withSchemaId(schema.id));\n+    final CreateSourceProperties withSchemaIds = properties.withSchemaIds(\n+        keySchema.map(s -> s.id),\n+        valueSchema.map(s -> s.id));\n+    return statement.copyWith(elements, withSchemaIds);\n   }\n \n   private static TableElements buildElements(\n-      final List<? extends SimpleColumn> valueColumns,\n-      final ConfiguredStatement<CreateSource> preparedStatement\n+      final ConfiguredStatement<CreateSource> preparedStatement,\n+      final Optional<SchemaAndId> keySchema,\n+      final Optional<SchemaAndId> valueSchema\n   ) {\n     final List<TableElement> elements = new ArrayList<>();\n \n-    getKeyColumns(preparedStatement)\n-        .forEach(elements::add);\n+    if (keySchema.isPresent()) {\n+      final Namespace namespace = getKeyNamespace(preparedStatement.getStatement());\n+      keySchema.get().columns.stream()\n+          .map(col -> new TableElement(namespace, col.name(), new Type(col.type())))\n+          .forEach(elements::add);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0f168f0deedd0a103c3b2a36ce9dd3ea8024086"}, "originalPosition": 188}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTY5NDM2Nw==", "bodyText": "Is the schema injector the right place for this assertion? I was under the impression that the schema injector should just blindly populate columns based on schemas from Schema Registry, and that the engine should be responsible for validation. The engine already validates that only a single key column is present.", "url": "https://github.com/confluentinc/ksql/pull/6380#discussion_r501694367", "createdAt": "2020-10-08T12:51:06Z", "author": {"login": "vcrfxia"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/schema/ksql/inference/DefaultSchemaInjector.java", "diffHunk": "@@ -91,94 +94,167 @@ public DefaultSchemaInjector(final TopicSchemaSupplier schemaSupplier) {\n   private Optional<ConfiguredStatement<CreateSource>> forCreateStatement(\n       final ConfiguredStatement<CreateSource> statement\n   ) {\n-    if (hasValueElements(statement) || !valueFormatSupportsSchemaInference(statement)) {\n+    final Optional<SchemaAndId> keySchema = getKeySchema(statement);\n+    final Optional<SchemaAndId> valueSchema = getValueSchema(statement);\n+    if (!keySchema.isPresent() && !valueSchema.isPresent()) {\n       return Optional.empty();\n     }\n \n-    final SchemaAndId valueSchema = getValueSchema(statement);\n-    final CreateSource withSchema = addSchemaFields(statement, valueSchema);\n+    final CreateSource withSchema = addSchemaFields(statement, keySchema, valueSchema);\n     final PreparedStatement<CreateSource> prepared = buildPreparedStatement(withSchema);\n     final ConfiguredStatement<CreateSource> configured = ConfiguredStatement\n         .of(prepared, statement.getSessionConfig());\n \n     return Optional.of(configured);\n   }\n \n-  private SchemaAndId getValueSchema(\n+  private Optional<SchemaAndId> getKeySchema(\n       final ConfiguredStatement<CreateSource> statement\n   ) {\n     final CreateSourceProperties props = statement.getStatement().getProperties();\n+    final FormatInfo keyFormat = SourcePropertiesUtil.getKeyFormat(props);\n \n-    final FormatInfo expectedValueFormat = SourcePropertiesUtil.getValueFormat(props);\n+    if (hasKeyElements(statement) || !formatSupportsSchemaInference(keyFormat)) {\n+      return Optional.empty();\n+    }\n+\n+    return Optional.of(getSchema(\n+        props.getKafkaTopic(),\n+        props.getKeySchemaId(),\n+        keyFormat,\n+        statement.getStatementText(),\n+        true\n+    ));\n+  }\n+\n+  private Optional<SchemaAndId> getValueSchema(\n+      final ConfiguredStatement<CreateSource> statement\n+  ) {\n+    final CreateSourceProperties props = statement.getStatement().getProperties();\n+    final FormatInfo valueFormat = SourcePropertiesUtil.getValueFormat(props);\n \n-    final SchemaResult result = schemaSupplier\n-        .getValueSchema(props.getKafkaTopic(), props.getSchemaId(), expectedValueFormat);\n+    if (hasValueElements(statement) || !formatSupportsSchemaInference(valueFormat)) {\n+      return Optional.empty();\n+    }\n+\n+    return Optional.of(getSchema(\n+        props.getKafkaTopic(),\n+        props.getValueSchemaId(),\n+        valueFormat,\n+        statement.getStatementText(),\n+        false\n+    ));\n+  }\n+\n+  private SchemaAndId getSchema(\n+      final String topicName,\n+      final Optional<Integer> schemaId,\n+      final FormatInfo expectedFormat,\n+      final String statementText,\n+      final boolean isKey\n+  ) {\n+    final SchemaResult result = isKey\n+        ? schemaSupplier.getKeySchema(topicName, schemaId, expectedFormat)\n+        : schemaSupplier.getValueSchema(topicName, schemaId, expectedFormat);\n \n     if (result.failureReason.isPresent()) {\n       final Exception cause = result.failureReason.get();\n       throw new KsqlStatementException(\n           cause.getMessage(),\n-          statement.getStatementText(),\n+          statementText,\n           cause);\n     }\n \n     return result.schemaAndId.get();\n   }\n \n-  private static boolean hasValueElements(\n+  private static boolean hasKeyElements(\n       final ConfiguredStatement<CreateSource> statement\n   ) {\n     return statement.getStatement().getElements().stream()\n-        .anyMatch(e -> e.getNamespace().equals(Namespace.VALUE));\n+        .anyMatch(e -> e.getNamespace().isKey());\n   }\n \n-  private static boolean valueFormatSupportsSchemaInference(\n+  private static boolean hasValueElements(\n       final ConfiguredStatement<CreateSource> statement\n   ) {\n-    final FormatInfo valueFormat = SourcePropertiesUtil\n-        .getValueFormat(statement.getStatement().getProperties());\n+    return statement.getStatement().getElements().stream()\n+        .anyMatch(e -> !e.getNamespace().isKey());\n+  }\n \n-    return FormatFactory.of(valueFormat).supportsFeature(SerdeFeature.SCHEMA_INFERENCE);\n+  private static boolean formatSupportsSchemaInference(final FormatInfo format) {\n+    return FormatFactory.of(format).supportsFeature(SerdeFeature.SCHEMA_INFERENCE);\n   }\n \n   private static CreateSource addSchemaFields(\n       final ConfiguredStatement<CreateSource> preparedStatement,\n-      final SchemaAndId schema\n+      final Optional<SchemaAndId> keySchema,\n+      final Optional<SchemaAndId> valueSchema\n   ) {\n-    final TableElements elements = buildElements(schema.columns, preparedStatement);\n+    final TableElements elements = buildElements(preparedStatement, keySchema, valueSchema);\n \n     final CreateSource statement = preparedStatement.getStatement();\n     final CreateSourceProperties properties = statement.getProperties();\n \n-    if (properties.getSchemaId().isPresent()) {\n-      return statement.copyWith(elements, properties);\n-    }\n-    return statement.copyWith(elements, properties.withSchemaId(schema.id));\n+    final CreateSourceProperties withSchemaIds = properties.withSchemaIds(\n+        keySchema.map(s -> s.id),\n+        valueSchema.map(s -> s.id));\n+    return statement.copyWith(elements, withSchemaIds);\n   }\n \n   private static TableElements buildElements(\n-      final List<? extends SimpleColumn> valueColumns,\n-      final ConfiguredStatement<CreateSource> preparedStatement\n+      final ConfiguredStatement<CreateSource> preparedStatement,\n+      final Optional<SchemaAndId> keySchema,\n+      final Optional<SchemaAndId> valueSchema\n   ) {\n     final List<TableElement> elements = new ArrayList<>();\n \n-    getKeyColumns(preparedStatement)\n-        .forEach(elements::add);\n+    if (keySchema.isPresent()) {\n+      final Namespace namespace = getKeyNamespace(preparedStatement.getStatement());\n+      keySchema.get().columns.stream()\n+          .map(col -> new TableElement(namespace, col.name(), new Type(col.type())))\n+          .forEach(elements::add);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTM4NTA2Mw=="}, "originalCommit": {"oid": "e0f168f0deedd0a103c3b2a36ce9dd3ea8024086"}, "originalPosition": 188}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzOTUwMTk5OnYy", "diffSide": "RIGHT", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/schema/ksql/inference/SchemaRegistryTopicSchemaSupplier.java", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQwMDo0MTowMVrOHeKOeg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOVQxNDoxNDowM1rOHfLixA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTM4Njg3NA==", "bodyText": "as I alluded to above, I think the behavior here needs to be different for keys/values. Namely, when we call the translator.toColumns(parsedSchema) we should only ever return one column for keys.\nI think we can leave that for a separate PR, and for this PR we can just assert that it only returns one column (i.e. we only support primitive keys and single field structs)", "url": "https://github.com/confluentinc/ksql/pull/6380#discussion_r501386874", "createdAt": "2020-10-08T00:41:01Z", "author": {"login": "agavra"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/schema/ksql/inference/SchemaRegistryTopicSchemaSupplier.java", "diffHunk": "@@ -74,52 +93,57 @@ public SchemaResult getValueSchema(\n       }\n \n       final ParsedSchema schema = srClient.getSchemaBySubjectAndId(subject, id);\n-      return fromParsedSchema(topicName, id, schema, expectedFormat);\n+      return fromParsedSchema(topicName, id, schema, expectedFormat, isKey);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0f168f0deedd0a103c3b2a36ce9dd3ea8024086"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTY5NDg1MA==", "bodyText": "Same question as above -- does it make sense to have that type of validation in the schema supplier, rather than in the engine? Seems like we'd be duplicating validation logic by adding it here as well.", "url": "https://github.com/confluentinc/ksql/pull/6380#discussion_r501694850", "createdAt": "2020-10-08T12:51:55Z", "author": {"login": "vcrfxia"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/schema/ksql/inference/SchemaRegistryTopicSchemaSupplier.java", "diffHunk": "@@ -74,52 +93,57 @@ public SchemaResult getValueSchema(\n       }\n \n       final ParsedSchema schema = srClient.getSchemaBySubjectAndId(subject, id);\n-      return fromParsedSchema(topicName, id, schema, expectedFormat);\n+      return fromParsedSchema(topicName, id, schema, expectedFormat, isKey);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTM4Njg3NA=="}, "originalCommit": {"oid": "e0f168f0deedd0a103c3b2a36ce9dd3ea8024086"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTgxMjcxMA==", "bodyText": "I think it makes sense to include it here but not in the schema injector (which is why I said perhaps this should be done in SchemaSupplier). The reason for that is that there are two separate pieces of logic: (1) how do we translate a connect schema to a ksqlDB schema and (2) do we support multi-column ksqlDB key schemas?\nTo me, they're different because I could decided that (1) should either (a) always convert a schema into a single column struct or (b) always convert a struct schema to multiple columns. That's orthogonal to how we decide (2) - in fact we could support (2) with either 1a or 1b.\nThe reason I think we need the assertion here for this PR is that we haven't chosen between 1a and 1b - so it makes sense to fail early.", "url": "https://github.com/confluentinc/ksql/pull/6380#discussion_r501812710", "createdAt": "2020-10-08T15:28:35Z", "author": {"login": "agavra"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/schema/ksql/inference/SchemaRegistryTopicSchemaSupplier.java", "diffHunk": "@@ -74,52 +93,57 @@ public SchemaResult getValueSchema(\n       }\n \n       final ParsedSchema schema = srClient.getSchemaBySubjectAndId(subject, id);\n-      return fromParsedSchema(topicName, id, schema, expectedFormat);\n+      return fromParsedSchema(topicName, id, schema, expectedFormat, isKey);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTM4Njg3NA=="}, "originalCommit": {"oid": "e0f168f0deedd0a103c3b2a36ce9dd3ea8024086"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTgxNDAzNw==", "bodyText": "The other reason is that the error here can make more sense. We can fail with \"your schema in schema registry has multiple columns, we do not support inference for such schemas...\" vs. getting an error at the engine \"ksqlDB does not support multiple key columns\"", "url": "https://github.com/confluentinc/ksql/pull/6380#discussion_r501814037", "createdAt": "2020-10-08T15:30:28Z", "author": {"login": "agavra"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/schema/ksql/inference/SchemaRegistryTopicSchemaSupplier.java", "diffHunk": "@@ -74,52 +93,57 @@ public SchemaResult getValueSchema(\n       }\n \n       final ParsedSchema schema = srClient.getSchemaBySubjectAndId(subject, id);\n-      return fromParsedSchema(topicName, id, schema, expectedFormat);\n+      return fromParsedSchema(topicName, id, schema, expectedFormat, isKey);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTM4Njg3NA=="}, "originalCommit": {"oid": "e0f168f0deedd0a103c3b2a36ce9dd3ea8024086"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjQ1NzAyOA==", "bodyText": "Sure, I'm convinced -- updated the schema supplier to fail if multiple key columns are found.", "url": "https://github.com/confluentinc/ksql/pull/6380#discussion_r502457028", "createdAt": "2020-10-09T14:14:03Z", "author": {"login": "vcrfxia"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/schema/ksql/inference/SchemaRegistryTopicSchemaSupplier.java", "diffHunk": "@@ -74,52 +93,57 @@ public SchemaResult getValueSchema(\n       }\n \n       final ParsedSchema schema = srClient.getSchemaBySubjectAndId(subject, id);\n-      return fromParsedSchema(topicName, id, schema, expectedFormat);\n+      return fromParsedSchema(topicName, id, schema, expectedFormat, isKey);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTM4Njg3NA=="}, "originalCommit": {"oid": "e0f168f0deedd0a103c3b2a36ce9dd3ea8024086"}, "originalPosition": 47}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzOTUzNzMwOnYy", "diffSide": "RIGHT", "path": "ksqldb-engine/src/main/java/io/confluent/ksql/schema/ksql/inference/SchemaRegistryTopicSchemaSupplier.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOFQwMTowMTowMVrOHeKinw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOVQxNDoxNjowNlrOHfLn3w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTM5MjAzMQ==", "bodyText": "nit: I used this pattern quite a bit, maybe we should move it to a util and refactor this? (and then we can also make SCHEMA_REGISTRY_*_SUFFIX private and just use this method) can be done in follow-up PR", "url": "https://github.com/confluentinc/ksql/pull/6380#discussion_r501392031", "createdAt": "2020-10-08T01:01:01Z", "author": {"login": "agavra"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/schema/ksql/inference/SchemaRegistryTopicSchemaSupplier.java", "diffHunk": "@@ -175,4 +201,11 @@ private static SchemaResult notCompatible(\n             + \"Schema:\" + schema,\n         cause));\n   }\n+\n+  private static String getSubject(final String topicName, final boolean isKey) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e0f168f0deedd0a103c3b2a36ce9dd3ea8024086"}, "originalPosition": 157}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjQ1ODMzNQ==", "bodyText": "I only see two uses of SCHEMA_REGISTRY_KEY_SUFFIX in the codebase so I've extracted those into a util method and made the constant private. However, there are a bunch of other uses of SCHEMA_REGISTRY_VALUE_SUFFIX that I want to leave for now to make it easier to audit to ensure proper handling of key schemas (at least parity with value schemas) so I've left those in for now. We can finish this refactor in a follow-up PR once the other bits of key schema support are in. Tracking in #6395", "url": "https://github.com/confluentinc/ksql/pull/6380#discussion_r502458335", "createdAt": "2020-10-09T14:16:06Z", "author": {"login": "vcrfxia"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/schema/ksql/inference/SchemaRegistryTopicSchemaSupplier.java", "diffHunk": "@@ -175,4 +201,11 @@ private static SchemaResult notCompatible(\n             + \"Schema:\" + schema,\n         cause));\n   }\n+\n+  private static String getSubject(final String topicName, final boolean isKey) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTM5MjAzMQ=="}, "originalCommit": {"oid": "e0f168f0deedd0a103c3b2a36ce9dd3ea8024086"}, "originalPosition": 157}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2680, "cost": 1, "resetAt": "2021-11-12T19:05:54Z"}}}