{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzYzMTgyODc1", "number": 4320, "reviewThreads": {"totalCount": 64, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMDowMjoyNlrODYS76g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QyMDowMzowNVrODY7LHw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI2ODAyNjY2OnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerVerticle.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMDowMjoyNlrOFeEwZg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQwNDozNzo1MFrOFeNycA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA3OTUyNg==", "bodyText": "Could we consider camelCase instead of kebab-case for the metadata object keys?\nI have the JS client in mind, where it would be more natural to operate on objects with the former.\nconst { columnNames, columnTypes } = queryMetadata;\n// vs\nconst columnNames = queryMetadata[\"column-names\"];\nconst columnTypes = queryMetadata[\"column-types\"];", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367079526", "createdAt": "2020-01-15T20:02:26Z", "author": {"login": "colinhicks"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerVerticle.java", "diffHunk": "@@ -0,0 +1,201 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.impl.Utils;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.QueryPublisher;\n+import io.vertx.core.AbstractVerticle;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Promise;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpMethod;\n+import io.vertx.core.http.HttpServer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.parsetools.RecordParser;\n+import io.vertx.ext.web.Router;\n+import io.vertx.ext.web.RoutingContext;\n+import io.vertx.ext.web.handler.BodyHandler;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * The server deploys multiple server verticles. This is where the HTTP2 requests are handled. The\n+ * actual implementation of the endpoints is provided by an implementation of {@code Endpoints}.\n+ */\n+public class ServerVerticle extends AbstractVerticle {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ServerVerticle.class);\n+\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Server server;\n+  private final Map<HttpConnection, ConnectionQueries> connectionsMap = new HashMap<>();\n+  private HttpServer httpServer;\n+\n+  public ServerVerticle(final Endpoints endpoints, final HttpServerOptions httpServerOptions,\n+      final Server server) {\n+    this.endpoints = endpoints;\n+    this.httpServerOptions = httpServerOptions;\n+    this.server = server;\n+  }\n+\n+  @Override\n+  public void start(final Promise<Void> startPromise) {\n+    httpServer = vertx.createHttpServer(httpServerOptions).requestHandler(setupRouter());\n+    httpServer.exceptionHandler(ServerUtils::handleException);\n+    Future<HttpServer> listenFuture = Promise.<HttpServer>promise().future();\n+    Utils.connectPromise(listenFuture.map(s -> null), startPromise);\n+    httpServer.listen(listenFuture);\n+    vertx.getOrCreateContext().exceptionHandler(ServerUtils::handleException);\n+  }\n+\n+  @Override\n+  public void stop(final Promise<Void> stopPromise) {\n+    if (httpServer == null) {\n+      stopPromise.complete();\n+    } else {\n+      httpServer.close(stopPromise.future());\n+    }\n+  }\n+\n+  private Router setupRouter() {\n+    Router router = Router.router(vertx);\n+    router.route(HttpMethod.POST, \"/query-stream\").handler(BodyHandler.create())\n+        .handler(this::handleQueryStream);\n+    router.route(HttpMethod.POST, \"/inserts-stream\").handler(this::handleInsertsStream);\n+    router.route(HttpMethod.POST, \"/close-query\").handler(BodyHandler.create())\n+        .handler(this::handleCloseQuery);\n+    return router;\n+  }\n+\n+  private void handleInsertsStream(final RoutingContext routingContext) {\n+    RecordParser recordParser = RecordParser\n+        .newDelimited(\"\\n\", new InsertsBodyParser(endpoints, routingContext)::handleBodyBuffer);\n+    routingContext.request()\n+        .handler(recordParser);\n+  }\n+\n+  private void handleQueryStream(final RoutingContext routingContext) {\n+    HttpConnection conn = routingContext.request().connection();\n+    ConnectionQueries connectionQueries = connectionsMap.get(conn);\n+    if (connectionQueries == null) {\n+      connectionQueries = new ConnectionQueries(conn);\n+      connectionsMap.put(conn, connectionQueries);\n+      conn.closeHandler(connectionQueries);\n+      server.registerQueryConnection(conn);\n+    }\n+    JsonObject requestBody = routingContext.getBodyAsJson();\n+    String sql = requestBody.getString(\"sql\");\n+    if (sql == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No sql in arguments\");\n+      return;\n+    }\n+    Boolean push = requestBody.getBoolean(\"push\");\n+    if (push == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No push in arguments\");\n+      return;\n+    }\n+    JsonObject properties = requestBody.getJsonObject(\"properties\");\n+    QueryPublisher queryPublisher = endpoints.createQueryPublisher(sql, push, properties);\n+    QuerySubscriber querySubscriber = new QuerySubscriber(routingContext.response());\n+\n+    String queryID = server.registerQuery(querySubscriber);\n+    connectionQueries.addQuery(queryID);\n+    JsonObject metadata = new JsonObject();\n+    metadata.put(\"column-names\", queryPublisher.getColumnNames());\n+    metadata.put(\"column-types\", queryPublisher.getColumnTypes());\n+    metadata.put(\"query-id\", queryID);\n+    if (!push) {\n+      metadata.put(\"row-count\", queryPublisher.getRowCount());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c40735e2be6944f3ccbb84adf34c0b4c64abd139"}, "originalPosition": 133}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzIyNzUwNA==", "bodyText": "+1 on camelCase - would be friendlier for JS.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367227504", "createdAt": "2020-01-16T04:37:50Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerVerticle.java", "diffHunk": "@@ -0,0 +1,201 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.impl.Utils;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.QueryPublisher;\n+import io.vertx.core.AbstractVerticle;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Promise;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpMethod;\n+import io.vertx.core.http.HttpServer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.parsetools.RecordParser;\n+import io.vertx.ext.web.Router;\n+import io.vertx.ext.web.RoutingContext;\n+import io.vertx.ext.web.handler.BodyHandler;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * The server deploys multiple server verticles. This is where the HTTP2 requests are handled. The\n+ * actual implementation of the endpoints is provided by an implementation of {@code Endpoints}.\n+ */\n+public class ServerVerticle extends AbstractVerticle {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ServerVerticle.class);\n+\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Server server;\n+  private final Map<HttpConnection, ConnectionQueries> connectionsMap = new HashMap<>();\n+  private HttpServer httpServer;\n+\n+  public ServerVerticle(final Endpoints endpoints, final HttpServerOptions httpServerOptions,\n+      final Server server) {\n+    this.endpoints = endpoints;\n+    this.httpServerOptions = httpServerOptions;\n+    this.server = server;\n+  }\n+\n+  @Override\n+  public void start(final Promise<Void> startPromise) {\n+    httpServer = vertx.createHttpServer(httpServerOptions).requestHandler(setupRouter());\n+    httpServer.exceptionHandler(ServerUtils::handleException);\n+    Future<HttpServer> listenFuture = Promise.<HttpServer>promise().future();\n+    Utils.connectPromise(listenFuture.map(s -> null), startPromise);\n+    httpServer.listen(listenFuture);\n+    vertx.getOrCreateContext().exceptionHandler(ServerUtils::handleException);\n+  }\n+\n+  @Override\n+  public void stop(final Promise<Void> stopPromise) {\n+    if (httpServer == null) {\n+      stopPromise.complete();\n+    } else {\n+      httpServer.close(stopPromise.future());\n+    }\n+  }\n+\n+  private Router setupRouter() {\n+    Router router = Router.router(vertx);\n+    router.route(HttpMethod.POST, \"/query-stream\").handler(BodyHandler.create())\n+        .handler(this::handleQueryStream);\n+    router.route(HttpMethod.POST, \"/inserts-stream\").handler(this::handleInsertsStream);\n+    router.route(HttpMethod.POST, \"/close-query\").handler(BodyHandler.create())\n+        .handler(this::handleCloseQuery);\n+    return router;\n+  }\n+\n+  private void handleInsertsStream(final RoutingContext routingContext) {\n+    RecordParser recordParser = RecordParser\n+        .newDelimited(\"\\n\", new InsertsBodyParser(endpoints, routingContext)::handleBodyBuffer);\n+    routingContext.request()\n+        .handler(recordParser);\n+  }\n+\n+  private void handleQueryStream(final RoutingContext routingContext) {\n+    HttpConnection conn = routingContext.request().connection();\n+    ConnectionQueries connectionQueries = connectionsMap.get(conn);\n+    if (connectionQueries == null) {\n+      connectionQueries = new ConnectionQueries(conn);\n+      connectionsMap.put(conn, connectionQueries);\n+      conn.closeHandler(connectionQueries);\n+      server.registerQueryConnection(conn);\n+    }\n+    JsonObject requestBody = routingContext.getBodyAsJson();\n+    String sql = requestBody.getString(\"sql\");\n+    if (sql == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No sql in arguments\");\n+      return;\n+    }\n+    Boolean push = requestBody.getBoolean(\"push\");\n+    if (push == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No push in arguments\");\n+      return;\n+    }\n+    JsonObject properties = requestBody.getJsonObject(\"properties\");\n+    QueryPublisher queryPublisher = endpoints.createQueryPublisher(sql, push, properties);\n+    QuerySubscriber querySubscriber = new QuerySubscriber(routingContext.response());\n+\n+    String queryID = server.registerQuery(querySubscriber);\n+    connectionQueries.addQuery(queryID);\n+    JsonObject metadata = new JsonObject();\n+    metadata.put(\"column-names\", queryPublisher.getColumnNames());\n+    metadata.put(\"column-types\", queryPublisher.getColumnTypes());\n+    metadata.put(\"query-id\", queryID);\n+    if (!push) {\n+      metadata.put(\"row-count\", queryPublisher.getRowCount());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA3OTUyNg=="}, "originalCommit": {"oid": "c40735e2be6944f3ccbb84adf34c0b4c64abd139"}, "originalPosition": 133}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MDEwNDE2OnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMjo1Nzo1NVrOFeYeLg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMFQxNjoxNjozNVrOFfjYew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwMjU0Mg==", "bodyText": "nit: null check params.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367402542", "createdAt": "2020-01-16T12:57:55Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "diffHunk": "@@ -0,0 +1,110 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerResponse;\n+import io.vertx.core.json.JsonObject;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * As the stream of inserts is processed by the back-end, it communicates success (or failure) of\n+ * each insert by sending a stream of acks back in the other direction. This class is the subscriber\n+ * which subscribes to that stream of acks and sends them back to the client. It's a reactive\n+ * streams subscriber so implements back pressure.\n+ */\n+public class AcksSubscriber implements Subscriber<Void> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n+  private static final int BATCH_SIZE = 4;\n+  private static final Buffer ACK_RESPONSE_LINE = new JsonObject().put(\"status\", \"ok\").toBuffer()\n+      .appendString(\"\\n\");\n+\n+  private final HttpServerResponse response;\n+  private Subscription subscription;\n+  private long tokens;\n+  private Long insertsSent;\n+  private long acksSent;\n+\n+  public AcksSubscriber(final HttpServerResponse response) {\n+    this.response = response;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc3MDY3Mg==", "bodyText": "I don't think you're ever going to give up with the null check comments ;)\nAs you know, I don't really agree with null checking args for internal classes (external APIs, yes), but in the interests of an easy life and simpler reviews I'm just going to swallow my pride and conform.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367770672", "createdAt": "2020-01-17T05:05:26Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "diffHunk": "@@ -0,0 +1,110 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerResponse;\n+import io.vertx.core.json.JsonObject;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * As the stream of inserts is processed by the back-end, it communicates success (or failure) of\n+ * each insert by sending a stream of acks back in the other direction. This class is the subscriber\n+ * which subscribes to that stream of acks and sends them back to the client. It's a reactive\n+ * streams subscriber so implements back pressure.\n+ */\n+public class AcksSubscriber implements Subscriber<Void> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n+  private static final int BATCH_SIZE = 4;\n+  private static final Buffer ACK_RESPONSE_LINE = new JsonObject().put(\"status\", \"ok\").toBuffer()\n+      .appendString(\"\\n\");\n+\n+  private final HttpServerResponse response;\n+  private Subscription subscription;\n+  private long tokens;\n+  private Long insertsSent;\n+  private long acksSent;\n+\n+  public AcksSubscriber(final HttpServerResponse response) {\n+    this.response = response;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwMjU0Mg=="}, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODYyOTg4Mw==", "bodyText": "Thanks. We can discuss more over a pint some time.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368629883", "createdAt": "2020-01-20T16:16:35Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "diffHunk": "@@ -0,0 +1,110 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerResponse;\n+import io.vertx.core.json.JsonObject;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * As the stream of inserts is processed by the back-end, it communicates success (or failure) of\n+ * each insert by sending a stream of acks back in the other direction. This class is the subscriber\n+ * which subscribes to that stream of acks and sends them back to the client. It's a reactive\n+ * streams subscriber so implements back pressure.\n+ */\n+public class AcksSubscriber implements Subscriber<Void> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n+  private static final int BATCH_SIZE = 4;\n+  private static final Buffer ACK_RESPONSE_LINE = new JsonObject().put(\"status\", \"ok\").toBuffer()\n+      .appendString(\"\\n\");\n+\n+  private final HttpServerResponse response;\n+  private Subscription subscription;\n+  private long tokens;\n+  private Long insertsSent;\n+  private long acksSent;\n+\n+  public AcksSubscriber(final HttpServerResponse response) {\n+    this.response = response;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwMjU0Mg=="}, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 48}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MDEwNTEwOnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMjo1ODoxMVrOFeYesg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMjo1ODoxMVrOFeYesg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwMjY3NA==", "bodyText": "nit: null check params.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367402674", "createdAt": "2020-01-16T12:58:11Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "diffHunk": "@@ -0,0 +1,110 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerResponse;\n+import io.vertx.core.json.JsonObject;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * As the stream of inserts is processed by the back-end, it communicates success (or failure) of\n+ * each insert by sending a stream of acks back in the other direction. This class is the subscriber\n+ * which subscribes to that stream of acks and sends them back to the client. It's a reactive\n+ * streams subscriber so implements back pressure.\n+ */\n+public class AcksSubscriber implements Subscriber<Void> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n+  private static final int BATCH_SIZE = 4;\n+  private static final Buffer ACK_RESPONSE_LINE = new JsonObject().put(\"status\", \"ok\").toBuffer()\n+      .appendString(\"\\n\");\n+\n+  private final HttpServerResponse response;\n+  private Subscription subscription;\n+  private long tokens;\n+  private Long insertsSent;\n+  private long acksSent;\n+\n+  public AcksSubscriber(final HttpServerResponse response) {\n+    this.response = response;\n+  }\n+\n+  @Override\n+  public synchronized void onSubscribe(final Subscription subscription) {\n+    if (this.subscription != null) {\n+      throw new IllegalStateException(\"Already subscribed\");\n+    }\n+    this.subscription = subscription;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 56}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MDEwOTgzOnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyParser.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMjo1OTo1NFrOFeYhlA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMjo1OTo1NFrOFeYhlA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwMzQxMg==", "bodyText": "nit: null check params.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367403412", "createdAt": "2020-01-16T12:59:54Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyParser.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.InsertsSubscriber;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.ext.web.RoutingContext;\n+\n+/**\n+ * This class handles the parsing of the request body for a stream of inserts. The user can send a\n+ * stream of inserts to the server by opening an HTTP2 request to the server at the appropriate uri\n+ * and POSTing a request. The request must contain an initial JSON object (encoded as UTF-8 text)\n+ * which contains the arguments for the request (e.g. the target to insert into, and whether acks\n+ * are wanted) This must be followed by a new line, and then followed by zero or more JSON objects\n+ * (also encoded as UTF-8 text) each representing a row to insert. The last JSON object must be\n+ * followed by a new-line.\n+ */\n+public class InsertsBodyParser {\n+\n+  private final Endpoints endpoints;\n+  private final RoutingContext routingContext;\n+  private boolean readArguments;\n+  private InsertsPublisher publisher;\n+  private long rowsReceived;\n+  private AcksSubscriber acksSubscriber;\n+\n+  public InsertsBodyParser(final Endpoints endpoints, final RoutingContext routingContext) {\n+    this.endpoints = endpoints;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 46}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MDExNDc1OnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyParser.java", "isResolved": false, "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzowMTo1MFrOFeYkmg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMFQyMTowNTowOVrOFfpNfw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwNDE4Ng==", "bodyText": "Could we deserialize the JSON in POJOs? I think this would make the code more readable and maintainable.  It's also self documenting on what's expected, i.e. users can dig into the code to see, or we can build the docs from the POJOs.\nWhat do you think?", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367404186", "createdAt": "2020-01-16T13:01:50Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyParser.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.InsertsSubscriber;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.ext.web.RoutingContext;\n+\n+/**\n+ * This class handles the parsing of the request body for a stream of inserts. The user can send a\n+ * stream of inserts to the server by opening an HTTP2 request to the server at the appropriate uri\n+ * and POSTing a request. The request must contain an initial JSON object (encoded as UTF-8 text)\n+ * which contains the arguments for the request (e.g. the target to insert into, and whether acks\n+ * are wanted) This must be followed by a new line, and then followed by zero or more JSON objects\n+ * (also encoded as UTF-8 text) each representing a row to insert. The last JSON object must be\n+ * followed by a new-line.\n+ */\n+public class InsertsBodyParser {\n+\n+  private final Endpoints endpoints;\n+  private final RoutingContext routingContext;\n+  private boolean readArguments;\n+  private InsertsPublisher publisher;\n+  private long rowsReceived;\n+  private AcksSubscriber acksSubscriber;\n+\n+  public InsertsBodyParser(final Endpoints endpoints, final RoutingContext routingContext) {\n+    this.endpoints = endpoints;\n+    this.routingContext = routingContext;\n+    routingContext.response().endHandler(v -> {\n+      if (publisher != null) {\n+        publisher.close();\n+      }\n+    });\n+  }\n+\n+  public void handleBodyEnd(final Void v) {\n+    if (acksSubscriber == null) {\n+      routingContext.response().end();\n+    } else {\n+      // We close the response after the stream of acks has been sent\n+      acksSubscriber.insertsSent(rowsReceived);\n+    }\n+  }\n+\n+  public void handleBodyBuffer(final Buffer buff) {\n+    if (!readArguments) {\n+      JsonObject args = new JsonObject(buff);\n+      readArguments = true;\n+      String target = args.getString(\"target\");\n+      if (target == null) {\n+        handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM,\n+            \"No target in arguments\");\n+        return;\n+      }\n+      Boolean acks = args.getBoolean(\"acks\");\n+      if (acks == null) {\n+        handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM,\n+            \"No acks in arguments\");\n+        return;\n+      }\n+      JsonObject properties = args.getJsonObject(\"properties\");\n+      routingContext.request().endHandler(this::handleBodyEnd);\n+      acksSubscriber = acks ? new AcksSubscriber(routingContext.response()) : null;\n+      InsertsSubscriber insertsSubscriber = endpoints\n+          .createInsertsSubscriber(target, properties, acksSubscriber);\n+      publisher = new InsertsPublisher();\n+      publisher.subscribe(insertsSubscriber);\n+    } else if (publisher != null) {\n+      JsonObject row = new JsonObject(buff);\n+      publisher.receiveRow(row);\n+      rowsReceived++;\n+    }\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 92}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzUzMzcwMw==", "bodyText": "As you probably know, I tend to err on the side of minimalism and avoid proliferation of classes, especially for simple things. In this case we're just extracting a couple of fields from a map so I did the simplest possible thing.\nI think it would be possible to use a Jackson ObjectMapper and create POJOs for the arguments (although it's not obvious to me exactly how I would do this, especially considering the params to query-stream contains a nested JsonObject in the properties field), but it would certainly result in a lot more code. Considering these args classes would never be used outside this specific method, my initial thoughts are this would be overkill. If the POJOs were passed to other parts of the program, I think the case would be more clear cut.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367533703", "createdAt": "2020-01-16T16:52:21Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyParser.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.InsertsSubscriber;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.ext.web.RoutingContext;\n+\n+/**\n+ * This class handles the parsing of the request body for a stream of inserts. The user can send a\n+ * stream of inserts to the server by opening an HTTP2 request to the server at the appropriate uri\n+ * and POSTing a request. The request must contain an initial JSON object (encoded as UTF-8 text)\n+ * which contains the arguments for the request (e.g. the target to insert into, and whether acks\n+ * are wanted) This must be followed by a new line, and then followed by zero or more JSON objects\n+ * (also encoded as UTF-8 text) each representing a row to insert. The last JSON object must be\n+ * followed by a new-line.\n+ */\n+public class InsertsBodyParser {\n+\n+  private final Endpoints endpoints;\n+  private final RoutingContext routingContext;\n+  private boolean readArguments;\n+  private InsertsPublisher publisher;\n+  private long rowsReceived;\n+  private AcksSubscriber acksSubscriber;\n+\n+  public InsertsBodyParser(final Endpoints endpoints, final RoutingContext routingContext) {\n+    this.endpoints = endpoints;\n+    this.routingContext = routingContext;\n+    routingContext.response().endHandler(v -> {\n+      if (publisher != null) {\n+        publisher.close();\n+      }\n+    });\n+  }\n+\n+  public void handleBodyEnd(final Void v) {\n+    if (acksSubscriber == null) {\n+      routingContext.response().end();\n+    } else {\n+      // We close the response after the stream of acks has been sent\n+      acksSubscriber.insertsSent(rowsReceived);\n+    }\n+  }\n+\n+  public void handleBodyBuffer(final Buffer buff) {\n+    if (!readArguments) {\n+      JsonObject args = new JsonObject(buff);\n+      readArguments = true;\n+      String target = args.getString(\"target\");\n+      if (target == null) {\n+        handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM,\n+            \"No target in arguments\");\n+        return;\n+      }\n+      Boolean acks = args.getBoolean(\"acks\");\n+      if (acks == null) {\n+        handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM,\n+            \"No acks in arguments\");\n+        return;\n+      }\n+      JsonObject properties = args.getJsonObject(\"properties\");\n+      routingContext.request().endHandler(this::handleBodyEnd);\n+      acksSubscriber = acks ? new AcksSubscriber(routingContext.response()) : null;\n+      InsertsSubscriber insertsSubscriber = endpoints\n+          .createInsertsSubscriber(target, properties, acksSubscriber);\n+      publisher = new InsertsPublisher();\n+      publisher.subscribe(insertsSubscriber);\n+    } else if (publisher != null) {\n+      JsonObject row = new JsonObject(buff);\n+      publisher.receiveRow(row);\n+      rowsReceived++;\n+    }\n+  }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwNDE4Ng=="}, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 92}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU4MzI4MA==", "bodyText": "I will however look into how hard this would be to do. One other thing to bear in mind that Vert. uses JsonObject in many APIs - it's kind of the \"Vert.x-way\" to do JSON. One of the reasons for that is also performance.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367583280", "createdAt": "2020-01-16T18:37:16Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyParser.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.InsertsSubscriber;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.ext.web.RoutingContext;\n+\n+/**\n+ * This class handles the parsing of the request body for a stream of inserts. The user can send a\n+ * stream of inserts to the server by opening an HTTP2 request to the server at the appropriate uri\n+ * and POSTing a request. The request must contain an initial JSON object (encoded as UTF-8 text)\n+ * which contains the arguments for the request (e.g. the target to insert into, and whether acks\n+ * are wanted) This must be followed by a new line, and then followed by zero or more JSON objects\n+ * (also encoded as UTF-8 text) each representing a row to insert. The last JSON object must be\n+ * followed by a new-line.\n+ */\n+public class InsertsBodyParser {\n+\n+  private final Endpoints endpoints;\n+  private final RoutingContext routingContext;\n+  private boolean readArguments;\n+  private InsertsPublisher publisher;\n+  private long rowsReceived;\n+  private AcksSubscriber acksSubscriber;\n+\n+  public InsertsBodyParser(final Endpoints endpoints, final RoutingContext routingContext) {\n+    this.endpoints = endpoints;\n+    this.routingContext = routingContext;\n+    routingContext.response().endHandler(v -> {\n+      if (publisher != null) {\n+        publisher.close();\n+      }\n+    });\n+  }\n+\n+  public void handleBodyEnd(final Void v) {\n+    if (acksSubscriber == null) {\n+      routingContext.response().end();\n+    } else {\n+      // We close the response after the stream of acks has been sent\n+      acksSubscriber.insertsSent(rowsReceived);\n+    }\n+  }\n+\n+  public void handleBodyBuffer(final Buffer buff) {\n+    if (!readArguments) {\n+      JsonObject args = new JsonObject(buff);\n+      readArguments = true;\n+      String target = args.getString(\"target\");\n+      if (target == null) {\n+        handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM,\n+            \"No target in arguments\");\n+        return;\n+      }\n+      Boolean acks = args.getBoolean(\"acks\");\n+      if (acks == null) {\n+        handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM,\n+            \"No acks in arguments\");\n+        return;\n+      }\n+      JsonObject properties = args.getJsonObject(\"properties\");\n+      routingContext.request().endHandler(this::handleBodyEnd);\n+      acksSubscriber = acks ? new AcksSubscriber(routingContext.response()) : null;\n+      InsertsSubscriber insertsSubscriber = endpoints\n+          .createInsertsSubscriber(target, properties, acksSubscriber);\n+      publisher = new InsertsPublisher();\n+      publisher.subscribe(insertsSubscriber);\n+    } else if (publisher != null) {\n+      JsonObject row = new JsonObject(buff);\n+      publisher.receiveRow(row);\n+      rowsReceived++;\n+    }\n+  }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwNDE4Ng=="}, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 92}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzYzMzU2MQ==", "bodyText": "#4333", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367633561", "createdAt": "2020-01-16T20:29:19Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyParser.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.InsertsSubscriber;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.ext.web.RoutingContext;\n+\n+/**\n+ * This class handles the parsing of the request body for a stream of inserts. The user can send a\n+ * stream of inserts to the server by opening an HTTP2 request to the server at the appropriate uri\n+ * and POSTing a request. The request must contain an initial JSON object (encoded as UTF-8 text)\n+ * which contains the arguments for the request (e.g. the target to insert into, and whether acks\n+ * are wanted) This must be followed by a new line, and then followed by zero or more JSON objects\n+ * (also encoded as UTF-8 text) each representing a row to insert. The last JSON object must be\n+ * followed by a new-line.\n+ */\n+public class InsertsBodyParser {\n+\n+  private final Endpoints endpoints;\n+  private final RoutingContext routingContext;\n+  private boolean readArguments;\n+  private InsertsPublisher publisher;\n+  private long rowsReceived;\n+  private AcksSubscriber acksSubscriber;\n+\n+  public InsertsBodyParser(final Endpoints endpoints, final RoutingContext routingContext) {\n+    this.endpoints = endpoints;\n+    this.routingContext = routingContext;\n+    routingContext.response().endHandler(v -> {\n+      if (publisher != null) {\n+        publisher.close();\n+      }\n+    });\n+  }\n+\n+  public void handleBodyEnd(final Void v) {\n+    if (acksSubscriber == null) {\n+      routingContext.response().end();\n+    } else {\n+      // We close the response after the stream of acks has been sent\n+      acksSubscriber.insertsSent(rowsReceived);\n+    }\n+  }\n+\n+  public void handleBodyBuffer(final Buffer buff) {\n+    if (!readArguments) {\n+      JsonObject args = new JsonObject(buff);\n+      readArguments = true;\n+      String target = args.getString(\"target\");\n+      if (target == null) {\n+        handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM,\n+            \"No target in arguments\");\n+        return;\n+      }\n+      Boolean acks = args.getBoolean(\"acks\");\n+      if (acks == null) {\n+        handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM,\n+            \"No acks in arguments\");\n+        return;\n+      }\n+      JsonObject properties = args.getJsonObject(\"properties\");\n+      routingContext.request().endHandler(this::handleBodyEnd);\n+      acksSubscriber = acks ? new AcksSubscriber(routingContext.response()) : null;\n+      InsertsSubscriber insertsSubscriber = endpoints\n+          .createInsertsSubscriber(target, properties, acksSubscriber);\n+      publisher = new InsertsPublisher();\n+      publisher.subscribe(insertsSubscriber);\n+    } else if (publisher != null) {\n+      JsonObject row = new JsonObject(buff);\n+      publisher.receiveRow(row);\n+      rowsReceived++;\n+    }\n+  }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwNDE4Ng=="}, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 92}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODExNTYzOQ==", "bodyText": "Adding my thoughts here - I tend to agree with Andy on this one. If there's a legitimate concern on performance than perhaps JSON objects that are used exclusively internally and are not exposed can be hand crafted - but it would be nice to have them constructed in a centralized place so that we can define the \"API\" coherently.\nOn the other hand, anything that is exposed externally I feel should definitely have an associated POJO to define the public API and allow us to automatically generate documentation on it.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368115639", "createdAt": "2020-01-17T20:08:58Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyParser.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.InsertsSubscriber;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.ext.web.RoutingContext;\n+\n+/**\n+ * This class handles the parsing of the request body for a stream of inserts. The user can send a\n+ * stream of inserts to the server by opening an HTTP2 request to the server at the appropriate uri\n+ * and POSTing a request. The request must contain an initial JSON object (encoded as UTF-8 text)\n+ * which contains the arguments for the request (e.g. the target to insert into, and whether acks\n+ * are wanted) This must be followed by a new line, and then followed by zero or more JSON objects\n+ * (also encoded as UTF-8 text) each representing a row to insert. The last JSON object must be\n+ * followed by a new-line.\n+ */\n+public class InsertsBodyParser {\n+\n+  private final Endpoints endpoints;\n+  private final RoutingContext routingContext;\n+  private boolean readArguments;\n+  private InsertsPublisher publisher;\n+  private long rowsReceived;\n+  private AcksSubscriber acksSubscriber;\n+\n+  public InsertsBodyParser(final Endpoints endpoints, final RoutingContext routingContext) {\n+    this.endpoints = endpoints;\n+    this.routingContext = routingContext;\n+    routingContext.response().endHandler(v -> {\n+      if (publisher != null) {\n+        publisher.close();\n+      }\n+    });\n+  }\n+\n+  public void handleBodyEnd(final Void v) {\n+    if (acksSubscriber == null) {\n+      routingContext.response().end();\n+    } else {\n+      // We close the response after the stream of acks has been sent\n+      acksSubscriber.insertsSent(rowsReceived);\n+    }\n+  }\n+\n+  public void handleBodyBuffer(final Buffer buff) {\n+    if (!readArguments) {\n+      JsonObject args = new JsonObject(buff);\n+      readArguments = true;\n+      String target = args.getString(\"target\");\n+      if (target == null) {\n+        handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM,\n+            \"No target in arguments\");\n+        return;\n+      }\n+      Boolean acks = args.getBoolean(\"acks\");\n+      if (acks == null) {\n+        handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM,\n+            \"No acks in arguments\");\n+        return;\n+      }\n+      JsonObject properties = args.getJsonObject(\"properties\");\n+      routingContext.request().endHandler(this::handleBodyEnd);\n+      acksSubscriber = acks ? new AcksSubscriber(routingContext.response()) : null;\n+      InsertsSubscriber insertsSubscriber = endpoints\n+          .createInsertsSubscriber(target, properties, acksSubscriber);\n+      publisher = new InsertsPublisher();\n+      publisher.subscribe(insertsSubscriber);\n+    } else if (publisher != null) {\n+      JsonObject row = new JsonObject(buff);\n+      publisher.receiveRow(row);\n+      rowsReceived++;\n+    }\n+  }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwNDE4Ng=="}, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 92}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODY0MTQ4MQ==", "bodyText": "If you're looking for examples of how to use Pojos with Json then take a look at the pojos in the current API are used; they're in the io.confluent.ksql.rest.entity package.\nthe general pattern is that you need a Jackson ObjectMapper and it can serialize a pojo to JSON and deserialize the JSON to a pojo.\nIdeally, put the model into a different module, so that it can be shared between client and server.\nActually, that makes me think: we're looking at clients with different languages, so what we really need for the API is the JSON schema.  We can then use this to generate / validate clients.   We can generate the schema from the Java pojos: @rohan has done this for our internal command API.  Alternatively, you may wish to hand write the JSON schema, from which we may be able to generate the Pojos.\nThoughts?", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368641481", "createdAt": "2020-01-20T16:40:52Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyParser.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.InsertsSubscriber;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.ext.web.RoutingContext;\n+\n+/**\n+ * This class handles the parsing of the request body for a stream of inserts. The user can send a\n+ * stream of inserts to the server by opening an HTTP2 request to the server at the appropriate uri\n+ * and POSTing a request. The request must contain an initial JSON object (encoded as UTF-8 text)\n+ * which contains the arguments for the request (e.g. the target to insert into, and whether acks\n+ * are wanted) This must be followed by a new line, and then followed by zero or more JSON objects\n+ * (also encoded as UTF-8 text) each representing a row to insert. The last JSON object must be\n+ * followed by a new-line.\n+ */\n+public class InsertsBodyParser {\n+\n+  private final Endpoints endpoints;\n+  private final RoutingContext routingContext;\n+  private boolean readArguments;\n+  private InsertsPublisher publisher;\n+  private long rowsReceived;\n+  private AcksSubscriber acksSubscriber;\n+\n+  public InsertsBodyParser(final Endpoints endpoints, final RoutingContext routingContext) {\n+    this.endpoints = endpoints;\n+    this.routingContext = routingContext;\n+    routingContext.response().endHandler(v -> {\n+      if (publisher != null) {\n+        publisher.close();\n+      }\n+    });\n+  }\n+\n+  public void handleBodyEnd(final Void v) {\n+    if (acksSubscriber == null) {\n+      routingContext.response().end();\n+    } else {\n+      // We close the response after the stream of acks has been sent\n+      acksSubscriber.insertsSent(rowsReceived);\n+    }\n+  }\n+\n+  public void handleBodyBuffer(final Buffer buff) {\n+    if (!readArguments) {\n+      JsonObject args = new JsonObject(buff);\n+      readArguments = true;\n+      String target = args.getString(\"target\");\n+      if (target == null) {\n+        handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM,\n+            \"No target in arguments\");\n+        return;\n+      }\n+      Boolean acks = args.getBoolean(\"acks\");\n+      if (acks == null) {\n+        handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM,\n+            \"No acks in arguments\");\n+        return;\n+      }\n+      JsonObject properties = args.getJsonObject(\"properties\");\n+      routingContext.request().endHandler(this::handleBodyEnd);\n+      acksSubscriber = acks ? new AcksSubscriber(routingContext.response()) : null;\n+      InsertsSubscriber insertsSubscriber = endpoints\n+          .createInsertsSubscriber(target, properties, acksSubscriber);\n+      publisher = new InsertsPublisher();\n+      publisher.subscribe(insertsSubscriber);\n+    } else if (publisher != null) {\n+      JsonObject row = new JsonObject(buff);\n+      publisher.receiveRow(row);\n+      rowsReceived++;\n+    }\n+  }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwNDE4Ng=="}, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 92}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODcyNTM3NQ==", "bodyText": "Chatted with Andy about this privately. Here's what code would like if we had to deserialize into POJOs and catch various exceptions so we can send back the right error codes on the wire: https://gist.github.com/purplefox/8975123fcc97da9c7f00eb2ce5ccf8ec\nSuper ugly I hope you agree. Now, sure we can hide this in a utility class but still.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368725375", "createdAt": "2020-01-20T21:05:09Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyParser.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.InsertsSubscriber;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.ext.web.RoutingContext;\n+\n+/**\n+ * This class handles the parsing of the request body for a stream of inserts. The user can send a\n+ * stream of inserts to the server by opening an HTTP2 request to the server at the appropriate uri\n+ * and POSTing a request. The request must contain an initial JSON object (encoded as UTF-8 text)\n+ * which contains the arguments for the request (e.g. the target to insert into, and whether acks\n+ * are wanted) This must be followed by a new line, and then followed by zero or more JSON objects\n+ * (also encoded as UTF-8 text) each representing a row to insert. The last JSON object must be\n+ * followed by a new-line.\n+ */\n+public class InsertsBodyParser {\n+\n+  private final Endpoints endpoints;\n+  private final RoutingContext routingContext;\n+  private boolean readArguments;\n+  private InsertsPublisher publisher;\n+  private long rowsReceived;\n+  private AcksSubscriber acksSubscriber;\n+\n+  public InsertsBodyParser(final Endpoints endpoints, final RoutingContext routingContext) {\n+    this.endpoints = endpoints;\n+    this.routingContext = routingContext;\n+    routingContext.response().endHandler(v -> {\n+      if (publisher != null) {\n+        publisher.close();\n+      }\n+    });\n+  }\n+\n+  public void handleBodyEnd(final Void v) {\n+    if (acksSubscriber == null) {\n+      routingContext.response().end();\n+    } else {\n+      // We close the response after the stream of acks has been sent\n+      acksSubscriber.insertsSent(rowsReceived);\n+    }\n+  }\n+\n+  public void handleBodyBuffer(final Buffer buff) {\n+    if (!readArguments) {\n+      JsonObject args = new JsonObject(buff);\n+      readArguments = true;\n+      String target = args.getString(\"target\");\n+      if (target == null) {\n+        handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM,\n+            \"No target in arguments\");\n+        return;\n+      }\n+      Boolean acks = args.getBoolean(\"acks\");\n+      if (acks == null) {\n+        handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM,\n+            \"No acks in arguments\");\n+        return;\n+      }\n+      JsonObject properties = args.getJsonObject(\"properties\");\n+      routingContext.request().endHandler(this::handleBodyEnd);\n+      acksSubscriber = acks ? new AcksSubscriber(routingContext.response()) : null;\n+      InsertsSubscriber insertsSubscriber = endpoints\n+          .createInsertsSubscriber(target, properties, acksSubscriber);\n+      publisher = new InsertsPublisher();\n+      publisher.subscribe(insertsSubscriber);\n+    } else if (publisher != null) {\n+      JsonObject row = new JsonObject(buff);\n+      publisher.receiveRow(row);\n+      rowsReceived++;\n+    }\n+  }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwNDE4Ng=="}, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 92}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MDExNzkwOnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsPublisher.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzowMjo1OFrOFeYmdw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzowMjo1OFrOFeYmdw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwNDY2Mw==", "bodyText": "nit: null checks", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367404663", "createdAt": "2020-01-16T13:02:58Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsPublisher.java", "diffHunk": "@@ -0,0 +1,82 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.json.JsonObject;\n+import java.util.LinkedList;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+\n+/**\n+ * This class is a reactive streams publisher which publishes the inserts to a subscriber which is\n+ * provided by the back-end. As it's reactive streams it supports back pressure.\n+ */\n+public class InsertsPublisher implements Publisher<JsonObject> {\n+\n+  private final Queue<JsonObject> buffer = new LinkedList<>();\n+  private long demand;\n+  private Subscriber<? super JsonObject> subscriber;\n+\n+  @Override\n+  public void subscribe(final Subscriber<? super JsonObject> subscriber) {\n+    this.subscriber = subscriber;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MDEyMDc2OnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsPublisher.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzowNDowOFrOFeYoLQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxODozNzo1N1rOFejhPQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwNTEwMQ==", "bodyText": "nit: make private?", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367405101", "createdAt": "2020-01-16T13:04:08Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsPublisher.java", "diffHunk": "@@ -0,0 +1,82 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.json.JsonObject;\n+import java.util.LinkedList;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+\n+/**\n+ * This class is a reactive streams publisher which publishes the inserts to a subscriber which is\n+ * provided by the back-end. As it's reactive streams it supports back pressure.\n+ */\n+public class InsertsPublisher implements Publisher<JsonObject> {\n+\n+  private final Queue<JsonObject> buffer = new LinkedList<>();\n+  private long demand;\n+  private Subscriber<? super JsonObject> subscriber;\n+\n+  @Override\n+  public void subscribe(final Subscriber<? super JsonObject> subscriber) {\n+    this.subscriber = subscriber;\n+    subscriber.onSubscribe(new InsertsSubscription());\n+  }\n+\n+  public synchronized void receiveRow(final JsonObject row) {\n+    if (subscriber == null) {\n+      return;\n+    }\n+    if (demand > 0) {\n+      demand--;\n+      subscriber.onNext(row);\n+    } else {\n+      buffer.add(row);\n+    }\n+  }\n+\n+  synchronized void acceptTokens(final long number) {\n+    demand += number;\n+    for (int i = 0; i < buffer.size(); i++) {\n+      JsonObject row = buffer.poll();\n+      demand--;\n+      subscriber.onNext(row);\n+    }\n+  }\n+\n+  synchronized void close() {\n+    subscriber.onComplete();\n+    subscriber = null;\n+  }\n+\n+  class InsertsSubscription implements Subscription {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU4MzU0OQ==", "bodyText": "Ack", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367583549", "createdAt": "2020-01-16T18:37:57Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsPublisher.java", "diffHunk": "@@ -0,0 +1,82 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.json.JsonObject;\n+import java.util.LinkedList;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+\n+/**\n+ * This class is a reactive streams publisher which publishes the inserts to a subscriber which is\n+ * provided by the back-end. As it's reactive streams it supports back pressure.\n+ */\n+public class InsertsPublisher implements Publisher<JsonObject> {\n+\n+  private final Queue<JsonObject> buffer = new LinkedList<>();\n+  private long demand;\n+  private Subscriber<? super JsonObject> subscriber;\n+\n+  @Override\n+  public void subscribe(final Subscriber<? super JsonObject> subscriber) {\n+    this.subscriber = subscriber;\n+    subscriber.onSubscribe(new InsertsSubscription());\n+  }\n+\n+  public synchronized void receiveRow(final JsonObject row) {\n+    if (subscriber == null) {\n+      return;\n+    }\n+    if (demand > 0) {\n+      demand--;\n+      subscriber.onNext(row);\n+    } else {\n+      buffer.add(row);\n+    }\n+  }\n+\n+  synchronized void acceptTokens(final long number) {\n+    demand += number;\n+    for (int i = 0; i < buffer.size(); i++) {\n+      JsonObject row = buffer.poll();\n+      demand--;\n+      subscriber.onNext(row);\n+    }\n+  }\n+\n+  synchronized void close() {\n+    subscriber.onComplete();\n+    subscriber = null;\n+  }\n+\n+  class InsertsSubscription implements Subscription {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwNTEwMQ=="}, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 67}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MDEyMTczOnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/QuerySubscriber.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzowNDozMlrOFeYoxQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzowNDozMlrOFeYoxQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwNTI1Mw==", "bodyText": "nit: null check.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367405253", "createdAt": "2020-01-16T13:04:32Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/QuerySubscriber.java", "diffHunk": "@@ -0,0 +1,95 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+\n+import io.vertx.core.http.HttpServerResponse;\n+import io.vertx.core.json.JsonArray;\n+import io.vertx.core.json.JsonObject;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This is a reactive streams subscriber which receives a stream of results from a publisher which\n+ * is implemented by the back-end. The results are then written to the HTTP2 response.\n+ */\n+public class QuerySubscriber implements Subscriber<JsonArray> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(QuerySubscriber.class);\n+\n+  private final HttpServerResponse response;\n+  private Subscription subscription;\n+  private long tokens;\n+\n+  private static final int BATCH_SIZE = 4;\n+\n+  public QuerySubscriber(final HttpServerResponse response) {\n+    this.response = response;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 43}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MDEyMjA0OnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/QuerySubscriber.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzowNDo0MFrOFeYo8Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMFQxNjo0Mzo1NlrOFfkLoA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwNTI5Nw==", "bodyText": "nit: null check.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367405297", "createdAt": "2020-01-16T13:04:40Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/QuerySubscriber.java", "diffHunk": "@@ -0,0 +1,95 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+\n+import io.vertx.core.http.HttpServerResponse;\n+import io.vertx.core.json.JsonArray;\n+import io.vertx.core.json.JsonObject;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This is a reactive streams subscriber which receives a stream of results from a publisher which\n+ * is implemented by the back-end. The results are then written to the HTTP2 response.\n+ */\n+public class QuerySubscriber implements Subscriber<JsonArray> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(QuerySubscriber.class);\n+\n+  private final HttpServerResponse response;\n+  private Subscription subscription;\n+  private long tokens;\n+\n+  private static final int BATCH_SIZE = 4;\n+\n+  public QuerySubscriber(final HttpServerResponse response) {\n+    this.response = response;\n+  }\n+\n+  @Override\n+  public synchronized void onSubscribe(final Subscription subscription) {\n+    if (this.subscription != null) {\n+      throw new IllegalStateException(\"Already subscribed\");\n+    }\n+    this.subscription = subscription;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODY0Mjk3Ng==", "bodyText": "By bad: this one's actually not needed! The if above checks this.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368642976", "createdAt": "2020-01-20T16:43:56Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/QuerySubscriber.java", "diffHunk": "@@ -0,0 +1,95 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+\n+import io.vertx.core.http.HttpServerResponse;\n+import io.vertx.core.json.JsonArray;\n+import io.vertx.core.json.JsonObject;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This is a reactive streams subscriber which receives a stream of results from a publisher which\n+ * is implemented by the back-end. The results are then written to the HTTP2 response.\n+ */\n+public class QuerySubscriber implements Subscriber<JsonArray> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(QuerySubscriber.class);\n+\n+  private final HttpServerResponse response;\n+  private Subscription subscription;\n+  private long tokens;\n+\n+  private static final int BATCH_SIZE = 4;\n+\n+  public QuerySubscriber(final HttpServerResponse response) {\n+    this.response = response;\n+  }\n+\n+  @Override\n+  public synchronized void onSubscribe(final Subscription subscription) {\n+    if (this.subscription != null) {\n+      throw new IllegalStateException(\"Already subscribed\");\n+    }\n+    this.subscription = subscription;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwNTI5Nw=="}, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 51}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MDEyNDMxOnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzowNTozM1rOFeYqVg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzowNTozM1rOFeYqVg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwNTY1NA==", "bodyText": "nit: null checks", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367405654", "createdAt": "2020-01-16T13:05:33Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.vertx.core.DeploymentOptions;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.impl.ConcurrentHashSet;\n+import io.vertx.core.json.JsonObject;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class represents the API server. On start-up it deploys multiple server verticles to spread\n+ * the load across available cores.\n+ */\n+public class Server {\n+\n+  private static final Logger log = LoggerFactory.getLogger(Server.class);\n+\n+  private final Vertx vertx;\n+  private final JsonObject config;\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Map<String, QuerySubscriber> queries = new ConcurrentHashMap<>();\n+  private final Set<HttpConnection> connections = new ConcurrentHashSet<>();\n+  private String deploymentID;\n+\n+  public Server(final Vertx vertx, final JsonObject config, final Endpoints endpoints,\n+      final HttpServerOptions httpServerOptions) {\n+    this.vertx = vertx;\n+    this.config = config;\n+    this.endpoints = endpoints;\n+    this.httpServerOptions = httpServerOptions;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 55}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MDEyOTM0OnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzowNzoyMFrOFeYtTA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxNjo1NjoxMVrOFegnVg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwNjQxMg==", "bodyText": "We generally use AbstractConfig as a base for config classes, as this provides a fair amount of functionality that can be useful, including defining validators and defaults: which keeps the calling code a lot cleaner.\nIn the future, we can also generate the docs from the config class.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367406412", "createdAt": "2020-01-16T13:07:20Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.vertx.core.DeploymentOptions;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.impl.ConcurrentHashSet;\n+import io.vertx.core.json.JsonObject;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class represents the API server. On start-up it deploys multiple server verticles to spread\n+ * the load across available cores.\n+ */\n+public class Server {\n+\n+  private static final Logger log = LoggerFactory.getLogger(Server.class);\n+\n+  private final Vertx vertx;\n+  private final JsonObject config;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzUzNTk1OA==", "bodyText": "#4330", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367535958", "createdAt": "2020-01-16T16:56:11Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.vertx.core.DeploymentOptions;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.impl.ConcurrentHashSet;\n+import io.vertx.core.json.JsonObject;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class represents the API server. On start-up it deploys multiple server verticles to spread\n+ * the load across available cores.\n+ */\n+public class Server {\n+\n+  private static final Logger log = LoggerFactory.getLogger(Server.class);\n+\n+  private final Vertx vertx;\n+  private final JsonObject config;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwNjQxMg=="}, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 43}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MDEzNjM0OnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzowOTo1NlrOFeYxnA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMFQxNzowNTo0NVrOFfkyvQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwNzUxNg==", "bodyText": "Consider throwing a more specific exception type, e.g. KsqlServerException, and include more info, e.g. \"Failed to start server\".", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367407516", "createdAt": "2020-01-16T13:09:56Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.vertx.core.DeploymentOptions;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.impl.ConcurrentHashSet;\n+import io.vertx.core.json.JsonObject;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class represents the API server. On start-up it deploys multiple server verticles to spread\n+ * the load across available cores.\n+ */\n+public class Server {\n+\n+  private static final Logger log = LoggerFactory.getLogger(Server.class);\n+\n+  private final Vertx vertx;\n+  private final JsonObject config;\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Map<String, QuerySubscriber> queries = new ConcurrentHashMap<>();\n+  private final Set<HttpConnection> connections = new ConcurrentHashSet<>();\n+  private String deploymentID;\n+\n+  public Server(final Vertx vertx, final JsonObject config, final Endpoints endpoints,\n+      final HttpServerOptions httpServerOptions) {\n+    this.vertx = vertx;\n+    this.config = config;\n+    this.endpoints = endpoints;\n+    this.httpServerOptions = httpServerOptions;\n+  }\n+\n+  public synchronized void start() {\n+    if (deploymentID != null) {\n+      throw new IllegalStateException(\"Already started\");\n+    }\n+    DeploymentOptions options = new DeploymentOptions();\n+    Integer verticleInstances = config.getInteger(\"verticle-instances\");\n+    if (verticleInstances == null) {\n+      options.setInstances(Runtime.getRuntime().availableProcessors() * 2);\n+    } else {\n+      options.setInstances(verticleInstances);\n+    }\n+    log.info(\"Deploying \" + options.getInstances() + \" instances of server verticle\");\n+    options.setConfig(config);\n+    VertxCompletableFuture<String> future = new VertxCompletableFuture<>();\n+    vertx.deployVerticle(\n+        () -> new ServerVerticle(endpoints, httpServerOptions, this), options, future);\n+    try {\n+      deploymentID = future.get();\n+    } catch (Exception e) {\n+      throw new RuntimeException(e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU4MzQxMw==", "bodyText": "Ack", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367583413", "createdAt": "2020-01-16T18:37:38Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.vertx.core.DeploymentOptions;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.impl.ConcurrentHashSet;\n+import io.vertx.core.json.JsonObject;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class represents the API server. On start-up it deploys multiple server verticles to spread\n+ * the load across available cores.\n+ */\n+public class Server {\n+\n+  private static final Logger log = LoggerFactory.getLogger(Server.class);\n+\n+  private final Vertx vertx;\n+  private final JsonObject config;\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Map<String, QuerySubscriber> queries = new ConcurrentHashMap<>();\n+  private final Set<HttpConnection> connections = new ConcurrentHashSet<>();\n+  private String deploymentID;\n+\n+  public Server(final Vertx vertx, final JsonObject config, final Endpoints endpoints,\n+      final HttpServerOptions httpServerOptions) {\n+    this.vertx = vertx;\n+    this.config = config;\n+    this.endpoints = endpoints;\n+    this.httpServerOptions = httpServerOptions;\n+  }\n+\n+  public synchronized void start() {\n+    if (deploymentID != null) {\n+      throw new IllegalStateException(\"Already started\");\n+    }\n+    DeploymentOptions options = new DeploymentOptions();\n+    Integer verticleInstances = config.getInteger(\"verticle-instances\");\n+    if (verticleInstances == null) {\n+      options.setInstances(Runtime.getRuntime().availableProcessors() * 2);\n+    } else {\n+      options.setInstances(verticleInstances);\n+    }\n+    log.info(\"Deploying \" + options.getInstances() + \" instances of server verticle\");\n+    options.setConfig(config);\n+    VertxCompletableFuture<String> future = new VertxCompletableFuture<>();\n+    vertx.deployVerticle(\n+        () -> new ServerVerticle(endpoints, httpServerOptions, this), options, future);\n+    try {\n+      deploymentID = future.get();\n+    } catch (Exception e) {\n+      throw new RuntimeException(e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwNzUxNg=="}, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODY1Mjk4OQ==", "bodyText": "FYI, use KsqlServerException, not KsqlException.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368652989", "createdAt": "2020-01-20T17:05:45Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.vertx.core.DeploymentOptions;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.impl.ConcurrentHashSet;\n+import io.vertx.core.json.JsonObject;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class represents the API server. On start-up it deploys multiple server verticles to spread\n+ * the load across available cores.\n+ */\n+public class Server {\n+\n+  private static final Logger log = LoggerFactory.getLogger(Server.class);\n+\n+  private final Vertx vertx;\n+  private final JsonObject config;\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Map<String, QuerySubscriber> queries = new ConcurrentHashMap<>();\n+  private final Set<HttpConnection> connections = new ConcurrentHashSet<>();\n+  private String deploymentID;\n+\n+  public Server(final Vertx vertx, final JsonObject config, final Endpoints endpoints,\n+      final HttpServerOptions httpServerOptions) {\n+    this.vertx = vertx;\n+    this.config = config;\n+    this.endpoints = endpoints;\n+    this.httpServerOptions = httpServerOptions;\n+  }\n+\n+  public synchronized void start() {\n+    if (deploymentID != null) {\n+      throw new IllegalStateException(\"Already started\");\n+    }\n+    DeploymentOptions options = new DeploymentOptions();\n+    Integer verticleInstances = config.getInteger(\"verticle-instances\");\n+    if (verticleInstances == null) {\n+      options.setInstances(Runtime.getRuntime().availableProcessors() * 2);\n+    } else {\n+      options.setInstances(verticleInstances);\n+    }\n+    log.info(\"Deploying \" + options.getInstances() + \" instances of server verticle\");\n+    options.setConfig(config);\n+    VertxCompletableFuture<String> future = new VertxCompletableFuture<>();\n+    vertx.deployVerticle(\n+        () -> new ServerVerticle(endpoints, httpServerOptions, this), options, future);\n+    try {\n+      deploymentID = future.get();\n+    } catch (Exception e) {\n+      throw new RuntimeException(e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwNzUxNg=="}, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 77}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MDEzNzM1OnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzoxMDoxOFrOFeYySg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxODozNzo0NFrOFejg5Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwNzY5MA==", "bodyText": "Consider throwing a more specific exception type, e.g. KsqlServerException, and include more info, e.g. \"failed to stop server\".", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367407690", "createdAt": "2020-01-16T13:10:18Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.vertx.core.DeploymentOptions;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.impl.ConcurrentHashSet;\n+import io.vertx.core.json.JsonObject;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class represents the API server. On start-up it deploys multiple server verticles to spread\n+ * the load across available cores.\n+ */\n+public class Server {\n+\n+  private static final Logger log = LoggerFactory.getLogger(Server.class);\n+\n+  private final Vertx vertx;\n+  private final JsonObject config;\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Map<String, QuerySubscriber> queries = new ConcurrentHashMap<>();\n+  private final Set<HttpConnection> connections = new ConcurrentHashSet<>();\n+  private String deploymentID;\n+\n+  public Server(final Vertx vertx, final JsonObject config, final Endpoints endpoints,\n+      final HttpServerOptions httpServerOptions) {\n+    this.vertx = vertx;\n+    this.config = config;\n+    this.endpoints = endpoints;\n+    this.httpServerOptions = httpServerOptions;\n+  }\n+\n+  public synchronized void start() {\n+    if (deploymentID != null) {\n+      throw new IllegalStateException(\"Already started\");\n+    }\n+    DeploymentOptions options = new DeploymentOptions();\n+    Integer verticleInstances = config.getInteger(\"verticle-instances\");\n+    if (verticleInstances == null) {\n+      options.setInstances(Runtime.getRuntime().availableProcessors() * 2);\n+    } else {\n+      options.setInstances(verticleInstances);\n+    }\n+    log.info(\"Deploying \" + options.getInstances() + \" instances of server verticle\");\n+    options.setConfig(config);\n+    VertxCompletableFuture<String> future = new VertxCompletableFuture<>();\n+    vertx.deployVerticle(\n+        () -> new ServerVerticle(endpoints, httpServerOptions, this), options, future);\n+    try {\n+      deploymentID = future.get();\n+    } catch (Exception e) {\n+      throw new RuntimeException(e);\n+    }\n+    log.info(\"API server started: \" + deploymentID);\n+  }\n+\n+  public synchronized void stop() {\n+    if (deploymentID == null) {\n+      throw new IllegalStateException(\"Not started\");\n+    }\n+    VertxCompletableFuture<Void> future = new VertxCompletableFuture<>();\n+    vertx.undeploy(deploymentID, future);\n+    try {\n+      future.get();\n+    } catch (Exception e) {\n+      throw new RuntimeException(e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU4MzQ2MQ==", "bodyText": "Ack", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367583461", "createdAt": "2020-01-16T18:37:44Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.vertx.core.DeploymentOptions;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.impl.ConcurrentHashSet;\n+import io.vertx.core.json.JsonObject;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class represents the API server. On start-up it deploys multiple server verticles to spread\n+ * the load across available cores.\n+ */\n+public class Server {\n+\n+  private static final Logger log = LoggerFactory.getLogger(Server.class);\n+\n+  private final Vertx vertx;\n+  private final JsonObject config;\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Map<String, QuerySubscriber> queries = new ConcurrentHashMap<>();\n+  private final Set<HttpConnection> connections = new ConcurrentHashSet<>();\n+  private String deploymentID;\n+\n+  public Server(final Vertx vertx, final JsonObject config, final Endpoints endpoints,\n+      final HttpServerOptions httpServerOptions) {\n+    this.vertx = vertx;\n+    this.config = config;\n+    this.endpoints = endpoints;\n+    this.httpServerOptions = httpServerOptions;\n+  }\n+\n+  public synchronized void start() {\n+    if (deploymentID != null) {\n+      throw new IllegalStateException(\"Already started\");\n+    }\n+    DeploymentOptions options = new DeploymentOptions();\n+    Integer verticleInstances = config.getInteger(\"verticle-instances\");\n+    if (verticleInstances == null) {\n+      options.setInstances(Runtime.getRuntime().availableProcessors() * 2);\n+    } else {\n+      options.setInstances(verticleInstances);\n+    }\n+    log.info(\"Deploying \" + options.getInstances() + \" instances of server verticle\");\n+    options.setConfig(config);\n+    VertxCompletableFuture<String> future = new VertxCompletableFuture<>();\n+    vertx.deployVerticle(\n+        () -> new ServerVerticle(endpoints, httpServerOptions, this), options, future);\n+    try {\n+      deploymentID = future.get();\n+    } catch (Exception e) {\n+      throw new RuntimeException(e);\n+    }\n+    log.info(\"API server started: \" + deploymentID);\n+  }\n+\n+  public synchronized void stop() {\n+    if (deploymentID == null) {\n+      throw new IllegalStateException(\"Not started\");\n+    }\n+    VertxCompletableFuture<Void> future = new VertxCompletableFuture<>();\n+    vertx.undeploy(deploymentID, future);\n+    try {\n+      future.get();\n+    } catch (Exception e) {\n+      throw new RuntimeException(e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwNzY5MA=="}, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 91}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MDEzOTY2OnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzoxMTowOFrOFeYzyA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzoxMTowOFrOFeYzyA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwODA3Mg==", "bodyText": "nit: null check state.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367408072", "createdAt": "2020-01-16T13:11:08Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.vertx.core.DeploymentOptions;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.impl.ConcurrentHashSet;\n+import io.vertx.core.json.JsonObject;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class represents the API server. On start-up it deploys multiple server verticles to spread\n+ * the load across available cores.\n+ */\n+public class Server {\n+\n+  private static final Logger log = LoggerFactory.getLogger(Server.class);\n+\n+  private final Vertx vertx;\n+  private final JsonObject config;\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Map<String, QuerySubscriber> queries = new ConcurrentHashMap<>();\n+  private final Set<HttpConnection> connections = new ConcurrentHashSet<>();\n+  private String deploymentID;\n+\n+  public Server(final Vertx vertx, final JsonObject config, final Endpoints endpoints,\n+      final HttpServerOptions httpServerOptions) {\n+    this.vertx = vertx;\n+    this.config = config;\n+    this.endpoints = endpoints;\n+    this.httpServerOptions = httpServerOptions;\n+  }\n+\n+  public synchronized void start() {\n+    if (deploymentID != null) {\n+      throw new IllegalStateException(\"Already started\");\n+    }\n+    DeploymentOptions options = new DeploymentOptions();\n+    Integer verticleInstances = config.getInteger(\"verticle-instances\");\n+    if (verticleInstances == null) {\n+      options.setInstances(Runtime.getRuntime().availableProcessors() * 2);\n+    } else {\n+      options.setInstances(verticleInstances);\n+    }\n+    log.info(\"Deploying \" + options.getInstances() + \" instances of server verticle\");\n+    options.setConfig(config);\n+    VertxCompletableFuture<String> future = new VertxCompletableFuture<>();\n+    vertx.deployVerticle(\n+        () -> new ServerVerticle(endpoints, httpServerOptions, this), options, future);\n+    try {\n+      deploymentID = future.get();\n+    } catch (Exception e) {\n+      throw new RuntimeException(e);\n+    }\n+    log.info(\"API server started: \" + deploymentID);\n+  }\n+\n+  public synchronized void stop() {\n+    if (deploymentID == null) {\n+      throw new IllegalStateException(\"Not started\");\n+    }\n+    VertxCompletableFuture<Void> future = new VertxCompletableFuture<>();\n+    vertx.undeploy(deploymentID, future);\n+    try {\n+      future.get();\n+    } catch (Exception e) {\n+      throw new RuntimeException(e);\n+    }\n+  }\n+\n+  String registerQuery(final QuerySubscriber querySubscriber) {\n+    String uuid = UUID.randomUUID().toString();\n+    queries.put(uuid, querySubscriber);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 97}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MDE0MDQ2OnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzoxMToyMlrOFeY0NA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzoxMToyMlrOFeY0NA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwODE4MA==", "bodyText": "nit: null check state.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367408180", "createdAt": "2020-01-16T13:11:22Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.vertx.core.DeploymentOptions;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.impl.ConcurrentHashSet;\n+import io.vertx.core.json.JsonObject;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class represents the API server. On start-up it deploys multiple server verticles to spread\n+ * the load across available cores.\n+ */\n+public class Server {\n+\n+  private static final Logger log = LoggerFactory.getLogger(Server.class);\n+\n+  private final Vertx vertx;\n+  private final JsonObject config;\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Map<String, QuerySubscriber> queries = new ConcurrentHashMap<>();\n+  private final Set<HttpConnection> connections = new ConcurrentHashSet<>();\n+  private String deploymentID;\n+\n+  public Server(final Vertx vertx, final JsonObject config, final Endpoints endpoints,\n+      final HttpServerOptions httpServerOptions) {\n+    this.vertx = vertx;\n+    this.config = config;\n+    this.endpoints = endpoints;\n+    this.httpServerOptions = httpServerOptions;\n+  }\n+\n+  public synchronized void start() {\n+    if (deploymentID != null) {\n+      throw new IllegalStateException(\"Already started\");\n+    }\n+    DeploymentOptions options = new DeploymentOptions();\n+    Integer verticleInstances = config.getInteger(\"verticle-instances\");\n+    if (verticleInstances == null) {\n+      options.setInstances(Runtime.getRuntime().availableProcessors() * 2);\n+    } else {\n+      options.setInstances(verticleInstances);\n+    }\n+    log.info(\"Deploying \" + options.getInstances() + \" instances of server verticle\");\n+    options.setConfig(config);\n+    VertxCompletableFuture<String> future = new VertxCompletableFuture<>();\n+    vertx.deployVerticle(\n+        () -> new ServerVerticle(endpoints, httpServerOptions, this), options, future);\n+    try {\n+      deploymentID = future.get();\n+    } catch (Exception e) {\n+      throw new RuntimeException(e);\n+    }\n+    log.info(\"API server started: \" + deploymentID);\n+  }\n+\n+  public synchronized void stop() {\n+    if (deploymentID == null) {\n+      throw new IllegalStateException(\"Not started\");\n+    }\n+    VertxCompletableFuture<Void> future = new VertxCompletableFuture<>();\n+    vertx.undeploy(deploymentID, future);\n+    try {\n+      future.get();\n+    } catch (Exception e) {\n+      throw new RuntimeException(e);\n+    }\n+  }\n+\n+  String registerQuery(final QuerySubscriber querySubscriber) {\n+    String uuid = UUID.randomUUID().toString();\n+    queries.put(uuid, querySubscriber);\n+    return uuid;\n+  }\n+\n+  QuerySubscriber removeQuery(final String queryID) {\n+    return queries.remove(queryID);\n+  }\n+\n+  public Set<String> getQueryIDs() {\n+    return new HashSet<>(queries.keySet());\n+  }\n+\n+  void registerQueryConnection(final HttpConnection connection) {\n+    this.connections.add(connection);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 110}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MDE0MjYyOnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerUtils.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzoxMjoxMlrOFeY1mA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzoxMjoxMlrOFeY1mA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwODUzNg==", "bodyText": "As above, consider using a Pojo.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367408536", "createdAt": "2020-01-16T13:12:12Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerUtils.java", "diffHunk": "@@ -0,0 +1,41 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.http.HttpServerResponse;\n+import io.vertx.core.json.JsonObject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * static util methods used in the server\n+ */\n+public class ServerUtils {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ServerUtils.class);\n+\n+  public static void handleError(final HttpServerResponse response, final int statusCode,\n+      final int errorCode, final String errMsg) {\n+    JsonObject errResponse = new JsonObject().put(\"status\", \"error\").put(\"errorCode\", errorCode)\n+        .put(\"message\", errMsg);\n+    response.setStatusCode(statusCode).end(errResponse.toBuffer());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 34}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MDE0NTA4OnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerUtils.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzoxMzowN1rOFeY3Pw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxNzowMjoxNFrOFeg0bg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwODk1OQ==", "bodyText": "nit: Function name out of whack with impl, e.g. consider naming it unhandledExceptionHandler or logUnhandledExcpetion, or similar.\nOut of interest, when would this be called? / should this be called in normal operation?\nOr is this just WIP?", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367408959", "createdAt": "2020-01-16T13:13:07Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerUtils.java", "diffHunk": "@@ -0,0 +1,41 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.http.HttpServerResponse;\n+import io.vertx.core.json.JsonObject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * static util methods used in the server\n+ */\n+public class ServerUtils {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ServerUtils.class);\n+\n+  public static void handleError(final HttpServerResponse response, final int statusCode,\n+      final int errorCode, final String errMsg) {\n+    JsonObject errResponse = new JsonObject().put(\"status\", \"error\").put(\"errorCode\", errorCode)\n+        .put(\"message\", errMsg);\n+    response.setStatusCode(statusCode).end(errResponse.toBuffer());\n+  }\n+\n+  public static void handleException(final Throwable t) {\n+    log.error(\"Unhandled exception\", t);\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzUzOTMxMA==", "bodyText": "It will be called for any unchecked exceptions thrown from handlers.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367539310", "createdAt": "2020-01-16T17:02:14Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerUtils.java", "diffHunk": "@@ -0,0 +1,41 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.http.HttpServerResponse;\n+import io.vertx.core.json.JsonObject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * static util methods used in the server\n+ */\n+public class ServerUtils {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ServerUtils.class);\n+\n+  public static void handleError(final HttpServerResponse response, final int statusCode,\n+      final int errorCode, final String errMsg) {\n+    JsonObject errResponse = new JsonObject().put(\"status\", \"error\").put(\"errorCode\", errorCode)\n+        .put(\"message\", errMsg);\n+    response.setStatusCode(statusCode).end(errResponse.toBuffer());\n+  }\n+\n+  public static void handleException(final Throwable t) {\n+    log.error(\"Unhandled exception\", t);\n+  }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwODk1OQ=="}, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 39}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MDE0OTQ4OnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerVerticle.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzoxNDo0N1rOFeY5_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzoxNDo0N1rOFeY5_g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwOTY2Mg==", "bodyText": "nit: null checks.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367409662", "createdAt": "2020-01-16T13:14:47Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerVerticle.java", "diffHunk": "@@ -0,0 +1,201 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.impl.Utils;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.QueryPublisher;\n+import io.vertx.core.AbstractVerticle;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Promise;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpMethod;\n+import io.vertx.core.http.HttpServer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.parsetools.RecordParser;\n+import io.vertx.ext.web.Router;\n+import io.vertx.ext.web.RoutingContext;\n+import io.vertx.ext.web.handler.BodyHandler;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * The server deploys multiple server verticles. This is where the HTTP2 requests are handled. The\n+ * actual implementation of the endpoints is provided by an implementation of {@code Endpoints}.\n+ */\n+public class ServerVerticle extends AbstractVerticle {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ServerVerticle.class);\n+\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Server server;\n+  private final Map<HttpConnection, ConnectionQueries> connectionsMap = new HashMap<>();\n+  private HttpServer httpServer;\n+\n+  public ServerVerticle(final Endpoints endpoints, final HttpServerOptions httpServerOptions,\n+      final Server server) {\n+    this.endpoints = endpoints;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 61}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MDE1NTA2OnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/impl/Utils.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzoxNjo0NlrOFeY9dw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzoxNjo0NlrOFeY9dw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQxMDU1MQ==", "bodyText": "Can't say I'm a fan of Utils classes.  This has the risk it will just become a dumping ground for a load of unrelated methods.  Could we possibly have a more targeted name? e.g. ReactiveUtils ?", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367410551", "createdAt": "2020-01-16T13:16:46Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/impl/Utils.java", "diffHunk": "@@ -0,0 +1,37 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.impl;\n+\n+import io.vertx.core.Future;\n+import io.vertx.core.Promise;\n+\n+/**\n+ * General purpose utils (not limited to the server, could be used by client too) for the API\n+ * module.\n+ */\n+public class Utils {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MDE2MjE0OnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerVerticle.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzoxOToxMlrOFeZBqQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMFQxNzoxMjowMFrOFfk8vw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQxMTYyNQ==", "bodyText": "Again, can we use Pojo's to avoid this manual / inline handling and validation of Json, please?", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367411625", "createdAt": "2020-01-16T13:19:12Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerVerticle.java", "diffHunk": "@@ -0,0 +1,201 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.impl.Utils;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.QueryPublisher;\n+import io.vertx.core.AbstractVerticle;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Promise;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpMethod;\n+import io.vertx.core.http.HttpServer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.parsetools.RecordParser;\n+import io.vertx.ext.web.Router;\n+import io.vertx.ext.web.RoutingContext;\n+import io.vertx.ext.web.handler.BodyHandler;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * The server deploys multiple server verticles. This is where the HTTP2 requests are handled. The\n+ * actual implementation of the endpoints is provided by an implementation of {@code Endpoints}.\n+ */\n+public class ServerVerticle extends AbstractVerticle {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ServerVerticle.class);\n+\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Server server;\n+  private final Map<HttpConnection, ConnectionQueries> connectionsMap = new HashMap<>();\n+  private HttpServer httpServer;\n+\n+  public ServerVerticle(final Endpoints endpoints, final HttpServerOptions httpServerOptions,\n+      final Server server) {\n+    this.endpoints = endpoints;\n+    this.httpServerOptions = httpServerOptions;\n+    this.server = server;\n+  }\n+\n+  @Override\n+  public void start(final Promise<Void> startPromise) {\n+    httpServer = vertx.createHttpServer(httpServerOptions).requestHandler(setupRouter())\n+        .exceptionHandler(ServerUtils::handleException);\n+    Future<HttpServer> listenFuture = Promise.<HttpServer>promise().future();\n+    Utils.connectPromise(listenFuture.map(s -> null), startPromise);\n+    httpServer.listen(listenFuture);\n+    vertx.getOrCreateContext().exceptionHandler(ServerUtils::handleException);\n+  }\n+\n+  @Override\n+  public void stop(final Promise<Void> stopPromise) {\n+    if (httpServer == null) {\n+      stopPromise.complete();\n+    } else {\n+      httpServer.close(stopPromise.future());\n+    }\n+  }\n+\n+  private Router setupRouter() {\n+    Router router = Router.router(vertx);\n+    router.route(HttpMethod.POST, \"/query-stream\").handler(BodyHandler.create())\n+        .handler(this::handleQueryStream);\n+    router.route(HttpMethod.POST, \"/inserts-stream\").handler(this::handleInsertsStream);\n+    router.route(HttpMethod.POST, \"/close-query\").handler(BodyHandler.create())\n+        .handler(this::handleCloseQuery);\n+    return router;\n+  }\n+\n+  private void handleInsertsStream(final RoutingContext routingContext) {\n+    RecordParser recordParser = RecordParser\n+        .newDelimited(\"\\n\", new InsertsBodyParser(endpoints, routingContext)::handleBodyBuffer);\n+    routingContext.request()\n+        .handler(recordParser);\n+  }\n+\n+  private void handleQueryStream(final RoutingContext routingContext) {\n+    HttpConnection conn = routingContext.request().connection();\n+    ConnectionQueries connectionQueries = connectionsMap.get(conn);\n+    if (connectionQueries == null) {\n+      connectionQueries = new ConnectionQueries(conn);\n+      connectionsMap.put(conn, connectionQueries);\n+      conn.closeHandler(connectionQueries);\n+      server.registerQueryConnection(conn);\n+    }\n+    JsonObject requestBody = routingContext.getBodyAsJson();\n+    String sql = requestBody.getString(\"sql\");\n+    if (sql == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No sql in arguments\");\n+      return;\n+    }\n+    Boolean push = requestBody.getBoolean(\"push\");\n+    if (push == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No push in arguments\");\n+      return;\n+    }\n+    JsonObject properties = requestBody.getJsonObject(\"properties\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 122}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU4NDA0Mw==", "bodyText": "Perhaps you could give an example of how you would do this with a POJO as it's not clear to me.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367584043", "createdAt": "2020-01-16T18:39:01Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerVerticle.java", "diffHunk": "@@ -0,0 +1,201 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.impl.Utils;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.QueryPublisher;\n+import io.vertx.core.AbstractVerticle;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Promise;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpMethod;\n+import io.vertx.core.http.HttpServer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.parsetools.RecordParser;\n+import io.vertx.ext.web.Router;\n+import io.vertx.ext.web.RoutingContext;\n+import io.vertx.ext.web.handler.BodyHandler;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * The server deploys multiple server verticles. This is where the HTTP2 requests are handled. The\n+ * actual implementation of the endpoints is provided by an implementation of {@code Endpoints}.\n+ */\n+public class ServerVerticle extends AbstractVerticle {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ServerVerticle.class);\n+\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Server server;\n+  private final Map<HttpConnection, ConnectionQueries> connectionsMap = new HashMap<>();\n+  private HttpServer httpServer;\n+\n+  public ServerVerticle(final Endpoints endpoints, final HttpServerOptions httpServerOptions,\n+      final Server server) {\n+    this.endpoints = endpoints;\n+    this.httpServerOptions = httpServerOptions;\n+    this.server = server;\n+  }\n+\n+  @Override\n+  public void start(final Promise<Void> startPromise) {\n+    httpServer = vertx.createHttpServer(httpServerOptions).requestHandler(setupRouter())\n+        .exceptionHandler(ServerUtils::handleException);\n+    Future<HttpServer> listenFuture = Promise.<HttpServer>promise().future();\n+    Utils.connectPromise(listenFuture.map(s -> null), startPromise);\n+    httpServer.listen(listenFuture);\n+    vertx.getOrCreateContext().exceptionHandler(ServerUtils::handleException);\n+  }\n+\n+  @Override\n+  public void stop(final Promise<Void> stopPromise) {\n+    if (httpServer == null) {\n+      stopPromise.complete();\n+    } else {\n+      httpServer.close(stopPromise.future());\n+    }\n+  }\n+\n+  private Router setupRouter() {\n+    Router router = Router.router(vertx);\n+    router.route(HttpMethod.POST, \"/query-stream\").handler(BodyHandler.create())\n+        .handler(this::handleQueryStream);\n+    router.route(HttpMethod.POST, \"/inserts-stream\").handler(this::handleInsertsStream);\n+    router.route(HttpMethod.POST, \"/close-query\").handler(BodyHandler.create())\n+        .handler(this::handleCloseQuery);\n+    return router;\n+  }\n+\n+  private void handleInsertsStream(final RoutingContext routingContext) {\n+    RecordParser recordParser = RecordParser\n+        .newDelimited(\"\\n\", new InsertsBodyParser(endpoints, routingContext)::handleBodyBuffer);\n+    routingContext.request()\n+        .handler(recordParser);\n+  }\n+\n+  private void handleQueryStream(final RoutingContext routingContext) {\n+    HttpConnection conn = routingContext.request().connection();\n+    ConnectionQueries connectionQueries = connectionsMap.get(conn);\n+    if (connectionQueries == null) {\n+      connectionQueries = new ConnectionQueries(conn);\n+      connectionsMap.put(conn, connectionQueries);\n+      conn.closeHandler(connectionQueries);\n+      server.registerQueryConnection(conn);\n+    }\n+    JsonObject requestBody = routingContext.getBodyAsJson();\n+    String sql = requestBody.getString(\"sql\");\n+    if (sql == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No sql in arguments\");\n+      return;\n+    }\n+    Boolean push = requestBody.getBoolean(\"push\");\n+    if (push == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No push in arguments\");\n+      return;\n+    }\n+    JsonObject properties = requestBody.getJsonObject(\"properties\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQxMTYyNQ=="}, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 122}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODY1NTU1MQ==", "bodyText": "See above.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368655551", "createdAt": "2020-01-20T17:12:00Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerVerticle.java", "diffHunk": "@@ -0,0 +1,201 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.impl.Utils;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.QueryPublisher;\n+import io.vertx.core.AbstractVerticle;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Promise;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpMethod;\n+import io.vertx.core.http.HttpServer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.parsetools.RecordParser;\n+import io.vertx.ext.web.Router;\n+import io.vertx.ext.web.RoutingContext;\n+import io.vertx.ext.web.handler.BodyHandler;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * The server deploys multiple server verticles. This is where the HTTP2 requests are handled. The\n+ * actual implementation of the endpoints is provided by an implementation of {@code Endpoints}.\n+ */\n+public class ServerVerticle extends AbstractVerticle {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ServerVerticle.class);\n+\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Server server;\n+  private final Map<HttpConnection, ConnectionQueries> connectionsMap = new HashMap<>();\n+  private HttpServer httpServer;\n+\n+  public ServerVerticle(final Endpoints endpoints, final HttpServerOptions httpServerOptions,\n+      final Server server) {\n+    this.endpoints = endpoints;\n+    this.httpServerOptions = httpServerOptions;\n+    this.server = server;\n+  }\n+\n+  @Override\n+  public void start(final Promise<Void> startPromise) {\n+    httpServer = vertx.createHttpServer(httpServerOptions).requestHandler(setupRouter())\n+        .exceptionHandler(ServerUtils::handleException);\n+    Future<HttpServer> listenFuture = Promise.<HttpServer>promise().future();\n+    Utils.connectPromise(listenFuture.map(s -> null), startPromise);\n+    httpServer.listen(listenFuture);\n+    vertx.getOrCreateContext().exceptionHandler(ServerUtils::handleException);\n+  }\n+\n+  @Override\n+  public void stop(final Promise<Void> stopPromise) {\n+    if (httpServer == null) {\n+      stopPromise.complete();\n+    } else {\n+      httpServer.close(stopPromise.future());\n+    }\n+  }\n+\n+  private Router setupRouter() {\n+    Router router = Router.router(vertx);\n+    router.route(HttpMethod.POST, \"/query-stream\").handler(BodyHandler.create())\n+        .handler(this::handleQueryStream);\n+    router.route(HttpMethod.POST, \"/inserts-stream\").handler(this::handleInsertsStream);\n+    router.route(HttpMethod.POST, \"/close-query\").handler(BodyHandler.create())\n+        .handler(this::handleCloseQuery);\n+    return router;\n+  }\n+\n+  private void handleInsertsStream(final RoutingContext routingContext) {\n+    RecordParser recordParser = RecordParser\n+        .newDelimited(\"\\n\", new InsertsBodyParser(endpoints, routingContext)::handleBodyBuffer);\n+    routingContext.request()\n+        .handler(recordParser);\n+  }\n+\n+  private void handleQueryStream(final RoutingContext routingContext) {\n+    HttpConnection conn = routingContext.request().connection();\n+    ConnectionQueries connectionQueries = connectionsMap.get(conn);\n+    if (connectionQueries == null) {\n+      connectionQueries = new ConnectionQueries(conn);\n+      connectionsMap.put(conn, connectionQueries);\n+      conn.closeHandler(connectionQueries);\n+      server.registerQueryConnection(conn);\n+    }\n+    JsonObject requestBody = routingContext.getBodyAsJson();\n+    String sql = requestBody.getString(\"sql\");\n+    if (sql == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No sql in arguments\");\n+      return;\n+    }\n+    Boolean push = requestBody.getBoolean(\"push\");\n+    if (push == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No push in arguments\");\n+      return;\n+    }\n+    JsonObject properties = requestBody.getJsonObject(\"properties\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQxMTYyNQ=="}, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 122}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MDE2NTc2OnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerVerticle.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzoyMDozMVrOFeZD9Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QwNTo1NzowOFrOFevgPg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQxMjIxMw==", "bodyText": "Is this queryId the same as our QueryId class that is used to identify queries?  If it is, can we use the more strongly typed QueryId class?\nIf its not... maybe use a different type to differentiate and avoid confusion?", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367412213", "createdAt": "2020-01-16T13:20:31Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerVerticle.java", "diffHunk": "@@ -0,0 +1,201 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.impl.Utils;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.QueryPublisher;\n+import io.vertx.core.AbstractVerticle;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Promise;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpMethod;\n+import io.vertx.core.http.HttpServer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.parsetools.RecordParser;\n+import io.vertx.ext.web.Router;\n+import io.vertx.ext.web.RoutingContext;\n+import io.vertx.ext.web.handler.BodyHandler;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * The server deploys multiple server verticles. This is where the HTTP2 requests are handled. The\n+ * actual implementation of the endpoints is provided by an implementation of {@code Endpoints}.\n+ */\n+public class ServerVerticle extends AbstractVerticle {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ServerVerticle.class);\n+\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Server server;\n+  private final Map<HttpConnection, ConnectionQueries> connectionsMap = new HashMap<>();\n+  private HttpServer httpServer;\n+\n+  public ServerVerticle(final Endpoints endpoints, final HttpServerOptions httpServerOptions,\n+      final Server server) {\n+    this.endpoints = endpoints;\n+    this.httpServerOptions = httpServerOptions;\n+    this.server = server;\n+  }\n+\n+  @Override\n+  public void start(final Promise<Void> startPromise) {\n+    httpServer = vertx.createHttpServer(httpServerOptions).requestHandler(setupRouter())\n+        .exceptionHandler(ServerUtils::handleException);\n+    Future<HttpServer> listenFuture = Promise.<HttpServer>promise().future();\n+    Utils.connectPromise(listenFuture.map(s -> null), startPromise);\n+    httpServer.listen(listenFuture);\n+    vertx.getOrCreateContext().exceptionHandler(ServerUtils::handleException);\n+  }\n+\n+  @Override\n+  public void stop(final Promise<Void> stopPromise) {\n+    if (httpServer == null) {\n+      stopPromise.complete();\n+    } else {\n+      httpServer.close(stopPromise.future());\n+    }\n+  }\n+\n+  private Router setupRouter() {\n+    Router router = Router.router(vertx);\n+    router.route(HttpMethod.POST, \"/query-stream\").handler(BodyHandler.create())\n+        .handler(this::handleQueryStream);\n+    router.route(HttpMethod.POST, \"/inserts-stream\").handler(this::handleInsertsStream);\n+    router.route(HttpMethod.POST, \"/close-query\").handler(BodyHandler.create())\n+        .handler(this::handleCloseQuery);\n+    return router;\n+  }\n+\n+  private void handleInsertsStream(final RoutingContext routingContext) {\n+    RecordParser recordParser = RecordParser\n+        .newDelimited(\"\\n\", new InsertsBodyParser(endpoints, routingContext)::handleBodyBuffer);\n+    routingContext.request()\n+        .handler(recordParser);\n+  }\n+\n+  private void handleQueryStream(final RoutingContext routingContext) {\n+    HttpConnection conn = routingContext.request().connection();\n+    ConnectionQueries connectionQueries = connectionsMap.get(conn);\n+    if (connectionQueries == null) {\n+      connectionQueries = new ConnectionQueries(conn);\n+      connectionsMap.put(conn, connectionQueries);\n+      conn.closeHandler(connectionQueries);\n+      server.registerQueryConnection(conn);\n+    }\n+    JsonObject requestBody = routingContext.getBodyAsJson();\n+    String sql = requestBody.getString(\"sql\");\n+    if (sql == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No sql in arguments\");\n+      return;\n+    }\n+    Boolean push = requestBody.getBoolean(\"push\");\n+    if (push == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No push in arguments\");\n+      return;\n+    }\n+    JsonObject properties = requestBody.getJsonObject(\"properties\");\n+    QueryPublisher queryPublisher = endpoints.createQueryPublisher(sql, push, properties);\n+    QuerySubscriber querySubscriber = new QuerySubscriber(routingContext.response());\n+\n+    String queryID = server.registerQuery(querySubscriber);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 126}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzYzNDk1MQ==", "bodyText": "It's a cryptographically secure, random UUID.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367634951", "createdAt": "2020-01-16T20:32:38Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerVerticle.java", "diffHunk": "@@ -0,0 +1,201 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.impl.Utils;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.QueryPublisher;\n+import io.vertx.core.AbstractVerticle;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Promise;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpMethod;\n+import io.vertx.core.http.HttpServer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.parsetools.RecordParser;\n+import io.vertx.ext.web.Router;\n+import io.vertx.ext.web.RoutingContext;\n+import io.vertx.ext.web.handler.BodyHandler;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * The server deploys multiple server verticles. This is where the HTTP2 requests are handled. The\n+ * actual implementation of the endpoints is provided by an implementation of {@code Endpoints}.\n+ */\n+public class ServerVerticle extends AbstractVerticle {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ServerVerticle.class);\n+\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Server server;\n+  private final Map<HttpConnection, ConnectionQueries> connectionsMap = new HashMap<>();\n+  private HttpServer httpServer;\n+\n+  public ServerVerticle(final Endpoints endpoints, final HttpServerOptions httpServerOptions,\n+      final Server server) {\n+    this.endpoints = endpoints;\n+    this.httpServerOptions = httpServerOptions;\n+    this.server = server;\n+  }\n+\n+  @Override\n+  public void start(final Promise<Void> startPromise) {\n+    httpServer = vertx.createHttpServer(httpServerOptions).requestHandler(setupRouter())\n+        .exceptionHandler(ServerUtils::handleException);\n+    Future<HttpServer> listenFuture = Promise.<HttpServer>promise().future();\n+    Utils.connectPromise(listenFuture.map(s -> null), startPromise);\n+    httpServer.listen(listenFuture);\n+    vertx.getOrCreateContext().exceptionHandler(ServerUtils::handleException);\n+  }\n+\n+  @Override\n+  public void stop(final Promise<Void> stopPromise) {\n+    if (httpServer == null) {\n+      stopPromise.complete();\n+    } else {\n+      httpServer.close(stopPromise.future());\n+    }\n+  }\n+\n+  private Router setupRouter() {\n+    Router router = Router.router(vertx);\n+    router.route(HttpMethod.POST, \"/query-stream\").handler(BodyHandler.create())\n+        .handler(this::handleQueryStream);\n+    router.route(HttpMethod.POST, \"/inserts-stream\").handler(this::handleInsertsStream);\n+    router.route(HttpMethod.POST, \"/close-query\").handler(BodyHandler.create())\n+        .handler(this::handleCloseQuery);\n+    return router;\n+  }\n+\n+  private void handleInsertsStream(final RoutingContext routingContext) {\n+    RecordParser recordParser = RecordParser\n+        .newDelimited(\"\\n\", new InsertsBodyParser(endpoints, routingContext)::handleBodyBuffer);\n+    routingContext.request()\n+        .handler(recordParser);\n+  }\n+\n+  private void handleQueryStream(final RoutingContext routingContext) {\n+    HttpConnection conn = routingContext.request().connection();\n+    ConnectionQueries connectionQueries = connectionsMap.get(conn);\n+    if (connectionQueries == null) {\n+      connectionQueries = new ConnectionQueries(conn);\n+      connectionsMap.put(conn, connectionQueries);\n+      conn.closeHandler(connectionQueries);\n+      server.registerQueryConnection(conn);\n+    }\n+    JsonObject requestBody = routingContext.getBodyAsJson();\n+    String sql = requestBody.getString(\"sql\");\n+    if (sql == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No sql in arguments\");\n+      return;\n+    }\n+    Boolean push = requestBody.getBoolean(\"push\");\n+    if (push == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No push in arguments\");\n+      return;\n+    }\n+    JsonObject properties = requestBody.getJsonObject(\"properties\");\n+    QueryPublisher queryPublisher = endpoints.createQueryPublisher(sql, push, properties);\n+    QuerySubscriber querySubscriber = new QuerySubscriber(routingContext.response());\n+\n+    String queryID = server.registerQuery(querySubscriber);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQxMjIxMw=="}, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 126}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc3OTkwMg==", "bodyText": "Ack wil change to a custom type", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367779902", "createdAt": "2020-01-17T05:57:08Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerVerticle.java", "diffHunk": "@@ -0,0 +1,201 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.impl.Utils;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.QueryPublisher;\n+import io.vertx.core.AbstractVerticle;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Promise;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpMethod;\n+import io.vertx.core.http.HttpServer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.parsetools.RecordParser;\n+import io.vertx.ext.web.Router;\n+import io.vertx.ext.web.RoutingContext;\n+import io.vertx.ext.web.handler.BodyHandler;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * The server deploys multiple server verticles. This is where the HTTP2 requests are handled. The\n+ * actual implementation of the endpoints is provided by an implementation of {@code Endpoints}.\n+ */\n+public class ServerVerticle extends AbstractVerticle {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ServerVerticle.class);\n+\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Server server;\n+  private final Map<HttpConnection, ConnectionQueries> connectionsMap = new HashMap<>();\n+  private HttpServer httpServer;\n+\n+  public ServerVerticle(final Endpoints endpoints, final HttpServerOptions httpServerOptions,\n+      final Server server) {\n+    this.endpoints = endpoints;\n+    this.httpServerOptions = httpServerOptions;\n+    this.server = server;\n+  }\n+\n+  @Override\n+  public void start(final Promise<Void> startPromise) {\n+    httpServer = vertx.createHttpServer(httpServerOptions).requestHandler(setupRouter())\n+        .exceptionHandler(ServerUtils::handleException);\n+    Future<HttpServer> listenFuture = Promise.<HttpServer>promise().future();\n+    Utils.connectPromise(listenFuture.map(s -> null), startPromise);\n+    httpServer.listen(listenFuture);\n+    vertx.getOrCreateContext().exceptionHandler(ServerUtils::handleException);\n+  }\n+\n+  @Override\n+  public void stop(final Promise<Void> stopPromise) {\n+    if (httpServer == null) {\n+      stopPromise.complete();\n+    } else {\n+      httpServer.close(stopPromise.future());\n+    }\n+  }\n+\n+  private Router setupRouter() {\n+    Router router = Router.router(vertx);\n+    router.route(HttpMethod.POST, \"/query-stream\").handler(BodyHandler.create())\n+        .handler(this::handleQueryStream);\n+    router.route(HttpMethod.POST, \"/inserts-stream\").handler(this::handleInsertsStream);\n+    router.route(HttpMethod.POST, \"/close-query\").handler(BodyHandler.create())\n+        .handler(this::handleCloseQuery);\n+    return router;\n+  }\n+\n+  private void handleInsertsStream(final RoutingContext routingContext) {\n+    RecordParser recordParser = RecordParser\n+        .newDelimited(\"\\n\", new InsertsBodyParser(endpoints, routingContext)::handleBodyBuffer);\n+    routingContext.request()\n+        .handler(recordParser);\n+  }\n+\n+  private void handleQueryStream(final RoutingContext routingContext) {\n+    HttpConnection conn = routingContext.request().connection();\n+    ConnectionQueries connectionQueries = connectionsMap.get(conn);\n+    if (connectionQueries == null) {\n+      connectionQueries = new ConnectionQueries(conn);\n+      connectionsMap.put(conn, connectionQueries);\n+      conn.closeHandler(connectionQueries);\n+      server.registerQueryConnection(conn);\n+    }\n+    JsonObject requestBody = routingContext.getBodyAsJson();\n+    String sql = requestBody.getString(\"sql\");\n+    if (sql == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No sql in arguments\");\n+      return;\n+    }\n+    Boolean push = requestBody.getBoolean(\"push\");\n+    if (push == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No push in arguments\");\n+      return;\n+    }\n+    JsonObject properties = requestBody.getJsonObject(\"properties\");\n+    QueryPublisher queryPublisher = endpoints.createQueryPublisher(sql, push, properties);\n+    QuerySubscriber querySubscriber = new QuerySubscriber(routingContext.response());\n+\n+    String queryID = server.registerQuery(querySubscriber);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQxMjIxMw=="}, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 126}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MDE2NjMxOnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerVerticle.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzoyMDo0M1rOFeZEUA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzoyMDo0M1rOFeZEUA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQxMjMwNA==", "bodyText": "Replace with Pojo?", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367412304", "createdAt": "2020-01-16T13:20:43Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerVerticle.java", "diffHunk": "@@ -0,0 +1,201 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.impl.Utils;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.QueryPublisher;\n+import io.vertx.core.AbstractVerticle;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Promise;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpMethod;\n+import io.vertx.core.http.HttpServer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.parsetools.RecordParser;\n+import io.vertx.ext.web.Router;\n+import io.vertx.ext.web.RoutingContext;\n+import io.vertx.ext.web.handler.BodyHandler;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * The server deploys multiple server verticles. This is where the HTTP2 requests are handled. The\n+ * actual implementation of the endpoints is provided by an implementation of {@code Endpoints}.\n+ */\n+public class ServerVerticle extends AbstractVerticle {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ServerVerticle.class);\n+\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Server server;\n+  private final Map<HttpConnection, ConnectionQueries> connectionsMap = new HashMap<>();\n+  private HttpServer httpServer;\n+\n+  public ServerVerticle(final Endpoints endpoints, final HttpServerOptions httpServerOptions,\n+      final Server server) {\n+    this.endpoints = endpoints;\n+    this.httpServerOptions = httpServerOptions;\n+    this.server = server;\n+  }\n+\n+  @Override\n+  public void start(final Promise<Void> startPromise) {\n+    httpServer = vertx.createHttpServer(httpServerOptions).requestHandler(setupRouter())\n+        .exceptionHandler(ServerUtils::handleException);\n+    Future<HttpServer> listenFuture = Promise.<HttpServer>promise().future();\n+    Utils.connectPromise(listenFuture.map(s -> null), startPromise);\n+    httpServer.listen(listenFuture);\n+    vertx.getOrCreateContext().exceptionHandler(ServerUtils::handleException);\n+  }\n+\n+  @Override\n+  public void stop(final Promise<Void> stopPromise) {\n+    if (httpServer == null) {\n+      stopPromise.complete();\n+    } else {\n+      httpServer.close(stopPromise.future());\n+    }\n+  }\n+\n+  private Router setupRouter() {\n+    Router router = Router.router(vertx);\n+    router.route(HttpMethod.POST, \"/query-stream\").handler(BodyHandler.create())\n+        .handler(this::handleQueryStream);\n+    router.route(HttpMethod.POST, \"/inserts-stream\").handler(this::handleInsertsStream);\n+    router.route(HttpMethod.POST, \"/close-query\").handler(BodyHandler.create())\n+        .handler(this::handleCloseQuery);\n+    return router;\n+  }\n+\n+  private void handleInsertsStream(final RoutingContext routingContext) {\n+    RecordParser recordParser = RecordParser\n+        .newDelimited(\"\\n\", new InsertsBodyParser(endpoints, routingContext)::handleBodyBuffer);\n+    routingContext.request()\n+        .handler(recordParser);\n+  }\n+\n+  private void handleQueryStream(final RoutingContext routingContext) {\n+    HttpConnection conn = routingContext.request().connection();\n+    ConnectionQueries connectionQueries = connectionsMap.get(conn);\n+    if (connectionQueries == null) {\n+      connectionQueries = new ConnectionQueries(conn);\n+      connectionsMap.put(conn, connectionQueries);\n+      conn.closeHandler(connectionQueries);\n+      server.registerQueryConnection(conn);\n+    }\n+    JsonObject requestBody = routingContext.getBodyAsJson();\n+    String sql = requestBody.getString(\"sql\");\n+    if (sql == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No sql in arguments\");\n+      return;\n+    }\n+    Boolean push = requestBody.getBoolean(\"push\");\n+    if (push == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No push in arguments\");\n+      return;\n+    }\n+    JsonObject properties = requestBody.getJsonObject(\"properties\");\n+    QueryPublisher queryPublisher = endpoints.createQueryPublisher(sql, push, properties);\n+    QuerySubscriber querySubscriber = new QuerySubscriber(routingContext.response());\n+\n+    String queryID = server.registerQuery(querySubscriber);\n+    connectionQueries.addQuery(queryID);\n+    JsonObject metadata = new JsonObject();\n+    metadata.put(\"columnNames\", queryPublisher.getColumnNames());\n+    metadata.put(\"columnTypes\", queryPublisher.getColumnTypes());\n+    metadata.put(\"queryID\", queryID);\n+    if (!push) {\n+      metadata.put(\"rowCount\", queryPublisher.getRowCount());\n+    }\n+    routingContext.response().write(metadata.toBuffer()).write(\"\\n\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 135}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MDE2ODM0OnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerVerticle.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzoyMToyN1rOFeZFhg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMFQxNzoxNjowMFrOFflCvw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQxMjYxNA==", "bodyText": "out of interest, what does returning false actually mean?", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367412614", "createdAt": "2020-01-16T13:21:27Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerVerticle.java", "diffHunk": "@@ -0,0 +1,201 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.impl.Utils;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.QueryPublisher;\n+import io.vertx.core.AbstractVerticle;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Promise;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpMethod;\n+import io.vertx.core.http.HttpServer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.parsetools.RecordParser;\n+import io.vertx.ext.web.Router;\n+import io.vertx.ext.web.RoutingContext;\n+import io.vertx.ext.web.handler.BodyHandler;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * The server deploys multiple server verticles. This is where the HTTP2 requests are handled. The\n+ * actual implementation of the endpoints is provided by an implementation of {@code Endpoints}.\n+ */\n+public class ServerVerticle extends AbstractVerticle {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ServerVerticle.class);\n+\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Server server;\n+  private final Map<HttpConnection, ConnectionQueries> connectionsMap = new HashMap<>();\n+  private HttpServer httpServer;\n+\n+  public ServerVerticle(final Endpoints endpoints, final HttpServerOptions httpServerOptions,\n+      final Server server) {\n+    this.endpoints = endpoints;\n+    this.httpServerOptions = httpServerOptions;\n+    this.server = server;\n+  }\n+\n+  @Override\n+  public void start(final Promise<Void> startPromise) {\n+    httpServer = vertx.createHttpServer(httpServerOptions).requestHandler(setupRouter())\n+        .exceptionHandler(ServerUtils::handleException);\n+    Future<HttpServer> listenFuture = Promise.<HttpServer>promise().future();\n+    Utils.connectPromise(listenFuture.map(s -> null), startPromise);\n+    httpServer.listen(listenFuture);\n+    vertx.getOrCreateContext().exceptionHandler(ServerUtils::handleException);\n+  }\n+\n+  @Override\n+  public void stop(final Promise<Void> stopPromise) {\n+    if (httpServer == null) {\n+      stopPromise.complete();\n+    } else {\n+      httpServer.close(stopPromise.future());\n+    }\n+  }\n+\n+  private Router setupRouter() {\n+    Router router = Router.router(vertx);\n+    router.route(HttpMethod.POST, \"/query-stream\").handler(BodyHandler.create())\n+        .handler(this::handleQueryStream);\n+    router.route(HttpMethod.POST, \"/inserts-stream\").handler(this::handleInsertsStream);\n+    router.route(HttpMethod.POST, \"/close-query\").handler(BodyHandler.create())\n+        .handler(this::handleCloseQuery);\n+    return router;\n+  }\n+\n+  private void handleInsertsStream(final RoutingContext routingContext) {\n+    RecordParser recordParser = RecordParser\n+        .newDelimited(\"\\n\", new InsertsBodyParser(endpoints, routingContext)::handleBodyBuffer);\n+    routingContext.request()\n+        .handler(recordParser);\n+  }\n+\n+  private void handleQueryStream(final RoutingContext routingContext) {\n+    HttpConnection conn = routingContext.request().connection();\n+    ConnectionQueries connectionQueries = connectionsMap.get(conn);\n+    if (connectionQueries == null) {\n+      connectionQueries = new ConnectionQueries(conn);\n+      connectionsMap.put(conn, connectionQueries);\n+      conn.closeHandler(connectionQueries);\n+      server.registerQueryConnection(conn);\n+    }\n+    JsonObject requestBody = routingContext.getBodyAsJson();\n+    String sql = requestBody.getString(\"sql\");\n+    if (sql == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No sql in arguments\");\n+      return;\n+    }\n+    Boolean push = requestBody.getBoolean(\"push\");\n+    if (push == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No push in arguments\");\n+      return;\n+    }\n+    JsonObject properties = requestBody.getJsonObject(\"properties\");\n+    QueryPublisher queryPublisher = endpoints.createQueryPublisher(sql, push, properties);\n+    QuerySubscriber querySubscriber = new QuerySubscriber(routingContext.response());\n+\n+    String queryID = server.registerQuery(querySubscriber);\n+    connectionQueries.addQuery(queryID);\n+    JsonObject metadata = new JsonObject();\n+    metadata.put(\"columnNames\", queryPublisher.getColumnNames());\n+    metadata.put(\"columnTypes\", queryPublisher.getColumnTypes());\n+    metadata.put(\"queryID\", queryID);\n+    if (!push) {\n+      metadata.put(\"rowCount\", queryPublisher.getRowCount());\n+    }\n+    routingContext.response().write(metadata.toBuffer()).write(\"\\n\");\n+    queryPublisher.subscribe(querySubscriber);\n+\n+    // When response is complete, publisher should be closed and query unregistered\n+    routingContext.response().endHandler(v -> closeQuery(queryID, routingContext));\n+  }\n+\n+  private boolean closeQuery(final String queryID, final RoutingContext routingContext) {\n+    QuerySubscriber querySubscriber = server.removeQuery(queryID);\n+    if (querySubscriber == null) {\n+      return false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 145}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzUwNjc2MA==", "bodyText": "It means the query wasn't found", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367506760", "createdAt": "2020-01-16T16:07:05Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerVerticle.java", "diffHunk": "@@ -0,0 +1,201 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.impl.Utils;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.QueryPublisher;\n+import io.vertx.core.AbstractVerticle;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Promise;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpMethod;\n+import io.vertx.core.http.HttpServer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.parsetools.RecordParser;\n+import io.vertx.ext.web.Router;\n+import io.vertx.ext.web.RoutingContext;\n+import io.vertx.ext.web.handler.BodyHandler;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * The server deploys multiple server verticles. This is where the HTTP2 requests are handled. The\n+ * actual implementation of the endpoints is provided by an implementation of {@code Endpoints}.\n+ */\n+public class ServerVerticle extends AbstractVerticle {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ServerVerticle.class);\n+\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Server server;\n+  private final Map<HttpConnection, ConnectionQueries> connectionsMap = new HashMap<>();\n+  private HttpServer httpServer;\n+\n+  public ServerVerticle(final Endpoints endpoints, final HttpServerOptions httpServerOptions,\n+      final Server server) {\n+    this.endpoints = endpoints;\n+    this.httpServerOptions = httpServerOptions;\n+    this.server = server;\n+  }\n+\n+  @Override\n+  public void start(final Promise<Void> startPromise) {\n+    httpServer = vertx.createHttpServer(httpServerOptions).requestHandler(setupRouter())\n+        .exceptionHandler(ServerUtils::handleException);\n+    Future<HttpServer> listenFuture = Promise.<HttpServer>promise().future();\n+    Utils.connectPromise(listenFuture.map(s -> null), startPromise);\n+    httpServer.listen(listenFuture);\n+    vertx.getOrCreateContext().exceptionHandler(ServerUtils::handleException);\n+  }\n+\n+  @Override\n+  public void stop(final Promise<Void> stopPromise) {\n+    if (httpServer == null) {\n+      stopPromise.complete();\n+    } else {\n+      httpServer.close(stopPromise.future());\n+    }\n+  }\n+\n+  private Router setupRouter() {\n+    Router router = Router.router(vertx);\n+    router.route(HttpMethod.POST, \"/query-stream\").handler(BodyHandler.create())\n+        .handler(this::handleQueryStream);\n+    router.route(HttpMethod.POST, \"/inserts-stream\").handler(this::handleInsertsStream);\n+    router.route(HttpMethod.POST, \"/close-query\").handler(BodyHandler.create())\n+        .handler(this::handleCloseQuery);\n+    return router;\n+  }\n+\n+  private void handleInsertsStream(final RoutingContext routingContext) {\n+    RecordParser recordParser = RecordParser\n+        .newDelimited(\"\\n\", new InsertsBodyParser(endpoints, routingContext)::handleBodyBuffer);\n+    routingContext.request()\n+        .handler(recordParser);\n+  }\n+\n+  private void handleQueryStream(final RoutingContext routingContext) {\n+    HttpConnection conn = routingContext.request().connection();\n+    ConnectionQueries connectionQueries = connectionsMap.get(conn);\n+    if (connectionQueries == null) {\n+      connectionQueries = new ConnectionQueries(conn);\n+      connectionsMap.put(conn, connectionQueries);\n+      conn.closeHandler(connectionQueries);\n+      server.registerQueryConnection(conn);\n+    }\n+    JsonObject requestBody = routingContext.getBodyAsJson();\n+    String sql = requestBody.getString(\"sql\");\n+    if (sql == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No sql in arguments\");\n+      return;\n+    }\n+    Boolean push = requestBody.getBoolean(\"push\");\n+    if (push == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No push in arguments\");\n+      return;\n+    }\n+    JsonObject properties = requestBody.getJsonObject(\"properties\");\n+    QueryPublisher queryPublisher = endpoints.createQueryPublisher(sql, push, properties);\n+    QuerySubscriber querySubscriber = new QuerySubscriber(routingContext.response());\n+\n+    String queryID = server.registerQuery(querySubscriber);\n+    connectionQueries.addQuery(queryID);\n+    JsonObject metadata = new JsonObject();\n+    metadata.put(\"columnNames\", queryPublisher.getColumnNames());\n+    metadata.put(\"columnTypes\", queryPublisher.getColumnTypes());\n+    metadata.put(\"queryID\", queryID);\n+    if (!push) {\n+      metadata.put(\"rowCount\", queryPublisher.getRowCount());\n+    }\n+    routingContext.response().write(metadata.toBuffer()).write(\"\\n\");\n+    queryPublisher.subscribe(querySubscriber);\n+\n+    // When response is complete, publisher should be closed and query unregistered\n+    routingContext.response().endHandler(v -> closeQuery(queryID, routingContext));\n+  }\n+\n+  private boolean closeQuery(final String queryID, final RoutingContext routingContext) {\n+    QuerySubscriber querySubscriber = server.removeQuery(queryID);\n+    if (querySubscriber == null) {\n+      return false;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQxMjYxNA=="}, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 145}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODYzMzc1NA==", "bodyText": "lol!!!! I realize that!!!!\nI meant, what does returning false mean in the context of the return value, which is used here:\nroutingContext.response().endHandler(v -> closeQuery(queryID, routingContext));\n\nShould of been more clear! I guess what I mean was what does endHandler do with that boolean?", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368633754", "createdAt": "2020-01-20T16:24:48Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerVerticle.java", "diffHunk": "@@ -0,0 +1,201 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.impl.Utils;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.QueryPublisher;\n+import io.vertx.core.AbstractVerticle;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Promise;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpMethod;\n+import io.vertx.core.http.HttpServer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.parsetools.RecordParser;\n+import io.vertx.ext.web.Router;\n+import io.vertx.ext.web.RoutingContext;\n+import io.vertx.ext.web.handler.BodyHandler;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * The server deploys multiple server verticles. This is where the HTTP2 requests are handled. The\n+ * actual implementation of the endpoints is provided by an implementation of {@code Endpoints}.\n+ */\n+public class ServerVerticle extends AbstractVerticle {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ServerVerticle.class);\n+\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Server server;\n+  private final Map<HttpConnection, ConnectionQueries> connectionsMap = new HashMap<>();\n+  private HttpServer httpServer;\n+\n+  public ServerVerticle(final Endpoints endpoints, final HttpServerOptions httpServerOptions,\n+      final Server server) {\n+    this.endpoints = endpoints;\n+    this.httpServerOptions = httpServerOptions;\n+    this.server = server;\n+  }\n+\n+  @Override\n+  public void start(final Promise<Void> startPromise) {\n+    httpServer = vertx.createHttpServer(httpServerOptions).requestHandler(setupRouter())\n+        .exceptionHandler(ServerUtils::handleException);\n+    Future<HttpServer> listenFuture = Promise.<HttpServer>promise().future();\n+    Utils.connectPromise(listenFuture.map(s -> null), startPromise);\n+    httpServer.listen(listenFuture);\n+    vertx.getOrCreateContext().exceptionHandler(ServerUtils::handleException);\n+  }\n+\n+  @Override\n+  public void stop(final Promise<Void> stopPromise) {\n+    if (httpServer == null) {\n+      stopPromise.complete();\n+    } else {\n+      httpServer.close(stopPromise.future());\n+    }\n+  }\n+\n+  private Router setupRouter() {\n+    Router router = Router.router(vertx);\n+    router.route(HttpMethod.POST, \"/query-stream\").handler(BodyHandler.create())\n+        .handler(this::handleQueryStream);\n+    router.route(HttpMethod.POST, \"/inserts-stream\").handler(this::handleInsertsStream);\n+    router.route(HttpMethod.POST, \"/close-query\").handler(BodyHandler.create())\n+        .handler(this::handleCloseQuery);\n+    return router;\n+  }\n+\n+  private void handleInsertsStream(final RoutingContext routingContext) {\n+    RecordParser recordParser = RecordParser\n+        .newDelimited(\"\\n\", new InsertsBodyParser(endpoints, routingContext)::handleBodyBuffer);\n+    routingContext.request()\n+        .handler(recordParser);\n+  }\n+\n+  private void handleQueryStream(final RoutingContext routingContext) {\n+    HttpConnection conn = routingContext.request().connection();\n+    ConnectionQueries connectionQueries = connectionsMap.get(conn);\n+    if (connectionQueries == null) {\n+      connectionQueries = new ConnectionQueries(conn);\n+      connectionsMap.put(conn, connectionQueries);\n+      conn.closeHandler(connectionQueries);\n+      server.registerQueryConnection(conn);\n+    }\n+    JsonObject requestBody = routingContext.getBodyAsJson();\n+    String sql = requestBody.getString(\"sql\");\n+    if (sql == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No sql in arguments\");\n+      return;\n+    }\n+    Boolean push = requestBody.getBoolean(\"push\");\n+    if (push == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No push in arguments\");\n+      return;\n+    }\n+    JsonObject properties = requestBody.getJsonObject(\"properties\");\n+    QueryPublisher queryPublisher = endpoints.createQueryPublisher(sql, push, properties);\n+    QuerySubscriber querySubscriber = new QuerySubscriber(routingContext.response());\n+\n+    String queryID = server.registerQuery(querySubscriber);\n+    connectionQueries.addQuery(queryID);\n+    JsonObject metadata = new JsonObject();\n+    metadata.put(\"columnNames\", queryPublisher.getColumnNames());\n+    metadata.put(\"columnTypes\", queryPublisher.getColumnTypes());\n+    metadata.put(\"queryID\", queryID);\n+    if (!push) {\n+      metadata.put(\"rowCount\", queryPublisher.getRowCount());\n+    }\n+    routingContext.response().write(metadata.toBuffer()).write(\"\\n\");\n+    queryPublisher.subscribe(querySubscriber);\n+\n+    // When response is complete, publisher should be closed and query unregistered\n+    routingContext.response().endHandler(v -> closeQuery(queryID, routingContext));\n+  }\n+\n+  private boolean closeQuery(final String queryID, final RoutingContext routingContext) {\n+    QuerySubscriber querySubscriber = server.removeQuery(queryID);\n+    if (querySubscriber == null) {\n+      return false;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQxMjYxNA=="}, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 145}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODYzNjQ4Ng==", "bodyText": "The lambda you see there is the handler that is called when the response is ended. So, at response end we close the query. The return value of closeQuery is ignored in this case as we don't care in this case.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368636486", "createdAt": "2020-01-20T16:30:31Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerVerticle.java", "diffHunk": "@@ -0,0 +1,201 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.impl.Utils;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.QueryPublisher;\n+import io.vertx.core.AbstractVerticle;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Promise;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpMethod;\n+import io.vertx.core.http.HttpServer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.parsetools.RecordParser;\n+import io.vertx.ext.web.Router;\n+import io.vertx.ext.web.RoutingContext;\n+import io.vertx.ext.web.handler.BodyHandler;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * The server deploys multiple server verticles. This is where the HTTP2 requests are handled. The\n+ * actual implementation of the endpoints is provided by an implementation of {@code Endpoints}.\n+ */\n+public class ServerVerticle extends AbstractVerticle {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ServerVerticle.class);\n+\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Server server;\n+  private final Map<HttpConnection, ConnectionQueries> connectionsMap = new HashMap<>();\n+  private HttpServer httpServer;\n+\n+  public ServerVerticle(final Endpoints endpoints, final HttpServerOptions httpServerOptions,\n+      final Server server) {\n+    this.endpoints = endpoints;\n+    this.httpServerOptions = httpServerOptions;\n+    this.server = server;\n+  }\n+\n+  @Override\n+  public void start(final Promise<Void> startPromise) {\n+    httpServer = vertx.createHttpServer(httpServerOptions).requestHandler(setupRouter())\n+        .exceptionHandler(ServerUtils::handleException);\n+    Future<HttpServer> listenFuture = Promise.<HttpServer>promise().future();\n+    Utils.connectPromise(listenFuture.map(s -> null), startPromise);\n+    httpServer.listen(listenFuture);\n+    vertx.getOrCreateContext().exceptionHandler(ServerUtils::handleException);\n+  }\n+\n+  @Override\n+  public void stop(final Promise<Void> stopPromise) {\n+    if (httpServer == null) {\n+      stopPromise.complete();\n+    } else {\n+      httpServer.close(stopPromise.future());\n+    }\n+  }\n+\n+  private Router setupRouter() {\n+    Router router = Router.router(vertx);\n+    router.route(HttpMethod.POST, \"/query-stream\").handler(BodyHandler.create())\n+        .handler(this::handleQueryStream);\n+    router.route(HttpMethod.POST, \"/inserts-stream\").handler(this::handleInsertsStream);\n+    router.route(HttpMethod.POST, \"/close-query\").handler(BodyHandler.create())\n+        .handler(this::handleCloseQuery);\n+    return router;\n+  }\n+\n+  private void handleInsertsStream(final RoutingContext routingContext) {\n+    RecordParser recordParser = RecordParser\n+        .newDelimited(\"\\n\", new InsertsBodyParser(endpoints, routingContext)::handleBodyBuffer);\n+    routingContext.request()\n+        .handler(recordParser);\n+  }\n+\n+  private void handleQueryStream(final RoutingContext routingContext) {\n+    HttpConnection conn = routingContext.request().connection();\n+    ConnectionQueries connectionQueries = connectionsMap.get(conn);\n+    if (connectionQueries == null) {\n+      connectionQueries = new ConnectionQueries(conn);\n+      connectionsMap.put(conn, connectionQueries);\n+      conn.closeHandler(connectionQueries);\n+      server.registerQueryConnection(conn);\n+    }\n+    JsonObject requestBody = routingContext.getBodyAsJson();\n+    String sql = requestBody.getString(\"sql\");\n+    if (sql == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No sql in arguments\");\n+      return;\n+    }\n+    Boolean push = requestBody.getBoolean(\"push\");\n+    if (push == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No push in arguments\");\n+      return;\n+    }\n+    JsonObject properties = requestBody.getJsonObject(\"properties\");\n+    QueryPublisher queryPublisher = endpoints.createQueryPublisher(sql, push, properties);\n+    QuerySubscriber querySubscriber = new QuerySubscriber(routingContext.response());\n+\n+    String queryID = server.registerQuery(querySubscriber);\n+    connectionQueries.addQuery(queryID);\n+    JsonObject metadata = new JsonObject();\n+    metadata.put(\"columnNames\", queryPublisher.getColumnNames());\n+    metadata.put(\"columnTypes\", queryPublisher.getColumnTypes());\n+    metadata.put(\"queryID\", queryID);\n+    if (!push) {\n+      metadata.put(\"rowCount\", queryPublisher.getRowCount());\n+    }\n+    routingContext.response().write(metadata.toBuffer()).write(\"\\n\");\n+    queryPublisher.subscribe(querySubscriber);\n+\n+    // When response is complete, publisher should be closed and query unregistered\n+    routingContext.response().endHandler(v -> closeQuery(queryID, routingContext));\n+  }\n+\n+  private boolean closeQuery(final String queryID, final RoutingContext routingContext) {\n+    QuerySubscriber querySubscriber = server.removeQuery(queryID);\n+    if (querySubscriber == null) {\n+      return false;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQxMjYxNA=="}, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 145}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODY1NzA4Nw==", "bodyText": "Cool. Thanks for clarifying!", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368657087", "createdAt": "2020-01-20T17:16:00Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerVerticle.java", "diffHunk": "@@ -0,0 +1,201 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.impl.Utils;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.QueryPublisher;\n+import io.vertx.core.AbstractVerticle;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Promise;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpMethod;\n+import io.vertx.core.http.HttpServer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.parsetools.RecordParser;\n+import io.vertx.ext.web.Router;\n+import io.vertx.ext.web.RoutingContext;\n+import io.vertx.ext.web.handler.BodyHandler;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * The server deploys multiple server verticles. This is where the HTTP2 requests are handled. The\n+ * actual implementation of the endpoints is provided by an implementation of {@code Endpoints}.\n+ */\n+public class ServerVerticle extends AbstractVerticle {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ServerVerticle.class);\n+\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Server server;\n+  private final Map<HttpConnection, ConnectionQueries> connectionsMap = new HashMap<>();\n+  private HttpServer httpServer;\n+\n+  public ServerVerticle(final Endpoints endpoints, final HttpServerOptions httpServerOptions,\n+      final Server server) {\n+    this.endpoints = endpoints;\n+    this.httpServerOptions = httpServerOptions;\n+    this.server = server;\n+  }\n+\n+  @Override\n+  public void start(final Promise<Void> startPromise) {\n+    httpServer = vertx.createHttpServer(httpServerOptions).requestHandler(setupRouter())\n+        .exceptionHandler(ServerUtils::handleException);\n+    Future<HttpServer> listenFuture = Promise.<HttpServer>promise().future();\n+    Utils.connectPromise(listenFuture.map(s -> null), startPromise);\n+    httpServer.listen(listenFuture);\n+    vertx.getOrCreateContext().exceptionHandler(ServerUtils::handleException);\n+  }\n+\n+  @Override\n+  public void stop(final Promise<Void> stopPromise) {\n+    if (httpServer == null) {\n+      stopPromise.complete();\n+    } else {\n+      httpServer.close(stopPromise.future());\n+    }\n+  }\n+\n+  private Router setupRouter() {\n+    Router router = Router.router(vertx);\n+    router.route(HttpMethod.POST, \"/query-stream\").handler(BodyHandler.create())\n+        .handler(this::handleQueryStream);\n+    router.route(HttpMethod.POST, \"/inserts-stream\").handler(this::handleInsertsStream);\n+    router.route(HttpMethod.POST, \"/close-query\").handler(BodyHandler.create())\n+        .handler(this::handleCloseQuery);\n+    return router;\n+  }\n+\n+  private void handleInsertsStream(final RoutingContext routingContext) {\n+    RecordParser recordParser = RecordParser\n+        .newDelimited(\"\\n\", new InsertsBodyParser(endpoints, routingContext)::handleBodyBuffer);\n+    routingContext.request()\n+        .handler(recordParser);\n+  }\n+\n+  private void handleQueryStream(final RoutingContext routingContext) {\n+    HttpConnection conn = routingContext.request().connection();\n+    ConnectionQueries connectionQueries = connectionsMap.get(conn);\n+    if (connectionQueries == null) {\n+      connectionQueries = new ConnectionQueries(conn);\n+      connectionsMap.put(conn, connectionQueries);\n+      conn.closeHandler(connectionQueries);\n+      server.registerQueryConnection(conn);\n+    }\n+    JsonObject requestBody = routingContext.getBodyAsJson();\n+    String sql = requestBody.getString(\"sql\");\n+    if (sql == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No sql in arguments\");\n+      return;\n+    }\n+    Boolean push = requestBody.getBoolean(\"push\");\n+    if (push == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No push in arguments\");\n+      return;\n+    }\n+    JsonObject properties = requestBody.getJsonObject(\"properties\");\n+    QueryPublisher queryPublisher = endpoints.createQueryPublisher(sql, push, properties);\n+    QuerySubscriber querySubscriber = new QuerySubscriber(routingContext.response());\n+\n+    String queryID = server.registerQuery(querySubscriber);\n+    connectionQueries.addQuery(queryID);\n+    JsonObject metadata = new JsonObject();\n+    metadata.put(\"columnNames\", queryPublisher.getColumnNames());\n+    metadata.put(\"columnTypes\", queryPublisher.getColumnTypes());\n+    metadata.put(\"queryID\", queryID);\n+    if (!push) {\n+      metadata.put(\"rowCount\", queryPublisher.getRowCount());\n+    }\n+    routingContext.response().write(metadata.toBuffer()).write(\"\\n\");\n+    queryPublisher.subscribe(querySubscriber);\n+\n+    // When response is complete, publisher should be closed and query unregistered\n+    routingContext.response().endHandler(v -> closeQuery(queryID, routingContext));\n+  }\n+\n+  private boolean closeQuery(final String queryID, final RoutingContext routingContext) {\n+    QuerySubscriber querySubscriber = server.removeQuery(queryID);\n+    if (querySubscriber == null) {\n+      return false;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQxMjYxNA=="}, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 145}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MDE3NTkxOnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/spi/Endpoints.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzoyNDowNVrOFeZKMg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzoyNDowNVrOFeZKMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQxMzgxMA==", "bodyText": "Might benefit from some javadocs explain the params.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367413810", "createdAt": "2020-01-16T13:24:05Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/spi/Endpoints.java", "diffHunk": "@@ -0,0 +1,33 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.spi;\n+\n+import io.vertx.core.json.JsonObject;\n+import org.reactivestreams.Subscriber;\n+\n+/**\n+ * In order to keep a clean separation between the plumbing of the API server and actual back-end\n+ * implementation of the endpoints we define this interface to encapsulate the actual endpoint\n+ * implementation.\n+ */\n+public interface Endpoints {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MDE4NzM5OnYy", "diffSide": "RIGHT", "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzoyNzo0OVrOFeZRGg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMFQxNjoyNTo1M1rOFfjpiw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQxNTU3OA==", "bodyText": "Are you up for adopting the Given/When/Then that everyone else in the team uses?  It can help really spell out what is setup, what is the exact bit under test, and what is expected outcome.  You've already added blank lines to separate by the looks of it, e.g. this test would become:\n@Test\n  public void shouldExecutePullQuery() throws Exception {\n    // Given:\n    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", false);\n    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n    requestBody.put(\"properties\", properties);\n\n    // When:\n    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n\n    // Then:\n    assertEquals(200, response.statusCode());\n    assertEquals(\"OK\", response.statusMessage());\n    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n    assertFalse(testEndpoints.getLastPush());\n    assertEquals(properties, testEndpoints.getLastProperties());\n\n    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n    assertEquals(0, server.getQueryIDs().size());\n    String queryID = queryResponse.responseObject.getString(\"queryID\");\n    assertNotNull(queryID);\n    assertFalse(server.getQueryIDs().contains(queryID));\n    Integer rowCount = queryResponse.responseObject.getInteger(\"rowCount\");\n    assertNotNull(rowCount);\n    assertEquals(DEFAULT_ROWS.size(), rowCount.intValue());\n  }\nThis is obviously not enforced by any tooling, but it a widely used pattern by most of the newer tests in the code base.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367415578", "createdAt": "2020-01-16T13:27:49Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "diffHunk": "@@ -0,0 +1,885 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import io.confluent.ksql.api.TestQueryPublisher.ListRowGenerator;\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.server.Server;\n+import io.vertx.codegen.annotations.Nullable;\n+import io.vertx.core.AsyncResult;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.http.HttpVersion;\n+import io.vertx.core.json.JsonArray;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.net.PemKeyCertOptions;\n+import io.vertx.core.streams.ReadStream;\n+import io.vertx.core.streams.WriteStream;\n+import io.vertx.ext.web.client.HttpResponse;\n+import io.vertx.ext.web.client.WebClient;\n+import io.vertx.ext.web.client.WebClientOptions;\n+import io.vertx.ext.web.codec.BodyCodec;\n+import java.io.FileNotFoundException;\n+import java.net.URL;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+public class ApiTest {\n+\n+  private static final long WAIT_TIMEOUT = 10000;\n+  private static final JsonArray DEFAULT_COLUMN_NAMES = new JsonArray().add(\"name\").add(\"age\")\n+      .add(\"male\");\n+  private static final JsonArray DEFAULT_COLUMN_TYPES = new JsonArray().add(\"STRING\").add(\"INT\")\n+      .add(\"BOOLEAN\");\n+  private static final List<JsonArray> DEFAULT_ROWS = generateRows();\n+\n+  private Vertx vertx;\n+  private Server server;\n+  private TestEndpoints testEndpoints;\n+  private WebClient client;\n+\n+  @Before\n+  public void setUp() throws Throwable {\n+\n+    vertx = Vertx.vertx();\n+\n+    HttpServerOptions httpServerOptions =\n+        new HttpServerOptions()\n+            .setHost(\"localhost\")\n+            .setPort(8089)\n+            .setUseAlpn(true)\n+            .setSsl(true)\n+            .setPemKeyCertOptions(\n+                new PemKeyCertOptions().setKeyPath(findFilePath(\"test-server-key.pem\"))\n+                    .setCertPath(findFilePath(\"test-server-cert.pem\"))\n+            );\n+\n+    testEndpoints = new TestEndpoints(vertx);\n+    JsonObject config = new JsonObject().put(\"verticle-instances\", 4);\n+    server = new Server(vertx, config, testEndpoints, httpServerOptions);\n+    server.start();\n+    client = createClient();\n+    setDefaultRowGenerator();\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    if (client != null) {\n+      client.close();\n+    }\n+    if (server != null) {\n+      server.stop();\n+    }\n+  }\n+\n+  @Test\n+  public void shouldExecutePullQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", false);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertFalse(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(0, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertFalse(server.getQueryIDs().contains(queryID));\n+    Integer rowCount = queryResponse.responseObject.getInteger(\"rowCount\");\n+    assertNotNull(rowCount);\n+    assertEquals(DEFAULT_ROWS.size(), rowCount.intValue());\n+  }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 134}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU0ODQxNg==", "bodyText": "Tbh, I find the given, when, then thing quite forced and simplistic. I can add it for some of the simpler tests.\nBut other tests won't fit so easily into this pattern. E.g. in some test I do things like start a bunch of push queries then do some asserts on the state, then I close the queries and do another bunch of asserts on the state. In this case there are multiple \"whens\" in the test .", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367548416", "createdAt": "2020-01-16T17:20:05Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "diffHunk": "@@ -0,0 +1,885 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import io.confluent.ksql.api.TestQueryPublisher.ListRowGenerator;\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.server.Server;\n+import io.vertx.codegen.annotations.Nullable;\n+import io.vertx.core.AsyncResult;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.http.HttpVersion;\n+import io.vertx.core.json.JsonArray;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.net.PemKeyCertOptions;\n+import io.vertx.core.streams.ReadStream;\n+import io.vertx.core.streams.WriteStream;\n+import io.vertx.ext.web.client.HttpResponse;\n+import io.vertx.ext.web.client.WebClient;\n+import io.vertx.ext.web.client.WebClientOptions;\n+import io.vertx.ext.web.codec.BodyCodec;\n+import java.io.FileNotFoundException;\n+import java.net.URL;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+public class ApiTest {\n+\n+  private static final long WAIT_TIMEOUT = 10000;\n+  private static final JsonArray DEFAULT_COLUMN_NAMES = new JsonArray().add(\"name\").add(\"age\")\n+      .add(\"male\");\n+  private static final JsonArray DEFAULT_COLUMN_TYPES = new JsonArray().add(\"STRING\").add(\"INT\")\n+      .add(\"BOOLEAN\");\n+  private static final List<JsonArray> DEFAULT_ROWS = generateRows();\n+\n+  private Vertx vertx;\n+  private Server server;\n+  private TestEndpoints testEndpoints;\n+  private WebClient client;\n+\n+  @Before\n+  public void setUp() throws Throwable {\n+\n+    vertx = Vertx.vertx();\n+\n+    HttpServerOptions httpServerOptions =\n+        new HttpServerOptions()\n+            .setHost(\"localhost\")\n+            .setPort(8089)\n+            .setUseAlpn(true)\n+            .setSsl(true)\n+            .setPemKeyCertOptions(\n+                new PemKeyCertOptions().setKeyPath(findFilePath(\"test-server-key.pem\"))\n+                    .setCertPath(findFilePath(\"test-server-cert.pem\"))\n+            );\n+\n+    testEndpoints = new TestEndpoints(vertx);\n+    JsonObject config = new JsonObject().put(\"verticle-instances\", 4);\n+    server = new Server(vertx, config, testEndpoints, httpServerOptions);\n+    server.start();\n+    client = createClient();\n+    setDefaultRowGenerator();\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    if (client != null) {\n+      client.close();\n+    }\n+    if (server != null) {\n+      server.stop();\n+    }\n+  }\n+\n+  @Test\n+  public void shouldExecutePullQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", false);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertFalse(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(0, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertFalse(server.getQueryIDs().contains(queryID));\n+    Integer rowCount = queryResponse.responseObject.getInteger(\"rowCount\");\n+    assertNotNull(rowCount);\n+    assertEquals(DEFAULT_ROWS.size(), rowCount.intValue());\n+  }\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQxNTU3OA=="}, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 134}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODExNjU0NA==", "bodyText": "I've found the Given/When/Then pattern a forcing function to make tests simple. There are admittedly some tests that are way more difficult to write when following that pattern, but those should be the exception not the rule IMO.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368116544", "createdAt": "2020-01-17T20:11:32Z", "author": {"login": "agavra"}, "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "diffHunk": "@@ -0,0 +1,885 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import io.confluent.ksql.api.TestQueryPublisher.ListRowGenerator;\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.server.Server;\n+import io.vertx.codegen.annotations.Nullable;\n+import io.vertx.core.AsyncResult;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.http.HttpVersion;\n+import io.vertx.core.json.JsonArray;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.net.PemKeyCertOptions;\n+import io.vertx.core.streams.ReadStream;\n+import io.vertx.core.streams.WriteStream;\n+import io.vertx.ext.web.client.HttpResponse;\n+import io.vertx.ext.web.client.WebClient;\n+import io.vertx.ext.web.client.WebClientOptions;\n+import io.vertx.ext.web.codec.BodyCodec;\n+import java.io.FileNotFoundException;\n+import java.net.URL;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+public class ApiTest {\n+\n+  private static final long WAIT_TIMEOUT = 10000;\n+  private static final JsonArray DEFAULT_COLUMN_NAMES = new JsonArray().add(\"name\").add(\"age\")\n+      .add(\"male\");\n+  private static final JsonArray DEFAULT_COLUMN_TYPES = new JsonArray().add(\"STRING\").add(\"INT\")\n+      .add(\"BOOLEAN\");\n+  private static final List<JsonArray> DEFAULT_ROWS = generateRows();\n+\n+  private Vertx vertx;\n+  private Server server;\n+  private TestEndpoints testEndpoints;\n+  private WebClient client;\n+\n+  @Before\n+  public void setUp() throws Throwable {\n+\n+    vertx = Vertx.vertx();\n+\n+    HttpServerOptions httpServerOptions =\n+        new HttpServerOptions()\n+            .setHost(\"localhost\")\n+            .setPort(8089)\n+            .setUseAlpn(true)\n+            .setSsl(true)\n+            .setPemKeyCertOptions(\n+                new PemKeyCertOptions().setKeyPath(findFilePath(\"test-server-key.pem\"))\n+                    .setCertPath(findFilePath(\"test-server-cert.pem\"))\n+            );\n+\n+    testEndpoints = new TestEndpoints(vertx);\n+    JsonObject config = new JsonObject().put(\"verticle-instances\", 4);\n+    server = new Server(vertx, config, testEndpoints, httpServerOptions);\n+    server.start();\n+    client = createClient();\n+    setDefaultRowGenerator();\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    if (client != null) {\n+      client.close();\n+    }\n+    if (server != null) {\n+      server.stop();\n+    }\n+  }\n+\n+  @Test\n+  public void shouldExecutePullQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", false);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertFalse(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(0, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertFalse(server.getQueryIDs().contains(queryID));\n+    Integer rowCount = queryResponse.responseObject.getInteger(\"rowCount\");\n+    assertNotNull(rowCount);\n+    assertEquals(DEFAULT_ROWS.size(), rowCount.intValue());\n+  }\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQxNTU3OA=="}, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 134}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODYzNDI1MQ==", "bodyText": "Yep, that's its purpose. If you've got a test that doesn't fit, it generally means you're trying to test too much in one test and it would be better split into multiple.\n\nE.g. in some test I do things like start a bunch of push queries then do some asserts on the state, then I close the queries and do another bunch of asserts on the state. In this case there are multiple \"whens\" in the test .\n\nThat sounds like two tests: the first tests the newly created query is in the right state. A second test tests the query is in the right state once its closed.\nUnit tests should, ideally, only test a single thing, e.g. the state of a query after its closed.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368634251", "createdAt": "2020-01-20T16:25:53Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "diffHunk": "@@ -0,0 +1,885 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import io.confluent.ksql.api.TestQueryPublisher.ListRowGenerator;\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.server.Server;\n+import io.vertx.codegen.annotations.Nullable;\n+import io.vertx.core.AsyncResult;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.http.HttpVersion;\n+import io.vertx.core.json.JsonArray;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.net.PemKeyCertOptions;\n+import io.vertx.core.streams.ReadStream;\n+import io.vertx.core.streams.WriteStream;\n+import io.vertx.ext.web.client.HttpResponse;\n+import io.vertx.ext.web.client.WebClient;\n+import io.vertx.ext.web.client.WebClientOptions;\n+import io.vertx.ext.web.codec.BodyCodec;\n+import java.io.FileNotFoundException;\n+import java.net.URL;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+public class ApiTest {\n+\n+  private static final long WAIT_TIMEOUT = 10000;\n+  private static final JsonArray DEFAULT_COLUMN_NAMES = new JsonArray().add(\"name\").add(\"age\")\n+      .add(\"male\");\n+  private static final JsonArray DEFAULT_COLUMN_TYPES = new JsonArray().add(\"STRING\").add(\"INT\")\n+      .add(\"BOOLEAN\");\n+  private static final List<JsonArray> DEFAULT_ROWS = generateRows();\n+\n+  private Vertx vertx;\n+  private Server server;\n+  private TestEndpoints testEndpoints;\n+  private WebClient client;\n+\n+  @Before\n+  public void setUp() throws Throwable {\n+\n+    vertx = Vertx.vertx();\n+\n+    HttpServerOptions httpServerOptions =\n+        new HttpServerOptions()\n+            .setHost(\"localhost\")\n+            .setPort(8089)\n+            .setUseAlpn(true)\n+            .setSsl(true)\n+            .setPemKeyCertOptions(\n+                new PemKeyCertOptions().setKeyPath(findFilePath(\"test-server-key.pem\"))\n+                    .setCertPath(findFilePath(\"test-server-cert.pem\"))\n+            );\n+\n+    testEndpoints = new TestEndpoints(vertx);\n+    JsonObject config = new JsonObject().put(\"verticle-instances\", 4);\n+    server = new Server(vertx, config, testEndpoints, httpServerOptions);\n+    server.start();\n+    client = createClient();\n+    setDefaultRowGenerator();\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    if (client != null) {\n+      client.close();\n+    }\n+    if (server != null) {\n+      server.stop();\n+    }\n+  }\n+\n+  @Test\n+  public void shouldExecutePullQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", false);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertFalse(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(0, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertFalse(server.getQueryIDs().contains(queryID));\n+    Integer rowCount = queryResponse.responseObject.getInteger(\"rowCount\");\n+    assertNotNull(rowCount);\n+    assertEquals(DEFAULT_ROWS.size(), rowCount.intValue());\n+  }\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQxNTU3OA=="}, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 134}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MDIwMjcyOnYy", "diffSide": "RIGHT", "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzozMjozMFrOFeZaNg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxODo0MjoyNFrOFejo6g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQxNzkxMA==", "bodyText": "Would you mind using the hamcrest matchers along with most others in the team? I appreciate this requires some time to skill up on, but the return is worth it IMHO.\nThey provide a lot more functionality and, importantly, tend to provide a lot more info when things fail, e.g.\nassertFalse(queryResponse.responseObject.containsKey(\"rowCount\"));\nWhen it fails will just say something like \"expected false, but was true\".\nHowever, hamcrest equivalent:\nassertThat(queryResponse.responseObject, hasKey(\"rowCount\"));\nWill fail with something like: \"Expected map to have key rowCount, actual keys: {rowcount, a, b}\".\nI hope you agree the latter is more helpful, especially when the test is only failing on the build server!!!\nI'll add some hamcrest equivalents below to get you started.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367417910", "createdAt": "2020-01-16T13:32:30Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "diffHunk": "@@ -0,0 +1,885 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import io.confluent.ksql.api.TestQueryPublisher.ListRowGenerator;\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.server.Server;\n+import io.vertx.codegen.annotations.Nullable;\n+import io.vertx.core.AsyncResult;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.http.HttpVersion;\n+import io.vertx.core.json.JsonArray;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.net.PemKeyCertOptions;\n+import io.vertx.core.streams.ReadStream;\n+import io.vertx.core.streams.WriteStream;\n+import io.vertx.ext.web.client.HttpResponse;\n+import io.vertx.ext.web.client.WebClient;\n+import io.vertx.ext.web.client.WebClientOptions;\n+import io.vertx.ext.web.codec.BodyCodec;\n+import java.io.FileNotFoundException;\n+import java.net.URL;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+public class ApiTest {\n+\n+  private static final long WAIT_TIMEOUT = 10000;\n+  private static final JsonArray DEFAULT_COLUMN_NAMES = new JsonArray().add(\"name\").add(\"age\")\n+      .add(\"male\");\n+  private static final JsonArray DEFAULT_COLUMN_TYPES = new JsonArray().add(\"STRING\").add(\"INT\")\n+      .add(\"BOOLEAN\");\n+  private static final List<JsonArray> DEFAULT_ROWS = generateRows();\n+\n+  private Vertx vertx;\n+  private Server server;\n+  private TestEndpoints testEndpoints;\n+  private WebClient client;\n+\n+  @Before\n+  public void setUp() throws Throwable {\n+\n+    vertx = Vertx.vertx();\n+\n+    HttpServerOptions httpServerOptions =\n+        new HttpServerOptions()\n+            .setHost(\"localhost\")\n+            .setPort(8089)\n+            .setUseAlpn(true)\n+            .setSsl(true)\n+            .setPemKeyCertOptions(\n+                new PemKeyCertOptions().setKeyPath(findFilePath(\"test-server-key.pem\"))\n+                    .setCertPath(findFilePath(\"test-server-cert.pem\"))\n+            );\n+\n+    testEndpoints = new TestEndpoints(vertx);\n+    JsonObject config = new JsonObject().put(\"verticle-instances\", 4);\n+    server = new Server(vertx, config, testEndpoints, httpServerOptions);\n+    server.start();\n+    client = createClient();\n+    setDefaultRowGenerator();\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    if (client != null) {\n+      client.close();\n+    }\n+    if (server != null) {\n+      server.stop();\n+    }\n+  }\n+\n+  @Test\n+  public void shouldExecutePullQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", false);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertFalse(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(0, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertFalse(server.getQueryIDs().contains(queryID));\n+    Integer rowCount = queryResponse.responseObject.getInteger(\"rowCount\");\n+    assertNotNull(rowCount);\n+    assertEquals(DEFAULT_ROWS.size(), rowCount.intValue());\n+  }\n+\n+  @Test\n+  public void shouldExecutePushQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertTrue(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(1, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertTrue(server.getQueryIDs().contains(queryID));\n+    assertFalse(queryResponse.responseObject.containsKey(\"rowCount\"));\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 156}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU1NzI5OA==", "bodyText": "I agree that Hamcrest can provide better error messages, but we write or refactor tests way more often than tests fail on build servers. Imho, we should optimise for ease of writing/refactoring tests not for good error messages. Hamcrest does the latter, and I find tests way harder to write with it. Imho that's not a good optimisation.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367557298", "createdAt": "2020-01-16T17:39:14Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "diffHunk": "@@ -0,0 +1,885 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import io.confluent.ksql.api.TestQueryPublisher.ListRowGenerator;\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.server.Server;\n+import io.vertx.codegen.annotations.Nullable;\n+import io.vertx.core.AsyncResult;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.http.HttpVersion;\n+import io.vertx.core.json.JsonArray;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.net.PemKeyCertOptions;\n+import io.vertx.core.streams.ReadStream;\n+import io.vertx.core.streams.WriteStream;\n+import io.vertx.ext.web.client.HttpResponse;\n+import io.vertx.ext.web.client.WebClient;\n+import io.vertx.ext.web.client.WebClientOptions;\n+import io.vertx.ext.web.codec.BodyCodec;\n+import java.io.FileNotFoundException;\n+import java.net.URL;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+public class ApiTest {\n+\n+  private static final long WAIT_TIMEOUT = 10000;\n+  private static final JsonArray DEFAULT_COLUMN_NAMES = new JsonArray().add(\"name\").add(\"age\")\n+      .add(\"male\");\n+  private static final JsonArray DEFAULT_COLUMN_TYPES = new JsonArray().add(\"STRING\").add(\"INT\")\n+      .add(\"BOOLEAN\");\n+  private static final List<JsonArray> DEFAULT_ROWS = generateRows();\n+\n+  private Vertx vertx;\n+  private Server server;\n+  private TestEndpoints testEndpoints;\n+  private WebClient client;\n+\n+  @Before\n+  public void setUp() throws Throwable {\n+\n+    vertx = Vertx.vertx();\n+\n+    HttpServerOptions httpServerOptions =\n+        new HttpServerOptions()\n+            .setHost(\"localhost\")\n+            .setPort(8089)\n+            .setUseAlpn(true)\n+            .setSsl(true)\n+            .setPemKeyCertOptions(\n+                new PemKeyCertOptions().setKeyPath(findFilePath(\"test-server-key.pem\"))\n+                    .setCertPath(findFilePath(\"test-server-cert.pem\"))\n+            );\n+\n+    testEndpoints = new TestEndpoints(vertx);\n+    JsonObject config = new JsonObject().put(\"verticle-instances\", 4);\n+    server = new Server(vertx, config, testEndpoints, httpServerOptions);\n+    server.start();\n+    client = createClient();\n+    setDefaultRowGenerator();\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    if (client != null) {\n+      client.close();\n+    }\n+    if (server != null) {\n+      server.stop();\n+    }\n+  }\n+\n+  @Test\n+  public void shouldExecutePullQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", false);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertFalse(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(0, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertFalse(server.getQueryIDs().contains(queryID));\n+    Integer rowCount = queryResponse.responseObject.getInteger(\"rowCount\");\n+    assertNotNull(rowCount);\n+    assertEquals(DEFAULT_ROWS.size(), rowCount.intValue());\n+  }\n+\n+  @Test\n+  public void shouldExecutePushQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertTrue(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(1, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertTrue(server.getQueryIDs().contains(queryID));\n+    assertFalse(queryResponse.responseObject.containsKey(\"rowCount\"));\n+  }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQxNzkxMA=="}, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 156}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU1NzcyNw==", "bodyText": "Imho Junit is clear, simple and straight to the point. Anyone can understand and build a new Junit assert without any special knowledge of the library. Invoking KISS principle ;)", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367557727", "createdAt": "2020-01-16T17:40:12Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "diffHunk": "@@ -0,0 +1,885 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import io.confluent.ksql.api.TestQueryPublisher.ListRowGenerator;\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.server.Server;\n+import io.vertx.codegen.annotations.Nullable;\n+import io.vertx.core.AsyncResult;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.http.HttpVersion;\n+import io.vertx.core.json.JsonArray;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.net.PemKeyCertOptions;\n+import io.vertx.core.streams.ReadStream;\n+import io.vertx.core.streams.WriteStream;\n+import io.vertx.ext.web.client.HttpResponse;\n+import io.vertx.ext.web.client.WebClient;\n+import io.vertx.ext.web.client.WebClientOptions;\n+import io.vertx.ext.web.codec.BodyCodec;\n+import java.io.FileNotFoundException;\n+import java.net.URL;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+public class ApiTest {\n+\n+  private static final long WAIT_TIMEOUT = 10000;\n+  private static final JsonArray DEFAULT_COLUMN_NAMES = new JsonArray().add(\"name\").add(\"age\")\n+      .add(\"male\");\n+  private static final JsonArray DEFAULT_COLUMN_TYPES = new JsonArray().add(\"STRING\").add(\"INT\")\n+      .add(\"BOOLEAN\");\n+  private static final List<JsonArray> DEFAULT_ROWS = generateRows();\n+\n+  private Vertx vertx;\n+  private Server server;\n+  private TestEndpoints testEndpoints;\n+  private WebClient client;\n+\n+  @Before\n+  public void setUp() throws Throwable {\n+\n+    vertx = Vertx.vertx();\n+\n+    HttpServerOptions httpServerOptions =\n+        new HttpServerOptions()\n+            .setHost(\"localhost\")\n+            .setPort(8089)\n+            .setUseAlpn(true)\n+            .setSsl(true)\n+            .setPemKeyCertOptions(\n+                new PemKeyCertOptions().setKeyPath(findFilePath(\"test-server-key.pem\"))\n+                    .setCertPath(findFilePath(\"test-server-cert.pem\"))\n+            );\n+\n+    testEndpoints = new TestEndpoints(vertx);\n+    JsonObject config = new JsonObject().put(\"verticle-instances\", 4);\n+    server = new Server(vertx, config, testEndpoints, httpServerOptions);\n+    server.start();\n+    client = createClient();\n+    setDefaultRowGenerator();\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    if (client != null) {\n+      client.close();\n+    }\n+    if (server != null) {\n+      server.stop();\n+    }\n+  }\n+\n+  @Test\n+  public void shouldExecutePullQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", false);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertFalse(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(0, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertFalse(server.getQueryIDs().contains(queryID));\n+    Integer rowCount = queryResponse.responseObject.getInteger(\"rowCount\");\n+    assertNotNull(rowCount);\n+    assertEquals(DEFAULT_ROWS.size(), rowCount.intValue());\n+  }\n+\n+  @Test\n+  public void shouldExecutePushQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertTrue(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(1, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertTrue(server.getQueryIDs().contains(queryID));\n+    assertFalse(queryResponse.responseObject.containsKey(\"rowCount\"));\n+  }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQxNzkxMA=="}, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 156}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzU4NTUxNA==", "bodyText": "#4332", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367585514", "createdAt": "2020-01-16T18:42:24Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "diffHunk": "@@ -0,0 +1,885 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import io.confluent.ksql.api.TestQueryPublisher.ListRowGenerator;\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.server.Server;\n+import io.vertx.codegen.annotations.Nullable;\n+import io.vertx.core.AsyncResult;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.http.HttpVersion;\n+import io.vertx.core.json.JsonArray;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.net.PemKeyCertOptions;\n+import io.vertx.core.streams.ReadStream;\n+import io.vertx.core.streams.WriteStream;\n+import io.vertx.ext.web.client.HttpResponse;\n+import io.vertx.ext.web.client.WebClient;\n+import io.vertx.ext.web.client.WebClientOptions;\n+import io.vertx.ext.web.codec.BodyCodec;\n+import java.io.FileNotFoundException;\n+import java.net.URL;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+public class ApiTest {\n+\n+  private static final long WAIT_TIMEOUT = 10000;\n+  private static final JsonArray DEFAULT_COLUMN_NAMES = new JsonArray().add(\"name\").add(\"age\")\n+      .add(\"male\");\n+  private static final JsonArray DEFAULT_COLUMN_TYPES = new JsonArray().add(\"STRING\").add(\"INT\")\n+      .add(\"BOOLEAN\");\n+  private static final List<JsonArray> DEFAULT_ROWS = generateRows();\n+\n+  private Vertx vertx;\n+  private Server server;\n+  private TestEndpoints testEndpoints;\n+  private WebClient client;\n+\n+  @Before\n+  public void setUp() throws Throwable {\n+\n+    vertx = Vertx.vertx();\n+\n+    HttpServerOptions httpServerOptions =\n+        new HttpServerOptions()\n+            .setHost(\"localhost\")\n+            .setPort(8089)\n+            .setUseAlpn(true)\n+            .setSsl(true)\n+            .setPemKeyCertOptions(\n+                new PemKeyCertOptions().setKeyPath(findFilePath(\"test-server-key.pem\"))\n+                    .setCertPath(findFilePath(\"test-server-cert.pem\"))\n+            );\n+\n+    testEndpoints = new TestEndpoints(vertx);\n+    JsonObject config = new JsonObject().put(\"verticle-instances\", 4);\n+    server = new Server(vertx, config, testEndpoints, httpServerOptions);\n+    server.start();\n+    client = createClient();\n+    setDefaultRowGenerator();\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    if (client != null) {\n+      client.close();\n+    }\n+    if (server != null) {\n+      server.stop();\n+    }\n+  }\n+\n+  @Test\n+  public void shouldExecutePullQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", false);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertFalse(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(0, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertFalse(server.getQueryIDs().contains(queryID));\n+    Integer rowCount = queryResponse.responseObject.getInteger(\"rowCount\");\n+    assertNotNull(rowCount);\n+    assertEquals(DEFAULT_ROWS.size(), rowCount.intValue());\n+  }\n+\n+  @Test\n+  public void shouldExecutePushQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertTrue(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(1, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertTrue(server.getQueryIDs().contains(queryID));\n+    assertFalse(queryResponse.responseObject.containsKey(\"rowCount\"));\n+  }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQxNzkxMA=="}, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 156}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MDIwNjIxOnYy", "diffSide": "RIGHT", "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzozMzozOVrOFeZcXw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzozMzozOVrOFeZcXw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQxODQ2Mw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  assertEquals(i + 1, server.getQueryIDs().size());\n          \n          \n            \n                  assertThat(server.getQueryIDs(), hasSize(i + 1));", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367418463", "createdAt": "2020-01-16T13:33:39Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "diffHunk": "@@ -0,0 +1,885 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import io.confluent.ksql.api.TestQueryPublisher.ListRowGenerator;\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.server.Server;\n+import io.vertx.codegen.annotations.Nullable;\n+import io.vertx.core.AsyncResult;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.http.HttpVersion;\n+import io.vertx.core.json.JsonArray;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.net.PemKeyCertOptions;\n+import io.vertx.core.streams.ReadStream;\n+import io.vertx.core.streams.WriteStream;\n+import io.vertx.ext.web.client.HttpResponse;\n+import io.vertx.ext.web.client.WebClient;\n+import io.vertx.ext.web.client.WebClientOptions;\n+import io.vertx.ext.web.codec.BodyCodec;\n+import java.io.FileNotFoundException;\n+import java.net.URL;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+public class ApiTest {\n+\n+  private static final long WAIT_TIMEOUT = 10000;\n+  private static final JsonArray DEFAULT_COLUMN_NAMES = new JsonArray().add(\"name\").add(\"age\")\n+      .add(\"male\");\n+  private static final JsonArray DEFAULT_COLUMN_TYPES = new JsonArray().add(\"STRING\").add(\"INT\")\n+      .add(\"BOOLEAN\");\n+  private static final List<JsonArray> DEFAULT_ROWS = generateRows();\n+\n+  private Vertx vertx;\n+  private Server server;\n+  private TestEndpoints testEndpoints;\n+  private WebClient client;\n+\n+  @Before\n+  public void setUp() throws Throwable {\n+\n+    vertx = Vertx.vertx();\n+\n+    HttpServerOptions httpServerOptions =\n+        new HttpServerOptions()\n+            .setHost(\"localhost\")\n+            .setPort(8089)\n+            .setUseAlpn(true)\n+            .setSsl(true)\n+            .setPemKeyCertOptions(\n+                new PemKeyCertOptions().setKeyPath(findFilePath(\"test-server-key.pem\"))\n+                    .setCertPath(findFilePath(\"test-server-cert.pem\"))\n+            );\n+\n+    testEndpoints = new TestEndpoints(vertx);\n+    JsonObject config = new JsonObject().put(\"verticle-instances\", 4);\n+    server = new Server(vertx, config, testEndpoints, httpServerOptions);\n+    server.start();\n+    client = createClient();\n+    setDefaultRowGenerator();\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    if (client != null) {\n+      client.close();\n+    }\n+    if (server != null) {\n+      server.stop();\n+    }\n+  }\n+\n+  @Test\n+  public void shouldExecutePullQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", false);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertFalse(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(0, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertFalse(server.getQueryIDs().contains(queryID));\n+    Integer rowCount = queryResponse.responseObject.getInteger(\"rowCount\");\n+    assertNotNull(rowCount);\n+    assertEquals(DEFAULT_ROWS.size(), rowCount.intValue());\n+  }\n+\n+  @Test\n+  public void shouldExecutePushQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertTrue(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(1, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertTrue(server.getQueryIDs().contains(queryID));\n+    assertFalse(queryResponse.responseObject.containsKey(\"rowCount\"));\n+  }\n+\n+  @Test\n+  public void shouldExecuteMultiplePushQueries() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numQueries = 10;\n+    for (int i = 0; i < numQueries; i++) {\n+      QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+      assertEquals(i + 1, server.getQueryIDs().size());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 168}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MDIwNzE5OnYy", "diffSide": "RIGHT", "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzozMzo1OVrOFeZc9w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzozMzo1OVrOFeZc9w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQxODYxNQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  assertNotNull(queryID);\n          \n          \n            \n                  assertThat(queryID, is(notNullValue()));", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367418615", "createdAt": "2020-01-16T13:33:59Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "diffHunk": "@@ -0,0 +1,885 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import io.confluent.ksql.api.TestQueryPublisher.ListRowGenerator;\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.server.Server;\n+import io.vertx.codegen.annotations.Nullable;\n+import io.vertx.core.AsyncResult;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.http.HttpVersion;\n+import io.vertx.core.json.JsonArray;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.net.PemKeyCertOptions;\n+import io.vertx.core.streams.ReadStream;\n+import io.vertx.core.streams.WriteStream;\n+import io.vertx.ext.web.client.HttpResponse;\n+import io.vertx.ext.web.client.WebClient;\n+import io.vertx.ext.web.client.WebClientOptions;\n+import io.vertx.ext.web.codec.BodyCodec;\n+import java.io.FileNotFoundException;\n+import java.net.URL;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+public class ApiTest {\n+\n+  private static final long WAIT_TIMEOUT = 10000;\n+  private static final JsonArray DEFAULT_COLUMN_NAMES = new JsonArray().add(\"name\").add(\"age\")\n+      .add(\"male\");\n+  private static final JsonArray DEFAULT_COLUMN_TYPES = new JsonArray().add(\"STRING\").add(\"INT\")\n+      .add(\"BOOLEAN\");\n+  private static final List<JsonArray> DEFAULT_ROWS = generateRows();\n+\n+  private Vertx vertx;\n+  private Server server;\n+  private TestEndpoints testEndpoints;\n+  private WebClient client;\n+\n+  @Before\n+  public void setUp() throws Throwable {\n+\n+    vertx = Vertx.vertx();\n+\n+    HttpServerOptions httpServerOptions =\n+        new HttpServerOptions()\n+            .setHost(\"localhost\")\n+            .setPort(8089)\n+            .setUseAlpn(true)\n+            .setSsl(true)\n+            .setPemKeyCertOptions(\n+                new PemKeyCertOptions().setKeyPath(findFilePath(\"test-server-key.pem\"))\n+                    .setCertPath(findFilePath(\"test-server-cert.pem\"))\n+            );\n+\n+    testEndpoints = new TestEndpoints(vertx);\n+    JsonObject config = new JsonObject().put(\"verticle-instances\", 4);\n+    server = new Server(vertx, config, testEndpoints, httpServerOptions);\n+    server.start();\n+    client = createClient();\n+    setDefaultRowGenerator();\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    if (client != null) {\n+      client.close();\n+    }\n+    if (server != null) {\n+      server.stop();\n+    }\n+  }\n+\n+  @Test\n+  public void shouldExecutePullQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", false);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertFalse(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(0, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertFalse(server.getQueryIDs().contains(queryID));\n+    Integer rowCount = queryResponse.responseObject.getInteger(\"rowCount\");\n+    assertNotNull(rowCount);\n+    assertEquals(DEFAULT_ROWS.size(), rowCount.intValue());\n+  }\n+\n+  @Test\n+  public void shouldExecutePushQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertTrue(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(1, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertTrue(server.getQueryIDs().contains(queryID));\n+    assertFalse(queryResponse.responseObject.containsKey(\"rowCount\"));\n+  }\n+\n+  @Test\n+  public void shouldExecuteMultiplePushQueries() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numQueries = 10;\n+    for (int i = 0; i < numQueries; i++) {\n+      QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+      assertEquals(i + 1, server.getQueryIDs().size());\n+      String queryID = queryResponse.responseObject.getString(\"queryID\");\n+      assertNotNull(queryID);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 170}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MDIwODYwOnYy", "diffSide": "RIGHT", "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzozNDoyOVrOFeZdzw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzozNDoyOVrOFeZdzw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQxODgzMQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  assertTrue(server.getQueryIDs().contains(queryID));\n          \n          \n            \n                  assertThat(server.getQueryIDs(), hasItem(queryID));", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367418831", "createdAt": "2020-01-16T13:34:29Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "diffHunk": "@@ -0,0 +1,885 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import io.confluent.ksql.api.TestQueryPublisher.ListRowGenerator;\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.server.Server;\n+import io.vertx.codegen.annotations.Nullable;\n+import io.vertx.core.AsyncResult;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.http.HttpVersion;\n+import io.vertx.core.json.JsonArray;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.net.PemKeyCertOptions;\n+import io.vertx.core.streams.ReadStream;\n+import io.vertx.core.streams.WriteStream;\n+import io.vertx.ext.web.client.HttpResponse;\n+import io.vertx.ext.web.client.WebClient;\n+import io.vertx.ext.web.client.WebClientOptions;\n+import io.vertx.ext.web.codec.BodyCodec;\n+import java.io.FileNotFoundException;\n+import java.net.URL;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+public class ApiTest {\n+\n+  private static final long WAIT_TIMEOUT = 10000;\n+  private static final JsonArray DEFAULT_COLUMN_NAMES = new JsonArray().add(\"name\").add(\"age\")\n+      .add(\"male\");\n+  private static final JsonArray DEFAULT_COLUMN_TYPES = new JsonArray().add(\"STRING\").add(\"INT\")\n+      .add(\"BOOLEAN\");\n+  private static final List<JsonArray> DEFAULT_ROWS = generateRows();\n+\n+  private Vertx vertx;\n+  private Server server;\n+  private TestEndpoints testEndpoints;\n+  private WebClient client;\n+\n+  @Before\n+  public void setUp() throws Throwable {\n+\n+    vertx = Vertx.vertx();\n+\n+    HttpServerOptions httpServerOptions =\n+        new HttpServerOptions()\n+            .setHost(\"localhost\")\n+            .setPort(8089)\n+            .setUseAlpn(true)\n+            .setSsl(true)\n+            .setPemKeyCertOptions(\n+                new PemKeyCertOptions().setKeyPath(findFilePath(\"test-server-key.pem\"))\n+                    .setCertPath(findFilePath(\"test-server-cert.pem\"))\n+            );\n+\n+    testEndpoints = new TestEndpoints(vertx);\n+    JsonObject config = new JsonObject().put(\"verticle-instances\", 4);\n+    server = new Server(vertx, config, testEndpoints, httpServerOptions);\n+    server.start();\n+    client = createClient();\n+    setDefaultRowGenerator();\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    if (client != null) {\n+      client.close();\n+    }\n+    if (server != null) {\n+      server.stop();\n+    }\n+  }\n+\n+  @Test\n+  public void shouldExecutePullQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", false);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertFalse(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(0, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertFalse(server.getQueryIDs().contains(queryID));\n+    Integer rowCount = queryResponse.responseObject.getInteger(\"rowCount\");\n+    assertNotNull(rowCount);\n+    assertEquals(DEFAULT_ROWS.size(), rowCount.intValue());\n+  }\n+\n+  @Test\n+  public void shouldExecutePushQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertTrue(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(1, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertTrue(server.getQueryIDs().contains(queryID));\n+    assertFalse(queryResponse.responseObject.containsKey(\"rowCount\"));\n+  }\n+\n+  @Test\n+  public void shouldExecuteMultiplePushQueries() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numQueries = 10;\n+    for (int i = 0; i < numQueries; i++) {\n+      QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+      assertEquals(i + 1, server.getQueryIDs().size());\n+      String queryID = queryResponse.responseObject.getString(\"queryID\");\n+      assertNotNull(queryID);\n+      assertTrue(server.getQueryIDs().contains(queryID));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 171}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MDIxMTg1OnYy", "diffSide": "RIGHT", "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzozNTozOVrOFeZf4w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzozNTozOVrOFeZf4w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQxOTM2Mw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                assertEquals(400, response.statusCode());\n          \n          \n            \n                assertThat(response.statusCode(), is(HttpStatus.SC_BAD_REQUEST));", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367419363", "createdAt": "2020-01-16T13:35:39Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "diffHunk": "@@ -0,0 +1,885 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import io.confluent.ksql.api.TestQueryPublisher.ListRowGenerator;\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.server.Server;\n+import io.vertx.codegen.annotations.Nullable;\n+import io.vertx.core.AsyncResult;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.http.HttpVersion;\n+import io.vertx.core.json.JsonArray;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.net.PemKeyCertOptions;\n+import io.vertx.core.streams.ReadStream;\n+import io.vertx.core.streams.WriteStream;\n+import io.vertx.ext.web.client.HttpResponse;\n+import io.vertx.ext.web.client.WebClient;\n+import io.vertx.ext.web.client.WebClientOptions;\n+import io.vertx.ext.web.codec.BodyCodec;\n+import java.io.FileNotFoundException;\n+import java.net.URL;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+public class ApiTest {\n+\n+  private static final long WAIT_TIMEOUT = 10000;\n+  private static final JsonArray DEFAULT_COLUMN_NAMES = new JsonArray().add(\"name\").add(\"age\")\n+      .add(\"male\");\n+  private static final JsonArray DEFAULT_COLUMN_TYPES = new JsonArray().add(\"STRING\").add(\"INT\")\n+      .add(\"BOOLEAN\");\n+  private static final List<JsonArray> DEFAULT_ROWS = generateRows();\n+\n+  private Vertx vertx;\n+  private Server server;\n+  private TestEndpoints testEndpoints;\n+  private WebClient client;\n+\n+  @Before\n+  public void setUp() throws Throwable {\n+\n+    vertx = Vertx.vertx();\n+\n+    HttpServerOptions httpServerOptions =\n+        new HttpServerOptions()\n+            .setHost(\"localhost\")\n+            .setPort(8089)\n+            .setUseAlpn(true)\n+            .setSsl(true)\n+            .setPemKeyCertOptions(\n+                new PemKeyCertOptions().setKeyPath(findFilePath(\"test-server-key.pem\"))\n+                    .setCertPath(findFilePath(\"test-server-cert.pem\"))\n+            );\n+\n+    testEndpoints = new TestEndpoints(vertx);\n+    JsonObject config = new JsonObject().put(\"verticle-instances\", 4);\n+    server = new Server(vertx, config, testEndpoints, httpServerOptions);\n+    server.start();\n+    client = createClient();\n+    setDefaultRowGenerator();\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    if (client != null) {\n+      client.close();\n+    }\n+    if (server != null) {\n+      server.stop();\n+    }\n+  }\n+\n+  @Test\n+  public void shouldExecutePullQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", false);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertFalse(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(0, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertFalse(server.getQueryIDs().contains(queryID));\n+    Integer rowCount = queryResponse.responseObject.getInteger(\"rowCount\");\n+    assertNotNull(rowCount);\n+    assertEquals(DEFAULT_ROWS.size(), rowCount.intValue());\n+  }\n+\n+  @Test\n+  public void shouldExecutePushQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertTrue(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(1, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertTrue(server.getQueryIDs().contains(queryID));\n+    assertFalse(queryResponse.responseObject.containsKey(\"rowCount\"));\n+  }\n+\n+  @Test\n+  public void shouldExecuteMultiplePushQueries() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numQueries = 10;\n+    for (int i = 0; i < numQueries; i++) {\n+      QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+      assertEquals(i + 1, server.getQueryIDs().size());\n+      String queryID = queryResponse.responseObject.getString(\"queryID\");\n+      assertNotNull(queryID);\n+      assertTrue(server.getQueryIDs().contains(queryID));\n+    }\n+  }\n+\n+  @Test\n+  public void shouldCloseQueriesOnDifferentConnectionsWhenConnectionsAreClosed() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numQueries = 10;\n+    List<WebClient> clients = new ArrayList<>();\n+    for (int i = 0; i < numQueries; i++) {\n+      // We use different clients to ensure requests are sent on different connections\n+      WebClient client = createClient();\n+      clients.add(client);\n+      QueryResponse queryResponse = executePushQueryAndWaitForRows(client, requestBody);\n+      String queryID = queryResponse.responseObject.getString(\"queryID\");\n+      assertNotNull(queryID);\n+      assertTrue(server.getQueryIDs().contains(queryID));\n+      assertEquals(i + 1, server.getQueryIDs().size());\n+      assertEquals(i + 1, server.queryConnectionCount());\n+    }\n+    assertAllQueries(numQueries, true);\n+\n+    int count = 0;\n+    for (WebClient client : clients) {\n+      client.close();\n+      int num = numQueries - count - 1;\n+      assertTrue(waitUntil(() -> server.queryConnectionCount() == num));\n+      assertEquals(num, server.getQueryIDs().size());\n+      count++;\n+    }\n+    assertAllQueries(numQueries, false);\n+  }\n+\n+  @Test\n+  public void shouldCloseQueriesOnSameConnectionsWhenConnectionsAreClosed() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numQueries = 10;\n+    for (int i = 0; i < numQueries; i++) {\n+      QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+      String queryID = queryResponse.responseObject.getString(\"queryID\");\n+      assertNotNull(queryID);\n+      assertTrue(server.getQueryIDs().contains(queryID));\n+      assertEquals(i + 1, server.getQueryIDs().size());\n+    }\n+    assertEquals(1, server.queryConnectionCount());\n+    assertAllQueries(numQueries, true);\n+\n+    client.close();\n+    assertTrue(waitUntil(() -> server.queryConnectionCount() == 0));\n+    assertTrue(server.getQueryIDs().isEmpty());\n+    client = null;\n+\n+    assertAllQueries(numQueries, false);\n+  }\n+\n+  @Test\n+  public void shouldCloseMultipleQueriesOnDifferentConnectionsWhenConnectionsAreClosed()\n+      throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numConnections = 5;\n+    int numQueries = 5;\n+    List<WebClient> clients = new ArrayList<>();\n+    for (int i = 0; i < numConnections; i++) {\n+      WebClient client = createClient();\n+      clients.add(client);\n+      for (int j = 0; j < numQueries; j++) {\n+        QueryResponse queryResponse = executePushQueryAndWaitForRows(client, requestBody);\n+        String queryID = queryResponse.responseObject.getString(\"queryID\");\n+        assertNotNull(queryID);\n+        assertTrue(server.getQueryIDs().contains(queryID));\n+        int queries = i * numQueries + j + 1;\n+        assertEquals(i * numQueries + j + 1, server.getQueryIDs().size());\n+        assertEquals(i + 1, server.queryConnectionCount());\n+        assertAllQueries(queries, true);\n+      }\n+    }\n+\n+    int count = 0;\n+    for (WebClient client : clients) {\n+      client.close();\n+      int connections = numConnections - count - 1;\n+      assertTrue(waitUntil(() -> server.queryConnectionCount() == connections));\n+      assertEquals(numQueries * connections, server.getQueryIDs().size());\n+      count++;\n+    }\n+\n+    assertAllQueries(numConnections * numQueries, false);\n+  }\n+\n+  @Test\n+  public void shouldHandleQueryWithMissingSql() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"foo\", \"bar\");\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(400, response.statusCode());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 279}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MDI2NzA1OnYy", "diffSide": "RIGHT", "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzo1MzoyM1rOFeaCKg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMFQxNzoxOToyMVrOFflHhA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQyODEzOA==", "bodyText": "Take a look at assertThatEventually. I think you can use this in place of waitUtil in at least some cases.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367428138", "createdAt": "2020-01-16T13:53:23Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "diffHunk": "@@ -0,0 +1,885 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import io.confluent.ksql.api.TestQueryPublisher.ListRowGenerator;\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.server.Server;\n+import io.vertx.codegen.annotations.Nullable;\n+import io.vertx.core.AsyncResult;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.http.HttpVersion;\n+import io.vertx.core.json.JsonArray;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.net.PemKeyCertOptions;\n+import io.vertx.core.streams.ReadStream;\n+import io.vertx.core.streams.WriteStream;\n+import io.vertx.ext.web.client.HttpResponse;\n+import io.vertx.ext.web.client.WebClient;\n+import io.vertx.ext.web.client.WebClientOptions;\n+import io.vertx.ext.web.codec.BodyCodec;\n+import java.io.FileNotFoundException;\n+import java.net.URL;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+public class ApiTest {\n+\n+  private static final long WAIT_TIMEOUT = 10000;\n+  private static final JsonArray DEFAULT_COLUMN_NAMES = new JsonArray().add(\"name\").add(\"age\")\n+      .add(\"male\");\n+  private static final JsonArray DEFAULT_COLUMN_TYPES = new JsonArray().add(\"STRING\").add(\"INT\")\n+      .add(\"BOOLEAN\");\n+  private static final List<JsonArray> DEFAULT_ROWS = generateRows();\n+\n+  private Vertx vertx;\n+  private Server server;\n+  private TestEndpoints testEndpoints;\n+  private WebClient client;\n+\n+  @Before\n+  public void setUp() throws Throwable {\n+\n+    vertx = Vertx.vertx();\n+\n+    HttpServerOptions httpServerOptions =\n+        new HttpServerOptions()\n+            .setHost(\"localhost\")\n+            .setPort(8089)\n+            .setUseAlpn(true)\n+            .setSsl(true)\n+            .setPemKeyCertOptions(\n+                new PemKeyCertOptions().setKeyPath(findFilePath(\"test-server-key.pem\"))\n+                    .setCertPath(findFilePath(\"test-server-cert.pem\"))\n+            );\n+\n+    testEndpoints = new TestEndpoints(vertx);\n+    JsonObject config = new JsonObject().put(\"verticle-instances\", 4);\n+    server = new Server(vertx, config, testEndpoints, httpServerOptions);\n+    server.start();\n+    client = createClient();\n+    setDefaultRowGenerator();\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    if (client != null) {\n+      client.close();\n+    }\n+    if (server != null) {\n+      server.stop();\n+    }\n+  }\n+\n+  @Test\n+  public void shouldExecutePullQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", false);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertFalse(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(0, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertFalse(server.getQueryIDs().contains(queryID));\n+    Integer rowCount = queryResponse.responseObject.getInteger(\"rowCount\");\n+    assertNotNull(rowCount);\n+    assertEquals(DEFAULT_ROWS.size(), rowCount.intValue());\n+  }\n+\n+  @Test\n+  public void shouldExecutePushQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertTrue(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(1, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertTrue(server.getQueryIDs().contains(queryID));\n+    assertFalse(queryResponse.responseObject.containsKey(\"rowCount\"));\n+  }\n+\n+  @Test\n+  public void shouldExecuteMultiplePushQueries() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numQueries = 10;\n+    for (int i = 0; i < numQueries; i++) {\n+      QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+      assertEquals(i + 1, server.getQueryIDs().size());\n+      String queryID = queryResponse.responseObject.getString(\"queryID\");\n+      assertNotNull(queryID);\n+      assertTrue(server.getQueryIDs().contains(queryID));\n+    }\n+  }\n+\n+  @Test\n+  public void shouldCloseQueriesOnDifferentConnectionsWhenConnectionsAreClosed() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numQueries = 10;\n+    List<WebClient> clients = new ArrayList<>();\n+    for (int i = 0; i < numQueries; i++) {\n+      // We use different clients to ensure requests are sent on different connections\n+      WebClient client = createClient();\n+      clients.add(client);\n+      QueryResponse queryResponse = executePushQueryAndWaitForRows(client, requestBody);\n+      String queryID = queryResponse.responseObject.getString(\"queryID\");\n+      assertNotNull(queryID);\n+      assertTrue(server.getQueryIDs().contains(queryID));\n+      assertEquals(i + 1, server.getQueryIDs().size());\n+      assertEquals(i + 1, server.queryConnectionCount());\n+    }\n+    assertAllQueries(numQueries, true);\n+\n+    int count = 0;\n+    for (WebClient client : clients) {\n+      client.close();\n+      int num = numQueries - count - 1;\n+      assertTrue(waitUntil(() -> server.queryConnectionCount() == num));\n+      assertEquals(num, server.getQueryIDs().size());\n+      count++;\n+    }\n+    assertAllQueries(numQueries, false);\n+  }\n+\n+  @Test\n+  public void shouldCloseQueriesOnSameConnectionsWhenConnectionsAreClosed() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numQueries = 10;\n+    for (int i = 0; i < numQueries; i++) {\n+      QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+      String queryID = queryResponse.responseObject.getString(\"queryID\");\n+      assertNotNull(queryID);\n+      assertTrue(server.getQueryIDs().contains(queryID));\n+      assertEquals(i + 1, server.getQueryIDs().size());\n+    }\n+    assertEquals(1, server.queryConnectionCount());\n+    assertAllQueries(numQueries, true);\n+\n+    client.close();\n+    assertTrue(waitUntil(() -> server.queryConnectionCount() == 0));\n+    assertTrue(server.getQueryIDs().isEmpty());\n+    client = null;\n+\n+    assertAllQueries(numQueries, false);\n+  }\n+\n+  @Test\n+  public void shouldCloseMultipleQueriesOnDifferentConnectionsWhenConnectionsAreClosed()\n+      throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numConnections = 5;\n+    int numQueries = 5;\n+    List<WebClient> clients = new ArrayList<>();\n+    for (int i = 0; i < numConnections; i++) {\n+      WebClient client = createClient();\n+      clients.add(client);\n+      for (int j = 0; j < numQueries; j++) {\n+        QueryResponse queryResponse = executePushQueryAndWaitForRows(client, requestBody);\n+        String queryID = queryResponse.responseObject.getString(\"queryID\");\n+        assertNotNull(queryID);\n+        assertTrue(server.getQueryIDs().contains(queryID));\n+        int queries = i * numQueries + j + 1;\n+        assertEquals(i * numQueries + j + 1, server.getQueryIDs().size());\n+        assertEquals(i + 1, server.queryConnectionCount());\n+        assertAllQueries(queries, true);\n+      }\n+    }\n+\n+    int count = 0;\n+    for (WebClient client : clients) {\n+      client.close();\n+      int connections = numConnections - count - 1;\n+      assertTrue(waitUntil(() -> server.queryConnectionCount() == connections));\n+      assertEquals(numQueries * connections, server.getQueryIDs().size());\n+      count++;\n+    }\n+\n+    assertAllQueries(numConnections * numQueries, false);\n+  }\n+\n+  @Test\n+  public void shouldHandleQueryWithMissingSql() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"foo\", \"bar\");\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(400, response.statusCode());\n+    assertEquals(\"Bad Request\", response.statusMessage());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    validateError(ERROR_CODE_MISSING_PARAM, \"No sql in arguments\", queryResponse.responseObject);\n+  }\n+\n+  @Test\n+  public void shouldHandleQueryWithMissingPush() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\");\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(400, response.statusCode());\n+    assertEquals(\"Bad Request\", response.statusMessage());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    validateError(ERROR_CODE_MISSING_PARAM, \"No push in arguments\", queryResponse.responseObject);\n+  }\n+\n+  @Test\n+  public void shouldHandleErrorInProcessingQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    testEndpoints.setRowsBeforePublisherError(DEFAULT_ROWS.size() - 1);\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    assertEquals(DEFAULT_ROWS.size() - 1, queryResponse.rows.size());\n+    validateError(ERROR_CODE_INTERNAL_ERROR, \"Error in processing query\", queryResponse.error);\n+\n+    assertEquals(1, testEndpoints.getQueryPublishers().size());\n+    assertFalse(testEndpoints.getQueryPublishers().iterator().next().hasSubscriber());\n+    assertTrue(server.getQueryIDs().isEmpty());\n+  }\n+\n+  @Test\n+  public void shouldCloseQuery() throws Exception {\n+\n+    JsonObject queryRequestBody = new JsonObject().put(\"sql\", \"select * from foo\")\n+        .put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    queryRequestBody.put(\"properties\", properties);\n+\n+    ReceiveStream writeStream = new ReceiveStream(vertx);\n+\n+    client.post(8089, \"localhost\", \"/query-stream\")\n+        .as(BodyCodec.pipe(writeStream))\n+        .sendJsonObject(queryRequestBody, ar -> {\n+        });\n+\n+    // Wait for all rows to arrive\n+    assertTrue(waitUntil(() -> {\n+      Buffer buff = writeStream.getBody();\n+      try {\n+        QueryResponse queryResponse = new QueryResponse(buff.toString());\n+        return queryResponse.rows.size() == DEFAULT_ROWS.size();\n+      } catch (Throwable t) {\n+        return false;\n+      }\n+    }));\n+\n+    assertFalse(writeStream.isEnded());\n+\n+    QueryResponse queryResponse = new QueryResponse(writeStream.getBody().toString());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertTrue(server.getQueryIDs().contains(queryID));\n+    assertEquals(1, server.getQueryIDs().size());\n+    assertEquals(1, testEndpoints.getQueryPublishers().size());\n+\n+    JsonObject closeQueryRequestBody = new JsonObject().put(\"queryID\", queryID);\n+    HttpResponse<Buffer> closeQueryResponse = sendRequest(client, \"/close-query\",\n+        closeQueryRequestBody.toBuffer());\n+    assertEquals(200, closeQueryResponse.statusCode());\n+    assertFalse(server.getQueryIDs().contains(queryID));\n+    assertEquals(0, server.getQueryIDs().size());\n+\n+    // This should trigger the response to end\n+    assertTrue(waitUntil(writeStream::isEnded));\n+\n+    assertEquals(1, testEndpoints.getQueryPublishers().size());\n+    assertFalse(testEndpoints.getQueryPublishers().iterator().next().hasSubscriber());\n+  }\n+\n+  @Test\n+  public void shouldHandleMissingQueryIDInCloseQuery() throws Exception {\n+\n+    JsonObject closeQueryRequestBody = new JsonObject().put(\"foo\", \"bar\");\n+    HttpResponse<Buffer> response = sendRequest(client, \"/close-query\",\n+        closeQueryRequestBody.toBuffer());\n+\n+    assertEquals(400, response.statusCode());\n+    assertEquals(\"Bad Request\", response.statusMessage());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    validateError(ERROR_CODE_MISSING_PARAM, \"No queryID in arguments\",\n+        queryResponse.responseObject);\n+  }\n+\n+  @Test\n+  public void shouldHandleUnknownQueryIDInCloseQuery() throws Exception {\n+\n+    JsonObject closeQueryRequestBody = new JsonObject().put(\"queryID\", \"xyzfasgf\");\n+    HttpResponse<Buffer> response = sendRequest(client, \"/close-query\",\n+        closeQueryRequestBody.toBuffer());\n+\n+    assertEquals(400, response.statusCode());\n+    assertEquals(\"Bad Request\", response.statusMessage());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    validateError(ERROR_CODE_UNKNOWN_QUERY_ID, \"No query with id xyzfasgf\",\n+        queryResponse.responseObject);\n+  }\n+\n+  @Test\n+  public void shouldInsertWithNoAcksStream() throws Exception {\n+\n+    JsonObject params = new JsonObject().put(\"target\", \"test-stream\").put(\"acks\", false);\n+\n+    List<JsonObject> rows = generateInsertRows();\n+    Buffer requestBody = Buffer.buffer();\n+    requestBody.appendBuffer(params.toBuffer()).appendString(\"\\n\");\n+    for (JsonObject row : rows) {\n+      requestBody.appendBuffer(row.toBuffer()).appendString(\"\\n\");\n+    }\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/inserts-stream\", requestBody);\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+\n+    assertEquals(rows, testEndpoints.getInsertsSubscriber().getRowsInserted());\n+    assertTrue(testEndpoints.getInsertsSubscriber().isCompleted());\n+    assertEquals(\"test-stream\", testEndpoints.getLastTarget());\n+  }\n+\n+  @Test\n+  public void shouldInsertWithAcksStream() throws Exception {\n+\n+    JsonObject params = new JsonObject().put(\"target\", \"test-stream\").put(\"acks\", true);\n+\n+    List<JsonObject> rows = generateInsertRows();\n+    Buffer requestBody = Buffer.buffer();\n+    requestBody.appendBuffer(params.toBuffer()).appendString(\"\\n\");\n+    for (JsonObject row : rows) {\n+      requestBody.appendBuffer(row.toBuffer()).appendString(\"\\n\");\n+    }\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/inserts-stream\", requestBody);\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+\n+    String responseBody = response.bodyAsString();\n+    InsertsResponse insertsResponse = new InsertsResponse(responseBody);\n+    assertEquals(rows.size(), insertsResponse.acks.size());\n+\n+    assertEquals(rows, testEndpoints.getInsertsSubscriber().getRowsInserted());\n+    assertTrue(testEndpoints.getInsertsSubscriber().isCompleted());\n+    assertEquals(\"test-stream\", testEndpoints.getLastTarget());\n+  }\n+\n+  @Test\n+  public void shouldStreamInserts() throws Exception {\n+\n+    JsonObject params = new JsonObject().put(\"target\", \"test-stream\").put(\"acks\", true);\n+\n+    SendStream readStream = new SendStream(vertx);\n+    ReceiveStream writeStream = new ReceiveStream(vertx);\n+    VertxCompletableFuture<HttpResponse<Void>> fut = new VertxCompletableFuture<>();\n+    List<JsonObject> rows = generateInsertRows();\n+\n+    client.post(8089, \"localhost\", \"/inserts-stream\")\n+        .as(BodyCodec.pipe(writeStream))\n+        .sendStream(readStream, fut);\n+\n+    readStream.acceptBuffer(params.toBuffer().appendString(\"\\n\"));\n+\n+    AtomicInteger rowIndex = new AtomicInteger();\n+    vertx.setPeriodic(100, tid -> {\n+      readStream.acceptBuffer(rows.get(rowIndex.getAndIncrement()).toBuffer().appendString(\"\\n\"));\n+      if (rowIndex.get() == rows.size()) {\n+        vertx.cancelTimer(tid);\n+        readStream.end();\n+      }\n+    });\n+\n+    HttpResponse<Void> response = fut.get();\n+\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+\n+    InsertsResponse insertsResponse = new InsertsResponse(writeStream.getBody().toString());\n+    assertEquals(rows.size(), insertsResponse.acks.size());\n+    assertEquals(rows, testEndpoints.getInsertsSubscriber().getRowsInserted());\n+    assertTrue(testEndpoints.getInsertsSubscriber().isCompleted());\n+    // When response is complete the acks subscriber should be unsubscribed\n+    assertFalse(testEndpoints.getAcksPublisher().hasSubscriber());\n+\n+    // Ensure we received at last some of the response before all the request body was written\n+    // Yay HTTP2!\n+    assertTrue(readStream.getLastSentTime() > writeStream.getFirstReceivedTime());\n+  }\n+\n+  @Test\n+  public void shouldHandleMissingTargetInInserts() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"acks\", true);\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/inserts-stream\",\n+        requestBody.toBuffer().appendString(\"\\n\"));\n+\n+    assertEquals(400, response.statusCode());\n+    assertEquals(\"Bad Request\", response.statusMessage());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    validateError(ERROR_CODE_MISSING_PARAM, \"No target in arguments\", queryResponse.responseObject);\n+  }\n+\n+  @Test\n+  public void shouldHandleMissingAcksInInserts() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"target\", \"some-stream\");\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/inserts-stream\",\n+        requestBody.toBuffer().appendString(\"\\n\"));\n+\n+    assertEquals(400, response.statusCode());\n+    assertEquals(\"Bad Request\", response.statusMessage());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    validateError(ERROR_CODE_MISSING_PARAM, \"No acks in arguments\",\n+        queryResponse.responseObject);\n+  }\n+\n+  @Test\n+  public void shouldHandleErrorInProcessingInserts() throws Exception {\n+\n+    JsonObject params = new JsonObject().put(\"target\", \"test-stream\").put(\"acks\", true);\n+\n+    List<JsonObject> rows = generateInsertRows();\n+    Buffer requestBody = Buffer.buffer();\n+    requestBody.appendBuffer(params.toBuffer()).appendString(\"\\n\");\n+    for (JsonObject row : rows) {\n+      requestBody.appendBuffer(row.toBuffer()).appendString(\"\\n\");\n+    }\n+\n+    // Inject an error on last row inserted\n+    testEndpoints.setAcksBeforePublisherError(rows.size() - 1);\n+\n+    // The HTTP response will be OK as the error is later in the stream after response\n+    // headers have been written\n+    HttpResponse<Buffer> response = sendRequest(\"/inserts-stream\", requestBody);\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+\n+    String responseBody = response.bodyAsString();\n+    InsertsResponse insertsResponse = new InsertsResponse(responseBody);\n+    assertEquals(rows.size() - 1, insertsResponse.acks.size());\n+    validateError(ERROR_CODE_INTERNAL_ERROR, \"Error in processing inserts\", insertsResponse.error);\n+\n+    assertTrue(testEndpoints.getInsertsSubscriber().isCompleted());\n+  }\n+\n+  private QueryResponse executePushQueryAndWaitForRows(final JsonObject requestBody)\n+      throws Exception {\n+    return executePushQueryAndWaitForRows(client, requestBody);\n+  }\n+\n+  private QueryResponse executePushQueryAndWaitForRows(final WebClient client,\n+      final JsonObject requestBody)\n+      throws Exception {\n+\n+    ReceiveStream writeStream = new ReceiveStream(vertx);\n+\n+    client.post(8089, \"localhost\", \"/query-stream\")\n+        .as(BodyCodec.pipe(writeStream))\n+        .sendJsonObject(requestBody, ar -> {\n+        });\n+\n+    // Wait for all rows to arrive\n+    assertTrue(waitUntil(() -> {\n+      Buffer buff = writeStream.getBody();\n+      try {\n+        QueryResponse queryResponse = new QueryResponse(buff.toString());\n+        return queryResponse.rows.size() == DEFAULT_ROWS.size();\n+      } catch (Throwable t) {\n+        return false;\n+      }\n+    }));\n+\n+    // Note, the response hasn't ended at this point\n+    assertFalse(writeStream.isEnded());\n+\n+    return new QueryResponse(writeStream.getBody().toString());\n+  }\n+\n+  private WebClient createClient() {\n+    WebClientOptions options = new WebClientOptions().setSsl(true).\n+        setUseAlpn(true).\n+        setProtocolVersion(HttpVersion.HTTP_2).\n+        setTrustAll(true);\n+\n+    return WebClient.create(vertx, options);\n+  }\n+\n+  private static void validateError(final int errorCode, final String message,\n+      final JsonObject error) {\n+    assertEquals(\"error\", error.getString(\"status\"));\n+    assertEquals(errorCode, error.getInteger(\"errorCode\").intValue());\n+    assertEquals(message, error.getString(\"message\"));\n+    assertEquals(3, error.size());\n+  }\n+\n+  private void assertAllQueries(final int num, final boolean open) {\n+    assertEquals(num, testEndpoints.getQueryPublishers().size());\n+    for (TestQueryPublisher queryPublisher : testEndpoints.getQueryPublishers()) {\n+      if (open) {\n+        assertTrue(queryPublisher.hasSubscriber());\n+      } else {\n+        assertFalse(queryPublisher.hasSubscriber());\n+      }\n+    }\n+  }\n+\n+  private HttpResponse<Buffer> sendRequest(final String uri, final Buffer requestBody)\n+      throws Exception {\n+    return sendRequest(client, uri, requestBody);\n+  }\n+\n+  private HttpResponse<Buffer> sendRequest(final WebClient client, final String uri,\n+      final Buffer requestBody)\n+      throws Exception {\n+    VertxCompletableFuture<HttpResponse<Buffer>> requestFuture = new VertxCompletableFuture<>();\n+    client\n+        .post(8089, \"localhost\", uri)\n+        .sendBuffer(requestBody, requestFuture);\n+    return requestFuture.get();\n+  }\n+\n+  private void setDefaultRowGenerator() {\n+    testEndpoints.setRowGeneratorFactory(\n+        () -> new ListRowGenerator(DEFAULT_COLUMN_NAMES, DEFAULT_COLUMN_TYPES,\n+            DEFAULT_ROWS));\n+  }\n+\n+  private static boolean waitUntil(final Supplier<Boolean> test) throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 631}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzYzNjA5MQ==", "bodyText": "I think that requires a hamcrest matcher as opposed to this version which works more simply with a Supplier.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367636091", "createdAt": "2020-01-16T20:34:48Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "diffHunk": "@@ -0,0 +1,885 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import io.confluent.ksql.api.TestQueryPublisher.ListRowGenerator;\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.server.Server;\n+import io.vertx.codegen.annotations.Nullable;\n+import io.vertx.core.AsyncResult;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.http.HttpVersion;\n+import io.vertx.core.json.JsonArray;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.net.PemKeyCertOptions;\n+import io.vertx.core.streams.ReadStream;\n+import io.vertx.core.streams.WriteStream;\n+import io.vertx.ext.web.client.HttpResponse;\n+import io.vertx.ext.web.client.WebClient;\n+import io.vertx.ext.web.client.WebClientOptions;\n+import io.vertx.ext.web.codec.BodyCodec;\n+import java.io.FileNotFoundException;\n+import java.net.URL;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+public class ApiTest {\n+\n+  private static final long WAIT_TIMEOUT = 10000;\n+  private static final JsonArray DEFAULT_COLUMN_NAMES = new JsonArray().add(\"name\").add(\"age\")\n+      .add(\"male\");\n+  private static final JsonArray DEFAULT_COLUMN_TYPES = new JsonArray().add(\"STRING\").add(\"INT\")\n+      .add(\"BOOLEAN\");\n+  private static final List<JsonArray> DEFAULT_ROWS = generateRows();\n+\n+  private Vertx vertx;\n+  private Server server;\n+  private TestEndpoints testEndpoints;\n+  private WebClient client;\n+\n+  @Before\n+  public void setUp() throws Throwable {\n+\n+    vertx = Vertx.vertx();\n+\n+    HttpServerOptions httpServerOptions =\n+        new HttpServerOptions()\n+            .setHost(\"localhost\")\n+            .setPort(8089)\n+            .setUseAlpn(true)\n+            .setSsl(true)\n+            .setPemKeyCertOptions(\n+                new PemKeyCertOptions().setKeyPath(findFilePath(\"test-server-key.pem\"))\n+                    .setCertPath(findFilePath(\"test-server-cert.pem\"))\n+            );\n+\n+    testEndpoints = new TestEndpoints(vertx);\n+    JsonObject config = new JsonObject().put(\"verticle-instances\", 4);\n+    server = new Server(vertx, config, testEndpoints, httpServerOptions);\n+    server.start();\n+    client = createClient();\n+    setDefaultRowGenerator();\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    if (client != null) {\n+      client.close();\n+    }\n+    if (server != null) {\n+      server.stop();\n+    }\n+  }\n+\n+  @Test\n+  public void shouldExecutePullQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", false);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertFalse(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(0, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertFalse(server.getQueryIDs().contains(queryID));\n+    Integer rowCount = queryResponse.responseObject.getInteger(\"rowCount\");\n+    assertNotNull(rowCount);\n+    assertEquals(DEFAULT_ROWS.size(), rowCount.intValue());\n+  }\n+\n+  @Test\n+  public void shouldExecutePushQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertTrue(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(1, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertTrue(server.getQueryIDs().contains(queryID));\n+    assertFalse(queryResponse.responseObject.containsKey(\"rowCount\"));\n+  }\n+\n+  @Test\n+  public void shouldExecuteMultiplePushQueries() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numQueries = 10;\n+    for (int i = 0; i < numQueries; i++) {\n+      QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+      assertEquals(i + 1, server.getQueryIDs().size());\n+      String queryID = queryResponse.responseObject.getString(\"queryID\");\n+      assertNotNull(queryID);\n+      assertTrue(server.getQueryIDs().contains(queryID));\n+    }\n+  }\n+\n+  @Test\n+  public void shouldCloseQueriesOnDifferentConnectionsWhenConnectionsAreClosed() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numQueries = 10;\n+    List<WebClient> clients = new ArrayList<>();\n+    for (int i = 0; i < numQueries; i++) {\n+      // We use different clients to ensure requests are sent on different connections\n+      WebClient client = createClient();\n+      clients.add(client);\n+      QueryResponse queryResponse = executePushQueryAndWaitForRows(client, requestBody);\n+      String queryID = queryResponse.responseObject.getString(\"queryID\");\n+      assertNotNull(queryID);\n+      assertTrue(server.getQueryIDs().contains(queryID));\n+      assertEquals(i + 1, server.getQueryIDs().size());\n+      assertEquals(i + 1, server.queryConnectionCount());\n+    }\n+    assertAllQueries(numQueries, true);\n+\n+    int count = 0;\n+    for (WebClient client : clients) {\n+      client.close();\n+      int num = numQueries - count - 1;\n+      assertTrue(waitUntil(() -> server.queryConnectionCount() == num));\n+      assertEquals(num, server.getQueryIDs().size());\n+      count++;\n+    }\n+    assertAllQueries(numQueries, false);\n+  }\n+\n+  @Test\n+  public void shouldCloseQueriesOnSameConnectionsWhenConnectionsAreClosed() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numQueries = 10;\n+    for (int i = 0; i < numQueries; i++) {\n+      QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+      String queryID = queryResponse.responseObject.getString(\"queryID\");\n+      assertNotNull(queryID);\n+      assertTrue(server.getQueryIDs().contains(queryID));\n+      assertEquals(i + 1, server.getQueryIDs().size());\n+    }\n+    assertEquals(1, server.queryConnectionCount());\n+    assertAllQueries(numQueries, true);\n+\n+    client.close();\n+    assertTrue(waitUntil(() -> server.queryConnectionCount() == 0));\n+    assertTrue(server.getQueryIDs().isEmpty());\n+    client = null;\n+\n+    assertAllQueries(numQueries, false);\n+  }\n+\n+  @Test\n+  public void shouldCloseMultipleQueriesOnDifferentConnectionsWhenConnectionsAreClosed()\n+      throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numConnections = 5;\n+    int numQueries = 5;\n+    List<WebClient> clients = new ArrayList<>();\n+    for (int i = 0; i < numConnections; i++) {\n+      WebClient client = createClient();\n+      clients.add(client);\n+      for (int j = 0; j < numQueries; j++) {\n+        QueryResponse queryResponse = executePushQueryAndWaitForRows(client, requestBody);\n+        String queryID = queryResponse.responseObject.getString(\"queryID\");\n+        assertNotNull(queryID);\n+        assertTrue(server.getQueryIDs().contains(queryID));\n+        int queries = i * numQueries + j + 1;\n+        assertEquals(i * numQueries + j + 1, server.getQueryIDs().size());\n+        assertEquals(i + 1, server.queryConnectionCount());\n+        assertAllQueries(queries, true);\n+      }\n+    }\n+\n+    int count = 0;\n+    for (WebClient client : clients) {\n+      client.close();\n+      int connections = numConnections - count - 1;\n+      assertTrue(waitUntil(() -> server.queryConnectionCount() == connections));\n+      assertEquals(numQueries * connections, server.getQueryIDs().size());\n+      count++;\n+    }\n+\n+    assertAllQueries(numConnections * numQueries, false);\n+  }\n+\n+  @Test\n+  public void shouldHandleQueryWithMissingSql() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"foo\", \"bar\");\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(400, response.statusCode());\n+    assertEquals(\"Bad Request\", response.statusMessage());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    validateError(ERROR_CODE_MISSING_PARAM, \"No sql in arguments\", queryResponse.responseObject);\n+  }\n+\n+  @Test\n+  public void shouldHandleQueryWithMissingPush() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\");\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(400, response.statusCode());\n+    assertEquals(\"Bad Request\", response.statusMessage());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    validateError(ERROR_CODE_MISSING_PARAM, \"No push in arguments\", queryResponse.responseObject);\n+  }\n+\n+  @Test\n+  public void shouldHandleErrorInProcessingQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    testEndpoints.setRowsBeforePublisherError(DEFAULT_ROWS.size() - 1);\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    assertEquals(DEFAULT_ROWS.size() - 1, queryResponse.rows.size());\n+    validateError(ERROR_CODE_INTERNAL_ERROR, \"Error in processing query\", queryResponse.error);\n+\n+    assertEquals(1, testEndpoints.getQueryPublishers().size());\n+    assertFalse(testEndpoints.getQueryPublishers().iterator().next().hasSubscriber());\n+    assertTrue(server.getQueryIDs().isEmpty());\n+  }\n+\n+  @Test\n+  public void shouldCloseQuery() throws Exception {\n+\n+    JsonObject queryRequestBody = new JsonObject().put(\"sql\", \"select * from foo\")\n+        .put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    queryRequestBody.put(\"properties\", properties);\n+\n+    ReceiveStream writeStream = new ReceiveStream(vertx);\n+\n+    client.post(8089, \"localhost\", \"/query-stream\")\n+        .as(BodyCodec.pipe(writeStream))\n+        .sendJsonObject(queryRequestBody, ar -> {\n+        });\n+\n+    // Wait for all rows to arrive\n+    assertTrue(waitUntil(() -> {\n+      Buffer buff = writeStream.getBody();\n+      try {\n+        QueryResponse queryResponse = new QueryResponse(buff.toString());\n+        return queryResponse.rows.size() == DEFAULT_ROWS.size();\n+      } catch (Throwable t) {\n+        return false;\n+      }\n+    }));\n+\n+    assertFalse(writeStream.isEnded());\n+\n+    QueryResponse queryResponse = new QueryResponse(writeStream.getBody().toString());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertTrue(server.getQueryIDs().contains(queryID));\n+    assertEquals(1, server.getQueryIDs().size());\n+    assertEquals(1, testEndpoints.getQueryPublishers().size());\n+\n+    JsonObject closeQueryRequestBody = new JsonObject().put(\"queryID\", queryID);\n+    HttpResponse<Buffer> closeQueryResponse = sendRequest(client, \"/close-query\",\n+        closeQueryRequestBody.toBuffer());\n+    assertEquals(200, closeQueryResponse.statusCode());\n+    assertFalse(server.getQueryIDs().contains(queryID));\n+    assertEquals(0, server.getQueryIDs().size());\n+\n+    // This should trigger the response to end\n+    assertTrue(waitUntil(writeStream::isEnded));\n+\n+    assertEquals(1, testEndpoints.getQueryPublishers().size());\n+    assertFalse(testEndpoints.getQueryPublishers().iterator().next().hasSubscriber());\n+  }\n+\n+  @Test\n+  public void shouldHandleMissingQueryIDInCloseQuery() throws Exception {\n+\n+    JsonObject closeQueryRequestBody = new JsonObject().put(\"foo\", \"bar\");\n+    HttpResponse<Buffer> response = sendRequest(client, \"/close-query\",\n+        closeQueryRequestBody.toBuffer());\n+\n+    assertEquals(400, response.statusCode());\n+    assertEquals(\"Bad Request\", response.statusMessage());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    validateError(ERROR_CODE_MISSING_PARAM, \"No queryID in arguments\",\n+        queryResponse.responseObject);\n+  }\n+\n+  @Test\n+  public void shouldHandleUnknownQueryIDInCloseQuery() throws Exception {\n+\n+    JsonObject closeQueryRequestBody = new JsonObject().put(\"queryID\", \"xyzfasgf\");\n+    HttpResponse<Buffer> response = sendRequest(client, \"/close-query\",\n+        closeQueryRequestBody.toBuffer());\n+\n+    assertEquals(400, response.statusCode());\n+    assertEquals(\"Bad Request\", response.statusMessage());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    validateError(ERROR_CODE_UNKNOWN_QUERY_ID, \"No query with id xyzfasgf\",\n+        queryResponse.responseObject);\n+  }\n+\n+  @Test\n+  public void shouldInsertWithNoAcksStream() throws Exception {\n+\n+    JsonObject params = new JsonObject().put(\"target\", \"test-stream\").put(\"acks\", false);\n+\n+    List<JsonObject> rows = generateInsertRows();\n+    Buffer requestBody = Buffer.buffer();\n+    requestBody.appendBuffer(params.toBuffer()).appendString(\"\\n\");\n+    for (JsonObject row : rows) {\n+      requestBody.appendBuffer(row.toBuffer()).appendString(\"\\n\");\n+    }\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/inserts-stream\", requestBody);\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+\n+    assertEquals(rows, testEndpoints.getInsertsSubscriber().getRowsInserted());\n+    assertTrue(testEndpoints.getInsertsSubscriber().isCompleted());\n+    assertEquals(\"test-stream\", testEndpoints.getLastTarget());\n+  }\n+\n+  @Test\n+  public void shouldInsertWithAcksStream() throws Exception {\n+\n+    JsonObject params = new JsonObject().put(\"target\", \"test-stream\").put(\"acks\", true);\n+\n+    List<JsonObject> rows = generateInsertRows();\n+    Buffer requestBody = Buffer.buffer();\n+    requestBody.appendBuffer(params.toBuffer()).appendString(\"\\n\");\n+    for (JsonObject row : rows) {\n+      requestBody.appendBuffer(row.toBuffer()).appendString(\"\\n\");\n+    }\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/inserts-stream\", requestBody);\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+\n+    String responseBody = response.bodyAsString();\n+    InsertsResponse insertsResponse = new InsertsResponse(responseBody);\n+    assertEquals(rows.size(), insertsResponse.acks.size());\n+\n+    assertEquals(rows, testEndpoints.getInsertsSubscriber().getRowsInserted());\n+    assertTrue(testEndpoints.getInsertsSubscriber().isCompleted());\n+    assertEquals(\"test-stream\", testEndpoints.getLastTarget());\n+  }\n+\n+  @Test\n+  public void shouldStreamInserts() throws Exception {\n+\n+    JsonObject params = new JsonObject().put(\"target\", \"test-stream\").put(\"acks\", true);\n+\n+    SendStream readStream = new SendStream(vertx);\n+    ReceiveStream writeStream = new ReceiveStream(vertx);\n+    VertxCompletableFuture<HttpResponse<Void>> fut = new VertxCompletableFuture<>();\n+    List<JsonObject> rows = generateInsertRows();\n+\n+    client.post(8089, \"localhost\", \"/inserts-stream\")\n+        .as(BodyCodec.pipe(writeStream))\n+        .sendStream(readStream, fut);\n+\n+    readStream.acceptBuffer(params.toBuffer().appendString(\"\\n\"));\n+\n+    AtomicInteger rowIndex = new AtomicInteger();\n+    vertx.setPeriodic(100, tid -> {\n+      readStream.acceptBuffer(rows.get(rowIndex.getAndIncrement()).toBuffer().appendString(\"\\n\"));\n+      if (rowIndex.get() == rows.size()) {\n+        vertx.cancelTimer(tid);\n+        readStream.end();\n+      }\n+    });\n+\n+    HttpResponse<Void> response = fut.get();\n+\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+\n+    InsertsResponse insertsResponse = new InsertsResponse(writeStream.getBody().toString());\n+    assertEquals(rows.size(), insertsResponse.acks.size());\n+    assertEquals(rows, testEndpoints.getInsertsSubscriber().getRowsInserted());\n+    assertTrue(testEndpoints.getInsertsSubscriber().isCompleted());\n+    // When response is complete the acks subscriber should be unsubscribed\n+    assertFalse(testEndpoints.getAcksPublisher().hasSubscriber());\n+\n+    // Ensure we received at last some of the response before all the request body was written\n+    // Yay HTTP2!\n+    assertTrue(readStream.getLastSentTime() > writeStream.getFirstReceivedTime());\n+  }\n+\n+  @Test\n+  public void shouldHandleMissingTargetInInserts() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"acks\", true);\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/inserts-stream\",\n+        requestBody.toBuffer().appendString(\"\\n\"));\n+\n+    assertEquals(400, response.statusCode());\n+    assertEquals(\"Bad Request\", response.statusMessage());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    validateError(ERROR_CODE_MISSING_PARAM, \"No target in arguments\", queryResponse.responseObject);\n+  }\n+\n+  @Test\n+  public void shouldHandleMissingAcksInInserts() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"target\", \"some-stream\");\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/inserts-stream\",\n+        requestBody.toBuffer().appendString(\"\\n\"));\n+\n+    assertEquals(400, response.statusCode());\n+    assertEquals(\"Bad Request\", response.statusMessage());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    validateError(ERROR_CODE_MISSING_PARAM, \"No acks in arguments\",\n+        queryResponse.responseObject);\n+  }\n+\n+  @Test\n+  public void shouldHandleErrorInProcessingInserts() throws Exception {\n+\n+    JsonObject params = new JsonObject().put(\"target\", \"test-stream\").put(\"acks\", true);\n+\n+    List<JsonObject> rows = generateInsertRows();\n+    Buffer requestBody = Buffer.buffer();\n+    requestBody.appendBuffer(params.toBuffer()).appendString(\"\\n\");\n+    for (JsonObject row : rows) {\n+      requestBody.appendBuffer(row.toBuffer()).appendString(\"\\n\");\n+    }\n+\n+    // Inject an error on last row inserted\n+    testEndpoints.setAcksBeforePublisherError(rows.size() - 1);\n+\n+    // The HTTP response will be OK as the error is later in the stream after response\n+    // headers have been written\n+    HttpResponse<Buffer> response = sendRequest(\"/inserts-stream\", requestBody);\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+\n+    String responseBody = response.bodyAsString();\n+    InsertsResponse insertsResponse = new InsertsResponse(responseBody);\n+    assertEquals(rows.size() - 1, insertsResponse.acks.size());\n+    validateError(ERROR_CODE_INTERNAL_ERROR, \"Error in processing inserts\", insertsResponse.error);\n+\n+    assertTrue(testEndpoints.getInsertsSubscriber().isCompleted());\n+  }\n+\n+  private QueryResponse executePushQueryAndWaitForRows(final JsonObject requestBody)\n+      throws Exception {\n+    return executePushQueryAndWaitForRows(client, requestBody);\n+  }\n+\n+  private QueryResponse executePushQueryAndWaitForRows(final WebClient client,\n+      final JsonObject requestBody)\n+      throws Exception {\n+\n+    ReceiveStream writeStream = new ReceiveStream(vertx);\n+\n+    client.post(8089, \"localhost\", \"/query-stream\")\n+        .as(BodyCodec.pipe(writeStream))\n+        .sendJsonObject(requestBody, ar -> {\n+        });\n+\n+    // Wait for all rows to arrive\n+    assertTrue(waitUntil(() -> {\n+      Buffer buff = writeStream.getBody();\n+      try {\n+        QueryResponse queryResponse = new QueryResponse(buff.toString());\n+        return queryResponse.rows.size() == DEFAULT_ROWS.size();\n+      } catch (Throwable t) {\n+        return false;\n+      }\n+    }));\n+\n+    // Note, the response hasn't ended at this point\n+    assertFalse(writeStream.isEnded());\n+\n+    return new QueryResponse(writeStream.getBody().toString());\n+  }\n+\n+  private WebClient createClient() {\n+    WebClientOptions options = new WebClientOptions().setSsl(true).\n+        setUseAlpn(true).\n+        setProtocolVersion(HttpVersion.HTTP_2).\n+        setTrustAll(true);\n+\n+    return WebClient.create(vertx, options);\n+  }\n+\n+  private static void validateError(final int errorCode, final String message,\n+      final JsonObject error) {\n+    assertEquals(\"error\", error.getString(\"status\"));\n+    assertEquals(errorCode, error.getInteger(\"errorCode\").intValue());\n+    assertEquals(message, error.getString(\"message\"));\n+    assertEquals(3, error.size());\n+  }\n+\n+  private void assertAllQueries(final int num, final boolean open) {\n+    assertEquals(num, testEndpoints.getQueryPublishers().size());\n+    for (TestQueryPublisher queryPublisher : testEndpoints.getQueryPublishers()) {\n+      if (open) {\n+        assertTrue(queryPublisher.hasSubscriber());\n+      } else {\n+        assertFalse(queryPublisher.hasSubscriber());\n+      }\n+    }\n+  }\n+\n+  private HttpResponse<Buffer> sendRequest(final String uri, final Buffer requestBody)\n+      throws Exception {\n+    return sendRequest(client, uri, requestBody);\n+  }\n+\n+  private HttpResponse<Buffer> sendRequest(final WebClient client, final String uri,\n+      final Buffer requestBody)\n+      throws Exception {\n+    VertxCompletableFuture<HttpResponse<Buffer>> requestFuture = new VertxCompletableFuture<>();\n+    client\n+        .post(8089, \"localhost\", uri)\n+        .sendBuffer(requestBody, requestFuture);\n+    return requestFuture.get();\n+  }\n+\n+  private void setDefaultRowGenerator() {\n+    testEndpoints.setRowGeneratorFactory(\n+        () -> new ListRowGenerator(DEFAULT_COLUMN_NAMES, DEFAULT_COLUMN_TYPES,\n+            DEFAULT_ROWS));\n+  }\n+\n+  private static boolean waitUntil(final Supplier<Boolean> test) throws Exception {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQyODEzOA=="}, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 631}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODY1ODMwOA==", "bodyText": "Yep, meaning assertThatEventually has richer functionality.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368658308", "createdAt": "2020-01-20T17:19:21Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "diffHunk": "@@ -0,0 +1,885 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import io.confluent.ksql.api.TestQueryPublisher.ListRowGenerator;\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.server.Server;\n+import io.vertx.codegen.annotations.Nullable;\n+import io.vertx.core.AsyncResult;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.http.HttpVersion;\n+import io.vertx.core.json.JsonArray;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.net.PemKeyCertOptions;\n+import io.vertx.core.streams.ReadStream;\n+import io.vertx.core.streams.WriteStream;\n+import io.vertx.ext.web.client.HttpResponse;\n+import io.vertx.ext.web.client.WebClient;\n+import io.vertx.ext.web.client.WebClientOptions;\n+import io.vertx.ext.web.codec.BodyCodec;\n+import java.io.FileNotFoundException;\n+import java.net.URL;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+public class ApiTest {\n+\n+  private static final long WAIT_TIMEOUT = 10000;\n+  private static final JsonArray DEFAULT_COLUMN_NAMES = new JsonArray().add(\"name\").add(\"age\")\n+      .add(\"male\");\n+  private static final JsonArray DEFAULT_COLUMN_TYPES = new JsonArray().add(\"STRING\").add(\"INT\")\n+      .add(\"BOOLEAN\");\n+  private static final List<JsonArray> DEFAULT_ROWS = generateRows();\n+\n+  private Vertx vertx;\n+  private Server server;\n+  private TestEndpoints testEndpoints;\n+  private WebClient client;\n+\n+  @Before\n+  public void setUp() throws Throwable {\n+\n+    vertx = Vertx.vertx();\n+\n+    HttpServerOptions httpServerOptions =\n+        new HttpServerOptions()\n+            .setHost(\"localhost\")\n+            .setPort(8089)\n+            .setUseAlpn(true)\n+            .setSsl(true)\n+            .setPemKeyCertOptions(\n+                new PemKeyCertOptions().setKeyPath(findFilePath(\"test-server-key.pem\"))\n+                    .setCertPath(findFilePath(\"test-server-cert.pem\"))\n+            );\n+\n+    testEndpoints = new TestEndpoints(vertx);\n+    JsonObject config = new JsonObject().put(\"verticle-instances\", 4);\n+    server = new Server(vertx, config, testEndpoints, httpServerOptions);\n+    server.start();\n+    client = createClient();\n+    setDefaultRowGenerator();\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    if (client != null) {\n+      client.close();\n+    }\n+    if (server != null) {\n+      server.stop();\n+    }\n+  }\n+\n+  @Test\n+  public void shouldExecutePullQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", false);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertFalse(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(0, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertFalse(server.getQueryIDs().contains(queryID));\n+    Integer rowCount = queryResponse.responseObject.getInteger(\"rowCount\");\n+    assertNotNull(rowCount);\n+    assertEquals(DEFAULT_ROWS.size(), rowCount.intValue());\n+  }\n+\n+  @Test\n+  public void shouldExecutePushQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertTrue(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(1, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertTrue(server.getQueryIDs().contains(queryID));\n+    assertFalse(queryResponse.responseObject.containsKey(\"rowCount\"));\n+  }\n+\n+  @Test\n+  public void shouldExecuteMultiplePushQueries() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numQueries = 10;\n+    for (int i = 0; i < numQueries; i++) {\n+      QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+      assertEquals(i + 1, server.getQueryIDs().size());\n+      String queryID = queryResponse.responseObject.getString(\"queryID\");\n+      assertNotNull(queryID);\n+      assertTrue(server.getQueryIDs().contains(queryID));\n+    }\n+  }\n+\n+  @Test\n+  public void shouldCloseQueriesOnDifferentConnectionsWhenConnectionsAreClosed() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numQueries = 10;\n+    List<WebClient> clients = new ArrayList<>();\n+    for (int i = 0; i < numQueries; i++) {\n+      // We use different clients to ensure requests are sent on different connections\n+      WebClient client = createClient();\n+      clients.add(client);\n+      QueryResponse queryResponse = executePushQueryAndWaitForRows(client, requestBody);\n+      String queryID = queryResponse.responseObject.getString(\"queryID\");\n+      assertNotNull(queryID);\n+      assertTrue(server.getQueryIDs().contains(queryID));\n+      assertEquals(i + 1, server.getQueryIDs().size());\n+      assertEquals(i + 1, server.queryConnectionCount());\n+    }\n+    assertAllQueries(numQueries, true);\n+\n+    int count = 0;\n+    for (WebClient client : clients) {\n+      client.close();\n+      int num = numQueries - count - 1;\n+      assertTrue(waitUntil(() -> server.queryConnectionCount() == num));\n+      assertEquals(num, server.getQueryIDs().size());\n+      count++;\n+    }\n+    assertAllQueries(numQueries, false);\n+  }\n+\n+  @Test\n+  public void shouldCloseQueriesOnSameConnectionsWhenConnectionsAreClosed() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numQueries = 10;\n+    for (int i = 0; i < numQueries; i++) {\n+      QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+      String queryID = queryResponse.responseObject.getString(\"queryID\");\n+      assertNotNull(queryID);\n+      assertTrue(server.getQueryIDs().contains(queryID));\n+      assertEquals(i + 1, server.getQueryIDs().size());\n+    }\n+    assertEquals(1, server.queryConnectionCount());\n+    assertAllQueries(numQueries, true);\n+\n+    client.close();\n+    assertTrue(waitUntil(() -> server.queryConnectionCount() == 0));\n+    assertTrue(server.getQueryIDs().isEmpty());\n+    client = null;\n+\n+    assertAllQueries(numQueries, false);\n+  }\n+\n+  @Test\n+  public void shouldCloseMultipleQueriesOnDifferentConnectionsWhenConnectionsAreClosed()\n+      throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numConnections = 5;\n+    int numQueries = 5;\n+    List<WebClient> clients = new ArrayList<>();\n+    for (int i = 0; i < numConnections; i++) {\n+      WebClient client = createClient();\n+      clients.add(client);\n+      for (int j = 0; j < numQueries; j++) {\n+        QueryResponse queryResponse = executePushQueryAndWaitForRows(client, requestBody);\n+        String queryID = queryResponse.responseObject.getString(\"queryID\");\n+        assertNotNull(queryID);\n+        assertTrue(server.getQueryIDs().contains(queryID));\n+        int queries = i * numQueries + j + 1;\n+        assertEquals(i * numQueries + j + 1, server.getQueryIDs().size());\n+        assertEquals(i + 1, server.queryConnectionCount());\n+        assertAllQueries(queries, true);\n+      }\n+    }\n+\n+    int count = 0;\n+    for (WebClient client : clients) {\n+      client.close();\n+      int connections = numConnections - count - 1;\n+      assertTrue(waitUntil(() -> server.queryConnectionCount() == connections));\n+      assertEquals(numQueries * connections, server.getQueryIDs().size());\n+      count++;\n+    }\n+\n+    assertAllQueries(numConnections * numQueries, false);\n+  }\n+\n+  @Test\n+  public void shouldHandleQueryWithMissingSql() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"foo\", \"bar\");\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(400, response.statusCode());\n+    assertEquals(\"Bad Request\", response.statusMessage());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    validateError(ERROR_CODE_MISSING_PARAM, \"No sql in arguments\", queryResponse.responseObject);\n+  }\n+\n+  @Test\n+  public void shouldHandleQueryWithMissingPush() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\");\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(400, response.statusCode());\n+    assertEquals(\"Bad Request\", response.statusMessage());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    validateError(ERROR_CODE_MISSING_PARAM, \"No push in arguments\", queryResponse.responseObject);\n+  }\n+\n+  @Test\n+  public void shouldHandleErrorInProcessingQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    testEndpoints.setRowsBeforePublisherError(DEFAULT_ROWS.size() - 1);\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    assertEquals(DEFAULT_ROWS.size() - 1, queryResponse.rows.size());\n+    validateError(ERROR_CODE_INTERNAL_ERROR, \"Error in processing query\", queryResponse.error);\n+\n+    assertEquals(1, testEndpoints.getQueryPublishers().size());\n+    assertFalse(testEndpoints.getQueryPublishers().iterator().next().hasSubscriber());\n+    assertTrue(server.getQueryIDs().isEmpty());\n+  }\n+\n+  @Test\n+  public void shouldCloseQuery() throws Exception {\n+\n+    JsonObject queryRequestBody = new JsonObject().put(\"sql\", \"select * from foo\")\n+        .put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    queryRequestBody.put(\"properties\", properties);\n+\n+    ReceiveStream writeStream = new ReceiveStream(vertx);\n+\n+    client.post(8089, \"localhost\", \"/query-stream\")\n+        .as(BodyCodec.pipe(writeStream))\n+        .sendJsonObject(queryRequestBody, ar -> {\n+        });\n+\n+    // Wait for all rows to arrive\n+    assertTrue(waitUntil(() -> {\n+      Buffer buff = writeStream.getBody();\n+      try {\n+        QueryResponse queryResponse = new QueryResponse(buff.toString());\n+        return queryResponse.rows.size() == DEFAULT_ROWS.size();\n+      } catch (Throwable t) {\n+        return false;\n+      }\n+    }));\n+\n+    assertFalse(writeStream.isEnded());\n+\n+    QueryResponse queryResponse = new QueryResponse(writeStream.getBody().toString());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertTrue(server.getQueryIDs().contains(queryID));\n+    assertEquals(1, server.getQueryIDs().size());\n+    assertEquals(1, testEndpoints.getQueryPublishers().size());\n+\n+    JsonObject closeQueryRequestBody = new JsonObject().put(\"queryID\", queryID);\n+    HttpResponse<Buffer> closeQueryResponse = sendRequest(client, \"/close-query\",\n+        closeQueryRequestBody.toBuffer());\n+    assertEquals(200, closeQueryResponse.statusCode());\n+    assertFalse(server.getQueryIDs().contains(queryID));\n+    assertEquals(0, server.getQueryIDs().size());\n+\n+    // This should trigger the response to end\n+    assertTrue(waitUntil(writeStream::isEnded));\n+\n+    assertEquals(1, testEndpoints.getQueryPublishers().size());\n+    assertFalse(testEndpoints.getQueryPublishers().iterator().next().hasSubscriber());\n+  }\n+\n+  @Test\n+  public void shouldHandleMissingQueryIDInCloseQuery() throws Exception {\n+\n+    JsonObject closeQueryRequestBody = new JsonObject().put(\"foo\", \"bar\");\n+    HttpResponse<Buffer> response = sendRequest(client, \"/close-query\",\n+        closeQueryRequestBody.toBuffer());\n+\n+    assertEquals(400, response.statusCode());\n+    assertEquals(\"Bad Request\", response.statusMessage());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    validateError(ERROR_CODE_MISSING_PARAM, \"No queryID in arguments\",\n+        queryResponse.responseObject);\n+  }\n+\n+  @Test\n+  public void shouldHandleUnknownQueryIDInCloseQuery() throws Exception {\n+\n+    JsonObject closeQueryRequestBody = new JsonObject().put(\"queryID\", \"xyzfasgf\");\n+    HttpResponse<Buffer> response = sendRequest(client, \"/close-query\",\n+        closeQueryRequestBody.toBuffer());\n+\n+    assertEquals(400, response.statusCode());\n+    assertEquals(\"Bad Request\", response.statusMessage());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    validateError(ERROR_CODE_UNKNOWN_QUERY_ID, \"No query with id xyzfasgf\",\n+        queryResponse.responseObject);\n+  }\n+\n+  @Test\n+  public void shouldInsertWithNoAcksStream() throws Exception {\n+\n+    JsonObject params = new JsonObject().put(\"target\", \"test-stream\").put(\"acks\", false);\n+\n+    List<JsonObject> rows = generateInsertRows();\n+    Buffer requestBody = Buffer.buffer();\n+    requestBody.appendBuffer(params.toBuffer()).appendString(\"\\n\");\n+    for (JsonObject row : rows) {\n+      requestBody.appendBuffer(row.toBuffer()).appendString(\"\\n\");\n+    }\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/inserts-stream\", requestBody);\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+\n+    assertEquals(rows, testEndpoints.getInsertsSubscriber().getRowsInserted());\n+    assertTrue(testEndpoints.getInsertsSubscriber().isCompleted());\n+    assertEquals(\"test-stream\", testEndpoints.getLastTarget());\n+  }\n+\n+  @Test\n+  public void shouldInsertWithAcksStream() throws Exception {\n+\n+    JsonObject params = new JsonObject().put(\"target\", \"test-stream\").put(\"acks\", true);\n+\n+    List<JsonObject> rows = generateInsertRows();\n+    Buffer requestBody = Buffer.buffer();\n+    requestBody.appendBuffer(params.toBuffer()).appendString(\"\\n\");\n+    for (JsonObject row : rows) {\n+      requestBody.appendBuffer(row.toBuffer()).appendString(\"\\n\");\n+    }\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/inserts-stream\", requestBody);\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+\n+    String responseBody = response.bodyAsString();\n+    InsertsResponse insertsResponse = new InsertsResponse(responseBody);\n+    assertEquals(rows.size(), insertsResponse.acks.size());\n+\n+    assertEquals(rows, testEndpoints.getInsertsSubscriber().getRowsInserted());\n+    assertTrue(testEndpoints.getInsertsSubscriber().isCompleted());\n+    assertEquals(\"test-stream\", testEndpoints.getLastTarget());\n+  }\n+\n+  @Test\n+  public void shouldStreamInserts() throws Exception {\n+\n+    JsonObject params = new JsonObject().put(\"target\", \"test-stream\").put(\"acks\", true);\n+\n+    SendStream readStream = new SendStream(vertx);\n+    ReceiveStream writeStream = new ReceiveStream(vertx);\n+    VertxCompletableFuture<HttpResponse<Void>> fut = new VertxCompletableFuture<>();\n+    List<JsonObject> rows = generateInsertRows();\n+\n+    client.post(8089, \"localhost\", \"/inserts-stream\")\n+        .as(BodyCodec.pipe(writeStream))\n+        .sendStream(readStream, fut);\n+\n+    readStream.acceptBuffer(params.toBuffer().appendString(\"\\n\"));\n+\n+    AtomicInteger rowIndex = new AtomicInteger();\n+    vertx.setPeriodic(100, tid -> {\n+      readStream.acceptBuffer(rows.get(rowIndex.getAndIncrement()).toBuffer().appendString(\"\\n\"));\n+      if (rowIndex.get() == rows.size()) {\n+        vertx.cancelTimer(tid);\n+        readStream.end();\n+      }\n+    });\n+\n+    HttpResponse<Void> response = fut.get();\n+\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+\n+    InsertsResponse insertsResponse = new InsertsResponse(writeStream.getBody().toString());\n+    assertEquals(rows.size(), insertsResponse.acks.size());\n+    assertEquals(rows, testEndpoints.getInsertsSubscriber().getRowsInserted());\n+    assertTrue(testEndpoints.getInsertsSubscriber().isCompleted());\n+    // When response is complete the acks subscriber should be unsubscribed\n+    assertFalse(testEndpoints.getAcksPublisher().hasSubscriber());\n+\n+    // Ensure we received at last some of the response before all the request body was written\n+    // Yay HTTP2!\n+    assertTrue(readStream.getLastSentTime() > writeStream.getFirstReceivedTime());\n+  }\n+\n+  @Test\n+  public void shouldHandleMissingTargetInInserts() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"acks\", true);\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/inserts-stream\",\n+        requestBody.toBuffer().appendString(\"\\n\"));\n+\n+    assertEquals(400, response.statusCode());\n+    assertEquals(\"Bad Request\", response.statusMessage());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    validateError(ERROR_CODE_MISSING_PARAM, \"No target in arguments\", queryResponse.responseObject);\n+  }\n+\n+  @Test\n+  public void shouldHandleMissingAcksInInserts() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"target\", \"some-stream\");\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/inserts-stream\",\n+        requestBody.toBuffer().appendString(\"\\n\"));\n+\n+    assertEquals(400, response.statusCode());\n+    assertEquals(\"Bad Request\", response.statusMessage());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    validateError(ERROR_CODE_MISSING_PARAM, \"No acks in arguments\",\n+        queryResponse.responseObject);\n+  }\n+\n+  @Test\n+  public void shouldHandleErrorInProcessingInserts() throws Exception {\n+\n+    JsonObject params = new JsonObject().put(\"target\", \"test-stream\").put(\"acks\", true);\n+\n+    List<JsonObject> rows = generateInsertRows();\n+    Buffer requestBody = Buffer.buffer();\n+    requestBody.appendBuffer(params.toBuffer()).appendString(\"\\n\");\n+    for (JsonObject row : rows) {\n+      requestBody.appendBuffer(row.toBuffer()).appendString(\"\\n\");\n+    }\n+\n+    // Inject an error on last row inserted\n+    testEndpoints.setAcksBeforePublisherError(rows.size() - 1);\n+\n+    // The HTTP response will be OK as the error is later in the stream after response\n+    // headers have been written\n+    HttpResponse<Buffer> response = sendRequest(\"/inserts-stream\", requestBody);\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+\n+    String responseBody = response.bodyAsString();\n+    InsertsResponse insertsResponse = new InsertsResponse(responseBody);\n+    assertEquals(rows.size() - 1, insertsResponse.acks.size());\n+    validateError(ERROR_CODE_INTERNAL_ERROR, \"Error in processing inserts\", insertsResponse.error);\n+\n+    assertTrue(testEndpoints.getInsertsSubscriber().isCompleted());\n+  }\n+\n+  private QueryResponse executePushQueryAndWaitForRows(final JsonObject requestBody)\n+      throws Exception {\n+    return executePushQueryAndWaitForRows(client, requestBody);\n+  }\n+\n+  private QueryResponse executePushQueryAndWaitForRows(final WebClient client,\n+      final JsonObject requestBody)\n+      throws Exception {\n+\n+    ReceiveStream writeStream = new ReceiveStream(vertx);\n+\n+    client.post(8089, \"localhost\", \"/query-stream\")\n+        .as(BodyCodec.pipe(writeStream))\n+        .sendJsonObject(requestBody, ar -> {\n+        });\n+\n+    // Wait for all rows to arrive\n+    assertTrue(waitUntil(() -> {\n+      Buffer buff = writeStream.getBody();\n+      try {\n+        QueryResponse queryResponse = new QueryResponse(buff.toString());\n+        return queryResponse.rows.size() == DEFAULT_ROWS.size();\n+      } catch (Throwable t) {\n+        return false;\n+      }\n+    }));\n+\n+    // Note, the response hasn't ended at this point\n+    assertFalse(writeStream.isEnded());\n+\n+    return new QueryResponse(writeStream.getBody().toString());\n+  }\n+\n+  private WebClient createClient() {\n+    WebClientOptions options = new WebClientOptions().setSsl(true).\n+        setUseAlpn(true).\n+        setProtocolVersion(HttpVersion.HTTP_2).\n+        setTrustAll(true);\n+\n+    return WebClient.create(vertx, options);\n+  }\n+\n+  private static void validateError(final int errorCode, final String message,\n+      final JsonObject error) {\n+    assertEquals(\"error\", error.getString(\"status\"));\n+    assertEquals(errorCode, error.getInteger(\"errorCode\").intValue());\n+    assertEquals(message, error.getString(\"message\"));\n+    assertEquals(3, error.size());\n+  }\n+\n+  private void assertAllQueries(final int num, final boolean open) {\n+    assertEquals(num, testEndpoints.getQueryPublishers().size());\n+    for (TestQueryPublisher queryPublisher : testEndpoints.getQueryPublishers()) {\n+      if (open) {\n+        assertTrue(queryPublisher.hasSubscriber());\n+      } else {\n+        assertFalse(queryPublisher.hasSubscriber());\n+      }\n+    }\n+  }\n+\n+  private HttpResponse<Buffer> sendRequest(final String uri, final Buffer requestBody)\n+      throws Exception {\n+    return sendRequest(client, uri, requestBody);\n+  }\n+\n+  private HttpResponse<Buffer> sendRequest(final WebClient client, final String uri,\n+      final Buffer requestBody)\n+      throws Exception {\n+    VertxCompletableFuture<HttpResponse<Buffer>> requestFuture = new VertxCompletableFuture<>();\n+    client\n+        .post(8089, \"localhost\", uri)\n+        .sendBuffer(requestBody, requestFuture);\n+    return requestFuture.get();\n+  }\n+\n+  private void setDefaultRowGenerator() {\n+    testEndpoints.setRowGeneratorFactory(\n+        () -> new ListRowGenerator(DEFAULT_COLUMN_NAMES, DEFAULT_COLUMN_TYPES,\n+            DEFAULT_ROWS));\n+  }\n+\n+  private static boolean waitUntil(final Supplier<Boolean> test) throws Exception {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQyODEzOA=="}, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 631}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MDI3MTU2OnYy", "diffSide": "RIGHT", "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzo1NDo0NFrOFeaE8w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQyMDozNToxMlrOFemvLg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQyODg1MQ==", "bodyText": "It's hard to tell what is going on in this test TBH.  You may understand it, but someone else may struggle if this starts failing when they change something.\nIMHO it would benefit from being refactored into methods with more descriptive names, using Given/When/Then to make it clear which is the actual bit under test, and avoid testing the same things in many tests e.g.\n@Test\npublic void shouldCloseQuery() throws Exception {\n   // Given:\n   QueryResponse queryResponse = executePushQueryAndWaitForRows(queryRequestBody);\n   String queryID = queryResponse.responseObject.getString(\"queryID\");\n\n    // When:\n    HttpResponse<Buffer> closeQueryResponse = sendRequest(closeRequest(queryId)));\n  \n    // Then:\n    assertThat(closeQueryResponse.statusCode(), is(200));\n    assertThat(server.getQueryIDs(), not(hasItem(queryID)));\n\n    // This should trigger the response to end\n    assertThatEventually(writeStream::isEnded, is(true)));\n\n    assertThat(testEndpoints.getQueryPublishers(), hasSize(1));\n    assertThat(testEndpoints.getQueryPublishers().iterator().next().hasSubscriber(), is(true));\n}\nNote, I excluded some lines from the test, as they are tested elsewhere:\n    assertTrue(server.getQueryIDs().contains(queryID));\n    assertEquals(1, server.getQueryIDs().size());\n    assertEquals(1, testEndpoints.getQueryPublishers().size());\n\n    assertEquals(0, server.getQueryIDs().size()); \n\nTBH, there's also a some code duplication in this test file. For example:\n\nmany tests create the same queryRequestBody.  Maybe this could just be in a constant?\nmany tests create new SendStream(vertx) or new ReceiveStream(vertx). Maybe these could be created in setUp method and stored in fields?\n\nRefactoring in this way removes the noise from test cases, making them much easier for the next person to understand.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367428851", "createdAt": "2020-01-16T13:54:44Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "diffHunk": "@@ -0,0 +1,885 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import io.confluent.ksql.api.TestQueryPublisher.ListRowGenerator;\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.server.Server;\n+import io.vertx.codegen.annotations.Nullable;\n+import io.vertx.core.AsyncResult;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.http.HttpVersion;\n+import io.vertx.core.json.JsonArray;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.net.PemKeyCertOptions;\n+import io.vertx.core.streams.ReadStream;\n+import io.vertx.core.streams.WriteStream;\n+import io.vertx.ext.web.client.HttpResponse;\n+import io.vertx.ext.web.client.WebClient;\n+import io.vertx.ext.web.client.WebClientOptions;\n+import io.vertx.ext.web.codec.BodyCodec;\n+import java.io.FileNotFoundException;\n+import java.net.URL;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+public class ApiTest {\n+\n+  private static final long WAIT_TIMEOUT = 10000;\n+  private static final JsonArray DEFAULT_COLUMN_NAMES = new JsonArray().add(\"name\").add(\"age\")\n+      .add(\"male\");\n+  private static final JsonArray DEFAULT_COLUMN_TYPES = new JsonArray().add(\"STRING\").add(\"INT\")\n+      .add(\"BOOLEAN\");\n+  private static final List<JsonArray> DEFAULT_ROWS = generateRows();\n+\n+  private Vertx vertx;\n+  private Server server;\n+  private TestEndpoints testEndpoints;\n+  private WebClient client;\n+\n+  @Before\n+  public void setUp() throws Throwable {\n+\n+    vertx = Vertx.vertx();\n+\n+    HttpServerOptions httpServerOptions =\n+        new HttpServerOptions()\n+            .setHost(\"localhost\")\n+            .setPort(8089)\n+            .setUseAlpn(true)\n+            .setSsl(true)\n+            .setPemKeyCertOptions(\n+                new PemKeyCertOptions().setKeyPath(findFilePath(\"test-server-key.pem\"))\n+                    .setCertPath(findFilePath(\"test-server-cert.pem\"))\n+            );\n+\n+    testEndpoints = new TestEndpoints(vertx);\n+    JsonObject config = new JsonObject().put(\"verticle-instances\", 4);\n+    server = new Server(vertx, config, testEndpoints, httpServerOptions);\n+    server.start();\n+    client = createClient();\n+    setDefaultRowGenerator();\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    if (client != null) {\n+      client.close();\n+    }\n+    if (server != null) {\n+      server.stop();\n+    }\n+  }\n+\n+  @Test\n+  public void shouldExecutePullQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", false);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertFalse(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(0, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertFalse(server.getQueryIDs().contains(queryID));\n+    Integer rowCount = queryResponse.responseObject.getInteger(\"rowCount\");\n+    assertNotNull(rowCount);\n+    assertEquals(DEFAULT_ROWS.size(), rowCount.intValue());\n+  }\n+\n+  @Test\n+  public void shouldExecutePushQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertTrue(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(1, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertTrue(server.getQueryIDs().contains(queryID));\n+    assertFalse(queryResponse.responseObject.containsKey(\"rowCount\"));\n+  }\n+\n+  @Test\n+  public void shouldExecuteMultiplePushQueries() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numQueries = 10;\n+    for (int i = 0; i < numQueries; i++) {\n+      QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+      assertEquals(i + 1, server.getQueryIDs().size());\n+      String queryID = queryResponse.responseObject.getString(\"queryID\");\n+      assertNotNull(queryID);\n+      assertTrue(server.getQueryIDs().contains(queryID));\n+    }\n+  }\n+\n+  @Test\n+  public void shouldCloseQueriesOnDifferentConnectionsWhenConnectionsAreClosed() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numQueries = 10;\n+    List<WebClient> clients = new ArrayList<>();\n+    for (int i = 0; i < numQueries; i++) {\n+      // We use different clients to ensure requests are sent on different connections\n+      WebClient client = createClient();\n+      clients.add(client);\n+      QueryResponse queryResponse = executePushQueryAndWaitForRows(client, requestBody);\n+      String queryID = queryResponse.responseObject.getString(\"queryID\");\n+      assertNotNull(queryID);\n+      assertTrue(server.getQueryIDs().contains(queryID));\n+      assertEquals(i + 1, server.getQueryIDs().size());\n+      assertEquals(i + 1, server.queryConnectionCount());\n+    }\n+    assertAllQueries(numQueries, true);\n+\n+    int count = 0;\n+    for (WebClient client : clients) {\n+      client.close();\n+      int num = numQueries - count - 1;\n+      assertTrue(waitUntil(() -> server.queryConnectionCount() == num));\n+      assertEquals(num, server.getQueryIDs().size());\n+      count++;\n+    }\n+    assertAllQueries(numQueries, false);\n+  }\n+\n+  @Test\n+  public void shouldCloseQueriesOnSameConnectionsWhenConnectionsAreClosed() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numQueries = 10;\n+    for (int i = 0; i < numQueries; i++) {\n+      QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+      String queryID = queryResponse.responseObject.getString(\"queryID\");\n+      assertNotNull(queryID);\n+      assertTrue(server.getQueryIDs().contains(queryID));\n+      assertEquals(i + 1, server.getQueryIDs().size());\n+    }\n+    assertEquals(1, server.queryConnectionCount());\n+    assertAllQueries(numQueries, true);\n+\n+    client.close();\n+    assertTrue(waitUntil(() -> server.queryConnectionCount() == 0));\n+    assertTrue(server.getQueryIDs().isEmpty());\n+    client = null;\n+\n+    assertAllQueries(numQueries, false);\n+  }\n+\n+  @Test\n+  public void shouldCloseMultipleQueriesOnDifferentConnectionsWhenConnectionsAreClosed()\n+      throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numConnections = 5;\n+    int numQueries = 5;\n+    List<WebClient> clients = new ArrayList<>();\n+    for (int i = 0; i < numConnections; i++) {\n+      WebClient client = createClient();\n+      clients.add(client);\n+      for (int j = 0; j < numQueries; j++) {\n+        QueryResponse queryResponse = executePushQueryAndWaitForRows(client, requestBody);\n+        String queryID = queryResponse.responseObject.getString(\"queryID\");\n+        assertNotNull(queryID);\n+        assertTrue(server.getQueryIDs().contains(queryID));\n+        int queries = i * numQueries + j + 1;\n+        assertEquals(i * numQueries + j + 1, server.getQueryIDs().size());\n+        assertEquals(i + 1, server.queryConnectionCount());\n+        assertAllQueries(queries, true);\n+      }\n+    }\n+\n+    int count = 0;\n+    for (WebClient client : clients) {\n+      client.close();\n+      int connections = numConnections - count - 1;\n+      assertTrue(waitUntil(() -> server.queryConnectionCount() == connections));\n+      assertEquals(numQueries * connections, server.getQueryIDs().size());\n+      count++;\n+    }\n+\n+    assertAllQueries(numConnections * numQueries, false);\n+  }\n+\n+  @Test\n+  public void shouldHandleQueryWithMissingSql() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"foo\", \"bar\");\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(400, response.statusCode());\n+    assertEquals(\"Bad Request\", response.statusMessage());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    validateError(ERROR_CODE_MISSING_PARAM, \"No sql in arguments\", queryResponse.responseObject);\n+  }\n+\n+  @Test\n+  public void shouldHandleQueryWithMissingPush() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\");\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(400, response.statusCode());\n+    assertEquals(\"Bad Request\", response.statusMessage());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    validateError(ERROR_CODE_MISSING_PARAM, \"No push in arguments\", queryResponse.responseObject);\n+  }\n+\n+  @Test\n+  public void shouldHandleErrorInProcessingQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    testEndpoints.setRowsBeforePublisherError(DEFAULT_ROWS.size() - 1);\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    assertEquals(DEFAULT_ROWS.size() - 1, queryResponse.rows.size());\n+    validateError(ERROR_CODE_INTERNAL_ERROR, \"Error in processing query\", queryResponse.error);\n+\n+    assertEquals(1, testEndpoints.getQueryPublishers().size());\n+    assertFalse(testEndpoints.getQueryPublishers().iterator().next().hasSubscriber());\n+    assertTrue(server.getQueryIDs().isEmpty());\n+  }\n+\n+  @Test\n+  public void shouldCloseQuery() throws Exception {\n+\n+    JsonObject queryRequestBody = new JsonObject().put(\"sql\", \"select * from foo\")\n+        .put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    queryRequestBody.put(\"properties\", properties);\n+\n+    ReceiveStream writeStream = new ReceiveStream(vertx);\n+\n+    client.post(8089, \"localhost\", \"/query-stream\")\n+        .as(BodyCodec.pipe(writeStream))\n+        .sendJsonObject(queryRequestBody, ar -> {\n+        });\n+\n+    // Wait for all rows to arrive\n+    assertTrue(waitUntil(() -> {\n+      Buffer buff = writeStream.getBody();\n+      try {\n+        QueryResponse queryResponse = new QueryResponse(buff.toString());\n+        return queryResponse.rows.size() == DEFAULT_ROWS.size();\n+      } catch (Throwable t) {\n+        return false;\n+      }\n+    }));\n+\n+    assertFalse(writeStream.isEnded());\n+\n+    QueryResponse queryResponse = new QueryResponse(writeStream.getBody().toString());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertTrue(server.getQueryIDs().contains(queryID));\n+    assertEquals(1, server.getQueryIDs().size());\n+    assertEquals(1, testEndpoints.getQueryPublishers().size());\n+\n+    JsonObject closeQueryRequestBody = new JsonObject().put(\"queryID\", queryID);\n+    HttpResponse<Buffer> closeQueryResponse = sendRequest(client, \"/close-query\",\n+        closeQueryRequestBody.toBuffer());\n+    assertEquals(200, closeQueryResponse.statusCode());\n+    assertFalse(server.getQueryIDs().contains(queryID));\n+    assertEquals(0, server.getQueryIDs().size());\n+\n+    // This should trigger the response to end\n+    assertTrue(waitUntil(writeStream::isEnded));\n+\n+    assertEquals(1, testEndpoints.getQueryPublishers().size());\n+    assertFalse(testEndpoints.getQueryPublishers().iterator().next().hasSubscriber());\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 369}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzYzNjI3MA==", "bodyText": "I've added a bunch more comments to it to make it clearer what it does.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367636270", "createdAt": "2020-01-16T20:35:12Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "diffHunk": "@@ -0,0 +1,885 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import io.confluent.ksql.api.TestQueryPublisher.ListRowGenerator;\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.server.Server;\n+import io.vertx.codegen.annotations.Nullable;\n+import io.vertx.core.AsyncResult;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.http.HttpVersion;\n+import io.vertx.core.json.JsonArray;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.net.PemKeyCertOptions;\n+import io.vertx.core.streams.ReadStream;\n+import io.vertx.core.streams.WriteStream;\n+import io.vertx.ext.web.client.HttpResponse;\n+import io.vertx.ext.web.client.WebClient;\n+import io.vertx.ext.web.client.WebClientOptions;\n+import io.vertx.ext.web.codec.BodyCodec;\n+import java.io.FileNotFoundException;\n+import java.net.URL;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+public class ApiTest {\n+\n+  private static final long WAIT_TIMEOUT = 10000;\n+  private static final JsonArray DEFAULT_COLUMN_NAMES = new JsonArray().add(\"name\").add(\"age\")\n+      .add(\"male\");\n+  private static final JsonArray DEFAULT_COLUMN_TYPES = new JsonArray().add(\"STRING\").add(\"INT\")\n+      .add(\"BOOLEAN\");\n+  private static final List<JsonArray> DEFAULT_ROWS = generateRows();\n+\n+  private Vertx vertx;\n+  private Server server;\n+  private TestEndpoints testEndpoints;\n+  private WebClient client;\n+\n+  @Before\n+  public void setUp() throws Throwable {\n+\n+    vertx = Vertx.vertx();\n+\n+    HttpServerOptions httpServerOptions =\n+        new HttpServerOptions()\n+            .setHost(\"localhost\")\n+            .setPort(8089)\n+            .setUseAlpn(true)\n+            .setSsl(true)\n+            .setPemKeyCertOptions(\n+                new PemKeyCertOptions().setKeyPath(findFilePath(\"test-server-key.pem\"))\n+                    .setCertPath(findFilePath(\"test-server-cert.pem\"))\n+            );\n+\n+    testEndpoints = new TestEndpoints(vertx);\n+    JsonObject config = new JsonObject().put(\"verticle-instances\", 4);\n+    server = new Server(vertx, config, testEndpoints, httpServerOptions);\n+    server.start();\n+    client = createClient();\n+    setDefaultRowGenerator();\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    if (client != null) {\n+      client.close();\n+    }\n+    if (server != null) {\n+      server.stop();\n+    }\n+  }\n+\n+  @Test\n+  public void shouldExecutePullQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", false);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertFalse(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(0, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertFalse(server.getQueryIDs().contains(queryID));\n+    Integer rowCount = queryResponse.responseObject.getInteger(\"rowCount\");\n+    assertNotNull(rowCount);\n+    assertEquals(DEFAULT_ROWS.size(), rowCount.intValue());\n+  }\n+\n+  @Test\n+  public void shouldExecutePushQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertTrue(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(1, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertTrue(server.getQueryIDs().contains(queryID));\n+    assertFalse(queryResponse.responseObject.containsKey(\"rowCount\"));\n+  }\n+\n+  @Test\n+  public void shouldExecuteMultiplePushQueries() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numQueries = 10;\n+    for (int i = 0; i < numQueries; i++) {\n+      QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+      assertEquals(i + 1, server.getQueryIDs().size());\n+      String queryID = queryResponse.responseObject.getString(\"queryID\");\n+      assertNotNull(queryID);\n+      assertTrue(server.getQueryIDs().contains(queryID));\n+    }\n+  }\n+\n+  @Test\n+  public void shouldCloseQueriesOnDifferentConnectionsWhenConnectionsAreClosed() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numQueries = 10;\n+    List<WebClient> clients = new ArrayList<>();\n+    for (int i = 0; i < numQueries; i++) {\n+      // We use different clients to ensure requests are sent on different connections\n+      WebClient client = createClient();\n+      clients.add(client);\n+      QueryResponse queryResponse = executePushQueryAndWaitForRows(client, requestBody);\n+      String queryID = queryResponse.responseObject.getString(\"queryID\");\n+      assertNotNull(queryID);\n+      assertTrue(server.getQueryIDs().contains(queryID));\n+      assertEquals(i + 1, server.getQueryIDs().size());\n+      assertEquals(i + 1, server.queryConnectionCount());\n+    }\n+    assertAllQueries(numQueries, true);\n+\n+    int count = 0;\n+    for (WebClient client : clients) {\n+      client.close();\n+      int num = numQueries - count - 1;\n+      assertTrue(waitUntil(() -> server.queryConnectionCount() == num));\n+      assertEquals(num, server.getQueryIDs().size());\n+      count++;\n+    }\n+    assertAllQueries(numQueries, false);\n+  }\n+\n+  @Test\n+  public void shouldCloseQueriesOnSameConnectionsWhenConnectionsAreClosed() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numQueries = 10;\n+    for (int i = 0; i < numQueries; i++) {\n+      QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+      String queryID = queryResponse.responseObject.getString(\"queryID\");\n+      assertNotNull(queryID);\n+      assertTrue(server.getQueryIDs().contains(queryID));\n+      assertEquals(i + 1, server.getQueryIDs().size());\n+    }\n+    assertEquals(1, server.queryConnectionCount());\n+    assertAllQueries(numQueries, true);\n+\n+    client.close();\n+    assertTrue(waitUntil(() -> server.queryConnectionCount() == 0));\n+    assertTrue(server.getQueryIDs().isEmpty());\n+    client = null;\n+\n+    assertAllQueries(numQueries, false);\n+  }\n+\n+  @Test\n+  public void shouldCloseMultipleQueriesOnDifferentConnectionsWhenConnectionsAreClosed()\n+      throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numConnections = 5;\n+    int numQueries = 5;\n+    List<WebClient> clients = new ArrayList<>();\n+    for (int i = 0; i < numConnections; i++) {\n+      WebClient client = createClient();\n+      clients.add(client);\n+      for (int j = 0; j < numQueries; j++) {\n+        QueryResponse queryResponse = executePushQueryAndWaitForRows(client, requestBody);\n+        String queryID = queryResponse.responseObject.getString(\"queryID\");\n+        assertNotNull(queryID);\n+        assertTrue(server.getQueryIDs().contains(queryID));\n+        int queries = i * numQueries + j + 1;\n+        assertEquals(i * numQueries + j + 1, server.getQueryIDs().size());\n+        assertEquals(i + 1, server.queryConnectionCount());\n+        assertAllQueries(queries, true);\n+      }\n+    }\n+\n+    int count = 0;\n+    for (WebClient client : clients) {\n+      client.close();\n+      int connections = numConnections - count - 1;\n+      assertTrue(waitUntil(() -> server.queryConnectionCount() == connections));\n+      assertEquals(numQueries * connections, server.getQueryIDs().size());\n+      count++;\n+    }\n+\n+    assertAllQueries(numConnections * numQueries, false);\n+  }\n+\n+  @Test\n+  public void shouldHandleQueryWithMissingSql() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"foo\", \"bar\");\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(400, response.statusCode());\n+    assertEquals(\"Bad Request\", response.statusMessage());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    validateError(ERROR_CODE_MISSING_PARAM, \"No sql in arguments\", queryResponse.responseObject);\n+  }\n+\n+  @Test\n+  public void shouldHandleQueryWithMissingPush() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\");\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(400, response.statusCode());\n+    assertEquals(\"Bad Request\", response.statusMessage());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    validateError(ERROR_CODE_MISSING_PARAM, \"No push in arguments\", queryResponse.responseObject);\n+  }\n+\n+  @Test\n+  public void shouldHandleErrorInProcessingQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    testEndpoints.setRowsBeforePublisherError(DEFAULT_ROWS.size() - 1);\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    assertEquals(DEFAULT_ROWS.size() - 1, queryResponse.rows.size());\n+    validateError(ERROR_CODE_INTERNAL_ERROR, \"Error in processing query\", queryResponse.error);\n+\n+    assertEquals(1, testEndpoints.getQueryPublishers().size());\n+    assertFalse(testEndpoints.getQueryPublishers().iterator().next().hasSubscriber());\n+    assertTrue(server.getQueryIDs().isEmpty());\n+  }\n+\n+  @Test\n+  public void shouldCloseQuery() throws Exception {\n+\n+    JsonObject queryRequestBody = new JsonObject().put(\"sql\", \"select * from foo\")\n+        .put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    queryRequestBody.put(\"properties\", properties);\n+\n+    ReceiveStream writeStream = new ReceiveStream(vertx);\n+\n+    client.post(8089, \"localhost\", \"/query-stream\")\n+        .as(BodyCodec.pipe(writeStream))\n+        .sendJsonObject(queryRequestBody, ar -> {\n+        });\n+\n+    // Wait for all rows to arrive\n+    assertTrue(waitUntil(() -> {\n+      Buffer buff = writeStream.getBody();\n+      try {\n+        QueryResponse queryResponse = new QueryResponse(buff.toString());\n+        return queryResponse.rows.size() == DEFAULT_ROWS.size();\n+      } catch (Throwable t) {\n+        return false;\n+      }\n+    }));\n+\n+    assertFalse(writeStream.isEnded());\n+\n+    QueryResponse queryResponse = new QueryResponse(writeStream.getBody().toString());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertTrue(server.getQueryIDs().contains(queryID));\n+    assertEquals(1, server.getQueryIDs().size());\n+    assertEquals(1, testEndpoints.getQueryPublishers().size());\n+\n+    JsonObject closeQueryRequestBody = new JsonObject().put(\"queryID\", queryID);\n+    HttpResponse<Buffer> closeQueryResponse = sendRequest(client, \"/close-query\",\n+        closeQueryRequestBody.toBuffer());\n+    assertEquals(200, closeQueryResponse.statusCode());\n+    assertFalse(server.getQueryIDs().contains(queryID));\n+    assertEquals(0, server.getQueryIDs().size());\n+\n+    // This should trigger the response to end\n+    assertTrue(waitUntil(writeStream::isEnded));\n+\n+    assertEquals(1, testEndpoints.getQueryPublishers().size());\n+    assertFalse(testEndpoints.getQueryPublishers().iterator().next().hasSubscriber());\n+  }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQyODg1MQ=="}, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 369}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MDI3OTYyOnYy", "diffSide": "RIGHT", "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzo1NzowM1rOFeaJ3g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxNjoyOTo1MVrOFefqsA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQzMDExMA==", "bodyText": "Not sure, but maybe ServerKeyStore or ClientTrustStore or similar can help simplify the test here?", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367430110", "createdAt": "2020-01-16T13:57:03Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "diffHunk": "@@ -0,0 +1,885 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import io.confluent.ksql.api.TestQueryPublisher.ListRowGenerator;\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.server.Server;\n+import io.vertx.codegen.annotations.Nullable;\n+import io.vertx.core.AsyncResult;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.http.HttpVersion;\n+import io.vertx.core.json.JsonArray;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.net.PemKeyCertOptions;\n+import io.vertx.core.streams.ReadStream;\n+import io.vertx.core.streams.WriteStream;\n+import io.vertx.ext.web.client.HttpResponse;\n+import io.vertx.ext.web.client.WebClient;\n+import io.vertx.ext.web.client.WebClientOptions;\n+import io.vertx.ext.web.codec.BodyCodec;\n+import java.io.FileNotFoundException;\n+import java.net.URL;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+public class ApiTest {\n+\n+  private static final long WAIT_TIMEOUT = 10000;\n+  private static final JsonArray DEFAULT_COLUMN_NAMES = new JsonArray().add(\"name\").add(\"age\")\n+      .add(\"male\");\n+  private static final JsonArray DEFAULT_COLUMN_TYPES = new JsonArray().add(\"STRING\").add(\"INT\")\n+      .add(\"BOOLEAN\");\n+  private static final List<JsonArray> DEFAULT_ROWS = generateRows();\n+\n+  private Vertx vertx;\n+  private Server server;\n+  private TestEndpoints testEndpoints;\n+  private WebClient client;\n+\n+  @Before\n+  public void setUp() throws Throwable {\n+\n+    vertx = Vertx.vertx();\n+\n+    HttpServerOptions httpServerOptions =\n+        new HttpServerOptions()\n+            .setHost(\"localhost\")\n+            .setPort(8089)\n+            .setUseAlpn(true)\n+            .setSsl(true)\n+            .setPemKeyCertOptions(\n+                new PemKeyCertOptions().setKeyPath(findFilePath(\"test-server-key.pem\"))\n+                    .setCertPath(findFilePath(\"test-server-cert.pem\"))\n+            );", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzUxNzM5NQ==", "bodyText": "Do you know what kind of key store ServerKeyStore contains? Is it JKS? I had an initial attempt to get it to work with Vert.x, but it didn't like it.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367517395", "createdAt": "2020-01-16T16:24:56Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "diffHunk": "@@ -0,0 +1,885 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import io.confluent.ksql.api.TestQueryPublisher.ListRowGenerator;\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.server.Server;\n+import io.vertx.codegen.annotations.Nullable;\n+import io.vertx.core.AsyncResult;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.http.HttpVersion;\n+import io.vertx.core.json.JsonArray;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.net.PemKeyCertOptions;\n+import io.vertx.core.streams.ReadStream;\n+import io.vertx.core.streams.WriteStream;\n+import io.vertx.ext.web.client.HttpResponse;\n+import io.vertx.ext.web.client.WebClient;\n+import io.vertx.ext.web.client.WebClientOptions;\n+import io.vertx.ext.web.codec.BodyCodec;\n+import java.io.FileNotFoundException;\n+import java.net.URL;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+public class ApiTest {\n+\n+  private static final long WAIT_TIMEOUT = 10000;\n+  private static final JsonArray DEFAULT_COLUMN_NAMES = new JsonArray().add(\"name\").add(\"age\")\n+      .add(\"male\");\n+  private static final JsonArray DEFAULT_COLUMN_TYPES = new JsonArray().add(\"STRING\").add(\"INT\")\n+      .add(\"BOOLEAN\");\n+  private static final List<JsonArray> DEFAULT_ROWS = generateRows();\n+\n+  private Vertx vertx;\n+  private Server server;\n+  private TestEndpoints testEndpoints;\n+  private WebClient client;\n+\n+  @Before\n+  public void setUp() throws Throwable {\n+\n+    vertx = Vertx.vertx();\n+\n+    HttpServerOptions httpServerOptions =\n+        new HttpServerOptions()\n+            .setHost(\"localhost\")\n+            .setPort(8089)\n+            .setUseAlpn(true)\n+            .setSsl(true)\n+            .setPemKeyCertOptions(\n+                new PemKeyCertOptions().setKeyPath(findFilePath(\"test-server-key.pem\"))\n+                    .setCertPath(findFilePath(\"test-server-cert.pem\"))\n+            );", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQzMDExMA=="}, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzUyMDQzMg==", "bodyText": "One thing with Vert.x - you can also provide the keystore/truststore as a buffer, so no need to save it to a temporary file and load it from there. Once we get to the point of removing Jetty we can simplify the ServerKeyStore class to be fully in memory.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367520432", "createdAt": "2020-01-16T16:29:51Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "diffHunk": "@@ -0,0 +1,885 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import io.confluent.ksql.api.TestQueryPublisher.ListRowGenerator;\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.server.Server;\n+import io.vertx.codegen.annotations.Nullable;\n+import io.vertx.core.AsyncResult;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.http.HttpVersion;\n+import io.vertx.core.json.JsonArray;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.net.PemKeyCertOptions;\n+import io.vertx.core.streams.ReadStream;\n+import io.vertx.core.streams.WriteStream;\n+import io.vertx.ext.web.client.HttpResponse;\n+import io.vertx.ext.web.client.WebClient;\n+import io.vertx.ext.web.client.WebClientOptions;\n+import io.vertx.ext.web.codec.BodyCodec;\n+import java.io.FileNotFoundException;\n+import java.net.URL;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+public class ApiTest {\n+\n+  private static final long WAIT_TIMEOUT = 10000;\n+  private static final JsonArray DEFAULT_COLUMN_NAMES = new JsonArray().add(\"name\").add(\"age\")\n+      .add(\"male\");\n+  private static final JsonArray DEFAULT_COLUMN_TYPES = new JsonArray().add(\"STRING\").add(\"INT\")\n+      .add(\"BOOLEAN\");\n+  private static final List<JsonArray> DEFAULT_ROWS = generateRows();\n+\n+  private Vertx vertx;\n+  private Server server;\n+  private TestEndpoints testEndpoints;\n+  private WebClient client;\n+\n+  @Before\n+  public void setUp() throws Throwable {\n+\n+    vertx = Vertx.vertx();\n+\n+    HttpServerOptions httpServerOptions =\n+        new HttpServerOptions()\n+            .setHost(\"localhost\")\n+            .setPort(8089)\n+            .setUseAlpn(true)\n+            .setSsl(true)\n+            .setPemKeyCertOptions(\n+                new PemKeyCertOptions().setKeyPath(findFilePath(\"test-server-key.pem\"))\n+                    .setCertPath(findFilePath(\"test-server-cert.pem\"))\n+            );", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQzMDExMA=="}, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 87}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NDMwNzc2OnYy", "diffSide": "RIGHT", "path": "ksql-api/pom.xml", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QxODowMDo1NFrOFfA1ew==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQwOTo0MTo1NlrOFgVxug==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA2Mzg2Nw==", "bodyText": "nit: copyright date (on this and other new files)", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368063867", "createdAt": "2020-01-17T18:00:54Z", "author": {"login": "agavra"}, "path": "ksql-api/pom.xml", "diffHunk": "@@ -0,0 +1,114 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+  ~ Copyright 2018 Confluent Inc.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 3}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQ1NTU0Ng==", "bodyText": "Ack", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r369455546", "createdAt": "2020-01-22T09:41:56Z", "author": {"login": "purplefox"}, "path": "ksql-api/pom.xml", "diffHunk": "@@ -0,0 +1,114 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+  ~ Copyright 2018 Confluent Inc.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA2Mzg2Nw=="}, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 3}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NDMwOTE2OnYy", "diffSide": "RIGHT", "path": "ksql-api/pom.xml", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QxODowMToyNlrOFfA2Sw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QxODowMToyNlrOFfA2Sw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA2NDA3NQ==", "bodyText": "any reason this shouldn't be in the parent pom?", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368064075", "createdAt": "2020-01-17T18:01:26Z", "author": {"login": "agavra"}, "path": "ksql-api/pom.xml", "diffHunk": "@@ -0,0 +1,114 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+  ~ Copyright 2018 Confluent Inc.\n+  ~\n+  ~ Licensed under the Confluent Community License (the \"License\"); you may not use\n+  ~ this file except in compliance with the License.  You may obtain a copy of the\n+  ~ License at\n+  ~\n+  ~ http://www.confluent.io/confluent-community-license\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+  ~ WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+  ~ specific language governing permissions and limitations under the License.\n+  -->\n+\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n+  xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n+  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+  <modelVersion>4.0.0</modelVersion>\n+\n+\n+  <parent>\n+    <groupId>io.confluent.ksql</groupId>\n+    <artifactId>ksql-parent</artifactId>\n+    <version>5.5.0-SNAPSHOT</version>\n+  </parent>\n+\n+  <artifactId>ksql-api</artifactId>\n+\n+  <properties>\n+    <vertx.version>3.8.4</vertx.version>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NDMxMDQ5OnYy", "diffSide": "RIGHT", "path": "ksql-api/pom.xml", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QxODowMTo1M1rOFfA3EA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQwOTo0MzozNlrOFgV0_w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA2NDI3Mg==", "bodyText": "nit: let's follow the pattern of declaring the version up top", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368064272", "createdAt": "2020-01-17T18:01:53Z", "author": {"login": "agavra"}, "path": "ksql-api/pom.xml", "diffHunk": "@@ -0,0 +1,114 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+  ~ Copyright 2018 Confluent Inc.\n+  ~\n+  ~ Licensed under the Confluent Community License (the \"License\"); you may not use\n+  ~ this file except in compliance with the License.  You may obtain a copy of the\n+  ~ License at\n+  ~\n+  ~ http://www.confluent.io/confluent-community-license\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+  ~ WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+  ~ specific language governing permissions and limitations under the License.\n+  -->\n+\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n+  xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n+  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+  <modelVersion>4.0.0</modelVersion>\n+\n+\n+  <parent>\n+    <groupId>io.confluent.ksql</groupId>\n+    <artifactId>ksql-parent</artifactId>\n+    <version>5.5.0-SNAPSHOT</version>\n+  </parent>\n+\n+  <artifactId>ksql-api</artifactId>\n+\n+  <properties>\n+    <vertx.version>3.8.4</vertx.version>\n+    <maven.compiler.source>1.8</maven.compiler.source>\n+    <maven.compiler.target>1.8</maven.compiler.target>\n+  </properties>\n+\n+  <dependencies>\n+    <dependency>\n+      <groupId>io.vertx</groupId>\n+      <artifactId>vertx-core</artifactId>\n+      <version>${vertx.version}</version>\n+    </dependency>\n+    <dependency>\n+      <groupId>io.vertx</groupId>\n+      <artifactId>vertx-codegen</artifactId>\n+      <version>${vertx.version}</version>\n+    </dependency>\n+    <dependency>\n+      <groupId>io.vertx</groupId>\n+      <artifactId>vertx-codegen</artifactId>\n+      <version>${vertx.version}</version>\n+    </dependency>\n+    <dependency>\n+      <groupId>io.vertx</groupId>\n+      <artifactId>vertx-web</artifactId>\n+      <version>${vertx.version}</version>\n+    </dependency>\n+    <dependency>\n+      <groupId>io.vertx</groupId>\n+      <artifactId>vertx-web-client</artifactId>\n+      <version>${vertx.version}</version>\n+    </dependency>\n+    <dependency>\n+      <groupId>io.netty</groupId>\n+      <artifactId>netty-tcnative-boringssl-static</artifactId>\n+      <version>2.0.28.Final</version>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQ1NjM4Mw==", "bodyText": "I usually only define the version as a property if it's used more than once, otherwise it adds little value imho. It's the same reasoning why I only define String constants in Java if the string is used more than once, otherwise inline String literals are fine.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r369456383", "createdAt": "2020-01-22T09:43:36Z", "author": {"login": "purplefox"}, "path": "ksql-api/pom.xml", "diffHunk": "@@ -0,0 +1,114 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+  ~ Copyright 2018 Confluent Inc.\n+  ~\n+  ~ Licensed under the Confluent Community License (the \"License\"); you may not use\n+  ~ this file except in compliance with the License.  You may obtain a copy of the\n+  ~ License at\n+  ~\n+  ~ http://www.confluent.io/confluent-community-license\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+  ~ WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+  ~ specific language governing permissions and limitations under the License.\n+  -->\n+\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n+  xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n+  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+  <modelVersion>4.0.0</modelVersion>\n+\n+\n+  <parent>\n+    <groupId>io.confluent.ksql</groupId>\n+    <artifactId>ksql-parent</artifactId>\n+    <version>5.5.0-SNAPSHOT</version>\n+  </parent>\n+\n+  <artifactId>ksql-api</artifactId>\n+\n+  <properties>\n+    <vertx.version>3.8.4</vertx.version>\n+    <maven.compiler.source>1.8</maven.compiler.source>\n+    <maven.compiler.target>1.8</maven.compiler.target>\n+  </properties>\n+\n+  <dependencies>\n+    <dependency>\n+      <groupId>io.vertx</groupId>\n+      <artifactId>vertx-core</artifactId>\n+      <version>${vertx.version}</version>\n+    </dependency>\n+    <dependency>\n+      <groupId>io.vertx</groupId>\n+      <artifactId>vertx-codegen</artifactId>\n+      <version>${vertx.version}</version>\n+    </dependency>\n+    <dependency>\n+      <groupId>io.vertx</groupId>\n+      <artifactId>vertx-codegen</artifactId>\n+      <version>${vertx.version}</version>\n+    </dependency>\n+    <dependency>\n+      <groupId>io.vertx</groupId>\n+      <artifactId>vertx-web</artifactId>\n+      <version>${vertx.version}</version>\n+    </dependency>\n+    <dependency>\n+      <groupId>io.vertx</groupId>\n+      <artifactId>vertx-web-client</artifactId>\n+      <version>${vertx.version}</version>\n+    </dependency>\n+    <dependency>\n+      <groupId>io.netty</groupId>\n+      <artifactId>netty-tcnative-boringssl-static</artifactId>\n+      <version>2.0.28.Final</version>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA2NDI3Mg=="}, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 66}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NDMxMzQwOnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/impl/Utils.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QxODowMzowOFrOFfA4-w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQwOTo0NTowN1rOFgV32g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA2NDc2Mw==", "bodyText": "javadoc please \ud83d\ude4f  unless this is some standard terminology I'm not aware of, I'm not sure what \"connecting a promise\" means", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368064763", "createdAt": "2020-01-17T18:03:08Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/impl/Utils.java", "diffHunk": "@@ -0,0 +1,40 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.impl;\n+\n+import io.vertx.core.Future;\n+import io.vertx.core.Promise;\n+\n+/**\n+ * General purpose utils (not limited to the server, could be used by client too) for the API\n+ * module.\n+ */\n+public final class Utils {\n+\n+  private Utils() {\n+  }\n+\n+  public static <T> void connectPromise(final Future<T> future, final Promise<T> promise) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQ1NzExNA==", "bodyText": "Added some javadoc", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r369457114", "createdAt": "2020-01-22T09:45:07Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/impl/Utils.java", "diffHunk": "@@ -0,0 +1,40 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.impl;\n+\n+import io.vertx.core.Future;\n+import io.vertx.core.Promise;\n+\n+/**\n+ * General purpose utils (not limited to the server, could be used by client too) for the API\n+ * module.\n+ */\n+public final class Utils {\n+\n+  private Utils() {\n+  }\n+\n+  public static <T> void connectPromise(final Future<T> future, final Promise<T> promise) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA2NDc2Mw=="}, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NDM3MTY5OnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QxODoyNjoxOVrOFfBdFg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQwOTo0NToyN1rOFgV4fA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA3NDAwNg==", "bodyText": "It took me some time to understand what this API does. Does it indicate that we've completed all the inserts we want to send? Do we expect it to be called more than once? Maybe we can name it requestClose(final long expectedAcks). Would also help to have javadoc around here.\nAlso instead of using a single Long to indicate two things: both that we should close and the value of acks expected, I think it would be safer (avoid unboxing a null value) and easier to read if we split it into a flag boolean closeRequested and long expectedAcks", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368074006", "createdAt": "2020-01-17T18:26:19Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerResponse;\n+import io.vertx.core.json.JsonObject;\n+import java.util.Objects;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * As the stream of inserts is processed by the back-end, it communicates success (or failure) of\n+ * each insert by sending a stream of acks back in the other direction. This class is the subscriber\n+ * which subscribes to that stream of acks and sends them back to the client. It's a reactive\n+ * streams subscriber so implements back pressure.\n+ */\n+public class AcksSubscriber implements Subscriber<Void> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n+  private static final int BATCH_SIZE = 4;\n+  private static final Buffer ACK_RESPONSE_LINE = new JsonObject().put(\"status\", \"ok\").toBuffer()\n+      .appendString(\"\\n\");\n+\n+  private final HttpServerResponse response;\n+  private Subscription subscription;\n+  private long tokens;\n+  private Long insertsSent;\n+  private long acksSent;\n+\n+  public AcksSubscriber(final HttpServerResponse response) {\n+    this.response = Objects.requireNonNull(response);\n+  }\n+\n+  @Override\n+  public synchronized void onSubscribe(final Subscription subscription) {\n+    Objects.requireNonNull(subscription);\n+    if (this.subscription != null) {\n+      throw new IllegalStateException(\"Already subscribed\");\n+    }\n+    this.subscription = subscription;\n+    checkRequestTokens();\n+  }\n+\n+  @Override\n+  public synchronized void onNext(final Void vo) {\n+    if (tokens == 0) {\n+      throw new IllegalStateException(\"Unsolicited data\");\n+    }\n+    response.write(ACK_RESPONSE_LINE);\n+    acksSent++;\n+    tokens--;\n+    if (insertsSent != null && insertsSent == acksSent) {\n+      close();\n+    } else if (response.writeQueueFull()) {\n+      response.drainHandler(v -> checkRequestTokens());\n+    } else {\n+      checkRequestTokens();\n+    }\n+  }\n+\n+  synchronized void insertsSent(final long num) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQ1NzI3Ng==", "bodyText": "out of date", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r369457276", "createdAt": "2020-01-22T09:45:27Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerResponse;\n+import io.vertx.core.json.JsonObject;\n+import java.util.Objects;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * As the stream of inserts is processed by the back-end, it communicates success (or failure) of\n+ * each insert by sending a stream of acks back in the other direction. This class is the subscriber\n+ * which subscribes to that stream of acks and sends them back to the client. It's a reactive\n+ * streams subscriber so implements back pressure.\n+ */\n+public class AcksSubscriber implements Subscriber<Void> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n+  private static final int BATCH_SIZE = 4;\n+  private static final Buffer ACK_RESPONSE_LINE = new JsonObject().put(\"status\", \"ok\").toBuffer()\n+      .appendString(\"\\n\");\n+\n+  private final HttpServerResponse response;\n+  private Subscription subscription;\n+  private long tokens;\n+  private Long insertsSent;\n+  private long acksSent;\n+\n+  public AcksSubscriber(final HttpServerResponse response) {\n+    this.response = Objects.requireNonNull(response);\n+  }\n+\n+  @Override\n+  public synchronized void onSubscribe(final Subscription subscription) {\n+    Objects.requireNonNull(subscription);\n+    if (this.subscription != null) {\n+      throw new IllegalStateException(\"Already subscribed\");\n+    }\n+    this.subscription = subscription;\n+    checkRequestTokens();\n+  }\n+\n+  @Override\n+  public synchronized void onNext(final Void vo) {\n+    if (tokens == 0) {\n+      throw new IllegalStateException(\"Unsolicited data\");\n+    }\n+    response.write(ACK_RESPONSE_LINE);\n+    acksSent++;\n+    tokens--;\n+    if (insertsSent != null && insertsSent == acksSent) {\n+      close();\n+    } else if (response.writeQueueFull()) {\n+      response.drainHandler(v -> checkRequestTokens());\n+    } else {\n+      checkRequestTokens();\n+    }\n+  }\n+\n+  synchronized void insertsSent(final long num) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA3NDAwNg=="}, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 79}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NDM4MDc2OnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QxODozMDoxMFrOFfBjDw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQwOTo0NTo1MFrOFgV5Wg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA3NTUzNQ==", "bodyText": "I'm unclear what this drainHandler method does. Looking at the JavaDoc it suggests that it sets the handler - is there any reason we need to set it every time the response queue fills up or can we just set it once on startup?", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368075535", "createdAt": "2020-01-17T18:30:10Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerResponse;\n+import io.vertx.core.json.JsonObject;\n+import java.util.Objects;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * As the stream of inserts is processed by the back-end, it communicates success (or failure) of\n+ * each insert by sending a stream of acks back in the other direction. This class is the subscriber\n+ * which subscribes to that stream of acks and sends them back to the client. It's a reactive\n+ * streams subscriber so implements back pressure.\n+ */\n+public class AcksSubscriber implements Subscriber<Void> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n+  private static final int BATCH_SIZE = 4;\n+  private static final Buffer ACK_RESPONSE_LINE = new JsonObject().put(\"status\", \"ok\").toBuffer()\n+      .appendString(\"\\n\");\n+\n+  private final HttpServerResponse response;\n+  private Subscription subscription;\n+  private long tokens;\n+  private Long insertsSent;\n+  private long acksSent;\n+\n+  public AcksSubscriber(final HttpServerResponse response) {\n+    this.response = Objects.requireNonNull(response);\n+  }\n+\n+  @Override\n+  public synchronized void onSubscribe(final Subscription subscription) {\n+    Objects.requireNonNull(subscription);\n+    if (this.subscription != null) {\n+      throw new IllegalStateException(\"Already subscribed\");\n+    }\n+    this.subscription = subscription;\n+    checkRequestTokens();\n+  }\n+\n+  @Override\n+  public synchronized void onNext(final Void vo) {\n+    if (tokens == 0) {\n+      throw new IllegalStateException(\"Unsolicited data\");\n+    }\n+    response.write(ACK_RESPONSE_LINE);\n+    acksSent++;\n+    tokens--;\n+    if (insertsSent != null && insertsSent == acksSent) {\n+      close();\n+    } else if (response.writeQueueFull()) {\n+      response.drainHandler(v -> checkRequestTokens());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 73}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQ1NzQ5OA==", "bodyText": "answered in subsequent PR", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r369457498", "createdAt": "2020-01-22T09:45:50Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerResponse;\n+import io.vertx.core.json.JsonObject;\n+import java.util.Objects;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * As the stream of inserts is processed by the back-end, it communicates success (or failure) of\n+ * each insert by sending a stream of acks back in the other direction. This class is the subscriber\n+ * which subscribes to that stream of acks and sends them back to the client. It's a reactive\n+ * streams subscriber so implements back pressure.\n+ */\n+public class AcksSubscriber implements Subscriber<Void> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n+  private static final int BATCH_SIZE = 4;\n+  private static final Buffer ACK_RESPONSE_LINE = new JsonObject().put(\"status\", \"ok\").toBuffer()\n+      .appendString(\"\\n\");\n+\n+  private final HttpServerResponse response;\n+  private Subscription subscription;\n+  private long tokens;\n+  private Long insertsSent;\n+  private long acksSent;\n+\n+  public AcksSubscriber(final HttpServerResponse response) {\n+    this.response = Objects.requireNonNull(response);\n+  }\n+\n+  @Override\n+  public synchronized void onSubscribe(final Subscription subscription) {\n+    Objects.requireNonNull(subscription);\n+    if (this.subscription != null) {\n+      throw new IllegalStateException(\"Already subscribed\");\n+    }\n+    this.subscription = subscription;\n+    checkRequestTokens();\n+  }\n+\n+  @Override\n+  public synchronized void onNext(final Void vo) {\n+    if (tokens == 0) {\n+      throw new IllegalStateException(\"Unsolicited data\");\n+    }\n+    response.write(ACK_RESPONSE_LINE);\n+    acksSent++;\n+    tokens--;\n+    if (insertsSent != null && insertsSent == acksSent) {\n+      close();\n+    } else if (response.writeQueueFull()) {\n+      response.drainHandler(v -> checkRequestTokens());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA3NTUzNQ=="}, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 73}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NDM4ODY0OnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QxODozMzoxM1rOFfBoBw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQwOTo0NjowNlrOFgV5zw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA3NjgwNw==", "bodyText": "I thought I saw @big-andy-coates comment this somewhere, but I agree with him that it's better if we can have jackson POJOs for these (and the ACK_RESPONSE_LINE) so that the schema is clear and well defined. Something I've found very useful is to be able to go to a single package and see all of the serialized object schemas that we're sending (e.g. io.confluent.ksql.rest.entity). I understand this adds a little bulk, but I think it's worth it in this case.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368076807", "createdAt": "2020-01-17T18:33:13Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerResponse;\n+import io.vertx.core.json.JsonObject;\n+import java.util.Objects;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * As the stream of inserts is processed by the back-end, it communicates success (or failure) of\n+ * each insert by sending a stream of acks back in the other direction. This class is the subscriber\n+ * which subscribes to that stream of acks and sends them back to the client. It's a reactive\n+ * streams subscriber so implements back pressure.\n+ */\n+public class AcksSubscriber implements Subscriber<Void> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n+  private static final int BATCH_SIZE = 4;\n+  private static final Buffer ACK_RESPONSE_LINE = new JsonObject().put(\"status\", \"ok\").toBuffer()\n+      .appendString(\"\\n\");\n+\n+  private final HttpServerResponse response;\n+  private Subscription subscription;\n+  private long tokens;\n+  private Long insertsSent;\n+  private long acksSent;\n+\n+  public AcksSubscriber(final HttpServerResponse response) {\n+    this.response = Objects.requireNonNull(response);\n+  }\n+\n+  @Override\n+  public synchronized void onSubscribe(final Subscription subscription) {\n+    Objects.requireNonNull(subscription);\n+    if (this.subscription != null) {\n+      throw new IllegalStateException(\"Already subscribed\");\n+    }\n+    this.subscription = subscription;\n+    checkRequestTokens();\n+  }\n+\n+  @Override\n+  public synchronized void onNext(final Void vo) {\n+    if (tokens == 0) {\n+      throw new IllegalStateException(\"Unsolicited data\");\n+    }\n+    response.write(ACK_RESPONSE_LINE);\n+    acksSent++;\n+    tokens--;\n+    if (insertsSent != null && insertsSent == acksSent) {\n+      close();\n+    } else if (response.writeQueueFull()) {\n+      response.drainHandler(v -> checkRequestTokens());\n+    } else {\n+      checkRequestTokens();\n+    }\n+  }\n+\n+  synchronized void insertsSent(final long num) {\n+    this.insertsSent = num;\n+    if (acksSent == num) {\n+      close();\n+    }\n+  }\n+\n+  private void close() {\n+    response.end();\n+    subscription.cancel();\n+  }\n+\n+  private void checkRequestTokens() {\n+    if (tokens == 0) {\n+      tokens = BATCH_SIZE;\n+      subscription.request(BATCH_SIZE);\n+    }\n+  }\n+\n+  @Override\n+  public synchronized void onError(final Throwable t) {\n+    log.error(\"Error in processing inserts\", t);\n+    final JsonObject err = new JsonObject().put(\"status\", \"error\")\n+        .put(\"errorCode\", ERROR_CODE_INTERNAL_ERROR)\n+        .put(\"message\", \"Error in processing inserts\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQ1NzYxNQ==", "bodyText": "addressed in POJO PR", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r369457615", "createdAt": "2020-01-22T09:46:06Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerResponse;\n+import io.vertx.core.json.JsonObject;\n+import java.util.Objects;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * As the stream of inserts is processed by the back-end, it communicates success (or failure) of\n+ * each insert by sending a stream of acks back in the other direction. This class is the subscriber\n+ * which subscribes to that stream of acks and sends them back to the client. It's a reactive\n+ * streams subscriber so implements back pressure.\n+ */\n+public class AcksSubscriber implements Subscriber<Void> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n+  private static final int BATCH_SIZE = 4;\n+  private static final Buffer ACK_RESPONSE_LINE = new JsonObject().put(\"status\", \"ok\").toBuffer()\n+      .appendString(\"\\n\");\n+\n+  private final HttpServerResponse response;\n+  private Subscription subscription;\n+  private long tokens;\n+  private Long insertsSent;\n+  private long acksSent;\n+\n+  public AcksSubscriber(final HttpServerResponse response) {\n+    this.response = Objects.requireNonNull(response);\n+  }\n+\n+  @Override\n+  public synchronized void onSubscribe(final Subscription subscription) {\n+    Objects.requireNonNull(subscription);\n+    if (this.subscription != null) {\n+      throw new IllegalStateException(\"Already subscribed\");\n+    }\n+    this.subscription = subscription;\n+    checkRequestTokens();\n+  }\n+\n+  @Override\n+  public synchronized void onNext(final Void vo) {\n+    if (tokens == 0) {\n+      throw new IllegalStateException(\"Unsolicited data\");\n+    }\n+    response.write(ACK_RESPONSE_LINE);\n+    acksSent++;\n+    tokens--;\n+    if (insertsSent != null && insertsSent == acksSent) {\n+      close();\n+    } else if (response.writeQueueFull()) {\n+      response.drainHandler(v -> checkRequestTokens());\n+    } else {\n+      checkRequestTokens();\n+    }\n+  }\n+\n+  synchronized void insertsSent(final long num) {\n+    this.insertsSent = num;\n+    if (acksSent == num) {\n+      close();\n+    }\n+  }\n+\n+  private void close() {\n+    response.end();\n+    subscription.cancel();\n+  }\n+\n+  private void checkRequestTokens() {\n+    if (tokens == 0) {\n+      tokens = BATCH_SIZE;\n+      subscription.request(BATCH_SIZE);\n+    }\n+  }\n+\n+  @Override\n+  public synchronized void onError(final Throwable t) {\n+    log.error(\"Error in processing inserts\", t);\n+    final JsonObject err = new JsonObject().put(\"status\", \"error\")\n+        .put(\"errorCode\", ERROR_CODE_INTERNAL_ERROR)\n+        .put(\"message\", \"Error in processing inserts\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA3NjgwNw=="}, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 103}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NDM5NDQwOnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QxODozNToyOVrOFfBrnw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQwOTo0NjoxOVrOFgV6Uw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA3NzcyNw==", "bodyText": "if subscription.cancel is idempotent can we just call close here?", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368077727", "createdAt": "2020-01-17T18:35:29Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerResponse;\n+import io.vertx.core.json.JsonObject;\n+import java.util.Objects;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * As the stream of inserts is processed by the back-end, it communicates success (or failure) of\n+ * each insert by sending a stream of acks back in the other direction. This class is the subscriber\n+ * which subscribes to that stream of acks and sends them back to the client. It's a reactive\n+ * streams subscriber so implements back pressure.\n+ */\n+public class AcksSubscriber implements Subscriber<Void> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n+  private static final int BATCH_SIZE = 4;\n+  private static final Buffer ACK_RESPONSE_LINE = new JsonObject().put(\"status\", \"ok\").toBuffer()\n+      .appendString(\"\\n\");\n+\n+  private final HttpServerResponse response;\n+  private Subscription subscription;\n+  private long tokens;\n+  private Long insertsSent;\n+  private long acksSent;\n+\n+  public AcksSubscriber(final HttpServerResponse response) {\n+    this.response = Objects.requireNonNull(response);\n+  }\n+\n+  @Override\n+  public synchronized void onSubscribe(final Subscription subscription) {\n+    Objects.requireNonNull(subscription);\n+    if (this.subscription != null) {\n+      throw new IllegalStateException(\"Already subscribed\");\n+    }\n+    this.subscription = subscription;\n+    checkRequestTokens();\n+  }\n+\n+  @Override\n+  public synchronized void onNext(final Void vo) {\n+    if (tokens == 0) {\n+      throw new IllegalStateException(\"Unsolicited data\");\n+    }\n+    response.write(ACK_RESPONSE_LINE);\n+    acksSent++;\n+    tokens--;\n+    if (insertsSent != null && insertsSent == acksSent) {\n+      close();\n+    } else if (response.writeQueueFull()) {\n+      response.drainHandler(v -> checkRequestTokens());\n+    } else {\n+      checkRequestTokens();\n+    }\n+  }\n+\n+  synchronized void insertsSent(final long num) {\n+    this.insertsSent = num;\n+    if (acksSent == num) {\n+      close();\n+    }\n+  }\n+\n+  private void close() {\n+    response.end();\n+    subscription.cancel();\n+  }\n+\n+  private void checkRequestTokens() {\n+    if (tokens == 0) {\n+      tokens = BATCH_SIZE;\n+      subscription.request(BATCH_SIZE);\n+    }\n+  }\n+\n+  @Override\n+  public synchronized void onError(final Throwable t) {\n+    log.error(\"Error in processing inserts\", t);\n+    final JsonObject err = new JsonObject().put(\"status\", \"error\")\n+        .put(\"errorCode\", ERROR_CODE_INTERNAL_ERROR)\n+        .put(\"message\", \"Error in processing inserts\");\n+    subscription.cancel();\n+    response.end(err.toBuffer());\n+  }\n+\n+  @Override\n+  public synchronized void onComplete() {\n+    response.end();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 110}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQ1Nzc0Nw==", "bodyText": "out of date", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r369457747", "createdAt": "2020-01-22T09:46:19Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerResponse;\n+import io.vertx.core.json.JsonObject;\n+import java.util.Objects;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * As the stream of inserts is processed by the back-end, it communicates success (or failure) of\n+ * each insert by sending a stream of acks back in the other direction. This class is the subscriber\n+ * which subscribes to that stream of acks and sends them back to the client. It's a reactive\n+ * streams subscriber so implements back pressure.\n+ */\n+public class AcksSubscriber implements Subscriber<Void> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n+  private static final int BATCH_SIZE = 4;\n+  private static final Buffer ACK_RESPONSE_LINE = new JsonObject().put(\"status\", \"ok\").toBuffer()\n+      .appendString(\"\\n\");\n+\n+  private final HttpServerResponse response;\n+  private Subscription subscription;\n+  private long tokens;\n+  private Long insertsSent;\n+  private long acksSent;\n+\n+  public AcksSubscriber(final HttpServerResponse response) {\n+    this.response = Objects.requireNonNull(response);\n+  }\n+\n+  @Override\n+  public synchronized void onSubscribe(final Subscription subscription) {\n+    Objects.requireNonNull(subscription);\n+    if (this.subscription != null) {\n+      throw new IllegalStateException(\"Already subscribed\");\n+    }\n+    this.subscription = subscription;\n+    checkRequestTokens();\n+  }\n+\n+  @Override\n+  public synchronized void onNext(final Void vo) {\n+    if (tokens == 0) {\n+      throw new IllegalStateException(\"Unsolicited data\");\n+    }\n+    response.write(ACK_RESPONSE_LINE);\n+    acksSent++;\n+    tokens--;\n+    if (insertsSent != null && insertsSent == acksSent) {\n+      close();\n+    } else if (response.writeQueueFull()) {\n+      response.drainHandler(v -> checkRequestTokens());\n+    } else {\n+      checkRequestTokens();\n+    }\n+  }\n+\n+  synchronized void insertsSent(final long num) {\n+    this.insertsSent = num;\n+    if (acksSent == num) {\n+      close();\n+    }\n+  }\n+\n+  private void close() {\n+    response.end();\n+    subscription.cancel();\n+  }\n+\n+  private void checkRequestTokens() {\n+    if (tokens == 0) {\n+      tokens = BATCH_SIZE;\n+      subscription.request(BATCH_SIZE);\n+    }\n+  }\n+\n+  @Override\n+  public synchronized void onError(final Throwable t) {\n+    log.error(\"Error in processing inserts\", t);\n+    final JsonObject err = new JsonObject().put(\"status\", \"error\")\n+        .put(\"errorCode\", ERROR_CODE_INTERNAL_ERROR)\n+        .put(\"message\", \"Error in processing inserts\");\n+    subscription.cancel();\n+    response.end(err.toBuffer());\n+  }\n+\n+  @Override\n+  public synchronized void onComplete() {\n+    response.end();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA3NzcyNw=="}, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 110}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NDM5Njg0OnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QxODozNjoyMlrOFfBtIQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQwOTo0NjozOVrOFgV66Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA3ODExMw==", "bodyText": "does the drainHandler trigger asyncrhonously? if so this method may also need to be synchronized", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368078113", "createdAt": "2020-01-17T18:36:22Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerResponse;\n+import io.vertx.core.json.JsonObject;\n+import java.util.Objects;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * As the stream of inserts is processed by the back-end, it communicates success (or failure) of\n+ * each insert by sending a stream of acks back in the other direction. This class is the subscriber\n+ * which subscribes to that stream of acks and sends them back to the client. It's a reactive\n+ * streams subscriber so implements back pressure.\n+ */\n+public class AcksSubscriber implements Subscriber<Void> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n+  private static final int BATCH_SIZE = 4;\n+  private static final Buffer ACK_RESPONSE_LINE = new JsonObject().put(\"status\", \"ok\").toBuffer()\n+      .appendString(\"\\n\");\n+\n+  private final HttpServerResponse response;\n+  private Subscription subscription;\n+  private long tokens;\n+  private Long insertsSent;\n+  private long acksSent;\n+\n+  public AcksSubscriber(final HttpServerResponse response) {\n+    this.response = Objects.requireNonNull(response);\n+  }\n+\n+  @Override\n+  public synchronized void onSubscribe(final Subscription subscription) {\n+    Objects.requireNonNull(subscription);\n+    if (this.subscription != null) {\n+      throw new IllegalStateException(\"Already subscribed\");\n+    }\n+    this.subscription = subscription;\n+    checkRequestTokens();\n+  }\n+\n+  @Override\n+  public synchronized void onNext(final Void vo) {\n+    if (tokens == 0) {\n+      throw new IllegalStateException(\"Unsolicited data\");\n+    }\n+    response.write(ACK_RESPONSE_LINE);\n+    acksSent++;\n+    tokens--;\n+    if (insertsSent != null && insertsSent == acksSent) {\n+      close();\n+    } else if (response.writeQueueFull()) {\n+      response.drainHandler(v -> checkRequestTokens());\n+    } else {\n+      checkRequestTokens();\n+    }\n+  }\n+\n+  synchronized void insertsSent(final long num) {\n+    this.insertsSent = num;\n+    if (acksSent == num) {\n+      close();\n+    }\n+  }\n+\n+  private void close() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQ1Nzg5Nw==", "bodyText": "out of date / answered in other PR", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r369457897", "createdAt": "2020-01-22T09:46:39Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerResponse;\n+import io.vertx.core.json.JsonObject;\n+import java.util.Objects;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * As the stream of inserts is processed by the back-end, it communicates success (or failure) of\n+ * each insert by sending a stream of acks back in the other direction. This class is the subscriber\n+ * which subscribes to that stream of acks and sends them back to the client. It's a reactive\n+ * streams subscriber so implements back pressure.\n+ */\n+public class AcksSubscriber implements Subscriber<Void> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n+  private static final int BATCH_SIZE = 4;\n+  private static final Buffer ACK_RESPONSE_LINE = new JsonObject().put(\"status\", \"ok\").toBuffer()\n+      .appendString(\"\\n\");\n+\n+  private final HttpServerResponse response;\n+  private Subscription subscription;\n+  private long tokens;\n+  private Long insertsSent;\n+  private long acksSent;\n+\n+  public AcksSubscriber(final HttpServerResponse response) {\n+    this.response = Objects.requireNonNull(response);\n+  }\n+\n+  @Override\n+  public synchronized void onSubscribe(final Subscription subscription) {\n+    Objects.requireNonNull(subscription);\n+    if (this.subscription != null) {\n+      throw new IllegalStateException(\"Already subscribed\");\n+    }\n+    this.subscription = subscription;\n+    checkRequestTokens();\n+  }\n+\n+  @Override\n+  public synchronized void onNext(final Void vo) {\n+    if (tokens == 0) {\n+      throw new IllegalStateException(\"Unsolicited data\");\n+    }\n+    response.write(ACK_RESPONSE_LINE);\n+    acksSent++;\n+    tokens--;\n+    if (insertsSent != null && insertsSent == acksSent) {\n+      close();\n+    } else if (response.writeQueueFull()) {\n+      response.drainHandler(v -> checkRequestTokens());\n+    } else {\n+      checkRequestTokens();\n+    }\n+  }\n+\n+  synchronized void insertsSent(final long num) {\n+    this.insertsSent = num;\n+    if (acksSent == num) {\n+      close();\n+    }\n+  }\n+\n+  private void close() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA3ODExMw=="}, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 86}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NDQxMDU2OnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyParser.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QxODo0MTo1OVrOFfB1sw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQwOTo0NzowMlrOFgV7tg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA4MDMwNw==", "bodyText": "nit: since this is a \"public\" API, it might benefit from giving an example so people don't need to grok descriptions", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368080307", "createdAt": "2020-01-17T18:41:59Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyParser.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.InsertsSubscriber;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.ext.web.RoutingContext;\n+import java.util.Objects;\n+\n+/**\n+ * This class handles the parsing of the request body for a stream of inserts. The user can send a\n+ * stream of inserts to the server by opening an HTTP2 request to the server at the appropriate uri\n+ * and POSTing a request. The request must contain an initial JSON object (encoded as UTF-8 text)\n+ * which contains the arguments for the request (e.g. the target to insert into, and whether acks\n+ * are wanted) This must be followed by a new line, and then followed by zero or more JSON objects\n+ * (also encoded as UTF-8 text) each representing a row to insert. The last JSON object must be\n+ * followed by a new-line.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQ1ODEwMg==", "bodyText": "Overkill at this stage imho", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r369458102", "createdAt": "2020-01-22T09:47:02Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyParser.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.InsertsSubscriber;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.ext.web.RoutingContext;\n+import java.util.Objects;\n+\n+/**\n+ * This class handles the parsing of the request body for a stream of inserts. The user can send a\n+ * stream of inserts to the server by opening an HTTP2 request to the server at the appropriate uri\n+ * and POSTing a request. The request must contain an initial JSON object (encoded as UTF-8 text)\n+ * which contains the arguments for the request (e.g. the target to insert into, and whether acks\n+ * are wanted) This must be followed by a new line, and then followed by zero or more JSON objects\n+ * (also encoded as UTF-8 text) each representing a row to insert. The last JSON object must be\n+ * followed by a new-line.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA4MDMwNw=="}, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NDQxMzU1OnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyParser.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QxODo0MzowM1rOFfB3hQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQwOTo0NzoyM1rOFgV8YA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA4MDc3Mw==", "bodyText": "does this need to be synchronized with handleBodyBuffer or is it impossible that they will come in concurrently?", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368080773", "createdAt": "2020-01-17T18:43:03Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyParser.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.InsertsSubscriber;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.ext.web.RoutingContext;\n+import java.util.Objects;\n+\n+/**\n+ * This class handles the parsing of the request body for a stream of inserts. The user can send a\n+ * stream of inserts to the server by opening an HTTP2 request to the server at the appropriate uri\n+ * and POSTing a request. The request must contain an initial JSON object (encoded as UTF-8 text)\n+ * which contains the arguments for the request (e.g. the target to insert into, and whether acks\n+ * are wanted) This must be followed by a new line, and then followed by zero or more JSON objects\n+ * (also encoded as UTF-8 text) each representing a row to insert. The last JSON object must be\n+ * followed by a new-line.\n+ */\n+public class InsertsBodyParser {\n+\n+  private final Endpoints endpoints;\n+  private final RoutingContext routingContext;\n+  private boolean readArguments;\n+  private InsertsPublisher publisher;\n+  private long rowsReceived;\n+  private AcksSubscriber acksSubscriber;\n+\n+  public InsertsBodyParser(final Endpoints endpoints, final RoutingContext routingContext) {\n+    this.endpoints = Objects.requireNonNull(endpoints);\n+    this.routingContext = Objects.requireNonNull(routingContext);\n+    routingContext.response().endHandler(v -> {\n+      if (publisher != null) {\n+        publisher.close();\n+      }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQ1ODI3Mg==", "bodyText": "it's impossible as per Vert.x threading model", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r369458272", "createdAt": "2020-01-22T09:47:23Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyParser.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.InsertsSubscriber;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.ext.web.RoutingContext;\n+import java.util.Objects;\n+\n+/**\n+ * This class handles the parsing of the request body for a stream of inserts. The user can send a\n+ * stream of inserts to the server by opening an HTTP2 request to the server at the appropriate uri\n+ * and POSTing a request. The request must contain an initial JSON object (encoded as UTF-8 text)\n+ * which contains the arguments for the request (e.g. the target to insert into, and whether acks\n+ * are wanted) This must be followed by a new line, and then followed by zero or more JSON objects\n+ * (also encoded as UTF-8 text) each representing a row to insert. The last JSON object must be\n+ * followed by a new-line.\n+ */\n+public class InsertsBodyParser {\n+\n+  private final Endpoints endpoints;\n+  private final RoutingContext routingContext;\n+  private boolean readArguments;\n+  private InsertsPublisher publisher;\n+  private long rowsReceived;\n+  private AcksSubscriber acksSubscriber;\n+\n+  public InsertsBodyParser(final Endpoints endpoints, final RoutingContext routingContext) {\n+    this.endpoints = Objects.requireNonNull(endpoints);\n+    this.routingContext = Objects.requireNonNull(routingContext);\n+    routingContext.response().endHandler(v -> {\n+      if (publisher != null) {\n+        publisher.close();\n+      }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA4MDc3Mw=="}, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NDQxOTc1OnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyParser.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QxODo0NTo1MFrOFfB7mQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQwOTo0Nzo0M1rOFgV8_w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA4MTgxNw==", "bodyText": "personal preference and totally unenforceable (so feel free to disagree) but I would be made very happy if we added some white space in this method to split up logical components \ud83d\ude02 code without whitespace feels like a run-on sentence", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368081817", "createdAt": "2020-01-17T18:45:50Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyParser.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.InsertsSubscriber;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.ext.web.RoutingContext;\n+import java.util.Objects;\n+\n+/**\n+ * This class handles the parsing of the request body for a stream of inserts. The user can send a\n+ * stream of inserts to the server by opening an HTTP2 request to the server at the appropriate uri\n+ * and POSTing a request. The request must contain an initial JSON object (encoded as UTF-8 text)\n+ * which contains the arguments for the request (e.g. the target to insert into, and whether acks\n+ * are wanted) This must be followed by a new line, and then followed by zero or more JSON objects\n+ * (also encoded as UTF-8 text) each representing a row to insert. The last JSON object must be\n+ * followed by a new-line.\n+ */\n+public class InsertsBodyParser {\n+\n+  private final Endpoints endpoints;\n+  private final RoutingContext routingContext;\n+  private boolean readArguments;\n+  private InsertsPublisher publisher;\n+  private long rowsReceived;\n+  private AcksSubscriber acksSubscriber;\n+\n+  public InsertsBodyParser(final Endpoints endpoints, final RoutingContext routingContext) {\n+    this.endpoints = Objects.requireNonNull(endpoints);\n+    this.routingContext = Objects.requireNonNull(routingContext);\n+    routingContext.response().endHandler(v -> {\n+      if (publisher != null) {\n+        publisher.close();\n+      }\n+    });\n+  }\n+\n+  public void handleBodyEnd(final Void v) {\n+    if (acksSubscriber == null) {\n+      routingContext.response().end();\n+    } else {\n+      // We close the response after the stream of acks has been sent\n+      acksSubscriber.insertsSent(rowsReceived);\n+    }\n+  }\n+\n+  public void handleBodyBuffer(final Buffer buff) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQ1ODQzMQ==", "bodyText": "Noted", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r369458431", "createdAt": "2020-01-22T09:47:43Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyParser.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.InsertsSubscriber;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.ext.web.RoutingContext;\n+import java.util.Objects;\n+\n+/**\n+ * This class handles the parsing of the request body for a stream of inserts. The user can send a\n+ * stream of inserts to the server by opening an HTTP2 request to the server at the appropriate uri\n+ * and POSTing a request. The request must contain an initial JSON object (encoded as UTF-8 text)\n+ * which contains the arguments for the request (e.g. the target to insert into, and whether acks\n+ * are wanted) This must be followed by a new line, and then followed by zero or more JSON objects\n+ * (also encoded as UTF-8 text) each representing a row to insert. The last JSON object must be\n+ * followed by a new-line.\n+ */\n+public class InsertsBodyParser {\n+\n+  private final Endpoints endpoints;\n+  private final RoutingContext routingContext;\n+  private boolean readArguments;\n+  private InsertsPublisher publisher;\n+  private long rowsReceived;\n+  private AcksSubscriber acksSubscriber;\n+\n+  public InsertsBodyParser(final Endpoints endpoints, final RoutingContext routingContext) {\n+    this.endpoints = Objects.requireNonNull(endpoints);\n+    this.routingContext = Objects.requireNonNull(routingContext);\n+    routingContext.response().endHandler(v -> {\n+      if (publisher != null) {\n+        publisher.close();\n+      }\n+    });\n+  }\n+\n+  public void handleBodyEnd(final Void v) {\n+    if (acksSubscriber == null) {\n+      routingContext.response().end();\n+    } else {\n+      // We close the response after the stream of acks has been sent\n+      acksSubscriber.insertsSent(rowsReceived);\n+    }\n+  }\n+\n+  public void handleBodyBuffer(final Buffer buff) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA4MTgxNw=="}, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 65}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NDQyMjI3OnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyParser.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QxODo0Njo1M1rOFfB9QQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQwOTo0Nzo1OVrOFgV9mA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA4MjI0MQ==", "bodyText": "same comment as above - it would be nice to have Jackson handle this schema validation for us (and as a way of documenting the public API programmatically)", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368082241", "createdAt": "2020-01-17T18:46:53Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyParser.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.InsertsSubscriber;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.ext.web.RoutingContext;\n+import java.util.Objects;\n+\n+/**\n+ * This class handles the parsing of the request body for a stream of inserts. The user can send a\n+ * stream of inserts to the server by opening an HTTP2 request to the server at the appropriate uri\n+ * and POSTing a request. The request must contain an initial JSON object (encoded as UTF-8 text)\n+ * which contains the arguments for the request (e.g. the target to insert into, and whether acks\n+ * are wanted) This must be followed by a new line, and then followed by zero or more JSON objects\n+ * (also encoded as UTF-8 text) each representing a row to insert. The last JSON object must be\n+ * followed by a new-line.\n+ */\n+public class InsertsBodyParser {\n+\n+  private final Endpoints endpoints;\n+  private final RoutingContext routingContext;\n+  private boolean readArguments;\n+  private InsertsPublisher publisher;\n+  private long rowsReceived;\n+  private AcksSubscriber acksSubscriber;\n+\n+  public InsertsBodyParser(final Endpoints endpoints, final RoutingContext routingContext) {\n+    this.endpoints = Objects.requireNonNull(endpoints);\n+    this.routingContext = Objects.requireNonNull(routingContext);\n+    routingContext.response().endHandler(v -> {\n+      if (publisher != null) {\n+        publisher.close();\n+      }\n+    });\n+  }\n+\n+  public void handleBodyEnd(final Void v) {\n+    if (acksSubscriber == null) {\n+      routingContext.response().end();\n+    } else {\n+      // We close the response after the stream of acks has been sent\n+      acksSubscriber.insertsSent(rowsReceived);\n+    }\n+  }\n+\n+  public void handleBodyBuffer(final Buffer buff) {\n+    if (!readArguments) {\n+      final JsonObject args = new JsonObject(buff);\n+      readArguments = true;\n+      final String target = args.getString(\"target\");\n+      if (target == null) {\n+        handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM,\n+            \"No target in arguments\");\n+        return;\n+      }\n+      final Boolean acks = args.getBoolean(\"acks\");\n+      if (acks == null) {\n+        handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM,\n+            \"No acks in arguments\");\n+        return;\n+      }\n+      final JsonObject properties = args.getJsonObject(\"properties\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 81}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQ1ODU4NA==", "bodyText": "See POJOs PR", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r369458584", "createdAt": "2020-01-22T09:47:59Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyParser.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.InsertsSubscriber;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.ext.web.RoutingContext;\n+import java.util.Objects;\n+\n+/**\n+ * This class handles the parsing of the request body for a stream of inserts. The user can send a\n+ * stream of inserts to the server by opening an HTTP2 request to the server at the appropriate uri\n+ * and POSTing a request. The request must contain an initial JSON object (encoded as UTF-8 text)\n+ * which contains the arguments for the request (e.g. the target to insert into, and whether acks\n+ * are wanted) This must be followed by a new line, and then followed by zero or more JSON objects\n+ * (also encoded as UTF-8 text) each representing a row to insert. The last JSON object must be\n+ * followed by a new-line.\n+ */\n+public class InsertsBodyParser {\n+\n+  private final Endpoints endpoints;\n+  private final RoutingContext routingContext;\n+  private boolean readArguments;\n+  private InsertsPublisher publisher;\n+  private long rowsReceived;\n+  private AcksSubscriber acksSubscriber;\n+\n+  public InsertsBodyParser(final Endpoints endpoints, final RoutingContext routingContext) {\n+    this.endpoints = Objects.requireNonNull(endpoints);\n+    this.routingContext = Objects.requireNonNull(routingContext);\n+    routingContext.response().endHandler(v -> {\n+      if (publisher != null) {\n+        publisher.close();\n+      }\n+    });\n+  }\n+\n+  public void handleBodyEnd(final Void v) {\n+    if (acksSubscriber == null) {\n+      routingContext.response().end();\n+    } else {\n+      // We close the response after the stream of acks has been sent\n+      acksSubscriber.insertsSent(rowsReceived);\n+    }\n+  }\n+\n+  public void handleBodyBuffer(final Buffer buff) {\n+    if (!readArguments) {\n+      final JsonObject args = new JsonObject(buff);\n+      readArguments = true;\n+      final String target = args.getString(\"target\");\n+      if (target == null) {\n+        handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM,\n+            \"No target in arguments\");\n+        return;\n+      }\n+      final Boolean acks = args.getBoolean(\"acks\");\n+      if (acks == null) {\n+        handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM,\n+            \"No acks in arguments\");\n+        return;\n+      }\n+      final JsonObject properties = args.getJsonObject(\"properties\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA4MjI0MQ=="}, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 81}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NDQyMzk1OnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyParser.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QxODo0NzozOFrOFfB-YA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQwOTo0ODowN1rOFgV94w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA4MjUyOA==", "bodyText": "we should name this something like requireAcks - acks sounds like a count of acks, not a boolean. Since this is public API I do feel like it's important to make it extra clear", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368082528", "createdAt": "2020-01-17T18:47:38Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyParser.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.InsertsSubscriber;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.ext.web.RoutingContext;\n+import java.util.Objects;\n+\n+/**\n+ * This class handles the parsing of the request body for a stream of inserts. The user can send a\n+ * stream of inserts to the server by opening an HTTP2 request to the server at the appropriate uri\n+ * and POSTing a request. The request must contain an initial JSON object (encoded as UTF-8 text)\n+ * which contains the arguments for the request (e.g. the target to insert into, and whether acks\n+ * are wanted) This must be followed by a new line, and then followed by zero or more JSON objects\n+ * (also encoded as UTF-8 text) each representing a row to insert. The last JSON object must be\n+ * followed by a new-line.\n+ */\n+public class InsertsBodyParser {\n+\n+  private final Endpoints endpoints;\n+  private final RoutingContext routingContext;\n+  private boolean readArguments;\n+  private InsertsPublisher publisher;\n+  private long rowsReceived;\n+  private AcksSubscriber acksSubscriber;\n+\n+  public InsertsBodyParser(final Endpoints endpoints, final RoutingContext routingContext) {\n+    this.endpoints = Objects.requireNonNull(endpoints);\n+    this.routingContext = Objects.requireNonNull(routingContext);\n+    routingContext.response().endHandler(v -> {\n+      if (publisher != null) {\n+        publisher.close();\n+      }\n+    });\n+  }\n+\n+  public void handleBodyEnd(final Void v) {\n+    if (acksSubscriber == null) {\n+      routingContext.response().end();\n+    } else {\n+      // We close the response after the stream of acks has been sent\n+      acksSubscriber.insertsSent(rowsReceived);\n+    }\n+  }\n+\n+  public void handleBodyBuffer(final Buffer buff) {\n+    if (!readArguments) {\n+      final JsonObject args = new JsonObject(buff);\n+      readArguments = true;\n+      final String target = args.getString(\"target\");\n+      if (target == null) {\n+        handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM,\n+            \"No target in arguments\");\n+        return;\n+      }\n+      final Boolean acks = args.getBoolean(\"acks\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQ1ODY1OQ==", "bodyText": "Ack", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r369458659", "createdAt": "2020-01-22T09:48:07Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyParser.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.InsertsSubscriber;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.ext.web.RoutingContext;\n+import java.util.Objects;\n+\n+/**\n+ * This class handles the parsing of the request body for a stream of inserts. The user can send a\n+ * stream of inserts to the server by opening an HTTP2 request to the server at the appropriate uri\n+ * and POSTing a request. The request must contain an initial JSON object (encoded as UTF-8 text)\n+ * which contains the arguments for the request (e.g. the target to insert into, and whether acks\n+ * are wanted) This must be followed by a new line, and then followed by zero or more JSON objects\n+ * (also encoded as UTF-8 text) each representing a row to insert. The last JSON object must be\n+ * followed by a new-line.\n+ */\n+public class InsertsBodyParser {\n+\n+  private final Endpoints endpoints;\n+  private final RoutingContext routingContext;\n+  private boolean readArguments;\n+  private InsertsPublisher publisher;\n+  private long rowsReceived;\n+  private AcksSubscriber acksSubscriber;\n+\n+  public InsertsBodyParser(final Endpoints endpoints, final RoutingContext routingContext) {\n+    this.endpoints = Objects.requireNonNull(endpoints);\n+    this.routingContext = Objects.requireNonNull(routingContext);\n+    routingContext.response().endHandler(v -> {\n+      if (publisher != null) {\n+        publisher.close();\n+      }\n+    });\n+  }\n+\n+  public void handleBodyEnd(final Void v) {\n+    if (acksSubscriber == null) {\n+      routingContext.response().end();\n+    } else {\n+      // We close the response after the stream of acks has been sent\n+      acksSubscriber.insertsSent(rowsReceived);\n+    }\n+  }\n+\n+  public void handleBodyBuffer(final Buffer buff) {\n+    if (!readArguments) {\n+      final JsonObject args = new JsonObject(buff);\n+      readArguments = true;\n+      final String target = args.getString(\"target\");\n+      if (target == null) {\n+        handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM,\n+            \"No target in arguments\");\n+        return;\n+      }\n+      final Boolean acks = args.getBoolean(\"acks\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA4MjUyOA=="}, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 75}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NDQzODYxOnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyParser.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QxODo1MzoyM1rOFfCH8g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQwOTo0ODo0NFrOFgV-_w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA4NDk3OA==", "bodyText": "nit s/readArguments/hasReadArguments/ because the past tense and command form of \"read\" are the spelled same \ud83d\ude02", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368084978", "createdAt": "2020-01-17T18:53:23Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyParser.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.InsertsSubscriber;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.ext.web.RoutingContext;\n+import java.util.Objects;\n+\n+/**\n+ * This class handles the parsing of the request body for a stream of inserts. The user can send a\n+ * stream of inserts to the server by opening an HTTP2 request to the server at the appropriate uri\n+ * and POSTing a request. The request must contain an initial JSON object (encoded as UTF-8 text)\n+ * which contains the arguments for the request (e.g. the target to insert into, and whether acks\n+ * are wanted) This must be followed by a new line, and then followed by zero or more JSON objects\n+ * (also encoded as UTF-8 text) each representing a row to insert. The last JSON object must be\n+ * followed by a new-line.\n+ */\n+public class InsertsBodyParser {\n+\n+  private final Endpoints endpoints;\n+  private final RoutingContext routingContext;\n+  private boolean readArguments;\n+  private InsertsPublisher publisher;\n+  private long rowsReceived;\n+  private AcksSubscriber acksSubscriber;\n+\n+  public InsertsBodyParser(final Endpoints endpoints, final RoutingContext routingContext) {\n+    this.endpoints = Objects.requireNonNull(endpoints);\n+    this.routingContext = Objects.requireNonNull(routingContext);\n+    routingContext.response().endHandler(v -> {\n+      if (publisher != null) {\n+        publisher.close();\n+      }\n+    });\n+  }\n+\n+  public void handleBodyEnd(final Void v) {\n+    if (acksSubscriber == null) {\n+      routingContext.response().end();\n+    } else {\n+      // We close the response after the stream of acks has been sent\n+      acksSubscriber.insertsSent(rowsReceived);\n+    }\n+  }\n+\n+  public void handleBodyBuffer(final Buffer buff) {\n+    if (!readArguments) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQ1ODk0Mw==", "bodyText": "ack", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r369458943", "createdAt": "2020-01-22T09:48:44Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyParser.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.InsertsSubscriber;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.ext.web.RoutingContext;\n+import java.util.Objects;\n+\n+/**\n+ * This class handles the parsing of the request body for a stream of inserts. The user can send a\n+ * stream of inserts to the server by opening an HTTP2 request to the server at the appropriate uri\n+ * and POSTing a request. The request must contain an initial JSON object (encoded as UTF-8 text)\n+ * which contains the arguments for the request (e.g. the target to insert into, and whether acks\n+ * are wanted) This must be followed by a new line, and then followed by zero or more JSON objects\n+ * (also encoded as UTF-8 text) each representing a row to insert. The last JSON object must be\n+ * followed by a new-line.\n+ */\n+public class InsertsBodyParser {\n+\n+  private final Endpoints endpoints;\n+  private final RoutingContext routingContext;\n+  private boolean readArguments;\n+  private InsertsPublisher publisher;\n+  private long rowsReceived;\n+  private AcksSubscriber acksSubscriber;\n+\n+  public InsertsBodyParser(final Endpoints endpoints, final RoutingContext routingContext) {\n+    this.endpoints = Objects.requireNonNull(endpoints);\n+    this.routingContext = Objects.requireNonNull(routingContext);\n+    routingContext.response().endHandler(v -> {\n+      if (publisher != null) {\n+        publisher.close();\n+      }\n+    });\n+  }\n+\n+  public void handleBodyEnd(final Void v) {\n+    if (acksSubscriber == null) {\n+      routingContext.response().end();\n+    } else {\n+      // We close the response after the stream of acks has been sent\n+      acksSubscriber.insertsSent(rowsReceived);\n+    }\n+  }\n+\n+  public void handleBodyBuffer(final Buffer buff) {\n+    if (!readArguments) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA4NDk3OA=="}, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 66}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NDQ0MTUxOnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyParser.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QxODo1NDoyN1rOFfCJwA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQwOTo1MToxNFrOFgWEPA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA4NTQ0MA==", "bodyText": "I'm trying to understand the control flow here - if readArguments is true, and publisher is null (say because we handled an error) then should we be receiving any more body buffers? maybe we should throw an exception in a final else clause", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368085440", "createdAt": "2020-01-17T18:54:27Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyParser.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.InsertsSubscriber;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.ext.web.RoutingContext;\n+import java.util.Objects;\n+\n+/**\n+ * This class handles the parsing of the request body for a stream of inserts. The user can send a\n+ * stream of inserts to the server by opening an HTTP2 request to the server at the appropriate uri\n+ * and POSTing a request. The request must contain an initial JSON object (encoded as UTF-8 text)\n+ * which contains the arguments for the request (e.g. the target to insert into, and whether acks\n+ * are wanted) This must be followed by a new line, and then followed by zero or more JSON objects\n+ * (also encoded as UTF-8 text) each representing a row to insert. The last JSON object must be\n+ * followed by a new-line.\n+ */\n+public class InsertsBodyParser {\n+\n+  private final Endpoints endpoints;\n+  private final RoutingContext routingContext;\n+  private boolean readArguments;\n+  private InsertsPublisher publisher;\n+  private long rowsReceived;\n+  private AcksSubscriber acksSubscriber;\n+\n+  public InsertsBodyParser(final Endpoints endpoints, final RoutingContext routingContext) {\n+    this.endpoints = Objects.requireNonNull(endpoints);\n+    this.routingContext = Objects.requireNonNull(routingContext);\n+    routingContext.response().endHandler(v -> {\n+      if (publisher != null) {\n+        publisher.close();\n+      }\n+    });\n+  }\n+\n+  public void handleBodyEnd(final Void v) {\n+    if (acksSubscriber == null) {\n+      routingContext.response().end();\n+    } else {\n+      // We close the response after the stream of acks has been sent\n+      acksSubscriber.insertsSent(rowsReceived);\n+    }\n+  }\n+\n+  public void handleBodyBuffer(final Buffer buff) {\n+    if (!readArguments) {\n+      final JsonObject args = new JsonObject(buff);\n+      readArguments = true;\n+      final String target = args.getString(\"target\");\n+      if (target == null) {\n+        handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM,\n+            \"No target in arguments\");\n+        return;\n+      }\n+      final Boolean acks = args.getBoolean(\"acks\");\n+      if (acks == null) {\n+        handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM,\n+            \"No acks in arguments\");\n+        return;\n+      }\n+      final JsonObject properties = args.getJsonObject(\"properties\");\n+      routingContext.request().endHandler(this::handleBodyEnd);\n+      acksSubscriber = acks ? new AcksSubscriber(routingContext.response()) : null;\n+      final InsertsSubscriber insertsSubscriber = endpoints\n+          .createInsertsSubscriber(target, properties, acksSubscriber);\n+      publisher = new InsertsPublisher();\n+      publisher.subscribe(insertsSubscriber);\n+    } else if (publisher != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQ2MDI4NA==", "bodyText": "It seems correct to me. If arguments have been read and publisher is null then we drop any more buffers coming in. Note the the client may have written many inserts to the wire before we handle the args so it should be expected more will arrive after validation error", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r369460284", "createdAt": "2020-01-22T09:51:14Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyParser.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.InsertsSubscriber;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.ext.web.RoutingContext;\n+import java.util.Objects;\n+\n+/**\n+ * This class handles the parsing of the request body for a stream of inserts. The user can send a\n+ * stream of inserts to the server by opening an HTTP2 request to the server at the appropriate uri\n+ * and POSTing a request. The request must contain an initial JSON object (encoded as UTF-8 text)\n+ * which contains the arguments for the request (e.g. the target to insert into, and whether acks\n+ * are wanted) This must be followed by a new line, and then followed by zero or more JSON objects\n+ * (also encoded as UTF-8 text) each representing a row to insert. The last JSON object must be\n+ * followed by a new-line.\n+ */\n+public class InsertsBodyParser {\n+\n+  private final Endpoints endpoints;\n+  private final RoutingContext routingContext;\n+  private boolean readArguments;\n+  private InsertsPublisher publisher;\n+  private long rowsReceived;\n+  private AcksSubscriber acksSubscriber;\n+\n+  public InsertsBodyParser(final Endpoints endpoints, final RoutingContext routingContext) {\n+    this.endpoints = Objects.requireNonNull(endpoints);\n+    this.routingContext = Objects.requireNonNull(routingContext);\n+    routingContext.response().endHandler(v -> {\n+      if (publisher != null) {\n+        publisher.close();\n+      }\n+    });\n+  }\n+\n+  public void handleBodyEnd(final Void v) {\n+    if (acksSubscriber == null) {\n+      routingContext.response().end();\n+    } else {\n+      // We close the response after the stream of acks has been sent\n+      acksSubscriber.insertsSent(rowsReceived);\n+    }\n+  }\n+\n+  public void handleBodyBuffer(final Buffer buff) {\n+    if (!readArguments) {\n+      final JsonObject args = new JsonObject(buff);\n+      readArguments = true;\n+      final String target = args.getString(\"target\");\n+      if (target == null) {\n+        handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM,\n+            \"No target in arguments\");\n+        return;\n+      }\n+      final Boolean acks = args.getBoolean(\"acks\");\n+      if (acks == null) {\n+        handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM,\n+            \"No acks in arguments\");\n+        return;\n+      }\n+      final JsonObject properties = args.getJsonObject(\"properties\");\n+      routingContext.request().endHandler(this::handleBodyEnd);\n+      acksSubscriber = acks ? new AcksSubscriber(routingContext.response()) : null;\n+      final InsertsSubscriber insertsSubscriber = endpoints\n+          .createInsertsSubscriber(target, properties, acksSubscriber);\n+      publisher = new InsertsPublisher();\n+      publisher.subscribe(insertsSubscriber);\n+    } else if (publisher != null) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA4NTQ0MA=="}, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 88}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NDU0NDk3OnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsPublisher.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QxOTozMzo1MlrOFfDJ_Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQwOTo1MToyOFrOFgWEnQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwMTg4NQ==", "bodyText": "can this be private?", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368101885", "createdAt": "2020-01-17T19:33:52Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsPublisher.java", "diffHunk": "@@ -0,0 +1,83 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.json.JsonObject;\n+import java.util.LinkedList;\n+import java.util.Objects;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+\n+/**\n+ * This class is a reactive streams publisher which publishes the inserts to a subscriber which is\n+ * provided by the back-end. As it's reactive streams it supports back pressure.\n+ */\n+public class InsertsPublisher implements Publisher<JsonObject> {\n+\n+  private final Queue<JsonObject> buffer = new LinkedList<>();\n+  private long demand;\n+  private Subscriber<? super JsonObject> subscriber;\n+\n+  @Override\n+  public synchronized void subscribe(final Subscriber<? super JsonObject> subscriber) {\n+    this.subscriber = Objects.requireNonNull(subscriber);\n+    subscriber.onSubscribe(new InsertsSubscription());\n+  }\n+\n+  public synchronized void receiveRow(final JsonObject row) {\n+    if (subscriber == null) {\n+      return;\n+    }\n+    if (demand > 0) {\n+      demand--;\n+      subscriber.onNext(row);\n+    } else {\n+      buffer.add(row);\n+    }\n+  }\n+\n+  synchronized void acceptTokens(final long number) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQ2MDM4MQ==", "bodyText": "out of date", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r369460381", "createdAt": "2020-01-22T09:51:28Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsPublisher.java", "diffHunk": "@@ -0,0 +1,83 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.json.JsonObject;\n+import java.util.LinkedList;\n+import java.util.Objects;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+\n+/**\n+ * This class is a reactive streams publisher which publishes the inserts to a subscriber which is\n+ * provided by the back-end. As it's reactive streams it supports back pressure.\n+ */\n+public class InsertsPublisher implements Publisher<JsonObject> {\n+\n+  private final Queue<JsonObject> buffer = new LinkedList<>();\n+  private long demand;\n+  private Subscriber<? super JsonObject> subscriber;\n+\n+  @Override\n+  public synchronized void subscribe(final Subscriber<? super JsonObject> subscriber) {\n+    this.subscriber = Objects.requireNonNull(subscriber);\n+    subscriber.onSubscribe(new InsertsSubscription());\n+  }\n+\n+  public synchronized void receiveRow(final JsonObject row) {\n+    if (subscriber == null) {\n+      return;\n+    }\n+    if (demand > 0) {\n+      demand--;\n+      subscriber.onNext(row);\n+    } else {\n+      buffer.add(row);\n+    }\n+  }\n+\n+  synchronized void acceptTokens(final long number) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwMTg4NQ=="}, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 54}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NDU1NDYwOnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsPublisher.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QxOTozNzo1MFrOFfDQEQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQwOTo1MTozN1rOFgWE9A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwMzQ0MQ==", "bodyText": "what happens if demand goes below 0. Is that Okay?", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368103441", "createdAt": "2020-01-17T19:37:50Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsPublisher.java", "diffHunk": "@@ -0,0 +1,83 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.json.JsonObject;\n+import java.util.LinkedList;\n+import java.util.Objects;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+\n+/**\n+ * This class is a reactive streams publisher which publishes the inserts to a subscriber which is\n+ * provided by the back-end. As it's reactive streams it supports back pressure.\n+ */\n+public class InsertsPublisher implements Publisher<JsonObject> {\n+\n+  private final Queue<JsonObject> buffer = new LinkedList<>();\n+  private long demand;\n+  private Subscriber<? super JsonObject> subscriber;\n+\n+  @Override\n+  public synchronized void subscribe(final Subscriber<? super JsonObject> subscriber) {\n+    this.subscriber = Objects.requireNonNull(subscriber);\n+    subscriber.onSubscribe(new InsertsSubscription());\n+  }\n+\n+  public synchronized void receiveRow(final JsonObject row) {\n+    if (subscriber == null) {\n+      return;\n+    }\n+    if (demand > 0) {\n+      demand--;\n+      subscriber.onNext(row);\n+    } else {\n+      buffer.add(row);\n+    }\n+  }\n+\n+  synchronized void acceptTokens(final long number) {\n+    demand += number;\n+    for (int i = 0; i < buffer.size(); i++) {\n+      final JsonObject row = buffer.poll();\n+      demand--;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQ2MDQ2OA==", "bodyText": "out of date", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r369460468", "createdAt": "2020-01-22T09:51:37Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsPublisher.java", "diffHunk": "@@ -0,0 +1,83 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.json.JsonObject;\n+import java.util.LinkedList;\n+import java.util.Objects;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+\n+/**\n+ * This class is a reactive streams publisher which publishes the inserts to a subscriber which is\n+ * provided by the back-end. As it's reactive streams it supports back pressure.\n+ */\n+public class InsertsPublisher implements Publisher<JsonObject> {\n+\n+  private final Queue<JsonObject> buffer = new LinkedList<>();\n+  private long demand;\n+  private Subscriber<? super JsonObject> subscriber;\n+\n+  @Override\n+  public synchronized void subscribe(final Subscriber<? super JsonObject> subscriber) {\n+    this.subscriber = Objects.requireNonNull(subscriber);\n+    subscriber.onSubscribe(new InsertsSubscription());\n+  }\n+\n+  public synchronized void receiveRow(final JsonObject row) {\n+    if (subscriber == null) {\n+      return;\n+    }\n+    if (demand > 0) {\n+      demand--;\n+      subscriber.onNext(row);\n+    } else {\n+      buffer.add(row);\n+    }\n+  }\n+\n+  synchronized void acceptTokens(final long number) {\n+    demand += number;\n+    for (int i = 0; i < buffer.size(); i++) {\n+      final JsonObject row = buffer.poll();\n+      demand--;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwMzQ0MQ=="}, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 58}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NDU1OTUyOnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsPublisher.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QxOTozOTo0NFrOFfDTDw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQwOTo1MTo0N1rOFgWFPA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwNDIwNw==", "bodyText": "since this is a blocking operation, does it need to be inside the synchronized block? I'm worried all of these interlocking synchronized calls may cause some deadlocks at some point \ud83d\ude02 perhaps we can cross that bridge when we get there though", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368104207", "createdAt": "2020-01-17T19:39:44Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsPublisher.java", "diffHunk": "@@ -0,0 +1,83 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.json.JsonObject;\n+import java.util.LinkedList;\n+import java.util.Objects;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+\n+/**\n+ * This class is a reactive streams publisher which publishes the inserts to a subscriber which is\n+ * provided by the back-end. As it's reactive streams it supports back pressure.\n+ */\n+public class InsertsPublisher implements Publisher<JsonObject> {\n+\n+  private final Queue<JsonObject> buffer = new LinkedList<>();\n+  private long demand;\n+  private Subscriber<? super JsonObject> subscriber;\n+\n+  @Override\n+  public synchronized void subscribe(final Subscriber<? super JsonObject> subscriber) {\n+    this.subscriber = Objects.requireNonNull(subscriber);\n+    subscriber.onSubscribe(new InsertsSubscription());\n+  }\n+\n+  public synchronized void receiveRow(final JsonObject row) {\n+    if (subscriber == null) {\n+      return;\n+    }\n+    if (demand > 0) {\n+      demand--;\n+      subscriber.onNext(row);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQ2MDU0MA==", "bodyText": "out of date", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r369460540", "createdAt": "2020-01-22T09:51:47Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsPublisher.java", "diffHunk": "@@ -0,0 +1,83 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.json.JsonObject;\n+import java.util.LinkedList;\n+import java.util.Objects;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+\n+/**\n+ * This class is a reactive streams publisher which publishes the inserts to a subscriber which is\n+ * provided by the back-end. As it's reactive streams it supports back pressure.\n+ */\n+public class InsertsPublisher implements Publisher<JsonObject> {\n+\n+  private final Queue<JsonObject> buffer = new LinkedList<>();\n+  private long demand;\n+  private Subscriber<? super JsonObject> subscriber;\n+\n+  @Override\n+  public synchronized void subscribe(final Subscriber<? super JsonObject> subscriber) {\n+    this.subscriber = Objects.requireNonNull(subscriber);\n+    subscriber.onSubscribe(new InsertsSubscription());\n+  }\n+\n+  public synchronized void receiveRow(final JsonObject row) {\n+    if (subscriber == null) {\n+      return;\n+    }\n+    if (demand > 0) {\n+      demand--;\n+      subscriber.onNext(row);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwNDIwNw=="}, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 48}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NDU2MDEwOnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/QueryID.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QxOTozOTo1N1rOFfDTbA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQwOTo1MTo1NVrOFgWFfQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwNDMwMA==", "bodyText": "nit: 2020", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368104300", "createdAt": "2020-01-17T19:39:57Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/QueryID.java", "diffHunk": "@@ -0,0 +1,60 @@\n+/*\n+ * Copyright 2019 Confluent Inc.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 2}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQ2MDYwNQ==", "bodyText": "ack", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r369460605", "createdAt": "2020-01-22T09:51:55Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/QueryID.java", "diffHunk": "@@ -0,0 +1,60 @@\n+/*\n+ * Copyright 2019 Confluent Inc.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwNDMwMA=="}, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 2}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NDU2Mjc4OnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/QueryID.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QxOTo0MDo1NVrOFfDVBw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQwOTo1Mjo0N1rOFgWHKg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwNDcxMQ==", "bodyText": "We already have a QueryID class in the code base - can we name this something more descriptive? Maybe this one should be ClientQueryId and the other PersistentQueryId", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368104711", "createdAt": "2020-01-17T19:40:55Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/QueryID.java", "diffHunk": "@@ -0,0 +1,60 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import java.util.Objects;\n+import java.util.UUID;\n+\n+/**\n+ * Handle to a query that is passed to the client on query creation and can subsequently be used to\n+ * close a query. Uses UUID.randomUUID() which internally uses SecureRandom - this makes the id\n+ * cryptographically secure. This is important as we don't want random users guessing query IDs and\n+ * closing other peoples queries.\n+ */\n+public final class QueryID {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODY1NjIzNQ==", "bodyText": "Not PersistentQueryId.. we already have persitent queries...", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368656235", "createdAt": "2020-01-20T17:13:45Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/QueryID.java", "diffHunk": "@@ -0,0 +1,60 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import java.util.Objects;\n+import java.util.UUID;\n+\n+/**\n+ * Handle to a query that is passed to the client on query creation and can subsequently be used to\n+ * close a query. Uses UUID.randomUUID() which internally uses SecureRandom - this makes the id\n+ * cryptographically secure. This is important as we don't want random users guessing query IDs and\n+ * closing other peoples queries.\n+ */\n+public final class QueryID {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwNDcxMQ=="}, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQ2MTAzNA==", "bodyText": "ack", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r369461034", "createdAt": "2020-01-22T09:52:47Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/QueryID.java", "diffHunk": "@@ -0,0 +1,60 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import java.util.Objects;\n+import java.util.UUID;\n+\n+/**\n+ * Handle to a query that is passed to the client on query creation and can subsequently be used to\n+ * close a query. Uses UUID.randomUUID() which internally uses SecureRandom - this makes the id\n+ * cryptographically secure. This is important as we don't want random users guessing query IDs and\n+ * closing other peoples queries.\n+ */\n+public final class QueryID {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwNDcxMQ=="}, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 27}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NDU2OTgyOnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QxOTo0Mzo0OFrOFfDZhA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQwOTo1MzowMFrOFgWHpQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwNTg2MA==", "bodyText": "same comment as above - whitespace please if you're so kind \ud83d\ude4f", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368105860", "createdAt": "2020-01-17T19:43:48Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.util.KsqlException;\n+import io.vertx.core.DeploymentOptions;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.impl.ConcurrentHashSet;\n+import io.vertx.core.json.JsonObject;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class represents the API server. On start-up it deploys multiple server verticles to spread\n+ * the load across available cores.\n+ */\n+public class Server {\n+\n+  private static final Logger log = LoggerFactory.getLogger(Server.class);\n+\n+  private final Vertx vertx;\n+  private final JsonObject config;\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Map<QueryID, QuerySubscriber> queries = new ConcurrentHashMap<>();\n+  private final Set<HttpConnection> connections = new ConcurrentHashSet<>();\n+  private String deploymentID;\n+\n+  public Server(final Vertx vertx, final JsonObject config, final Endpoints endpoints,\n+      final HttpServerOptions httpServerOptions) {\n+    this.vertx = Objects.requireNonNull(vertx);\n+    this.config = Objects.requireNonNull(config);\n+    this.endpoints = Objects.requireNonNull(endpoints);\n+    this.httpServerOptions = Objects.requireNonNull(httpServerOptions);\n+  }\n+\n+  public synchronized void start() {\n+    if (deploymentID != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQ2MTE1Nw==", "bodyText": "noted", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r369461157", "createdAt": "2020-01-22T09:53:00Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.util.KsqlException;\n+import io.vertx.core.DeploymentOptions;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.impl.ConcurrentHashSet;\n+import io.vertx.core.json.JsonObject;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class represents the API server. On start-up it deploys multiple server verticles to spread\n+ * the load across available cores.\n+ */\n+public class Server {\n+\n+  private static final Logger log = LoggerFactory.getLogger(Server.class);\n+\n+  private final Vertx vertx;\n+  private final JsonObject config;\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Map<QueryID, QuerySubscriber> queries = new ConcurrentHashMap<>();\n+  private final Set<HttpConnection> connections = new ConcurrentHashSet<>();\n+  private String deploymentID;\n+\n+  public Server(final Vertx vertx, final JsonObject config, final Endpoints endpoints,\n+      final HttpServerOptions httpServerOptions) {\n+    this.vertx = Objects.requireNonNull(vertx);\n+    this.config = Objects.requireNonNull(config);\n+    this.endpoints = Objects.requireNonNull(endpoints);\n+    this.httpServerOptions = Objects.requireNonNull(httpServerOptions);\n+  }\n+\n+  public synchronized void start() {\n+    if (deploymentID != null) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwNTg2MA=="}, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 60}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NDU3MjI2OnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QxOTo0NDo1MFrOFfDbDw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQwOTo1MzoyOVrOFgWIqw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwNjI1NQ==", "bodyText": "nit: ksql configurations are usually . separated or camel case (e.g. ksql.vertex.verticleInstances", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368106255", "createdAt": "2020-01-17T19:44:50Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.util.KsqlException;\n+import io.vertx.core.DeploymentOptions;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.impl.ConcurrentHashSet;\n+import io.vertx.core.json.JsonObject;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class represents the API server. On start-up it deploys multiple server verticles to spread\n+ * the load across available cores.\n+ */\n+public class Server {\n+\n+  private static final Logger log = LoggerFactory.getLogger(Server.class);\n+\n+  private final Vertx vertx;\n+  private final JsonObject config;\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Map<QueryID, QuerySubscriber> queries = new ConcurrentHashMap<>();\n+  private final Set<HttpConnection> connections = new ConcurrentHashSet<>();\n+  private String deploymentID;\n+\n+  public Server(final Vertx vertx, final JsonObject config, final Endpoints endpoints,\n+      final HttpServerOptions httpServerOptions) {\n+    this.vertx = Objects.requireNonNull(vertx);\n+    this.config = Objects.requireNonNull(config);\n+    this.endpoints = Objects.requireNonNull(endpoints);\n+    this.httpServerOptions = Objects.requireNonNull(httpServerOptions);\n+  }\n+\n+  public synchronized void start() {\n+    if (deploymentID != null) {\n+      throw new IllegalStateException(\"Already started\");\n+    }\n+    final DeploymentOptions options = new DeploymentOptions();\n+    final Integer verticleInstances = config.getInteger(\"verticle-instances\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQ2MTQxOQ==", "bodyText": "out of date with AbstractConfig PR", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r369461419", "createdAt": "2020-01-22T09:53:29Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.util.KsqlException;\n+import io.vertx.core.DeploymentOptions;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.impl.ConcurrentHashSet;\n+import io.vertx.core.json.JsonObject;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class represents the API server. On start-up it deploys multiple server verticles to spread\n+ * the load across available cores.\n+ */\n+public class Server {\n+\n+  private static final Logger log = LoggerFactory.getLogger(Server.class);\n+\n+  private final Vertx vertx;\n+  private final JsonObject config;\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Map<QueryID, QuerySubscriber> queries = new ConcurrentHashMap<>();\n+  private final Set<HttpConnection> connections = new ConcurrentHashSet<>();\n+  private String deploymentID;\n+\n+  public Server(final Vertx vertx, final JsonObject config, final Endpoints endpoints,\n+      final HttpServerOptions httpServerOptions) {\n+    this.vertx = Objects.requireNonNull(vertx);\n+    this.config = Objects.requireNonNull(config);\n+    this.endpoints = Objects.requireNonNull(endpoints);\n+    this.httpServerOptions = Objects.requireNonNull(httpServerOptions);\n+  }\n+\n+  public synchronized void start() {\n+    if (deploymentID != null) {\n+      throw new IllegalStateException(\"Already started\");\n+    }\n+    final DeploymentOptions options = new DeploymentOptions();\n+    final Integer verticleInstances = config.getInteger(\"verticle-instances\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwNjI1NQ=="}, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 64}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NDU3NTM3OnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QxOTo0NTo1MVrOFfDc3w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQwOTo1NDoxM1rOFgWKLQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwNjcxOQ==", "bodyText": "can we just return? if we never started do we need to throw an exception?", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368106719", "createdAt": "2020-01-17T19:45:51Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.util.KsqlException;\n+import io.vertx.core.DeploymentOptions;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.impl.ConcurrentHashSet;\n+import io.vertx.core.json.JsonObject;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class represents the API server. On start-up it deploys multiple server verticles to spread\n+ * the load across available cores.\n+ */\n+public class Server {\n+\n+  private static final Logger log = LoggerFactory.getLogger(Server.class);\n+\n+  private final Vertx vertx;\n+  private final JsonObject config;\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Map<QueryID, QuerySubscriber> queries = new ConcurrentHashMap<>();\n+  private final Set<HttpConnection> connections = new ConcurrentHashSet<>();\n+  private String deploymentID;\n+\n+  public Server(final Vertx vertx, final JsonObject config, final Endpoints endpoints,\n+      final HttpServerOptions httpServerOptions) {\n+    this.vertx = Objects.requireNonNull(vertx);\n+    this.config = Objects.requireNonNull(config);\n+    this.endpoints = Objects.requireNonNull(endpoints);\n+    this.httpServerOptions = Objects.requireNonNull(httpServerOptions);\n+  }\n+\n+  public synchronized void start() {\n+    if (deploymentID != null) {\n+      throw new IllegalStateException(\"Already started\");\n+    }\n+    final DeploymentOptions options = new DeploymentOptions();\n+    final Integer verticleInstances = config.getInteger(\"verticle-instances\");\n+    if (verticleInstances == null) {\n+      options.setInstances(Runtime.getRuntime().availableProcessors() * 2);\n+    } else {\n+      options.setInstances(verticleInstances);\n+    }\n+    log.info(\"Deploying \" + options.getInstances() + \" instances of server verticle\");\n+    options.setConfig(config);\n+    final VertxCompletableFuture<String> future = new VertxCompletableFuture<>();\n+    vertx.deployVerticle(\n+        () -> new ServerVerticle(endpoints, httpServerOptions, this), options, future);\n+    try {\n+      deploymentID = future.get();\n+    } catch (Exception e) {\n+      throw new KsqlException(\"Failed to start API server\", e);\n+    }\n+    log.info(\"API server started: \" + deploymentID);\n+  }\n+\n+  public synchronized void stop() {\n+    if (deploymentID == null) {\n+      throw new IllegalStateException(\"Not started\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQ2MTgwNQ==", "bodyText": "I like throwing an exception as it can highlight errors in the callers life cycle management code.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r369461805", "createdAt": "2020-01-22T09:54:13Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.util.KsqlException;\n+import io.vertx.core.DeploymentOptions;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.impl.ConcurrentHashSet;\n+import io.vertx.core.json.JsonObject;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class represents the API server. On start-up it deploys multiple server verticles to spread\n+ * the load across available cores.\n+ */\n+public class Server {\n+\n+  private static final Logger log = LoggerFactory.getLogger(Server.class);\n+\n+  private final Vertx vertx;\n+  private final JsonObject config;\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Map<QueryID, QuerySubscriber> queries = new ConcurrentHashMap<>();\n+  private final Set<HttpConnection> connections = new ConcurrentHashSet<>();\n+  private String deploymentID;\n+\n+  public Server(final Vertx vertx, final JsonObject config, final Endpoints endpoints,\n+      final HttpServerOptions httpServerOptions) {\n+    this.vertx = Objects.requireNonNull(vertx);\n+    this.config = Objects.requireNonNull(config);\n+    this.endpoints = Objects.requireNonNull(endpoints);\n+    this.httpServerOptions = Objects.requireNonNull(httpServerOptions);\n+  }\n+\n+  public synchronized void start() {\n+    if (deploymentID != null) {\n+      throw new IllegalStateException(\"Already started\");\n+    }\n+    final DeploymentOptions options = new DeploymentOptions();\n+    final Integer verticleInstances = config.getInteger(\"verticle-instances\");\n+    if (verticleInstances == null) {\n+      options.setInstances(Runtime.getRuntime().availableProcessors() * 2);\n+    } else {\n+      options.setInstances(verticleInstances);\n+    }\n+    log.info(\"Deploying \" + options.getInstances() + \" instances of server verticle\");\n+    options.setConfig(config);\n+    final VertxCompletableFuture<String> future = new VertxCompletableFuture<>();\n+    vertx.deployVerticle(\n+        () -> new ServerVerticle(endpoints, httpServerOptions, this), options, future);\n+    try {\n+      deploymentID = future.get();\n+    } catch (Exception e) {\n+      throw new KsqlException(\"Failed to start API server\", e);\n+    }\n+    log.info(\"API server started: \" + deploymentID);\n+  }\n+\n+  public synchronized void stop() {\n+    if (deploymentID == null) {\n+      throw new IllegalStateException(\"Not started\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwNjcxOQ=="}, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 85}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NDU3ODYyOnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QxOTo0NzoxM1rOFfDe8g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQwOTo1Nzo1NVrOFgWSDg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwNzI1MA==", "bodyText": "I think it could be nice to model this using Guava's AbstractIdleService which handles transitions between nascent, starting, running, shutting down, shutdown and failure. We can add a ticket for this to be done in the future", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368107250", "createdAt": "2020-01-17T19:47:13Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.util.KsqlException;\n+import io.vertx.core.DeploymentOptions;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.impl.ConcurrentHashSet;\n+import io.vertx.core.json.JsonObject;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class represents the API server. On start-up it deploys multiple server verticles to spread\n+ * the load across available cores.\n+ */\n+public class Server {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQ2MzgyMg==", "bodyText": "I would rather not use 3rd party libraries unless there is an extremely good reason to. I appreciate my bar is probably higher in this regard to others in the team.\nThis comes from many years writing frameworks and clients where it's super important to have minimal deps as they will be dragged into the user's application too. The more deps you have the longer the build, the bigger the binary size, and the probability of version clashes gets higher (especially with commonly used libs such as apache commons or Guava), and the surface area for security issues increases. Not to mention the barrier to entry for a new developer gets higher as they have to understand N libraries in order to understand the code.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r369463822", "createdAt": "2020-01-22T09:57:55Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.util.KsqlException;\n+import io.vertx.core.DeploymentOptions;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.impl.ConcurrentHashSet;\n+import io.vertx.core.json.JsonObject;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class represents the API server. On start-up it deploys multiple server verticles to spread\n+ * the load across available cores.\n+ */\n+public class Server {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwNzI1MA=="}, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 39}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NDU4MzMxOnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QxOTo0OTowNlrOFfDh3A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQxMDowMDoxMFrOFgWWwQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwNzk5Ng==", "bodyText": "putIfAbsent to avoid races in the (very) unlikely chance of a collision", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368107996", "createdAt": "2020-01-17T19:49:06Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.util.KsqlException;\n+import io.vertx.core.DeploymentOptions;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.impl.ConcurrentHashSet;\n+import io.vertx.core.json.JsonObject;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class represents the API server. On start-up it deploys multiple server verticles to spread\n+ * the load across available cores.\n+ */\n+public class Server {\n+\n+  private static final Logger log = LoggerFactory.getLogger(Server.class);\n+\n+  private final Vertx vertx;\n+  private final JsonObject config;\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Map<QueryID, QuerySubscriber> queries = new ConcurrentHashMap<>();\n+  private final Set<HttpConnection> connections = new ConcurrentHashSet<>();\n+  private String deploymentID;\n+\n+  public Server(final Vertx vertx, final JsonObject config, final Endpoints endpoints,\n+      final HttpServerOptions httpServerOptions) {\n+    this.vertx = Objects.requireNonNull(vertx);\n+    this.config = Objects.requireNonNull(config);\n+    this.endpoints = Objects.requireNonNull(endpoints);\n+    this.httpServerOptions = Objects.requireNonNull(httpServerOptions);\n+  }\n+\n+  public synchronized void start() {\n+    if (deploymentID != null) {\n+      throw new IllegalStateException(\"Already started\");\n+    }\n+    final DeploymentOptions options = new DeploymentOptions();\n+    final Integer verticleInstances = config.getInteger(\"verticle-instances\");\n+    if (verticleInstances == null) {\n+      options.setInstances(Runtime.getRuntime().availableProcessors() * 2);\n+    } else {\n+      options.setInstances(verticleInstances);\n+    }\n+    log.info(\"Deploying \" + options.getInstances() + \" instances of server verticle\");\n+    options.setConfig(config);\n+    final VertxCompletableFuture<String> future = new VertxCompletableFuture<>();\n+    vertx.deployVerticle(\n+        () -> new ServerVerticle(endpoints, httpServerOptions, this), options, future);\n+    try {\n+      deploymentID = future.get();\n+    } catch (Exception e) {\n+      throw new KsqlException(\"Failed to start API server\", e);\n+    }\n+    log.info(\"API server started: \" + deploymentID);\n+  }\n+\n+  public synchronized void stop() {\n+    if (deploymentID == null) {\n+      throw new IllegalStateException(\"Not started\");\n+    }\n+    final VertxCompletableFuture<Void> future = new VertxCompletableFuture<>();\n+    vertx.undeploy(deploymentID, future);\n+    try {\n+      future.get();\n+    } catch (Exception e) {\n+      throw new KsqlException(\"Failure in stopping API server\", e);\n+    }\n+  }\n+\n+  QueryID registerQuery(final QuerySubscriber querySubscriber) {\n+    Objects.requireNonNull(querySubscriber);\n+    final QueryID queryID = new QueryID();\n+    queries.put(queryID, querySubscriber);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 99}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQ2NTAyNQ==", "bodyText": "It won't happen, QueryID wraps a crytographically secure (i.e. evenly distributed) random UUID.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r369465025", "createdAt": "2020-01-22T10:00:10Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.util.KsqlException;\n+import io.vertx.core.DeploymentOptions;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.impl.ConcurrentHashSet;\n+import io.vertx.core.json.JsonObject;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class represents the API server. On start-up it deploys multiple server verticles to spread\n+ * the load across available cores.\n+ */\n+public class Server {\n+\n+  private static final Logger log = LoggerFactory.getLogger(Server.class);\n+\n+  private final Vertx vertx;\n+  private final JsonObject config;\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Map<QueryID, QuerySubscriber> queries = new ConcurrentHashMap<>();\n+  private final Set<HttpConnection> connections = new ConcurrentHashSet<>();\n+  private String deploymentID;\n+\n+  public Server(final Vertx vertx, final JsonObject config, final Endpoints endpoints,\n+      final HttpServerOptions httpServerOptions) {\n+    this.vertx = Objects.requireNonNull(vertx);\n+    this.config = Objects.requireNonNull(config);\n+    this.endpoints = Objects.requireNonNull(endpoints);\n+    this.httpServerOptions = Objects.requireNonNull(httpServerOptions);\n+  }\n+\n+  public synchronized void start() {\n+    if (deploymentID != null) {\n+      throw new IllegalStateException(\"Already started\");\n+    }\n+    final DeploymentOptions options = new DeploymentOptions();\n+    final Integer verticleInstances = config.getInteger(\"verticle-instances\");\n+    if (verticleInstances == null) {\n+      options.setInstances(Runtime.getRuntime().availableProcessors() * 2);\n+    } else {\n+      options.setInstances(verticleInstances);\n+    }\n+    log.info(\"Deploying \" + options.getInstances() + \" instances of server verticle\");\n+    options.setConfig(config);\n+    final VertxCompletableFuture<String> future = new VertxCompletableFuture<>();\n+    vertx.deployVerticle(\n+        () -> new ServerVerticle(endpoints, httpServerOptions, this), options, future);\n+    try {\n+      deploymentID = future.get();\n+    } catch (Exception e) {\n+      throw new KsqlException(\"Failed to start API server\", e);\n+    }\n+    log.info(\"API server started: \" + deploymentID);\n+  }\n+\n+  public synchronized void stop() {\n+    if (deploymentID == null) {\n+      throw new IllegalStateException(\"Not started\");\n+    }\n+    final VertxCompletableFuture<Void> future = new VertxCompletableFuture<>();\n+    vertx.undeploy(deploymentID, future);\n+    try {\n+      future.get();\n+    } catch (Exception e) {\n+      throw new KsqlException(\"Failure in stopping API server\", e);\n+    }\n+  }\n+\n+  QueryID registerQuery(final QuerySubscriber querySubscriber) {\n+    Objects.requireNonNull(querySubscriber);\n+    final QueryID queryID = new QueryID();\n+    queries.put(queryID, querySubscriber);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwNzk5Ng=="}, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 99}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NDU4NTc4OnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QxOTo1MDowMlrOFfDjSw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQxMDowMTowOFrOFgWY0g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwODM2Mw==", "bodyText": "we should document that this can return null if the query doesnt' exist (or maybe instead just return an Optional to indicate that)", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368108363", "createdAt": "2020-01-17T19:50:02Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.util.KsqlException;\n+import io.vertx.core.DeploymentOptions;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.impl.ConcurrentHashSet;\n+import io.vertx.core.json.JsonObject;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class represents the API server. On start-up it deploys multiple server verticles to spread\n+ * the load across available cores.\n+ */\n+public class Server {\n+\n+  private static final Logger log = LoggerFactory.getLogger(Server.class);\n+\n+  private final Vertx vertx;\n+  private final JsonObject config;\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Map<QueryID, QuerySubscriber> queries = new ConcurrentHashMap<>();\n+  private final Set<HttpConnection> connections = new ConcurrentHashSet<>();\n+  private String deploymentID;\n+\n+  public Server(final Vertx vertx, final JsonObject config, final Endpoints endpoints,\n+      final HttpServerOptions httpServerOptions) {\n+    this.vertx = Objects.requireNonNull(vertx);\n+    this.config = Objects.requireNonNull(config);\n+    this.endpoints = Objects.requireNonNull(endpoints);\n+    this.httpServerOptions = Objects.requireNonNull(httpServerOptions);\n+  }\n+\n+  public synchronized void start() {\n+    if (deploymentID != null) {\n+      throw new IllegalStateException(\"Already started\");\n+    }\n+    final DeploymentOptions options = new DeploymentOptions();\n+    final Integer verticleInstances = config.getInteger(\"verticle-instances\");\n+    if (verticleInstances == null) {\n+      options.setInstances(Runtime.getRuntime().availableProcessors() * 2);\n+    } else {\n+      options.setInstances(verticleInstances);\n+    }\n+    log.info(\"Deploying \" + options.getInstances() + \" instances of server verticle\");\n+    options.setConfig(config);\n+    final VertxCompletableFuture<String> future = new VertxCompletableFuture<>();\n+    vertx.deployVerticle(\n+        () -> new ServerVerticle(endpoints, httpServerOptions, this), options, future);\n+    try {\n+      deploymentID = future.get();\n+    } catch (Exception e) {\n+      throw new KsqlException(\"Failed to start API server\", e);\n+    }\n+    log.info(\"API server started: \" + deploymentID);\n+  }\n+\n+  public synchronized void stop() {\n+    if (deploymentID == null) {\n+      throw new IllegalStateException(\"Not started\");\n+    }\n+    final VertxCompletableFuture<Void> future = new VertxCompletableFuture<>();\n+    vertx.undeploy(deploymentID, future);\n+    try {\n+      future.get();\n+    } catch (Exception e) {\n+      throw new KsqlException(\"Failure in stopping API server\", e);\n+    }\n+  }\n+\n+  QueryID registerQuery(final QuerySubscriber querySubscriber) {\n+    Objects.requireNonNull(querySubscriber);\n+    final QueryID queryID = new QueryID();\n+    queries.put(queryID, querySubscriber);\n+    return queryID;\n+  }\n+\n+  QuerySubscriber removeQuery(final QueryID queryID) {\n+    return queries.remove(queryID);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 104}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQ2NTU1NA==", "bodyText": "Most probably this will change before production so I want to hold off putting in too much Javadoc", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r369465554", "createdAt": "2020-01-22T10:01:08Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.util.KsqlException;\n+import io.vertx.core.DeploymentOptions;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.impl.ConcurrentHashSet;\n+import io.vertx.core.json.JsonObject;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class represents the API server. On start-up it deploys multiple server verticles to spread\n+ * the load across available cores.\n+ */\n+public class Server {\n+\n+  private static final Logger log = LoggerFactory.getLogger(Server.class);\n+\n+  private final Vertx vertx;\n+  private final JsonObject config;\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Map<QueryID, QuerySubscriber> queries = new ConcurrentHashMap<>();\n+  private final Set<HttpConnection> connections = new ConcurrentHashSet<>();\n+  private String deploymentID;\n+\n+  public Server(final Vertx vertx, final JsonObject config, final Endpoints endpoints,\n+      final HttpServerOptions httpServerOptions) {\n+    this.vertx = Objects.requireNonNull(vertx);\n+    this.config = Objects.requireNonNull(config);\n+    this.endpoints = Objects.requireNonNull(endpoints);\n+    this.httpServerOptions = Objects.requireNonNull(httpServerOptions);\n+  }\n+\n+  public synchronized void start() {\n+    if (deploymentID != null) {\n+      throw new IllegalStateException(\"Already started\");\n+    }\n+    final DeploymentOptions options = new DeploymentOptions();\n+    final Integer verticleInstances = config.getInteger(\"verticle-instances\");\n+    if (verticleInstances == null) {\n+      options.setInstances(Runtime.getRuntime().availableProcessors() * 2);\n+    } else {\n+      options.setInstances(verticleInstances);\n+    }\n+    log.info(\"Deploying \" + options.getInstances() + \" instances of server verticle\");\n+    options.setConfig(config);\n+    final VertxCompletableFuture<String> future = new VertxCompletableFuture<>();\n+    vertx.deployVerticle(\n+        () -> new ServerVerticle(endpoints, httpServerOptions, this), options, future);\n+    try {\n+      deploymentID = future.get();\n+    } catch (Exception e) {\n+      throw new KsqlException(\"Failed to start API server\", e);\n+    }\n+    log.info(\"API server started: \" + deploymentID);\n+  }\n+\n+  public synchronized void stop() {\n+    if (deploymentID == null) {\n+      throw new IllegalStateException(\"Not started\");\n+    }\n+    final VertxCompletableFuture<Void> future = new VertxCompletableFuture<>();\n+    vertx.undeploy(deploymentID, future);\n+    try {\n+      future.get();\n+    } catch (Exception e) {\n+      throw new KsqlException(\"Failure in stopping API server\", e);\n+    }\n+  }\n+\n+  QueryID registerQuery(final QuerySubscriber querySubscriber) {\n+    Objects.requireNonNull(querySubscriber);\n+    final QueryID queryID = new QueryID();\n+    queries.put(queryID, querySubscriber);\n+    return queryID;\n+  }\n+\n+  QuerySubscriber removeQuery(final QueryID queryID) {\n+    return queries.remove(queryID);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwODM2Mw=="}, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 104}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NDU4NjkzOnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QxOTo1MDozMVrOFfDkBA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMFQxNzowNToyNFrOFfkyLg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwODU0OA==", "bodyText": "Maybe ImmutableSet.copyOf?", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368108548", "createdAt": "2020-01-17T19:50:31Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.util.KsqlException;\n+import io.vertx.core.DeploymentOptions;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.impl.ConcurrentHashSet;\n+import io.vertx.core.json.JsonObject;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class represents the API server. On start-up it deploys multiple server verticles to spread\n+ * the load across available cores.\n+ */\n+public class Server {\n+\n+  private static final Logger log = LoggerFactory.getLogger(Server.class);\n+\n+  private final Vertx vertx;\n+  private final JsonObject config;\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Map<QueryID, QuerySubscriber> queries = new ConcurrentHashMap<>();\n+  private final Set<HttpConnection> connections = new ConcurrentHashSet<>();\n+  private String deploymentID;\n+\n+  public Server(final Vertx vertx, final JsonObject config, final Endpoints endpoints,\n+      final HttpServerOptions httpServerOptions) {\n+    this.vertx = Objects.requireNonNull(vertx);\n+    this.config = Objects.requireNonNull(config);\n+    this.endpoints = Objects.requireNonNull(endpoints);\n+    this.httpServerOptions = Objects.requireNonNull(httpServerOptions);\n+  }\n+\n+  public synchronized void start() {\n+    if (deploymentID != null) {\n+      throw new IllegalStateException(\"Already started\");\n+    }\n+    final DeploymentOptions options = new DeploymentOptions();\n+    final Integer verticleInstances = config.getInteger(\"verticle-instances\");\n+    if (verticleInstances == null) {\n+      options.setInstances(Runtime.getRuntime().availableProcessors() * 2);\n+    } else {\n+      options.setInstances(verticleInstances);\n+    }\n+    log.info(\"Deploying \" + options.getInstances() + \" instances of server verticle\");\n+    options.setConfig(config);\n+    final VertxCompletableFuture<String> future = new VertxCompletableFuture<>();\n+    vertx.deployVerticle(\n+        () -> new ServerVerticle(endpoints, httpServerOptions, this), options, future);\n+    try {\n+      deploymentID = future.get();\n+    } catch (Exception e) {\n+      throw new KsqlException(\"Failed to start API server\", e);\n+    }\n+    log.info(\"API server started: \" + deploymentID);\n+  }\n+\n+  public synchronized void stop() {\n+    if (deploymentID == null) {\n+      throw new IllegalStateException(\"Not started\");\n+    }\n+    final VertxCompletableFuture<Void> future = new VertxCompletableFuture<>();\n+    vertx.undeploy(deploymentID, future);\n+    try {\n+      future.get();\n+    } catch (Exception e) {\n+      throw new KsqlException(\"Failure in stopping API server\", e);\n+    }\n+  }\n+\n+  QueryID registerQuery(final QuerySubscriber querySubscriber) {\n+    Objects.requireNonNull(querySubscriber);\n+    final QueryID queryID = new QueryID();\n+    queries.put(queryID, querySubscriber);\n+    return queryID;\n+  }\n+\n+  QuerySubscriber removeQuery(final QueryID queryID) {\n+    return queries.remove(queryID);\n+  }\n+\n+  public Set<QueryID> getQueryIDs() {\n+    return new HashSet<>(queries.keySet());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 108}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODY1Mjg0Ng==", "bodyText": "Immutable types by default :D", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368652846", "createdAt": "2020-01-20T17:05:24Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.util.KsqlException;\n+import io.vertx.core.DeploymentOptions;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.impl.ConcurrentHashSet;\n+import io.vertx.core.json.JsonObject;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class represents the API server. On start-up it deploys multiple server verticles to spread\n+ * the load across available cores.\n+ */\n+public class Server {\n+\n+  private static final Logger log = LoggerFactory.getLogger(Server.class);\n+\n+  private final Vertx vertx;\n+  private final JsonObject config;\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Map<QueryID, QuerySubscriber> queries = new ConcurrentHashMap<>();\n+  private final Set<HttpConnection> connections = new ConcurrentHashSet<>();\n+  private String deploymentID;\n+\n+  public Server(final Vertx vertx, final JsonObject config, final Endpoints endpoints,\n+      final HttpServerOptions httpServerOptions) {\n+    this.vertx = Objects.requireNonNull(vertx);\n+    this.config = Objects.requireNonNull(config);\n+    this.endpoints = Objects.requireNonNull(endpoints);\n+    this.httpServerOptions = Objects.requireNonNull(httpServerOptions);\n+  }\n+\n+  public synchronized void start() {\n+    if (deploymentID != null) {\n+      throw new IllegalStateException(\"Already started\");\n+    }\n+    final DeploymentOptions options = new DeploymentOptions();\n+    final Integer verticleInstances = config.getInteger(\"verticle-instances\");\n+    if (verticleInstances == null) {\n+      options.setInstances(Runtime.getRuntime().availableProcessors() * 2);\n+    } else {\n+      options.setInstances(verticleInstances);\n+    }\n+    log.info(\"Deploying \" + options.getInstances() + \" instances of server verticle\");\n+    options.setConfig(config);\n+    final VertxCompletableFuture<String> future = new VertxCompletableFuture<>();\n+    vertx.deployVerticle(\n+        () -> new ServerVerticle(endpoints, httpServerOptions, this), options, future);\n+    try {\n+      deploymentID = future.get();\n+    } catch (Exception e) {\n+      throw new KsqlException(\"Failed to start API server\", e);\n+    }\n+    log.info(\"API server started: \" + deploymentID);\n+  }\n+\n+  public synchronized void stop() {\n+    if (deploymentID == null) {\n+      throw new IllegalStateException(\"Not started\");\n+    }\n+    final VertxCompletableFuture<Void> future = new VertxCompletableFuture<>();\n+    vertx.undeploy(deploymentID, future);\n+    try {\n+      future.get();\n+    } catch (Exception e) {\n+      throw new KsqlException(\"Failure in stopping API server\", e);\n+    }\n+  }\n+\n+  QueryID registerQuery(final QuerySubscriber querySubscriber) {\n+    Objects.requireNonNull(querySubscriber);\n+    final QueryID queryID = new QueryID();\n+    queries.put(queryID, querySubscriber);\n+    return queryID;\n+  }\n+\n+  QuerySubscriber removeQuery(final QueryID queryID) {\n+    return queries.remove(queryID);\n+  }\n+\n+  public Set<QueryID> getQueryIDs() {\n+    return new HashSet<>(queries.keySet());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwODU0OA=="}, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 108}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NDYwNjIwOnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerVerticle.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QxOTo1Nzo0MlrOFfDvgg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQxMDowMTo0MVrOFgWaBw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODExMTQ5MA==", "bodyText": "I'm no REST expert, but wouldn't it be more \"restful\" to have this be HttpMethod.DELETE on a /query endpoint?", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368111490", "createdAt": "2020-01-17T19:57:42Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerVerticle.java", "diffHunk": "@@ -0,0 +1,202 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.impl.Utils;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.QueryPublisher;\n+import io.vertx.core.AbstractVerticle;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Promise;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpMethod;\n+import io.vertx.core.http.HttpServer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.parsetools.RecordParser;\n+import io.vertx.ext.web.Router;\n+import io.vertx.ext.web.RoutingContext;\n+import io.vertx.ext.web.handler.BodyHandler;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * The server deploys multiple server verticles. This is where the HTTP2 requests are handled. The\n+ * actual implementation of the endpoints is provided by an implementation of {@code Endpoints}.\n+ */\n+public class ServerVerticle extends AbstractVerticle {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ServerVerticle.class);\n+\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Server server;\n+  private final Map<HttpConnection, ConnectionQueries> connectionsMap = new HashMap<>();\n+  private HttpServer httpServer;\n+\n+  public ServerVerticle(final Endpoints endpoints, final HttpServerOptions httpServerOptions,\n+      final Server server) {\n+    this.endpoints = endpoints;\n+    this.httpServerOptions = httpServerOptions;\n+    this.server = server;\n+  }\n+\n+  @Override\n+  public void start(final Promise<Void> startPromise) {\n+    httpServer = vertx.createHttpServer(httpServerOptions).requestHandler(setupRouter())\n+        .exceptionHandler(ServerUtils::unhandledExceptonHandler);\n+    final Future<HttpServer> listenFuture = Promise.<HttpServer>promise().future();\n+    Utils.connectPromise(listenFuture.map(s -> null), startPromise);\n+    httpServer.listen(listenFuture);\n+    vertx.getOrCreateContext().exceptionHandler(ServerUtils::unhandledExceptonHandler);\n+  }\n+\n+  @Override\n+  public void stop(final Promise<Void> stopPromise) {\n+    if (httpServer == null) {\n+      stopPromise.complete();\n+    } else {\n+      httpServer.close(stopPromise.future());\n+    }\n+  }\n+\n+  private Router setupRouter() {\n+    final Router router = Router.router(vertx);\n+    router.route(HttpMethod.POST, \"/query-stream\").handler(BodyHandler.create())\n+        .handler(this::handleQueryStream);\n+    router.route(HttpMethod.POST, \"/inserts-stream\").handler(this::handleInsertsStream);\n+    router.route(HttpMethod.POST, \"/close-query\").handler(BodyHandler.create())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 90}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQ2NTg2Mw==", "bodyText": "It's not a REST API ;)", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r369465863", "createdAt": "2020-01-22T10:01:41Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerVerticle.java", "diffHunk": "@@ -0,0 +1,202 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.impl.Utils;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.QueryPublisher;\n+import io.vertx.core.AbstractVerticle;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Promise;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpMethod;\n+import io.vertx.core.http.HttpServer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.parsetools.RecordParser;\n+import io.vertx.ext.web.Router;\n+import io.vertx.ext.web.RoutingContext;\n+import io.vertx.ext.web.handler.BodyHandler;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * The server deploys multiple server verticles. This is where the HTTP2 requests are handled. The\n+ * actual implementation of the endpoints is provided by an implementation of {@code Endpoints}.\n+ */\n+public class ServerVerticle extends AbstractVerticle {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ServerVerticle.class);\n+\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Server server;\n+  private final Map<HttpConnection, ConnectionQueries> connectionsMap = new HashMap<>();\n+  private HttpServer httpServer;\n+\n+  public ServerVerticle(final Endpoints endpoints, final HttpServerOptions httpServerOptions,\n+      final Server server) {\n+    this.endpoints = endpoints;\n+    this.httpServerOptions = httpServerOptions;\n+    this.server = server;\n+  }\n+\n+  @Override\n+  public void start(final Promise<Void> startPromise) {\n+    httpServer = vertx.createHttpServer(httpServerOptions).requestHandler(setupRouter())\n+        .exceptionHandler(ServerUtils::unhandledExceptonHandler);\n+    final Future<HttpServer> listenFuture = Promise.<HttpServer>promise().future();\n+    Utils.connectPromise(listenFuture.map(s -> null), startPromise);\n+    httpServer.listen(listenFuture);\n+    vertx.getOrCreateContext().exceptionHandler(ServerUtils::unhandledExceptonHandler);\n+  }\n+\n+  @Override\n+  public void stop(final Promise<Void> stopPromise) {\n+    if (httpServer == null) {\n+      stopPromise.complete();\n+    } else {\n+      httpServer.close(stopPromise.future());\n+    }\n+  }\n+\n+  private Router setupRouter() {\n+    final Router router = Router.router(vertx);\n+    router.route(HttpMethod.POST, \"/query-stream\").handler(BodyHandler.create())\n+        .handler(this::handleQueryStream);\n+    router.route(HttpMethod.POST, \"/inserts-stream\").handler(this::handleInsertsStream);\n+    router.route(HttpMethod.POST, \"/close-query\").handler(BodyHandler.create())", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODExMTQ5MA=="}, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 90}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NDYxMzM4OnYy", "diffSide": "RIGHT", "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerVerticle.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QyMDowMDoyOVrOFfD0Cw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQxMDowMTo1NlrOFgWalQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODExMjY1MQ==", "bodyText": "again - having the API defined inline in the code as string literals makes it really hard to construct automated documentation about our public API. would be nice to have Jackson objects that we can generate documentation from", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368112651", "createdAt": "2020-01-17T20:00:29Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerVerticle.java", "diffHunk": "@@ -0,0 +1,202 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.impl.Utils;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.QueryPublisher;\n+import io.vertx.core.AbstractVerticle;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Promise;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpMethod;\n+import io.vertx.core.http.HttpServer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.parsetools.RecordParser;\n+import io.vertx.ext.web.Router;\n+import io.vertx.ext.web.RoutingContext;\n+import io.vertx.ext.web.handler.BodyHandler;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * The server deploys multiple server verticles. This is where the HTTP2 requests are handled. The\n+ * actual implementation of the endpoints is provided by an implementation of {@code Endpoints}.\n+ */\n+public class ServerVerticle extends AbstractVerticle {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ServerVerticle.class);\n+\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Server server;\n+  private final Map<HttpConnection, ConnectionQueries> connectionsMap = new HashMap<>();\n+  private HttpServer httpServer;\n+\n+  public ServerVerticle(final Endpoints endpoints, final HttpServerOptions httpServerOptions,\n+      final Server server) {\n+    this.endpoints = endpoints;\n+    this.httpServerOptions = httpServerOptions;\n+    this.server = server;\n+  }\n+\n+  @Override\n+  public void start(final Promise<Void> startPromise) {\n+    httpServer = vertx.createHttpServer(httpServerOptions).requestHandler(setupRouter())\n+        .exceptionHandler(ServerUtils::unhandledExceptonHandler);\n+    final Future<HttpServer> listenFuture = Promise.<HttpServer>promise().future();\n+    Utils.connectPromise(listenFuture.map(s -> null), startPromise);\n+    httpServer.listen(listenFuture);\n+    vertx.getOrCreateContext().exceptionHandler(ServerUtils::unhandledExceptonHandler);\n+  }\n+\n+  @Override\n+  public void stop(final Promise<Void> stopPromise) {\n+    if (httpServer == null) {\n+      stopPromise.complete();\n+    } else {\n+      httpServer.close(stopPromise.future());\n+    }\n+  }\n+\n+  private Router setupRouter() {\n+    final Router router = Router.router(vertx);\n+    router.route(HttpMethod.POST, \"/query-stream\").handler(BodyHandler.create())\n+        .handler(this::handleQueryStream);\n+    router.route(HttpMethod.POST, \"/inserts-stream\").handler(this::handleInsertsStream);\n+    router.route(HttpMethod.POST, \"/close-query\").handler(BodyHandler.create())\n+        .handler(this::handleCloseQuery);\n+    return router;\n+  }\n+\n+  private void handleInsertsStream(final RoutingContext routingContext) {\n+    final RecordParser recordParser = RecordParser\n+        .newDelimited(\"\\n\", new InsertsBodyParser(endpoints, routingContext)::handleBodyBuffer);\n+    routingContext.request()\n+        .handler(recordParser);\n+  }\n+\n+  private void handleQueryStream(final RoutingContext routingContext) {\n+    final HttpConnection conn = routingContext.request().connection();\n+    ConnectionQueries connectionQueries = connectionsMap.get(conn);\n+    if (connectionQueries == null) {\n+      connectionQueries = new ConnectionQueries(conn);\n+      connectionsMap.put(conn, connectionQueries);\n+      conn.closeHandler(connectionQueries);\n+      server.registerQueryConnection(conn);\n+    }\n+    final JsonObject requestBody = routingContext.getBodyAsJson();\n+    final String sql = requestBody.getString(\"sql\");\n+    if (sql == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No sql in arguments\");\n+      return;\n+    }\n+    final Boolean push = requestBody.getBoolean(\"push\");\n+    if (push == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No push in arguments\");\n+      return;\n+    }\n+    final JsonObject properties = requestBody.getJsonObject(\"properties\");\n+    final QueryPublisher queryPublisher = endpoints.createQueryPublisher(sql, push, properties);\n+    final QuerySubscriber querySubscriber = new QuerySubscriber(routingContext.response());\n+\n+    final QueryID queryID = server.registerQuery(querySubscriber);\n+    connectionQueries.addQuery(queryID);\n+    final JsonObject metadata = new JsonObject();\n+    metadata.put(\"columnNames\", queryPublisher.getColumnNames());\n+    metadata.put(\"columnTypes\", queryPublisher.getColumnTypes());\n+    metadata.put(\"queryID\", queryID.toString());\n+    if (!push) {\n+      metadata.put(\"rowCount\", queryPublisher.getRowCount());\n+    }\n+    routingContext.response().write(metadata.toBuffer()).write(\"\\n\");\n+    queryPublisher.subscribe(querySubscriber);\n+\n+    // When response is complete, publisher should be closed and query unregistered\n+    routingContext.response().endHandler(v -> closeQuery(queryID, routingContext));\n+  }\n+\n+  private boolean closeQuery(final QueryID queryID, final RoutingContext routingContext) {\n+    final QuerySubscriber querySubscriber = server.removeQuery(queryID);\n+    if (querySubscriber == null) {\n+      return false;\n+    }\n+    final HttpConnection conn = routingContext.request().connection();\n+    final ConnectionQueries connectionQueries = connectionsMap.get(conn);\n+    connectionQueries.removeQuery(queryID);\n+    querySubscriber.close();\n+    return true;\n+  }\n+\n+  private void handleCloseQuery(final RoutingContext routingContext) {\n+    final JsonObject requestBody = routingContext.getBodyAsJson();\n+    final String queryIDArg = requestBody.getString(\"queryID\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 156}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQ2NjAwNQ==", "bodyText": "see POJOs PR", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r369466005", "createdAt": "2020-01-22T10:01:56Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerVerticle.java", "diffHunk": "@@ -0,0 +1,202 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.impl.Utils;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.QueryPublisher;\n+import io.vertx.core.AbstractVerticle;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Promise;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpMethod;\n+import io.vertx.core.http.HttpServer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.parsetools.RecordParser;\n+import io.vertx.ext.web.Router;\n+import io.vertx.ext.web.RoutingContext;\n+import io.vertx.ext.web.handler.BodyHandler;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * The server deploys multiple server verticles. This is where the HTTP2 requests are handled. The\n+ * actual implementation of the endpoints is provided by an implementation of {@code Endpoints}.\n+ */\n+public class ServerVerticle extends AbstractVerticle {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ServerVerticle.class);\n+\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Server server;\n+  private final Map<HttpConnection, ConnectionQueries> connectionsMap = new HashMap<>();\n+  private HttpServer httpServer;\n+\n+  public ServerVerticle(final Endpoints endpoints, final HttpServerOptions httpServerOptions,\n+      final Server server) {\n+    this.endpoints = endpoints;\n+    this.httpServerOptions = httpServerOptions;\n+    this.server = server;\n+  }\n+\n+  @Override\n+  public void start(final Promise<Void> startPromise) {\n+    httpServer = vertx.createHttpServer(httpServerOptions).requestHandler(setupRouter())\n+        .exceptionHandler(ServerUtils::unhandledExceptonHandler);\n+    final Future<HttpServer> listenFuture = Promise.<HttpServer>promise().future();\n+    Utils.connectPromise(listenFuture.map(s -> null), startPromise);\n+    httpServer.listen(listenFuture);\n+    vertx.getOrCreateContext().exceptionHandler(ServerUtils::unhandledExceptonHandler);\n+  }\n+\n+  @Override\n+  public void stop(final Promise<Void> stopPromise) {\n+    if (httpServer == null) {\n+      stopPromise.complete();\n+    } else {\n+      httpServer.close(stopPromise.future());\n+    }\n+  }\n+\n+  private Router setupRouter() {\n+    final Router router = Router.router(vertx);\n+    router.route(HttpMethod.POST, \"/query-stream\").handler(BodyHandler.create())\n+        .handler(this::handleQueryStream);\n+    router.route(HttpMethod.POST, \"/inserts-stream\").handler(this::handleInsertsStream);\n+    router.route(HttpMethod.POST, \"/close-query\").handler(BodyHandler.create())\n+        .handler(this::handleCloseQuery);\n+    return router;\n+  }\n+\n+  private void handleInsertsStream(final RoutingContext routingContext) {\n+    final RecordParser recordParser = RecordParser\n+        .newDelimited(\"\\n\", new InsertsBodyParser(endpoints, routingContext)::handleBodyBuffer);\n+    routingContext.request()\n+        .handler(recordParser);\n+  }\n+\n+  private void handleQueryStream(final RoutingContext routingContext) {\n+    final HttpConnection conn = routingContext.request().connection();\n+    ConnectionQueries connectionQueries = connectionsMap.get(conn);\n+    if (connectionQueries == null) {\n+      connectionQueries = new ConnectionQueries(conn);\n+      connectionsMap.put(conn, connectionQueries);\n+      conn.closeHandler(connectionQueries);\n+      server.registerQueryConnection(conn);\n+    }\n+    final JsonObject requestBody = routingContext.getBodyAsJson();\n+    final String sql = requestBody.getString(\"sql\");\n+    if (sql == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No sql in arguments\");\n+      return;\n+    }\n+    final Boolean push = requestBody.getBoolean(\"push\");\n+    if (push == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No push in arguments\");\n+      return;\n+    }\n+    final JsonObject properties = requestBody.getJsonObject(\"properties\");\n+    final QueryPublisher queryPublisher = endpoints.createQueryPublisher(sql, push, properties);\n+    final QuerySubscriber querySubscriber = new QuerySubscriber(routingContext.response());\n+\n+    final QueryID queryID = server.registerQuery(querySubscriber);\n+    connectionQueries.addQuery(queryID);\n+    final JsonObject metadata = new JsonObject();\n+    metadata.put(\"columnNames\", queryPublisher.getColumnNames());\n+    metadata.put(\"columnTypes\", queryPublisher.getColumnTypes());\n+    metadata.put(\"queryID\", queryID.toString());\n+    if (!push) {\n+      metadata.put(\"rowCount\", queryPublisher.getRowCount());\n+    }\n+    routingContext.response().write(metadata.toBuffer()).write(\"\\n\");\n+    queryPublisher.subscribe(querySubscriber);\n+\n+    // When response is complete, publisher should be closed and query unregistered\n+    routingContext.response().endHandler(v -> closeQuery(queryID, routingContext));\n+  }\n+\n+  private boolean closeQuery(final QueryID queryID, final RoutingContext routingContext) {\n+    final QuerySubscriber querySubscriber = server.removeQuery(queryID);\n+    if (querySubscriber == null) {\n+      return false;\n+    }\n+    final HttpConnection conn = routingContext.request().connection();\n+    final ConnectionQueries connectionQueries = connectionsMap.get(conn);\n+    connectionQueries.removeQuery(queryID);\n+    querySubscriber.close();\n+    return true;\n+  }\n+\n+  private void handleCloseQuery(final RoutingContext routingContext) {\n+    final JsonObject requestBody = routingContext.getBodyAsJson();\n+    final String queryIDArg = requestBody.getString(\"queryID\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODExMjY1MQ=="}, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 156}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NDYxOTE5OnYy", "diffSide": "RIGHT", "path": "ksql-api/src/test/java/io/confluent/ksql/api/TestEndpoints.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QyMDowMzowNVrOFfD3sw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQxMDowMjowNFrOFgWa5Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODExMzU4Nw==", "bodyText": "All the tests seem to also have 2019 in copyright", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368113587", "createdAt": "2020-01-17T20:03:05Z", "author": {"login": "agavra"}, "path": "ksql-api/src/test/java/io/confluent/ksql/api/TestEndpoints.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Copyright 2019 Confluent Inc.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 2}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTQ2NjA4NQ==", "bodyText": "Ack", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r369466085", "createdAt": "2020-01-22T10:02:04Z", "author": {"login": "purplefox"}, "path": "ksql-api/src/test/java/io/confluent/ksql/api/TestEndpoints.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Copyright 2019 Confluent Inc.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODExMzU4Nw=="}, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 2}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2228, "cost": 1, "resetAt": "2021-11-12T19:05:54Z"}}}