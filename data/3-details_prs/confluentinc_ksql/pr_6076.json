{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDcxNzc3OTE4", "number": 6076, "title": "chore: support filters for stream aggregations", "bodyText": "Description\nThis PR add support and testing for modifying filters in stream aggregations. The main changes are in StreamAggregate, StreamGroupBy and StreamGroupByKey classes to check that they are the same when an upgrade happens.\nTesting done\n\nadded tests to filters.json\n\nReviewer checklist\n\n Ensure docs are updated if necessary. (eg. if a user visible feature is being added or changed).\n Ensure relevant issues are linked (description should include text like \"Fixes #\")", "createdAt": "2020-08-21T18:20:29Z", "url": "https://github.com/confluentinc/ksql/pull/6076", "merged": true, "mergeCommit": {"oid": "fe13f3ac1465164f424f46a57b9af3cad28050ca"}, "closed": true, "closedAt": "2020-08-24T19:52:50Z", "author": {"login": "agavra"}, "timelineItems": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdBLccZgH2gAyNDcxNzc3OTE4Ojk2OWY3NGIyNjVjNTAxYjNhOWE2ZTk3ZTcyNzc2YTA2M2MxODRmOTk=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdCHtj3gFqTQ3Mzc4OTkxMw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "969f74b265c501b3a9a6e97e72776a063c184f99", "author": {"user": {"login": "agavra", "name": "Almog Gavra"}}, "url": "https://github.com/confluentinc/ksql/commit/969f74b265c501b3a9a6e97e72776a063c184f99", "committedDate": "2020-08-21T21:11:11Z", "message": "chore: support filters for stream aggregations"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0700c270d60f9a31af635339143a5b559d0b6b21", "author": {"user": {"login": "agavra", "name": "Almog Gavra"}}, "url": "https://github.com/confluentinc/ksql/commit/0700c270d60f9a31af635339143a5b559d0b6b21", "committedDate": "2020-08-21T16:50:28Z", "message": "chore: support filters for stream aggregations"}, "afterCommit": {"oid": "969f74b265c501b3a9a6e97e72776a063c184f99", "author": {"user": {"login": "agavra", "name": "Almog Gavra"}}, "url": "https://github.com/confluentinc/ksql/commit/969f74b265c501b3a9a6e97e72776a063c184f99", "committedDate": "2020-08-21T21:11:11Z", "message": "chore: support filters for stream aggregations"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDczNzg5OTEz", "url": "https://github.com/confluentinc/ksql/pull/6076#pullrequestreview-473789913", "createdAt": "2020-08-24T19:22:20Z", "commit": {"oid": "969f74b265c501b3a9a6e97e72776a063c184f99"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxOToyMjoyMFrOHFzChg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxOToyMjoyMFrOHFzChg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTg0MTE1OA==", "bodyText": "this is kind of a confusing error message since the columns are part of the aggregate, and the user likely doesn't know about the implicit substitution of wildcard for ROWTIME. I think its fair to say fixing this is probably out of scope for this PR, but maybe file an issue?", "url": "https://github.com/confluentinc/ksql/pull/6076#discussion_r475841158", "createdAt": "2020-08-24T19:22:20Z", "author": {"login": "rodesai"}, "path": "ksqldb-functional-tests/src/test/resources/sql-tests/query-upgrades/filters.sql", "diffHunk": "@@ -131,16 +125,133 @@ CREATE STREAM j AS SELECT s.id, s.foo, t.bar FROM s JOIN t ON s.id = t.id;\n CREATE OR REPLACE STREAM j AS SELECT s.id, s.foo, t.bar FROM s JOIN t ON s.id = t.id WHERE s.foo > 0;\n \n ----------------------------------------------------------------------------------------------------\n---@test: add filter to StreamAggregate\n+--@test: change filter in StreamAggregate (StreamGroupByKey)\n+----------------------------------------------------------------------------------------------------\n+SET 'ksql.create.or.replace.enabled' = 'true';\n+\n+CREATE STREAM foo (id INT KEY, col1 INT) WITH (kafka_topic='foo', value_format='JSON');\n+CREATE TABLE bar AS SELECT id, COUNT(*) as count FROM foo WHERE col1 >= 0 GROUP BY id;\n+\n+INSERT INTO foo (id, col1) VALUES (1, 0);\n+INSERT INTO foo (id, col1) VALUES (2, 0);\n+\n+ASSERT VALUES bar (id, count) VALUES (1, 1);\n+ASSERT VALUES bar (id, count) VALUES (2, 1);\n+\n+CREATE OR REPLACE TABLE bar AS SELECT id, COUNT(*) as count FROM foo WHERE col1 > 0 GROUP BY id;\n+\n+INSERT INTO foo (id, col1) VALUES (1, 0);\n+INSERT INTO foo (id, col1) VALUES (2, 1);\n+\n+ASSERT VALUES bar (id, count) VALUES (2, 2);\n+\n+----------------------------------------------------------------------------------------------------\n+--@test: change filter in StreamAggregate (StreamGroupBy)\n+----------------------------------------------------------------------------------------------------\n+SET 'ksql.create.or.replace.enabled' = 'true';\n+\n+CREATE STREAM foo (id INT KEY, col1 INT) WITH (kafka_topic='foo', value_format='JSON');\n+CREATE TABLE bar AS SELECT col1, COUNT(*) as count FROM foo WHERE col1 >= 0 GROUP BY col1;\n+\n+INSERT INTO foo (col1, id) VALUES (1, 0);\n+INSERT INTO foo (col1, id) VALUES (2, 0);\n+\n+ASSERT VALUES bar (col1, count) VALUES (1, 1);\n+ASSERT VALUES bar (col1, count) VALUES (2, 1);\n+\n+CREATE OR REPLACE TABLE bar AS SELECT col1, COUNT(*) as count FROM foo WHERE col1 > 1 GROUP BY col1;\n+\n+INSERT INTO foo (col1, id) VALUES (1, 0);\n+INSERT INTO foo (col1, id) VALUES (2, 1);\n+\n+ASSERT VALUES bar (col1, count) VALUES (2, 2);\n+\n+----------------------------------------------------------------------------------------------------\n+--@test: add filter in StreamAggregate where columns are already in input schema\n+----------------------------------------------------------------------------------------------------\n+SET 'ksql.create.or.replace.enabled' = 'true';\n+\n+CREATE STREAM foo (id INT KEY, col1 INT) WITH (kafka_topic='foo', value_format='JSON');\n+CREATE TABLE bar AS SELECT id, COUNT(col1) as count FROM foo GROUP BY id;\n+\n+INSERT INTO foo (id, col1) VALUES (1, 0);\n+INSERT INTO foo (id, col1) VALUES (2, 0);\n+\n+ASSERT VALUES bar (id, count) VALUES (1, 1);\n+ASSERT VALUES bar (id, count) VALUES (2, 1);\n+\n+CREATE OR REPLACE TABLE bar AS SELECT id, COUNT(col1) as count FROM foo WHERE col1 > 0 GROUP BY id;\n+\n+INSERT INTO foo (id, col1) VALUES (1, 0);\n+INSERT INTO foo (id, col1) VALUES (2, 1);\n+\n+ASSERT VALUES bar (id, count) VALUES (2, 2);\n+\n+----------------------------------------------------------------------------------------------------\n+--@test: remove filter in StreamAggregate where columns are already in input schema\n+----------------------------------------------------------------------------------------------------\n+SET 'ksql.create.or.replace.enabled' = 'true';\n+\n+CREATE STREAM foo (id INT KEY, col1 INT) WITH (kafka_topic='foo', value_format='JSON');\n+CREATE TABLE bar AS SELECT id, COUNT(col1) as count FROM foo WHERE col1 > 0 GROUP BY id;\n+\n+INSERT INTO foo (id, col1) VALUES (1, 1);\n+\n+ASSERT VALUES bar (id, count) VALUES (1, 1);\n+\n+CREATE OR REPLACE TABLE bar AS SELECT id, COUNT(col1) as count FROM foo GROUP BY id;\n+\n+INSERT INTO foo (id, col1) VALUES (1, 0);\n+\n+ASSERT VALUES bar (id, count) VALUES (1, 2);\n+\n+----------------------------------------------------------------------------------------------------\n+--@test: change filter in StreamAggregate to another column that already exists in input\n+----------------------------------------------------------------------------------------------------\n+SET 'ksql.create.or.replace.enabled' = 'true';\n+\n+CREATE STREAM foo (id INT KEY, col1 INT) WITH (kafka_topic='foo', value_format='JSON');\n+CREATE TABLE bar AS SELECT id, COUNT(col1) as count FROM foo WHERE col1 >= 0 GROUP BY id;\n+\n+INSERT INTO foo (id, col1) VALUES (1, 0);\n+INSERT INTO foo (id, col1) VALUES (2, 0);\n+\n+ASSERT VALUES bar (id, count) VALUES (1, 1);\n+ASSERT VALUES bar (id, count) VALUES (2, 1);\n+\n+CREATE OR REPLACE TABLE bar AS SELECT id, COUNT(col1) as count FROM foo WHERE id > 1 GROUP BY id;\n+\n+INSERT INTO foo (id, col1) VALUES (1, 0);\n+INSERT INTO foo (id, col1) VALUES (2, -1);\n+\n+ASSERT VALUES bar (id, count) VALUES (2, 2);\n+\n+----------------------------------------------------------------------------------------------------\n+--@test: remove filter in StreamAggregate where columns are not already in input schema\n+--@test: add filter in StreamAggregate where columns are not in input schema\n --@expected.error: io.confluent.ksql.util.KsqlException\n---@expected.message: Upgrades not yet supported for StreamAggregate\n+--@expected.message: StreamAggregate must have matching nonAggregateColumns. Values differ: [`ID`, `ROWTIME`, `COL1`] vs. [`ID`, `ROWTIME`]\n ----------------------------------------------------------------------------------------------------\n SET 'ksql.create.or.replace.enabled' = 'true';\n \n CREATE STREAM foo (id INT KEY, col1 INT) WITH (kafka_topic='foo', value_format='JSON');\n+CREATE TABLE bar AS SELECT id, COUNT(*) as count FROM foo WHERE col1 > 0 GROUP BY id;\n+\n+CREATE OR REPLACE TABLE bar AS SELECT id, COUNT(*) as count FROM foo GROUP BY id;\n \n+----------------------------------------------------------------------------------------------------\n+-- until we think this through a little bit more, don't allow changing non-aggregate columns\n+-- to StreamAggregate nodes, though this should technically be OK\n+\n+--@test: add filter in StreamAggregate where columns are not in input schema\n+--@expected.error: io.confluent.ksql.util.KsqlException\n+--@expected.message: StreamAggregate must have matching nonAggregateColumns. Values differ: [`ID`, `ROWTIME`] vs. [`ID`, `COL1`]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "969f74b265c501b3a9a6e97e72776a063c184f99"}, "originalPosition": 139}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4726, "cost": 1, "resetAt": "2021-11-01T13:51:04Z"}}}