{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDcxNzc3OTE4", "number": 6076, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxOToyMjoyMFrOEbtZnQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxOToyMjoyMFrOEbtZnQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk3NDkwODQ1OnYy", "diffSide": "RIGHT", "path": "ksqldb-functional-tests/src/test/resources/sql-tests/query-upgrades/filters.sql", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxOToyMjoyMFrOHFzChg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQyMjo0OTozM1rOHF43oQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTg0MTE1OA==", "bodyText": "this is kind of a confusing error message since the columns are part of the aggregate, and the user likely doesn't know about the implicit substitution of wildcard for ROWTIME. I think its fair to say fixing this is probably out of scope for this PR, but maybe file an issue?", "url": "https://github.com/confluentinc/ksql/pull/6076#discussion_r475841158", "createdAt": "2020-08-24T19:22:20Z", "author": {"login": "rodesai"}, "path": "ksqldb-functional-tests/src/test/resources/sql-tests/query-upgrades/filters.sql", "diffHunk": "@@ -131,16 +125,133 @@ CREATE STREAM j AS SELECT s.id, s.foo, t.bar FROM s JOIN t ON s.id = t.id;\n CREATE OR REPLACE STREAM j AS SELECT s.id, s.foo, t.bar FROM s JOIN t ON s.id = t.id WHERE s.foo > 0;\n \n ----------------------------------------------------------------------------------------------------\n---@test: add filter to StreamAggregate\n+--@test: change filter in StreamAggregate (StreamGroupByKey)\n+----------------------------------------------------------------------------------------------------\n+SET 'ksql.create.or.replace.enabled' = 'true';\n+\n+CREATE STREAM foo (id INT KEY, col1 INT) WITH (kafka_topic='foo', value_format='JSON');\n+CREATE TABLE bar AS SELECT id, COUNT(*) as count FROM foo WHERE col1 >= 0 GROUP BY id;\n+\n+INSERT INTO foo (id, col1) VALUES (1, 0);\n+INSERT INTO foo (id, col1) VALUES (2, 0);\n+\n+ASSERT VALUES bar (id, count) VALUES (1, 1);\n+ASSERT VALUES bar (id, count) VALUES (2, 1);\n+\n+CREATE OR REPLACE TABLE bar AS SELECT id, COUNT(*) as count FROM foo WHERE col1 > 0 GROUP BY id;\n+\n+INSERT INTO foo (id, col1) VALUES (1, 0);\n+INSERT INTO foo (id, col1) VALUES (2, 1);\n+\n+ASSERT VALUES bar (id, count) VALUES (2, 2);\n+\n+----------------------------------------------------------------------------------------------------\n+--@test: change filter in StreamAggregate (StreamGroupBy)\n+----------------------------------------------------------------------------------------------------\n+SET 'ksql.create.or.replace.enabled' = 'true';\n+\n+CREATE STREAM foo (id INT KEY, col1 INT) WITH (kafka_topic='foo', value_format='JSON');\n+CREATE TABLE bar AS SELECT col1, COUNT(*) as count FROM foo WHERE col1 >= 0 GROUP BY col1;\n+\n+INSERT INTO foo (col1, id) VALUES (1, 0);\n+INSERT INTO foo (col1, id) VALUES (2, 0);\n+\n+ASSERT VALUES bar (col1, count) VALUES (1, 1);\n+ASSERT VALUES bar (col1, count) VALUES (2, 1);\n+\n+CREATE OR REPLACE TABLE bar AS SELECT col1, COUNT(*) as count FROM foo WHERE col1 > 1 GROUP BY col1;\n+\n+INSERT INTO foo (col1, id) VALUES (1, 0);\n+INSERT INTO foo (col1, id) VALUES (2, 1);\n+\n+ASSERT VALUES bar (col1, count) VALUES (2, 2);\n+\n+----------------------------------------------------------------------------------------------------\n+--@test: add filter in StreamAggregate where columns are already in input schema\n+----------------------------------------------------------------------------------------------------\n+SET 'ksql.create.or.replace.enabled' = 'true';\n+\n+CREATE STREAM foo (id INT KEY, col1 INT) WITH (kafka_topic='foo', value_format='JSON');\n+CREATE TABLE bar AS SELECT id, COUNT(col1) as count FROM foo GROUP BY id;\n+\n+INSERT INTO foo (id, col1) VALUES (1, 0);\n+INSERT INTO foo (id, col1) VALUES (2, 0);\n+\n+ASSERT VALUES bar (id, count) VALUES (1, 1);\n+ASSERT VALUES bar (id, count) VALUES (2, 1);\n+\n+CREATE OR REPLACE TABLE bar AS SELECT id, COUNT(col1) as count FROM foo WHERE col1 > 0 GROUP BY id;\n+\n+INSERT INTO foo (id, col1) VALUES (1, 0);\n+INSERT INTO foo (id, col1) VALUES (2, 1);\n+\n+ASSERT VALUES bar (id, count) VALUES (2, 2);\n+\n+----------------------------------------------------------------------------------------------------\n+--@test: remove filter in StreamAggregate where columns are already in input schema\n+----------------------------------------------------------------------------------------------------\n+SET 'ksql.create.or.replace.enabled' = 'true';\n+\n+CREATE STREAM foo (id INT KEY, col1 INT) WITH (kafka_topic='foo', value_format='JSON');\n+CREATE TABLE bar AS SELECT id, COUNT(col1) as count FROM foo WHERE col1 > 0 GROUP BY id;\n+\n+INSERT INTO foo (id, col1) VALUES (1, 1);\n+\n+ASSERT VALUES bar (id, count) VALUES (1, 1);\n+\n+CREATE OR REPLACE TABLE bar AS SELECT id, COUNT(col1) as count FROM foo GROUP BY id;\n+\n+INSERT INTO foo (id, col1) VALUES (1, 0);\n+\n+ASSERT VALUES bar (id, count) VALUES (1, 2);\n+\n+----------------------------------------------------------------------------------------------------\n+--@test: change filter in StreamAggregate to another column that already exists in input\n+----------------------------------------------------------------------------------------------------\n+SET 'ksql.create.or.replace.enabled' = 'true';\n+\n+CREATE STREAM foo (id INT KEY, col1 INT) WITH (kafka_topic='foo', value_format='JSON');\n+CREATE TABLE bar AS SELECT id, COUNT(col1) as count FROM foo WHERE col1 >= 0 GROUP BY id;\n+\n+INSERT INTO foo (id, col1) VALUES (1, 0);\n+INSERT INTO foo (id, col1) VALUES (2, 0);\n+\n+ASSERT VALUES bar (id, count) VALUES (1, 1);\n+ASSERT VALUES bar (id, count) VALUES (2, 1);\n+\n+CREATE OR REPLACE TABLE bar AS SELECT id, COUNT(col1) as count FROM foo WHERE id > 1 GROUP BY id;\n+\n+INSERT INTO foo (id, col1) VALUES (1, 0);\n+INSERT INTO foo (id, col1) VALUES (2, -1);\n+\n+ASSERT VALUES bar (id, count) VALUES (2, 2);\n+\n+----------------------------------------------------------------------------------------------------\n+--@test: remove filter in StreamAggregate where columns are not already in input schema\n+--@test: add filter in StreamAggregate where columns are not in input schema\n --@expected.error: io.confluent.ksql.util.KsqlException\n---@expected.message: Upgrades not yet supported for StreamAggregate\n+--@expected.message: StreamAggregate must have matching nonAggregateColumns. Values differ: [`ID`, `ROWTIME`, `COL1`] vs. [`ID`, `ROWTIME`]\n ----------------------------------------------------------------------------------------------------\n SET 'ksql.create.or.replace.enabled' = 'true';\n \n CREATE STREAM foo (id INT KEY, col1 INT) WITH (kafka_topic='foo', value_format='JSON');\n+CREATE TABLE bar AS SELECT id, COUNT(*) as count FROM foo WHERE col1 > 0 GROUP BY id;\n+\n+CREATE OR REPLACE TABLE bar AS SELECT id, COUNT(*) as count FROM foo GROUP BY id;\n \n+----------------------------------------------------------------------------------------------------\n+-- until we think this through a little bit more, don't allow changing non-aggregate columns\n+-- to StreamAggregate nodes, though this should technically be OK\n+\n+--@test: add filter in StreamAggregate where columns are not in input schema\n+--@expected.error: io.confluent.ksql.util.KsqlException\n+--@expected.message: StreamAggregate must have matching nonAggregateColumns. Values differ: [`ID`, `ROWTIME`] vs. [`ID`, `COL1`]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "969f74b265c501b3a9a6e97e72776a063c184f99"}, "originalPosition": 139}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTg1NjM4MA==", "bodyText": "yeah, I need to improve the error messages across the board for query upgrades when physical plan checks fail. I'm not entirely sure what a good strategy for that is but I'll file a ticket", "url": "https://github.com/confluentinc/ksql/pull/6076#discussion_r475856380", "createdAt": "2020-08-24T19:52:45Z", "author": {"login": "agavra"}, "path": "ksqldb-functional-tests/src/test/resources/sql-tests/query-upgrades/filters.sql", "diffHunk": "@@ -131,16 +125,133 @@ CREATE STREAM j AS SELECT s.id, s.foo, t.bar FROM s JOIN t ON s.id = t.id;\n CREATE OR REPLACE STREAM j AS SELECT s.id, s.foo, t.bar FROM s JOIN t ON s.id = t.id WHERE s.foo > 0;\n \n ----------------------------------------------------------------------------------------------------\n---@test: add filter to StreamAggregate\n+--@test: change filter in StreamAggregate (StreamGroupByKey)\n+----------------------------------------------------------------------------------------------------\n+SET 'ksql.create.or.replace.enabled' = 'true';\n+\n+CREATE STREAM foo (id INT KEY, col1 INT) WITH (kafka_topic='foo', value_format='JSON');\n+CREATE TABLE bar AS SELECT id, COUNT(*) as count FROM foo WHERE col1 >= 0 GROUP BY id;\n+\n+INSERT INTO foo (id, col1) VALUES (1, 0);\n+INSERT INTO foo (id, col1) VALUES (2, 0);\n+\n+ASSERT VALUES bar (id, count) VALUES (1, 1);\n+ASSERT VALUES bar (id, count) VALUES (2, 1);\n+\n+CREATE OR REPLACE TABLE bar AS SELECT id, COUNT(*) as count FROM foo WHERE col1 > 0 GROUP BY id;\n+\n+INSERT INTO foo (id, col1) VALUES (1, 0);\n+INSERT INTO foo (id, col1) VALUES (2, 1);\n+\n+ASSERT VALUES bar (id, count) VALUES (2, 2);\n+\n+----------------------------------------------------------------------------------------------------\n+--@test: change filter in StreamAggregate (StreamGroupBy)\n+----------------------------------------------------------------------------------------------------\n+SET 'ksql.create.or.replace.enabled' = 'true';\n+\n+CREATE STREAM foo (id INT KEY, col1 INT) WITH (kafka_topic='foo', value_format='JSON');\n+CREATE TABLE bar AS SELECT col1, COUNT(*) as count FROM foo WHERE col1 >= 0 GROUP BY col1;\n+\n+INSERT INTO foo (col1, id) VALUES (1, 0);\n+INSERT INTO foo (col1, id) VALUES (2, 0);\n+\n+ASSERT VALUES bar (col1, count) VALUES (1, 1);\n+ASSERT VALUES bar (col1, count) VALUES (2, 1);\n+\n+CREATE OR REPLACE TABLE bar AS SELECT col1, COUNT(*) as count FROM foo WHERE col1 > 1 GROUP BY col1;\n+\n+INSERT INTO foo (col1, id) VALUES (1, 0);\n+INSERT INTO foo (col1, id) VALUES (2, 1);\n+\n+ASSERT VALUES bar (col1, count) VALUES (2, 2);\n+\n+----------------------------------------------------------------------------------------------------\n+--@test: add filter in StreamAggregate where columns are already in input schema\n+----------------------------------------------------------------------------------------------------\n+SET 'ksql.create.or.replace.enabled' = 'true';\n+\n+CREATE STREAM foo (id INT KEY, col1 INT) WITH (kafka_topic='foo', value_format='JSON');\n+CREATE TABLE bar AS SELECT id, COUNT(col1) as count FROM foo GROUP BY id;\n+\n+INSERT INTO foo (id, col1) VALUES (1, 0);\n+INSERT INTO foo (id, col1) VALUES (2, 0);\n+\n+ASSERT VALUES bar (id, count) VALUES (1, 1);\n+ASSERT VALUES bar (id, count) VALUES (2, 1);\n+\n+CREATE OR REPLACE TABLE bar AS SELECT id, COUNT(col1) as count FROM foo WHERE col1 > 0 GROUP BY id;\n+\n+INSERT INTO foo (id, col1) VALUES (1, 0);\n+INSERT INTO foo (id, col1) VALUES (2, 1);\n+\n+ASSERT VALUES bar (id, count) VALUES (2, 2);\n+\n+----------------------------------------------------------------------------------------------------\n+--@test: remove filter in StreamAggregate where columns are already in input schema\n+----------------------------------------------------------------------------------------------------\n+SET 'ksql.create.or.replace.enabled' = 'true';\n+\n+CREATE STREAM foo (id INT KEY, col1 INT) WITH (kafka_topic='foo', value_format='JSON');\n+CREATE TABLE bar AS SELECT id, COUNT(col1) as count FROM foo WHERE col1 > 0 GROUP BY id;\n+\n+INSERT INTO foo (id, col1) VALUES (1, 1);\n+\n+ASSERT VALUES bar (id, count) VALUES (1, 1);\n+\n+CREATE OR REPLACE TABLE bar AS SELECT id, COUNT(col1) as count FROM foo GROUP BY id;\n+\n+INSERT INTO foo (id, col1) VALUES (1, 0);\n+\n+ASSERT VALUES bar (id, count) VALUES (1, 2);\n+\n+----------------------------------------------------------------------------------------------------\n+--@test: change filter in StreamAggregate to another column that already exists in input\n+----------------------------------------------------------------------------------------------------\n+SET 'ksql.create.or.replace.enabled' = 'true';\n+\n+CREATE STREAM foo (id INT KEY, col1 INT) WITH (kafka_topic='foo', value_format='JSON');\n+CREATE TABLE bar AS SELECT id, COUNT(col1) as count FROM foo WHERE col1 >= 0 GROUP BY id;\n+\n+INSERT INTO foo (id, col1) VALUES (1, 0);\n+INSERT INTO foo (id, col1) VALUES (2, 0);\n+\n+ASSERT VALUES bar (id, count) VALUES (1, 1);\n+ASSERT VALUES bar (id, count) VALUES (2, 1);\n+\n+CREATE OR REPLACE TABLE bar AS SELECT id, COUNT(col1) as count FROM foo WHERE id > 1 GROUP BY id;\n+\n+INSERT INTO foo (id, col1) VALUES (1, 0);\n+INSERT INTO foo (id, col1) VALUES (2, -1);\n+\n+ASSERT VALUES bar (id, count) VALUES (2, 2);\n+\n+----------------------------------------------------------------------------------------------------\n+--@test: remove filter in StreamAggregate where columns are not already in input schema\n+--@test: add filter in StreamAggregate where columns are not in input schema\n --@expected.error: io.confluent.ksql.util.KsqlException\n---@expected.message: Upgrades not yet supported for StreamAggregate\n+--@expected.message: StreamAggregate must have matching nonAggregateColumns. Values differ: [`ID`, `ROWTIME`, `COL1`] vs. [`ID`, `ROWTIME`]\n ----------------------------------------------------------------------------------------------------\n SET 'ksql.create.or.replace.enabled' = 'true';\n \n CREATE STREAM foo (id INT KEY, col1 INT) WITH (kafka_topic='foo', value_format='JSON');\n+CREATE TABLE bar AS SELECT id, COUNT(*) as count FROM foo WHERE col1 > 0 GROUP BY id;\n+\n+CREATE OR REPLACE TABLE bar AS SELECT id, COUNT(*) as count FROM foo GROUP BY id;\n \n+----------------------------------------------------------------------------------------------------\n+-- until we think this through a little bit more, don't allow changing non-aggregate columns\n+-- to StreamAggregate nodes, though this should technically be OK\n+\n+--@test: add filter in StreamAggregate where columns are not in input schema\n+--@expected.error: io.confluent.ksql.util.KsqlException\n+--@expected.message: StreamAggregate must have matching nonAggregateColumns. Values differ: [`ID`, `ROWTIME`] vs. [`ID`, `COL1`]", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTg0MTE1OA=="}, "originalCommit": {"oid": "969f74b265c501b3a9a6e97e72776a063c184f99"}, "originalPosition": 139}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTg1ODM3Nw==", "bodyText": "#6087", "url": "https://github.com/confluentinc/ksql/pull/6076#discussion_r475858377", "createdAt": "2020-08-24T19:56:35Z", "author": {"login": "agavra"}, "path": "ksqldb-functional-tests/src/test/resources/sql-tests/query-upgrades/filters.sql", "diffHunk": "@@ -131,16 +125,133 @@ CREATE STREAM j AS SELECT s.id, s.foo, t.bar FROM s JOIN t ON s.id = t.id;\n CREATE OR REPLACE STREAM j AS SELECT s.id, s.foo, t.bar FROM s JOIN t ON s.id = t.id WHERE s.foo > 0;\n \n ----------------------------------------------------------------------------------------------------\n---@test: add filter to StreamAggregate\n+--@test: change filter in StreamAggregate (StreamGroupByKey)\n+----------------------------------------------------------------------------------------------------\n+SET 'ksql.create.or.replace.enabled' = 'true';\n+\n+CREATE STREAM foo (id INT KEY, col1 INT) WITH (kafka_topic='foo', value_format='JSON');\n+CREATE TABLE bar AS SELECT id, COUNT(*) as count FROM foo WHERE col1 >= 0 GROUP BY id;\n+\n+INSERT INTO foo (id, col1) VALUES (1, 0);\n+INSERT INTO foo (id, col1) VALUES (2, 0);\n+\n+ASSERT VALUES bar (id, count) VALUES (1, 1);\n+ASSERT VALUES bar (id, count) VALUES (2, 1);\n+\n+CREATE OR REPLACE TABLE bar AS SELECT id, COUNT(*) as count FROM foo WHERE col1 > 0 GROUP BY id;\n+\n+INSERT INTO foo (id, col1) VALUES (1, 0);\n+INSERT INTO foo (id, col1) VALUES (2, 1);\n+\n+ASSERT VALUES bar (id, count) VALUES (2, 2);\n+\n+----------------------------------------------------------------------------------------------------\n+--@test: change filter in StreamAggregate (StreamGroupBy)\n+----------------------------------------------------------------------------------------------------\n+SET 'ksql.create.or.replace.enabled' = 'true';\n+\n+CREATE STREAM foo (id INT KEY, col1 INT) WITH (kafka_topic='foo', value_format='JSON');\n+CREATE TABLE bar AS SELECT col1, COUNT(*) as count FROM foo WHERE col1 >= 0 GROUP BY col1;\n+\n+INSERT INTO foo (col1, id) VALUES (1, 0);\n+INSERT INTO foo (col1, id) VALUES (2, 0);\n+\n+ASSERT VALUES bar (col1, count) VALUES (1, 1);\n+ASSERT VALUES bar (col1, count) VALUES (2, 1);\n+\n+CREATE OR REPLACE TABLE bar AS SELECT col1, COUNT(*) as count FROM foo WHERE col1 > 1 GROUP BY col1;\n+\n+INSERT INTO foo (col1, id) VALUES (1, 0);\n+INSERT INTO foo (col1, id) VALUES (2, 1);\n+\n+ASSERT VALUES bar (col1, count) VALUES (2, 2);\n+\n+----------------------------------------------------------------------------------------------------\n+--@test: add filter in StreamAggregate where columns are already in input schema\n+----------------------------------------------------------------------------------------------------\n+SET 'ksql.create.or.replace.enabled' = 'true';\n+\n+CREATE STREAM foo (id INT KEY, col1 INT) WITH (kafka_topic='foo', value_format='JSON');\n+CREATE TABLE bar AS SELECT id, COUNT(col1) as count FROM foo GROUP BY id;\n+\n+INSERT INTO foo (id, col1) VALUES (1, 0);\n+INSERT INTO foo (id, col1) VALUES (2, 0);\n+\n+ASSERT VALUES bar (id, count) VALUES (1, 1);\n+ASSERT VALUES bar (id, count) VALUES (2, 1);\n+\n+CREATE OR REPLACE TABLE bar AS SELECT id, COUNT(col1) as count FROM foo WHERE col1 > 0 GROUP BY id;\n+\n+INSERT INTO foo (id, col1) VALUES (1, 0);\n+INSERT INTO foo (id, col1) VALUES (2, 1);\n+\n+ASSERT VALUES bar (id, count) VALUES (2, 2);\n+\n+----------------------------------------------------------------------------------------------------\n+--@test: remove filter in StreamAggregate where columns are already in input schema\n+----------------------------------------------------------------------------------------------------\n+SET 'ksql.create.or.replace.enabled' = 'true';\n+\n+CREATE STREAM foo (id INT KEY, col1 INT) WITH (kafka_topic='foo', value_format='JSON');\n+CREATE TABLE bar AS SELECT id, COUNT(col1) as count FROM foo WHERE col1 > 0 GROUP BY id;\n+\n+INSERT INTO foo (id, col1) VALUES (1, 1);\n+\n+ASSERT VALUES bar (id, count) VALUES (1, 1);\n+\n+CREATE OR REPLACE TABLE bar AS SELECT id, COUNT(col1) as count FROM foo GROUP BY id;\n+\n+INSERT INTO foo (id, col1) VALUES (1, 0);\n+\n+ASSERT VALUES bar (id, count) VALUES (1, 2);\n+\n+----------------------------------------------------------------------------------------------------\n+--@test: change filter in StreamAggregate to another column that already exists in input\n+----------------------------------------------------------------------------------------------------\n+SET 'ksql.create.or.replace.enabled' = 'true';\n+\n+CREATE STREAM foo (id INT KEY, col1 INT) WITH (kafka_topic='foo', value_format='JSON');\n+CREATE TABLE bar AS SELECT id, COUNT(col1) as count FROM foo WHERE col1 >= 0 GROUP BY id;\n+\n+INSERT INTO foo (id, col1) VALUES (1, 0);\n+INSERT INTO foo (id, col1) VALUES (2, 0);\n+\n+ASSERT VALUES bar (id, count) VALUES (1, 1);\n+ASSERT VALUES bar (id, count) VALUES (2, 1);\n+\n+CREATE OR REPLACE TABLE bar AS SELECT id, COUNT(col1) as count FROM foo WHERE id > 1 GROUP BY id;\n+\n+INSERT INTO foo (id, col1) VALUES (1, 0);\n+INSERT INTO foo (id, col1) VALUES (2, -1);\n+\n+ASSERT VALUES bar (id, count) VALUES (2, 2);\n+\n+----------------------------------------------------------------------------------------------------\n+--@test: remove filter in StreamAggregate where columns are not already in input schema\n+--@test: add filter in StreamAggregate where columns are not in input schema\n --@expected.error: io.confluent.ksql.util.KsqlException\n---@expected.message: Upgrades not yet supported for StreamAggregate\n+--@expected.message: StreamAggregate must have matching nonAggregateColumns. Values differ: [`ID`, `ROWTIME`, `COL1`] vs. [`ID`, `ROWTIME`]\n ----------------------------------------------------------------------------------------------------\n SET 'ksql.create.or.replace.enabled' = 'true';\n \n CREATE STREAM foo (id INT KEY, col1 INT) WITH (kafka_topic='foo', value_format='JSON');\n+CREATE TABLE bar AS SELECT id, COUNT(*) as count FROM foo WHERE col1 > 0 GROUP BY id;\n+\n+CREATE OR REPLACE TABLE bar AS SELECT id, COUNT(*) as count FROM foo GROUP BY id;\n \n+----------------------------------------------------------------------------------------------------\n+-- until we think this through a little bit more, don't allow changing non-aggregate columns\n+-- to StreamAggregate nodes, though this should technically be OK\n+\n+--@test: add filter in StreamAggregate where columns are not in input schema\n+--@expected.error: io.confluent.ksql.util.KsqlException\n+--@expected.message: StreamAggregate must have matching nonAggregateColumns. Values differ: [`ID`, `ROWTIME`] vs. [`ID`, `COL1`]", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTg0MTE1OA=="}, "originalCommit": {"oid": "969f74b265c501b3a9a6e97e72776a063c184f99"}, "originalPosition": 139}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTkzNjY3Mw==", "bodyText": "and specifically for fixing the rowtime issue: #3732", "url": "https://github.com/confluentinc/ksql/pull/6076#discussion_r475936673", "createdAt": "2020-08-24T22:49:33Z", "author": {"login": "agavra"}, "path": "ksqldb-functional-tests/src/test/resources/sql-tests/query-upgrades/filters.sql", "diffHunk": "@@ -131,16 +125,133 @@ CREATE STREAM j AS SELECT s.id, s.foo, t.bar FROM s JOIN t ON s.id = t.id;\n CREATE OR REPLACE STREAM j AS SELECT s.id, s.foo, t.bar FROM s JOIN t ON s.id = t.id WHERE s.foo > 0;\n \n ----------------------------------------------------------------------------------------------------\n---@test: add filter to StreamAggregate\n+--@test: change filter in StreamAggregate (StreamGroupByKey)\n+----------------------------------------------------------------------------------------------------\n+SET 'ksql.create.or.replace.enabled' = 'true';\n+\n+CREATE STREAM foo (id INT KEY, col1 INT) WITH (kafka_topic='foo', value_format='JSON');\n+CREATE TABLE bar AS SELECT id, COUNT(*) as count FROM foo WHERE col1 >= 0 GROUP BY id;\n+\n+INSERT INTO foo (id, col1) VALUES (1, 0);\n+INSERT INTO foo (id, col1) VALUES (2, 0);\n+\n+ASSERT VALUES bar (id, count) VALUES (1, 1);\n+ASSERT VALUES bar (id, count) VALUES (2, 1);\n+\n+CREATE OR REPLACE TABLE bar AS SELECT id, COUNT(*) as count FROM foo WHERE col1 > 0 GROUP BY id;\n+\n+INSERT INTO foo (id, col1) VALUES (1, 0);\n+INSERT INTO foo (id, col1) VALUES (2, 1);\n+\n+ASSERT VALUES bar (id, count) VALUES (2, 2);\n+\n+----------------------------------------------------------------------------------------------------\n+--@test: change filter in StreamAggregate (StreamGroupBy)\n+----------------------------------------------------------------------------------------------------\n+SET 'ksql.create.or.replace.enabled' = 'true';\n+\n+CREATE STREAM foo (id INT KEY, col1 INT) WITH (kafka_topic='foo', value_format='JSON');\n+CREATE TABLE bar AS SELECT col1, COUNT(*) as count FROM foo WHERE col1 >= 0 GROUP BY col1;\n+\n+INSERT INTO foo (col1, id) VALUES (1, 0);\n+INSERT INTO foo (col1, id) VALUES (2, 0);\n+\n+ASSERT VALUES bar (col1, count) VALUES (1, 1);\n+ASSERT VALUES bar (col1, count) VALUES (2, 1);\n+\n+CREATE OR REPLACE TABLE bar AS SELECT col1, COUNT(*) as count FROM foo WHERE col1 > 1 GROUP BY col1;\n+\n+INSERT INTO foo (col1, id) VALUES (1, 0);\n+INSERT INTO foo (col1, id) VALUES (2, 1);\n+\n+ASSERT VALUES bar (col1, count) VALUES (2, 2);\n+\n+----------------------------------------------------------------------------------------------------\n+--@test: add filter in StreamAggregate where columns are already in input schema\n+----------------------------------------------------------------------------------------------------\n+SET 'ksql.create.or.replace.enabled' = 'true';\n+\n+CREATE STREAM foo (id INT KEY, col1 INT) WITH (kafka_topic='foo', value_format='JSON');\n+CREATE TABLE bar AS SELECT id, COUNT(col1) as count FROM foo GROUP BY id;\n+\n+INSERT INTO foo (id, col1) VALUES (1, 0);\n+INSERT INTO foo (id, col1) VALUES (2, 0);\n+\n+ASSERT VALUES bar (id, count) VALUES (1, 1);\n+ASSERT VALUES bar (id, count) VALUES (2, 1);\n+\n+CREATE OR REPLACE TABLE bar AS SELECT id, COUNT(col1) as count FROM foo WHERE col1 > 0 GROUP BY id;\n+\n+INSERT INTO foo (id, col1) VALUES (1, 0);\n+INSERT INTO foo (id, col1) VALUES (2, 1);\n+\n+ASSERT VALUES bar (id, count) VALUES (2, 2);\n+\n+----------------------------------------------------------------------------------------------------\n+--@test: remove filter in StreamAggregate where columns are already in input schema\n+----------------------------------------------------------------------------------------------------\n+SET 'ksql.create.or.replace.enabled' = 'true';\n+\n+CREATE STREAM foo (id INT KEY, col1 INT) WITH (kafka_topic='foo', value_format='JSON');\n+CREATE TABLE bar AS SELECT id, COUNT(col1) as count FROM foo WHERE col1 > 0 GROUP BY id;\n+\n+INSERT INTO foo (id, col1) VALUES (1, 1);\n+\n+ASSERT VALUES bar (id, count) VALUES (1, 1);\n+\n+CREATE OR REPLACE TABLE bar AS SELECT id, COUNT(col1) as count FROM foo GROUP BY id;\n+\n+INSERT INTO foo (id, col1) VALUES (1, 0);\n+\n+ASSERT VALUES bar (id, count) VALUES (1, 2);\n+\n+----------------------------------------------------------------------------------------------------\n+--@test: change filter in StreamAggregate to another column that already exists in input\n+----------------------------------------------------------------------------------------------------\n+SET 'ksql.create.or.replace.enabled' = 'true';\n+\n+CREATE STREAM foo (id INT KEY, col1 INT) WITH (kafka_topic='foo', value_format='JSON');\n+CREATE TABLE bar AS SELECT id, COUNT(col1) as count FROM foo WHERE col1 >= 0 GROUP BY id;\n+\n+INSERT INTO foo (id, col1) VALUES (1, 0);\n+INSERT INTO foo (id, col1) VALUES (2, 0);\n+\n+ASSERT VALUES bar (id, count) VALUES (1, 1);\n+ASSERT VALUES bar (id, count) VALUES (2, 1);\n+\n+CREATE OR REPLACE TABLE bar AS SELECT id, COUNT(col1) as count FROM foo WHERE id > 1 GROUP BY id;\n+\n+INSERT INTO foo (id, col1) VALUES (1, 0);\n+INSERT INTO foo (id, col1) VALUES (2, -1);\n+\n+ASSERT VALUES bar (id, count) VALUES (2, 2);\n+\n+----------------------------------------------------------------------------------------------------\n+--@test: remove filter in StreamAggregate where columns are not already in input schema\n+--@test: add filter in StreamAggregate where columns are not in input schema\n --@expected.error: io.confluent.ksql.util.KsqlException\n---@expected.message: Upgrades not yet supported for StreamAggregate\n+--@expected.message: StreamAggregate must have matching nonAggregateColumns. Values differ: [`ID`, `ROWTIME`, `COL1`] vs. [`ID`, `ROWTIME`]\n ----------------------------------------------------------------------------------------------------\n SET 'ksql.create.or.replace.enabled' = 'true';\n \n CREATE STREAM foo (id INT KEY, col1 INT) WITH (kafka_topic='foo', value_format='JSON');\n+CREATE TABLE bar AS SELECT id, COUNT(*) as count FROM foo WHERE col1 > 0 GROUP BY id;\n+\n+CREATE OR REPLACE TABLE bar AS SELECT id, COUNT(*) as count FROM foo GROUP BY id;\n \n+----------------------------------------------------------------------------------------------------\n+-- until we think this through a little bit more, don't allow changing non-aggregate columns\n+-- to StreamAggregate nodes, though this should technically be OK\n+\n+--@test: add filter in StreamAggregate where columns are not in input schema\n+--@expected.error: io.confluent.ksql.util.KsqlException\n+--@expected.message: StreamAggregate must have matching nonAggregateColumns. Values differ: [`ID`, `ROWTIME`] vs. [`ID`, `COL1`]", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTg0MTE1OA=="}, "originalCommit": {"oid": "969f74b265c501b3a9a6e97e72776a063c184f99"}, "originalPosition": 139}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2929, "cost": 1, "resetAt": "2021-11-12T19:05:54Z"}}}