{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQ3NTUwMzgx", "number": 5811, "title": "test:  Adds another test case for pull queries for active restoring state", "bodyText": "Description\nThis test case covers restoring all state when active restarts and checks that we can see the lag as it restores completely.\nTesting done\nRan integration tests\nReviewer checklist\n\n Ensure docs are updated if necessary. (eg. if a user visible feature is being added or changed).\n Ensure relevant issues are linked (description should include text like \"Fixes #\")", "createdAt": "2020-07-10T17:11:15Z", "url": "https://github.com/confluentinc/ksql/pull/5811", "merged": true, "mergeCommit": {"oid": "f98f5305509a07136d93073f8e2af20c11142eed"}, "closed": true, "closedAt": "2020-07-11T01:54:04Z", "author": {"login": "AlanConfluent"}, "timelineItems": {"totalCount": 17, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcznVougFqTQ0NjU4NTE4MQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcztEq9gH2gAyNDQ3NTUwMzgxOmUyNWRmNTFmNjRkMzU1OGI5ZjAyY2EwZTdlOWM1NGVhZTJlYTQ2M2Q=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2NTg1MTgx", "url": "https://github.com/confluentinc/ksql/pull/5811#pullrequestreview-446585181", "createdAt": "2020-07-10T17:46:09Z", "commit": {"oid": "67b17d59d38de14886f913fe9988b0733356d7cd"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQxNzo0NjowOVrOGwACDA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQxNzo0NjowOVrOGwACDA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjk4NTM1Ng==", "bodyText": "This method checks that the clusterStatus response contains lag reporting? Not that there is actual lag, right?", "url": "https://github.com/confluentinc/ksql/pull/5811#discussion_r452985356", "createdAt": "2020-07-10T17:46:09Z", "author": {"login": "vpapavas"}, "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/HighAvailabilityTestUtil.java", "diffHunk": "@@ -264,5 +270,121 @@ public static void sendLagReportingRequest(\n           .get();\n     }\n   }\n+\n+  static String extractQueryId(final String outputString) {\n+    final java.util.regex.Matcher matcher = QUERY_ID_PATTERN.matcher(outputString);\n+    if (!matcher.find()) {\n+      throw new AssertionError(\"Could not find query id in: \" + outputString);\n+    }\n+    return matcher.group(1);\n+  }\n+\n+  // Ensures that lags exist for the cluster.  Makes the simplified assumption that there's just one\n+  // state store.\n+  static BiFunction<KsqlHostInfoEntity, Map<KsqlHostInfoEntity, HostStatusEntity>, Boolean>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "67b17d59d38de14886f913fe9988b0733356d7cd"}, "originalPosition": 43}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2NTg2NDMz", "url": "https://github.com/confluentinc/ksql/pull/5811#pullrequestreview-446586433", "createdAt": "2020-07-10T17:48:13Z", "commit": {"oid": "67b17d59d38de14886f913fe9988b0733356d7cd"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQxNzo0ODoxM1rOGwAF7Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQxNzo0ODoxM1rOGwAF7Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjk4NjM0OQ==", "bodyText": "This method checks for a specific server if there is actual lag reported? I don't understand the if condition: currentOffset < 0  what does this mean?", "url": "https://github.com/confluentinc/ksql/pull/5811#discussion_r452986349", "createdAt": "2020-07-10T17:48:13Z", "author": {"login": "vpapavas"}, "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/HighAvailabilityTestUtil.java", "diffHunk": "@@ -264,5 +270,121 @@ public static void sendLagReportingRequest(\n           .get();\n     }\n   }\n+\n+  static String extractQueryId(final String outputString) {\n+    final java.util.regex.Matcher matcher = QUERY_ID_PATTERN.matcher(outputString);\n+    if (!matcher.find()) {\n+      throw new AssertionError(\"Could not find query id in: \" + outputString);\n+    }\n+    return matcher.group(1);\n+  }\n+\n+  // Ensures that lags exist for the cluster.  Makes the simplified assumption that there's just one\n+  // state store.\n+  static BiFunction<KsqlHostInfoEntity, Map<KsqlHostInfoEntity, HostStatusEntity>, Boolean>\n+  lagsExist(\n+      final int expectedClusterSize\n+  ) {\n+    return (remoteServer, clusterStatus) -> {\n+      if (clusterStatus.size() == expectedClusterSize) {\n+        int numWithLag = 0;\n+        for (Entry<KsqlHostInfoEntity, HostStatusEntity> e : clusterStatus.entrySet()) {\n+          if (e.getValue().getHostStoreLags().getStateStoreLags().size() > 0) {\n+            numWithLag++;\n+          }\n+        }\n+        if (numWithLag >= Math.min(expectedClusterSize, 2)) {\n+          LOG.info(\"Found expected lags: {}\", clusterStatus.toString());\n+          return true;\n+        }\n+      }\n+      LOG.info(\"Didn't yet find expected lags: {}\", clusterStatus.toString());\n+      return false;\n+    };\n+  }\n+\n+  // Ensures that lags exist for the given host.  Makes the simplified assumption that there's just\n+  // one state store.\n+  static BiFunction<KsqlHostInfoEntity, Map<KsqlHostInfoEntity, HostStatusEntity>, Boolean>\n+  lagsExist(\n+      final int clusterSize,\n+      final KsqlHostInfoEntity server,\n+      final long currentOffset,\n+      final long endOffset\n+  ) {\n+    return (remote, clusterStatus) -> {\n+      if (clusterStatus.size() == clusterSize) {\n+        HostStatusEntity hostStatusEntity = clusterStatus.get(server);\n+        if (hostStatusEntity == null) {\n+          LOG.info(\"Didn't find {}\", server.toString());\n+          return false;\n+        }\n+        Pair<Long, Long> pair = getOffsets(server,clusterStatus);\n+        long current = pair.left;\n+        long end = pair.right;\n+        if ((currentOffset < 0 || current >= currentOffset) && end >= endOffset) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "67b17d59d38de14886f913fe9988b0733356d7cd"}, "originalPosition": 84}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2NTg2ODg0", "url": "https://github.com/confluentinc/ksql/pull/5811#pullrequestreview-446586884", "createdAt": "2020-07-10T17:48:57Z", "commit": {"oid": "67b17d59d38de14886f913fe9988b0733356d7cd"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQxNzo0ODo1OFrOGwAHXg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQxNzo0ODo1OFrOGwAHXg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mjk4NjcxOA==", "bodyText": "Why do we need the lagsExists check here?", "url": "https://github.com/confluentinc/ksql/pull/5811#discussion_r452986718", "createdAt": "2020-07-10T17:48:58Z", "author": {"login": "vpapavas"}, "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/PullQueryRoutingFunctionalTest.java", "diffHunk": "@@ -258,19 +249,13 @@ public void cleanUp() {\n     APP_SHUTOFFS_2.reset();\n   }\n \n-  @AfterClass\n-  public static void classTearDown() {\n-    TMP.delete();\n-  }\n-\n   @Test\n   public void shouldQueryActiveWhenActiveAliveQueryIssuedToStandby() throws Exception {\n     // Given:\n-    ClusterFormation clusterFormation = findClusterFormation(REST_APP_0, REST_APP_1, REST_APP_2);\n+    ClusterFormation clusterFormation = findClusterFormation(TEST_APP_0, TEST_APP_1, TEST_APP_2);\n     waitForClusterToBeDiscovered(clusterFormation.standBy.getApp(), 3);\n     waitForRemoteServerToChangeStatus(clusterFormation.router.getApp(),\n-        clusterFormation.router.getHost(),\n-        PullQueryRoutingFunctionalTest::lagsExist);\n+        clusterFormation.router.getHost(), HighAvailabilityTestUtil.lagsExist(3));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "67b17d59d38de14886f913fe9988b0733356d7cd"}, "originalPosition": 176}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2NjM2Mjg1", "url": "https://github.com/confluentinc/ksql/pull/5811#pullrequestreview-446636285", "createdAt": "2020-07-10T19:00:24Z", "commit": {"oid": "34b1b9f322d27f108070f642924ea3b059880456"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQxOTowMDoyNFrOGwChyA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQxOTowMDoyNFrOGwChyA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzAyNjI0OA==", "bodyText": "This checks that the currentOffset is 3 and endOffset is 5, right?", "url": "https://github.com/confluentinc/ksql/pull/5811#discussion_r453026248", "createdAt": "2020-07-10T19:00:24Z", "author": {"login": "vpapavas"}, "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/PullQueryRoutingFunctionalTest.java", "diffHunk": "@@ -376,10 +358,11 @@ public void shouldFilterLaggyServers() throws Exception {\n \n     waitForRemoteServerToChangeStatus(clusterFormation.router.getApp(),\n         clusterFormation.router.getHost(),\n-        PullQueryRoutingFunctionalTest.lagsExist(clusterFormation.standBy.getHost(), 5));\n+        HighAvailabilityTestUtil.lagsReported(3, clusterFormation.standBy.getHost(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "34b1b9f322d27f108070f642924ea3b059880456"}, "originalPosition": 227}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2NjQxOTU3", "url": "https://github.com/confluentinc/ksql/pull/5811#pullrequestreview-446641957", "createdAt": "2020-07-10T19:10:27Z", "commit": {"oid": "34b1b9f322d27f108070f642924ea3b059880456"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQxOToxMDoyOFrOGwCzCg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQxOToxMDoyOFrOGwCzCg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzAzMDY2Ng==", "bodyText": "I am confused by the title and description of the PR. You say you add a new test case for restoring the active after it restarts but that's not what's happening here: the active gets killed and we query the standby that has lag. Am I missing something?", "url": "https://github.com/confluentinc/ksql/pull/5811#discussion_r453030666", "createdAt": "2020-07-10T19:10:28Z", "author": {"login": "vpapavas"}, "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/PullQueryRoutingFunctionalTest.java", "diffHunk": "@@ -360,11 +343,10 @@ public void shouldQueryStandbyWhenActiveDeadStandbyAliveQueryIssuedToRouter() th\n   @Test", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "34b1b9f322d27f108070f642924ea3b059880456"}, "originalPosition": 209}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5fdf11eecf09d378a536df49c0ad4c82d4c1b515", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/5fdf11eecf09d378a536df49c0ad4c82d4c1b515", "committedDate": "2020-07-10T19:46:51Z", "message": "test: Adds another test case for single active to pull query correctness tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e2c57b36a201f751fec0fc03891bcf5c52a1c6b2", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/e2c57b36a201f751fec0fc03891bcf5c52a1c6b2", "committedDate": "2020-07-10T19:46:51Z", "message": "Working state"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "092b78dea6c12e898ef93569a9d1daa29ad4a574", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/092b78dea6c12e898ef93569a9d1daa29ad4a574", "committedDate": "2020-07-10T19:46:51Z", "message": "Splits test into another file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "413c9293e03d0a509ccf2b6927766800bbd32109", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/413c9293e03d0a509ccf2b6927766800bbd32109", "committedDate": "2020-07-10T19:46:51Z", "message": "Feedback"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1af6cf792f4feb94d00330a3f3f4ae4eed4fb9a8", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/1af6cf792f4feb94d00330a3f3f4ae4eed4fb9a8", "committedDate": "2020-07-10T19:46:51Z", "message": "Feedback"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "34b1b9f322d27f108070f642924ea3b059880456", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/34b1b9f322d27f108070f642924ea3b059880456", "committedDate": "2020-07-10T18:53:58Z", "message": "Feedback"}, "afterCommit": {"oid": "1af6cf792f4feb94d00330a3f3f4ae4eed4fb9a8", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/1af6cf792f4feb94d00330a3f3f4ae4eed4fb9a8", "committedDate": "2020-07-10T19:46:51Z", "message": "Feedback"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "746400f3e755d05770d849c3eea1a1019d7d7d0c", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/746400f3e755d05770d849c3eea1a1019d7d7d0c", "committedDate": "2020-07-10T21:03:30Z", "message": "Adds annotation"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2NzE2MDA3", "url": "https://github.com/confluentinc/ksql/pull/5811#pullrequestreview-446716007", "createdAt": "2020-07-10T21:41:39Z", "commit": {"oid": "746400f3e755d05770d849c3eea1a1019d7d7d0c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMTo0MTozOVrOGwGZxQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMTo0MTozOVrOGwGZxQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzA4OTczMw==", "bodyText": "Now the title makes sense :)", "url": "https://github.com/confluentinc/ksql/pull/5811#discussion_r453089733", "createdAt": "2020-07-10T21:41:39Z", "author": {"login": "vpapavas"}, "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/PullQuerySingleNodeFunctionalTest.java", "diffHunk": "@@ -0,0 +1,346 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.integration;\n+\n+import static io.confluent.ksql.rest.integration.HighAvailabilityTestUtil.getOffsets;\n+import static io.confluent.ksql.rest.integration.HighAvailabilityTestUtil.waitForRemoteServerToChangeStatus;\n+import static io.confluent.ksql.rest.integration.HighAvailabilityTestUtil.waitForStreamsMetadataToInitialize;\n+import static io.confluent.ksql.util.KsqlConfig.KSQL_STREAMS_PREFIX;\n+import static org.apache.kafka.streams.StreamsConfig.CONSUMER_PREFIX;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.hasSize;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.not;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Iterables;\n+import io.confluent.common.utils.IntegrationTest;\n+import io.confluent.ksql.integration.IntegrationTestHarness;\n+import io.confluent.ksql.integration.Retry;\n+import io.confluent.ksql.name.ColumnName;\n+import io.confluent.ksql.rest.entity.ClusterStatusResponse;\n+import io.confluent.ksql.rest.entity.KsqlEntity;\n+import io.confluent.ksql.rest.entity.KsqlHostInfoEntity;\n+import io.confluent.ksql.rest.entity.StreamedRow;\n+import io.confluent.ksql.rest.integration.FaultyKafkaConsumer.FaultyKafkaConsumer0;\n+import io.confluent.ksql.rest.integration.HighAvailabilityTestUtil.Shutoffs;\n+import io.confluent.ksql.rest.server.KsqlRestConfig;\n+import io.confluent.ksql.rest.server.TestKsqlRestApp;\n+import io.confluent.ksql.rest.server.utils.TestUtils;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.serde.FormatFactory;\n+import io.confluent.ksql.serde.SerdeOption;\n+import io.confluent.ksql.test.util.KsqlIdentifierTestUtil;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlRequestConfig;\n+import io.confluent.ksql.util.Pair;\n+import io.confluent.ksql.util.UserDataProvider;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n+import kafka.zookeeper.ZooKeeperClientException;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.RuleChain;\n+import org.junit.rules.TemporaryFolder;\n+import org.junit.rules.Timeout;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+@Category({IntegrationTest.class})\n+public class PullQuerySingleNodeFunctionalTest {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(PullQuerySingleNodeFunctionalTest.class);\n+\n+  private static final Pattern QUERY_ID_PATTERN = Pattern.compile(\"query with ID (\\\\S+)\");\n+  private static final String USER_TOPIC = \"user_topic_\";\n+  private static final String USERS_STREAM = \"users\";\n+  private static final UserDataProvider USER_PROVIDER = new UserDataProvider();\n+  private static final int HEADER = 1;\n+  private static final int BASE_TIME = 1_000_000;\n+  private final static String KEY = Iterables.get(USER_PROVIDER.data().keySet(), 0);\n+  private final static String KEY_3 = Iterables.get(USER_PROVIDER.data().keySet(), 3);\n+  private static final Map<String, ?> LAG_FILTER_3 =\n+      ImmutableMap.of(KsqlConfig.KSQL_QUERY_PULL_MAX_ALLOWED_OFFSET_LAG_CONFIG, \"3\");\n+\n+  private static final PhysicalSchema AGGREGATE_SCHEMA = PhysicalSchema.from(\n+      LogicalSchema.builder()\n+          .keyColumn(ColumnName.of(\"USERID\"), SqlTypes.STRING)\n+          .valueColumn(ColumnName.of(\"COUNT\"), SqlTypes.BIGINT)\n+          .build(),\n+      SerdeOption.none()\n+  );\n+\n+  private static final Map<String, Object> COMMON_CONFIG = ImmutableMap.<String, Object>builder()\n+      .put(KSQL_STREAMS_PREFIX + StreamsConfig.NUM_STREAM_THREADS_CONFIG, 1)\n+      .put(KsqlRestConfig.KSQL_HEARTBEAT_ENABLE_CONFIG, true)\n+      .put(KsqlRestConfig.KSQL_HEARTBEAT_SEND_INTERVAL_MS_CONFIG, 500)\n+      .put(KsqlRestConfig.KSQL_HEARTBEAT_CHECK_INTERVAL_MS_CONFIG, 1000)\n+      .put(KsqlRestConfig.KSQL_HEARTBEAT_DISCOVER_CLUSTER_MS_CONFIG, 2000)\n+      .put(KsqlRestConfig.KSQL_LAG_REPORTING_ENABLE_CONFIG, true)\n+      .put(KsqlRestConfig.KSQL_LAG_REPORTING_SEND_INTERVAL_MS_CONFIG, 3000)\n+      .put(KsqlConfig.KSQL_QUERY_PULL_ENABLE_STANDBY_READS, true)\n+      .put(KsqlConfig.KSQL_STREAMS_PREFIX + \"num.standby.replicas\", 1)\n+      .put(KsqlConfig.KSQL_SHUTDOWN_TIMEOUT_MS_CONFIG, 1000)\n+      .build();\n+\n+  private static final IntegrationTestHarness TEST_HARNESS = IntegrationTestHarness.build();\n+  private static final TemporaryFolder TMP = new TemporaryFolder();\n+  private static final int INT_PORT_0 = TestUtils.findFreeLocalPort();\n+  private static final KsqlHostInfoEntity host0 = new KsqlHostInfoEntity(\"localhost\", INT_PORT_0);\n+  private static final Shutoffs APP_SHUTOFFS_0 = new Shutoffs();\n+\n+  @Rule\n+  public final TestKsqlRestApp REST_APP_0 = TestKsqlRestApp\n+      .builder(TEST_HARNESS::kafkaBootstrapServers)\n+      .withProperty(KSQL_STREAMS_PREFIX + StreamsConfig.STATE_DIR_CONFIG, getNewStateDir(TMP))\n+      .withProperty(KsqlRestConfig.LISTENERS_CONFIG, \"http://localhost:0\")\n+      .withProperty(KsqlRestConfig.INTERNAL_LISTENER_CONFIG, \"http://localhost:\" + INT_PORT_0)\n+      .withProperty(KsqlRestConfig.ADVERTISED_LISTENER_CONFIG, \"http://localhost:\" + INT_PORT_0)\n+      .withFaultyKsqlClient(APP_SHUTOFFS_0::getKsqlOutgoing)\n+      .withProperty(KSQL_STREAMS_PREFIX + CONSUMER_PREFIX\n+          + ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG, FaultyKafkaConsumer0.class.getName())\n+      .withProperty(KSQL_STREAMS_PREFIX + CONSUMER_PREFIX + \"max.poll.records\", 1)\n+      .withProperties(COMMON_CONFIG)\n+      .build();\n+\n+  private final AtomicLong timestampSupplier = new AtomicLong(BASE_TIME);\n+  private String output;\n+  private String queryId;\n+  private String sql;\n+  private String sqlKey3;\n+  private String topic;\n+\n+  @ClassRule\n+  public static final RuleChain CHAIN = RuleChain\n+      .outerRule(Retry.of(3, ZooKeeperClientException.class, 3, TimeUnit.SECONDS))\n+      .around(TEST_HARNESS).around(TMP);\n+\n+  @Rule\n+  public final Timeout timeout = Timeout.builder()\n+      .withTimeout(1, TimeUnit.MINUTES)\n+      .withLookingForStuckThread(true)\n+      .build();\n+\n+\n+  @BeforeClass\n+  public static void setUpClass() {\n+    FaultyKafkaConsumer0.setPauseOffset(APP_SHUTOFFS_0::getKafkaPauseOffset);\n+  }\n+\n+  @After\n+  public void cleanUp() {\n+    REST_APP_0.closePersistentQueries();\n+    REST_APP_0.dropSourcesExcept();\n+    APP_SHUTOFFS_0.reset();\n+  }\n+\n+  @Before\n+  public void setUp() {\n+    //Create topic with 1 partition to control who is active and standby\n+    topic = USER_TOPIC + KsqlIdentifierTestUtil.uniqueIdentifierName();\n+    TEST_HARNESS.ensureTopics(1, topic);\n+\n+    TEST_HARNESS.produceRows(\n+        topic,\n+        USER_PROVIDER,\n+        FormatFactory.JSON,\n+        timestampSupplier::getAndIncrement\n+    );\n+\n+    //Create stream\n+    makeAdminRequest(\n+        REST_APP_0,\n+        \"CREATE STREAM \" + USERS_STREAM\n+            + \" (\" + USER_PROVIDER.ksqlSchemaString(false) + \")\"\n+            + \" WITH (\"\n+            + \"   kafka_topic='\" + topic + \"', \"\n+            + \"   value_format='JSON');\"\n+    );\n+    //Create table\n+    output = KsqlIdentifierTestUtil.uniqueIdentifierName();\n+    sql = \"SELECT * FROM \" + output + \" WHERE USERID = '\" + KEY + \"';\";\n+    List<KsqlEntity> res = makeAdminRequestWithResponse(\n+        REST_APP_0,\n+        \"CREATE TABLE \" + output + \" AS\"\n+            + \" SELECT \" + USER_PROVIDER.key() + \", COUNT(1) AS COUNT FROM \" + USERS_STREAM\n+            + \" GROUP BY \" + USER_PROVIDER.key() + \";\"\n+    );\n+    queryId = extractQueryId(res.get(0).toString());\n+    queryId = queryId.substring(0, queryId.length() - 1);\n+    waitForTableRows(TEST_HARNESS);\n+\n+    sqlKey3 = \"SELECT * FROM \" + output + \" WHERE USERID = '\" + KEY_3\n+        + \"';\";\n+    waitForStreamsMetadataToInitialize(\n+        REST_APP_0, ImmutableList.of(host0), queryId);\n+  }\n+\n+  @Test", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "746400f3e755d05770d849c3eea1a1019d7d7d0c"}, "originalPosition": 211}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2NzE2MzE0", "url": "https://github.com/confluentinc/ksql/pull/5811#pullrequestreview-446716314", "createdAt": "2020-07-10T21:42:28Z", "commit": {"oid": "746400f3e755d05770d849c3eea1a1019d7d7d0c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMTo0MjoyOVrOGwGauw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMTo0MjoyOVrOGwGauw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzA4OTk3OQ==", "bodyText": "These are common methods with the PullQueryRoutingFunctionalTest. Maybe move them to the HATestUtil class so that they are in one place?", "url": "https://github.com/confluentinc/ksql/pull/5811#discussion_r453089979", "createdAt": "2020-07-10T21:42:29Z", "author": {"login": "vpapavas"}, "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/PullQuerySingleNodeFunctionalTest.java", "diffHunk": "@@ -0,0 +1,346 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.integration;\n+\n+import static io.confluent.ksql.rest.integration.HighAvailabilityTestUtil.getOffsets;\n+import static io.confluent.ksql.rest.integration.HighAvailabilityTestUtil.waitForRemoteServerToChangeStatus;\n+import static io.confluent.ksql.rest.integration.HighAvailabilityTestUtil.waitForStreamsMetadataToInitialize;\n+import static io.confluent.ksql.util.KsqlConfig.KSQL_STREAMS_PREFIX;\n+import static org.apache.kafka.streams.StreamsConfig.CONSUMER_PREFIX;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.hasSize;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.not;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableMap;\n+import com.google.common.collect.Iterables;\n+import io.confluent.common.utils.IntegrationTest;\n+import io.confluent.ksql.integration.IntegrationTestHarness;\n+import io.confluent.ksql.integration.Retry;\n+import io.confluent.ksql.name.ColumnName;\n+import io.confluent.ksql.rest.entity.ClusterStatusResponse;\n+import io.confluent.ksql.rest.entity.KsqlEntity;\n+import io.confluent.ksql.rest.entity.KsqlHostInfoEntity;\n+import io.confluent.ksql.rest.entity.StreamedRow;\n+import io.confluent.ksql.rest.integration.FaultyKafkaConsumer.FaultyKafkaConsumer0;\n+import io.confluent.ksql.rest.integration.HighAvailabilityTestUtil.Shutoffs;\n+import io.confluent.ksql.rest.server.KsqlRestConfig;\n+import io.confluent.ksql.rest.server.TestKsqlRestApp;\n+import io.confluent.ksql.rest.server.utils.TestUtils;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.serde.FormatFactory;\n+import io.confluent.ksql.serde.SerdeOption;\n+import io.confluent.ksql.test.util.KsqlIdentifierTestUtil;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.KsqlRequestConfig;\n+import io.confluent.ksql.util.Pair;\n+import io.confluent.ksql.util.UserDataProvider;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicLong;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n+import kafka.zookeeper.ZooKeeperClientException;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.RuleChain;\n+import org.junit.rules.TemporaryFolder;\n+import org.junit.rules.Timeout;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+@Category({IntegrationTest.class})\n+public class PullQuerySingleNodeFunctionalTest {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(PullQuerySingleNodeFunctionalTest.class);\n+\n+  private static final Pattern QUERY_ID_PATTERN = Pattern.compile(\"query with ID (\\\\S+)\");\n+  private static final String USER_TOPIC = \"user_topic_\";\n+  private static final String USERS_STREAM = \"users\";\n+  private static final UserDataProvider USER_PROVIDER = new UserDataProvider();\n+  private static final int HEADER = 1;\n+  private static final int BASE_TIME = 1_000_000;\n+  private final static String KEY = Iterables.get(USER_PROVIDER.data().keySet(), 0);\n+  private final static String KEY_3 = Iterables.get(USER_PROVIDER.data().keySet(), 3);\n+  private static final Map<String, ?> LAG_FILTER_3 =\n+      ImmutableMap.of(KsqlConfig.KSQL_QUERY_PULL_MAX_ALLOWED_OFFSET_LAG_CONFIG, \"3\");\n+\n+  private static final PhysicalSchema AGGREGATE_SCHEMA = PhysicalSchema.from(\n+      LogicalSchema.builder()\n+          .keyColumn(ColumnName.of(\"USERID\"), SqlTypes.STRING)\n+          .valueColumn(ColumnName.of(\"COUNT\"), SqlTypes.BIGINT)\n+          .build(),\n+      SerdeOption.none()\n+  );\n+\n+  private static final Map<String, Object> COMMON_CONFIG = ImmutableMap.<String, Object>builder()\n+      .put(KSQL_STREAMS_PREFIX + StreamsConfig.NUM_STREAM_THREADS_CONFIG, 1)\n+      .put(KsqlRestConfig.KSQL_HEARTBEAT_ENABLE_CONFIG, true)\n+      .put(KsqlRestConfig.KSQL_HEARTBEAT_SEND_INTERVAL_MS_CONFIG, 500)\n+      .put(KsqlRestConfig.KSQL_HEARTBEAT_CHECK_INTERVAL_MS_CONFIG, 1000)\n+      .put(KsqlRestConfig.KSQL_HEARTBEAT_DISCOVER_CLUSTER_MS_CONFIG, 2000)\n+      .put(KsqlRestConfig.KSQL_LAG_REPORTING_ENABLE_CONFIG, true)\n+      .put(KsqlRestConfig.KSQL_LAG_REPORTING_SEND_INTERVAL_MS_CONFIG, 3000)\n+      .put(KsqlConfig.KSQL_QUERY_PULL_ENABLE_STANDBY_READS, true)\n+      .put(KsqlConfig.KSQL_STREAMS_PREFIX + \"num.standby.replicas\", 1)\n+      .put(KsqlConfig.KSQL_SHUTDOWN_TIMEOUT_MS_CONFIG, 1000)\n+      .build();\n+\n+  private static final IntegrationTestHarness TEST_HARNESS = IntegrationTestHarness.build();\n+  private static final TemporaryFolder TMP = new TemporaryFolder();\n+  private static final int INT_PORT_0 = TestUtils.findFreeLocalPort();\n+  private static final KsqlHostInfoEntity host0 = new KsqlHostInfoEntity(\"localhost\", INT_PORT_0);\n+  private static final Shutoffs APP_SHUTOFFS_0 = new Shutoffs();\n+\n+  @Rule\n+  public final TestKsqlRestApp REST_APP_0 = TestKsqlRestApp\n+      .builder(TEST_HARNESS::kafkaBootstrapServers)\n+      .withProperty(KSQL_STREAMS_PREFIX + StreamsConfig.STATE_DIR_CONFIG, getNewStateDir(TMP))\n+      .withProperty(KsqlRestConfig.LISTENERS_CONFIG, \"http://localhost:0\")\n+      .withProperty(KsqlRestConfig.INTERNAL_LISTENER_CONFIG, \"http://localhost:\" + INT_PORT_0)\n+      .withProperty(KsqlRestConfig.ADVERTISED_LISTENER_CONFIG, \"http://localhost:\" + INT_PORT_0)\n+      .withFaultyKsqlClient(APP_SHUTOFFS_0::getKsqlOutgoing)\n+      .withProperty(KSQL_STREAMS_PREFIX + CONSUMER_PREFIX\n+          + ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG, FaultyKafkaConsumer0.class.getName())\n+      .withProperty(KSQL_STREAMS_PREFIX + CONSUMER_PREFIX + \"max.poll.records\", 1)\n+      .withProperties(COMMON_CONFIG)\n+      .build();\n+\n+  private final AtomicLong timestampSupplier = new AtomicLong(BASE_TIME);\n+  private String output;\n+  private String queryId;\n+  private String sql;\n+  private String sqlKey3;\n+  private String topic;\n+\n+  @ClassRule\n+  public static final RuleChain CHAIN = RuleChain\n+      .outerRule(Retry.of(3, ZooKeeperClientException.class, 3, TimeUnit.SECONDS))\n+      .around(TEST_HARNESS).around(TMP);\n+\n+  @Rule\n+  public final Timeout timeout = Timeout.builder()\n+      .withTimeout(1, TimeUnit.MINUTES)\n+      .withLookingForStuckThread(true)\n+      .build();\n+\n+\n+  @BeforeClass\n+  public static void setUpClass() {\n+    FaultyKafkaConsumer0.setPauseOffset(APP_SHUTOFFS_0::getKafkaPauseOffset);\n+  }\n+\n+  @After\n+  public void cleanUp() {\n+    REST_APP_0.closePersistentQueries();\n+    REST_APP_0.dropSourcesExcept();\n+    APP_SHUTOFFS_0.reset();\n+  }\n+\n+  @Before\n+  public void setUp() {\n+    //Create topic with 1 partition to control who is active and standby\n+    topic = USER_TOPIC + KsqlIdentifierTestUtil.uniqueIdentifierName();\n+    TEST_HARNESS.ensureTopics(1, topic);\n+\n+    TEST_HARNESS.produceRows(\n+        topic,\n+        USER_PROVIDER,\n+        FormatFactory.JSON,\n+        timestampSupplier::getAndIncrement\n+    );\n+\n+    //Create stream\n+    makeAdminRequest(\n+        REST_APP_0,\n+        \"CREATE STREAM \" + USERS_STREAM\n+            + \" (\" + USER_PROVIDER.ksqlSchemaString(false) + \")\"\n+            + \" WITH (\"\n+            + \"   kafka_topic='\" + topic + \"', \"\n+            + \"   value_format='JSON');\"\n+    );\n+    //Create table\n+    output = KsqlIdentifierTestUtil.uniqueIdentifierName();\n+    sql = \"SELECT * FROM \" + output + \" WHERE USERID = '\" + KEY + \"';\";\n+    List<KsqlEntity> res = makeAdminRequestWithResponse(\n+        REST_APP_0,\n+        \"CREATE TABLE \" + output + \" AS\"\n+            + \" SELECT \" + USER_PROVIDER.key() + \", COUNT(1) AS COUNT FROM \" + USERS_STREAM\n+            + \" GROUP BY \" + USER_PROVIDER.key() + \";\"\n+    );\n+    queryId = extractQueryId(res.get(0).toString());\n+    queryId = queryId.substring(0, queryId.length() - 1);\n+    waitForTableRows(TEST_HARNESS);\n+\n+    sqlKey3 = \"SELECT * FROM \" + output + \" WHERE USERID = '\" + KEY_3\n+        + \"';\";\n+    waitForStreamsMetadataToInitialize(\n+        REST_APP_0, ImmutableList.of(host0), queryId);\n+  }\n+\n+  @Test\n+  public void restoreAfterClearState() throws Exception {\n+    waitForStreamsMetadataToInitialize(REST_APP_0, ImmutableList.of(host0), queryId);\n+    waitForRemoteServerToChangeStatus(REST_APP_0, host0, HighAvailabilityTestUtil\n+        .lagsReported(host0, Optional.empty(), 5));\n+\n+    // When:\n+    final List<StreamedRow> rows_0 = makePullQueryRequest(\n+        REST_APP_0, sql, LAG_FILTER_3);\n+\n+    // Then:\n+    assertThat(rows_0, hasSize(HEADER + 1));\n+    KsqlHostInfoEntity host = rows_0.get(1).getSourceHost().get();\n+    assertThat(host.getHost(), is(host0.getHost()));\n+    assertThat(host.getPort(), is(host0.getPort()));\n+    assertThat(rows_0.get(1).getRow(), is(not(Optional.empty())));\n+    assertThat(rows_0.get(1).getRow().get().values(), is(ImmutableList.of(KEY, 1)));\n+\n+    // Stop the server and blow away the state\n+    LOG.info(\"Shutting down the server \" + host0.toString());\n+    REST_APP_0.stop();\n+    String stateDir = (String)REST_APP_0.getBaseConfig()\n+        .get(KSQL_STREAMS_PREFIX + StreamsConfig.STATE_DIR_CONFIG);\n+    clearDir(stateDir);\n+\n+    // Pause incoming kafka consumption\n+    APP_SHUTOFFS_0.setKafkaPauseOffset(2);\n+\n+    LOG.info(\"Restarting the server \" + host0.toString());\n+    REST_APP_0.start();\n+\n+    waitForStreamsMetadataToInitialize(REST_APP_0, ImmutableList.of(host0), queryId);\n+    waitForRemoteServerToChangeStatus(REST_APP_0, host0, HighAvailabilityTestUtil\n+        .lagsReported(host0, Optional.of(2L), 5));\n+\n+    ClusterStatusResponse clusterStatusResponse = HighAvailabilityTestUtil\n+        .sendClusterStatusRequest(REST_APP_0);\n+    Pair<Long, Long> pair = getOffsets(host0, clusterStatusResponse.getClusterStatus());\n+    assertThat(pair.left, is(2L));\n+    assertThat(pair.right, is(5L));\n+\n+    final List<StreamedRow> sameRows = makePullQueryRequest(\n+        REST_APP_0, sql, LAG_FILTER_3);\n+\n+    host = sameRows.get(1).getSourceHost().get();\n+    assertThat(host.getHost(), is(host0.getHost()));\n+    assertThat(host.getPort(), is(host0.getPort()));\n+    assertThat(sameRows.get(1).getRow(), is(not(Optional.empty())));\n+    // Still haven't gotten the update yet\n+    assertThat(sameRows.get(1).getRow().get().values(), is(ImmutableList.of(KEY, 1)));\n+\n+    // Row not found!\n+    final List<StreamedRow> headerOnly = makePullQueryRequest(\n+        REST_APP_0, sqlKey3, LAG_FILTER_3);\n+    assertThat(headerOnly.size(), is(1));\n+\n+    // Unpause incoming kafka consumption. We then expect active to catch back up.\n+    APP_SHUTOFFS_0.setKafkaPauseOffset(-1);\n+\n+    waitForRemoteServerToChangeStatus(REST_APP_0, host0, HighAvailabilityTestUtil\n+        .lagsReported(host0, Optional.of(5L), 5));\n+\n+    clusterStatusResponse = HighAvailabilityTestUtil\n+        .sendClusterStatusRequest(REST_APP_0);\n+    pair = getOffsets(host0, clusterStatusResponse.getClusterStatus());\n+    assertThat(pair.left, is(5L));\n+    assertThat(pair.right, is(5L));\n+\n+    final List<StreamedRow> updatedRows = makePullQueryRequest(\n+        REST_APP_0, sqlKey3, LAG_FILTER_3);\n+\n+    // Now it is found!\n+    host = updatedRows.get(1).getSourceHost().get();\n+    assertThat(host.getHost(), is(host0.getHost()));\n+    assertThat(host.getPort(), is(host0.getPort()));\n+    assertThat(updatedRows.get(1).getRow(), is(not(Optional.empty())));\n+    assertThat(updatedRows.get(1).getRow().get().values(), is(ImmutableList.of(KEY_3, 1)));\n+  }\n+\n+  private static String extractQueryId(final String outputString) {\n+    final java.util.regex.Matcher matcher = QUERY_ID_PATTERN.matcher(outputString);\n+    assertThat(\"Could not find query id in: \" + outputString, matcher.find());\n+    return matcher.group(1);\n+  }\n+\n+  private static void makeAdminRequest(TestKsqlRestApp restApp, final String sql) {\n+    RestIntegrationTestUtil.makeKsqlRequest(restApp, sql, Optional.empty());\n+  }\n+\n+  private static List<KsqlEntity> makeAdminRequestWithResponse(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "746400f3e755d05770d849c3eea1a1019d7d7d0c"}, "originalPosition": 300}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "aa22d115045f641459a371059219899f4c7be346", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/aa22d115045f641459a371059219899f4c7be346", "committedDate": "2020-07-10T21:42:49Z", "message": "Fixes warning"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2NzE2NTY1", "url": "https://github.com/confluentinc/ksql/pull/5811#pullrequestreview-446716565", "createdAt": "2020-07-10T21:43:09Z", "commit": {"oid": "746400f3e755d05770d849c3eea1a1019d7d7d0c"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e25df51f64d3558b9f02ca0e7e9c54eae2ea463d", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/e25df51f64d3558b9f02ca0e7e9c54eae2ea463d", "committedDate": "2020-07-11T00:27:03Z", "message": "More feedback"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4827, "cost": 1, "resetAt": "2021-11-01T13:51:04Z"}}}