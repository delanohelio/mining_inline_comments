{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE4OTI3NjAz", "number": 5378, "title": "test(client): add integration tests for Java client", "bodyText": "Description\nAs the title says, this PR adds integration tests for the Java client.\nTesting done\nTest-only change.\nReviewer checklist\n\n Ensure docs are updated if necessary. (eg. if a user visible feature is being added or changed).\n Ensure relevant issues are linked (description should include text like \"Fixes #\")", "createdAt": "2020-05-16T07:10:50Z", "url": "https://github.com/confluentinc/ksql/pull/5378", "merged": true, "mergeCommit": {"oid": "0cbeae2187ce953f2cb84af46278c91346296fed"}, "closed": true, "closedAt": "2020-05-18T22:04:02Z", "author": {"login": "vcrfxia"}, "timelineItems": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABch_q_1AH2gAyNDE4OTI3NjAzOjIzMDgyYjYxNTYwYzdjOWZkOTRkMjYyMzJiZGRlYTg2YjVkNzM0MzU=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcimgMkAH2gAyNDE4OTI3NjAzOjgxYTVmMDc3OGM4OTZkNDIyYmY2MzVlMGQ5MjQ0N2VkZDc5NzQwMWI=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "23082b61560c7c9fd94d26232bddea86b5d73435", "author": {"user": {"login": "vcrfxia", "name": "Victoria Xia"}}, "url": "https://github.com/confluentinc/ksql/commit/23082b61560c7c9fd94d26232bddea86b5d73435", "committedDate": "2020-05-16T23:56:34Z", "message": "test(client): add integration tests for Java client"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "239f16c08a482837299e10246324631f39f13ded", "author": {"user": {"login": "vcrfxia", "name": "Victoria Xia"}}, "url": "https://github.com/confluentinc/ksql/commit/239f16c08a482837299e10246324631f39f13ded", "committedDate": "2020-05-16T23:56:34Z", "message": "refactor: move duplicate code to util file"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0e3b7ae892fe614a17be5e67357654c8a9d0fd1f", "author": {"user": {"login": "vcrfxia", "name": "Victoria Xia"}}, "url": "https://github.com/confluentinc/ksql/commit/0e3b7ae892fe614a17be5e67357654c8a9d0fd1f", "committedDate": "2020-05-16T07:07:49Z", "message": "refactor: move duplicate code to util file"}, "afterCommit": {"oid": "239f16c08a482837299e10246324631f39f13ded", "author": {"user": {"login": "vcrfxia", "name": "Victoria Xia"}}, "url": "https://github.com/confluentinc/ksql/commit/239f16c08a482837299e10246324631f39f13ded", "committedDate": "2020-05-16T23:56:34Z", "message": "refactor: move duplicate code to util file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9f51cd2448cd1b8a22caa020f975969c41447d83", "author": {"user": {"login": "vcrfxia", "name": "Victoria Xia"}}, "url": "https://github.com/confluentinc/ksql/commit/9f51cd2448cd1b8a22caa020f975969c41447d83", "committedDate": "2020-05-18T17:42:36Z", "message": "chore: remove useless retries"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "befd197b1f74295d39095af9631862e16f2e9e0c", "author": {"user": {"login": "vcrfxia", "name": "Victoria Xia"}}, "url": "https://github.com/confluentinc/ksql/commit/befd197b1f74295d39095af9631862e16f2e9e0c", "committedDate": "2020-05-18T18:41:51Z", "message": "Merge branch 'master' into java-client-integration-test"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDEzODc2MTA5", "url": "https://github.com/confluentinc/ksql/pull/5378#pullrequestreview-413876109", "createdAt": "2020-05-18T19:23:35Z", "commit": {"oid": "befd197b1f74295d39095af9631862e16f2e9e0c"}, "state": "APPROVED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQxOToyMzozNVrOGXEiKg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQxOToyNDo0N1rOGXEkfA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjg0NDcxNA==", "bodyText": "I think the limit here is just the number of rows - would be better imho to test with limit < number of rows to make sure the limit really works.", "url": "https://github.com/confluentinc/ksql/pull/5378#discussion_r426844714", "createdAt": "2020-05-18T19:23:35Z", "author": {"login": "purplefox"}, "path": "ksqldb-api-client/src/test/java/io/confluent/ksql/api/client/integration/ClientIntegrationTest.java", "diffHunk": "@@ -0,0 +1,552 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.client.integration;\n+\n+import static io.confluent.ksql.api.client.util.ClientTestUtil.shouldReceiveRows;\n+import static io.confluent.ksql.api.client.util.ClientTestUtil.subscribeAndWait;\n+import static io.confluent.ksql.test.util.AssertEventually.assertThatEventually;\n+import static io.confluent.ksql.util.KsqlConfig.KSQL_STREAMS_PREFIX;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.contains;\n+import static org.hamcrest.Matchers.containsString;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.hasSize;\n+import static org.hamcrest.Matchers.instanceOf;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.notNullValue;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.junit.Assert.assertThrows;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Multimap;\n+import io.confluent.common.utils.IntegrationTest;\n+import io.confluent.ksql.GenericRow;\n+import io.confluent.ksql.api.client.BatchedQueryResult;\n+import io.confluent.ksql.api.client.Client;\n+import io.confluent.ksql.api.client.ClientOptions;\n+import io.confluent.ksql.api.client.ColumnType;\n+import io.confluent.ksql.api.client.KsqlArray;\n+import io.confluent.ksql.api.client.KsqlObject;\n+import io.confluent.ksql.api.client.Row;\n+import io.confluent.ksql.api.client.StreamedQueryResult;\n+import io.confluent.ksql.api.client.util.ClientTestUtil.TestSubscriber;\n+import io.confluent.ksql.api.client.util.RowUtil;\n+import io.confluent.ksql.engine.KsqlEngine;\n+import io.confluent.ksql.integration.IntegrationTestHarness;\n+import io.confluent.ksql.integration.Retry;\n+import io.confluent.ksql.name.ColumnName;\n+import io.confluent.ksql.rest.client.KsqlRestClientException;\n+import io.confluent.ksql.rest.integration.RestIntegrationTestUtil;\n+import io.confluent.ksql.rest.server.TestKsqlRestApp;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.serde.FormatFactory;\n+import io.confluent.ksql.serde.SerdeOption;\n+import io.confluent.ksql.util.PageViewDataProvider;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.json.JsonArray;\n+import io.vertx.core.json.JsonObject;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import kafka.zookeeper.ZooKeeperClientException;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.junit.After;\n+import org.junit.AfterClass;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.RuleChain;\n+import org.reactivestreams.Publisher;\n+\n+@Category({IntegrationTest.class})\n+public class ClientIntegrationTest {\n+\n+  private static final PageViewDataProvider PAGE_VIEWS_PROVIDER = new PageViewDataProvider();\n+  private static final String PAGE_VIEW_TOPIC = PAGE_VIEWS_PROVIDER.topicName();\n+  private static final String PAGE_VIEW_STREAM = PAGE_VIEWS_PROVIDER.kstreamName();\n+  private static final int PAGE_VIEW_NUM_ROWS = PAGE_VIEWS_PROVIDER.data().size();\n+  private static final List<String> PAGE_VIEW_COLUMN_NAMES =\n+      ImmutableList.of(\"PAGEID\", \"USERID\", \"VIEWTIME\");\n+  private static final List<ColumnType> PAGE_VIEW_COLUMN_TYPES =\n+      RowUtil.columnTypesFromStrings(ImmutableList.of(\"STRING\", \"STRING\", \"BIGINT\"));\n+  private static final List<KsqlArray> PAGE_VIEW_EXPECTED_ROWS = convertToClientRows(PAGE_VIEWS_PROVIDER.data());\n+\n+  private static final String AGG_TABLE = \"AGG_TABLE\";\n+  private static final String AN_AGG_KEY = \"USER_1\";\n+  private static final PhysicalSchema AGG_SCHEMA = PhysicalSchema.from(\n+      LogicalSchema.builder()\n+          .keyColumn(ColumnName.of(\"USERID\"), SqlTypes.STRING)\n+          .valueColumn(ColumnName.of(\"COUNT\"), SqlTypes.BIGINT)\n+          .build(),\n+      SerdeOption.none()\n+  );\n+\n+  private static final String PUSH_QUERY = \"SELECT * FROM \" + PAGE_VIEW_STREAM + \" EMIT CHANGES;\";\n+  private static final String PULL_QUERY = \"SELECT * from \" + AGG_TABLE + \" WHERE USERID='\" + AN_AGG_KEY + \"';\";\n+  private static final String PUSH_QUERY_WITH_LIMIT =\n+      \"SELECT * FROM \" + PAGE_VIEW_STREAM + \" EMIT CHANGES LIMIT \" + PAGE_VIEW_NUM_ROWS + \";\";\n+\n+  private static final List<String> PULL_QUERY_COLUMN_NAMES = ImmutableList.of(\"USERID\", \"COUNT\");\n+  private static final List<ColumnType> PULL_QUERY_COLUMN_TYPES =\n+      RowUtil.columnTypesFromStrings(ImmutableList.of(\"STRING\", \"BIGINT\"));\n+  private static final KsqlArray PULL_QUERY_EXPECTED_ROW = new KsqlArray(ImmutableList.of(\"USER_1\", 1));\n+\n+  private static final IntegrationTestHarness TEST_HARNESS = IntegrationTestHarness.build();\n+\n+  private static final TestKsqlRestApp REST_APP = TestKsqlRestApp\n+      .builder(TEST_HARNESS::kafkaBootstrapServers)\n+      .withProperty(KSQL_STREAMS_PREFIX + StreamsConfig.NUM_STREAM_THREADS_CONFIG, 1)\n+      .build();\n+\n+  @ClassRule\n+  public static final RuleChain CHAIN = RuleChain\n+      .outerRule(Retry.of(3, ZooKeeperClientException.class, 3, TimeUnit.SECONDS))\n+      .around(TEST_HARNESS)\n+      .around(REST_APP);\n+\n+  @BeforeClass\n+  public static void setUpClass() {\n+    TEST_HARNESS.ensureTopics(PAGE_VIEW_TOPIC);\n+\n+    TEST_HARNESS.produceRows(PAGE_VIEW_TOPIC, PAGE_VIEWS_PROVIDER, FormatFactory.JSON);\n+\n+    RestIntegrationTestUtil.createStream(REST_APP, PAGE_VIEWS_PROVIDER);\n+\n+    makeKsqlRequest(\"CREATE TABLE \" + AGG_TABLE + \" AS \"\n+        + \"SELECT USERID, COUNT(1) AS COUNT FROM \" + PAGE_VIEW_STREAM + \" GROUP BY USERID;\"\n+    );\n+\n+    TEST_HARNESS.verifyAvailableUniqueRows(\n+        AGG_TABLE,\n+        5, // Only unique keys are counted\n+        FormatFactory.JSON,\n+        AGG_SCHEMA\n+    );\n+  }\n+\n+  @AfterClass\n+  public static void classTearDown() {\n+    REST_APP.getPersistentQueries().forEach(str -> makeKsqlRequest(\"TERMINATE \" + str + \";\"));\n+  }\n+\n+  private Vertx vertx;\n+  private Client client;\n+\n+  @Before\n+  public void setUp() {\n+    vertx = Vertx.vertx();\n+    client = createClient();\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    if (client != null) {\n+      client.close();\n+    }\n+    if (vertx != null) {\n+      vertx.close();\n+    }\n+    REST_APP.getServiceContext().close();\n+  }\n+\n+  @Test\n+  public void shouldStreamPushQueryAsync() throws Exception {\n+    // When\n+    final StreamedQueryResult streamedQueryResult = client.streamQuery(PUSH_QUERY).get();\n+\n+    // Then\n+    assertThat(streamedQueryResult.columnNames(), is(PAGE_VIEW_COLUMN_NAMES));\n+    assertThat(streamedQueryResult.columnTypes(), is(PAGE_VIEW_COLUMN_TYPES));\n+    assertThat(streamedQueryResult.queryID(), is(notNullValue()));\n+\n+    shouldReceivePageViewRows(streamedQueryResult, false);\n+\n+    assertThat(streamedQueryResult.isComplete(), is(false));\n+  }\n+\n+  @Test\n+  public void shouldStreamPushQuerySync() throws Exception {\n+    // When\n+    final StreamedQueryResult streamedQueryResult = client.streamQuery(PUSH_QUERY).get();\n+\n+    // Then\n+    assertThat(streamedQueryResult.columnNames(), is(PAGE_VIEW_COLUMN_NAMES));\n+    assertThat(streamedQueryResult.columnTypes(), is(PAGE_VIEW_COLUMN_TYPES));\n+    assertThat(streamedQueryResult.queryID(), is(notNullValue()));\n+\n+    for (int i = 0; i < PAGE_VIEW_NUM_ROWS; i++) {\n+      final Row row = streamedQueryResult.poll();\n+      verifyPageViewRowWithIndex(row, i);\n+    }\n+\n+    assertThat(streamedQueryResult.isComplete(), is(false));\n+  }\n+\n+  @Test\n+  public void shouldStreamPullQueryAsync() throws Exception {\n+    // When\n+    final StreamedQueryResult streamedQueryResult = client.streamQuery(PULL_QUERY).get();\n+\n+    // Then\n+    assertThat(streamedQueryResult.columnNames(), is(PULL_QUERY_COLUMN_NAMES));\n+    assertThat(streamedQueryResult.columnTypes(), is(PULL_QUERY_COLUMN_TYPES));\n+    assertThat(streamedQueryResult.queryID(), is(nullValue()));\n+\n+    shouldReceivePullQueryRow(streamedQueryResult);\n+\n+    assertThatEventually(streamedQueryResult::isComplete, is(true));\n+  }\n+\n+  @Test\n+  public void shouldStreamPullQuerySync() throws Exception {\n+    // When\n+    final StreamedQueryResult streamedQueryResult = client.streamQuery(PULL_QUERY).get();\n+\n+    // Then\n+    assertThat(streamedQueryResult.columnNames(), is(PULL_QUERY_COLUMN_NAMES));\n+    assertThat(streamedQueryResult.columnTypes(), is(PULL_QUERY_COLUMN_TYPES));\n+    assertThat(streamedQueryResult.queryID(), is(nullValue()));\n+\n+    final Row row = streamedQueryResult.poll();\n+    verifyPullQueryRow(row);\n+    assertThat(streamedQueryResult.poll(), is(nullValue()));\n+\n+    assertThatEventually(streamedQueryResult::isComplete, is(true));\n+  }\n+\n+  @Test\n+  public void shouldStreamPushQueryWithLimitAsync() throws Exception {\n+    // When\n+    final StreamedQueryResult streamedQueryResult = client.streamQuery(PUSH_QUERY_WITH_LIMIT).get();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "befd197b1f74295d39095af9631862e16f2e9e0c"}, "originalPosition": 239}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjg0NTMwOA==", "bodyText": "Isn't default tls false already?", "url": "https://github.com/confluentinc/ksql/pull/5378#discussion_r426845308", "createdAt": "2020-05-18T19:24:47Z", "author": {"login": "purplefox"}, "path": "ksqldb-api-client/src/test/java/io/confluent/ksql/api/client/integration/ClientIntegrationTest.java", "diffHunk": "@@ -0,0 +1,552 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.client.integration;\n+\n+import static io.confluent.ksql.api.client.util.ClientTestUtil.shouldReceiveRows;\n+import static io.confluent.ksql.api.client.util.ClientTestUtil.subscribeAndWait;\n+import static io.confluent.ksql.test.util.AssertEventually.assertThatEventually;\n+import static io.confluent.ksql.util.KsqlConfig.KSQL_STREAMS_PREFIX;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.contains;\n+import static org.hamcrest.Matchers.containsString;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.hasSize;\n+import static org.hamcrest.Matchers.instanceOf;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.notNullValue;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.junit.Assert.assertThrows;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Multimap;\n+import io.confluent.common.utils.IntegrationTest;\n+import io.confluent.ksql.GenericRow;\n+import io.confluent.ksql.api.client.BatchedQueryResult;\n+import io.confluent.ksql.api.client.Client;\n+import io.confluent.ksql.api.client.ClientOptions;\n+import io.confluent.ksql.api.client.ColumnType;\n+import io.confluent.ksql.api.client.KsqlArray;\n+import io.confluent.ksql.api.client.KsqlObject;\n+import io.confluent.ksql.api.client.Row;\n+import io.confluent.ksql.api.client.StreamedQueryResult;\n+import io.confluent.ksql.api.client.util.ClientTestUtil.TestSubscriber;\n+import io.confluent.ksql.api.client.util.RowUtil;\n+import io.confluent.ksql.engine.KsqlEngine;\n+import io.confluent.ksql.integration.IntegrationTestHarness;\n+import io.confluent.ksql.integration.Retry;\n+import io.confluent.ksql.name.ColumnName;\n+import io.confluent.ksql.rest.client.KsqlRestClientException;\n+import io.confluent.ksql.rest.integration.RestIntegrationTestUtil;\n+import io.confluent.ksql.rest.server.TestKsqlRestApp;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.schema.ksql.types.SqlTypes;\n+import io.confluent.ksql.serde.FormatFactory;\n+import io.confluent.ksql.serde.SerdeOption;\n+import io.confluent.ksql.util.PageViewDataProvider;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.json.JsonArray;\n+import io.vertx.core.json.JsonObject;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import kafka.zookeeper.ZooKeeperClientException;\n+import org.apache.kafka.streams.StreamsConfig;\n+import org.junit.After;\n+import org.junit.AfterClass;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.RuleChain;\n+import org.reactivestreams.Publisher;\n+\n+@Category({IntegrationTest.class})\n+public class ClientIntegrationTest {\n+\n+  private static final PageViewDataProvider PAGE_VIEWS_PROVIDER = new PageViewDataProvider();\n+  private static final String PAGE_VIEW_TOPIC = PAGE_VIEWS_PROVIDER.topicName();\n+  private static final String PAGE_VIEW_STREAM = PAGE_VIEWS_PROVIDER.kstreamName();\n+  private static final int PAGE_VIEW_NUM_ROWS = PAGE_VIEWS_PROVIDER.data().size();\n+  private static final List<String> PAGE_VIEW_COLUMN_NAMES =\n+      ImmutableList.of(\"PAGEID\", \"USERID\", \"VIEWTIME\");\n+  private static final List<ColumnType> PAGE_VIEW_COLUMN_TYPES =\n+      RowUtil.columnTypesFromStrings(ImmutableList.of(\"STRING\", \"STRING\", \"BIGINT\"));\n+  private static final List<KsqlArray> PAGE_VIEW_EXPECTED_ROWS = convertToClientRows(PAGE_VIEWS_PROVIDER.data());\n+\n+  private static final String AGG_TABLE = \"AGG_TABLE\";\n+  private static final String AN_AGG_KEY = \"USER_1\";\n+  private static final PhysicalSchema AGG_SCHEMA = PhysicalSchema.from(\n+      LogicalSchema.builder()\n+          .keyColumn(ColumnName.of(\"USERID\"), SqlTypes.STRING)\n+          .valueColumn(ColumnName.of(\"COUNT\"), SqlTypes.BIGINT)\n+          .build(),\n+      SerdeOption.none()\n+  );\n+\n+  private static final String PUSH_QUERY = \"SELECT * FROM \" + PAGE_VIEW_STREAM + \" EMIT CHANGES;\";\n+  private static final String PULL_QUERY = \"SELECT * from \" + AGG_TABLE + \" WHERE USERID='\" + AN_AGG_KEY + \"';\";\n+  private static final String PUSH_QUERY_WITH_LIMIT =\n+      \"SELECT * FROM \" + PAGE_VIEW_STREAM + \" EMIT CHANGES LIMIT \" + PAGE_VIEW_NUM_ROWS + \";\";\n+\n+  private static final List<String> PULL_QUERY_COLUMN_NAMES = ImmutableList.of(\"USERID\", \"COUNT\");\n+  private static final List<ColumnType> PULL_QUERY_COLUMN_TYPES =\n+      RowUtil.columnTypesFromStrings(ImmutableList.of(\"STRING\", \"BIGINT\"));\n+  private static final KsqlArray PULL_QUERY_EXPECTED_ROW = new KsqlArray(ImmutableList.of(\"USER_1\", 1));\n+\n+  private static final IntegrationTestHarness TEST_HARNESS = IntegrationTestHarness.build();\n+\n+  private static final TestKsqlRestApp REST_APP = TestKsqlRestApp\n+      .builder(TEST_HARNESS::kafkaBootstrapServers)\n+      .withProperty(KSQL_STREAMS_PREFIX + StreamsConfig.NUM_STREAM_THREADS_CONFIG, 1)\n+      .build();\n+\n+  @ClassRule\n+  public static final RuleChain CHAIN = RuleChain\n+      .outerRule(Retry.of(3, ZooKeeperClientException.class, 3, TimeUnit.SECONDS))\n+      .around(TEST_HARNESS)\n+      .around(REST_APP);\n+\n+  @BeforeClass\n+  public static void setUpClass() {\n+    TEST_HARNESS.ensureTopics(PAGE_VIEW_TOPIC);\n+\n+    TEST_HARNESS.produceRows(PAGE_VIEW_TOPIC, PAGE_VIEWS_PROVIDER, FormatFactory.JSON);\n+\n+    RestIntegrationTestUtil.createStream(REST_APP, PAGE_VIEWS_PROVIDER);\n+\n+    makeKsqlRequest(\"CREATE TABLE \" + AGG_TABLE + \" AS \"\n+        + \"SELECT USERID, COUNT(1) AS COUNT FROM \" + PAGE_VIEW_STREAM + \" GROUP BY USERID;\"\n+    );\n+\n+    TEST_HARNESS.verifyAvailableUniqueRows(\n+        AGG_TABLE,\n+        5, // Only unique keys are counted\n+        FormatFactory.JSON,\n+        AGG_SCHEMA\n+    );\n+  }\n+\n+  @AfterClass\n+  public static void classTearDown() {\n+    REST_APP.getPersistentQueries().forEach(str -> makeKsqlRequest(\"TERMINATE \" + str + \";\"));\n+  }\n+\n+  private Vertx vertx;\n+  private Client client;\n+\n+  @Before\n+  public void setUp() {\n+    vertx = Vertx.vertx();\n+    client = createClient();\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    if (client != null) {\n+      client.close();\n+    }\n+    if (vertx != null) {\n+      vertx.close();\n+    }\n+    REST_APP.getServiceContext().close();\n+  }\n+\n+  @Test\n+  public void shouldStreamPushQueryAsync() throws Exception {\n+    // When\n+    final StreamedQueryResult streamedQueryResult = client.streamQuery(PUSH_QUERY).get();\n+\n+    // Then\n+    assertThat(streamedQueryResult.columnNames(), is(PAGE_VIEW_COLUMN_NAMES));\n+    assertThat(streamedQueryResult.columnTypes(), is(PAGE_VIEW_COLUMN_TYPES));\n+    assertThat(streamedQueryResult.queryID(), is(notNullValue()));\n+\n+    shouldReceivePageViewRows(streamedQueryResult, false);\n+\n+    assertThat(streamedQueryResult.isComplete(), is(false));\n+  }\n+\n+  @Test\n+  public void shouldStreamPushQuerySync() throws Exception {\n+    // When\n+    final StreamedQueryResult streamedQueryResult = client.streamQuery(PUSH_QUERY).get();\n+\n+    // Then\n+    assertThat(streamedQueryResult.columnNames(), is(PAGE_VIEW_COLUMN_NAMES));\n+    assertThat(streamedQueryResult.columnTypes(), is(PAGE_VIEW_COLUMN_TYPES));\n+    assertThat(streamedQueryResult.queryID(), is(notNullValue()));\n+\n+    for (int i = 0; i < PAGE_VIEW_NUM_ROWS; i++) {\n+      final Row row = streamedQueryResult.poll();\n+      verifyPageViewRowWithIndex(row, i);\n+    }\n+\n+    assertThat(streamedQueryResult.isComplete(), is(false));\n+  }\n+\n+  @Test\n+  public void shouldStreamPullQueryAsync() throws Exception {\n+    // When\n+    final StreamedQueryResult streamedQueryResult = client.streamQuery(PULL_QUERY).get();\n+\n+    // Then\n+    assertThat(streamedQueryResult.columnNames(), is(PULL_QUERY_COLUMN_NAMES));\n+    assertThat(streamedQueryResult.columnTypes(), is(PULL_QUERY_COLUMN_TYPES));\n+    assertThat(streamedQueryResult.queryID(), is(nullValue()));\n+\n+    shouldReceivePullQueryRow(streamedQueryResult);\n+\n+    assertThatEventually(streamedQueryResult::isComplete, is(true));\n+  }\n+\n+  @Test\n+  public void shouldStreamPullQuerySync() throws Exception {\n+    // When\n+    final StreamedQueryResult streamedQueryResult = client.streamQuery(PULL_QUERY).get();\n+\n+    // Then\n+    assertThat(streamedQueryResult.columnNames(), is(PULL_QUERY_COLUMN_NAMES));\n+    assertThat(streamedQueryResult.columnTypes(), is(PULL_QUERY_COLUMN_TYPES));\n+    assertThat(streamedQueryResult.queryID(), is(nullValue()));\n+\n+    final Row row = streamedQueryResult.poll();\n+    verifyPullQueryRow(row);\n+    assertThat(streamedQueryResult.poll(), is(nullValue()));\n+\n+    assertThatEventually(streamedQueryResult::isComplete, is(true));\n+  }\n+\n+  @Test\n+  public void shouldStreamPushQueryWithLimitAsync() throws Exception {\n+    // When\n+    final StreamedQueryResult streamedQueryResult = client.streamQuery(PUSH_QUERY_WITH_LIMIT).get();\n+\n+    // Then\n+    assertThat(streamedQueryResult.columnNames(), is(PAGE_VIEW_COLUMN_NAMES));\n+    assertThat(streamedQueryResult.columnTypes(), is(PAGE_VIEW_COLUMN_TYPES));\n+    assertThat(streamedQueryResult.queryID(), is(notNullValue()));\n+\n+    shouldReceivePageViewRows(streamedQueryResult, true);\n+\n+    assertThat(streamedQueryResult.isComplete(), is(true));\n+  }\n+\n+  @Test\n+  public void shouldStreamPushQueryWithLimitSync() throws Exception {\n+    // When\n+    final StreamedQueryResult streamedQueryResult = client.streamQuery(PUSH_QUERY_WITH_LIMIT).get();\n+\n+    // Then\n+    assertThat(streamedQueryResult.columnNames(), is(PAGE_VIEW_COLUMN_NAMES));\n+    assertThat(streamedQueryResult.columnTypes(), is(PAGE_VIEW_COLUMN_TYPES));\n+    assertThat(streamedQueryResult.queryID(), is(notNullValue()));\n+\n+    for (int i = 0; i < PAGE_VIEW_NUM_ROWS; i++) {\n+      final Row row = streamedQueryResult.poll();\n+      verifyPageViewRowWithIndex(row, i);\n+    }\n+    assertThat(streamedQueryResult.poll(), is(nullValue()));\n+\n+    assertThat(streamedQueryResult.isComplete(), is(true));\n+  }\n+\n+  @Test\n+  public void shouldHandleErrorResponseFromStreamQuery() {\n+    // When\n+    final Exception e = assertThrows(\n+        ExecutionException.class, // thrown from .get() when the future completes exceptionally\n+        () -> client.streamQuery(\"SELECT * FROM NONEXISTENT EMIT CHANGES;\").get()\n+    );\n+\n+    // Then\n+    assertThat(e.getCause(), instanceOf(KsqlRestClientException.class));\n+    assertThat(e.getCause().getMessage(), containsString(\"Received 400 response from server\"));\n+    assertThat(e.getCause().getMessage(), containsString(\"NONEXISTENT does not exist\"));\n+  }\n+\n+  @Test\n+  public void shouldDeliverBufferedRowsViaPollIfComplete() throws Exception {\n+    // Given\n+    final StreamedQueryResult streamedQueryResult = client.streamQuery(PUSH_QUERY_WITH_LIMIT).get();\n+    assertThatEventually(streamedQueryResult::isComplete, is(true));\n+\n+    // When / Then\n+    for (int i = 0; i < PAGE_VIEW_NUM_ROWS; i++) {\n+      final Row row = streamedQueryResult.poll();\n+      verifyPageViewRowWithIndex(row, i);\n+    }\n+    assertThat(streamedQueryResult.poll(), is(nullValue()));\n+  }\n+\n+  @Test\n+  public void shouldAllowSubscribeStreamedQueryResultIfComplete() throws Exception {\n+    // Given\n+    final StreamedQueryResult streamedQueryResult = client.streamQuery(PUSH_QUERY_WITH_LIMIT).get();\n+    assertThatEventually(streamedQueryResult::isComplete, is(true));\n+\n+    // When\n+    TestSubscriber<Row> subscriber = subscribeAndWait(streamedQueryResult);\n+    assertThat(subscriber.getValues(), hasSize(0));\n+    subscriber.getSub().request(PAGE_VIEW_NUM_ROWS);\n+\n+    // Then\n+    assertThatEventually(subscriber::getValues, hasSize(PAGE_VIEW_NUM_ROWS));\n+    verifyPageViewRows(subscriber.getValues());\n+    assertThat(subscriber.getError(), is(nullValue()));\n+  }\n+\n+  @Test\n+  public void shouldExecutePullQuery() throws Exception {\n+    // When\n+    final BatchedQueryResult batchedQueryResult = client.executeQuery(PULL_QUERY).get();\n+\n+    // Then\n+    assertThat(batchedQueryResult.columnNames(), is(PULL_QUERY_COLUMN_NAMES));\n+    assertThat(batchedQueryResult.columnTypes(), is(PULL_QUERY_COLUMN_TYPES));\n+    assertThat(batchedQueryResult.queryID(), is(nullValue()));\n+\n+    verifyPullQueryRows(batchedQueryResult.rows());\n+  }\n+\n+  @Test\n+  public void shouldExecutePushWithLimitQuery() throws Exception {\n+    // When\n+    final BatchedQueryResult batchedQueryResult = client.executeQuery(PUSH_QUERY_WITH_LIMIT).get();\n+\n+    // Then\n+    assertThat(batchedQueryResult.columnNames(), is(PAGE_VIEW_COLUMN_NAMES));\n+    assertThat(batchedQueryResult.columnTypes(), is(PAGE_VIEW_COLUMN_TYPES));\n+    assertThat(batchedQueryResult.queryID(), is(notNullValue()));\n+\n+    verifyPageViewRows(batchedQueryResult.rows());\n+  }\n+\n+  @Test\n+  public void shouldHandleErrorResponseFromExecuteQuery() {\n+    // When\n+    final Exception e = assertThrows(\n+        ExecutionException.class, // thrown from .get() when the future completes exceptionally\n+        () -> client.executeQuery(\"SELECT * from \" + AGG_TABLE + \";\").get()\n+    );\n+\n+    // Then\n+    assertThat(e.getCause(), instanceOf(KsqlRestClientException.class));\n+    assertThat(e.getCause().getMessage(), containsString(\"Received 400 response from server\"));\n+    assertThat(e.getCause().getMessage(), containsString(\"Missing WHERE clause\"));\n+  }\n+\n+  @Test\n+  public void shouldTerminatePushQueryIssuedViaStreamQuery() throws Exception {\n+    // Given: one persistent query for the agg table\n+    verifyNumActiveQueries(1);\n+\n+    final StreamedQueryResult streamedQueryResult = client.streamQuery(PUSH_QUERY).get();\n+    final String queryId = streamedQueryResult.queryID();\n+    assertThat(queryId, is(notNullValue()));\n+\n+    // Query is running on server, and StreamedQueryResult is not complete\n+    verifyNumActiveQueries(2);\n+    assertThat(streamedQueryResult.isComplete(), is(false));\n+\n+    // When\n+    client.terminatePushQuery(queryId).get();\n+\n+    // Then: query is no longer running on server, and StreamedQueryResult is complete\n+    verifyNumActiveQueries(1);\n+    assertThatEventually(streamedQueryResult::isComplete, is(true));\n+  }\n+\n+  @Test\n+  public void shouldTerminatePushQueryIssuedViaExecuteQuery() {\n+    // Will implement once https://github.com/confluentinc/ksql/pull/5236#issuecomment-628997138\n+    // is resolved\n+  }\n+\n+  @Test\n+  public void shouldHandleErrorResponseFromTerminatePushQuery() {\n+    // When\n+    final Exception e = assertThrows(\n+        ExecutionException.class, // thrown from .get() when the future completes exceptionally\n+        () -> client.terminatePushQuery(\"NONEXISTENT\").get()\n+    );\n+\n+    // Then\n+    assertThat(e.getCause(), instanceOf(KsqlRestClientException.class));\n+    assertThat(e.getCause().getMessage(), containsString(\"Received 400 response from server\"));\n+    assertThat(e.getCause().getMessage(), containsString(\"No query with id NONEXISTENT\"));\n+  }\n+\n+  private Client createClient() {\n+    final ClientOptions clientOptions = ClientOptions.create()\n+        .setHost(\"localhost\")\n+        .setPort(REST_APP.getListeners().get(0).getPort())\n+        .setUseTls(false);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "befd197b1f74295d39095af9631862e16f2e9e0c"}, "originalPosition": 400}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8dc3702cbb9f493fc1fd3498bdcca3629eae5f21", "author": {"user": {"login": "vcrfxia", "name": "Victoria Xia"}}, "url": "https://github.com/confluentinc/ksql/commit/8dc3702cbb9f493fc1fd3498bdcca3629eae5f21", "committedDate": "2020-05-18T20:09:03Z", "message": "chore: feedback"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "81a5f0778c896d422bf635e0d92447edd797401b", "author": {"user": {"login": "vcrfxia", "name": "Victoria Xia"}}, "url": "https://github.com/confluentinc/ksql/commit/81a5f0778c896d422bf635e0d92447edd797401b", "committedDate": "2020-05-18T21:11:04Z", "message": "chore: findbugs"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4774, "cost": 1, "resetAt": "2021-11-01T13:51:04Z"}}}