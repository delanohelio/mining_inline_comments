{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTEyNDg0Mzk5", "number": 6544, "title": "feat: support multi-column key declarations", "bodyText": "partial implementation for #824 - all that's left is lifting the config flag\nDescription\nWell @big-andy-coates does it again. I dug into this and hit some walls the first times around making me think it would be really tough, but after a few scrap-my-work-and-try-again loops I have proved Andy right and myself wrong - it was actually much easier to support multi-column keys than I suspected!\nThere are still imitations (you cannot issue pull queries against a multi-column key table and you cannot join a multi-column source that cannot be repartition) and the existing limitations still hold (group by still causes an ugly concatenation of the key) but will be fixed in future releases.\nTesting done\nMostly fixed unit tests, added multi-key-cols.json which tests most of the basic scenarios.\nTODOs\nAfter this PR we will still need to:\n\nsplit up the mega ksql.key.format.enabled config into multiple that target smaller diffs\nschema inference work\nmake sure avro/pb work (all tests were done in JSON)\nfix semantics\njoins, pull query support\npartition by multiple column support\n\nReviewer checklist\n\n Ensure docs are updated if necessary. (eg. if a user visible feature is being added or changed).\n Ensure relevant issues are linked (description should include text like \"Fixes #\")", "createdAt": "2020-10-29T18:42:11Z", "url": "https://github.com/confluentinc/ksql/pull/6544", "merged": true, "mergeCommit": {"oid": "2e1023e1dde4991539105c75c81c6d9d4d256e4f"}, "closed": true, "closedAt": "2020-11-06T01:13:47Z", "author": {"login": "agavra"}, "timelineItems": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdXYdpkABqjM5MzgzNzAxOTY=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdZrLCdgBqjM5NjQ4NTcwNTE=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a7f380b92d463b38cae1b2fccde552111022b7a4", "author": {"user": {"login": "agavra", "name": "Almog Gavra"}}, "url": "https://github.com/confluentinc/ksql/commit/a7f380b92d463b38cae1b2fccde552111022b7a4", "committedDate": "2020-10-29T18:38:19Z", "message": "feat: support multi-column key declarations"}, "afterCommit": {"oid": "627deaf91e153e65514d6c82fae3b89730473512", "author": {"user": {"login": "agavra", "name": "Almog Gavra"}}, "url": "https://github.com/confluentinc/ksql/commit/627deaf91e153e65514d6c82fae3b89730473512", "committedDate": "2020-10-29T20:47:27Z", "message": "feat: support multi-column key declarations"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "627deaf91e153e65514d6c82fae3b89730473512", "author": {"user": {"login": "agavra", "name": "Almog Gavra"}}, "url": "https://github.com/confluentinc/ksql/commit/627deaf91e153e65514d6c82fae3b89730473512", "committedDate": "2020-10-29T20:47:27Z", "message": "feat: support multi-column key declarations"}, "afterCommit": {"oid": "7b75de383a9b35503f3897c8e2eead67142cfec5", "author": {"user": {"login": "agavra", "name": "Almog Gavra"}}, "url": "https://github.com/confluentinc/ksql/commit/7b75de383a9b35503f3897c8e2eead67142cfec5", "committedDate": "2020-10-29T21:39:03Z", "message": "feat: support multi-column key declarations"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "7b75de383a9b35503f3897c8e2eead67142cfec5", "author": {"user": {"login": "agavra", "name": "Almog Gavra"}}, "url": "https://github.com/confluentinc/ksql/commit/7b75de383a9b35503f3897c8e2eead67142cfec5", "committedDate": "2020-10-29T21:39:03Z", "message": "feat: support multi-column key declarations"}, "afterCommit": {"oid": "20d2c78ec74a88360fddb695fb087236c9ec4ab6", "author": {"user": {"login": "agavra", "name": "Almog Gavra"}}, "url": "https://github.com/confluentinc/ksql/commit/20d2c78ec74a88360fddb695fb087236c9ec4ab6", "committedDate": "2020-10-29T21:44:48Z", "message": "feat: support multi-column key declarations"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "20d2c78ec74a88360fddb695fb087236c9ec4ab6", "author": {"user": {"login": "agavra", "name": "Almog Gavra"}}, "url": "https://github.com/confluentinc/ksql/commit/20d2c78ec74a88360fddb695fb087236c9ec4ab6", "committedDate": "2020-10-29T21:44:48Z", "message": "feat: support multi-column key declarations"}, "afterCommit": {"oid": "36ded16889a98cc1fef3382eec929c84372472ab", "author": {"user": {"login": "agavra", "name": "Almog Gavra"}}, "url": "https://github.com/confluentinc/ksql/commit/36ded16889a98cc1fef3382eec929c84372472ab", "committedDate": "2020-10-29T22:04:12Z", "message": "feat: support multi-column key declarations"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "36ded16889a98cc1fef3382eec929c84372472ab", "author": {"user": {"login": "agavra", "name": "Almog Gavra"}}, "url": "https://github.com/confluentinc/ksql/commit/36ded16889a98cc1fef3382eec929c84372472ab", "committedDate": "2020-10-29T22:04:12Z", "message": "feat: support multi-column key declarations"}, "afterCommit": {"oid": "348b36b17be6acdb18218ffb353af1fadaa25ba7", "author": {"user": {"login": "agavra", "name": "Almog Gavra"}}, "url": "https://github.com/confluentinc/ksql/commit/348b36b17be6acdb18218ffb353af1fadaa25ba7", "committedDate": "2020-10-30T00:20:32Z", "message": "feat: support multi-column key declarations"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "348b36b17be6acdb18218ffb353af1fadaa25ba7", "author": {"user": {"login": "agavra", "name": "Almog Gavra"}}, "url": "https://github.com/confluentinc/ksql/commit/348b36b17be6acdb18218ffb353af1fadaa25ba7", "committedDate": "2020-10-30T00:20:32Z", "message": "feat: support multi-column key declarations"}, "afterCommit": {"oid": "20d2c78ec74a88360fddb695fb087236c9ec4ab6", "author": {"user": {"login": "agavra", "name": "Almog Gavra"}}, "url": "https://github.com/confluentinc/ksql/commit/20d2c78ec74a88360fddb695fb087236c9ec4ab6", "committedDate": "2020-10-29T21:44:48Z", "message": "feat: support multi-column key declarations"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIzODI4NjY3", "url": "https://github.com/confluentinc/ksql/pull/6544#pullrequestreview-523828667", "createdAt": "2020-11-05T00:17:01Z", "commit": {"oid": "20d2c78ec74a88360fddb695fb087236c9ec4ab6"}, "state": "APPROVED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQwMDoxNzowMlrOHtuWuA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQwMDoxODozNFrOHtuYag==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcwNzQ0OA==", "bodyText": "nit (not your code):\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  // Persistent queries have key columns as key columns - so final projection can exclude them:\n          \n          \n            \n                  // Persistent queries have key columns as value columns - so final projection can exclude them:", "url": "https://github.com/confluentinc/ksql/pull/6544#discussion_r517707448", "createdAt": "2020-11-05T00:17:02Z", "author": {"login": "vcrfxia"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/planner/plan/FinalProjectNode.java", "diffHunk": "@@ -104,6 +108,7 @@ public void validateKeyPresent(final SourceName sinkName) {\n \n     if (into.isPresent()) {\n       // Persistent queries have key columns as key columns - so final projection can exclude them:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "20d2c78ec74a88360fddb695fb087236c9ec4ab6"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcwNzQ3Mw==", "bodyText": "Not directly related to your PR, but can you help me understand why the validation that key columns are not selected more than once is performed in FinalProjectNode while the validation that key columns are selected is performed in DataSourceNode, rather than performing both checks in the same place?", "url": "https://github.com/confluentinc/ksql/pull/6544#discussion_r517707473", "createdAt": "2020-11-05T00:17:07Z", "author": {"login": "vcrfxia"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/planner/plan/FinalProjectNode.java", "diffHunk": "@@ -114,10 +119,28 @@ public void validateKeyPresent(final SourceName sinkName) {\n             return true;\n           }\n \n-          return parentSchema.isKeyColumn(columnName);\n+          if (parentSchema.isKeyColumn(columnName)) {\n+            seenKeyColumns.computeIfAbsent(columnName, k -> new HashSet<>()).add(se.getAlias());\n+            return true;\n+          }\n         }\n         return false;\n       });\n+\n+      for (final Entry<ColumnName, Set<ColumnName>> seenKey : seenKeyColumns.entrySet()) {\n+        if (seenKey.getValue().size() > 1) {\n+          final String keys = GrammaticalJoiner.and().join(\n+              seenKey.getValue().stream().map(Name::text).sorted());\n+          throw new KsqlException(\"The projection contains a key column (\" + seenKey.getKey()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "20d2c78ec74a88360fddb695fb087236c9ec4ab6"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcwNzUwNw==", "bodyText": "nit: it's a bit odd that this method is called validate now that there's validation being performed in build() as well. Can we either move the validation back into this method, or rename this method to something more specific (throwOnZeroValueColumns() or similar)?", "url": "https://github.com/confluentinc/ksql/pull/6544#discussion_r517707507", "createdAt": "2020-11-05T00:17:11Z", "author": {"login": "vcrfxia"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/planner/plan/FinalProjectNode.java", "diffHunk": "@@ -142,16 +165,6 @@ public void validateKeyPresent(final SourceName sinkName) {\n   private void validate() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "20d2c78ec74a88360fddb695fb087236c9ec4ab6"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcwNzY5Ng==", "bodyText": "To check my understanding: this works today because we only ever end up with a single key after partition by or group by, but this method signature will have to change to support building structs with multiple key columns in a future PR, yes?", "url": "https://github.com/confluentinc/ksql/pull/6544#discussion_r517707696", "createdAt": "2020-11-05T00:17:55Z", "author": {"login": "vcrfxia"}, "path": "ksqldb-execution/src/main/java/io/confluent/ksql/execution/util/StructKeyUtil.java", "diffHunk": "@@ -58,16 +57,14 @@ public static KeyBuilder keyBuilder(final ColumnName name, final SqlType type) {\n   public static final class KeyBuilder {\n \n     private final Schema keySchema;\n-    private final org.apache.kafka.connect.data.Field keyField;\n \n-    private KeyBuilder(final Schema keySchema) {\n+    public KeyBuilder(final Schema keySchema) {\n       this.keySchema = Objects.requireNonNull(keySchema, \"keySchema\");\n-      this.keyField = Iterables.getOnlyElement(keySchema.fields());\n     }\n \n-    public Struct build(final Object keyValue) {\n+    public Struct build(final Object keyValue, final int fieldIndex) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "20d2c78ec74a88360fddb695fb087236c9ec4ab6"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcwNzgyMg==", "bodyText": "How is this is a nested struct key?", "url": "https://github.com/confluentinc/ksql/pull/6544#discussion_r517707822", "createdAt": "2020-11-05T00:18:23Z", "author": {"login": "vcrfxia"}, "path": "ksqldb-functional-tests/src/test/resources/query-validation-tests/multi-col-keys.json", "diffHunk": "@@ -0,0 +1,371 @@\n+{\n+  \"tests\": [\n+    {\n+      \"name\": \"select * from stream\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE STREAM OUTPUT AS SELECT * FROM INPUT;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}},\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": null, \"K2\": 2}, \"value\": {\"V\": 0}},\n+        {\"topic\": \"input_topic\", \"key\": null, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}},\n+        {\"topic\": \"OUTPUT\", \"key\": {\"K\": null, \"K2\": 2}, \"value\": {\"V\": 0}},\n+        {\"topic\": \"OUTPUT\", \"key\": null, \"value\": {\"V\": 0}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"stream\", \"schema\": \"K INT KEY, K2 INT KEY, V INT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"select * from table\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE TABLE INPUT (K INT PRIMARY KEY, K2 INT PRIMARY KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT * FROM INPUT;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"table\", \"schema\": \"K INT PRIMARY KEY, K2 INT PRIMARY KEY, V INT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"select * with WHERE on single key\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE STREAM OUTPUT AS SELECT * FROM INPUT WHERE K = 1;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}},\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 2, \"K2\": 1}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"stream\", \"schema\": \"K INT KEY, K2 INT KEY, V INT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"select * with WHERE on both key\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE STREAM OUTPUT AS SELECT * FROM INPUT WHERE K = 1 AND K2 = 2;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}},\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 1}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"stream\", \"schema\": \"K INT KEY, K2 INT KEY, V INT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"select * from stream partition by single key col\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE STREAM OUTPUT AS SELECT * FROM INPUT PARTITION BY K;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": 1, \"value\": {\"K2\": 2, \"V\": 0}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"stream\", \"schema\": \"K INT KEY, V INT, K2 INT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"select * from stream partition by struct representing the key\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE STREAM OUTPUT AS SELECT * FROM INPUT PARTITION BY STRUCT(K:=K, K2:=K2);\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0, \"K\": 1, \"K2\": 2}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"stream\", \"schema\": \"KSQL_COL_0 STRUCT<K INT, K2 INT> KEY, V INT, K INT, K2 INT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"group by one col\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT K, COUNT(*) as COUNT FROM INPUT GROUP BY K;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": 1, \"value\": {\"COUNT\": 1}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"table\", \"schema\": \"K INTEGER KEY, COUNT BIGINT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"group by two cols\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT K, K2, COUNT(*) as COUNT FROM INPUT GROUP BY K, K2;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"1|+|2\", \"value\": {\"COUNT\": 1}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"table\", \"schema\": \"KSQL_COL_0 STRING KEY, COUNT BIGINT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"group by one col table with tombstones\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE TABLE INPUT (K INT PRIMARY KEY, K2 INT PRIMARY KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT K, COUNT(*) as COUNT FROM INPUT GROUP BY K;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}},\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": null}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": 1, \"value\": {\"COUNT\": 1}},\n+        {\"topic\": \"OUTPUT\", \"key\": 1, \"value\": {\"COUNT\": 0}}\n+      ]\n+    },\n+    {\n+      \"name\": \"group by two cols table with tombstones\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE TABLE INPUT (K INT PRIMARY KEY, K2 INT PRIMARY KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT K, K2, COUNT(*) as COUNT FROM INPUT GROUP BY K, K2;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}},\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": null}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"1|+|2\", \"value\": {\"COUNT\": 1}},\n+        {\"topic\": \"OUTPUT\", \"key\": \"1|+|2\", \"value\": {\"COUNT\": 0}}\n+      ]\n+    },\n+    {\n+      \"name\": \"group by two cols with AS_VALUE copies\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT K, K2, AS_VALUE(K) as kv, AS_VALUE(K2) as kv2, COUNT(*) as COUNT FROM INPUT GROUP BY K, K2;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"1|+|2\", \"value\": {\"KV\": 1, \"KV2\": 2, \"COUNT\": 1}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"table\", \"schema\": \"KSQL_COL_0 STRING KEY, KV INT, KV2 INT, COUNT BIGINT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"windowed group by one col\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT K, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 1 SECOND) GROUP BY K;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}, \"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}, \"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}, \"timestamp\": 1001}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": 1, \"value\": {\"COUNT\": 1}, \"window\": {\"start\": 0, \"end\": 1000, \"type\": \"time\"}},\n+        {\"topic\": \"OUTPUT\", \"key\": 1, \"value\": {\"COUNT\": 2}, \"window\": {\"start\": 0, \"end\": 1000, \"type\": \"time\"}},\n+        {\"topic\": \"OUTPUT\", \"key\": 1, \"value\": {\"COUNT\": 1}, \"window\": {\"start\": 1000, \"end\": 2000, \"type\": \"time\"}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"table\", \"schema\": \"K INTEGER KEY, COUNT BIGINT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"join with repartition on single key\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM S1 (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='s1', format='JSON');\",\n+        \"CREATE STREAM S2 (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='s2', format='JSON');\",\n+        \"CREATE STREAM OUTPUT AS SELECT * FROM S1 JOIN S2 WITHIN 1 DAY on S1.K = S2.K;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"s1\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}},\n+        {\"topic\": \"s2\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": 1, \"value\": {\"S1_K2\": 2, \"S1_V\": 0, \"S2_K\": 1, \"S2_K2\": 2, \"S2_V\": 0}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"stream\", \"schema\": \"S1_K INTEGER KEY, S1_K2 INTEGER, S1_V INTEGER, S2_K INTEGER, S2_K2 INTEGER, S2_V INTEGER\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"join with repartition on single value\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM S1 (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='s1', format='JSON');\",\n+        \"CREATE STREAM S2 (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='s2', format='JSON');\",\n+        \"CREATE STREAM OUTPUT AS SELECT * FROM S1 JOIN S2 WITHIN 1 DAY on S1.v = S2.V;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"s1\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}},\n+        {\"topic\": \"s2\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": 0, \"value\": {\"S1_K\": 1, \"S1_K2\": 2, \"S2_K\": 1, \"S2_K2\": 2, \"S2_V\": 0}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"stream\", \"schema\": \"S1_V INTEGER KEY, S1_K INTEGER, S1_K2 INTEGER, S2_K INTEGER, S2_K2 INTEGER, S2_V INTEGER\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"nested struct key\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "20d2c78ec74a88360fddb695fb087236c9ec4ab6"}, "originalPosition": 306}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcwNzg0Mw==", "bodyText": "Can we also add a negative test for partition by on multiple columns?", "url": "https://github.com/confluentinc/ksql/pull/6544#discussion_r517707843", "createdAt": "2020-11-05T00:18:26Z", "author": {"login": "vcrfxia"}, "path": "ksqldb-functional-tests/src/test/resources/query-validation-tests/multi-col-keys.json", "diffHunk": "@@ -0,0 +1,371 @@\n+{\n+  \"tests\": [\n+    {\n+      \"name\": \"select * from stream\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE STREAM OUTPUT AS SELECT * FROM INPUT;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}},\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": null, \"K2\": 2}, \"value\": {\"V\": 0}},\n+        {\"topic\": \"input_topic\", \"key\": null, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}},\n+        {\"topic\": \"OUTPUT\", \"key\": {\"K\": null, \"K2\": 2}, \"value\": {\"V\": 0}},\n+        {\"topic\": \"OUTPUT\", \"key\": null, \"value\": {\"V\": 0}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"stream\", \"schema\": \"K INT KEY, K2 INT KEY, V INT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"select * from table\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE TABLE INPUT (K INT PRIMARY KEY, K2 INT PRIMARY KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT * FROM INPUT;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"table\", \"schema\": \"K INT PRIMARY KEY, K2 INT PRIMARY KEY, V INT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"select * with WHERE on single key\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE STREAM OUTPUT AS SELECT * FROM INPUT WHERE K = 1;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}},\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 2, \"K2\": 1}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"stream\", \"schema\": \"K INT KEY, K2 INT KEY, V INT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"select * with WHERE on both key\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE STREAM OUTPUT AS SELECT * FROM INPUT WHERE K = 1 AND K2 = 2;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}},\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 1}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"stream\", \"schema\": \"K INT KEY, K2 INT KEY, V INT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"select * from stream partition by single key col\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE STREAM OUTPUT AS SELECT * FROM INPUT PARTITION BY K;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": 1, \"value\": {\"K2\": 2, \"V\": 0}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"stream\", \"schema\": \"K INT KEY, V INT, K2 INT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"select * from stream partition by struct representing the key\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE STREAM OUTPUT AS SELECT * FROM INPUT PARTITION BY STRUCT(K:=K, K2:=K2);\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0, \"K\": 1, \"K2\": 2}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"stream\", \"schema\": \"KSQL_COL_0 STRUCT<K INT, K2 INT> KEY, V INT, K INT, K2 INT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"group by one col\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT K, COUNT(*) as COUNT FROM INPUT GROUP BY K;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": 1, \"value\": {\"COUNT\": 1}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"table\", \"schema\": \"K INTEGER KEY, COUNT BIGINT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"group by two cols\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT K, K2, COUNT(*) as COUNT FROM INPUT GROUP BY K, K2;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"1|+|2\", \"value\": {\"COUNT\": 1}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"table\", \"schema\": \"KSQL_COL_0 STRING KEY, COUNT BIGINT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"group by one col table with tombstones\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE TABLE INPUT (K INT PRIMARY KEY, K2 INT PRIMARY KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT K, COUNT(*) as COUNT FROM INPUT GROUP BY K;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}},\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": null}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": 1, \"value\": {\"COUNT\": 1}},\n+        {\"topic\": \"OUTPUT\", \"key\": 1, \"value\": {\"COUNT\": 0}}\n+      ]\n+    },\n+    {\n+      \"name\": \"group by two cols table with tombstones\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE TABLE INPUT (K INT PRIMARY KEY, K2 INT PRIMARY KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT K, K2, COUNT(*) as COUNT FROM INPUT GROUP BY K, K2;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}},\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": null}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"1|+|2\", \"value\": {\"COUNT\": 1}},\n+        {\"topic\": \"OUTPUT\", \"key\": \"1|+|2\", \"value\": {\"COUNT\": 0}}\n+      ]\n+    },\n+    {\n+      \"name\": \"group by two cols with AS_VALUE copies\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT K, K2, AS_VALUE(K) as kv, AS_VALUE(K2) as kv2, COUNT(*) as COUNT FROM INPUT GROUP BY K, K2;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"1|+|2\", \"value\": {\"KV\": 1, \"KV2\": 2, \"COUNT\": 1}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"table\", \"schema\": \"KSQL_COL_0 STRING KEY, KV INT, KV2 INT, COUNT BIGINT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"windowed group by one col\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT K, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 1 SECOND) GROUP BY K;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}, \"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}, \"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}, \"timestamp\": 1001}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": 1, \"value\": {\"COUNT\": 1}, \"window\": {\"start\": 0, \"end\": 1000, \"type\": \"time\"}},\n+        {\"topic\": \"OUTPUT\", \"key\": 1, \"value\": {\"COUNT\": 2}, \"window\": {\"start\": 0, \"end\": 1000, \"type\": \"time\"}},\n+        {\"topic\": \"OUTPUT\", \"key\": 1, \"value\": {\"COUNT\": 1}, \"window\": {\"start\": 1000, \"end\": 2000, \"type\": \"time\"}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"table\", \"schema\": \"K INTEGER KEY, COUNT BIGINT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"join with repartition on single key\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM S1 (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='s1', format='JSON');\",\n+        \"CREATE STREAM S2 (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='s2', format='JSON');\",\n+        \"CREATE STREAM OUTPUT AS SELECT * FROM S1 JOIN S2 WITHIN 1 DAY on S1.K = S2.K;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"s1\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}},\n+        {\"topic\": \"s2\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": 1, \"value\": {\"S1_K2\": 2, \"S1_V\": 0, \"S2_K\": 1, \"S2_K2\": 2, \"S2_V\": 0}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"stream\", \"schema\": \"S1_K INTEGER KEY, S1_K2 INTEGER, S1_V INTEGER, S2_K INTEGER, S2_K2 INTEGER, S2_V INTEGER\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"join with repartition on single value\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM S1 (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='s1', format='JSON');\",\n+        \"CREATE STREAM S2 (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='s2', format='JSON');\",\n+        \"CREATE STREAM OUTPUT AS SELECT * FROM S1 JOIN S2 WITHIN 1 DAY on S1.v = S2.V;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"s1\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}},\n+        {\"topic\": \"s2\", \"key\": {\"K\": 1, \"K2\": 2}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": 0, \"value\": {\"S1_K\": 1, \"S1_K2\": 2, \"S2_K\": 1, \"S2_K2\": 2, \"S2_V\": 0}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"stream\", \"schema\": \"S1_V INTEGER KEY, S1_K INTEGER, S1_K2 INTEGER, S2_K INTEGER, S2_K2 INTEGER, S2_V INTEGER\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"nested struct key\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (K INT KEY, K2 STRUCT<F1 INT> KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE STREAM OUTPUT AS SELECT * FROM INPUT;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": {\"K\": 1, \"K2\": {\"F1\": 2}}, \"value\": {\"V\": 0}}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": {\"K\": 1, \"K2\": {\"F1\": 2}}, \"value\": {\"V\": 0}}\n+      ],\n+      \"post\": {\n+        \"sources\": [\n+          {\"name\": \"OUTPUT\", \"type\": \"stream\", \"schema\": \"K INT KEY, K2 STRUCT<F1 INT> KEY, V INT\"}\n+        ]\n+      }\n+    },\n+    {\n+      \"name\": \"select only single key col\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='input_topic', format='JSON');\",\n+        \"CREATE STREAM OUTPUT AS SELECT K, V FROM INPUT;\"\n+      ],\n+      \"expectedException\": {\n+        \"type\": \"io.confluent.ksql.util.KsqlStatementException\",\n+        \"message\": \"The query used to build `OUTPUT` must include the key columns K and K2 in its projection.\"\n+      }\n+    },\n+    {\n+      \"name\": \"join on multi-column key\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM S1 (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='s1', format='JSON');\",\n+        \"CREATE STREAM S2 (K INT KEY, K2 INT KEY, V INT) WITH (kafka_topic='s2', format='JSON');\",\n+        \"CREATE STREAM OUTPUT AS SELECT * FROM S1 JOIN S2 WITHIN 1 DAY on S1.K = S2.K AND S1.K2 = S2.K2;\"\n+      ],\n+      \"expectedException\": {\n+        \"type\": \"io.confluent.ksql.util.KsqlStatementException\",\n+        \"message\": \"JOINs on multiple conditions are not yet supported: ((S1.K = S2.K) AND (S1.K2 = S2.K2))\"\n+      }\n+    },\n+    {\n+      \"name\": \"join to multi-column table\",\n+      \"properties\": {\n+        \"ksql.key.format.enabled\": true\n+      },\n+      \"statements\": [\n+        \"CREATE STREAM S (K STRING KEY, ID VARCHAR) WITH (kafka_topic='S', format='JSON');\",\n+        \"CREATE TABLE NO_KEY (K STRING PRIMARY KEY, K2 STRING PRIMARY KEY, NAME string) WITH (kafka_topic='NO_KEY', format='JSON');\",\n+        \"CREATE STREAM OUTPUT as SELECT s.k, name FROM S JOIN NO_KEY t ON s.k = t.k;\"\n+      ],\n+      \"expectedException\": {\n+        \"type\": \"io.confluent.ksql.util.KsqlStatementException\",\n+        \"message\": \"Cannot repartition a TABLE source. If this is a join, joins on tables with multiple columns is not yet supported.\"\n+      }\n+    }\n+  ]\n+}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "20d2c78ec74a88360fddb695fb087236c9ec4ab6"}, "originalPosition": 371}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcwNzg2Mw==", "bodyText": "nit:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              public void shouldHandleMultiField() {\n          \n          \n            \n              public void shouldHandleMultiKeyField() {\n          \n      \n    \n    \n  \n\nand similarly for the other new tests below.", "url": "https://github.com/confluentinc/ksql/pull/6544#discussion_r517707863", "createdAt": "2020-11-05T00:18:30Z", "author": {"login": "vcrfxia"}, "path": "ksqldb-streams/src/test/java/io/confluent/ksql/execution/streams/SourceBuilderTest.java", "diffHunk": "@@ -555,6 +560,70 @@ public void shouldHandleNullKey() {\n   }\n \n   @Test\n+  public void shouldHandleMultiField() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "20d2c78ec74a88360fddb695fb087236c9ec4ab6"}, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzcwNzg4Mg==", "bodyText": "It's not possible for a user to have a windowed, multi-key table today, right? Since group by on multiple columns still creates a single key, and we don't allow importing windowed tables?\nAlso, this method looks unused.", "url": "https://github.com/confluentinc/ksql/pull/6544#discussion_r517707882", "createdAt": "2020-11-05T00:18:34Z", "author": {"login": "vcrfxia"}, "path": "ksqldb-streams/src/test/java/io/confluent/ksql/execution/streams/SourceBuilderTest.java", "diffHunk": "@@ -768,6 +849,20 @@ private void givenWindowedSourceTable() {\n     );\n   }\n \n+  private void givenWindowedMultiKeySourceTable() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "20d2c78ec74a88360fddb695fb087236c9ec4ab6"}, "originalPosition": 186}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b80179045c88861c45fc05c61ad484c4559ab4ee", "author": {"user": {"login": "agavra", "name": "Almog Gavra"}}, "url": "https://github.com/confluentinc/ksql/commit/b80179045c88861c45fc05c61ad484c4559ab4ee", "committedDate": "2020-11-05T23:39:45Z", "message": "feat: support multi-column key declarations"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3b251ddc8c37bfbb01811961d14b45e2920c62ea", "author": {"user": {"login": "agavra", "name": "Almog Gavra"}}, "url": "https://github.com/confluentinc/ksql/commit/3b251ddc8c37bfbb01811961d14b45e2920c62ea", "committedDate": "2020-11-05T23:39:46Z", "message": "chore: victorias comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f058668991caf6bba494db6416936ee3efa35b8c", "author": {"user": {"login": "agavra", "name": "Almog Gavra"}}, "url": "https://github.com/confluentinc/ksql/commit/f058668991caf6bba494db6416936ee3efa35b8c", "committedDate": "2020-11-05T23:43:11Z", "message": "chore: rebase"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "3362d09acef4cdd578d3dc43c16f895ec35dcffa", "author": {"user": {"login": "agavra", "name": "Almog Gavra"}}, "url": "https://github.com/confluentinc/ksql/commit/3362d09acef4cdd578d3dc43c16f895ec35dcffa", "committedDate": "2020-11-05T20:56:40Z", "message": "chore: victorias comments"}, "afterCommit": {"oid": "f058668991caf6bba494db6416936ee3efa35b8c", "author": {"user": {"login": "agavra", "name": "Almog Gavra"}}, "url": "https://github.com/confluentinc/ksql/commit/f058668991caf6bba494db6416936ee3efa35b8c", "committedDate": "2020-11-05T23:43:11Z", "message": "chore: rebase"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4596, "cost": 1, "resetAt": "2021-11-01T13:51:04Z"}}}