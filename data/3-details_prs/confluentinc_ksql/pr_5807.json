{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQ3MDU3NTQ5", "number": 5807, "title": "feat: add service to restart failed persistent queries", "bodyText": "Description\nFixes #5897\nThis PR adds a new global thread, CommandMonitor, that monitors all persistent queries registered in the system and restarts those that have failed for any reason (system, user,  unknown reasons). Restarting queries automatically in the background helps reduce the effort of users to terminate the queries and re-create the stream/table/insert manually.\nThe query restart uses an exponential backoff time (in milliseconds) to wait before retrying another restart. For now, the initial backoff time is hard-coded to 10 seconds, and it is being incremented exponentially on every restart (10s, 20s, 40s, ...) up to the maximum backoff time. The maximum backoff time may be configured using ksql.query.retry.backoff.max.ms and is set to 2 minutes by default (see KsqlConfig).\nA new KafkaStream is required to be able to restart a query. When a query is stopped, manually or due to an error, the KafkaStream cannot be started anymore. To allow a restart, the CommandMonitor closes the KafkaStream and resets the internal KafkaStream with a new KafkaStream object that contains a copy of the topology and stream configurations. It is important not to close the KafkaStream completely (cleanUp= true) to avoid deleting the local state directory.\nResetting the query is done in the KsqlEngine because it has access to two registerQuery() methods (one in the EngineContext and another in the KsqlEngine). A query reset creates a new QueryMetadata that must be registered (the old is unregistered). Resetting the internal KafkaStream is not done inside the QueryMetadata because it violates the immutability of the initial KafkaStream passed in the constructor. **Note:**There should be better ways to handle these resets, but it needs some important code refactors.\nWhen restarting a new failed query, the QueryMonitor keeps a list of queries that have been restarted. Each of these retry events, or RetryEvent, have information about the QueryId, a number of retry attempts, and the time for the next restart to help the monitor know when to restart the query again.\nTesting done\n\nI added unit tests.\nRun some manual tests to verify the queries are restarted when they failed. It is difficult to test this, though, because it's not easy to cause a query failure locally. I had to throw an exception from the TimestampTransformer in the SinkBuilder and also set the ksql.streams.num.stream.threads=1 so KafkaStreams detect the exception quickly.\n\nThe manual test causes an error when inserting 1 row. It then checks the query was restarting immediately, and during the backoff time period, I caused another error with another inserting row and checked the query was not restarted until the backoff time period expired and restarted the query.\nReviewer checklist\n\n Ensure docs are updated if necessary. (eg. if a user visible feature is being added or changed).\n Ensure relevant issues are linked (description should include text like \"Fixes #\")", "createdAt": "2020-07-09T19:43:18Z", "url": "https://github.com/confluentinc/ksql/pull/5807", "merged": true, "mergeCommit": {"oid": "0ffe3e2872726d8e800e8d58696413746c4971b9"}, "closed": true, "closedAt": "2020-08-03T16:16:20Z", "author": {"login": "spena"}, "timelineItems": {"totalCount": 21, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABczUaurgBqjM1MzExODY4ODE=", "endCursor": "Y3Vyc29yOnYyOpPPAAABc6a_YXgH2gAyNDQ3MDU3NTQ5OjBhYmRmOGVmZDdlZTU4ZTdlZTRjMGQ5YjJmYmE3ZmJjNjdhZDUwZDA=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0d7e987caaf14f9f3065c98224d534d190396b11", "author": {"user": {"login": "spena", "name": "Sergio Pe\u00f1a"}}, "url": "https://github.com/confluentinc/ksql/commit/0d7e987caaf14f9f3065c98224d534d190396b11", "committedDate": "2020-07-09T19:12:34Z", "message": "feat: add service to restart failed persistent queries"}, "afterCommit": {"oid": "fba960455d241c91ca985172d9c6216846b5569d", "author": {"user": {"login": "spena", "name": "Sergio Pe\u00f1a"}}, "url": "https://github.com/confluentinc/ksql/commit/fba960455d241c91ca985172d9c6216846b5569d", "committedDate": "2020-07-09T19:29:46Z", "message": "feat: add service to restart failed persistent queries"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2MDE2OTU0", "url": "https://github.com/confluentinc/ksql/pull/5807#pullrequestreview-446016954", "createdAt": "2020-07-09T22:44:17Z", "commit": {"oid": "fba960455d241c91ca985172d9c6216846b5569d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQyMjo0NDoxOFrOGvkOFw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQyMjo0NDoxOFrOGvkOFw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjUyOTY4Nw==", "bodyText": "Just wondering, we restart queries that are in NOT_RUNNING state initially. But here, we keep trying for queries that are in ERROR state. Why? How can a restart recover from an error?", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r452529687", "createdAt": "2020-07-09T22:44:18Z", "author": {"login": "vpapavas"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/QueryMonitor.java", "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.engine;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Ticker;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.util.KsqlConfig;\n+import java.io.Closeable;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Monitor and manages the restart of persistent failed queries.\n+ */\n+public class QueryMonitor implements Closeable {\n+  private static final Logger LOG = LoggerFactory.getLogger(QueryMonitor.class);\n+\n+  private static final Random random = new Random();\n+  private static final Ticker CURRENT_TIME_MILLIS_TICKER = new Ticker() {\n+    @Override\n+    public long read() {\n+      return System.currentTimeMillis();\n+    }\n+  };\n+\n+  private static final long BASE_WAITING_TIME_MS = 10000;\n+  private static final int SHUTDOWN_TIMEOUT_MS = 5000;\n+\n+  private final Ticker ticker;\n+  private final long retryBackoffMaxMs;\n+  private final KsqlEngine ksqlEngine;\n+  private final ExecutorService executor;\n+  private final Map<QueryId, RetryEvent> queriesRetries = new HashMap<>();\n+\n+  private volatile boolean closed = false;\n+\n+  public QueryMonitor(final KsqlConfig ksqlConfig, final KsqlEngine ksqlEngine) {\n+    this(\n+        ksqlConfig,\n+        ksqlEngine,\n+        Executors.newSingleThreadExecutor(r -> new Thread(r, \"QueryMonitor\")),\n+        CURRENT_TIME_MILLIS_TICKER\n+    );\n+  }\n+\n+  @VisibleForTesting\n+  QueryMonitor(\n+      final KsqlConfig ksqlConfig,\n+      final KsqlEngine ksqlEngine,\n+      final ExecutorService executor,\n+      final Ticker ticker\n+  ) {\n+    this.retryBackoffMaxMs = ksqlConfig.getLong(KsqlConfig.KSQL_QUERY_RETRY_BACKOFF_MAX_MS);\n+    this.ksqlEngine = ksqlEngine;\n+    this.executor = executor;\n+    this.ticker = ticker;\n+  }\n+\n+  public void start() {\n+    executor.execute(new Runner());\n+    executor.shutdown();\n+  }\n+\n+  @Override\n+  public void close() {\n+    closed = true;\n+\n+    try {\n+      executor.awaitTermination(SHUTDOWN_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n+    } catch (final InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+    }\n+  }\n+\n+  boolean isClosed() {\n+    return closed;\n+  }\n+\n+  void restartFailedQueries() {\n+    ksqlEngine.getPersistentQueries().stream()\n+        .forEach(query -> {\n+          final QueryId queryId = query.getQueryId();\n+          final KafkaStreams.State queryState = query.getState();\n+\n+          // If the query was restarted previously, check if it needs another restart; or if the\n+          // query is now up and running, then remove it from the restart list.\n+          if (queriesRetries.containsKey(queryId)) {\n+            final RetryEvent retryEvent = queriesRetries.get(queryId);\n+            if (ticker.read() > retryEvent.nextRestartTimeMs()) {\n+              if (queryState == KafkaStreams.State.ERROR) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fba960455d241c91ca985172d9c6216846b5569d"}, "originalPosition": 112}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "fba960455d241c91ca985172d9c6216846b5569d", "author": {"user": {"login": "spena", "name": "Sergio Pe\u00f1a"}}, "url": "https://github.com/confluentinc/ksql/commit/fba960455d241c91ca985172d9c6216846b5569d", "committedDate": "2020-07-09T19:29:46Z", "message": "feat: add service to restart failed persistent queries"}, "afterCommit": {"oid": "b5a44021f5c340a5b1aa1a1d848617d0eeb3c311", "author": {"user": {"login": "spena", "name": "Sergio Pe\u00f1a"}}, "url": "https://github.com/confluentinc/ksql/commit/b5a44021f5c340a5b1aa1a1d848617d0eeb3c311", "committedDate": "2020-07-10T20:05:25Z", "message": "feat: add service to restart failed persistent queries"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ4NzE5NjEy", "url": "https://github.com/confluentinc/ksql/pull/5807#pullrequestreview-448719612", "createdAt": "2020-07-15T08:03:31Z", "commit": {"oid": "b5a44021f5c340a5b1aa1a1d848617d0eeb3c311"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQwODowMzozMVrOGxy4FA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQxODo1MTowNlrOGyLdLQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg2Njk2NA==", "bodyText": "This needs to be properly synchronized with the rest of the engine. For example, what happens if the command-runner thread terminates a query while the command runner thread is restarting it?", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r454866964", "createdAt": "2020-07-15T08:03:31Z", "author": {"login": "rodesai"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/KsqlEngine.java", "diffHunk": "@@ -252,6 +258,39 @@ public static boolean isExecutableStatement(final Statement statement) {\n         || statement instanceof Query;\n   }\n \n+  /**\n+   * Resets a query internal KafkaStreams so it can be restarted.\n+   * </p>\n+   * When a KafkaStreams has been stopped, it cannot be started again. To allow a restart,\n+   * the rest creates a new new KafkaStreams with the same topology and configs.\n+   *\n+   * @param queryId the queryId to reset.\n+   */\n+  public void resetQuery(final QueryId queryId) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b5a44021f5c340a5b1aa1a1d848617d0eeb3c311"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTI2NDY1Nw==", "bodyText": "I don't think unregistering/re-registering is the right approach here. This effectively removes the query from the namespace, so for example, a query listing in between unregister and register would fail. Why do we even need to unregister/register? If we could just restart a query (as described below) that would not be required.", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r455264657", "createdAt": "2020-07-15T18:42:14Z", "author": {"login": "rodesai"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/KsqlEngine.java", "diffHunk": "@@ -252,6 +258,39 @@ public static boolean isExecutableStatement(final Statement statement) {\n         || statement instanceof Query;\n   }\n \n+  /**\n+   * Resets a query internal KafkaStreams so it can be restarted.\n+   * </p>\n+   * When a KafkaStreams has been stopped, it cannot be started again. To allow a restart,\n+   * the rest creates a new new KafkaStreams with the same topology and configs.\n+   *\n+   * @param queryId the queryId to reset.\n+   */\n+  public void resetQuery(final QueryId queryId) {\n+    if (primaryContext.getPersistentQueries().containsKey(queryId)) {\n+      final PersistentQueryMetadata query = primaryContext.getPersistentQueries().get(queryId);\n+      if (query.getState() != State.NOT_RUNNING) {\n+        throw new IllegalStateException(\n+            String.format(\"Cannot reset query with application id: %s because is in %s state\",\n+                query.getQueryApplicationId(), query.getState()));\n+      }\n+\n+      // Unregister the query to replace it with a new PersistentQueryMetadata\n+      primaryContext.unregisterQuery(query);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b5a44021f5c340a5b1aa1a1d848617d0eeb3c311"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTI2OTY3Nw==", "bodyText": "I'd encapsulate this logic into the query class and add a restart method there.", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r455269677", "createdAt": "2020-07-15T18:51:06Z", "author": {"login": "rodesai"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/KsqlEngine.java", "diffHunk": "@@ -252,6 +258,39 @@ public static boolean isExecutableStatement(final Statement statement) {\n         || statement instanceof Query;\n   }\n \n+  /**\n+   * Resets a query internal KafkaStreams so it can be restarted.\n+   * </p>\n+   * When a KafkaStreams has been stopped, it cannot be started again. To allow a restart,\n+   * the rest creates a new new KafkaStreams with the same topology and configs.\n+   *\n+   * @param queryId the queryId to reset.\n+   */\n+  public void resetQuery(final QueryId queryId) {\n+    if (primaryContext.getPersistentQueries().containsKey(queryId)) {\n+      final PersistentQueryMetadata query = primaryContext.getPersistentQueries().get(queryId);\n+      if (query.getState() != State.NOT_RUNNING) {\n+        throw new IllegalStateException(\n+            String.format(\"Cannot reset query with application id: %s because is in %s state\",\n+                query.getQueryApplicationId(), query.getState()));\n+      }\n+\n+      // Unregister the query to replace it with a new PersistentQueryMetadata\n+      primaryContext.unregisterQuery(query);\n+      // this.unregisterQuery() is called from withing primaryContext.unregisterQuery()\n+\n+      final Topology topology = query.getTopology();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b5a44021f5c340a5b1aa1a1d848617d0eeb3c311"}, "originalPosition": 52}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ5NDQxNzk1", "url": "https://github.com/confluentinc/ksql/pull/5807#pullrequestreview-449441795", "createdAt": "2020-07-16T01:11:05Z", "commit": {"oid": "b5a44021f5c340a5b1aa1a1d848617d0eeb3c311"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQwMToxMTowNlrOGyWkHQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQwMTozMjoyMlrOGyW6fg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ1MTY3Nw==", "bodyText": "I think we should piggy-back on the work in #5766 for query upgrades; we could consider a restart as an upgrade which just upgrades to itself. That way we could reuse the \"replace query\" codepath that I worked on for that - specifically if you call registerQuery with a query with the same ID it will close the old one and register the new one. Also unregister remains private, which I think is an important abstraction detail", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r455451677", "createdAt": "2020-07-16T01:11:06Z", "author": {"login": "agavra"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/EngineContext.java", "diffHunk": "@@ -227,7 +227,7 @@ void registerQuery(final QueryMetadata query) {\n     }\n   }\n \n-  private void unregisterQuery(final QueryMetadata query) {\n+  void unregisterQuery(final QueryMetadata query) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b5a44021f5c340a5b1aa1a1d848617d0eeb3c311"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ1MzY1MA==", "bodyText": "instead of having the try/catch around the entire batch should we try/catch each individual query restart? that way if there's some issue causing the very first one to restart we won't just keep trying only the very first one", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r455453650", "createdAt": "2020-07-16T01:18:44Z", "author": {"login": "agavra"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/QueryMonitor.java", "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.engine;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Ticker;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.util.KsqlConfig;\n+import java.io.Closeable;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Monitor and manages the restart of persistent failed queries.\n+ */\n+public class QueryMonitor implements Closeable {\n+  private static final Logger LOG = LoggerFactory.getLogger(QueryMonitor.class);\n+\n+  private static final Random random = new Random();\n+  private static final Ticker CURRENT_TIME_MILLIS_TICKER = new Ticker() {\n+    @Override\n+    public long read() {\n+      return System.currentTimeMillis();\n+    }\n+  };\n+\n+  private static final long BASE_WAITING_TIME_MS = 10000;\n+  private static final int SHUTDOWN_TIMEOUT_MS = 5000;\n+\n+  private final Ticker ticker;\n+  private final long retryBackoffMaxMs;\n+  private final KsqlEngine ksqlEngine;\n+  private final ExecutorService executor;\n+  private final Map<QueryId, RetryEvent> queriesRetries = new HashMap<>();\n+\n+  private volatile boolean closed = false;\n+\n+  public QueryMonitor(final KsqlConfig ksqlConfig, final KsqlEngine ksqlEngine) {\n+    this(\n+        ksqlConfig,\n+        ksqlEngine,\n+        Executors.newSingleThreadExecutor(r -> new Thread(r, \"QueryMonitor\")),\n+        CURRENT_TIME_MILLIS_TICKER\n+    );\n+  }\n+\n+  @VisibleForTesting\n+  QueryMonitor(\n+      final KsqlConfig ksqlConfig,\n+      final KsqlEngine ksqlEngine,\n+      final ExecutorService executor,\n+      final Ticker ticker\n+  ) {\n+    this.retryBackoffMaxMs = ksqlConfig.getLong(KsqlConfig.KSQL_QUERY_RETRY_BACKOFF_MAX_MS);\n+    this.ksqlEngine = ksqlEngine;\n+    this.executor = executor;\n+    this.ticker = ticker;\n+  }\n+\n+  public void start() {\n+    executor.execute(new Runner());\n+    executor.shutdown();\n+  }\n+\n+  @Override\n+  public void close() {\n+    closed = true;\n+\n+    try {\n+      executor.awaitTermination(SHUTDOWN_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n+    } catch (final InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+    }\n+  }\n+\n+  boolean isClosed() {\n+    return closed;\n+  }\n+\n+  void restartFailedQueries() {\n+    ksqlEngine.getPersistentQueries().stream()\n+        .forEach(query -> {\n+          final QueryId queryId = query.getQueryId();\n+          final KafkaStreams.State queryState = query.getState();\n+\n+          // If the query was restarted previously, check if it needs another restart; or if the\n+          // query is now up and running, then remove it from the restart list.\n+          if (queriesRetries.containsKey(queryId)) {\n+            final RetryEvent retryEvent = queriesRetries.get(queryId);\n+            if (ticker.read() > retryEvent.nextRestartTimeMs()) {\n+              if (queryState == KafkaStreams.State.ERROR) {\n+                // Retry again if it's still in ERROR state\n+                retryEvent.restart();\n+              } else {\n+                // Query is not in ERROR state anymore.\n+                queriesRetries.remove(queryId);\n+              }\n+            }\n+          } else if (queryState == KafkaStreams.State.ERROR) {\n+            // Restart new query in ERROR state, and add it to the list of retries.\n+            final RetryEvent retryEvent = new RetryEvent(\n+                ksqlEngine, queryId, BASE_WAITING_TIME_MS, retryBackoffMaxMs, ticker);\n+\n+            queriesRetries.put(queryId, retryEvent);\n+            retryEvent.restart();\n+          }\n+        });\n+  }\n+\n+  private class Runner implements Runnable {\n+    @Override\n+    public void run() {\n+      LOG.info(\"KSQL query monitor started.\");\n+\n+      while (!closed) {\n+        try {\n+          restartFailedQueries();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b5a44021f5c340a5b1aa1a1d848617d0eeb3c311"}, "originalPosition": 138}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ1Mzg4Nw==", "bodyText": "nit: consider using AbstractExecutionThreadService to manage the lifecycle of this class", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r455453887", "createdAt": "2020-07-16T01:19:40Z", "author": {"login": "agavra"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/QueryMonitor.java", "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.engine;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Ticker;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.util.KsqlConfig;\n+import java.io.Closeable;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Monitor and manages the restart of persistent failed queries.\n+ */\n+public class QueryMonitor implements Closeable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b5a44021f5c340a5b1aa1a1d848617d0eeb3c311"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ1NTE3NA==", "bodyText": "I don't think we want to be calling stop here - we should introduce a new method to make sure that KafkaStreams.cleanUp() isn't called. If I understand correctly this will actually clean up the state store directory and cause it to restore all of that state from the changelog topic (or expose doClose publicly with a better name).\nI suppose there's a consideration where the error is caused by a corrupted state store (e.g. as was the case with #5673) and cleaning it up might help. We might want to try this after N failed retries.\nthis will also close the state listener, which will remove all of the metrics (which could be problematic for alerting reasons)", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r455455174", "createdAt": "2020-07-16T01:24:23Z", "author": {"login": "agavra"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/QueryMonitor.java", "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.engine;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Ticker;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.util.KsqlConfig;\n+import java.io.Closeable;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Monitor and manages the restart of persistent failed queries.\n+ */\n+public class QueryMonitor implements Closeable {\n+  private static final Logger LOG = LoggerFactory.getLogger(QueryMonitor.class);\n+\n+  private static final Random random = new Random();\n+  private static final Ticker CURRENT_TIME_MILLIS_TICKER = new Ticker() {\n+    @Override\n+    public long read() {\n+      return System.currentTimeMillis();\n+    }\n+  };\n+\n+  private static final long BASE_WAITING_TIME_MS = 10000;\n+  private static final int SHUTDOWN_TIMEOUT_MS = 5000;\n+\n+  private final Ticker ticker;\n+  private final long retryBackoffMaxMs;\n+  private final KsqlEngine ksqlEngine;\n+  private final ExecutorService executor;\n+  private final Map<QueryId, RetryEvent> queriesRetries = new HashMap<>();\n+\n+  private volatile boolean closed = false;\n+\n+  public QueryMonitor(final KsqlConfig ksqlConfig, final KsqlEngine ksqlEngine) {\n+    this(\n+        ksqlConfig,\n+        ksqlEngine,\n+        Executors.newSingleThreadExecutor(r -> new Thread(r, \"QueryMonitor\")),\n+        CURRENT_TIME_MILLIS_TICKER\n+    );\n+  }\n+\n+  @VisibleForTesting\n+  QueryMonitor(\n+      final KsqlConfig ksqlConfig,\n+      final KsqlEngine ksqlEngine,\n+      final ExecutorService executor,\n+      final Ticker ticker\n+  ) {\n+    this.retryBackoffMaxMs = ksqlConfig.getLong(KsqlConfig.KSQL_QUERY_RETRY_BACKOFF_MAX_MS);\n+    this.ksqlEngine = ksqlEngine;\n+    this.executor = executor;\n+    this.ticker = ticker;\n+  }\n+\n+  public void start() {\n+    executor.execute(new Runner());\n+    executor.shutdown();\n+  }\n+\n+  @Override\n+  public void close() {\n+    closed = true;\n+\n+    try {\n+      executor.awaitTermination(SHUTDOWN_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n+    } catch (final InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+    }\n+  }\n+\n+  boolean isClosed() {\n+    return closed;\n+  }\n+\n+  void restartFailedQueries() {\n+    ksqlEngine.getPersistentQueries().stream()\n+        .forEach(query -> {\n+          final QueryId queryId = query.getQueryId();\n+          final KafkaStreams.State queryState = query.getState();\n+\n+          // If the query was restarted previously, check if it needs another restart; or if the\n+          // query is now up and running, then remove it from the restart list.\n+          if (queriesRetries.containsKey(queryId)) {\n+            final RetryEvent retryEvent = queriesRetries.get(queryId);\n+            if (ticker.read() > retryEvent.nextRestartTimeMs()) {\n+              if (queryState == KafkaStreams.State.ERROR) {\n+                // Retry again if it's still in ERROR state\n+                retryEvent.restart();\n+              } else {\n+                // Query is not in ERROR state anymore.\n+                queriesRetries.remove(queryId);\n+              }\n+            }\n+          } else if (queryState == KafkaStreams.State.ERROR) {\n+            // Restart new query in ERROR state, and add it to the list of retries.\n+            final RetryEvent retryEvent = new RetryEvent(\n+                ksqlEngine, queryId, BASE_WAITING_TIME_MS, retryBackoffMaxMs, ticker);\n+\n+            queriesRetries.put(queryId, retryEvent);\n+            retryEvent.restart();\n+          }\n+        });\n+  }\n+\n+  private class Runner implements Runnable {\n+    @Override\n+    public void run() {\n+      LOG.info(\"KSQL query monitor started.\");\n+\n+      while (!closed) {\n+        try {\n+          restartFailedQueries();\n+        } catch (final Exception e) {\n+          LOG.warn(\"KSQL query monitor found an error attempting to restart failed queries.\", e);\n+        }\n+      }\n+    }\n+  }\n+\n+  static class RetryEvent {\n+    private final KsqlEngine ksqlEngine;\n+    private final QueryId queryId;\n+    private final Ticker ticker;\n+\n+    private int numRetries = 0;\n+    private long waitingTimeMs;\n+    private long expiryTimeMs;\n+    private long retryBackoffMaxMs;\n+    private long baseWaitingTimeMs;\n+\n+    RetryEvent(\n+        final KsqlEngine ksqlEngine,\n+        final QueryId queryId,\n+        final long baseWaitingTimeMs,\n+        final long retryBackoffMaxMs,\n+        final Ticker ticker\n+    ) {\n+      this.ksqlEngine = ksqlEngine;\n+      this.queryId = queryId;\n+      this.ticker = ticker;\n+\n+      this.baseWaitingTimeMs = baseWaitingTimeMs;\n+      this.waitingTimeMs = baseWaitingTimeMs;\n+      this.expiryTimeMs = ticker.read() + baseWaitingTimeMs;\n+      this.retryBackoffMaxMs = retryBackoffMaxMs;\n+    }\n+\n+    public long nextRestartTimeMs() {\n+      return expiryTimeMs;\n+    }\n+\n+    public int getNumRetries() {\n+      return numRetries;\n+    }\n+\n+    public void restart() {\n+      numRetries++;\n+\n+      LOG.info(\"Restarting query {} (attempt #{})\", queryId, numRetries);\n+\n+      // Stop the queryId using the current QueryMetadata\n+      ksqlEngine.getPersistentQuery(queryId).ifPresent(q -> q.stop());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b5a44021f5c340a5b1aa1a1d848617d0eeb3c311"}, "originalPosition": 188}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ1NTc2OQ==", "bodyText": "what happens if we fail after closing the kafka streams query but before we call reset query? then the kafka streams application will be DEAD or PENDING_SHUTDOWN and we wouldn't try restarting it again. I think we should make sure that this block is transactional - either all of it happens, or none of it happens. That might be a challenge, but I think it's important", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r455455769", "createdAt": "2020-07-16T01:26:31Z", "author": {"login": "agavra"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/QueryMonitor.java", "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.engine;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Ticker;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.util.KsqlConfig;\n+import java.io.Closeable;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Monitor and manages the restart of persistent failed queries.\n+ */\n+public class QueryMonitor implements Closeable {\n+  private static final Logger LOG = LoggerFactory.getLogger(QueryMonitor.class);\n+\n+  private static final Random random = new Random();\n+  private static final Ticker CURRENT_TIME_MILLIS_TICKER = new Ticker() {\n+    @Override\n+    public long read() {\n+      return System.currentTimeMillis();\n+    }\n+  };\n+\n+  private static final long BASE_WAITING_TIME_MS = 10000;\n+  private static final int SHUTDOWN_TIMEOUT_MS = 5000;\n+\n+  private final Ticker ticker;\n+  private final long retryBackoffMaxMs;\n+  private final KsqlEngine ksqlEngine;\n+  private final ExecutorService executor;\n+  private final Map<QueryId, RetryEvent> queriesRetries = new HashMap<>();\n+\n+  private volatile boolean closed = false;\n+\n+  public QueryMonitor(final KsqlConfig ksqlConfig, final KsqlEngine ksqlEngine) {\n+    this(\n+        ksqlConfig,\n+        ksqlEngine,\n+        Executors.newSingleThreadExecutor(r -> new Thread(r, \"QueryMonitor\")),\n+        CURRENT_TIME_MILLIS_TICKER\n+    );\n+  }\n+\n+  @VisibleForTesting\n+  QueryMonitor(\n+      final KsqlConfig ksqlConfig,\n+      final KsqlEngine ksqlEngine,\n+      final ExecutorService executor,\n+      final Ticker ticker\n+  ) {\n+    this.retryBackoffMaxMs = ksqlConfig.getLong(KsqlConfig.KSQL_QUERY_RETRY_BACKOFF_MAX_MS);\n+    this.ksqlEngine = ksqlEngine;\n+    this.executor = executor;\n+    this.ticker = ticker;\n+  }\n+\n+  public void start() {\n+    executor.execute(new Runner());\n+    executor.shutdown();\n+  }\n+\n+  @Override\n+  public void close() {\n+    closed = true;\n+\n+    try {\n+      executor.awaitTermination(SHUTDOWN_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n+    } catch (final InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+    }\n+  }\n+\n+  boolean isClosed() {\n+    return closed;\n+  }\n+\n+  void restartFailedQueries() {\n+    ksqlEngine.getPersistentQueries().stream()\n+        .forEach(query -> {\n+          final QueryId queryId = query.getQueryId();\n+          final KafkaStreams.State queryState = query.getState();\n+\n+          // If the query was restarted previously, check if it needs another restart; or if the\n+          // query is now up and running, then remove it from the restart list.\n+          if (queriesRetries.containsKey(queryId)) {\n+            final RetryEvent retryEvent = queriesRetries.get(queryId);\n+            if (ticker.read() > retryEvent.nextRestartTimeMs()) {\n+              if (queryState == KafkaStreams.State.ERROR) {\n+                // Retry again if it's still in ERROR state\n+                retryEvent.restart();\n+              } else {\n+                // Query is not in ERROR state anymore.\n+                queriesRetries.remove(queryId);\n+              }\n+            }\n+          } else if (queryState == KafkaStreams.State.ERROR) {\n+            // Restart new query in ERROR state, and add it to the list of retries.\n+            final RetryEvent retryEvent = new RetryEvent(\n+                ksqlEngine, queryId, BASE_WAITING_TIME_MS, retryBackoffMaxMs, ticker);\n+\n+            queriesRetries.put(queryId, retryEvent);\n+            retryEvent.restart();\n+          }\n+        });\n+  }\n+\n+  private class Runner implements Runnable {\n+    @Override\n+    public void run() {\n+      LOG.info(\"KSQL query monitor started.\");\n+\n+      while (!closed) {\n+        try {\n+          restartFailedQueries();\n+        } catch (final Exception e) {\n+          LOG.warn(\"KSQL query monitor found an error attempting to restart failed queries.\", e);\n+        }\n+      }\n+    }\n+  }\n+\n+  static class RetryEvent {\n+    private final KsqlEngine ksqlEngine;\n+    private final QueryId queryId;\n+    private final Ticker ticker;\n+\n+    private int numRetries = 0;\n+    private long waitingTimeMs;\n+    private long expiryTimeMs;\n+    private long retryBackoffMaxMs;\n+    private long baseWaitingTimeMs;\n+\n+    RetryEvent(\n+        final KsqlEngine ksqlEngine,\n+        final QueryId queryId,\n+        final long baseWaitingTimeMs,\n+        final long retryBackoffMaxMs,\n+        final Ticker ticker\n+    ) {\n+      this.ksqlEngine = ksqlEngine;\n+      this.queryId = queryId;\n+      this.ticker = ticker;\n+\n+      this.baseWaitingTimeMs = baseWaitingTimeMs;\n+      this.waitingTimeMs = baseWaitingTimeMs;\n+      this.expiryTimeMs = ticker.read() + baseWaitingTimeMs;\n+      this.retryBackoffMaxMs = retryBackoffMaxMs;\n+    }\n+\n+    public long nextRestartTimeMs() {\n+      return expiryTimeMs;\n+    }\n+\n+    public int getNumRetries() {\n+      return numRetries;\n+    }\n+\n+    public void restart() {\n+      numRetries++;\n+\n+      LOG.info(\"Restarting query {} (attempt #{})\", queryId, numRetries);\n+\n+      // Stop the queryId using the current QueryMetadata\n+      ksqlEngine.getPersistentQuery(queryId).ifPresent(q -> q.stop());\n+\n+      // Reset the internal KafkaStreams query. This creates a new QueryMetadata.\n+      ksqlEngine.resetQuery(queryId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b5a44021f5c340a5b1aa1a1d848617d0eeb3c311"}, "originalPosition": 191}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ1NzQwNg==", "bodyText": "can be done in a different PR, but please create a ticket to make sure that we track these in our metrics - it would be good to see - and I think it should also be something that we can expose to the users so they know that they're in a crash-back-off loop", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r455457406", "createdAt": "2020-07-16T01:32:22Z", "author": {"login": "agavra"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/QueryMonitor.java", "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.engine;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Ticker;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.util.KsqlConfig;\n+import java.io.Closeable;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Monitor and manages the restart of persistent failed queries.\n+ */\n+public class QueryMonitor implements Closeable {\n+  private static final Logger LOG = LoggerFactory.getLogger(QueryMonitor.class);\n+\n+  private static final Random random = new Random();\n+  private static final Ticker CURRENT_TIME_MILLIS_TICKER = new Ticker() {\n+    @Override\n+    public long read() {\n+      return System.currentTimeMillis();\n+    }\n+  };\n+\n+  private static final long BASE_WAITING_TIME_MS = 10000;\n+  private static final int SHUTDOWN_TIMEOUT_MS = 5000;\n+\n+  private final Ticker ticker;\n+  private final long retryBackoffMaxMs;\n+  private final KsqlEngine ksqlEngine;\n+  private final ExecutorService executor;\n+  private final Map<QueryId, RetryEvent> queriesRetries = new HashMap<>();\n+\n+  private volatile boolean closed = false;\n+\n+  public QueryMonitor(final KsqlConfig ksqlConfig, final KsqlEngine ksqlEngine) {\n+    this(\n+        ksqlConfig,\n+        ksqlEngine,\n+        Executors.newSingleThreadExecutor(r -> new Thread(r, \"QueryMonitor\")),\n+        CURRENT_TIME_MILLIS_TICKER\n+    );\n+  }\n+\n+  @VisibleForTesting\n+  QueryMonitor(\n+      final KsqlConfig ksqlConfig,\n+      final KsqlEngine ksqlEngine,\n+      final ExecutorService executor,\n+      final Ticker ticker\n+  ) {\n+    this.retryBackoffMaxMs = ksqlConfig.getLong(KsqlConfig.KSQL_QUERY_RETRY_BACKOFF_MAX_MS);\n+    this.ksqlEngine = ksqlEngine;\n+    this.executor = executor;\n+    this.ticker = ticker;\n+  }\n+\n+  public void start() {\n+    executor.execute(new Runner());\n+    executor.shutdown();\n+  }\n+\n+  @Override\n+  public void close() {\n+    closed = true;\n+\n+    try {\n+      executor.awaitTermination(SHUTDOWN_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n+    } catch (final InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+    }\n+  }\n+\n+  boolean isClosed() {\n+    return closed;\n+  }\n+\n+  void restartFailedQueries() {\n+    ksqlEngine.getPersistentQueries().stream()\n+        .forEach(query -> {\n+          final QueryId queryId = query.getQueryId();\n+          final KafkaStreams.State queryState = query.getState();\n+\n+          // If the query was restarted previously, check if it needs another restart; or if the\n+          // query is now up and running, then remove it from the restart list.\n+          if (queriesRetries.containsKey(queryId)) {\n+            final RetryEvent retryEvent = queriesRetries.get(queryId);\n+            if (ticker.read() > retryEvent.nextRestartTimeMs()) {\n+              if (queryState == KafkaStreams.State.ERROR) {\n+                // Retry again if it's still in ERROR state\n+                retryEvent.restart();\n+              } else {\n+                // Query is not in ERROR state anymore.\n+                queriesRetries.remove(queryId);\n+              }\n+            }\n+          } else if (queryState == KafkaStreams.State.ERROR) {\n+            // Restart new query in ERROR state, and add it to the list of retries.\n+            final RetryEvent retryEvent = new RetryEvent(\n+                ksqlEngine, queryId, BASE_WAITING_TIME_MS, retryBackoffMaxMs, ticker);\n+\n+            queriesRetries.put(queryId, retryEvent);\n+            retryEvent.restart();\n+          }\n+        });\n+  }\n+\n+  private class Runner implements Runnable {\n+    @Override\n+    public void run() {\n+      LOG.info(\"KSQL query monitor started.\");\n+\n+      while (!closed) {\n+        try {\n+          restartFailedQueries();\n+        } catch (final Exception e) {\n+          LOG.warn(\"KSQL query monitor found an error attempting to restart failed queries.\", e);\n+        }\n+      }\n+    }\n+  }\n+\n+  static class RetryEvent {\n+    private final KsqlEngine ksqlEngine;\n+    private final QueryId queryId;\n+    private final Ticker ticker;\n+\n+    private int numRetries = 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b5a44021f5c340a5b1aa1a1d848617d0eeb3c311"}, "originalPosition": 151}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUwMjkzNzU0", "url": "https://github.com/confluentinc/ksql/pull/5807#pullrequestreview-450293754", "createdAt": "2020-07-17T00:05:32Z", "commit": {"oid": "b5a44021f5c340a5b1aa1a1d848617d0eeb3c311"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwMDowNTozMlrOGzA4DQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwMDowNTozMlrOGzA4DQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjE0NDkwOQ==", "bodyText": "do we also want to check what type of error happened? you can get the errors that happened with QueryMetadata#getQueryErrors and they may be classified as USER errors, in which case restarting them is unlikely to help. We can also be conservative and just retry them anyway.", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r456144909", "createdAt": "2020-07-17T00:05:32Z", "author": {"login": "agavra"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/QueryMonitor.java", "diffHunk": "@@ -0,0 +1,215 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.engine;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Ticker;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.util.KsqlConfig;\n+import java.io.Closeable;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Monitor and manages the restart of persistent failed queries.\n+ */\n+public class QueryMonitor implements Closeable {\n+  private static final Logger LOG = LoggerFactory.getLogger(QueryMonitor.class);\n+\n+  private static final Random random = new Random();\n+  private static final Ticker CURRENT_TIME_MILLIS_TICKER = new Ticker() {\n+    @Override\n+    public long read() {\n+      return System.currentTimeMillis();\n+    }\n+  };\n+\n+  private static final long BASE_WAITING_TIME_MS = 10000;\n+  private static final int SHUTDOWN_TIMEOUT_MS = 5000;\n+\n+  private final Ticker ticker;\n+  private final long retryBackoffMaxMs;\n+  private final KsqlEngine ksqlEngine;\n+  private final ExecutorService executor;\n+  private final Map<QueryId, RetryEvent> queriesRetries = new HashMap<>();\n+\n+  private volatile boolean closed = false;\n+\n+  public QueryMonitor(final KsqlConfig ksqlConfig, final KsqlEngine ksqlEngine) {\n+    this(\n+        ksqlConfig,\n+        ksqlEngine,\n+        Executors.newSingleThreadExecutor(r -> new Thread(r, \"QueryMonitor\")),\n+        CURRENT_TIME_MILLIS_TICKER\n+    );\n+  }\n+\n+  @VisibleForTesting\n+  QueryMonitor(\n+      final KsqlConfig ksqlConfig,\n+      final KsqlEngine ksqlEngine,\n+      final ExecutorService executor,\n+      final Ticker ticker\n+  ) {\n+    this.retryBackoffMaxMs = ksqlConfig.getLong(KsqlConfig.KSQL_QUERY_RETRY_BACKOFF_MAX_MS);\n+    this.ksqlEngine = ksqlEngine;\n+    this.executor = executor;\n+    this.ticker = ticker;\n+  }\n+\n+  public void start() {\n+    executor.execute(new Runner());\n+    executor.shutdown();\n+  }\n+\n+  @Override\n+  public void close() {\n+    closed = true;\n+\n+    try {\n+      executor.awaitTermination(SHUTDOWN_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n+    } catch (final InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+    }\n+  }\n+\n+  boolean isClosed() {\n+    return closed;\n+  }\n+\n+  void restartFailedQueries() {\n+    ksqlEngine.getPersistentQueries().stream()\n+        .forEach(query -> {\n+          final QueryId queryId = query.getQueryId();\n+          final KafkaStreams.State queryState = query.getState();\n+\n+          // If the query was restarted previously, check if it needs another restart; or if the\n+          // query is now up and running, then remove it from the restart list.\n+          if (queriesRetries.containsKey(queryId)) {\n+            final RetryEvent retryEvent = queriesRetries.get(queryId);\n+            if (ticker.read() > retryEvent.nextRestartTimeMs()) {\n+              if (queryState == KafkaStreams.State.ERROR) {\n+                // Retry again if it's still in ERROR state\n+                retryEvent.restart();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b5a44021f5c340a5b1aa1a1d848617d0eeb3c311"}, "originalPosition": 114}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b5a44021f5c340a5b1aa1a1d848617d0eeb3c311", "author": {"user": {"login": "spena", "name": "Sergio Pe\u00f1a"}}, "url": "https://github.com/confluentinc/ksql/commit/b5a44021f5c340a5b1aa1a1d848617d0eeb3c311", "committedDate": "2020-07-10T20:05:25Z", "message": "feat: add service to restart failed persistent queries"}, "afterCommit": {"oid": "c82776c90bfd25662b22ba8c00794ca5162e0513", "author": {"user": {"login": "spena", "name": "Sergio Pe\u00f1a"}}, "url": "https://github.com/confluentinc/ksql/commit/c82776c90bfd25662b22ba8c00794ca5162e0513", "committedDate": "2020-07-22T22:41:28Z", "message": "fix: address 1st round of reviews"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUzNzM4MTEz", "url": "https://github.com/confluentinc/ksql/pull/5807#pullrequestreview-453738113", "createdAt": "2020-07-22T22:50:52Z", "commit": {"oid": "c82776c90bfd25662b22ba8c00794ca5162e0513"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMjo1MDo1MlrOG1268g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMjo1MDo1MlrOG1268g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTEyNzUzOA==", "bodyText": "I added a few MS sleep just to not keep walking through the failed queries too often.", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r459127538", "createdAt": "2020-07-22T22:50:52Z", "author": {"login": "spena"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/QueryMonitor.java", "diffHunk": "@@ -137,10 +151,12 @@ public void run() {\n       LOG.info(\"KSQL query monitor started.\");\n \n       while (!closed) {\n+        restartFailedQueries();\n+\n         try {\n-          restartFailedQueries();\n+          Thread.sleep(500);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c82776c90bfd25662b22ba8c00794ca5162e0513"}, "originalPosition": 89}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU3MTIzNzky", "url": "https://github.com/confluentinc/ksql/pull/5807#pullrequestreview-457123792", "createdAt": "2020-07-29T00:52:18Z", "commit": {"oid": "c82776c90bfd25662b22ba8c00794ca5162e0513"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwMDo1MjoxOVrOG4kvMA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwMToyNDoxOVrOG4lPMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk3NTM0NA==", "bodyText": "nit: move this block to its own method called something like maybeRestartQuery", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r461975344", "createdAt": "2020-07-29T00:52:19Z", "author": {"login": "rodesai"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/QueryMonitor.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.engine;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Ticker;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import io.confluent.ksql.util.QueryMetadata;\n+import java.io.Closeable;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Random;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Monitor and manages the restart of persistent failed queries.\n+ */\n+public class QueryMonitor implements Closeable {\n+  private static final Logger LOG = LoggerFactory.getLogger(QueryMonitor.class);\n+\n+  private static final Random random = new Random();\n+  private static final Ticker CURRENT_TIME_MILLIS_TICKER = new Ticker() {\n+    @Override\n+    public long read() {\n+      return System.currentTimeMillis();\n+    }\n+  };\n+\n+  private static final int SHUTDOWN_TIMEOUT_MS = 5000;\n+\n+  private final Ticker ticker;\n+  private final long retryBackoffInitialMs;\n+  private final long retryBackoffMaxMs;\n+  private final KsqlEngine ksqlEngine;\n+  private final ExecutorService executor;\n+  private final Map<QueryId, RetryEvent> queriesRetries = new HashMap<>();\n+\n+  private volatile boolean closed = false;\n+\n+  public QueryMonitor(final KsqlConfig ksqlConfig, final KsqlEngine ksqlEngine) {\n+    this(\n+        ksqlEngine,\n+        Executors.newSingleThreadExecutor(r -> new Thread(r, QueryMonitor.class.getName())),\n+        ksqlConfig.getLong(KsqlConfig.KSQL_QUERY_RETRY_BACKOFF_INITIAL_MS),\n+        ksqlConfig.getLong(KsqlConfig.KSQL_QUERY_RETRY_BACKOFF_MAX_MS),\n+        CURRENT_TIME_MILLIS_TICKER\n+    );\n+  }\n+\n+  @VisibleForTesting\n+  QueryMonitor(\n+      final KsqlEngine ksqlEngine,\n+      final ExecutorService executor,\n+      final long retryBackoffInitialMs,\n+      final long retryBackoffMaxMs,\n+      final Ticker ticker\n+  ) {\n+    this.retryBackoffInitialMs = retryBackoffInitialMs;\n+    this.retryBackoffMaxMs = retryBackoffMaxMs;\n+    this.ksqlEngine = ksqlEngine;\n+    this.executor = executor;\n+    this.ticker = ticker;\n+  }\n+\n+  public void start() {\n+    executor.execute(new Runner());\n+    executor.shutdown();\n+  }\n+\n+  @Override\n+  public void close() {\n+    closed = true;\n+\n+    try {\n+      executor.awaitTermination(SHUTDOWN_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n+    } catch (final InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+    }\n+  }\n+\n+  boolean isClosed() {\n+    return closed;\n+  }\n+\n+  void restartFailedQueries() {\n+    // Collect a list of new queries in ERROR state\n+    ksqlEngine.getPersistentQueries().stream()\n+        .filter(query -> query.getState() == KafkaStreams.State.ERROR)\n+        .filter(query -> !queriesRetries.containsKey(query.getQueryId()))\n+        .map(QueryMetadata::getQueryId)\n+        .forEach(queryId -> queriesRetries.put(queryId, newRetryEvent(queryId)));\n+\n+    // Restart queries that has passed the waiting timeout\n+    final List<QueryId> deleteRetryEvents = new ArrayList<>();\n+    queriesRetries.entrySet().stream()\n+        .forEach(mapEntry -> {\n+          final QueryId queryId = mapEntry.getKey();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c82776c90bfd25662b22ba8c00794ca5162e0513"}, "originalPosition": 121}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk3NjE5NQ==", "bodyText": "kind fo nit: we may want some threshold here, otherwise it's possible we will never apply any backoff if it takes a long time to hit a given error. Basically there are 2 intervals we care about:\n\nthe next time we retry (retryEvent.nextRetsartTimeMs)\nhow long a query is up and running before which we stamp it as \"healthy\". Currently we're just using 2x however long we waited last time. Which is maybe ok - but let's make that more explicit in the code by adding a method to retryEvent like queryHealthyTime and making sure the query is not in ERROR state after whatever that returns. They we can possibly make that configurable in a follow up.", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r461976195", "createdAt": "2020-07-29T00:55:40Z", "author": {"login": "rodesai"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/QueryMonitor.java", "diffHunk": "@@ -0,0 +1,228 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.engine;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Ticker;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import io.confluent.ksql.util.QueryMetadata;\n+import java.io.Closeable;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Random;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Monitor and manages the restart of persistent failed queries.\n+ */\n+public class QueryMonitor implements Closeable {\n+  private static final Logger LOG = LoggerFactory.getLogger(QueryMonitor.class);\n+\n+  private static final Random random = new Random();\n+  private static final Ticker CURRENT_TIME_MILLIS_TICKER = new Ticker() {\n+    @Override\n+    public long read() {\n+      return System.currentTimeMillis();\n+    }\n+  };\n+\n+  private static final int SHUTDOWN_TIMEOUT_MS = 5000;\n+\n+  private final Ticker ticker;\n+  private final long retryBackoffInitialMs;\n+  private final long retryBackoffMaxMs;\n+  private final KsqlEngine ksqlEngine;\n+  private final ExecutorService executor;\n+  private final Map<QueryId, RetryEvent> queriesRetries = new HashMap<>();\n+\n+  private volatile boolean closed = false;\n+\n+  public QueryMonitor(final KsqlConfig ksqlConfig, final KsqlEngine ksqlEngine) {\n+    this(\n+        ksqlEngine,\n+        Executors.newSingleThreadExecutor(r -> new Thread(r, QueryMonitor.class.getName())),\n+        ksqlConfig.getLong(KsqlConfig.KSQL_QUERY_RETRY_BACKOFF_INITIAL_MS),\n+        ksqlConfig.getLong(KsqlConfig.KSQL_QUERY_RETRY_BACKOFF_MAX_MS),\n+        CURRENT_TIME_MILLIS_TICKER\n+    );\n+  }\n+\n+  @VisibleForTesting\n+  QueryMonitor(\n+      final KsqlEngine ksqlEngine,\n+      final ExecutorService executor,\n+      final long retryBackoffInitialMs,\n+      final long retryBackoffMaxMs,\n+      final Ticker ticker\n+  ) {\n+    this.retryBackoffInitialMs = retryBackoffInitialMs;\n+    this.retryBackoffMaxMs = retryBackoffMaxMs;\n+    this.ksqlEngine = ksqlEngine;\n+    this.executor = executor;\n+    this.ticker = ticker;\n+  }\n+\n+  public void start() {\n+    executor.execute(new Runner());\n+    executor.shutdown();\n+  }\n+\n+  @Override\n+  public void close() {\n+    closed = true;\n+\n+    try {\n+      executor.awaitTermination(SHUTDOWN_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n+    } catch (final InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+    }\n+  }\n+\n+  boolean isClosed() {\n+    return closed;\n+  }\n+\n+  void restartFailedQueries() {\n+    // Collect a list of new queries in ERROR state\n+    ksqlEngine.getPersistentQueries().stream()\n+        .filter(query -> query.getState() == KafkaStreams.State.ERROR)\n+        .filter(query -> !queriesRetries.containsKey(query.getQueryId()))\n+        .map(QueryMetadata::getQueryId)\n+        .forEach(queryId -> queriesRetries.put(queryId, newRetryEvent(queryId)));\n+\n+    // Restart queries that has passed the waiting timeout\n+    final List<QueryId> deleteRetryEvents = new ArrayList<>();\n+    queriesRetries.entrySet().stream()\n+        .forEach(mapEntry -> {\n+          final QueryId queryId = mapEntry.getKey();\n+          final RetryEvent retryEvent = mapEntry.getValue();\n+          final Optional<PersistentQueryMetadata> query = ksqlEngine.getPersistentQuery(queryId);\n+\n+          // Query was terminated manually if no present\n+          if (!query.isPresent()) {\n+            deleteRetryEvents.add(queryId);\n+          } else if (ticker.read() > retryEvent.nextRestartTimeMs()) {\n+            if (query.get().getState() == KafkaStreams.State.ERROR) {\n+              // Retry again if it's still in ERROR state\n+              retryEvent.restart();\n+            } else {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c82776c90bfd25662b22ba8c00794ca5162e0513"}, "originalPosition": 132}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk3NjQ4Mw==", "bodyText": "nit: this seems like a long initial wait. Maybe 15 or 30 seconds to start with?", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r461976483", "createdAt": "2020-07-29T00:56:44Z", "author": {"login": "rodesai"}, "path": "ksqldb-common/src/main/java/io/confluent/ksql/util/KsqlConfig.java", "diffHunk": "@@ -308,6 +308,17 @@\n   public static final String KSQL_SUPPRESS_ENABLED_DOC =\n       \"Feature flag for suppression, specifically EMIT FINAL\";\n \n+  public static final String KSQL_QUERY_RETRY_BACKOFF_INITIAL_MS\n+      = \"ksql.query.retry.backoff.initial.ms\";\n+  public static final Long KSQL_QUERY_RETRY_BACKOFF_INITIAL_MS_DEFAULT = 60000L;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c82776c90bfd25662b22ba8c00794ca5162e0513"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk3Nzg3Mg==", "bodyText": "we don't want to clear errors here, right? Otherwise when in a retry loop we may not actually return any errors back. I think it would be better to accumulate them (up to a certain size/time bound)", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r461977872", "createdAt": "2020-07-29T01:02:19Z", "author": {"login": "rodesai"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/util/QueryMetadata.java", "diffHunk": "@@ -208,6 +217,37 @@ public KsqlQueryType getQueryType() {\n     return KsqlQueryType.PERSISTENT;\n   }\n \n+  public String getTopologyDescription() {\n+    return topology.describe().toString();\n+  }\n+\n+  public List<QueryError> getQueryErrors() {\n+    return ImmutableList.copyOf(queryErrors);\n+  }\n+\n+  protected boolean isClosed() {\n+    return closed;\n+  }\n+\n+  protected KafkaStreams getKafkaStreams() {\n+    return kafkaStreams;\n+  }\n+\n+  protected void resetKafkaStreams(final KafkaStreams kafkaStreams) {\n+    this.kafkaStreams = kafkaStreams;\n+    queryErrors.clear();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c82776c90bfd25662b22ba8c00794ca5162e0513"}, "originalPosition": 126}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk4MzUzOA==", "bodyText": "we should add a test case to ensure that the query monitor deals with terminated queries correctly.", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r461983538", "createdAt": "2020-07-29T01:24:19Z", "author": {"login": "rodesai"}, "path": "ksqldb-engine/src/test/java/io/confluent/ksql/engine/QueryMonitorTest.java", "diffHunk": "@@ -0,0 +1,245 @@\n+package io.confluent.ksql.engine;\n+\n+import com.google.common.base.Ticker;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.mockito.InOrder;\n+import org.mockito.Mock;\n+import org.mockito.junit.MockitoJUnitRunner;\n+\n+import java.util.Arrays;\n+import java.util.Optional;\n+import java.util.concurrent.ExecutorService;\n+\n+import static org.apache.kafka.streams.KafkaStreams.State.ERROR;\n+import static org.apache.kafka.streams.KafkaStreams.State.RUNNING;\n+import static org.hamcrest.Matchers.greaterThanOrEqualTo;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.ArgumentMatchers.anyLong;\n+import static org.mockito.Mockito.atLeastOnce;\n+import static org.mockito.Mockito.doThrow;\n+import static org.mockito.Mockito.inOrder;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.never;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+@RunWith(MockitoJUnitRunner.class)\n+public class QueryMonitorTest {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c82776c90bfd25662b22ba8c00794ca5162e0513"}, "originalPosition": 35}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c82776c90bfd25662b22ba8c00794ca5162e0513", "author": {"user": {"login": "spena", "name": "Sergio Pe\u00f1a"}}, "url": "https://github.com/confluentinc/ksql/commit/c82776c90bfd25662b22ba8c00794ca5162e0513", "committedDate": "2020-07-22T22:41:28Z", "message": "fix: address 1st round of reviews"}, "afterCommit": {"oid": "66440ee6d27457b7def7408fa1e70ad4ca85a67d", "author": {"user": {"login": "spena", "name": "Sergio Pe\u00f1a"}}, "url": "https://github.com/confluentinc/ksql/commit/66440ee6d27457b7def7408fa1e70ad4ca85a67d", "committedDate": "2020-07-29T21:42:35Z", "message": "fix: 2nd round of feedback"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "66440ee6d27457b7def7408fa1e70ad4ca85a67d", "author": {"user": {"login": "spena", "name": "Sergio Pe\u00f1a"}}, "url": "https://github.com/confluentinc/ksql/commit/66440ee6d27457b7def7408fa1e70ad4ca85a67d", "committedDate": "2020-07-29T21:42:35Z", "message": "fix: 2nd round of feedback"}, "afterCommit": {"oid": "2160b820a5eec74fc4996ff9e378ebedf7ec8e2d", "author": {"user": {"login": "spena", "name": "Sergio Pe\u00f1a"}}, "url": "https://github.com/confluentinc/ksql/commit/2160b820a5eec74fc4996ff9e378ebedf7ec8e2d", "committedDate": "2020-07-29T21:44:09Z", "message": "fix: 2nd round of feedback"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU5MzQ0NTk2", "url": "https://github.com/confluentinc/ksql/pull/5807#pullrequestreview-459344596", "createdAt": "2020-07-31T17:34:30Z", "commit": {"oid": "2160b820a5eec74fc4996ff9e378ebedf7ec8e2d"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "82b6fd6d4901dc39a6f24089f75d741a53a19ea2", "author": {"user": {"login": "spena", "name": "Sergio Pe\u00f1a"}}, "url": "https://github.com/confluentinc/ksql/commit/82b6fd6d4901dc39a6f24089f75d741a53a19ea2", "committedDate": "2020-07-31T17:36:23Z", "message": "feat: add service to restart failed persistent queries"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "88bb6d76c8e072879269942167744f2d90e126ba", "author": {"user": {"login": "spena", "name": "Sergio Pe\u00f1a"}}, "url": "https://github.com/confluentinc/ksql/commit/88bb6d76c8e072879269942167744f2d90e126ba", "committedDate": "2020-07-31T17:36:23Z", "message": "feat: add retry.initial.backoff.ms config + increase max. time"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c41fad9525ba2b4fc0f99c0251134c01d43c2725", "author": {"user": {"login": "spena", "name": "Sergio Pe\u00f1a"}}, "url": "https://github.com/confluentinc/ksql/commit/c41fad9525ba2b4fc0f99c0251134c01d43c2725", "committedDate": "2020-07-31T17:36:23Z", "message": "refactor: wrap 3 sink params into 1 DataSource in PersistentQueryMetadata"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a2a39318eff4af7836b69cc692e1cee8c27f0d98", "author": {"user": {"login": "spena", "name": "Sergio Pe\u00f1a"}}, "url": "https://github.com/confluentinc/ksql/commit/a2a39318eff4af7836b69cc692e1cee8c27f0d98", "committedDate": "2020-07-31T17:36:23Z", "message": "fix: address 1st round of reviews"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b0fd58f1c04149ab1916c11e3e8e070b05a29bd5", "author": {"user": {"login": "spena", "name": "Sergio Pe\u00f1a"}}, "url": "https://github.com/confluentinc/ksql/commit/b0fd58f1c04149ab1916c11e3e8e070b05a29bd5", "committedDate": "2020-07-31T17:39:03Z", "message": "fix: 2nd round of feedback"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7cec7b98d26dccd7246089cc35ce156d7f74c10f", "author": {"user": {"login": "spena", "name": "Sergio Pe\u00f1a"}}, "url": "https://github.com/confluentinc/ksql/commit/7cec7b98d26dccd7246089cc35ce156d7f74c10f", "committedDate": "2020-07-31T17:49:38Z", "message": "chore: add queryHealthyTime() to RetryEvent"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "2160b820a5eec74fc4996ff9e378ebedf7ec8e2d", "author": {"user": {"login": "spena", "name": "Sergio Pe\u00f1a"}}, "url": "https://github.com/confluentinc/ksql/commit/2160b820a5eec74fc4996ff9e378ebedf7ec8e2d", "committedDate": "2020-07-29T21:44:09Z", "message": "fix: 2nd round of feedback"}, "afterCommit": {"oid": "7cec7b98d26dccd7246089cc35ce156d7f74c10f", "author": {"user": {"login": "spena", "name": "Sergio Pe\u00f1a"}}, "url": "https://github.com/confluentinc/ksql/commit/7cec7b98d26dccd7246089cc35ce156d7f74c10f", "committedDate": "2020-07-31T17:49:38Z", "message": "chore: add queryHealthyTime() to RetryEvent"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU5MzYwMDgz", "url": "https://github.com/confluentinc/ksql/pull/5807#pullrequestreview-459360083", "createdAt": "2020-07-31T17:59:39Z", "commit": {"oid": "7cec7b98d26dccd7246089cc35ce156d7f74c10f"}, "state": "APPROVED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQxNzo1OTozOVrOG6RNew==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQxODoyMjoyNlrOG6R2eg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzc1MjU3MQ==", "bodyText": "i think InterruptedException is the only valid exception here, which we should catch and respect", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r463752571", "createdAt": "2020-07-31T17:59:39Z", "author": {"login": "agavra"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/QueryMonitor.java", "diffHunk": "@@ -0,0 +1,237 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.engine;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Ticker;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import io.confluent.ksql.util.QueryMetadata;\n+import java.io.Closeable;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Random;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Monitor and manages the restart of persistent failed queries.\n+ */\n+public class QueryMonitor implements Closeable {\n+  private static final Logger LOG = LoggerFactory.getLogger(QueryMonitor.class);\n+\n+  private static final Random random = new Random();\n+  private static final Ticker CURRENT_TIME_MILLIS_TICKER = new Ticker() {\n+    @Override\n+    public long read() {\n+      return System.currentTimeMillis();\n+    }\n+  };\n+\n+  private static final int SHUTDOWN_TIMEOUT_MS = 5000;\n+\n+  private final Ticker ticker;\n+  private final long retryBackoffInitialMs;\n+  private final long retryBackoffMaxMs;\n+  private final KsqlEngine ksqlEngine;\n+  private final ExecutorService executor;\n+  private final Map<QueryId, RetryEvent> queriesRetries = new HashMap<>();\n+\n+  private volatile boolean closed = false;\n+\n+  public QueryMonitor(final KsqlConfig ksqlConfig, final KsqlEngine ksqlEngine) {\n+    this(\n+        ksqlEngine,\n+        Executors.newSingleThreadExecutor(r -> new Thread(r, QueryMonitor.class.getName())),\n+        ksqlConfig.getLong(KsqlConfig.KSQL_QUERY_RETRY_BACKOFF_INITIAL_MS),\n+        ksqlConfig.getLong(KsqlConfig.KSQL_QUERY_RETRY_BACKOFF_MAX_MS),\n+        CURRENT_TIME_MILLIS_TICKER\n+    );\n+  }\n+\n+  @VisibleForTesting\n+  QueryMonitor(\n+      final KsqlEngine ksqlEngine,\n+      final ExecutorService executor,\n+      final long retryBackoffInitialMs,\n+      final long retryBackoffMaxMs,\n+      final Ticker ticker\n+  ) {\n+    this.retryBackoffInitialMs = retryBackoffInitialMs;\n+    this.retryBackoffMaxMs = retryBackoffMaxMs;\n+    this.ksqlEngine = ksqlEngine;\n+    this.executor = executor;\n+    this.ticker = ticker;\n+  }\n+\n+  public void start() {\n+    executor.execute(new Runner());\n+    executor.shutdown();\n+  }\n+\n+  @Override\n+  public void close() {\n+    closed = true;\n+\n+    try {\n+      executor.awaitTermination(SHUTDOWN_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n+    } catch (final InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+    }\n+  }\n+\n+  boolean isClosed() {\n+    return closed;\n+  }\n+\n+  void restartFailedQueries() {\n+    // Collect a list of new queries in ERROR state\n+    ksqlEngine.getPersistentQueries().stream()\n+        .filter(QueryMetadata::isError)\n+        .filter(query -> !queriesRetries.containsKey(query.getQueryId()))\n+        .map(QueryMetadata::getQueryId)\n+        .forEach(queryId -> queriesRetries.put(queryId, newRetryEvent(queryId)));\n+\n+    maybeRestartQueries();\n+  }\n+\n+  private void maybeRestartQueries() {\n+    final long now = ticker.read();\n+\n+    // Restart queries that has passed the waiting timeout\n+    final List<QueryId> deleteRetryEvents = new ArrayList<>();\n+    queriesRetries.entrySet().stream()\n+        .forEach(mapEntry -> {\n+          final QueryId queryId = mapEntry.getKey();\n+          final RetryEvent retryEvent = mapEntry.getValue();\n+          final Optional<PersistentQueryMetadata> query = ksqlEngine.getPersistentQuery(queryId);\n+\n+          // Query was terminated manually if no present\n+          if (!query.isPresent()) {\n+            deleteRetryEvents.add(queryId);\n+          } else if (query.get().isError() && now > retryEvent.nextRestartTimeMs()) {\n+            // Retry again if it's still in ERROR state\n+            retryEvent.restart();\n+          } else if (now > retryEvent.queryHealthyTime()) {\n+            // Clean the errors queue & delete the query from future retries now the query is\n+            // healthy\n+            query.ifPresent(QueryMetadata::clearErrors);\n+            deleteRetryEvents.add(queryId);\n+          }\n+        });\n+\n+    deleteRetryEvents.stream().forEach(queriesRetries::remove);\n+  }\n+\n+  private RetryEvent newRetryEvent(final QueryId queryId) {\n+    return new RetryEvent(ksqlEngine, queryId, retryBackoffInitialMs, retryBackoffMaxMs, ticker);\n+  }\n+\n+  private class Runner implements Runnable {\n+    @Override\n+    public void run() {\n+      LOG.info(\"KSQL query monitor started.\");\n+\n+      while (!closed) {\n+        restartFailedQueries();\n+\n+        try {\n+          Thread.sleep(500);\n+        } catch (final Exception e) {\n+          // ignore.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7cec7b98d26dccd7246089cc35ce156d7f74c10f"}, "originalPosition": 162}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzc1OTYwOA==", "bodyText": "might be good to add a summary log line here (e.g. restarted queries [X, Y], marked queries [Z] as healthy, could not find queries [A])", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r463759608", "createdAt": "2020-07-31T18:14:52Z", "author": {"login": "agavra"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/QueryMonitor.java", "diffHunk": "@@ -0,0 +1,237 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.engine;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Ticker;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import io.confluent.ksql.util.QueryMetadata;\n+import java.io.Closeable;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Random;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Monitor and manages the restart of persistent failed queries.\n+ */\n+public class QueryMonitor implements Closeable {\n+  private static final Logger LOG = LoggerFactory.getLogger(QueryMonitor.class);\n+\n+  private static final Random random = new Random();\n+  private static final Ticker CURRENT_TIME_MILLIS_TICKER = new Ticker() {\n+    @Override\n+    public long read() {\n+      return System.currentTimeMillis();\n+    }\n+  };\n+\n+  private static final int SHUTDOWN_TIMEOUT_MS = 5000;\n+\n+  private final Ticker ticker;\n+  private final long retryBackoffInitialMs;\n+  private final long retryBackoffMaxMs;\n+  private final KsqlEngine ksqlEngine;\n+  private final ExecutorService executor;\n+  private final Map<QueryId, RetryEvent> queriesRetries = new HashMap<>();\n+\n+  private volatile boolean closed = false;\n+\n+  public QueryMonitor(final KsqlConfig ksqlConfig, final KsqlEngine ksqlEngine) {\n+    this(\n+        ksqlEngine,\n+        Executors.newSingleThreadExecutor(r -> new Thread(r, QueryMonitor.class.getName())),\n+        ksqlConfig.getLong(KsqlConfig.KSQL_QUERY_RETRY_BACKOFF_INITIAL_MS),\n+        ksqlConfig.getLong(KsqlConfig.KSQL_QUERY_RETRY_BACKOFF_MAX_MS),\n+        CURRENT_TIME_MILLIS_TICKER\n+    );\n+  }\n+\n+  @VisibleForTesting\n+  QueryMonitor(\n+      final KsqlEngine ksqlEngine,\n+      final ExecutorService executor,\n+      final long retryBackoffInitialMs,\n+      final long retryBackoffMaxMs,\n+      final Ticker ticker\n+  ) {\n+    this.retryBackoffInitialMs = retryBackoffInitialMs;\n+    this.retryBackoffMaxMs = retryBackoffMaxMs;\n+    this.ksqlEngine = ksqlEngine;\n+    this.executor = executor;\n+    this.ticker = ticker;\n+  }\n+\n+  public void start() {\n+    executor.execute(new Runner());\n+    executor.shutdown();\n+  }\n+\n+  @Override\n+  public void close() {\n+    closed = true;\n+\n+    try {\n+      executor.awaitTermination(SHUTDOWN_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n+    } catch (final InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+    }\n+  }\n+\n+  boolean isClosed() {\n+    return closed;\n+  }\n+\n+  void restartFailedQueries() {\n+    // Collect a list of new queries in ERROR state\n+    ksqlEngine.getPersistentQueries().stream()\n+        .filter(QueryMetadata::isError)\n+        .filter(query -> !queriesRetries.containsKey(query.getQueryId()))\n+        .map(QueryMetadata::getQueryId)\n+        .forEach(queryId -> queriesRetries.put(queryId, newRetryEvent(queryId)));\n+\n+    maybeRestartQueries();\n+  }\n+\n+  private void maybeRestartQueries() {\n+    final long now = ticker.read();\n+\n+    // Restart queries that has passed the waiting timeout\n+    final List<QueryId> deleteRetryEvents = new ArrayList<>();\n+    queriesRetries.entrySet().stream()\n+        .forEach(mapEntry -> {\n+          final QueryId queryId = mapEntry.getKey();\n+          final RetryEvent retryEvent = mapEntry.getValue();\n+          final Optional<PersistentQueryMetadata> query = ksqlEngine.getPersistentQuery(queryId);\n+\n+          // Query was terminated manually if no present\n+          if (!query.isPresent()) {\n+            deleteRetryEvents.add(queryId);\n+          } else if (query.get().isError() && now > retryEvent.nextRestartTimeMs()) {\n+            // Retry again if it's still in ERROR state\n+            retryEvent.restart();\n+          } else if (now > retryEvent.queryHealthyTime()) {\n+            // Clean the errors queue & delete the query from future retries now the query is\n+            // healthy\n+            query.ifPresent(QueryMetadata::clearErrors);\n+            deleteRetryEvents.add(queryId);\n+          }\n+        });\n+\n+    deleteRetryEvents.stream().forEach(queriesRetries::remove);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7cec7b98d26dccd7246089cc35ce156d7f74c10f"}, "originalPosition": 144}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzc2MzA2Ng==", "bodyText": "we might want to make restart return something and just have the getPersistentQuery(queryId) call inside restart so that we don't have a race which would cause the lookup below to return something different (e.g. in the case of deletions or query upgrade) than what's here", "url": "https://github.com/confluentinc/ksql/pull/5807#discussion_r463763066", "createdAt": "2020-07-31T18:22:26Z", "author": {"login": "agavra"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/QueryMonitor.java", "diffHunk": "@@ -0,0 +1,237 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.engine;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.google.common.base.Ticker;\n+import io.confluent.ksql.query.QueryId;\n+import io.confluent.ksql.util.KsqlConfig;\n+import io.confluent.ksql.util.PersistentQueryMetadata;\n+import io.confluent.ksql.util.QueryMetadata;\n+import java.io.Closeable;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Random;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.TimeUnit;\n+\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Monitor and manages the restart of persistent failed queries.\n+ */\n+public class QueryMonitor implements Closeable {\n+  private static final Logger LOG = LoggerFactory.getLogger(QueryMonitor.class);\n+\n+  private static final Random random = new Random();\n+  private static final Ticker CURRENT_TIME_MILLIS_TICKER = new Ticker() {\n+    @Override\n+    public long read() {\n+      return System.currentTimeMillis();\n+    }\n+  };\n+\n+  private static final int SHUTDOWN_TIMEOUT_MS = 5000;\n+\n+  private final Ticker ticker;\n+  private final long retryBackoffInitialMs;\n+  private final long retryBackoffMaxMs;\n+  private final KsqlEngine ksqlEngine;\n+  private final ExecutorService executor;\n+  private final Map<QueryId, RetryEvent> queriesRetries = new HashMap<>();\n+\n+  private volatile boolean closed = false;\n+\n+  public QueryMonitor(final KsqlConfig ksqlConfig, final KsqlEngine ksqlEngine) {\n+    this(\n+        ksqlEngine,\n+        Executors.newSingleThreadExecutor(r -> new Thread(r, QueryMonitor.class.getName())),\n+        ksqlConfig.getLong(KsqlConfig.KSQL_QUERY_RETRY_BACKOFF_INITIAL_MS),\n+        ksqlConfig.getLong(KsqlConfig.KSQL_QUERY_RETRY_BACKOFF_MAX_MS),\n+        CURRENT_TIME_MILLIS_TICKER\n+    );\n+  }\n+\n+  @VisibleForTesting\n+  QueryMonitor(\n+      final KsqlEngine ksqlEngine,\n+      final ExecutorService executor,\n+      final long retryBackoffInitialMs,\n+      final long retryBackoffMaxMs,\n+      final Ticker ticker\n+  ) {\n+    this.retryBackoffInitialMs = retryBackoffInitialMs;\n+    this.retryBackoffMaxMs = retryBackoffMaxMs;\n+    this.ksqlEngine = ksqlEngine;\n+    this.executor = executor;\n+    this.ticker = ticker;\n+  }\n+\n+  public void start() {\n+    executor.execute(new Runner());\n+    executor.shutdown();\n+  }\n+\n+  @Override\n+  public void close() {\n+    closed = true;\n+\n+    try {\n+      executor.awaitTermination(SHUTDOWN_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n+    } catch (final InterruptedException e) {\n+      Thread.currentThread().interrupt();\n+    }\n+  }\n+\n+  boolean isClosed() {\n+    return closed;\n+  }\n+\n+  void restartFailedQueries() {\n+    // Collect a list of new queries in ERROR state\n+    ksqlEngine.getPersistentQueries().stream()\n+        .filter(QueryMetadata::isError)\n+        .filter(query -> !queriesRetries.containsKey(query.getQueryId()))\n+        .map(QueryMetadata::getQueryId)\n+        .forEach(queryId -> queriesRetries.put(queryId, newRetryEvent(queryId)));\n+\n+    maybeRestartQueries();\n+  }\n+\n+  private void maybeRestartQueries() {\n+    final long now = ticker.read();\n+\n+    // Restart queries that has passed the waiting timeout\n+    final List<QueryId> deleteRetryEvents = new ArrayList<>();\n+    queriesRetries.entrySet().stream()\n+        .forEach(mapEntry -> {\n+          final QueryId queryId = mapEntry.getKey();\n+          final RetryEvent retryEvent = mapEntry.getValue();\n+          final Optional<PersistentQueryMetadata> query = ksqlEngine.getPersistentQuery(queryId);\n+\n+          // Query was terminated manually if no present\n+          if (!query.isPresent()) {\n+            deleteRetryEvents.add(queryId);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7cec7b98d26dccd7246089cc35ce156d7f74c10f"}, "originalPosition": 132}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0abdf8efd7ee58e7ee4c0d9b2fba7fbc67ad50d0", "author": {"user": {"login": "spena", "name": "Sergio Pe\u00f1a"}}, "url": "https://github.com/confluentinc/ksql/commit/0abdf8efd7ee58e7ee4c0d9b2fba7fbc67ad50d0", "committedDate": "2020-07-31T21:20:27Z", "message": "chore: stop QueryMonitor if Thread.sleep is interrupted"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4822, "cost": 1, "resetAt": "2021-11-01T13:51:04Z"}}}