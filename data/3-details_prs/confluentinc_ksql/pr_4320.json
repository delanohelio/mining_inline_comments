{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzYzMTgyODc1", "number": 4320, "title": "feat: Bare bones API server", "bodyText": "Description\nFixes #4255\nThis PR introduces the new Vert.x based API server as proposed in KLIP-15 #4069\nIt's phase 1 of the work and implements the minimum set of endpoints necessary to enable an example JavaScript application.\nThe actual implementation of the endpoints is abstracted out using the Endpoints interface. This means the Vert.x server code and the actual endpoint implementation can be maintained separately.\nAt this point we don't actual plug-in to a real ksqlDB back end. We simply test against test implementations of the endpoints to ensure the request and responses are handled as expected.\nThe implementation uses reactive streams https://www.reactive-streams.org/ to implement the streams between the API server and the back-end.\nThe server itself uses Vert.x and Vert.x Web to handle the HTTP 2 requests and responses.\nFor more info on Vert.x and Vert.x Web please see the Vert.x documentation. https://vertx.io/docs/\nTesting done\nIncludes a new set of API tests.\nReviewer checklist\n\n Ensure docs are updated if necessary. (eg. if a user visible feature is being added or changed).\n Ensure relevant issues are linked (description should include text like \"Fixes #\")", "createdAt": "2020-01-15T15:04:36Z", "url": "https://github.com/confluentinc/ksql/pull/4320", "merged": true, "mergeCommit": {"oid": "7a8ba8c7cde9244606e56bc0cae67df938b11452"}, "closed": true, "closedAt": "2020-01-17T10:42:55Z", "author": {"login": "purplefox"}, "timelineItems": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABb6rMzFAFqTM0MzQ4NTQxMQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABb7UatQAFqTM0NDc0NzI1OQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQzNDg1NDEx", "url": "https://github.com/confluentinc/ksql/pull/4320#pullrequestreview-343485411", "createdAt": "2020-01-15T20:02:25Z", "commit": {"oid": "c40735e2be6944f3ccbb84adf34c0b4c64abd139"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMDowMjoyNlrOFeEwZg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNVQyMDowMjoyNlrOFeEwZg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzA3OTUyNg==", "bodyText": "Could we consider camelCase instead of kebab-case for the metadata object keys?\nI have the JS client in mind, where it would be more natural to operate on objects with the former.\nconst { columnNames, columnTypes } = queryMetadata;\n// vs\nconst columnNames = queryMetadata[\"column-names\"];\nconst columnTypes = queryMetadata[\"column-types\"];", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367079526", "createdAt": "2020-01-15T20:02:26Z", "author": {"login": "colinhicks"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerVerticle.java", "diffHunk": "@@ -0,0 +1,201 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.impl.Utils;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.QueryPublisher;\n+import io.vertx.core.AbstractVerticle;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Promise;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpMethod;\n+import io.vertx.core.http.HttpServer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.parsetools.RecordParser;\n+import io.vertx.ext.web.Router;\n+import io.vertx.ext.web.RoutingContext;\n+import io.vertx.ext.web.handler.BodyHandler;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * The server deploys multiple server verticles. This is where the HTTP2 requests are handled. The\n+ * actual implementation of the endpoints is provided by an implementation of {@code Endpoints}.\n+ */\n+public class ServerVerticle extends AbstractVerticle {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ServerVerticle.class);\n+\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Server server;\n+  private final Map<HttpConnection, ConnectionQueries> connectionsMap = new HashMap<>();\n+  private HttpServer httpServer;\n+\n+  public ServerVerticle(final Endpoints endpoints, final HttpServerOptions httpServerOptions,\n+      final Server server) {\n+    this.endpoints = endpoints;\n+    this.httpServerOptions = httpServerOptions;\n+    this.server = server;\n+  }\n+\n+  @Override\n+  public void start(final Promise<Void> startPromise) {\n+    httpServer = vertx.createHttpServer(httpServerOptions).requestHandler(setupRouter());\n+    httpServer.exceptionHandler(ServerUtils::handleException);\n+    Future<HttpServer> listenFuture = Promise.<HttpServer>promise().future();\n+    Utils.connectPromise(listenFuture.map(s -> null), startPromise);\n+    httpServer.listen(listenFuture);\n+    vertx.getOrCreateContext().exceptionHandler(ServerUtils::handleException);\n+  }\n+\n+  @Override\n+  public void stop(final Promise<Void> stopPromise) {\n+    if (httpServer == null) {\n+      stopPromise.complete();\n+    } else {\n+      httpServer.close(stopPromise.future());\n+    }\n+  }\n+\n+  private Router setupRouter() {\n+    Router router = Router.router(vertx);\n+    router.route(HttpMethod.POST, \"/query-stream\").handler(BodyHandler.create())\n+        .handler(this::handleQueryStream);\n+    router.route(HttpMethod.POST, \"/inserts-stream\").handler(this::handleInsertsStream);\n+    router.route(HttpMethod.POST, \"/close-query\").handler(BodyHandler.create())\n+        .handler(this::handleCloseQuery);\n+    return router;\n+  }\n+\n+  private void handleInsertsStream(final RoutingContext routingContext) {\n+    RecordParser recordParser = RecordParser\n+        .newDelimited(\"\\n\", new InsertsBodyParser(endpoints, routingContext)::handleBodyBuffer);\n+    routingContext.request()\n+        .handler(recordParser);\n+  }\n+\n+  private void handleQueryStream(final RoutingContext routingContext) {\n+    HttpConnection conn = routingContext.request().connection();\n+    ConnectionQueries connectionQueries = connectionsMap.get(conn);\n+    if (connectionQueries == null) {\n+      connectionQueries = new ConnectionQueries(conn);\n+      connectionsMap.put(conn, connectionQueries);\n+      conn.closeHandler(connectionQueries);\n+      server.registerQueryConnection(conn);\n+    }\n+    JsonObject requestBody = routingContext.getBodyAsJson();\n+    String sql = requestBody.getString(\"sql\");\n+    if (sql == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No sql in arguments\");\n+      return;\n+    }\n+    Boolean push = requestBody.getBoolean(\"push\");\n+    if (push == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No push in arguments\");\n+      return;\n+    }\n+    JsonObject properties = requestBody.getJsonObject(\"properties\");\n+    QueryPublisher queryPublisher = endpoints.createQueryPublisher(sql, push, properties);\n+    QuerySubscriber querySubscriber = new QuerySubscriber(routingContext.response());\n+\n+    String queryID = server.registerQuery(querySubscriber);\n+    connectionQueries.addQuery(queryID);\n+    JsonObject metadata = new JsonObject();\n+    metadata.put(\"column-names\", queryPublisher.getColumnNames());\n+    metadata.put(\"column-types\", queryPublisher.getColumnTypes());\n+    metadata.put(\"query-id\", queryID);\n+    if (!push) {\n+      metadata.put(\"row-count\", queryPublisher.getRowCount());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c40735e2be6944f3ccbb84adf34c0b4c64abd139"}, "originalPosition": 133}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQzODkxNjQ3", "url": "https://github.com/confluentinc/ksql/pull/4320#pullrequestreview-343891647", "createdAt": "2020-01-16T12:57:54Z", "commit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "state": "APPROVED", "comments": {"totalCount": 32, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMjo1Nzo1NVrOFeYeLg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xNlQxMzo1NzowM1rOFeaJ3g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwMjU0Mg==", "bodyText": "nit: null check params.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367402542", "createdAt": "2020-01-16T12:57:55Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "diffHunk": "@@ -0,0 +1,110 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerResponse;\n+import io.vertx.core.json.JsonObject;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * As the stream of inserts is processed by the back-end, it communicates success (or failure) of\n+ * each insert by sending a stream of acks back in the other direction. This class is the subscriber\n+ * which subscribes to that stream of acks and sends them back to the client. It's a reactive\n+ * streams subscriber so implements back pressure.\n+ */\n+public class AcksSubscriber implements Subscriber<Void> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n+  private static final int BATCH_SIZE = 4;\n+  private static final Buffer ACK_RESPONSE_LINE = new JsonObject().put(\"status\", \"ok\").toBuffer()\n+      .appendString(\"\\n\");\n+\n+  private final HttpServerResponse response;\n+  private Subscription subscription;\n+  private long tokens;\n+  private Long insertsSent;\n+  private long acksSent;\n+\n+  public AcksSubscriber(final HttpServerResponse response) {\n+    this.response = response;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwMjY3NA==", "bodyText": "nit: null check params.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367402674", "createdAt": "2020-01-16T12:58:11Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "diffHunk": "@@ -0,0 +1,110 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerResponse;\n+import io.vertx.core.json.JsonObject;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * As the stream of inserts is processed by the back-end, it communicates success (or failure) of\n+ * each insert by sending a stream of acks back in the other direction. This class is the subscriber\n+ * which subscribes to that stream of acks and sends them back to the client. It's a reactive\n+ * streams subscriber so implements back pressure.\n+ */\n+public class AcksSubscriber implements Subscriber<Void> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n+  private static final int BATCH_SIZE = 4;\n+  private static final Buffer ACK_RESPONSE_LINE = new JsonObject().put(\"status\", \"ok\").toBuffer()\n+      .appendString(\"\\n\");\n+\n+  private final HttpServerResponse response;\n+  private Subscription subscription;\n+  private long tokens;\n+  private Long insertsSent;\n+  private long acksSent;\n+\n+  public AcksSubscriber(final HttpServerResponse response) {\n+    this.response = response;\n+  }\n+\n+  @Override\n+  public synchronized void onSubscribe(final Subscription subscription) {\n+    if (this.subscription != null) {\n+      throw new IllegalStateException(\"Already subscribed\");\n+    }\n+    this.subscription = subscription;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwMzQxMg==", "bodyText": "nit: null check params.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367403412", "createdAt": "2020-01-16T12:59:54Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyParser.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.InsertsSubscriber;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.ext.web.RoutingContext;\n+\n+/**\n+ * This class handles the parsing of the request body for a stream of inserts. The user can send a\n+ * stream of inserts to the server by opening an HTTP2 request to the server at the appropriate uri\n+ * and POSTing a request. The request must contain an initial JSON object (encoded as UTF-8 text)\n+ * which contains the arguments for the request (e.g. the target to insert into, and whether acks\n+ * are wanted) This must be followed by a new line, and then followed by zero or more JSON objects\n+ * (also encoded as UTF-8 text) each representing a row to insert. The last JSON object must be\n+ * followed by a new-line.\n+ */\n+public class InsertsBodyParser {\n+\n+  private final Endpoints endpoints;\n+  private final RoutingContext routingContext;\n+  private boolean readArguments;\n+  private InsertsPublisher publisher;\n+  private long rowsReceived;\n+  private AcksSubscriber acksSubscriber;\n+\n+  public InsertsBodyParser(final Endpoints endpoints, final RoutingContext routingContext) {\n+    this.endpoints = endpoints;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwNDE4Ng==", "bodyText": "Could we deserialize the JSON in POJOs? I think this would make the code more readable and maintainable.  It's also self documenting on what's expected, i.e. users can dig into the code to see, or we can build the docs from the POJOs.\nWhat do you think?", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367404186", "createdAt": "2020-01-16T13:01:50Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyParser.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.InsertsSubscriber;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.ext.web.RoutingContext;\n+\n+/**\n+ * This class handles the parsing of the request body for a stream of inserts. The user can send a\n+ * stream of inserts to the server by opening an HTTP2 request to the server at the appropriate uri\n+ * and POSTing a request. The request must contain an initial JSON object (encoded as UTF-8 text)\n+ * which contains the arguments for the request (e.g. the target to insert into, and whether acks\n+ * are wanted) This must be followed by a new line, and then followed by zero or more JSON objects\n+ * (also encoded as UTF-8 text) each representing a row to insert. The last JSON object must be\n+ * followed by a new-line.\n+ */\n+public class InsertsBodyParser {\n+\n+  private final Endpoints endpoints;\n+  private final RoutingContext routingContext;\n+  private boolean readArguments;\n+  private InsertsPublisher publisher;\n+  private long rowsReceived;\n+  private AcksSubscriber acksSubscriber;\n+\n+  public InsertsBodyParser(final Endpoints endpoints, final RoutingContext routingContext) {\n+    this.endpoints = endpoints;\n+    this.routingContext = routingContext;\n+    routingContext.response().endHandler(v -> {\n+      if (publisher != null) {\n+        publisher.close();\n+      }\n+    });\n+  }\n+\n+  public void handleBodyEnd(final Void v) {\n+    if (acksSubscriber == null) {\n+      routingContext.response().end();\n+    } else {\n+      // We close the response after the stream of acks has been sent\n+      acksSubscriber.insertsSent(rowsReceived);\n+    }\n+  }\n+\n+  public void handleBodyBuffer(final Buffer buff) {\n+    if (!readArguments) {\n+      JsonObject args = new JsonObject(buff);\n+      readArguments = true;\n+      String target = args.getString(\"target\");\n+      if (target == null) {\n+        handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM,\n+            \"No target in arguments\");\n+        return;\n+      }\n+      Boolean acks = args.getBoolean(\"acks\");\n+      if (acks == null) {\n+        handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM,\n+            \"No acks in arguments\");\n+        return;\n+      }\n+      JsonObject properties = args.getJsonObject(\"properties\");\n+      routingContext.request().endHandler(this::handleBodyEnd);\n+      acksSubscriber = acks ? new AcksSubscriber(routingContext.response()) : null;\n+      InsertsSubscriber insertsSubscriber = endpoints\n+          .createInsertsSubscriber(target, properties, acksSubscriber);\n+      publisher = new InsertsPublisher();\n+      publisher.subscribe(insertsSubscriber);\n+    } else if (publisher != null) {\n+      JsonObject row = new JsonObject(buff);\n+      publisher.receiveRow(row);\n+      rowsReceived++;\n+    }\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 92}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwNDY2Mw==", "bodyText": "nit: null checks", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367404663", "createdAt": "2020-01-16T13:02:58Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsPublisher.java", "diffHunk": "@@ -0,0 +1,82 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.json.JsonObject;\n+import java.util.LinkedList;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+\n+/**\n+ * This class is a reactive streams publisher which publishes the inserts to a subscriber which is\n+ * provided by the back-end. As it's reactive streams it supports back pressure.\n+ */\n+public class InsertsPublisher implements Publisher<JsonObject> {\n+\n+  private final Queue<JsonObject> buffer = new LinkedList<>();\n+  private long demand;\n+  private Subscriber<? super JsonObject> subscriber;\n+\n+  @Override\n+  public void subscribe(final Subscriber<? super JsonObject> subscriber) {\n+    this.subscriber = subscriber;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwNTEwMQ==", "bodyText": "nit: make private?", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367405101", "createdAt": "2020-01-16T13:04:08Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsPublisher.java", "diffHunk": "@@ -0,0 +1,82 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.json.JsonObject;\n+import java.util.LinkedList;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+\n+/**\n+ * This class is a reactive streams publisher which publishes the inserts to a subscriber which is\n+ * provided by the back-end. As it's reactive streams it supports back pressure.\n+ */\n+public class InsertsPublisher implements Publisher<JsonObject> {\n+\n+  private final Queue<JsonObject> buffer = new LinkedList<>();\n+  private long demand;\n+  private Subscriber<? super JsonObject> subscriber;\n+\n+  @Override\n+  public void subscribe(final Subscriber<? super JsonObject> subscriber) {\n+    this.subscriber = subscriber;\n+    subscriber.onSubscribe(new InsertsSubscription());\n+  }\n+\n+  public synchronized void receiveRow(final JsonObject row) {\n+    if (subscriber == null) {\n+      return;\n+    }\n+    if (demand > 0) {\n+      demand--;\n+      subscriber.onNext(row);\n+    } else {\n+      buffer.add(row);\n+    }\n+  }\n+\n+  synchronized void acceptTokens(final long number) {\n+    demand += number;\n+    for (int i = 0; i < buffer.size(); i++) {\n+      JsonObject row = buffer.poll();\n+      demand--;\n+      subscriber.onNext(row);\n+    }\n+  }\n+\n+  synchronized void close() {\n+    subscriber.onComplete();\n+    subscriber = null;\n+  }\n+\n+  class InsertsSubscription implements Subscription {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwNTI1Mw==", "bodyText": "nit: null check.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367405253", "createdAt": "2020-01-16T13:04:32Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/QuerySubscriber.java", "diffHunk": "@@ -0,0 +1,95 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+\n+import io.vertx.core.http.HttpServerResponse;\n+import io.vertx.core.json.JsonArray;\n+import io.vertx.core.json.JsonObject;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This is a reactive streams subscriber which receives a stream of results from a publisher which\n+ * is implemented by the back-end. The results are then written to the HTTP2 response.\n+ */\n+public class QuerySubscriber implements Subscriber<JsonArray> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(QuerySubscriber.class);\n+\n+  private final HttpServerResponse response;\n+  private Subscription subscription;\n+  private long tokens;\n+\n+  private static final int BATCH_SIZE = 4;\n+\n+  public QuerySubscriber(final HttpServerResponse response) {\n+    this.response = response;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwNTI5Nw==", "bodyText": "nit: null check.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367405297", "createdAt": "2020-01-16T13:04:40Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/QuerySubscriber.java", "diffHunk": "@@ -0,0 +1,95 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+\n+import io.vertx.core.http.HttpServerResponse;\n+import io.vertx.core.json.JsonArray;\n+import io.vertx.core.json.JsonObject;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This is a reactive streams subscriber which receives a stream of results from a publisher which\n+ * is implemented by the back-end. The results are then written to the HTTP2 response.\n+ */\n+public class QuerySubscriber implements Subscriber<JsonArray> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(QuerySubscriber.class);\n+\n+  private final HttpServerResponse response;\n+  private Subscription subscription;\n+  private long tokens;\n+\n+  private static final int BATCH_SIZE = 4;\n+\n+  public QuerySubscriber(final HttpServerResponse response) {\n+    this.response = response;\n+  }\n+\n+  @Override\n+  public synchronized void onSubscribe(final Subscription subscription) {\n+    if (this.subscription != null) {\n+      throw new IllegalStateException(\"Already subscribed\");\n+    }\n+    this.subscription = subscription;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwNTY1NA==", "bodyText": "nit: null checks", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367405654", "createdAt": "2020-01-16T13:05:33Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.vertx.core.DeploymentOptions;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.impl.ConcurrentHashSet;\n+import io.vertx.core.json.JsonObject;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class represents the API server. On start-up it deploys multiple server verticles to spread\n+ * the load across available cores.\n+ */\n+public class Server {\n+\n+  private static final Logger log = LoggerFactory.getLogger(Server.class);\n+\n+  private final Vertx vertx;\n+  private final JsonObject config;\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Map<String, QuerySubscriber> queries = new ConcurrentHashMap<>();\n+  private final Set<HttpConnection> connections = new ConcurrentHashSet<>();\n+  private String deploymentID;\n+\n+  public Server(final Vertx vertx, final JsonObject config, final Endpoints endpoints,\n+      final HttpServerOptions httpServerOptions) {\n+    this.vertx = vertx;\n+    this.config = config;\n+    this.endpoints = endpoints;\n+    this.httpServerOptions = httpServerOptions;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwNjQxMg==", "bodyText": "We generally use AbstractConfig as a base for config classes, as this provides a fair amount of functionality that can be useful, including defining validators and defaults: which keeps the calling code a lot cleaner.\nIn the future, we can also generate the docs from the config class.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367406412", "createdAt": "2020-01-16T13:07:20Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.vertx.core.DeploymentOptions;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.impl.ConcurrentHashSet;\n+import io.vertx.core.json.JsonObject;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class represents the API server. On start-up it deploys multiple server verticles to spread\n+ * the load across available cores.\n+ */\n+public class Server {\n+\n+  private static final Logger log = LoggerFactory.getLogger(Server.class);\n+\n+  private final Vertx vertx;\n+  private final JsonObject config;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwNzUxNg==", "bodyText": "Consider throwing a more specific exception type, e.g. KsqlServerException, and include more info, e.g. \"Failed to start server\".", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367407516", "createdAt": "2020-01-16T13:09:56Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.vertx.core.DeploymentOptions;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.impl.ConcurrentHashSet;\n+import io.vertx.core.json.JsonObject;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class represents the API server. On start-up it deploys multiple server verticles to spread\n+ * the load across available cores.\n+ */\n+public class Server {\n+\n+  private static final Logger log = LoggerFactory.getLogger(Server.class);\n+\n+  private final Vertx vertx;\n+  private final JsonObject config;\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Map<String, QuerySubscriber> queries = new ConcurrentHashMap<>();\n+  private final Set<HttpConnection> connections = new ConcurrentHashSet<>();\n+  private String deploymentID;\n+\n+  public Server(final Vertx vertx, final JsonObject config, final Endpoints endpoints,\n+      final HttpServerOptions httpServerOptions) {\n+    this.vertx = vertx;\n+    this.config = config;\n+    this.endpoints = endpoints;\n+    this.httpServerOptions = httpServerOptions;\n+  }\n+\n+  public synchronized void start() {\n+    if (deploymentID != null) {\n+      throw new IllegalStateException(\"Already started\");\n+    }\n+    DeploymentOptions options = new DeploymentOptions();\n+    Integer verticleInstances = config.getInteger(\"verticle-instances\");\n+    if (verticleInstances == null) {\n+      options.setInstances(Runtime.getRuntime().availableProcessors() * 2);\n+    } else {\n+      options.setInstances(verticleInstances);\n+    }\n+    log.info(\"Deploying \" + options.getInstances() + \" instances of server verticle\");\n+    options.setConfig(config);\n+    VertxCompletableFuture<String> future = new VertxCompletableFuture<>();\n+    vertx.deployVerticle(\n+        () -> new ServerVerticle(endpoints, httpServerOptions, this), options, future);\n+    try {\n+      deploymentID = future.get();\n+    } catch (Exception e) {\n+      throw new RuntimeException(e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwNzY5MA==", "bodyText": "Consider throwing a more specific exception type, e.g. KsqlServerException, and include more info, e.g. \"failed to stop server\".", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367407690", "createdAt": "2020-01-16T13:10:18Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.vertx.core.DeploymentOptions;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.impl.ConcurrentHashSet;\n+import io.vertx.core.json.JsonObject;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class represents the API server. On start-up it deploys multiple server verticles to spread\n+ * the load across available cores.\n+ */\n+public class Server {\n+\n+  private static final Logger log = LoggerFactory.getLogger(Server.class);\n+\n+  private final Vertx vertx;\n+  private final JsonObject config;\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Map<String, QuerySubscriber> queries = new ConcurrentHashMap<>();\n+  private final Set<HttpConnection> connections = new ConcurrentHashSet<>();\n+  private String deploymentID;\n+\n+  public Server(final Vertx vertx, final JsonObject config, final Endpoints endpoints,\n+      final HttpServerOptions httpServerOptions) {\n+    this.vertx = vertx;\n+    this.config = config;\n+    this.endpoints = endpoints;\n+    this.httpServerOptions = httpServerOptions;\n+  }\n+\n+  public synchronized void start() {\n+    if (deploymentID != null) {\n+      throw new IllegalStateException(\"Already started\");\n+    }\n+    DeploymentOptions options = new DeploymentOptions();\n+    Integer verticleInstances = config.getInteger(\"verticle-instances\");\n+    if (verticleInstances == null) {\n+      options.setInstances(Runtime.getRuntime().availableProcessors() * 2);\n+    } else {\n+      options.setInstances(verticleInstances);\n+    }\n+    log.info(\"Deploying \" + options.getInstances() + \" instances of server verticle\");\n+    options.setConfig(config);\n+    VertxCompletableFuture<String> future = new VertxCompletableFuture<>();\n+    vertx.deployVerticle(\n+        () -> new ServerVerticle(endpoints, httpServerOptions, this), options, future);\n+    try {\n+      deploymentID = future.get();\n+    } catch (Exception e) {\n+      throw new RuntimeException(e);\n+    }\n+    log.info(\"API server started: \" + deploymentID);\n+  }\n+\n+  public synchronized void stop() {\n+    if (deploymentID == null) {\n+      throw new IllegalStateException(\"Not started\");\n+    }\n+    VertxCompletableFuture<Void> future = new VertxCompletableFuture<>();\n+    vertx.undeploy(deploymentID, future);\n+    try {\n+      future.get();\n+    } catch (Exception e) {\n+      throw new RuntimeException(e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwODA3Mg==", "bodyText": "nit: null check state.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367408072", "createdAt": "2020-01-16T13:11:08Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.vertx.core.DeploymentOptions;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.impl.ConcurrentHashSet;\n+import io.vertx.core.json.JsonObject;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class represents the API server. On start-up it deploys multiple server verticles to spread\n+ * the load across available cores.\n+ */\n+public class Server {\n+\n+  private static final Logger log = LoggerFactory.getLogger(Server.class);\n+\n+  private final Vertx vertx;\n+  private final JsonObject config;\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Map<String, QuerySubscriber> queries = new ConcurrentHashMap<>();\n+  private final Set<HttpConnection> connections = new ConcurrentHashSet<>();\n+  private String deploymentID;\n+\n+  public Server(final Vertx vertx, final JsonObject config, final Endpoints endpoints,\n+      final HttpServerOptions httpServerOptions) {\n+    this.vertx = vertx;\n+    this.config = config;\n+    this.endpoints = endpoints;\n+    this.httpServerOptions = httpServerOptions;\n+  }\n+\n+  public synchronized void start() {\n+    if (deploymentID != null) {\n+      throw new IllegalStateException(\"Already started\");\n+    }\n+    DeploymentOptions options = new DeploymentOptions();\n+    Integer verticleInstances = config.getInteger(\"verticle-instances\");\n+    if (verticleInstances == null) {\n+      options.setInstances(Runtime.getRuntime().availableProcessors() * 2);\n+    } else {\n+      options.setInstances(verticleInstances);\n+    }\n+    log.info(\"Deploying \" + options.getInstances() + \" instances of server verticle\");\n+    options.setConfig(config);\n+    VertxCompletableFuture<String> future = new VertxCompletableFuture<>();\n+    vertx.deployVerticle(\n+        () -> new ServerVerticle(endpoints, httpServerOptions, this), options, future);\n+    try {\n+      deploymentID = future.get();\n+    } catch (Exception e) {\n+      throw new RuntimeException(e);\n+    }\n+    log.info(\"API server started: \" + deploymentID);\n+  }\n+\n+  public synchronized void stop() {\n+    if (deploymentID == null) {\n+      throw new IllegalStateException(\"Not started\");\n+    }\n+    VertxCompletableFuture<Void> future = new VertxCompletableFuture<>();\n+    vertx.undeploy(deploymentID, future);\n+    try {\n+      future.get();\n+    } catch (Exception e) {\n+      throw new RuntimeException(e);\n+    }\n+  }\n+\n+  String registerQuery(final QuerySubscriber querySubscriber) {\n+    String uuid = UUID.randomUUID().toString();\n+    queries.put(uuid, querySubscriber);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwODE4MA==", "bodyText": "nit: null check state.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367408180", "createdAt": "2020-01-16T13:11:22Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "diffHunk": "@@ -0,0 +1,121 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.vertx.core.DeploymentOptions;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.impl.ConcurrentHashSet;\n+import io.vertx.core.json.JsonObject;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class represents the API server. On start-up it deploys multiple server verticles to spread\n+ * the load across available cores.\n+ */\n+public class Server {\n+\n+  private static final Logger log = LoggerFactory.getLogger(Server.class);\n+\n+  private final Vertx vertx;\n+  private final JsonObject config;\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Map<String, QuerySubscriber> queries = new ConcurrentHashMap<>();\n+  private final Set<HttpConnection> connections = new ConcurrentHashSet<>();\n+  private String deploymentID;\n+\n+  public Server(final Vertx vertx, final JsonObject config, final Endpoints endpoints,\n+      final HttpServerOptions httpServerOptions) {\n+    this.vertx = vertx;\n+    this.config = config;\n+    this.endpoints = endpoints;\n+    this.httpServerOptions = httpServerOptions;\n+  }\n+\n+  public synchronized void start() {\n+    if (deploymentID != null) {\n+      throw new IllegalStateException(\"Already started\");\n+    }\n+    DeploymentOptions options = new DeploymentOptions();\n+    Integer verticleInstances = config.getInteger(\"verticle-instances\");\n+    if (verticleInstances == null) {\n+      options.setInstances(Runtime.getRuntime().availableProcessors() * 2);\n+    } else {\n+      options.setInstances(verticleInstances);\n+    }\n+    log.info(\"Deploying \" + options.getInstances() + \" instances of server verticle\");\n+    options.setConfig(config);\n+    VertxCompletableFuture<String> future = new VertxCompletableFuture<>();\n+    vertx.deployVerticle(\n+        () -> new ServerVerticle(endpoints, httpServerOptions, this), options, future);\n+    try {\n+      deploymentID = future.get();\n+    } catch (Exception e) {\n+      throw new RuntimeException(e);\n+    }\n+    log.info(\"API server started: \" + deploymentID);\n+  }\n+\n+  public synchronized void stop() {\n+    if (deploymentID == null) {\n+      throw new IllegalStateException(\"Not started\");\n+    }\n+    VertxCompletableFuture<Void> future = new VertxCompletableFuture<>();\n+    vertx.undeploy(deploymentID, future);\n+    try {\n+      future.get();\n+    } catch (Exception e) {\n+      throw new RuntimeException(e);\n+    }\n+  }\n+\n+  String registerQuery(final QuerySubscriber querySubscriber) {\n+    String uuid = UUID.randomUUID().toString();\n+    queries.put(uuid, querySubscriber);\n+    return uuid;\n+  }\n+\n+  QuerySubscriber removeQuery(final String queryID) {\n+    return queries.remove(queryID);\n+  }\n+\n+  public Set<String> getQueryIDs() {\n+    return new HashSet<>(queries.keySet());\n+  }\n+\n+  void registerQueryConnection(final HttpConnection connection) {\n+    this.connections.add(connection);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 110}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwODUzNg==", "bodyText": "As above, consider using a Pojo.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367408536", "createdAt": "2020-01-16T13:12:12Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerUtils.java", "diffHunk": "@@ -0,0 +1,41 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.http.HttpServerResponse;\n+import io.vertx.core.json.JsonObject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * static util methods used in the server\n+ */\n+public class ServerUtils {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ServerUtils.class);\n+\n+  public static void handleError(final HttpServerResponse response, final int statusCode,\n+      final int errorCode, final String errMsg) {\n+    JsonObject errResponse = new JsonObject().put(\"status\", \"error\").put(\"errorCode\", errorCode)\n+        .put(\"message\", errMsg);\n+    response.setStatusCode(statusCode).end(errResponse.toBuffer());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwODk1OQ==", "bodyText": "nit: Function name out of whack with impl, e.g. consider naming it unhandledExceptionHandler or logUnhandledExcpetion, or similar.\nOut of interest, when would this be called? / should this be called in normal operation?\nOr is this just WIP?", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367408959", "createdAt": "2020-01-16T13:13:07Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerUtils.java", "diffHunk": "@@ -0,0 +1,41 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.http.HttpServerResponse;\n+import io.vertx.core.json.JsonObject;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * static util methods used in the server\n+ */\n+public class ServerUtils {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ServerUtils.class);\n+\n+  public static void handleError(final HttpServerResponse response, final int statusCode,\n+      final int errorCode, final String errMsg) {\n+    JsonObject errResponse = new JsonObject().put(\"status\", \"error\").put(\"errorCode\", errorCode)\n+        .put(\"message\", errMsg);\n+    response.setStatusCode(statusCode).end(errResponse.toBuffer());\n+  }\n+\n+  public static void handleException(final Throwable t) {\n+    log.error(\"Unhandled exception\", t);\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQwOTY2Mg==", "bodyText": "nit: null checks.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367409662", "createdAt": "2020-01-16T13:14:47Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerVerticle.java", "diffHunk": "@@ -0,0 +1,201 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.impl.Utils;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.QueryPublisher;\n+import io.vertx.core.AbstractVerticle;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Promise;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpMethod;\n+import io.vertx.core.http.HttpServer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.parsetools.RecordParser;\n+import io.vertx.ext.web.Router;\n+import io.vertx.ext.web.RoutingContext;\n+import io.vertx.ext.web.handler.BodyHandler;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * The server deploys multiple server verticles. This is where the HTTP2 requests are handled. The\n+ * actual implementation of the endpoints is provided by an implementation of {@code Endpoints}.\n+ */\n+public class ServerVerticle extends AbstractVerticle {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ServerVerticle.class);\n+\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Server server;\n+  private final Map<HttpConnection, ConnectionQueries> connectionsMap = new HashMap<>();\n+  private HttpServer httpServer;\n+\n+  public ServerVerticle(final Endpoints endpoints, final HttpServerOptions httpServerOptions,\n+      final Server server) {\n+    this.endpoints = endpoints;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQxMDU1MQ==", "bodyText": "Can't say I'm a fan of Utils classes.  This has the risk it will just become a dumping ground for a load of unrelated methods.  Could we possibly have a more targeted name? e.g. ReactiveUtils ?", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367410551", "createdAt": "2020-01-16T13:16:46Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/impl/Utils.java", "diffHunk": "@@ -0,0 +1,37 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.impl;\n+\n+import io.vertx.core.Future;\n+import io.vertx.core.Promise;\n+\n+/**\n+ * General purpose utils (not limited to the server, could be used by client too) for the API\n+ * module.\n+ */\n+public class Utils {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQxMTYyNQ==", "bodyText": "Again, can we use Pojo's to avoid this manual / inline handling and validation of Json, please?", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367411625", "createdAt": "2020-01-16T13:19:12Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerVerticle.java", "diffHunk": "@@ -0,0 +1,201 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.impl.Utils;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.QueryPublisher;\n+import io.vertx.core.AbstractVerticle;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Promise;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpMethod;\n+import io.vertx.core.http.HttpServer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.parsetools.RecordParser;\n+import io.vertx.ext.web.Router;\n+import io.vertx.ext.web.RoutingContext;\n+import io.vertx.ext.web.handler.BodyHandler;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * The server deploys multiple server verticles. This is where the HTTP2 requests are handled. The\n+ * actual implementation of the endpoints is provided by an implementation of {@code Endpoints}.\n+ */\n+public class ServerVerticle extends AbstractVerticle {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ServerVerticle.class);\n+\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Server server;\n+  private final Map<HttpConnection, ConnectionQueries> connectionsMap = new HashMap<>();\n+  private HttpServer httpServer;\n+\n+  public ServerVerticle(final Endpoints endpoints, final HttpServerOptions httpServerOptions,\n+      final Server server) {\n+    this.endpoints = endpoints;\n+    this.httpServerOptions = httpServerOptions;\n+    this.server = server;\n+  }\n+\n+  @Override\n+  public void start(final Promise<Void> startPromise) {\n+    httpServer = vertx.createHttpServer(httpServerOptions).requestHandler(setupRouter())\n+        .exceptionHandler(ServerUtils::handleException);\n+    Future<HttpServer> listenFuture = Promise.<HttpServer>promise().future();\n+    Utils.connectPromise(listenFuture.map(s -> null), startPromise);\n+    httpServer.listen(listenFuture);\n+    vertx.getOrCreateContext().exceptionHandler(ServerUtils::handleException);\n+  }\n+\n+  @Override\n+  public void stop(final Promise<Void> stopPromise) {\n+    if (httpServer == null) {\n+      stopPromise.complete();\n+    } else {\n+      httpServer.close(stopPromise.future());\n+    }\n+  }\n+\n+  private Router setupRouter() {\n+    Router router = Router.router(vertx);\n+    router.route(HttpMethod.POST, \"/query-stream\").handler(BodyHandler.create())\n+        .handler(this::handleQueryStream);\n+    router.route(HttpMethod.POST, \"/inserts-stream\").handler(this::handleInsertsStream);\n+    router.route(HttpMethod.POST, \"/close-query\").handler(BodyHandler.create())\n+        .handler(this::handleCloseQuery);\n+    return router;\n+  }\n+\n+  private void handleInsertsStream(final RoutingContext routingContext) {\n+    RecordParser recordParser = RecordParser\n+        .newDelimited(\"\\n\", new InsertsBodyParser(endpoints, routingContext)::handleBodyBuffer);\n+    routingContext.request()\n+        .handler(recordParser);\n+  }\n+\n+  private void handleQueryStream(final RoutingContext routingContext) {\n+    HttpConnection conn = routingContext.request().connection();\n+    ConnectionQueries connectionQueries = connectionsMap.get(conn);\n+    if (connectionQueries == null) {\n+      connectionQueries = new ConnectionQueries(conn);\n+      connectionsMap.put(conn, connectionQueries);\n+      conn.closeHandler(connectionQueries);\n+      server.registerQueryConnection(conn);\n+    }\n+    JsonObject requestBody = routingContext.getBodyAsJson();\n+    String sql = requestBody.getString(\"sql\");\n+    if (sql == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No sql in arguments\");\n+      return;\n+    }\n+    Boolean push = requestBody.getBoolean(\"push\");\n+    if (push == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No push in arguments\");\n+      return;\n+    }\n+    JsonObject properties = requestBody.getJsonObject(\"properties\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 122}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQxMjIxMw==", "bodyText": "Is this queryId the same as our QueryId class that is used to identify queries?  If it is, can we use the more strongly typed QueryId class?\nIf its not... maybe use a different type to differentiate and avoid confusion?", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367412213", "createdAt": "2020-01-16T13:20:31Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerVerticle.java", "diffHunk": "@@ -0,0 +1,201 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.impl.Utils;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.QueryPublisher;\n+import io.vertx.core.AbstractVerticle;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Promise;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpMethod;\n+import io.vertx.core.http.HttpServer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.parsetools.RecordParser;\n+import io.vertx.ext.web.Router;\n+import io.vertx.ext.web.RoutingContext;\n+import io.vertx.ext.web.handler.BodyHandler;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * The server deploys multiple server verticles. This is where the HTTP2 requests are handled. The\n+ * actual implementation of the endpoints is provided by an implementation of {@code Endpoints}.\n+ */\n+public class ServerVerticle extends AbstractVerticle {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ServerVerticle.class);\n+\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Server server;\n+  private final Map<HttpConnection, ConnectionQueries> connectionsMap = new HashMap<>();\n+  private HttpServer httpServer;\n+\n+  public ServerVerticle(final Endpoints endpoints, final HttpServerOptions httpServerOptions,\n+      final Server server) {\n+    this.endpoints = endpoints;\n+    this.httpServerOptions = httpServerOptions;\n+    this.server = server;\n+  }\n+\n+  @Override\n+  public void start(final Promise<Void> startPromise) {\n+    httpServer = vertx.createHttpServer(httpServerOptions).requestHandler(setupRouter())\n+        .exceptionHandler(ServerUtils::handleException);\n+    Future<HttpServer> listenFuture = Promise.<HttpServer>promise().future();\n+    Utils.connectPromise(listenFuture.map(s -> null), startPromise);\n+    httpServer.listen(listenFuture);\n+    vertx.getOrCreateContext().exceptionHandler(ServerUtils::handleException);\n+  }\n+\n+  @Override\n+  public void stop(final Promise<Void> stopPromise) {\n+    if (httpServer == null) {\n+      stopPromise.complete();\n+    } else {\n+      httpServer.close(stopPromise.future());\n+    }\n+  }\n+\n+  private Router setupRouter() {\n+    Router router = Router.router(vertx);\n+    router.route(HttpMethod.POST, \"/query-stream\").handler(BodyHandler.create())\n+        .handler(this::handleQueryStream);\n+    router.route(HttpMethod.POST, \"/inserts-stream\").handler(this::handleInsertsStream);\n+    router.route(HttpMethod.POST, \"/close-query\").handler(BodyHandler.create())\n+        .handler(this::handleCloseQuery);\n+    return router;\n+  }\n+\n+  private void handleInsertsStream(final RoutingContext routingContext) {\n+    RecordParser recordParser = RecordParser\n+        .newDelimited(\"\\n\", new InsertsBodyParser(endpoints, routingContext)::handleBodyBuffer);\n+    routingContext.request()\n+        .handler(recordParser);\n+  }\n+\n+  private void handleQueryStream(final RoutingContext routingContext) {\n+    HttpConnection conn = routingContext.request().connection();\n+    ConnectionQueries connectionQueries = connectionsMap.get(conn);\n+    if (connectionQueries == null) {\n+      connectionQueries = new ConnectionQueries(conn);\n+      connectionsMap.put(conn, connectionQueries);\n+      conn.closeHandler(connectionQueries);\n+      server.registerQueryConnection(conn);\n+    }\n+    JsonObject requestBody = routingContext.getBodyAsJson();\n+    String sql = requestBody.getString(\"sql\");\n+    if (sql == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No sql in arguments\");\n+      return;\n+    }\n+    Boolean push = requestBody.getBoolean(\"push\");\n+    if (push == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No push in arguments\");\n+      return;\n+    }\n+    JsonObject properties = requestBody.getJsonObject(\"properties\");\n+    QueryPublisher queryPublisher = endpoints.createQueryPublisher(sql, push, properties);\n+    QuerySubscriber querySubscriber = new QuerySubscriber(routingContext.response());\n+\n+    String queryID = server.registerQuery(querySubscriber);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 126}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQxMjMwNA==", "bodyText": "Replace with Pojo?", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367412304", "createdAt": "2020-01-16T13:20:43Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerVerticle.java", "diffHunk": "@@ -0,0 +1,201 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.impl.Utils;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.QueryPublisher;\n+import io.vertx.core.AbstractVerticle;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Promise;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpMethod;\n+import io.vertx.core.http.HttpServer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.parsetools.RecordParser;\n+import io.vertx.ext.web.Router;\n+import io.vertx.ext.web.RoutingContext;\n+import io.vertx.ext.web.handler.BodyHandler;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * The server deploys multiple server verticles. This is where the HTTP2 requests are handled. The\n+ * actual implementation of the endpoints is provided by an implementation of {@code Endpoints}.\n+ */\n+public class ServerVerticle extends AbstractVerticle {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ServerVerticle.class);\n+\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Server server;\n+  private final Map<HttpConnection, ConnectionQueries> connectionsMap = new HashMap<>();\n+  private HttpServer httpServer;\n+\n+  public ServerVerticle(final Endpoints endpoints, final HttpServerOptions httpServerOptions,\n+      final Server server) {\n+    this.endpoints = endpoints;\n+    this.httpServerOptions = httpServerOptions;\n+    this.server = server;\n+  }\n+\n+  @Override\n+  public void start(final Promise<Void> startPromise) {\n+    httpServer = vertx.createHttpServer(httpServerOptions).requestHandler(setupRouter())\n+        .exceptionHandler(ServerUtils::handleException);\n+    Future<HttpServer> listenFuture = Promise.<HttpServer>promise().future();\n+    Utils.connectPromise(listenFuture.map(s -> null), startPromise);\n+    httpServer.listen(listenFuture);\n+    vertx.getOrCreateContext().exceptionHandler(ServerUtils::handleException);\n+  }\n+\n+  @Override\n+  public void stop(final Promise<Void> stopPromise) {\n+    if (httpServer == null) {\n+      stopPromise.complete();\n+    } else {\n+      httpServer.close(stopPromise.future());\n+    }\n+  }\n+\n+  private Router setupRouter() {\n+    Router router = Router.router(vertx);\n+    router.route(HttpMethod.POST, \"/query-stream\").handler(BodyHandler.create())\n+        .handler(this::handleQueryStream);\n+    router.route(HttpMethod.POST, \"/inserts-stream\").handler(this::handleInsertsStream);\n+    router.route(HttpMethod.POST, \"/close-query\").handler(BodyHandler.create())\n+        .handler(this::handleCloseQuery);\n+    return router;\n+  }\n+\n+  private void handleInsertsStream(final RoutingContext routingContext) {\n+    RecordParser recordParser = RecordParser\n+        .newDelimited(\"\\n\", new InsertsBodyParser(endpoints, routingContext)::handleBodyBuffer);\n+    routingContext.request()\n+        .handler(recordParser);\n+  }\n+\n+  private void handleQueryStream(final RoutingContext routingContext) {\n+    HttpConnection conn = routingContext.request().connection();\n+    ConnectionQueries connectionQueries = connectionsMap.get(conn);\n+    if (connectionQueries == null) {\n+      connectionQueries = new ConnectionQueries(conn);\n+      connectionsMap.put(conn, connectionQueries);\n+      conn.closeHandler(connectionQueries);\n+      server.registerQueryConnection(conn);\n+    }\n+    JsonObject requestBody = routingContext.getBodyAsJson();\n+    String sql = requestBody.getString(\"sql\");\n+    if (sql == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No sql in arguments\");\n+      return;\n+    }\n+    Boolean push = requestBody.getBoolean(\"push\");\n+    if (push == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No push in arguments\");\n+      return;\n+    }\n+    JsonObject properties = requestBody.getJsonObject(\"properties\");\n+    QueryPublisher queryPublisher = endpoints.createQueryPublisher(sql, push, properties);\n+    QuerySubscriber querySubscriber = new QuerySubscriber(routingContext.response());\n+\n+    String queryID = server.registerQuery(querySubscriber);\n+    connectionQueries.addQuery(queryID);\n+    JsonObject metadata = new JsonObject();\n+    metadata.put(\"columnNames\", queryPublisher.getColumnNames());\n+    metadata.put(\"columnTypes\", queryPublisher.getColumnTypes());\n+    metadata.put(\"queryID\", queryID);\n+    if (!push) {\n+      metadata.put(\"rowCount\", queryPublisher.getRowCount());\n+    }\n+    routingContext.response().write(metadata.toBuffer()).write(\"\\n\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 135}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQxMjYxNA==", "bodyText": "out of interest, what does returning false actually mean?", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367412614", "createdAt": "2020-01-16T13:21:27Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerVerticle.java", "diffHunk": "@@ -0,0 +1,201 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.impl.Utils;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.QueryPublisher;\n+import io.vertx.core.AbstractVerticle;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Promise;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpMethod;\n+import io.vertx.core.http.HttpServer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.parsetools.RecordParser;\n+import io.vertx.ext.web.Router;\n+import io.vertx.ext.web.RoutingContext;\n+import io.vertx.ext.web.handler.BodyHandler;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * The server deploys multiple server verticles. This is where the HTTP2 requests are handled. The\n+ * actual implementation of the endpoints is provided by an implementation of {@code Endpoints}.\n+ */\n+public class ServerVerticle extends AbstractVerticle {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ServerVerticle.class);\n+\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Server server;\n+  private final Map<HttpConnection, ConnectionQueries> connectionsMap = new HashMap<>();\n+  private HttpServer httpServer;\n+\n+  public ServerVerticle(final Endpoints endpoints, final HttpServerOptions httpServerOptions,\n+      final Server server) {\n+    this.endpoints = endpoints;\n+    this.httpServerOptions = httpServerOptions;\n+    this.server = server;\n+  }\n+\n+  @Override\n+  public void start(final Promise<Void> startPromise) {\n+    httpServer = vertx.createHttpServer(httpServerOptions).requestHandler(setupRouter())\n+        .exceptionHandler(ServerUtils::handleException);\n+    Future<HttpServer> listenFuture = Promise.<HttpServer>promise().future();\n+    Utils.connectPromise(listenFuture.map(s -> null), startPromise);\n+    httpServer.listen(listenFuture);\n+    vertx.getOrCreateContext().exceptionHandler(ServerUtils::handleException);\n+  }\n+\n+  @Override\n+  public void stop(final Promise<Void> stopPromise) {\n+    if (httpServer == null) {\n+      stopPromise.complete();\n+    } else {\n+      httpServer.close(stopPromise.future());\n+    }\n+  }\n+\n+  private Router setupRouter() {\n+    Router router = Router.router(vertx);\n+    router.route(HttpMethod.POST, \"/query-stream\").handler(BodyHandler.create())\n+        .handler(this::handleQueryStream);\n+    router.route(HttpMethod.POST, \"/inserts-stream\").handler(this::handleInsertsStream);\n+    router.route(HttpMethod.POST, \"/close-query\").handler(BodyHandler.create())\n+        .handler(this::handleCloseQuery);\n+    return router;\n+  }\n+\n+  private void handleInsertsStream(final RoutingContext routingContext) {\n+    RecordParser recordParser = RecordParser\n+        .newDelimited(\"\\n\", new InsertsBodyParser(endpoints, routingContext)::handleBodyBuffer);\n+    routingContext.request()\n+        .handler(recordParser);\n+  }\n+\n+  private void handleQueryStream(final RoutingContext routingContext) {\n+    HttpConnection conn = routingContext.request().connection();\n+    ConnectionQueries connectionQueries = connectionsMap.get(conn);\n+    if (connectionQueries == null) {\n+      connectionQueries = new ConnectionQueries(conn);\n+      connectionsMap.put(conn, connectionQueries);\n+      conn.closeHandler(connectionQueries);\n+      server.registerQueryConnection(conn);\n+    }\n+    JsonObject requestBody = routingContext.getBodyAsJson();\n+    String sql = requestBody.getString(\"sql\");\n+    if (sql == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No sql in arguments\");\n+      return;\n+    }\n+    Boolean push = requestBody.getBoolean(\"push\");\n+    if (push == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No push in arguments\");\n+      return;\n+    }\n+    JsonObject properties = requestBody.getJsonObject(\"properties\");\n+    QueryPublisher queryPublisher = endpoints.createQueryPublisher(sql, push, properties);\n+    QuerySubscriber querySubscriber = new QuerySubscriber(routingContext.response());\n+\n+    String queryID = server.registerQuery(querySubscriber);\n+    connectionQueries.addQuery(queryID);\n+    JsonObject metadata = new JsonObject();\n+    metadata.put(\"columnNames\", queryPublisher.getColumnNames());\n+    metadata.put(\"columnTypes\", queryPublisher.getColumnTypes());\n+    metadata.put(\"queryID\", queryID);\n+    if (!push) {\n+      metadata.put(\"rowCount\", queryPublisher.getRowCount());\n+    }\n+    routingContext.response().write(metadata.toBuffer()).write(\"\\n\");\n+    queryPublisher.subscribe(querySubscriber);\n+\n+    // When response is complete, publisher should be closed and query unregistered\n+    routingContext.response().endHandler(v -> closeQuery(queryID, routingContext));\n+  }\n+\n+  private boolean closeQuery(final String queryID, final RoutingContext routingContext) {\n+    QuerySubscriber querySubscriber = server.removeQuery(queryID);\n+    if (querySubscriber == null) {\n+      return false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 145}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQxMzgxMA==", "bodyText": "Might benefit from some javadocs explain the params.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367413810", "createdAt": "2020-01-16T13:24:05Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/spi/Endpoints.java", "diffHunk": "@@ -0,0 +1,33 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.spi;\n+\n+import io.vertx.core.json.JsonObject;\n+import org.reactivestreams.Subscriber;\n+\n+/**\n+ * In order to keep a clean separation between the plumbing of the API server and actual back-end\n+ * implementation of the endpoints we define this interface to encapsulate the actual endpoint\n+ * implementation.\n+ */\n+public interface Endpoints {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQxNTU3OA==", "bodyText": "Are you up for adopting the Given/When/Then that everyone else in the team uses?  It can help really spell out what is setup, what is the exact bit under test, and what is expected outcome.  You've already added blank lines to separate by the looks of it, e.g. this test would become:\n@Test\n  public void shouldExecutePullQuery() throws Exception {\n    // Given:\n    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", false);\n    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n    requestBody.put(\"properties\", properties);\n\n    // When:\n    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n\n    // Then:\n    assertEquals(200, response.statusCode());\n    assertEquals(\"OK\", response.statusMessage());\n    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n    assertFalse(testEndpoints.getLastPush());\n    assertEquals(properties, testEndpoints.getLastProperties());\n\n    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n    assertEquals(0, server.getQueryIDs().size());\n    String queryID = queryResponse.responseObject.getString(\"queryID\");\n    assertNotNull(queryID);\n    assertFalse(server.getQueryIDs().contains(queryID));\n    Integer rowCount = queryResponse.responseObject.getInteger(\"rowCount\");\n    assertNotNull(rowCount);\n    assertEquals(DEFAULT_ROWS.size(), rowCount.intValue());\n  }\nThis is obviously not enforced by any tooling, but it a widely used pattern by most of the newer tests in the code base.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367415578", "createdAt": "2020-01-16T13:27:49Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "diffHunk": "@@ -0,0 +1,885 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import io.confluent.ksql.api.TestQueryPublisher.ListRowGenerator;\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.server.Server;\n+import io.vertx.codegen.annotations.Nullable;\n+import io.vertx.core.AsyncResult;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.http.HttpVersion;\n+import io.vertx.core.json.JsonArray;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.net.PemKeyCertOptions;\n+import io.vertx.core.streams.ReadStream;\n+import io.vertx.core.streams.WriteStream;\n+import io.vertx.ext.web.client.HttpResponse;\n+import io.vertx.ext.web.client.WebClient;\n+import io.vertx.ext.web.client.WebClientOptions;\n+import io.vertx.ext.web.codec.BodyCodec;\n+import java.io.FileNotFoundException;\n+import java.net.URL;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+public class ApiTest {\n+\n+  private static final long WAIT_TIMEOUT = 10000;\n+  private static final JsonArray DEFAULT_COLUMN_NAMES = new JsonArray().add(\"name\").add(\"age\")\n+      .add(\"male\");\n+  private static final JsonArray DEFAULT_COLUMN_TYPES = new JsonArray().add(\"STRING\").add(\"INT\")\n+      .add(\"BOOLEAN\");\n+  private static final List<JsonArray> DEFAULT_ROWS = generateRows();\n+\n+  private Vertx vertx;\n+  private Server server;\n+  private TestEndpoints testEndpoints;\n+  private WebClient client;\n+\n+  @Before\n+  public void setUp() throws Throwable {\n+\n+    vertx = Vertx.vertx();\n+\n+    HttpServerOptions httpServerOptions =\n+        new HttpServerOptions()\n+            .setHost(\"localhost\")\n+            .setPort(8089)\n+            .setUseAlpn(true)\n+            .setSsl(true)\n+            .setPemKeyCertOptions(\n+                new PemKeyCertOptions().setKeyPath(findFilePath(\"test-server-key.pem\"))\n+                    .setCertPath(findFilePath(\"test-server-cert.pem\"))\n+            );\n+\n+    testEndpoints = new TestEndpoints(vertx);\n+    JsonObject config = new JsonObject().put(\"verticle-instances\", 4);\n+    server = new Server(vertx, config, testEndpoints, httpServerOptions);\n+    server.start();\n+    client = createClient();\n+    setDefaultRowGenerator();\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    if (client != null) {\n+      client.close();\n+    }\n+    if (server != null) {\n+      server.stop();\n+    }\n+  }\n+\n+  @Test\n+  public void shouldExecutePullQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", false);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertFalse(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(0, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertFalse(server.getQueryIDs().contains(queryID));\n+    Integer rowCount = queryResponse.responseObject.getInteger(\"rowCount\");\n+    assertNotNull(rowCount);\n+    assertEquals(DEFAULT_ROWS.size(), rowCount.intValue());\n+  }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 134}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQxNzkxMA==", "bodyText": "Would you mind using the hamcrest matchers along with most others in the team? I appreciate this requires some time to skill up on, but the return is worth it IMHO.\nThey provide a lot more functionality and, importantly, tend to provide a lot more info when things fail, e.g.\nassertFalse(queryResponse.responseObject.containsKey(\"rowCount\"));\nWhen it fails will just say something like \"expected false, but was true\".\nHowever, hamcrest equivalent:\nassertThat(queryResponse.responseObject, hasKey(\"rowCount\"));\nWill fail with something like: \"Expected map to have key rowCount, actual keys: {rowcount, a, b}\".\nI hope you agree the latter is more helpful, especially when the test is only failing on the build server!!!\nI'll add some hamcrest equivalents below to get you started.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367417910", "createdAt": "2020-01-16T13:32:30Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "diffHunk": "@@ -0,0 +1,885 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import io.confluent.ksql.api.TestQueryPublisher.ListRowGenerator;\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.server.Server;\n+import io.vertx.codegen.annotations.Nullable;\n+import io.vertx.core.AsyncResult;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.http.HttpVersion;\n+import io.vertx.core.json.JsonArray;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.net.PemKeyCertOptions;\n+import io.vertx.core.streams.ReadStream;\n+import io.vertx.core.streams.WriteStream;\n+import io.vertx.ext.web.client.HttpResponse;\n+import io.vertx.ext.web.client.WebClient;\n+import io.vertx.ext.web.client.WebClientOptions;\n+import io.vertx.ext.web.codec.BodyCodec;\n+import java.io.FileNotFoundException;\n+import java.net.URL;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+public class ApiTest {\n+\n+  private static final long WAIT_TIMEOUT = 10000;\n+  private static final JsonArray DEFAULT_COLUMN_NAMES = new JsonArray().add(\"name\").add(\"age\")\n+      .add(\"male\");\n+  private static final JsonArray DEFAULT_COLUMN_TYPES = new JsonArray().add(\"STRING\").add(\"INT\")\n+      .add(\"BOOLEAN\");\n+  private static final List<JsonArray> DEFAULT_ROWS = generateRows();\n+\n+  private Vertx vertx;\n+  private Server server;\n+  private TestEndpoints testEndpoints;\n+  private WebClient client;\n+\n+  @Before\n+  public void setUp() throws Throwable {\n+\n+    vertx = Vertx.vertx();\n+\n+    HttpServerOptions httpServerOptions =\n+        new HttpServerOptions()\n+            .setHost(\"localhost\")\n+            .setPort(8089)\n+            .setUseAlpn(true)\n+            .setSsl(true)\n+            .setPemKeyCertOptions(\n+                new PemKeyCertOptions().setKeyPath(findFilePath(\"test-server-key.pem\"))\n+                    .setCertPath(findFilePath(\"test-server-cert.pem\"))\n+            );\n+\n+    testEndpoints = new TestEndpoints(vertx);\n+    JsonObject config = new JsonObject().put(\"verticle-instances\", 4);\n+    server = new Server(vertx, config, testEndpoints, httpServerOptions);\n+    server.start();\n+    client = createClient();\n+    setDefaultRowGenerator();\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    if (client != null) {\n+      client.close();\n+    }\n+    if (server != null) {\n+      server.stop();\n+    }\n+  }\n+\n+  @Test\n+  public void shouldExecutePullQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", false);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertFalse(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(0, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertFalse(server.getQueryIDs().contains(queryID));\n+    Integer rowCount = queryResponse.responseObject.getInteger(\"rowCount\");\n+    assertNotNull(rowCount);\n+    assertEquals(DEFAULT_ROWS.size(), rowCount.intValue());\n+  }\n+\n+  @Test\n+  public void shouldExecutePushQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertTrue(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(1, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertTrue(server.getQueryIDs().contains(queryID));\n+    assertFalse(queryResponse.responseObject.containsKey(\"rowCount\"));\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 156}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQxODQ2Mw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  assertEquals(i + 1, server.getQueryIDs().size());\n          \n          \n            \n                  assertThat(server.getQueryIDs(), hasSize(i + 1));", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367418463", "createdAt": "2020-01-16T13:33:39Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "diffHunk": "@@ -0,0 +1,885 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import io.confluent.ksql.api.TestQueryPublisher.ListRowGenerator;\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.server.Server;\n+import io.vertx.codegen.annotations.Nullable;\n+import io.vertx.core.AsyncResult;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.http.HttpVersion;\n+import io.vertx.core.json.JsonArray;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.net.PemKeyCertOptions;\n+import io.vertx.core.streams.ReadStream;\n+import io.vertx.core.streams.WriteStream;\n+import io.vertx.ext.web.client.HttpResponse;\n+import io.vertx.ext.web.client.WebClient;\n+import io.vertx.ext.web.client.WebClientOptions;\n+import io.vertx.ext.web.codec.BodyCodec;\n+import java.io.FileNotFoundException;\n+import java.net.URL;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+public class ApiTest {\n+\n+  private static final long WAIT_TIMEOUT = 10000;\n+  private static final JsonArray DEFAULT_COLUMN_NAMES = new JsonArray().add(\"name\").add(\"age\")\n+      .add(\"male\");\n+  private static final JsonArray DEFAULT_COLUMN_TYPES = new JsonArray().add(\"STRING\").add(\"INT\")\n+      .add(\"BOOLEAN\");\n+  private static final List<JsonArray> DEFAULT_ROWS = generateRows();\n+\n+  private Vertx vertx;\n+  private Server server;\n+  private TestEndpoints testEndpoints;\n+  private WebClient client;\n+\n+  @Before\n+  public void setUp() throws Throwable {\n+\n+    vertx = Vertx.vertx();\n+\n+    HttpServerOptions httpServerOptions =\n+        new HttpServerOptions()\n+            .setHost(\"localhost\")\n+            .setPort(8089)\n+            .setUseAlpn(true)\n+            .setSsl(true)\n+            .setPemKeyCertOptions(\n+                new PemKeyCertOptions().setKeyPath(findFilePath(\"test-server-key.pem\"))\n+                    .setCertPath(findFilePath(\"test-server-cert.pem\"))\n+            );\n+\n+    testEndpoints = new TestEndpoints(vertx);\n+    JsonObject config = new JsonObject().put(\"verticle-instances\", 4);\n+    server = new Server(vertx, config, testEndpoints, httpServerOptions);\n+    server.start();\n+    client = createClient();\n+    setDefaultRowGenerator();\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    if (client != null) {\n+      client.close();\n+    }\n+    if (server != null) {\n+      server.stop();\n+    }\n+  }\n+\n+  @Test\n+  public void shouldExecutePullQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", false);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertFalse(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(0, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertFalse(server.getQueryIDs().contains(queryID));\n+    Integer rowCount = queryResponse.responseObject.getInteger(\"rowCount\");\n+    assertNotNull(rowCount);\n+    assertEquals(DEFAULT_ROWS.size(), rowCount.intValue());\n+  }\n+\n+  @Test\n+  public void shouldExecutePushQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertTrue(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(1, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertTrue(server.getQueryIDs().contains(queryID));\n+    assertFalse(queryResponse.responseObject.containsKey(\"rowCount\"));\n+  }\n+\n+  @Test\n+  public void shouldExecuteMultiplePushQueries() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numQueries = 10;\n+    for (int i = 0; i < numQueries; i++) {\n+      QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+      assertEquals(i + 1, server.getQueryIDs().size());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 168}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQxODYxNQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  assertNotNull(queryID);\n          \n          \n            \n                  assertThat(queryID, is(notNullValue()));", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367418615", "createdAt": "2020-01-16T13:33:59Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "diffHunk": "@@ -0,0 +1,885 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import io.confluent.ksql.api.TestQueryPublisher.ListRowGenerator;\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.server.Server;\n+import io.vertx.codegen.annotations.Nullable;\n+import io.vertx.core.AsyncResult;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.http.HttpVersion;\n+import io.vertx.core.json.JsonArray;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.net.PemKeyCertOptions;\n+import io.vertx.core.streams.ReadStream;\n+import io.vertx.core.streams.WriteStream;\n+import io.vertx.ext.web.client.HttpResponse;\n+import io.vertx.ext.web.client.WebClient;\n+import io.vertx.ext.web.client.WebClientOptions;\n+import io.vertx.ext.web.codec.BodyCodec;\n+import java.io.FileNotFoundException;\n+import java.net.URL;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+public class ApiTest {\n+\n+  private static final long WAIT_TIMEOUT = 10000;\n+  private static final JsonArray DEFAULT_COLUMN_NAMES = new JsonArray().add(\"name\").add(\"age\")\n+      .add(\"male\");\n+  private static final JsonArray DEFAULT_COLUMN_TYPES = new JsonArray().add(\"STRING\").add(\"INT\")\n+      .add(\"BOOLEAN\");\n+  private static final List<JsonArray> DEFAULT_ROWS = generateRows();\n+\n+  private Vertx vertx;\n+  private Server server;\n+  private TestEndpoints testEndpoints;\n+  private WebClient client;\n+\n+  @Before\n+  public void setUp() throws Throwable {\n+\n+    vertx = Vertx.vertx();\n+\n+    HttpServerOptions httpServerOptions =\n+        new HttpServerOptions()\n+            .setHost(\"localhost\")\n+            .setPort(8089)\n+            .setUseAlpn(true)\n+            .setSsl(true)\n+            .setPemKeyCertOptions(\n+                new PemKeyCertOptions().setKeyPath(findFilePath(\"test-server-key.pem\"))\n+                    .setCertPath(findFilePath(\"test-server-cert.pem\"))\n+            );\n+\n+    testEndpoints = new TestEndpoints(vertx);\n+    JsonObject config = new JsonObject().put(\"verticle-instances\", 4);\n+    server = new Server(vertx, config, testEndpoints, httpServerOptions);\n+    server.start();\n+    client = createClient();\n+    setDefaultRowGenerator();\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    if (client != null) {\n+      client.close();\n+    }\n+    if (server != null) {\n+      server.stop();\n+    }\n+  }\n+\n+  @Test\n+  public void shouldExecutePullQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", false);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertFalse(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(0, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertFalse(server.getQueryIDs().contains(queryID));\n+    Integer rowCount = queryResponse.responseObject.getInteger(\"rowCount\");\n+    assertNotNull(rowCount);\n+    assertEquals(DEFAULT_ROWS.size(), rowCount.intValue());\n+  }\n+\n+  @Test\n+  public void shouldExecutePushQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertTrue(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(1, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertTrue(server.getQueryIDs().contains(queryID));\n+    assertFalse(queryResponse.responseObject.containsKey(\"rowCount\"));\n+  }\n+\n+  @Test\n+  public void shouldExecuteMultiplePushQueries() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numQueries = 10;\n+    for (int i = 0; i < numQueries; i++) {\n+      QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+      assertEquals(i + 1, server.getQueryIDs().size());\n+      String queryID = queryResponse.responseObject.getString(\"queryID\");\n+      assertNotNull(queryID);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 170}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQxODgzMQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  assertTrue(server.getQueryIDs().contains(queryID));\n          \n          \n            \n                  assertThat(server.getQueryIDs(), hasItem(queryID));", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367418831", "createdAt": "2020-01-16T13:34:29Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "diffHunk": "@@ -0,0 +1,885 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import io.confluent.ksql.api.TestQueryPublisher.ListRowGenerator;\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.server.Server;\n+import io.vertx.codegen.annotations.Nullable;\n+import io.vertx.core.AsyncResult;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.http.HttpVersion;\n+import io.vertx.core.json.JsonArray;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.net.PemKeyCertOptions;\n+import io.vertx.core.streams.ReadStream;\n+import io.vertx.core.streams.WriteStream;\n+import io.vertx.ext.web.client.HttpResponse;\n+import io.vertx.ext.web.client.WebClient;\n+import io.vertx.ext.web.client.WebClientOptions;\n+import io.vertx.ext.web.codec.BodyCodec;\n+import java.io.FileNotFoundException;\n+import java.net.URL;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+public class ApiTest {\n+\n+  private static final long WAIT_TIMEOUT = 10000;\n+  private static final JsonArray DEFAULT_COLUMN_NAMES = new JsonArray().add(\"name\").add(\"age\")\n+      .add(\"male\");\n+  private static final JsonArray DEFAULT_COLUMN_TYPES = new JsonArray().add(\"STRING\").add(\"INT\")\n+      .add(\"BOOLEAN\");\n+  private static final List<JsonArray> DEFAULT_ROWS = generateRows();\n+\n+  private Vertx vertx;\n+  private Server server;\n+  private TestEndpoints testEndpoints;\n+  private WebClient client;\n+\n+  @Before\n+  public void setUp() throws Throwable {\n+\n+    vertx = Vertx.vertx();\n+\n+    HttpServerOptions httpServerOptions =\n+        new HttpServerOptions()\n+            .setHost(\"localhost\")\n+            .setPort(8089)\n+            .setUseAlpn(true)\n+            .setSsl(true)\n+            .setPemKeyCertOptions(\n+                new PemKeyCertOptions().setKeyPath(findFilePath(\"test-server-key.pem\"))\n+                    .setCertPath(findFilePath(\"test-server-cert.pem\"))\n+            );\n+\n+    testEndpoints = new TestEndpoints(vertx);\n+    JsonObject config = new JsonObject().put(\"verticle-instances\", 4);\n+    server = new Server(vertx, config, testEndpoints, httpServerOptions);\n+    server.start();\n+    client = createClient();\n+    setDefaultRowGenerator();\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    if (client != null) {\n+      client.close();\n+    }\n+    if (server != null) {\n+      server.stop();\n+    }\n+  }\n+\n+  @Test\n+  public void shouldExecutePullQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", false);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertFalse(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(0, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertFalse(server.getQueryIDs().contains(queryID));\n+    Integer rowCount = queryResponse.responseObject.getInteger(\"rowCount\");\n+    assertNotNull(rowCount);\n+    assertEquals(DEFAULT_ROWS.size(), rowCount.intValue());\n+  }\n+\n+  @Test\n+  public void shouldExecutePushQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertTrue(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(1, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertTrue(server.getQueryIDs().contains(queryID));\n+    assertFalse(queryResponse.responseObject.containsKey(\"rowCount\"));\n+  }\n+\n+  @Test\n+  public void shouldExecuteMultiplePushQueries() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numQueries = 10;\n+    for (int i = 0; i < numQueries; i++) {\n+      QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+      assertEquals(i + 1, server.getQueryIDs().size());\n+      String queryID = queryResponse.responseObject.getString(\"queryID\");\n+      assertNotNull(queryID);\n+      assertTrue(server.getQueryIDs().contains(queryID));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 171}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQxOTM2Mw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                assertEquals(400, response.statusCode());\n          \n          \n            \n                assertThat(response.statusCode(), is(HttpStatus.SC_BAD_REQUEST));", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367419363", "createdAt": "2020-01-16T13:35:39Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "diffHunk": "@@ -0,0 +1,885 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import io.confluent.ksql.api.TestQueryPublisher.ListRowGenerator;\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.server.Server;\n+import io.vertx.codegen.annotations.Nullable;\n+import io.vertx.core.AsyncResult;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.http.HttpVersion;\n+import io.vertx.core.json.JsonArray;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.net.PemKeyCertOptions;\n+import io.vertx.core.streams.ReadStream;\n+import io.vertx.core.streams.WriteStream;\n+import io.vertx.ext.web.client.HttpResponse;\n+import io.vertx.ext.web.client.WebClient;\n+import io.vertx.ext.web.client.WebClientOptions;\n+import io.vertx.ext.web.codec.BodyCodec;\n+import java.io.FileNotFoundException;\n+import java.net.URL;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+public class ApiTest {\n+\n+  private static final long WAIT_TIMEOUT = 10000;\n+  private static final JsonArray DEFAULT_COLUMN_NAMES = new JsonArray().add(\"name\").add(\"age\")\n+      .add(\"male\");\n+  private static final JsonArray DEFAULT_COLUMN_TYPES = new JsonArray().add(\"STRING\").add(\"INT\")\n+      .add(\"BOOLEAN\");\n+  private static final List<JsonArray> DEFAULT_ROWS = generateRows();\n+\n+  private Vertx vertx;\n+  private Server server;\n+  private TestEndpoints testEndpoints;\n+  private WebClient client;\n+\n+  @Before\n+  public void setUp() throws Throwable {\n+\n+    vertx = Vertx.vertx();\n+\n+    HttpServerOptions httpServerOptions =\n+        new HttpServerOptions()\n+            .setHost(\"localhost\")\n+            .setPort(8089)\n+            .setUseAlpn(true)\n+            .setSsl(true)\n+            .setPemKeyCertOptions(\n+                new PemKeyCertOptions().setKeyPath(findFilePath(\"test-server-key.pem\"))\n+                    .setCertPath(findFilePath(\"test-server-cert.pem\"))\n+            );\n+\n+    testEndpoints = new TestEndpoints(vertx);\n+    JsonObject config = new JsonObject().put(\"verticle-instances\", 4);\n+    server = new Server(vertx, config, testEndpoints, httpServerOptions);\n+    server.start();\n+    client = createClient();\n+    setDefaultRowGenerator();\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    if (client != null) {\n+      client.close();\n+    }\n+    if (server != null) {\n+      server.stop();\n+    }\n+  }\n+\n+  @Test\n+  public void shouldExecutePullQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", false);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertFalse(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(0, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertFalse(server.getQueryIDs().contains(queryID));\n+    Integer rowCount = queryResponse.responseObject.getInteger(\"rowCount\");\n+    assertNotNull(rowCount);\n+    assertEquals(DEFAULT_ROWS.size(), rowCount.intValue());\n+  }\n+\n+  @Test\n+  public void shouldExecutePushQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertTrue(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(1, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertTrue(server.getQueryIDs().contains(queryID));\n+    assertFalse(queryResponse.responseObject.containsKey(\"rowCount\"));\n+  }\n+\n+  @Test\n+  public void shouldExecuteMultiplePushQueries() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numQueries = 10;\n+    for (int i = 0; i < numQueries; i++) {\n+      QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+      assertEquals(i + 1, server.getQueryIDs().size());\n+      String queryID = queryResponse.responseObject.getString(\"queryID\");\n+      assertNotNull(queryID);\n+      assertTrue(server.getQueryIDs().contains(queryID));\n+    }\n+  }\n+\n+  @Test\n+  public void shouldCloseQueriesOnDifferentConnectionsWhenConnectionsAreClosed() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numQueries = 10;\n+    List<WebClient> clients = new ArrayList<>();\n+    for (int i = 0; i < numQueries; i++) {\n+      // We use different clients to ensure requests are sent on different connections\n+      WebClient client = createClient();\n+      clients.add(client);\n+      QueryResponse queryResponse = executePushQueryAndWaitForRows(client, requestBody);\n+      String queryID = queryResponse.responseObject.getString(\"queryID\");\n+      assertNotNull(queryID);\n+      assertTrue(server.getQueryIDs().contains(queryID));\n+      assertEquals(i + 1, server.getQueryIDs().size());\n+      assertEquals(i + 1, server.queryConnectionCount());\n+    }\n+    assertAllQueries(numQueries, true);\n+\n+    int count = 0;\n+    for (WebClient client : clients) {\n+      client.close();\n+      int num = numQueries - count - 1;\n+      assertTrue(waitUntil(() -> server.queryConnectionCount() == num));\n+      assertEquals(num, server.getQueryIDs().size());\n+      count++;\n+    }\n+    assertAllQueries(numQueries, false);\n+  }\n+\n+  @Test\n+  public void shouldCloseQueriesOnSameConnectionsWhenConnectionsAreClosed() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numQueries = 10;\n+    for (int i = 0; i < numQueries; i++) {\n+      QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+      String queryID = queryResponse.responseObject.getString(\"queryID\");\n+      assertNotNull(queryID);\n+      assertTrue(server.getQueryIDs().contains(queryID));\n+      assertEquals(i + 1, server.getQueryIDs().size());\n+    }\n+    assertEquals(1, server.queryConnectionCount());\n+    assertAllQueries(numQueries, true);\n+\n+    client.close();\n+    assertTrue(waitUntil(() -> server.queryConnectionCount() == 0));\n+    assertTrue(server.getQueryIDs().isEmpty());\n+    client = null;\n+\n+    assertAllQueries(numQueries, false);\n+  }\n+\n+  @Test\n+  public void shouldCloseMultipleQueriesOnDifferentConnectionsWhenConnectionsAreClosed()\n+      throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numConnections = 5;\n+    int numQueries = 5;\n+    List<WebClient> clients = new ArrayList<>();\n+    for (int i = 0; i < numConnections; i++) {\n+      WebClient client = createClient();\n+      clients.add(client);\n+      for (int j = 0; j < numQueries; j++) {\n+        QueryResponse queryResponse = executePushQueryAndWaitForRows(client, requestBody);\n+        String queryID = queryResponse.responseObject.getString(\"queryID\");\n+        assertNotNull(queryID);\n+        assertTrue(server.getQueryIDs().contains(queryID));\n+        int queries = i * numQueries + j + 1;\n+        assertEquals(i * numQueries + j + 1, server.getQueryIDs().size());\n+        assertEquals(i + 1, server.queryConnectionCount());\n+        assertAllQueries(queries, true);\n+      }\n+    }\n+\n+    int count = 0;\n+    for (WebClient client : clients) {\n+      client.close();\n+      int connections = numConnections - count - 1;\n+      assertTrue(waitUntil(() -> server.queryConnectionCount() == connections));\n+      assertEquals(numQueries * connections, server.getQueryIDs().size());\n+      count++;\n+    }\n+\n+    assertAllQueries(numConnections * numQueries, false);\n+  }\n+\n+  @Test\n+  public void shouldHandleQueryWithMissingSql() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"foo\", \"bar\");\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(400, response.statusCode());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 279}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQyODEzOA==", "bodyText": "Take a look at assertThatEventually. I think you can use this in place of waitUtil in at least some cases.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367428138", "createdAt": "2020-01-16T13:53:23Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "diffHunk": "@@ -0,0 +1,885 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import io.confluent.ksql.api.TestQueryPublisher.ListRowGenerator;\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.server.Server;\n+import io.vertx.codegen.annotations.Nullable;\n+import io.vertx.core.AsyncResult;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.http.HttpVersion;\n+import io.vertx.core.json.JsonArray;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.net.PemKeyCertOptions;\n+import io.vertx.core.streams.ReadStream;\n+import io.vertx.core.streams.WriteStream;\n+import io.vertx.ext.web.client.HttpResponse;\n+import io.vertx.ext.web.client.WebClient;\n+import io.vertx.ext.web.client.WebClientOptions;\n+import io.vertx.ext.web.codec.BodyCodec;\n+import java.io.FileNotFoundException;\n+import java.net.URL;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+public class ApiTest {\n+\n+  private static final long WAIT_TIMEOUT = 10000;\n+  private static final JsonArray DEFAULT_COLUMN_NAMES = new JsonArray().add(\"name\").add(\"age\")\n+      .add(\"male\");\n+  private static final JsonArray DEFAULT_COLUMN_TYPES = new JsonArray().add(\"STRING\").add(\"INT\")\n+      .add(\"BOOLEAN\");\n+  private static final List<JsonArray> DEFAULT_ROWS = generateRows();\n+\n+  private Vertx vertx;\n+  private Server server;\n+  private TestEndpoints testEndpoints;\n+  private WebClient client;\n+\n+  @Before\n+  public void setUp() throws Throwable {\n+\n+    vertx = Vertx.vertx();\n+\n+    HttpServerOptions httpServerOptions =\n+        new HttpServerOptions()\n+            .setHost(\"localhost\")\n+            .setPort(8089)\n+            .setUseAlpn(true)\n+            .setSsl(true)\n+            .setPemKeyCertOptions(\n+                new PemKeyCertOptions().setKeyPath(findFilePath(\"test-server-key.pem\"))\n+                    .setCertPath(findFilePath(\"test-server-cert.pem\"))\n+            );\n+\n+    testEndpoints = new TestEndpoints(vertx);\n+    JsonObject config = new JsonObject().put(\"verticle-instances\", 4);\n+    server = new Server(vertx, config, testEndpoints, httpServerOptions);\n+    server.start();\n+    client = createClient();\n+    setDefaultRowGenerator();\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    if (client != null) {\n+      client.close();\n+    }\n+    if (server != null) {\n+      server.stop();\n+    }\n+  }\n+\n+  @Test\n+  public void shouldExecutePullQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", false);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertFalse(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(0, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertFalse(server.getQueryIDs().contains(queryID));\n+    Integer rowCount = queryResponse.responseObject.getInteger(\"rowCount\");\n+    assertNotNull(rowCount);\n+    assertEquals(DEFAULT_ROWS.size(), rowCount.intValue());\n+  }\n+\n+  @Test\n+  public void shouldExecutePushQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertTrue(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(1, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertTrue(server.getQueryIDs().contains(queryID));\n+    assertFalse(queryResponse.responseObject.containsKey(\"rowCount\"));\n+  }\n+\n+  @Test\n+  public void shouldExecuteMultiplePushQueries() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numQueries = 10;\n+    for (int i = 0; i < numQueries; i++) {\n+      QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+      assertEquals(i + 1, server.getQueryIDs().size());\n+      String queryID = queryResponse.responseObject.getString(\"queryID\");\n+      assertNotNull(queryID);\n+      assertTrue(server.getQueryIDs().contains(queryID));\n+    }\n+  }\n+\n+  @Test\n+  public void shouldCloseQueriesOnDifferentConnectionsWhenConnectionsAreClosed() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numQueries = 10;\n+    List<WebClient> clients = new ArrayList<>();\n+    for (int i = 0; i < numQueries; i++) {\n+      // We use different clients to ensure requests are sent on different connections\n+      WebClient client = createClient();\n+      clients.add(client);\n+      QueryResponse queryResponse = executePushQueryAndWaitForRows(client, requestBody);\n+      String queryID = queryResponse.responseObject.getString(\"queryID\");\n+      assertNotNull(queryID);\n+      assertTrue(server.getQueryIDs().contains(queryID));\n+      assertEquals(i + 1, server.getQueryIDs().size());\n+      assertEquals(i + 1, server.queryConnectionCount());\n+    }\n+    assertAllQueries(numQueries, true);\n+\n+    int count = 0;\n+    for (WebClient client : clients) {\n+      client.close();\n+      int num = numQueries - count - 1;\n+      assertTrue(waitUntil(() -> server.queryConnectionCount() == num));\n+      assertEquals(num, server.getQueryIDs().size());\n+      count++;\n+    }\n+    assertAllQueries(numQueries, false);\n+  }\n+\n+  @Test\n+  public void shouldCloseQueriesOnSameConnectionsWhenConnectionsAreClosed() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numQueries = 10;\n+    for (int i = 0; i < numQueries; i++) {\n+      QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+      String queryID = queryResponse.responseObject.getString(\"queryID\");\n+      assertNotNull(queryID);\n+      assertTrue(server.getQueryIDs().contains(queryID));\n+      assertEquals(i + 1, server.getQueryIDs().size());\n+    }\n+    assertEquals(1, server.queryConnectionCount());\n+    assertAllQueries(numQueries, true);\n+\n+    client.close();\n+    assertTrue(waitUntil(() -> server.queryConnectionCount() == 0));\n+    assertTrue(server.getQueryIDs().isEmpty());\n+    client = null;\n+\n+    assertAllQueries(numQueries, false);\n+  }\n+\n+  @Test\n+  public void shouldCloseMultipleQueriesOnDifferentConnectionsWhenConnectionsAreClosed()\n+      throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numConnections = 5;\n+    int numQueries = 5;\n+    List<WebClient> clients = new ArrayList<>();\n+    for (int i = 0; i < numConnections; i++) {\n+      WebClient client = createClient();\n+      clients.add(client);\n+      for (int j = 0; j < numQueries; j++) {\n+        QueryResponse queryResponse = executePushQueryAndWaitForRows(client, requestBody);\n+        String queryID = queryResponse.responseObject.getString(\"queryID\");\n+        assertNotNull(queryID);\n+        assertTrue(server.getQueryIDs().contains(queryID));\n+        int queries = i * numQueries + j + 1;\n+        assertEquals(i * numQueries + j + 1, server.getQueryIDs().size());\n+        assertEquals(i + 1, server.queryConnectionCount());\n+        assertAllQueries(queries, true);\n+      }\n+    }\n+\n+    int count = 0;\n+    for (WebClient client : clients) {\n+      client.close();\n+      int connections = numConnections - count - 1;\n+      assertTrue(waitUntil(() -> server.queryConnectionCount() == connections));\n+      assertEquals(numQueries * connections, server.getQueryIDs().size());\n+      count++;\n+    }\n+\n+    assertAllQueries(numConnections * numQueries, false);\n+  }\n+\n+  @Test\n+  public void shouldHandleQueryWithMissingSql() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"foo\", \"bar\");\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(400, response.statusCode());\n+    assertEquals(\"Bad Request\", response.statusMessage());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    validateError(ERROR_CODE_MISSING_PARAM, \"No sql in arguments\", queryResponse.responseObject);\n+  }\n+\n+  @Test\n+  public void shouldHandleQueryWithMissingPush() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\");\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(400, response.statusCode());\n+    assertEquals(\"Bad Request\", response.statusMessage());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    validateError(ERROR_CODE_MISSING_PARAM, \"No push in arguments\", queryResponse.responseObject);\n+  }\n+\n+  @Test\n+  public void shouldHandleErrorInProcessingQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    testEndpoints.setRowsBeforePublisherError(DEFAULT_ROWS.size() - 1);\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    assertEquals(DEFAULT_ROWS.size() - 1, queryResponse.rows.size());\n+    validateError(ERROR_CODE_INTERNAL_ERROR, \"Error in processing query\", queryResponse.error);\n+\n+    assertEquals(1, testEndpoints.getQueryPublishers().size());\n+    assertFalse(testEndpoints.getQueryPublishers().iterator().next().hasSubscriber());\n+    assertTrue(server.getQueryIDs().isEmpty());\n+  }\n+\n+  @Test\n+  public void shouldCloseQuery() throws Exception {\n+\n+    JsonObject queryRequestBody = new JsonObject().put(\"sql\", \"select * from foo\")\n+        .put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    queryRequestBody.put(\"properties\", properties);\n+\n+    ReceiveStream writeStream = new ReceiveStream(vertx);\n+\n+    client.post(8089, \"localhost\", \"/query-stream\")\n+        .as(BodyCodec.pipe(writeStream))\n+        .sendJsonObject(queryRequestBody, ar -> {\n+        });\n+\n+    // Wait for all rows to arrive\n+    assertTrue(waitUntil(() -> {\n+      Buffer buff = writeStream.getBody();\n+      try {\n+        QueryResponse queryResponse = new QueryResponse(buff.toString());\n+        return queryResponse.rows.size() == DEFAULT_ROWS.size();\n+      } catch (Throwable t) {\n+        return false;\n+      }\n+    }));\n+\n+    assertFalse(writeStream.isEnded());\n+\n+    QueryResponse queryResponse = new QueryResponse(writeStream.getBody().toString());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertTrue(server.getQueryIDs().contains(queryID));\n+    assertEquals(1, server.getQueryIDs().size());\n+    assertEquals(1, testEndpoints.getQueryPublishers().size());\n+\n+    JsonObject closeQueryRequestBody = new JsonObject().put(\"queryID\", queryID);\n+    HttpResponse<Buffer> closeQueryResponse = sendRequest(client, \"/close-query\",\n+        closeQueryRequestBody.toBuffer());\n+    assertEquals(200, closeQueryResponse.statusCode());\n+    assertFalse(server.getQueryIDs().contains(queryID));\n+    assertEquals(0, server.getQueryIDs().size());\n+\n+    // This should trigger the response to end\n+    assertTrue(waitUntil(writeStream::isEnded));\n+\n+    assertEquals(1, testEndpoints.getQueryPublishers().size());\n+    assertFalse(testEndpoints.getQueryPublishers().iterator().next().hasSubscriber());\n+  }\n+\n+  @Test\n+  public void shouldHandleMissingQueryIDInCloseQuery() throws Exception {\n+\n+    JsonObject closeQueryRequestBody = new JsonObject().put(\"foo\", \"bar\");\n+    HttpResponse<Buffer> response = sendRequest(client, \"/close-query\",\n+        closeQueryRequestBody.toBuffer());\n+\n+    assertEquals(400, response.statusCode());\n+    assertEquals(\"Bad Request\", response.statusMessage());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    validateError(ERROR_CODE_MISSING_PARAM, \"No queryID in arguments\",\n+        queryResponse.responseObject);\n+  }\n+\n+  @Test\n+  public void shouldHandleUnknownQueryIDInCloseQuery() throws Exception {\n+\n+    JsonObject closeQueryRequestBody = new JsonObject().put(\"queryID\", \"xyzfasgf\");\n+    HttpResponse<Buffer> response = sendRequest(client, \"/close-query\",\n+        closeQueryRequestBody.toBuffer());\n+\n+    assertEquals(400, response.statusCode());\n+    assertEquals(\"Bad Request\", response.statusMessage());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    validateError(ERROR_CODE_UNKNOWN_QUERY_ID, \"No query with id xyzfasgf\",\n+        queryResponse.responseObject);\n+  }\n+\n+  @Test\n+  public void shouldInsertWithNoAcksStream() throws Exception {\n+\n+    JsonObject params = new JsonObject().put(\"target\", \"test-stream\").put(\"acks\", false);\n+\n+    List<JsonObject> rows = generateInsertRows();\n+    Buffer requestBody = Buffer.buffer();\n+    requestBody.appendBuffer(params.toBuffer()).appendString(\"\\n\");\n+    for (JsonObject row : rows) {\n+      requestBody.appendBuffer(row.toBuffer()).appendString(\"\\n\");\n+    }\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/inserts-stream\", requestBody);\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+\n+    assertEquals(rows, testEndpoints.getInsertsSubscriber().getRowsInserted());\n+    assertTrue(testEndpoints.getInsertsSubscriber().isCompleted());\n+    assertEquals(\"test-stream\", testEndpoints.getLastTarget());\n+  }\n+\n+  @Test\n+  public void shouldInsertWithAcksStream() throws Exception {\n+\n+    JsonObject params = new JsonObject().put(\"target\", \"test-stream\").put(\"acks\", true);\n+\n+    List<JsonObject> rows = generateInsertRows();\n+    Buffer requestBody = Buffer.buffer();\n+    requestBody.appendBuffer(params.toBuffer()).appendString(\"\\n\");\n+    for (JsonObject row : rows) {\n+      requestBody.appendBuffer(row.toBuffer()).appendString(\"\\n\");\n+    }\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/inserts-stream\", requestBody);\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+\n+    String responseBody = response.bodyAsString();\n+    InsertsResponse insertsResponse = new InsertsResponse(responseBody);\n+    assertEquals(rows.size(), insertsResponse.acks.size());\n+\n+    assertEquals(rows, testEndpoints.getInsertsSubscriber().getRowsInserted());\n+    assertTrue(testEndpoints.getInsertsSubscriber().isCompleted());\n+    assertEquals(\"test-stream\", testEndpoints.getLastTarget());\n+  }\n+\n+  @Test\n+  public void shouldStreamInserts() throws Exception {\n+\n+    JsonObject params = new JsonObject().put(\"target\", \"test-stream\").put(\"acks\", true);\n+\n+    SendStream readStream = new SendStream(vertx);\n+    ReceiveStream writeStream = new ReceiveStream(vertx);\n+    VertxCompletableFuture<HttpResponse<Void>> fut = new VertxCompletableFuture<>();\n+    List<JsonObject> rows = generateInsertRows();\n+\n+    client.post(8089, \"localhost\", \"/inserts-stream\")\n+        .as(BodyCodec.pipe(writeStream))\n+        .sendStream(readStream, fut);\n+\n+    readStream.acceptBuffer(params.toBuffer().appendString(\"\\n\"));\n+\n+    AtomicInteger rowIndex = new AtomicInteger();\n+    vertx.setPeriodic(100, tid -> {\n+      readStream.acceptBuffer(rows.get(rowIndex.getAndIncrement()).toBuffer().appendString(\"\\n\"));\n+      if (rowIndex.get() == rows.size()) {\n+        vertx.cancelTimer(tid);\n+        readStream.end();\n+      }\n+    });\n+\n+    HttpResponse<Void> response = fut.get();\n+\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+\n+    InsertsResponse insertsResponse = new InsertsResponse(writeStream.getBody().toString());\n+    assertEquals(rows.size(), insertsResponse.acks.size());\n+    assertEquals(rows, testEndpoints.getInsertsSubscriber().getRowsInserted());\n+    assertTrue(testEndpoints.getInsertsSubscriber().isCompleted());\n+    // When response is complete the acks subscriber should be unsubscribed\n+    assertFalse(testEndpoints.getAcksPublisher().hasSubscriber());\n+\n+    // Ensure we received at last some of the response before all the request body was written\n+    // Yay HTTP2!\n+    assertTrue(readStream.getLastSentTime() > writeStream.getFirstReceivedTime());\n+  }\n+\n+  @Test\n+  public void shouldHandleMissingTargetInInserts() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"acks\", true);\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/inserts-stream\",\n+        requestBody.toBuffer().appendString(\"\\n\"));\n+\n+    assertEquals(400, response.statusCode());\n+    assertEquals(\"Bad Request\", response.statusMessage());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    validateError(ERROR_CODE_MISSING_PARAM, \"No target in arguments\", queryResponse.responseObject);\n+  }\n+\n+  @Test\n+  public void shouldHandleMissingAcksInInserts() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"target\", \"some-stream\");\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/inserts-stream\",\n+        requestBody.toBuffer().appendString(\"\\n\"));\n+\n+    assertEquals(400, response.statusCode());\n+    assertEquals(\"Bad Request\", response.statusMessage());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    validateError(ERROR_CODE_MISSING_PARAM, \"No acks in arguments\",\n+        queryResponse.responseObject);\n+  }\n+\n+  @Test\n+  public void shouldHandleErrorInProcessingInserts() throws Exception {\n+\n+    JsonObject params = new JsonObject().put(\"target\", \"test-stream\").put(\"acks\", true);\n+\n+    List<JsonObject> rows = generateInsertRows();\n+    Buffer requestBody = Buffer.buffer();\n+    requestBody.appendBuffer(params.toBuffer()).appendString(\"\\n\");\n+    for (JsonObject row : rows) {\n+      requestBody.appendBuffer(row.toBuffer()).appendString(\"\\n\");\n+    }\n+\n+    // Inject an error on last row inserted\n+    testEndpoints.setAcksBeforePublisherError(rows.size() - 1);\n+\n+    // The HTTP response will be OK as the error is later in the stream after response\n+    // headers have been written\n+    HttpResponse<Buffer> response = sendRequest(\"/inserts-stream\", requestBody);\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+\n+    String responseBody = response.bodyAsString();\n+    InsertsResponse insertsResponse = new InsertsResponse(responseBody);\n+    assertEquals(rows.size() - 1, insertsResponse.acks.size());\n+    validateError(ERROR_CODE_INTERNAL_ERROR, \"Error in processing inserts\", insertsResponse.error);\n+\n+    assertTrue(testEndpoints.getInsertsSubscriber().isCompleted());\n+  }\n+\n+  private QueryResponse executePushQueryAndWaitForRows(final JsonObject requestBody)\n+      throws Exception {\n+    return executePushQueryAndWaitForRows(client, requestBody);\n+  }\n+\n+  private QueryResponse executePushQueryAndWaitForRows(final WebClient client,\n+      final JsonObject requestBody)\n+      throws Exception {\n+\n+    ReceiveStream writeStream = new ReceiveStream(vertx);\n+\n+    client.post(8089, \"localhost\", \"/query-stream\")\n+        .as(BodyCodec.pipe(writeStream))\n+        .sendJsonObject(requestBody, ar -> {\n+        });\n+\n+    // Wait for all rows to arrive\n+    assertTrue(waitUntil(() -> {\n+      Buffer buff = writeStream.getBody();\n+      try {\n+        QueryResponse queryResponse = new QueryResponse(buff.toString());\n+        return queryResponse.rows.size() == DEFAULT_ROWS.size();\n+      } catch (Throwable t) {\n+        return false;\n+      }\n+    }));\n+\n+    // Note, the response hasn't ended at this point\n+    assertFalse(writeStream.isEnded());\n+\n+    return new QueryResponse(writeStream.getBody().toString());\n+  }\n+\n+  private WebClient createClient() {\n+    WebClientOptions options = new WebClientOptions().setSsl(true).\n+        setUseAlpn(true).\n+        setProtocolVersion(HttpVersion.HTTP_2).\n+        setTrustAll(true);\n+\n+    return WebClient.create(vertx, options);\n+  }\n+\n+  private static void validateError(final int errorCode, final String message,\n+      final JsonObject error) {\n+    assertEquals(\"error\", error.getString(\"status\"));\n+    assertEquals(errorCode, error.getInteger(\"errorCode\").intValue());\n+    assertEquals(message, error.getString(\"message\"));\n+    assertEquals(3, error.size());\n+  }\n+\n+  private void assertAllQueries(final int num, final boolean open) {\n+    assertEquals(num, testEndpoints.getQueryPublishers().size());\n+    for (TestQueryPublisher queryPublisher : testEndpoints.getQueryPublishers()) {\n+      if (open) {\n+        assertTrue(queryPublisher.hasSubscriber());\n+      } else {\n+        assertFalse(queryPublisher.hasSubscriber());\n+      }\n+    }\n+  }\n+\n+  private HttpResponse<Buffer> sendRequest(final String uri, final Buffer requestBody)\n+      throws Exception {\n+    return sendRequest(client, uri, requestBody);\n+  }\n+\n+  private HttpResponse<Buffer> sendRequest(final WebClient client, final String uri,\n+      final Buffer requestBody)\n+      throws Exception {\n+    VertxCompletableFuture<HttpResponse<Buffer>> requestFuture = new VertxCompletableFuture<>();\n+    client\n+        .post(8089, \"localhost\", uri)\n+        .sendBuffer(requestBody, requestFuture);\n+    return requestFuture.get();\n+  }\n+\n+  private void setDefaultRowGenerator() {\n+    testEndpoints.setRowGeneratorFactory(\n+        () -> new ListRowGenerator(DEFAULT_COLUMN_NAMES, DEFAULT_COLUMN_TYPES,\n+            DEFAULT_ROWS));\n+  }\n+\n+  private static boolean waitUntil(final Supplier<Boolean> test) throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 631}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQyODg1MQ==", "bodyText": "It's hard to tell what is going on in this test TBH.  You may understand it, but someone else may struggle if this starts failing when they change something.\nIMHO it would benefit from being refactored into methods with more descriptive names, using Given/When/Then to make it clear which is the actual bit under test, and avoid testing the same things in many tests e.g.\n@Test\npublic void shouldCloseQuery() throws Exception {\n   // Given:\n   QueryResponse queryResponse = executePushQueryAndWaitForRows(queryRequestBody);\n   String queryID = queryResponse.responseObject.getString(\"queryID\");\n\n    // When:\n    HttpResponse<Buffer> closeQueryResponse = sendRequest(closeRequest(queryId)));\n  \n    // Then:\n    assertThat(closeQueryResponse.statusCode(), is(200));\n    assertThat(server.getQueryIDs(), not(hasItem(queryID)));\n\n    // This should trigger the response to end\n    assertThatEventually(writeStream::isEnded, is(true)));\n\n    assertThat(testEndpoints.getQueryPublishers(), hasSize(1));\n    assertThat(testEndpoints.getQueryPublishers().iterator().next().hasSubscriber(), is(true));\n}\nNote, I excluded some lines from the test, as they are tested elsewhere:\n    assertTrue(server.getQueryIDs().contains(queryID));\n    assertEquals(1, server.getQueryIDs().size());\n    assertEquals(1, testEndpoints.getQueryPublishers().size());\n\n    assertEquals(0, server.getQueryIDs().size()); \n\nTBH, there's also a some code duplication in this test file. For example:\n\nmany tests create the same queryRequestBody.  Maybe this could just be in a constant?\nmany tests create new SendStream(vertx) or new ReceiveStream(vertx). Maybe these could be created in setUp method and stored in fields?\n\nRefactoring in this way removes the noise from test cases, making them much easier for the next person to understand.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367428851", "createdAt": "2020-01-16T13:54:44Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "diffHunk": "@@ -0,0 +1,885 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import io.confluent.ksql.api.TestQueryPublisher.ListRowGenerator;\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.server.Server;\n+import io.vertx.codegen.annotations.Nullable;\n+import io.vertx.core.AsyncResult;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.http.HttpVersion;\n+import io.vertx.core.json.JsonArray;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.net.PemKeyCertOptions;\n+import io.vertx.core.streams.ReadStream;\n+import io.vertx.core.streams.WriteStream;\n+import io.vertx.ext.web.client.HttpResponse;\n+import io.vertx.ext.web.client.WebClient;\n+import io.vertx.ext.web.client.WebClientOptions;\n+import io.vertx.ext.web.codec.BodyCodec;\n+import java.io.FileNotFoundException;\n+import java.net.URL;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+public class ApiTest {\n+\n+  private static final long WAIT_TIMEOUT = 10000;\n+  private static final JsonArray DEFAULT_COLUMN_NAMES = new JsonArray().add(\"name\").add(\"age\")\n+      .add(\"male\");\n+  private static final JsonArray DEFAULT_COLUMN_TYPES = new JsonArray().add(\"STRING\").add(\"INT\")\n+      .add(\"BOOLEAN\");\n+  private static final List<JsonArray> DEFAULT_ROWS = generateRows();\n+\n+  private Vertx vertx;\n+  private Server server;\n+  private TestEndpoints testEndpoints;\n+  private WebClient client;\n+\n+  @Before\n+  public void setUp() throws Throwable {\n+\n+    vertx = Vertx.vertx();\n+\n+    HttpServerOptions httpServerOptions =\n+        new HttpServerOptions()\n+            .setHost(\"localhost\")\n+            .setPort(8089)\n+            .setUseAlpn(true)\n+            .setSsl(true)\n+            .setPemKeyCertOptions(\n+                new PemKeyCertOptions().setKeyPath(findFilePath(\"test-server-key.pem\"))\n+                    .setCertPath(findFilePath(\"test-server-cert.pem\"))\n+            );\n+\n+    testEndpoints = new TestEndpoints(vertx);\n+    JsonObject config = new JsonObject().put(\"verticle-instances\", 4);\n+    server = new Server(vertx, config, testEndpoints, httpServerOptions);\n+    server.start();\n+    client = createClient();\n+    setDefaultRowGenerator();\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    if (client != null) {\n+      client.close();\n+    }\n+    if (server != null) {\n+      server.stop();\n+    }\n+  }\n+\n+  @Test\n+  public void shouldExecutePullQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", false);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertFalse(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(0, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertFalse(server.getQueryIDs().contains(queryID));\n+    Integer rowCount = queryResponse.responseObject.getInteger(\"rowCount\");\n+    assertNotNull(rowCount);\n+    assertEquals(DEFAULT_ROWS.size(), rowCount.intValue());\n+  }\n+\n+  @Test\n+  public void shouldExecutePushQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+\n+    assertEquals(\"select * from foo\", testEndpoints.getLastSql());\n+    assertTrue(testEndpoints.getLastPush());\n+    assertEquals(properties, testEndpoints.getLastProperties());\n+\n+    assertEquals(DEFAULT_COLUMN_NAMES, queryResponse.responseObject.getJsonArray(\"columnNames\"));\n+    assertEquals(DEFAULT_COLUMN_TYPES, queryResponse.responseObject.getJsonArray(\"columnTypes\"));\n+    assertEquals(DEFAULT_ROWS, queryResponse.rows);\n+    assertEquals(1, server.getQueryIDs().size());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertNotNull(queryID);\n+    assertTrue(server.getQueryIDs().contains(queryID));\n+    assertFalse(queryResponse.responseObject.containsKey(\"rowCount\"));\n+  }\n+\n+  @Test\n+  public void shouldExecuteMultiplePushQueries() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numQueries = 10;\n+    for (int i = 0; i < numQueries; i++) {\n+      QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+      assertEquals(i + 1, server.getQueryIDs().size());\n+      String queryID = queryResponse.responseObject.getString(\"queryID\");\n+      assertNotNull(queryID);\n+      assertTrue(server.getQueryIDs().contains(queryID));\n+    }\n+  }\n+\n+  @Test\n+  public void shouldCloseQueriesOnDifferentConnectionsWhenConnectionsAreClosed() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numQueries = 10;\n+    List<WebClient> clients = new ArrayList<>();\n+    for (int i = 0; i < numQueries; i++) {\n+      // We use different clients to ensure requests are sent on different connections\n+      WebClient client = createClient();\n+      clients.add(client);\n+      QueryResponse queryResponse = executePushQueryAndWaitForRows(client, requestBody);\n+      String queryID = queryResponse.responseObject.getString(\"queryID\");\n+      assertNotNull(queryID);\n+      assertTrue(server.getQueryIDs().contains(queryID));\n+      assertEquals(i + 1, server.getQueryIDs().size());\n+      assertEquals(i + 1, server.queryConnectionCount());\n+    }\n+    assertAllQueries(numQueries, true);\n+\n+    int count = 0;\n+    for (WebClient client : clients) {\n+      client.close();\n+      int num = numQueries - count - 1;\n+      assertTrue(waitUntil(() -> server.queryConnectionCount() == num));\n+      assertEquals(num, server.getQueryIDs().size());\n+      count++;\n+    }\n+    assertAllQueries(numQueries, false);\n+  }\n+\n+  @Test\n+  public void shouldCloseQueriesOnSameConnectionsWhenConnectionsAreClosed() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numQueries = 10;\n+    for (int i = 0; i < numQueries; i++) {\n+      QueryResponse queryResponse = executePushQueryAndWaitForRows(requestBody);\n+      String queryID = queryResponse.responseObject.getString(\"queryID\");\n+      assertNotNull(queryID);\n+      assertTrue(server.getQueryIDs().contains(queryID));\n+      assertEquals(i + 1, server.getQueryIDs().size());\n+    }\n+    assertEquals(1, server.queryConnectionCount());\n+    assertAllQueries(numQueries, true);\n+\n+    client.close();\n+    assertTrue(waitUntil(() -> server.queryConnectionCount() == 0));\n+    assertTrue(server.getQueryIDs().isEmpty());\n+    client = null;\n+\n+    assertAllQueries(numQueries, false);\n+  }\n+\n+  @Test\n+  public void shouldCloseMultipleQueriesOnDifferentConnectionsWhenConnectionsAreClosed()\n+      throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    int numConnections = 5;\n+    int numQueries = 5;\n+    List<WebClient> clients = new ArrayList<>();\n+    for (int i = 0; i < numConnections; i++) {\n+      WebClient client = createClient();\n+      clients.add(client);\n+      for (int j = 0; j < numQueries; j++) {\n+        QueryResponse queryResponse = executePushQueryAndWaitForRows(client, requestBody);\n+        String queryID = queryResponse.responseObject.getString(\"queryID\");\n+        assertNotNull(queryID);\n+        assertTrue(server.getQueryIDs().contains(queryID));\n+        int queries = i * numQueries + j + 1;\n+        assertEquals(i * numQueries + j + 1, server.getQueryIDs().size());\n+        assertEquals(i + 1, server.queryConnectionCount());\n+        assertAllQueries(queries, true);\n+      }\n+    }\n+\n+    int count = 0;\n+    for (WebClient client : clients) {\n+      client.close();\n+      int connections = numConnections - count - 1;\n+      assertTrue(waitUntil(() -> server.queryConnectionCount() == connections));\n+      assertEquals(numQueries * connections, server.getQueryIDs().size());\n+      count++;\n+    }\n+\n+    assertAllQueries(numConnections * numQueries, false);\n+  }\n+\n+  @Test\n+  public void shouldHandleQueryWithMissingSql() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"foo\", \"bar\");\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(400, response.statusCode());\n+    assertEquals(\"Bad Request\", response.statusMessage());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    validateError(ERROR_CODE_MISSING_PARAM, \"No sql in arguments\", queryResponse.responseObject);\n+  }\n+\n+  @Test\n+  public void shouldHandleQueryWithMissingPush() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\");\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(400, response.statusCode());\n+    assertEquals(\"Bad Request\", response.statusMessage());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    validateError(ERROR_CODE_MISSING_PARAM, \"No push in arguments\", queryResponse.responseObject);\n+  }\n+\n+  @Test\n+  public void shouldHandleErrorInProcessingQuery() throws Exception {\n+\n+    JsonObject requestBody = new JsonObject().put(\"sql\", \"select * from foo\").put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    requestBody.put(\"properties\", properties);\n+\n+    testEndpoints.setRowsBeforePublisherError(DEFAULT_ROWS.size() - 1);\n+\n+    HttpResponse<Buffer> response = sendRequest(\"/query-stream\", requestBody.toBuffer());\n+\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+\n+    QueryResponse queryResponse = new QueryResponse(response.bodyAsString());\n+    assertEquals(DEFAULT_ROWS.size() - 1, queryResponse.rows.size());\n+    validateError(ERROR_CODE_INTERNAL_ERROR, \"Error in processing query\", queryResponse.error);\n+\n+    assertEquals(1, testEndpoints.getQueryPublishers().size());\n+    assertFalse(testEndpoints.getQueryPublishers().iterator().next().hasSubscriber());\n+    assertTrue(server.getQueryIDs().isEmpty());\n+  }\n+\n+  @Test\n+  public void shouldCloseQuery() throws Exception {\n+\n+    JsonObject queryRequestBody = new JsonObject().put(\"sql\", \"select * from foo\")\n+        .put(\"push\", true);\n+    JsonObject properties = new JsonObject().put(\"prop1\", \"val1\").put(\"prop2\", 23);\n+    queryRequestBody.put(\"properties\", properties);\n+\n+    ReceiveStream writeStream = new ReceiveStream(vertx);\n+\n+    client.post(8089, \"localhost\", \"/query-stream\")\n+        .as(BodyCodec.pipe(writeStream))\n+        .sendJsonObject(queryRequestBody, ar -> {\n+        });\n+\n+    // Wait for all rows to arrive\n+    assertTrue(waitUntil(() -> {\n+      Buffer buff = writeStream.getBody();\n+      try {\n+        QueryResponse queryResponse = new QueryResponse(buff.toString());\n+        return queryResponse.rows.size() == DEFAULT_ROWS.size();\n+      } catch (Throwable t) {\n+        return false;\n+      }\n+    }));\n+\n+    assertFalse(writeStream.isEnded());\n+\n+    QueryResponse queryResponse = new QueryResponse(writeStream.getBody().toString());\n+    String queryID = queryResponse.responseObject.getString(\"queryID\");\n+    assertTrue(server.getQueryIDs().contains(queryID));\n+    assertEquals(1, server.getQueryIDs().size());\n+    assertEquals(1, testEndpoints.getQueryPublishers().size());\n+\n+    JsonObject closeQueryRequestBody = new JsonObject().put(\"queryID\", queryID);\n+    HttpResponse<Buffer> closeQueryResponse = sendRequest(client, \"/close-query\",\n+        closeQueryRequestBody.toBuffer());\n+    assertEquals(200, closeQueryResponse.statusCode());\n+    assertFalse(server.getQueryIDs().contains(queryID));\n+    assertEquals(0, server.getQueryIDs().size());\n+\n+    // This should trigger the response to end\n+    assertTrue(waitUntil(writeStream::isEnded));\n+\n+    assertEquals(1, testEndpoints.getQueryPublishers().size());\n+    assertFalse(testEndpoints.getQueryPublishers().iterator().next().hasSubscriber());\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 369}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2NzQzMDExMA==", "bodyText": "Not sure, but maybe ServerKeyStore or ClientTrustStore or similar can help simplify the test here?", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r367430110", "createdAt": "2020-01-16T13:57:03Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "diffHunk": "@@ -0,0 +1,885 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertNull;\n+import static org.junit.Assert.assertTrue;\n+\n+import io.confluent.ksql.api.TestQueryPublisher.ListRowGenerator;\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.server.Server;\n+import io.vertx.codegen.annotations.Nullable;\n+import io.vertx.core.AsyncResult;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.http.HttpVersion;\n+import io.vertx.core.json.JsonArray;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.net.PemKeyCertOptions;\n+import io.vertx.core.streams.ReadStream;\n+import io.vertx.core.streams.WriteStream;\n+import io.vertx.ext.web.client.HttpResponse;\n+import io.vertx.ext.web.client.WebClient;\n+import io.vertx.ext.web.client.WebClientOptions;\n+import io.vertx.ext.web.codec.BodyCodec;\n+import java.io.FileNotFoundException;\n+import java.net.URL;\n+import java.util.ArrayList;\n+import java.util.LinkedList;\n+import java.util.List;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+public class ApiTest {\n+\n+  private static final long WAIT_TIMEOUT = 10000;\n+  private static final JsonArray DEFAULT_COLUMN_NAMES = new JsonArray().add(\"name\").add(\"age\")\n+      .add(\"male\");\n+  private static final JsonArray DEFAULT_COLUMN_TYPES = new JsonArray().add(\"STRING\").add(\"INT\")\n+      .add(\"BOOLEAN\");\n+  private static final List<JsonArray> DEFAULT_ROWS = generateRows();\n+\n+  private Vertx vertx;\n+  private Server server;\n+  private TestEndpoints testEndpoints;\n+  private WebClient client;\n+\n+  @Before\n+  public void setUp() throws Throwable {\n+\n+    vertx = Vertx.vertx();\n+\n+    HttpServerOptions httpServerOptions =\n+        new HttpServerOptions()\n+            .setHost(\"localhost\")\n+            .setPort(8089)\n+            .setUseAlpn(true)\n+            .setSsl(true)\n+            .setPemKeyCertOptions(\n+                new PemKeyCertOptions().setKeyPath(findFilePath(\"test-server-key.pem\"))\n+                    .setCertPath(findFilePath(\"test-server-cert.pem\"))\n+            );", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa"}, "originalPosition": 87}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6e3ab13e06f480e63c038bd634fb050b27e979b7", "author": {"user": {"login": "purplefox", "name": "Tim Fox"}}, "url": "https://github.com/confluentinc/ksql/commit/6e3ab13e06f480e63c038bd634fb050b27e979b7", "committedDate": "2020-01-16T20:40:14Z", "message": "Implement bare bones server"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "92ac3ce0feac9acd143b159b24e085c57ada49aa", "author": {"user": {"login": "purplefox", "name": "Tim Fox"}}, "url": "https://github.com/confluentinc/ksql/commit/92ac3ce0feac9acd143b159b24e085c57ada49aa", "committedDate": "2020-01-16T11:05:26Z", "message": "use camel case for JSON properties"}, "afterCommit": {"oid": "6e3ab13e06f480e63c038bd634fb050b27e979b7", "author": {"user": {"login": "purplefox", "name": "Tim Fox"}}, "url": "https://github.com/confluentinc/ksql/commit/6e3ab13e06f480e63c038bd634fb050b27e979b7", "committedDate": "2020-01-16T20:40:14Z", "message": "Implement bare bones server"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "521fa777964c12a51492923ead5fdbf9d918f648", "author": {"user": {"login": "purplefox", "name": "Tim Fox"}}, "url": "https://github.com/confluentinc/ksql/commit/521fa777964c12a51492923ead5fdbf9d918f648", "committedDate": "2020-01-17T06:31:47Z", "message": "Updates from review"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "93e53febe73e22a9af84c510e6c3c6877f326d82", "author": {"user": {"login": "purplefox", "name": "Tim Fox"}}, "url": "https://github.com/confluentinc/ksql/commit/93e53febe73e22a9af84c510e6c3c6877f326d82", "committedDate": "2020-01-17T06:54:41Z", "message": "a few more updates"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "941a4ca39f1c9d0198948f02bcac4736f351239a", "author": {"user": {"login": "purplefox", "name": "Tim Fox"}}, "url": "https://github.com/confluentinc/ksql/commit/941a4ca39f1c9d0198948f02bcac4736f351239a", "committedDate": "2020-01-17T08:24:24Z", "message": "findbugs and checkstyle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e", "author": {"user": {"login": "purplefox", "name": "Tim Fox"}}, "url": "https://github.com/confluentinc/ksql/commit/1abba4b5eab82f21a93441721e3d988a1080248e", "committedDate": "2020-01-17T09:30:35Z", "message": "checkstyle"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ0NzQ3MjU5", "url": "https://github.com/confluentinc/ksql/pull/4320#pullrequestreview-344747259", "createdAt": "2020-01-17T18:00:54Z", "commit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "state": "COMMENTED", "comments": {"totalCount": 31, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QxODowMDo1NFrOFfA1ew==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QyMDowMzowNVrOFfD3sw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA2Mzg2Nw==", "bodyText": "nit: copyright date (on this and other new files)", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368063867", "createdAt": "2020-01-17T18:00:54Z", "author": {"login": "agavra"}, "path": "ksql-api/pom.xml", "diffHunk": "@@ -0,0 +1,114 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+  ~ Copyright 2018 Confluent Inc.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 3}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA2NDA3NQ==", "bodyText": "any reason this shouldn't be in the parent pom?", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368064075", "createdAt": "2020-01-17T18:01:26Z", "author": {"login": "agavra"}, "path": "ksql-api/pom.xml", "diffHunk": "@@ -0,0 +1,114 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+  ~ Copyright 2018 Confluent Inc.\n+  ~\n+  ~ Licensed under the Confluent Community License (the \"License\"); you may not use\n+  ~ this file except in compliance with the License.  You may obtain a copy of the\n+  ~ License at\n+  ~\n+  ~ http://www.confluent.io/confluent-community-license\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+  ~ WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+  ~ specific language governing permissions and limitations under the License.\n+  -->\n+\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n+  xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n+  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+  <modelVersion>4.0.0</modelVersion>\n+\n+\n+  <parent>\n+    <groupId>io.confluent.ksql</groupId>\n+    <artifactId>ksql-parent</artifactId>\n+    <version>5.5.0-SNAPSHOT</version>\n+  </parent>\n+\n+  <artifactId>ksql-api</artifactId>\n+\n+  <properties>\n+    <vertx.version>3.8.4</vertx.version>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA2NDI3Mg==", "bodyText": "nit: let's follow the pattern of declaring the version up top", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368064272", "createdAt": "2020-01-17T18:01:53Z", "author": {"login": "agavra"}, "path": "ksql-api/pom.xml", "diffHunk": "@@ -0,0 +1,114 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<!--\n+  ~ Copyright 2018 Confluent Inc.\n+  ~\n+  ~ Licensed under the Confluent Community License (the \"License\"); you may not use\n+  ~ this file except in compliance with the License.  You may obtain a copy of the\n+  ~ License at\n+  ~\n+  ~ http://www.confluent.io/confluent-community-license\n+  ~\n+  ~ Unless required by applicable law or agreed to in writing, software\n+  ~ distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+  ~ WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+  ~ specific language governing permissions and limitations under the License.\n+  -->\n+\n+<project xmlns=\"http://maven.apache.org/POM/4.0.0\"\n+  xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n+  xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\">\n+  <modelVersion>4.0.0</modelVersion>\n+\n+\n+  <parent>\n+    <groupId>io.confluent.ksql</groupId>\n+    <artifactId>ksql-parent</artifactId>\n+    <version>5.5.0-SNAPSHOT</version>\n+  </parent>\n+\n+  <artifactId>ksql-api</artifactId>\n+\n+  <properties>\n+    <vertx.version>3.8.4</vertx.version>\n+    <maven.compiler.source>1.8</maven.compiler.source>\n+    <maven.compiler.target>1.8</maven.compiler.target>\n+  </properties>\n+\n+  <dependencies>\n+    <dependency>\n+      <groupId>io.vertx</groupId>\n+      <artifactId>vertx-core</artifactId>\n+      <version>${vertx.version}</version>\n+    </dependency>\n+    <dependency>\n+      <groupId>io.vertx</groupId>\n+      <artifactId>vertx-codegen</artifactId>\n+      <version>${vertx.version}</version>\n+    </dependency>\n+    <dependency>\n+      <groupId>io.vertx</groupId>\n+      <artifactId>vertx-codegen</artifactId>\n+      <version>${vertx.version}</version>\n+    </dependency>\n+    <dependency>\n+      <groupId>io.vertx</groupId>\n+      <artifactId>vertx-web</artifactId>\n+      <version>${vertx.version}</version>\n+    </dependency>\n+    <dependency>\n+      <groupId>io.vertx</groupId>\n+      <artifactId>vertx-web-client</artifactId>\n+      <version>${vertx.version}</version>\n+    </dependency>\n+    <dependency>\n+      <groupId>io.netty</groupId>\n+      <artifactId>netty-tcnative-boringssl-static</artifactId>\n+      <version>2.0.28.Final</version>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA2NDc2Mw==", "bodyText": "javadoc please \ud83d\ude4f  unless this is some standard terminology I'm not aware of, I'm not sure what \"connecting a promise\" means", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368064763", "createdAt": "2020-01-17T18:03:08Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/impl/Utils.java", "diffHunk": "@@ -0,0 +1,40 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.impl;\n+\n+import io.vertx.core.Future;\n+import io.vertx.core.Promise;\n+\n+/**\n+ * General purpose utils (not limited to the server, could be used by client too) for the API\n+ * module.\n+ */\n+public final class Utils {\n+\n+  private Utils() {\n+  }\n+\n+  public static <T> void connectPromise(final Future<T> future, final Promise<T> promise) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA3NDAwNg==", "bodyText": "It took me some time to understand what this API does. Does it indicate that we've completed all the inserts we want to send? Do we expect it to be called more than once? Maybe we can name it requestClose(final long expectedAcks). Would also help to have javadoc around here.\nAlso instead of using a single Long to indicate two things: both that we should close and the value of acks expected, I think it would be safer (avoid unboxing a null value) and easier to read if we split it into a flag boolean closeRequested and long expectedAcks", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368074006", "createdAt": "2020-01-17T18:26:19Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerResponse;\n+import io.vertx.core.json.JsonObject;\n+import java.util.Objects;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * As the stream of inserts is processed by the back-end, it communicates success (or failure) of\n+ * each insert by sending a stream of acks back in the other direction. This class is the subscriber\n+ * which subscribes to that stream of acks and sends them back to the client. It's a reactive\n+ * streams subscriber so implements back pressure.\n+ */\n+public class AcksSubscriber implements Subscriber<Void> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n+  private static final int BATCH_SIZE = 4;\n+  private static final Buffer ACK_RESPONSE_LINE = new JsonObject().put(\"status\", \"ok\").toBuffer()\n+      .appendString(\"\\n\");\n+\n+  private final HttpServerResponse response;\n+  private Subscription subscription;\n+  private long tokens;\n+  private Long insertsSent;\n+  private long acksSent;\n+\n+  public AcksSubscriber(final HttpServerResponse response) {\n+    this.response = Objects.requireNonNull(response);\n+  }\n+\n+  @Override\n+  public synchronized void onSubscribe(final Subscription subscription) {\n+    Objects.requireNonNull(subscription);\n+    if (this.subscription != null) {\n+      throw new IllegalStateException(\"Already subscribed\");\n+    }\n+    this.subscription = subscription;\n+    checkRequestTokens();\n+  }\n+\n+  @Override\n+  public synchronized void onNext(final Void vo) {\n+    if (tokens == 0) {\n+      throw new IllegalStateException(\"Unsolicited data\");\n+    }\n+    response.write(ACK_RESPONSE_LINE);\n+    acksSent++;\n+    tokens--;\n+    if (insertsSent != null && insertsSent == acksSent) {\n+      close();\n+    } else if (response.writeQueueFull()) {\n+      response.drainHandler(v -> checkRequestTokens());\n+    } else {\n+      checkRequestTokens();\n+    }\n+  }\n+\n+  synchronized void insertsSent(final long num) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA3NTUzNQ==", "bodyText": "I'm unclear what this drainHandler method does. Looking at the JavaDoc it suggests that it sets the handler - is there any reason we need to set it every time the response queue fills up or can we just set it once on startup?", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368075535", "createdAt": "2020-01-17T18:30:10Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerResponse;\n+import io.vertx.core.json.JsonObject;\n+import java.util.Objects;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * As the stream of inserts is processed by the back-end, it communicates success (or failure) of\n+ * each insert by sending a stream of acks back in the other direction. This class is the subscriber\n+ * which subscribes to that stream of acks and sends them back to the client. It's a reactive\n+ * streams subscriber so implements back pressure.\n+ */\n+public class AcksSubscriber implements Subscriber<Void> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n+  private static final int BATCH_SIZE = 4;\n+  private static final Buffer ACK_RESPONSE_LINE = new JsonObject().put(\"status\", \"ok\").toBuffer()\n+      .appendString(\"\\n\");\n+\n+  private final HttpServerResponse response;\n+  private Subscription subscription;\n+  private long tokens;\n+  private Long insertsSent;\n+  private long acksSent;\n+\n+  public AcksSubscriber(final HttpServerResponse response) {\n+    this.response = Objects.requireNonNull(response);\n+  }\n+\n+  @Override\n+  public synchronized void onSubscribe(final Subscription subscription) {\n+    Objects.requireNonNull(subscription);\n+    if (this.subscription != null) {\n+      throw new IllegalStateException(\"Already subscribed\");\n+    }\n+    this.subscription = subscription;\n+    checkRequestTokens();\n+  }\n+\n+  @Override\n+  public synchronized void onNext(final Void vo) {\n+    if (tokens == 0) {\n+      throw new IllegalStateException(\"Unsolicited data\");\n+    }\n+    response.write(ACK_RESPONSE_LINE);\n+    acksSent++;\n+    tokens--;\n+    if (insertsSent != null && insertsSent == acksSent) {\n+      close();\n+    } else if (response.writeQueueFull()) {\n+      response.drainHandler(v -> checkRequestTokens());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 73}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA3NjgwNw==", "bodyText": "I thought I saw @big-andy-coates comment this somewhere, but I agree with him that it's better if we can have jackson POJOs for these (and the ACK_RESPONSE_LINE) so that the schema is clear and well defined. Something I've found very useful is to be able to go to a single package and see all of the serialized object schemas that we're sending (e.g. io.confluent.ksql.rest.entity). I understand this adds a little bulk, but I think it's worth it in this case.", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368076807", "createdAt": "2020-01-17T18:33:13Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerResponse;\n+import io.vertx.core.json.JsonObject;\n+import java.util.Objects;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * As the stream of inserts is processed by the back-end, it communicates success (or failure) of\n+ * each insert by sending a stream of acks back in the other direction. This class is the subscriber\n+ * which subscribes to that stream of acks and sends them back to the client. It's a reactive\n+ * streams subscriber so implements back pressure.\n+ */\n+public class AcksSubscriber implements Subscriber<Void> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n+  private static final int BATCH_SIZE = 4;\n+  private static final Buffer ACK_RESPONSE_LINE = new JsonObject().put(\"status\", \"ok\").toBuffer()\n+      .appendString(\"\\n\");\n+\n+  private final HttpServerResponse response;\n+  private Subscription subscription;\n+  private long tokens;\n+  private Long insertsSent;\n+  private long acksSent;\n+\n+  public AcksSubscriber(final HttpServerResponse response) {\n+    this.response = Objects.requireNonNull(response);\n+  }\n+\n+  @Override\n+  public synchronized void onSubscribe(final Subscription subscription) {\n+    Objects.requireNonNull(subscription);\n+    if (this.subscription != null) {\n+      throw new IllegalStateException(\"Already subscribed\");\n+    }\n+    this.subscription = subscription;\n+    checkRequestTokens();\n+  }\n+\n+  @Override\n+  public synchronized void onNext(final Void vo) {\n+    if (tokens == 0) {\n+      throw new IllegalStateException(\"Unsolicited data\");\n+    }\n+    response.write(ACK_RESPONSE_LINE);\n+    acksSent++;\n+    tokens--;\n+    if (insertsSent != null && insertsSent == acksSent) {\n+      close();\n+    } else if (response.writeQueueFull()) {\n+      response.drainHandler(v -> checkRequestTokens());\n+    } else {\n+      checkRequestTokens();\n+    }\n+  }\n+\n+  synchronized void insertsSent(final long num) {\n+    this.insertsSent = num;\n+    if (acksSent == num) {\n+      close();\n+    }\n+  }\n+\n+  private void close() {\n+    response.end();\n+    subscription.cancel();\n+  }\n+\n+  private void checkRequestTokens() {\n+    if (tokens == 0) {\n+      tokens = BATCH_SIZE;\n+      subscription.request(BATCH_SIZE);\n+    }\n+  }\n+\n+  @Override\n+  public synchronized void onError(final Throwable t) {\n+    log.error(\"Error in processing inserts\", t);\n+    final JsonObject err = new JsonObject().put(\"status\", \"error\")\n+        .put(\"errorCode\", ERROR_CODE_INTERNAL_ERROR)\n+        .put(\"message\", \"Error in processing inserts\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA3NzcyNw==", "bodyText": "if subscription.cancel is idempotent can we just call close here?", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368077727", "createdAt": "2020-01-17T18:35:29Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerResponse;\n+import io.vertx.core.json.JsonObject;\n+import java.util.Objects;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * As the stream of inserts is processed by the back-end, it communicates success (or failure) of\n+ * each insert by sending a stream of acks back in the other direction. This class is the subscriber\n+ * which subscribes to that stream of acks and sends them back to the client. It's a reactive\n+ * streams subscriber so implements back pressure.\n+ */\n+public class AcksSubscriber implements Subscriber<Void> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n+  private static final int BATCH_SIZE = 4;\n+  private static final Buffer ACK_RESPONSE_LINE = new JsonObject().put(\"status\", \"ok\").toBuffer()\n+      .appendString(\"\\n\");\n+\n+  private final HttpServerResponse response;\n+  private Subscription subscription;\n+  private long tokens;\n+  private Long insertsSent;\n+  private long acksSent;\n+\n+  public AcksSubscriber(final HttpServerResponse response) {\n+    this.response = Objects.requireNonNull(response);\n+  }\n+\n+  @Override\n+  public synchronized void onSubscribe(final Subscription subscription) {\n+    Objects.requireNonNull(subscription);\n+    if (this.subscription != null) {\n+      throw new IllegalStateException(\"Already subscribed\");\n+    }\n+    this.subscription = subscription;\n+    checkRequestTokens();\n+  }\n+\n+  @Override\n+  public synchronized void onNext(final Void vo) {\n+    if (tokens == 0) {\n+      throw new IllegalStateException(\"Unsolicited data\");\n+    }\n+    response.write(ACK_RESPONSE_LINE);\n+    acksSent++;\n+    tokens--;\n+    if (insertsSent != null && insertsSent == acksSent) {\n+      close();\n+    } else if (response.writeQueueFull()) {\n+      response.drainHandler(v -> checkRequestTokens());\n+    } else {\n+      checkRequestTokens();\n+    }\n+  }\n+\n+  synchronized void insertsSent(final long num) {\n+    this.insertsSent = num;\n+    if (acksSent == num) {\n+      close();\n+    }\n+  }\n+\n+  private void close() {\n+    response.end();\n+    subscription.cancel();\n+  }\n+\n+  private void checkRequestTokens() {\n+    if (tokens == 0) {\n+      tokens = BATCH_SIZE;\n+      subscription.request(BATCH_SIZE);\n+    }\n+  }\n+\n+  @Override\n+  public synchronized void onError(final Throwable t) {\n+    log.error(\"Error in processing inserts\", t);\n+    final JsonObject err = new JsonObject().put(\"status\", \"error\")\n+        .put(\"errorCode\", ERROR_CODE_INTERNAL_ERROR)\n+        .put(\"message\", \"Error in processing inserts\");\n+    subscription.cancel();\n+    response.end(err.toBuffer());\n+  }\n+\n+  @Override\n+  public synchronized void onComplete() {\n+    response.end();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 110}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA3ODExMw==", "bodyText": "does the drainHandler trigger asyncrhonously? if so this method may also need to be synchronized", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368078113", "createdAt": "2020-01-17T18:36:22Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n+\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.http.HttpServerResponse;\n+import io.vertx.core.json.JsonObject;\n+import java.util.Objects;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * As the stream of inserts is processed by the back-end, it communicates success (or failure) of\n+ * each insert by sending a stream of acks back in the other direction. This class is the subscriber\n+ * which subscribes to that stream of acks and sends them back to the client. It's a reactive\n+ * streams subscriber so implements back pressure.\n+ */\n+public class AcksSubscriber implements Subscriber<Void> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n+  private static final int BATCH_SIZE = 4;\n+  private static final Buffer ACK_RESPONSE_LINE = new JsonObject().put(\"status\", \"ok\").toBuffer()\n+      .appendString(\"\\n\");\n+\n+  private final HttpServerResponse response;\n+  private Subscription subscription;\n+  private long tokens;\n+  private Long insertsSent;\n+  private long acksSent;\n+\n+  public AcksSubscriber(final HttpServerResponse response) {\n+    this.response = Objects.requireNonNull(response);\n+  }\n+\n+  @Override\n+  public synchronized void onSubscribe(final Subscription subscription) {\n+    Objects.requireNonNull(subscription);\n+    if (this.subscription != null) {\n+      throw new IllegalStateException(\"Already subscribed\");\n+    }\n+    this.subscription = subscription;\n+    checkRequestTokens();\n+  }\n+\n+  @Override\n+  public synchronized void onNext(final Void vo) {\n+    if (tokens == 0) {\n+      throw new IllegalStateException(\"Unsolicited data\");\n+    }\n+    response.write(ACK_RESPONSE_LINE);\n+    acksSent++;\n+    tokens--;\n+    if (insertsSent != null && insertsSent == acksSent) {\n+      close();\n+    } else if (response.writeQueueFull()) {\n+      response.drainHandler(v -> checkRequestTokens());\n+    } else {\n+      checkRequestTokens();\n+    }\n+  }\n+\n+  synchronized void insertsSent(final long num) {\n+    this.insertsSent = num;\n+    if (acksSent == num) {\n+      close();\n+    }\n+  }\n+\n+  private void close() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA4MDMwNw==", "bodyText": "nit: since this is a \"public\" API, it might benefit from giving an example so people don't need to grok descriptions", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368080307", "createdAt": "2020-01-17T18:41:59Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyParser.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.InsertsSubscriber;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.ext.web.RoutingContext;\n+import java.util.Objects;\n+\n+/**\n+ * This class handles the parsing of the request body for a stream of inserts. The user can send a\n+ * stream of inserts to the server by opening an HTTP2 request to the server at the appropriate uri\n+ * and POSTing a request. The request must contain an initial JSON object (encoded as UTF-8 text)\n+ * which contains the arguments for the request (e.g. the target to insert into, and whether acks\n+ * are wanted) This must be followed by a new line, and then followed by zero or more JSON objects\n+ * (also encoded as UTF-8 text) each representing a row to insert. The last JSON object must be\n+ * followed by a new-line.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA4MDc3Mw==", "bodyText": "does this need to be synchronized with handleBodyBuffer or is it impossible that they will come in concurrently?", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368080773", "createdAt": "2020-01-17T18:43:03Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyParser.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.InsertsSubscriber;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.ext.web.RoutingContext;\n+import java.util.Objects;\n+\n+/**\n+ * This class handles the parsing of the request body for a stream of inserts. The user can send a\n+ * stream of inserts to the server by opening an HTTP2 request to the server at the appropriate uri\n+ * and POSTing a request. The request must contain an initial JSON object (encoded as UTF-8 text)\n+ * which contains the arguments for the request (e.g. the target to insert into, and whether acks\n+ * are wanted) This must be followed by a new line, and then followed by zero or more JSON objects\n+ * (also encoded as UTF-8 text) each representing a row to insert. The last JSON object must be\n+ * followed by a new-line.\n+ */\n+public class InsertsBodyParser {\n+\n+  private final Endpoints endpoints;\n+  private final RoutingContext routingContext;\n+  private boolean readArguments;\n+  private InsertsPublisher publisher;\n+  private long rowsReceived;\n+  private AcksSubscriber acksSubscriber;\n+\n+  public InsertsBodyParser(final Endpoints endpoints, final RoutingContext routingContext) {\n+    this.endpoints = Objects.requireNonNull(endpoints);\n+    this.routingContext = Objects.requireNonNull(routingContext);\n+    routingContext.response().endHandler(v -> {\n+      if (publisher != null) {\n+        publisher.close();\n+      }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA4MTgxNw==", "bodyText": "personal preference and totally unenforceable (so feel free to disagree) but I would be made very happy if we added some white space in this method to split up logical components \ud83d\ude02 code without whitespace feels like a run-on sentence", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368081817", "createdAt": "2020-01-17T18:45:50Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyParser.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.InsertsSubscriber;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.ext.web.RoutingContext;\n+import java.util.Objects;\n+\n+/**\n+ * This class handles the parsing of the request body for a stream of inserts. The user can send a\n+ * stream of inserts to the server by opening an HTTP2 request to the server at the appropriate uri\n+ * and POSTing a request. The request must contain an initial JSON object (encoded as UTF-8 text)\n+ * which contains the arguments for the request (e.g. the target to insert into, and whether acks\n+ * are wanted) This must be followed by a new line, and then followed by zero or more JSON objects\n+ * (also encoded as UTF-8 text) each representing a row to insert. The last JSON object must be\n+ * followed by a new-line.\n+ */\n+public class InsertsBodyParser {\n+\n+  private final Endpoints endpoints;\n+  private final RoutingContext routingContext;\n+  private boolean readArguments;\n+  private InsertsPublisher publisher;\n+  private long rowsReceived;\n+  private AcksSubscriber acksSubscriber;\n+\n+  public InsertsBodyParser(final Endpoints endpoints, final RoutingContext routingContext) {\n+    this.endpoints = Objects.requireNonNull(endpoints);\n+    this.routingContext = Objects.requireNonNull(routingContext);\n+    routingContext.response().endHandler(v -> {\n+      if (publisher != null) {\n+        publisher.close();\n+      }\n+    });\n+  }\n+\n+  public void handleBodyEnd(final Void v) {\n+    if (acksSubscriber == null) {\n+      routingContext.response().end();\n+    } else {\n+      // We close the response after the stream of acks has been sent\n+      acksSubscriber.insertsSent(rowsReceived);\n+    }\n+  }\n+\n+  public void handleBodyBuffer(final Buffer buff) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA4MjI0MQ==", "bodyText": "same comment as above - it would be nice to have Jackson handle this schema validation for us (and as a way of documenting the public API programmatically)", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368082241", "createdAt": "2020-01-17T18:46:53Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyParser.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.InsertsSubscriber;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.ext.web.RoutingContext;\n+import java.util.Objects;\n+\n+/**\n+ * This class handles the parsing of the request body for a stream of inserts. The user can send a\n+ * stream of inserts to the server by opening an HTTP2 request to the server at the appropriate uri\n+ * and POSTing a request. The request must contain an initial JSON object (encoded as UTF-8 text)\n+ * which contains the arguments for the request (e.g. the target to insert into, and whether acks\n+ * are wanted) This must be followed by a new line, and then followed by zero or more JSON objects\n+ * (also encoded as UTF-8 text) each representing a row to insert. The last JSON object must be\n+ * followed by a new-line.\n+ */\n+public class InsertsBodyParser {\n+\n+  private final Endpoints endpoints;\n+  private final RoutingContext routingContext;\n+  private boolean readArguments;\n+  private InsertsPublisher publisher;\n+  private long rowsReceived;\n+  private AcksSubscriber acksSubscriber;\n+\n+  public InsertsBodyParser(final Endpoints endpoints, final RoutingContext routingContext) {\n+    this.endpoints = Objects.requireNonNull(endpoints);\n+    this.routingContext = Objects.requireNonNull(routingContext);\n+    routingContext.response().endHandler(v -> {\n+      if (publisher != null) {\n+        publisher.close();\n+      }\n+    });\n+  }\n+\n+  public void handleBodyEnd(final Void v) {\n+    if (acksSubscriber == null) {\n+      routingContext.response().end();\n+    } else {\n+      // We close the response after the stream of acks has been sent\n+      acksSubscriber.insertsSent(rowsReceived);\n+    }\n+  }\n+\n+  public void handleBodyBuffer(final Buffer buff) {\n+    if (!readArguments) {\n+      final JsonObject args = new JsonObject(buff);\n+      readArguments = true;\n+      final String target = args.getString(\"target\");\n+      if (target == null) {\n+        handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM,\n+            \"No target in arguments\");\n+        return;\n+      }\n+      final Boolean acks = args.getBoolean(\"acks\");\n+      if (acks == null) {\n+        handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM,\n+            \"No acks in arguments\");\n+        return;\n+      }\n+      final JsonObject properties = args.getJsonObject(\"properties\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 81}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA4MjUyOA==", "bodyText": "we should name this something like requireAcks - acks sounds like a count of acks, not a boolean. Since this is public API I do feel like it's important to make it extra clear", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368082528", "createdAt": "2020-01-17T18:47:38Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyParser.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.InsertsSubscriber;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.ext.web.RoutingContext;\n+import java.util.Objects;\n+\n+/**\n+ * This class handles the parsing of the request body for a stream of inserts. The user can send a\n+ * stream of inserts to the server by opening an HTTP2 request to the server at the appropriate uri\n+ * and POSTing a request. The request must contain an initial JSON object (encoded as UTF-8 text)\n+ * which contains the arguments for the request (e.g. the target to insert into, and whether acks\n+ * are wanted) This must be followed by a new line, and then followed by zero or more JSON objects\n+ * (also encoded as UTF-8 text) each representing a row to insert. The last JSON object must be\n+ * followed by a new-line.\n+ */\n+public class InsertsBodyParser {\n+\n+  private final Endpoints endpoints;\n+  private final RoutingContext routingContext;\n+  private boolean readArguments;\n+  private InsertsPublisher publisher;\n+  private long rowsReceived;\n+  private AcksSubscriber acksSubscriber;\n+\n+  public InsertsBodyParser(final Endpoints endpoints, final RoutingContext routingContext) {\n+    this.endpoints = Objects.requireNonNull(endpoints);\n+    this.routingContext = Objects.requireNonNull(routingContext);\n+    routingContext.response().endHandler(v -> {\n+      if (publisher != null) {\n+        publisher.close();\n+      }\n+    });\n+  }\n+\n+  public void handleBodyEnd(final Void v) {\n+    if (acksSubscriber == null) {\n+      routingContext.response().end();\n+    } else {\n+      // We close the response after the stream of acks has been sent\n+      acksSubscriber.insertsSent(rowsReceived);\n+    }\n+  }\n+\n+  public void handleBodyBuffer(final Buffer buff) {\n+    if (!readArguments) {\n+      final JsonObject args = new JsonObject(buff);\n+      readArguments = true;\n+      final String target = args.getString(\"target\");\n+      if (target == null) {\n+        handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM,\n+            \"No target in arguments\");\n+        return;\n+      }\n+      final Boolean acks = args.getBoolean(\"acks\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA4NDk3OA==", "bodyText": "nit s/readArguments/hasReadArguments/ because the past tense and command form of \"read\" are the spelled same \ud83d\ude02", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368084978", "createdAt": "2020-01-17T18:53:23Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyParser.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.InsertsSubscriber;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.ext.web.RoutingContext;\n+import java.util.Objects;\n+\n+/**\n+ * This class handles the parsing of the request body for a stream of inserts. The user can send a\n+ * stream of inserts to the server by opening an HTTP2 request to the server at the appropriate uri\n+ * and POSTing a request. The request must contain an initial JSON object (encoded as UTF-8 text)\n+ * which contains the arguments for the request (e.g. the target to insert into, and whether acks\n+ * are wanted) This must be followed by a new line, and then followed by zero or more JSON objects\n+ * (also encoded as UTF-8 text) each representing a row to insert. The last JSON object must be\n+ * followed by a new-line.\n+ */\n+public class InsertsBodyParser {\n+\n+  private final Endpoints endpoints;\n+  private final RoutingContext routingContext;\n+  private boolean readArguments;\n+  private InsertsPublisher publisher;\n+  private long rowsReceived;\n+  private AcksSubscriber acksSubscriber;\n+\n+  public InsertsBodyParser(final Endpoints endpoints, final RoutingContext routingContext) {\n+    this.endpoints = Objects.requireNonNull(endpoints);\n+    this.routingContext = Objects.requireNonNull(routingContext);\n+    routingContext.response().endHandler(v -> {\n+      if (publisher != null) {\n+        publisher.close();\n+      }\n+    });\n+  }\n+\n+  public void handleBodyEnd(final Void v) {\n+    if (acksSubscriber == null) {\n+      routingContext.response().end();\n+    } else {\n+      // We close the response after the stream of acks has been sent\n+      acksSubscriber.insertsSent(rowsReceived);\n+    }\n+  }\n+\n+  public void handleBodyBuffer(final Buffer buff) {\n+    if (!readArguments) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA4NTQ0MA==", "bodyText": "I'm trying to understand the control flow here - if readArguments is true, and publisher is null (say because we handled an error) then should we be receiving any more body buffers? maybe we should throw an exception in a final else clause", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368085440", "createdAt": "2020-01-17T18:54:27Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyParser.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.InsertsSubscriber;\n+import io.vertx.core.buffer.Buffer;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.ext.web.RoutingContext;\n+import java.util.Objects;\n+\n+/**\n+ * This class handles the parsing of the request body for a stream of inserts. The user can send a\n+ * stream of inserts to the server by opening an HTTP2 request to the server at the appropriate uri\n+ * and POSTing a request. The request must contain an initial JSON object (encoded as UTF-8 text)\n+ * which contains the arguments for the request (e.g. the target to insert into, and whether acks\n+ * are wanted) This must be followed by a new line, and then followed by zero or more JSON objects\n+ * (also encoded as UTF-8 text) each representing a row to insert. The last JSON object must be\n+ * followed by a new-line.\n+ */\n+public class InsertsBodyParser {\n+\n+  private final Endpoints endpoints;\n+  private final RoutingContext routingContext;\n+  private boolean readArguments;\n+  private InsertsPublisher publisher;\n+  private long rowsReceived;\n+  private AcksSubscriber acksSubscriber;\n+\n+  public InsertsBodyParser(final Endpoints endpoints, final RoutingContext routingContext) {\n+    this.endpoints = Objects.requireNonNull(endpoints);\n+    this.routingContext = Objects.requireNonNull(routingContext);\n+    routingContext.response().endHandler(v -> {\n+      if (publisher != null) {\n+        publisher.close();\n+      }\n+    });\n+  }\n+\n+  public void handleBodyEnd(final Void v) {\n+    if (acksSubscriber == null) {\n+      routingContext.response().end();\n+    } else {\n+      // We close the response after the stream of acks has been sent\n+      acksSubscriber.insertsSent(rowsReceived);\n+    }\n+  }\n+\n+  public void handleBodyBuffer(final Buffer buff) {\n+    if (!readArguments) {\n+      final JsonObject args = new JsonObject(buff);\n+      readArguments = true;\n+      final String target = args.getString(\"target\");\n+      if (target == null) {\n+        handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM,\n+            \"No target in arguments\");\n+        return;\n+      }\n+      final Boolean acks = args.getBoolean(\"acks\");\n+      if (acks == null) {\n+        handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM,\n+            \"No acks in arguments\");\n+        return;\n+      }\n+      final JsonObject properties = args.getJsonObject(\"properties\");\n+      routingContext.request().endHandler(this::handleBodyEnd);\n+      acksSubscriber = acks ? new AcksSubscriber(routingContext.response()) : null;\n+      final InsertsSubscriber insertsSubscriber = endpoints\n+          .createInsertsSubscriber(target, properties, acksSubscriber);\n+      publisher = new InsertsPublisher();\n+      publisher.subscribe(insertsSubscriber);\n+    } else if (publisher != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwMTg4NQ==", "bodyText": "can this be private?", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368101885", "createdAt": "2020-01-17T19:33:52Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsPublisher.java", "diffHunk": "@@ -0,0 +1,83 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.json.JsonObject;\n+import java.util.LinkedList;\n+import java.util.Objects;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+\n+/**\n+ * This class is a reactive streams publisher which publishes the inserts to a subscriber which is\n+ * provided by the back-end. As it's reactive streams it supports back pressure.\n+ */\n+public class InsertsPublisher implements Publisher<JsonObject> {\n+\n+  private final Queue<JsonObject> buffer = new LinkedList<>();\n+  private long demand;\n+  private Subscriber<? super JsonObject> subscriber;\n+\n+  @Override\n+  public synchronized void subscribe(final Subscriber<? super JsonObject> subscriber) {\n+    this.subscriber = Objects.requireNonNull(subscriber);\n+    subscriber.onSubscribe(new InsertsSubscription());\n+  }\n+\n+  public synchronized void receiveRow(final JsonObject row) {\n+    if (subscriber == null) {\n+      return;\n+    }\n+    if (demand > 0) {\n+      demand--;\n+      subscriber.onNext(row);\n+    } else {\n+      buffer.add(row);\n+    }\n+  }\n+\n+  synchronized void acceptTokens(final long number) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwMzQ0MQ==", "bodyText": "what happens if demand goes below 0. Is that Okay?", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368103441", "createdAt": "2020-01-17T19:37:50Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsPublisher.java", "diffHunk": "@@ -0,0 +1,83 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.json.JsonObject;\n+import java.util.LinkedList;\n+import java.util.Objects;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+\n+/**\n+ * This class is a reactive streams publisher which publishes the inserts to a subscriber which is\n+ * provided by the back-end. As it's reactive streams it supports back pressure.\n+ */\n+public class InsertsPublisher implements Publisher<JsonObject> {\n+\n+  private final Queue<JsonObject> buffer = new LinkedList<>();\n+  private long demand;\n+  private Subscriber<? super JsonObject> subscriber;\n+\n+  @Override\n+  public synchronized void subscribe(final Subscriber<? super JsonObject> subscriber) {\n+    this.subscriber = Objects.requireNonNull(subscriber);\n+    subscriber.onSubscribe(new InsertsSubscription());\n+  }\n+\n+  public synchronized void receiveRow(final JsonObject row) {\n+    if (subscriber == null) {\n+      return;\n+    }\n+    if (demand > 0) {\n+      demand--;\n+      subscriber.onNext(row);\n+    } else {\n+      buffer.add(row);\n+    }\n+  }\n+\n+  synchronized void acceptTokens(final long number) {\n+    demand += number;\n+    for (int i = 0; i < buffer.size(); i++) {\n+      final JsonObject row = buffer.poll();\n+      demand--;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwNDIwNw==", "bodyText": "since this is a blocking operation, does it need to be inside the synchronized block? I'm worried all of these interlocking synchronized calls may cause some deadlocks at some point \ud83d\ude02 perhaps we can cross that bridge when we get there though", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368104207", "createdAt": "2020-01-17T19:39:44Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsPublisher.java", "diffHunk": "@@ -0,0 +1,83 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.json.JsonObject;\n+import java.util.LinkedList;\n+import java.util.Objects;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+\n+/**\n+ * This class is a reactive streams publisher which publishes the inserts to a subscriber which is\n+ * provided by the back-end. As it's reactive streams it supports back pressure.\n+ */\n+public class InsertsPublisher implements Publisher<JsonObject> {\n+\n+  private final Queue<JsonObject> buffer = new LinkedList<>();\n+  private long demand;\n+  private Subscriber<? super JsonObject> subscriber;\n+\n+  @Override\n+  public synchronized void subscribe(final Subscriber<? super JsonObject> subscriber) {\n+    this.subscriber = Objects.requireNonNull(subscriber);\n+    subscriber.onSubscribe(new InsertsSubscription());\n+  }\n+\n+  public synchronized void receiveRow(final JsonObject row) {\n+    if (subscriber == null) {\n+      return;\n+    }\n+    if (demand > 0) {\n+      demand--;\n+      subscriber.onNext(row);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwNDMwMA==", "bodyText": "nit: 2020", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368104300", "createdAt": "2020-01-17T19:39:57Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/QueryID.java", "diffHunk": "@@ -0,0 +1,60 @@\n+/*\n+ * Copyright 2019 Confluent Inc.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 2}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwNDcxMQ==", "bodyText": "We already have a QueryID class in the code base - can we name this something more descriptive? Maybe this one should be ClientQueryId and the other PersistentQueryId", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368104711", "createdAt": "2020-01-17T19:40:55Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/QueryID.java", "diffHunk": "@@ -0,0 +1,60 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import java.util.Objects;\n+import java.util.UUID;\n+\n+/**\n+ * Handle to a query that is passed to the client on query creation and can subsequently be used to\n+ * close a query. Uses UUID.randomUUID() which internally uses SecureRandom - this makes the id\n+ * cryptographically secure. This is important as we don't want random users guessing query IDs and\n+ * closing other peoples queries.\n+ */\n+public final class QueryID {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwNTg2MA==", "bodyText": "same comment as above - whitespace please if you're so kind \ud83d\ude4f", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368105860", "createdAt": "2020-01-17T19:43:48Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.util.KsqlException;\n+import io.vertx.core.DeploymentOptions;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.impl.ConcurrentHashSet;\n+import io.vertx.core.json.JsonObject;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class represents the API server. On start-up it deploys multiple server verticles to spread\n+ * the load across available cores.\n+ */\n+public class Server {\n+\n+  private static final Logger log = LoggerFactory.getLogger(Server.class);\n+\n+  private final Vertx vertx;\n+  private final JsonObject config;\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Map<QueryID, QuerySubscriber> queries = new ConcurrentHashMap<>();\n+  private final Set<HttpConnection> connections = new ConcurrentHashSet<>();\n+  private String deploymentID;\n+\n+  public Server(final Vertx vertx, final JsonObject config, final Endpoints endpoints,\n+      final HttpServerOptions httpServerOptions) {\n+    this.vertx = Objects.requireNonNull(vertx);\n+    this.config = Objects.requireNonNull(config);\n+    this.endpoints = Objects.requireNonNull(endpoints);\n+    this.httpServerOptions = Objects.requireNonNull(httpServerOptions);\n+  }\n+\n+  public synchronized void start() {\n+    if (deploymentID != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwNjI1NQ==", "bodyText": "nit: ksql configurations are usually . separated or camel case (e.g. ksql.vertex.verticleInstances", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368106255", "createdAt": "2020-01-17T19:44:50Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.util.KsqlException;\n+import io.vertx.core.DeploymentOptions;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.impl.ConcurrentHashSet;\n+import io.vertx.core.json.JsonObject;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class represents the API server. On start-up it deploys multiple server verticles to spread\n+ * the load across available cores.\n+ */\n+public class Server {\n+\n+  private static final Logger log = LoggerFactory.getLogger(Server.class);\n+\n+  private final Vertx vertx;\n+  private final JsonObject config;\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Map<QueryID, QuerySubscriber> queries = new ConcurrentHashMap<>();\n+  private final Set<HttpConnection> connections = new ConcurrentHashSet<>();\n+  private String deploymentID;\n+\n+  public Server(final Vertx vertx, final JsonObject config, final Endpoints endpoints,\n+      final HttpServerOptions httpServerOptions) {\n+    this.vertx = Objects.requireNonNull(vertx);\n+    this.config = Objects.requireNonNull(config);\n+    this.endpoints = Objects.requireNonNull(endpoints);\n+    this.httpServerOptions = Objects.requireNonNull(httpServerOptions);\n+  }\n+\n+  public synchronized void start() {\n+    if (deploymentID != null) {\n+      throw new IllegalStateException(\"Already started\");\n+    }\n+    final DeploymentOptions options = new DeploymentOptions();\n+    final Integer verticleInstances = config.getInteger(\"verticle-instances\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwNjcxOQ==", "bodyText": "can we just return? if we never started do we need to throw an exception?", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368106719", "createdAt": "2020-01-17T19:45:51Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.util.KsqlException;\n+import io.vertx.core.DeploymentOptions;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.impl.ConcurrentHashSet;\n+import io.vertx.core.json.JsonObject;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class represents the API server. On start-up it deploys multiple server verticles to spread\n+ * the load across available cores.\n+ */\n+public class Server {\n+\n+  private static final Logger log = LoggerFactory.getLogger(Server.class);\n+\n+  private final Vertx vertx;\n+  private final JsonObject config;\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Map<QueryID, QuerySubscriber> queries = new ConcurrentHashMap<>();\n+  private final Set<HttpConnection> connections = new ConcurrentHashSet<>();\n+  private String deploymentID;\n+\n+  public Server(final Vertx vertx, final JsonObject config, final Endpoints endpoints,\n+      final HttpServerOptions httpServerOptions) {\n+    this.vertx = Objects.requireNonNull(vertx);\n+    this.config = Objects.requireNonNull(config);\n+    this.endpoints = Objects.requireNonNull(endpoints);\n+    this.httpServerOptions = Objects.requireNonNull(httpServerOptions);\n+  }\n+\n+  public synchronized void start() {\n+    if (deploymentID != null) {\n+      throw new IllegalStateException(\"Already started\");\n+    }\n+    final DeploymentOptions options = new DeploymentOptions();\n+    final Integer verticleInstances = config.getInteger(\"verticle-instances\");\n+    if (verticleInstances == null) {\n+      options.setInstances(Runtime.getRuntime().availableProcessors() * 2);\n+    } else {\n+      options.setInstances(verticleInstances);\n+    }\n+    log.info(\"Deploying \" + options.getInstances() + \" instances of server verticle\");\n+    options.setConfig(config);\n+    final VertxCompletableFuture<String> future = new VertxCompletableFuture<>();\n+    vertx.deployVerticle(\n+        () -> new ServerVerticle(endpoints, httpServerOptions, this), options, future);\n+    try {\n+      deploymentID = future.get();\n+    } catch (Exception e) {\n+      throw new KsqlException(\"Failed to start API server\", e);\n+    }\n+    log.info(\"API server started: \" + deploymentID);\n+  }\n+\n+  public synchronized void stop() {\n+    if (deploymentID == null) {\n+      throw new IllegalStateException(\"Not started\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwNzI1MA==", "bodyText": "I think it could be nice to model this using Guava's AbstractIdleService which handles transitions between nascent, starting, running, shutting down, shutdown and failure. We can add a ticket for this to be done in the future", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368107250", "createdAt": "2020-01-17T19:47:13Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.util.KsqlException;\n+import io.vertx.core.DeploymentOptions;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.impl.ConcurrentHashSet;\n+import io.vertx.core.json.JsonObject;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class represents the API server. On start-up it deploys multiple server verticles to spread\n+ * the load across available cores.\n+ */\n+public class Server {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwNzk5Ng==", "bodyText": "putIfAbsent to avoid races in the (very) unlikely chance of a collision", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368107996", "createdAt": "2020-01-17T19:49:06Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.util.KsqlException;\n+import io.vertx.core.DeploymentOptions;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.impl.ConcurrentHashSet;\n+import io.vertx.core.json.JsonObject;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class represents the API server. On start-up it deploys multiple server verticles to spread\n+ * the load across available cores.\n+ */\n+public class Server {\n+\n+  private static final Logger log = LoggerFactory.getLogger(Server.class);\n+\n+  private final Vertx vertx;\n+  private final JsonObject config;\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Map<QueryID, QuerySubscriber> queries = new ConcurrentHashMap<>();\n+  private final Set<HttpConnection> connections = new ConcurrentHashSet<>();\n+  private String deploymentID;\n+\n+  public Server(final Vertx vertx, final JsonObject config, final Endpoints endpoints,\n+      final HttpServerOptions httpServerOptions) {\n+    this.vertx = Objects.requireNonNull(vertx);\n+    this.config = Objects.requireNonNull(config);\n+    this.endpoints = Objects.requireNonNull(endpoints);\n+    this.httpServerOptions = Objects.requireNonNull(httpServerOptions);\n+  }\n+\n+  public synchronized void start() {\n+    if (deploymentID != null) {\n+      throw new IllegalStateException(\"Already started\");\n+    }\n+    final DeploymentOptions options = new DeploymentOptions();\n+    final Integer verticleInstances = config.getInteger(\"verticle-instances\");\n+    if (verticleInstances == null) {\n+      options.setInstances(Runtime.getRuntime().availableProcessors() * 2);\n+    } else {\n+      options.setInstances(verticleInstances);\n+    }\n+    log.info(\"Deploying \" + options.getInstances() + \" instances of server verticle\");\n+    options.setConfig(config);\n+    final VertxCompletableFuture<String> future = new VertxCompletableFuture<>();\n+    vertx.deployVerticle(\n+        () -> new ServerVerticle(endpoints, httpServerOptions, this), options, future);\n+    try {\n+      deploymentID = future.get();\n+    } catch (Exception e) {\n+      throw new KsqlException(\"Failed to start API server\", e);\n+    }\n+    log.info(\"API server started: \" + deploymentID);\n+  }\n+\n+  public synchronized void stop() {\n+    if (deploymentID == null) {\n+      throw new IllegalStateException(\"Not started\");\n+    }\n+    final VertxCompletableFuture<Void> future = new VertxCompletableFuture<>();\n+    vertx.undeploy(deploymentID, future);\n+    try {\n+      future.get();\n+    } catch (Exception e) {\n+      throw new KsqlException(\"Failure in stopping API server\", e);\n+    }\n+  }\n+\n+  QueryID registerQuery(final QuerySubscriber querySubscriber) {\n+    Objects.requireNonNull(querySubscriber);\n+    final QueryID queryID = new QueryID();\n+    queries.put(queryID, querySubscriber);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 99}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwODM2Mw==", "bodyText": "we should document that this can return null if the query doesnt' exist (or maybe instead just return an Optional to indicate that)", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368108363", "createdAt": "2020-01-17T19:50:02Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.util.KsqlException;\n+import io.vertx.core.DeploymentOptions;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.impl.ConcurrentHashSet;\n+import io.vertx.core.json.JsonObject;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class represents the API server. On start-up it deploys multiple server verticles to spread\n+ * the load across available cores.\n+ */\n+public class Server {\n+\n+  private static final Logger log = LoggerFactory.getLogger(Server.class);\n+\n+  private final Vertx vertx;\n+  private final JsonObject config;\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Map<QueryID, QuerySubscriber> queries = new ConcurrentHashMap<>();\n+  private final Set<HttpConnection> connections = new ConcurrentHashSet<>();\n+  private String deploymentID;\n+\n+  public Server(final Vertx vertx, final JsonObject config, final Endpoints endpoints,\n+      final HttpServerOptions httpServerOptions) {\n+    this.vertx = Objects.requireNonNull(vertx);\n+    this.config = Objects.requireNonNull(config);\n+    this.endpoints = Objects.requireNonNull(endpoints);\n+    this.httpServerOptions = Objects.requireNonNull(httpServerOptions);\n+  }\n+\n+  public synchronized void start() {\n+    if (deploymentID != null) {\n+      throw new IllegalStateException(\"Already started\");\n+    }\n+    final DeploymentOptions options = new DeploymentOptions();\n+    final Integer verticleInstances = config.getInteger(\"verticle-instances\");\n+    if (verticleInstances == null) {\n+      options.setInstances(Runtime.getRuntime().availableProcessors() * 2);\n+    } else {\n+      options.setInstances(verticleInstances);\n+    }\n+    log.info(\"Deploying \" + options.getInstances() + \" instances of server verticle\");\n+    options.setConfig(config);\n+    final VertxCompletableFuture<String> future = new VertxCompletableFuture<>();\n+    vertx.deployVerticle(\n+        () -> new ServerVerticle(endpoints, httpServerOptions, this), options, future);\n+    try {\n+      deploymentID = future.get();\n+    } catch (Exception e) {\n+      throw new KsqlException(\"Failed to start API server\", e);\n+    }\n+    log.info(\"API server started: \" + deploymentID);\n+  }\n+\n+  public synchronized void stop() {\n+    if (deploymentID == null) {\n+      throw new IllegalStateException(\"Not started\");\n+    }\n+    final VertxCompletableFuture<Void> future = new VertxCompletableFuture<>();\n+    vertx.undeploy(deploymentID, future);\n+    try {\n+      future.get();\n+    } catch (Exception e) {\n+      throw new KsqlException(\"Failure in stopping API server\", e);\n+    }\n+  }\n+\n+  QueryID registerQuery(final QuerySubscriber querySubscriber) {\n+    Objects.requireNonNull(querySubscriber);\n+    final QueryID queryID = new QueryID();\n+    queries.put(queryID, querySubscriber);\n+    return queryID;\n+  }\n+\n+  QuerySubscriber removeQuery(final QueryID queryID) {\n+    return queries.remove(queryID);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 104}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwODU0OA==", "bodyText": "Maybe ImmutableSet.copyOf?", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368108548", "createdAt": "2020-01-17T19:50:31Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.confluent.ksql.api.impl.VertxCompletableFuture;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.util.KsqlException;\n+import io.vertx.core.DeploymentOptions;\n+import io.vertx.core.Vertx;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.impl.ConcurrentHashSet;\n+import io.vertx.core.json.JsonObject;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * This class represents the API server. On start-up it deploys multiple server verticles to spread\n+ * the load across available cores.\n+ */\n+public class Server {\n+\n+  private static final Logger log = LoggerFactory.getLogger(Server.class);\n+\n+  private final Vertx vertx;\n+  private final JsonObject config;\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Map<QueryID, QuerySubscriber> queries = new ConcurrentHashMap<>();\n+  private final Set<HttpConnection> connections = new ConcurrentHashSet<>();\n+  private String deploymentID;\n+\n+  public Server(final Vertx vertx, final JsonObject config, final Endpoints endpoints,\n+      final HttpServerOptions httpServerOptions) {\n+    this.vertx = Objects.requireNonNull(vertx);\n+    this.config = Objects.requireNonNull(config);\n+    this.endpoints = Objects.requireNonNull(endpoints);\n+    this.httpServerOptions = Objects.requireNonNull(httpServerOptions);\n+  }\n+\n+  public synchronized void start() {\n+    if (deploymentID != null) {\n+      throw new IllegalStateException(\"Already started\");\n+    }\n+    final DeploymentOptions options = new DeploymentOptions();\n+    final Integer verticleInstances = config.getInteger(\"verticle-instances\");\n+    if (verticleInstances == null) {\n+      options.setInstances(Runtime.getRuntime().availableProcessors() * 2);\n+    } else {\n+      options.setInstances(verticleInstances);\n+    }\n+    log.info(\"Deploying \" + options.getInstances() + \" instances of server verticle\");\n+    options.setConfig(config);\n+    final VertxCompletableFuture<String> future = new VertxCompletableFuture<>();\n+    vertx.deployVerticle(\n+        () -> new ServerVerticle(endpoints, httpServerOptions, this), options, future);\n+    try {\n+      deploymentID = future.get();\n+    } catch (Exception e) {\n+      throw new KsqlException(\"Failed to start API server\", e);\n+    }\n+    log.info(\"API server started: \" + deploymentID);\n+  }\n+\n+  public synchronized void stop() {\n+    if (deploymentID == null) {\n+      throw new IllegalStateException(\"Not started\");\n+    }\n+    final VertxCompletableFuture<Void> future = new VertxCompletableFuture<>();\n+    vertx.undeploy(deploymentID, future);\n+    try {\n+      future.get();\n+    } catch (Exception e) {\n+      throw new KsqlException(\"Failure in stopping API server\", e);\n+    }\n+  }\n+\n+  QueryID registerQuery(final QuerySubscriber querySubscriber) {\n+    Objects.requireNonNull(querySubscriber);\n+    final QueryID queryID = new QueryID();\n+    queries.put(queryID, querySubscriber);\n+    return queryID;\n+  }\n+\n+  QuerySubscriber removeQuery(final QueryID queryID) {\n+    return queries.remove(queryID);\n+  }\n+\n+  public Set<QueryID> getQueryIDs() {\n+    return new HashSet<>(queries.keySet());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 108}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODExMTQ5MA==", "bodyText": "I'm no REST expert, but wouldn't it be more \"restful\" to have this be HttpMethod.DELETE on a /query endpoint?", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368111490", "createdAt": "2020-01-17T19:57:42Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerVerticle.java", "diffHunk": "@@ -0,0 +1,202 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.impl.Utils;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.QueryPublisher;\n+import io.vertx.core.AbstractVerticle;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Promise;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpMethod;\n+import io.vertx.core.http.HttpServer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.parsetools.RecordParser;\n+import io.vertx.ext.web.Router;\n+import io.vertx.ext.web.RoutingContext;\n+import io.vertx.ext.web.handler.BodyHandler;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * The server deploys multiple server verticles. This is where the HTTP2 requests are handled. The\n+ * actual implementation of the endpoints is provided by an implementation of {@code Endpoints}.\n+ */\n+public class ServerVerticle extends AbstractVerticle {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ServerVerticle.class);\n+\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Server server;\n+  private final Map<HttpConnection, ConnectionQueries> connectionsMap = new HashMap<>();\n+  private HttpServer httpServer;\n+\n+  public ServerVerticle(final Endpoints endpoints, final HttpServerOptions httpServerOptions,\n+      final Server server) {\n+    this.endpoints = endpoints;\n+    this.httpServerOptions = httpServerOptions;\n+    this.server = server;\n+  }\n+\n+  @Override\n+  public void start(final Promise<Void> startPromise) {\n+    httpServer = vertx.createHttpServer(httpServerOptions).requestHandler(setupRouter())\n+        .exceptionHandler(ServerUtils::unhandledExceptonHandler);\n+    final Future<HttpServer> listenFuture = Promise.<HttpServer>promise().future();\n+    Utils.connectPromise(listenFuture.map(s -> null), startPromise);\n+    httpServer.listen(listenFuture);\n+    vertx.getOrCreateContext().exceptionHandler(ServerUtils::unhandledExceptonHandler);\n+  }\n+\n+  @Override\n+  public void stop(final Promise<Void> stopPromise) {\n+    if (httpServer == null) {\n+      stopPromise.complete();\n+    } else {\n+      httpServer.close(stopPromise.future());\n+    }\n+  }\n+\n+  private Router setupRouter() {\n+    final Router router = Router.router(vertx);\n+    router.route(HttpMethod.POST, \"/query-stream\").handler(BodyHandler.create())\n+        .handler(this::handleQueryStream);\n+    router.route(HttpMethod.POST, \"/inserts-stream\").handler(this::handleInsertsStream);\n+    router.route(HttpMethod.POST, \"/close-query\").handler(BodyHandler.create())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 90}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODExMjY1MQ==", "bodyText": "again - having the API defined inline in the code as string literals makes it really hard to construct automated documentation about our public API. would be nice to have Jackson objects that we can generate documentation from", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368112651", "createdAt": "2020-01-17T20:00:29Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerVerticle.java", "diffHunk": "@@ -0,0 +1,202 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_MISSING_PARAM;\n+import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_UNKNOWN_QUERY_ID;\n+import static io.confluent.ksql.api.server.ServerUtils.handleError;\n+\n+import io.confluent.ksql.api.impl.Utils;\n+import io.confluent.ksql.api.spi.Endpoints;\n+import io.confluent.ksql.api.spi.QueryPublisher;\n+import io.vertx.core.AbstractVerticle;\n+import io.vertx.core.Future;\n+import io.vertx.core.Handler;\n+import io.vertx.core.Promise;\n+import io.vertx.core.http.HttpConnection;\n+import io.vertx.core.http.HttpMethod;\n+import io.vertx.core.http.HttpServer;\n+import io.vertx.core.http.HttpServerOptions;\n+import io.vertx.core.json.JsonObject;\n+import io.vertx.core.parsetools.RecordParser;\n+import io.vertx.ext.web.Router;\n+import io.vertx.ext.web.RoutingContext;\n+import io.vertx.ext.web.handler.BodyHandler;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Map;\n+import java.util.Set;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * The server deploys multiple server verticles. This is where the HTTP2 requests are handled. The\n+ * actual implementation of the endpoints is provided by an implementation of {@code Endpoints}.\n+ */\n+public class ServerVerticle extends AbstractVerticle {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ServerVerticle.class);\n+\n+  private final Endpoints endpoints;\n+  private final HttpServerOptions httpServerOptions;\n+  private final Server server;\n+  private final Map<HttpConnection, ConnectionQueries> connectionsMap = new HashMap<>();\n+  private HttpServer httpServer;\n+\n+  public ServerVerticle(final Endpoints endpoints, final HttpServerOptions httpServerOptions,\n+      final Server server) {\n+    this.endpoints = endpoints;\n+    this.httpServerOptions = httpServerOptions;\n+    this.server = server;\n+  }\n+\n+  @Override\n+  public void start(final Promise<Void> startPromise) {\n+    httpServer = vertx.createHttpServer(httpServerOptions).requestHandler(setupRouter())\n+        .exceptionHandler(ServerUtils::unhandledExceptonHandler);\n+    final Future<HttpServer> listenFuture = Promise.<HttpServer>promise().future();\n+    Utils.connectPromise(listenFuture.map(s -> null), startPromise);\n+    httpServer.listen(listenFuture);\n+    vertx.getOrCreateContext().exceptionHandler(ServerUtils::unhandledExceptonHandler);\n+  }\n+\n+  @Override\n+  public void stop(final Promise<Void> stopPromise) {\n+    if (httpServer == null) {\n+      stopPromise.complete();\n+    } else {\n+      httpServer.close(stopPromise.future());\n+    }\n+  }\n+\n+  private Router setupRouter() {\n+    final Router router = Router.router(vertx);\n+    router.route(HttpMethod.POST, \"/query-stream\").handler(BodyHandler.create())\n+        .handler(this::handleQueryStream);\n+    router.route(HttpMethod.POST, \"/inserts-stream\").handler(this::handleInsertsStream);\n+    router.route(HttpMethod.POST, \"/close-query\").handler(BodyHandler.create())\n+        .handler(this::handleCloseQuery);\n+    return router;\n+  }\n+\n+  private void handleInsertsStream(final RoutingContext routingContext) {\n+    final RecordParser recordParser = RecordParser\n+        .newDelimited(\"\\n\", new InsertsBodyParser(endpoints, routingContext)::handleBodyBuffer);\n+    routingContext.request()\n+        .handler(recordParser);\n+  }\n+\n+  private void handleQueryStream(final RoutingContext routingContext) {\n+    final HttpConnection conn = routingContext.request().connection();\n+    ConnectionQueries connectionQueries = connectionsMap.get(conn);\n+    if (connectionQueries == null) {\n+      connectionQueries = new ConnectionQueries(conn);\n+      connectionsMap.put(conn, connectionQueries);\n+      conn.closeHandler(connectionQueries);\n+      server.registerQueryConnection(conn);\n+    }\n+    final JsonObject requestBody = routingContext.getBodyAsJson();\n+    final String sql = requestBody.getString(\"sql\");\n+    if (sql == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No sql in arguments\");\n+      return;\n+    }\n+    final Boolean push = requestBody.getBoolean(\"push\");\n+    if (push == null) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_MISSING_PARAM, \"No push in arguments\");\n+      return;\n+    }\n+    final JsonObject properties = requestBody.getJsonObject(\"properties\");\n+    final QueryPublisher queryPublisher = endpoints.createQueryPublisher(sql, push, properties);\n+    final QuerySubscriber querySubscriber = new QuerySubscriber(routingContext.response());\n+\n+    final QueryID queryID = server.registerQuery(querySubscriber);\n+    connectionQueries.addQuery(queryID);\n+    final JsonObject metadata = new JsonObject();\n+    metadata.put(\"columnNames\", queryPublisher.getColumnNames());\n+    metadata.put(\"columnTypes\", queryPublisher.getColumnTypes());\n+    metadata.put(\"queryID\", queryID.toString());\n+    if (!push) {\n+      metadata.put(\"rowCount\", queryPublisher.getRowCount());\n+    }\n+    routingContext.response().write(metadata.toBuffer()).write(\"\\n\");\n+    queryPublisher.subscribe(querySubscriber);\n+\n+    // When response is complete, publisher should be closed and query unregistered\n+    routingContext.response().endHandler(v -> closeQuery(queryID, routingContext));\n+  }\n+\n+  private boolean closeQuery(final QueryID queryID, final RoutingContext routingContext) {\n+    final QuerySubscriber querySubscriber = server.removeQuery(queryID);\n+    if (querySubscriber == null) {\n+      return false;\n+    }\n+    final HttpConnection conn = routingContext.request().connection();\n+    final ConnectionQueries connectionQueries = connectionsMap.get(conn);\n+    connectionQueries.removeQuery(queryID);\n+    querySubscriber.close();\n+    return true;\n+  }\n+\n+  private void handleCloseQuery(final RoutingContext routingContext) {\n+    final JsonObject requestBody = routingContext.getBodyAsJson();\n+    final String queryIDArg = requestBody.getString(\"queryID\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 156}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODExMzU4Nw==", "bodyText": "All the tests seem to also have 2019 in copyright", "url": "https://github.com/confluentinc/ksql/pull/4320#discussion_r368113587", "createdAt": "2020-01-17T20:03:05Z", "author": {"login": "agavra"}, "path": "ksql-api/src/test/java/io/confluent/ksql/api/TestEndpoints.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Copyright 2019 Confluent Inc.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1abba4b5eab82f21a93441721e3d988a1080248e"}, "originalPosition": 2}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 90, "cost": 1, "resetAt": "2021-11-01T13:07:16Z"}}}