{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzkyNjYxMTI3", "number": 4875, "title": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement", "bodyText": "Description\n\nDiscoverRemoteHostUtil is sufficient for this use right now, but it could be improved. #4910\n\nWhat the output looks like now\n[\n    {\n        \"@type\": \"queries\",\n        \"statementText\": \"Show queries;\",\n        \"queries\": [\n            {\n                \"queryString\": \"CREATE STREAM TEST WITH (KAFKA_TOPIC='TEST', PARTITIONS=1, REPLICAS=1) AS SELECT *\\nFROM KSQL_PROCESSING_LOG KSQL_PROCESSING_LOG\\nEMIT CHANGES;\",\n                \"sinks\": [\n                    \"TEST\"\n                ],\n                \"sinkKafkaTopics\": [\n                    \"TEST\"\n                ],\n                \"id\": \"CSAS_TEST_0\",\n                \"state\": \"RUNNING:2\",\n                \"stateCount\": {\n                    \"RUNNING\": 2\n                }\n            }\n        ],\n        \"warnings\": []\n    }\n]\n\n[\n    {\n        \"@type\": \"query_descriptions\",\n        \"statementText\": \"Show queries extended;\",\n        \"queryDescriptions\": [\n            {\n                \"id\": \"CSAS_TEST_0\",\n                \"statementText\": \"CREATE STREAM TEST WITH (KAFKA_TOPIC='TEST', PARTITIONS=1, REPLICAS=1) AS SELECT *\\nFROM KSQL_PROCESSING_LOG KSQL_PROCESSING_LOG\\nEMIT CHANGES;\",\n                \"windowType\": null,\n                ...\n                \"state\": \"{192.168.1.6:8088=RUNNING, 192.168.1.6:8089=RUNNING}\",\n                \"ksqlHostQueryState\": {\n                    \"192.168.1.6:8088\": \"RUNNING\",\n                    \"192.168.1.6:8089\": \"RUNNING\"\n                }\n            }\n        ],\n        \"warnings\": []\n    }\n]\n\nListSourcesExecutor and ExplainExecutor probably need to follow the same scatter gather pattern too eventually\nTesting done\nManual test, unit tests, new integration test\nReviewer checklist\n\n Ensure docs are updated if necessary. (eg. if a user visible feature is being added or changed).\n Ensure relevant issues are linked (description should include text like \"Fixes #\")", "createdAt": "2020-03-23T22:01:33Z", "url": "https://github.com/confluentinc/ksql/pull/4875", "merged": true, "mergeCommit": {"oid": "7385a31dd33293b76e594649213da2abb81b8ddf"}, "closed": true, "closedAt": "2020-04-08T00:09:34Z", "author": {"login": "stevenpyzhang"}, "timelineItems": {"totalCount": 43, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcQniVMABqjMxNTc1ODU4NzE=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcVZUJ8ABqjMyMTE1MDA0Mjk=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "65710fade13d13f91571798983ed3c1feba22bd4", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/65710fade13d13f91571798983ed3c1feba22bd4", "committedDate": "2020-03-23T22:00:34Z", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement"}, "afterCommit": {"oid": "5a871718d2401b79c45548a52994b37e3106d778", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/5a871718d2401b79c45548a52994b37e3106d778", "committedDate": "2020-03-24T00:12:34Z", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "5a871718d2401b79c45548a52994b37e3106d778", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/5a871718d2401b79c45548a52994b37e3106d778", "committedDate": "2020-03-24T00:12:34Z", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement"}, "afterCommit": {"oid": "8ab02f964c73fb48d54f0deeffbb5884cbf93c62", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/8ab02f964c73fb48d54f0deeffbb5884cbf93c62", "committedDate": "2020-03-24T18:58:12Z", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8ab02f964c73fb48d54f0deeffbb5884cbf93c62", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/8ab02f964c73fb48d54f0deeffbb5884cbf93c62", "committedDate": "2020-03-24T18:58:12Z", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement"}, "afterCommit": {"oid": "865e158a791082b48f6c11e75bcf26befd28b1d0", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/865e158a791082b48f6c11e75bcf26befd28b1d0", "committedDate": "2020-03-25T18:46:27Z", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "865e158a791082b48f6c11e75bcf26befd28b1d0", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/865e158a791082b48f6c11e75bcf26befd28b1d0", "committedDate": "2020-03-25T18:46:27Z", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement"}, "afterCommit": {"oid": "115659497df719d8e1913ed113d2d61a4056a302", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/115659497df719d8e1913ed113d2d61a4056a302", "committedDate": "2020-03-25T22:36:51Z", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "115659497df719d8e1913ed113d2d61a4056a302", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/115659497df719d8e1913ed113d2d61a4056a302", "committedDate": "2020-03-25T22:36:51Z", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement"}, "afterCommit": {"oid": "fcd157bf075d61c840bab2bab86b1013f28a3204", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/fcd157bf075d61c840bab2bab86b1013f28a3204", "committedDate": "2020-03-26T00:04:19Z", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "fcd157bf075d61c840bab2bab86b1013f28a3204", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/fcd157bf075d61c840bab2bab86b1013f28a3204", "committedDate": "2020-03-26T00:04:19Z", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement"}, "afterCommit": {"oid": "80f552536a53dcf361f7de8165e21fd20e47808a", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/80f552536a53dcf361f7de8165e21fd20e47808a", "committedDate": "2020-03-26T00:05:54Z", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "80f552536a53dcf361f7de8165e21fd20e47808a", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/80f552536a53dcf361f7de8165e21fd20e47808a", "committedDate": "2020-03-26T00:05:54Z", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement"}, "afterCommit": {"oid": "4cc10dbfcf6030635899df8a758da0c3ba7ff519", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/4cc10dbfcf6030635899df8a758da0c3ba7ff519", "committedDate": "2020-03-26T03:00:11Z", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "4cc10dbfcf6030635899df8a758da0c3ba7ff519", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/4cc10dbfcf6030635899df8a758da0c3ba7ff519", "committedDate": "2020-03-26T03:00:11Z", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement"}, "afterCommit": {"oid": "413146c650913a86bce395aff75949e0104e5e7a", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/413146c650913a86bce395aff75949e0104e5e7a", "committedDate": "2020-03-26T03:35:16Z", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "413146c650913a86bce395aff75949e0104e5e7a", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/413146c650913a86bce395aff75949e0104e5e7a", "committedDate": "2020-03-26T03:35:16Z", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement"}, "afterCommit": {"oid": "157df014f2f5adb180949d2b07a132b957a4d0f2", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/157df014f2f5adb180949d2b07a132b957a4d0f2", "committedDate": "2020-03-26T06:45:19Z", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "157df014f2f5adb180949d2b07a132b957a4d0f2", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/157df014f2f5adb180949d2b07a132b957a4d0f2", "committedDate": "2020-03-26T06:45:19Z", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement"}, "afterCommit": {"oid": "470d006b25626e2d60ef3fb8f6ef0ebc52b11b62", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/470d006b25626e2d60ef3fb8f6ef0ebc52b11b62", "committedDate": "2020-03-26T07:18:50Z", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "470d006b25626e2d60ef3fb8f6ef0ebc52b11b62", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/470d006b25626e2d60ef3fb8f6ef0ebc52b11b62", "committedDate": "2020-03-26T07:18:50Z", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement"}, "afterCommit": {"oid": "d0dc3c9e88cd0e986f3058c761ac1929836b07ce", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/d0dc3c9e88cd0e986f3058c761ac1929836b07ce", "committedDate": "2020-03-26T23:14:33Z", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgyNTA4MzI4", "url": "https://github.com/confluentinc/ksql/pull/4875#pullrequestreview-382508328", "createdAt": "2020-03-27T00:26:43Z", "commit": {"oid": "d0dc3c9e88cd0e986f3058c761ac1929836b07ce"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QwMDoyNjo0M1rOF8fKVA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QwMDoyNjo0M1rOF8fKVA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk2OTQyOA==", "bodyText": "Changing this to reduce the amount of logging from creating the KsqlRequestConfig", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r398969428", "createdAt": "2020-03-27T00:26:43Z", "author": {"login": "stevenpyzhang"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/KsqlResource.java", "diffHunk": "@@ -247,8 +247,9 @@ public Response handleKsqlStatements(\n           request,\n           distributedCmdResponseTimeout);\n \n-      final KsqlRequestConfig requestConfig =\n-          new KsqlRequestConfig(request.getRequestProperties());\n+      final boolean internalRequest =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d0dc3c9e88cd0e986f3058c761ac1929836b07ce"}, "originalPosition": 6}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d0dc3c9e88cd0e986f3058c761ac1929836b07ce", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/d0dc3c9e88cd0e986f3058c761ac1929836b07ce", "committedDate": "2020-03-26T23:14:33Z", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement"}, "afterCommit": {"oid": "5784bc7d76ce514960fe7116a3aeb898bed15188", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/5784bc7d76ce514960fe7116a3aeb898bed15188", "committedDate": "2020-03-27T00:54:45Z", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "5784bc7d76ce514960fe7116a3aeb898bed15188", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/5784bc7d76ce514960fe7116a3aeb898bed15188", "committedDate": "2020-03-27T00:54:45Z", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement"}, "afterCommit": {"oid": "5271edf3d2fbf858bde71926fedd246edd9fa693", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/5271edf3d2fbf858bde71926fedd246edd9fa693", "committedDate": "2020-03-27T00:55:25Z", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgyNTE2OTYy", "url": "https://github.com/confluentinc/ksql/pull/4875#pullrequestreview-382516962", "createdAt": "2020-03-27T00:56:23Z", "commit": {"oid": "5784bc7d76ce514960fe7116a3aeb898bed15188"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QwMDo1Njo0N1rOF8fpRw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QwMDo1Njo0N1rOF8fpRw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk3NzM1MQ==", "bodyText": "This has to be set in order for waitForClusterToBeDiscovered(REST_APP_0, 2); to work properly. The wait is necessary in order to make sure the queries are in a RUNNING state before proceeding with the test", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r398977351", "createdAt": "2020-03-27T00:56:47Z", "author": {"login": "stevenpyzhang"}, "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.integration;\n+\n+import static io.confluent.ksql.rest.integration.HighAvailabilityTestUtil.waitForClusterToBeDiscovered;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.containsInAnyOrder;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.is;\n+\n+import io.confluent.common.utils.IntegrationTest;\n+import io.confluent.ksql.integration.IntegrationTestHarness;\n+import io.confluent.ksql.integration.Retry;\n+import io.confluent.ksql.rest.entity.KsqlEntity;\n+import io.confluent.ksql.rest.entity.KsqlHostInfoEntity;\n+import io.confluent.ksql.rest.entity.Queries;\n+import io.confluent.ksql.rest.entity.QueryDescription;\n+import io.confluent.ksql.rest.entity.QueryDescriptionList;\n+import io.confluent.ksql.rest.entity.RunningQuery;\n+import io.confluent.ksql.rest.server.KsqlRestConfig;\n+import io.confluent.ksql.rest.server.TestKsqlRestApp;\n+import io.confluent.ksql.serde.FormatFactory;\n+import io.confluent.ksql.test.util.secure.ClientTrustStore;\n+import io.confluent.ksql.util.PageViewDataProvider;\n+\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+import kafka.zookeeper.ZooKeeperClientException;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.RuleChain;\n+\n+@Category({IntegrationTest.class})\n+public class ShowQueriesMultiNodeFunctionalTest {\n+\n+  private static final PageViewDataProvider PAGE_VIEWS_PROVIDER = new PageViewDataProvider();\n+  private static final String PAGE_VIEW_TOPIC = PAGE_VIEWS_PROVIDER.topicName();\n+  private static final String PAGE_VIEW_STREAM = PAGE_VIEWS_PROVIDER.kstreamName();\n+  private static final KsqlHostInfoEntity host0 = new KsqlHostInfoEntity(\"localhost\", 8088);\n+  private static final KsqlHostInfoEntity host1 = new KsqlHostInfoEntity(\"localhost\", 8089);\n+  private static final IntegrationTestHarness TEST_HARNESS = IntegrationTestHarness.build();\n+  private static final TestKsqlRestApp REST_APP_0 = TestKsqlRestApp\n+      .builder(TEST_HARNESS::kafkaBootstrapServers)\n+      .withProperty(KsqlRestConfig.LISTENERS_CONFIG, \"http://localhost:8088\")\n+      .withProperty(KsqlRestConfig.ADVERTISED_LISTENER_CONFIG, \"http://localhost:8088\")\n+      .withProperty(KsqlRestConfig.KSQL_HEARTBEAT_ENABLE_CONFIG, true)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5271edf3d2fbf858bde71926fedd246edd9fa693"}, "originalPosition": 62}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgyNTkxMDAy", "url": "https://github.com/confluentinc/ksql/pull/4875#pullrequestreview-382591002", "createdAt": "2020-03-27T05:38:38Z", "commit": {"oid": "5271edf3d2fbf858bde71926fedd246edd9fa693"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QwNTozODozOVrOF8jy2g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QwNTozODozOVrOF8jy2g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTA0NTMzOA==", "bodyText": "Adding in once we're satisfied with the final new output", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r399045338", "createdAt": "2020-03-27T05:38:39Z", "author": {"login": "stevenpyzhang"}, "path": "docs-md/developer-guide/ksqldb-reference/show-queries.md", "diffHunk": "@@ -13,13 +13,15 @@ Synopsis\n --------\r\n \r\n ```sql\r\n-SHOW QUERIES;\r\n+SHOW | LIST QUERIES [EXTENDED];\r\n ```\r\n \r\n Description\r\n -----------\r\n \r\n-List the running persistent queries.\r\n+`SHOW QUERIES` lists queries running in the cluster.\r\n+\r\n+`SHOW QUERIES EXTENDED` lists queries running in the cluster in more detail.\r\n \r\n Example\r\n -------\r", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5271edf3d2fbf858bde71926fedd246edd9fa693"}, "originalPosition": 17}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgyOTg2NDI5", "url": "https://github.com/confluentinc/ksql/pull/4875#pullrequestreview-382986429", "createdAt": "2020-03-27T15:55:03Z", "commit": {"oid": "5271edf3d2fbf858bde71926fedd246edd9fa693"}, "state": "COMMENTED", "comments": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QxNTo1NTowM1rOF83amQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QxNjozMzowM1rOF8491A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTM2NjgwOQ==", "bodyText": "nit: I believe the toString is superfluous here", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r399366809", "createdAt": "2020-03-27T15:55:03Z", "author": {"login": "agavra"}, "path": "ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java", "diffHunk": "@@ -659,6 +659,11 @@ private void printQueryDescription(final QueryDescription query) {\n     if (query.getState().isPresent()) {\n       writer().println(String.format(\"%-20s : %s\", \"Status\", query.getState().get()));\n     }\n+    if (query.getKsqlHostQueryState().size() > 0) {\n+      writer().println(String.format(\n+          \"%-20s : %s\", \"Host Query Status\",\n+          query.getKsqlHostQueryState().toString()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5271edf3d2fbf858bde71926fedd246edd9fa693"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTM2OTQ3NA==", "bodyText": "can we just use KafkaStreams.State#valueOf instead of this map?", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r399369474", "createdAt": "2020-03-27T15:58:52Z", "author": {"login": "agavra"}, "path": "ksqldb-common/src/main/java/io/confluent/ksql/util/KsqlConstants.java", "diffHunk": "@@ -46,6 +51,17 @@ private KsqlConstants() {\n   public static final String DEFAULT_AVRO_SCHEMA_FULL_NAME =\n           AVRO_SCHEMA_NAMESPACE + \".\" + AVRO_SCHEMA_NAME;\n \n+  public static final ImmutableMap<String, KafkaStreams.State>\n+      STRING_TO_KAFKA_STREAMS_STATE_MAPPING;\n+\n+  static {\n+    final  Map<String, KafkaStreams.State> stringToStateMapping = new HashMap<>();\n+    for (KafkaStreams.State state: KafkaStreams.State.values()) {\n+      stringToStateMapping.put(state.toString(), state);\n+    }\n+    STRING_TO_KAFKA_STREAMS_STATE_MAPPING = ImmutableMap.copyOf(stringToStateMapping);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5271edf3d2fbf858bde71926fedd246edd9fa693"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTM2OTczMg==", "bodyText": "nit: javadoc ;)", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r399369732", "createdAt": "2020-03-27T15:59:15Z", "author": {"login": "agavra"}, "path": "ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java", "diffHunk": "@@ -34,6 +34,12 @@\n       String sql\n   );\n \n+  RestResponse<KsqlEntityList> makeKsqlRequestWithRequestProperties(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5271edf3d2fbf858bde71926fedd246edd9fa693"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTM3MzI4Ng==", "bodyText": "nit: up to you, but I would recommend replacing all of these .forEach calls with vanilla for-each loops. It will make the stack traces way more readable, error handling easier and debugging anything with remote calls a little simpler. the way it stands, I think we have four nested lambdas, which were really designed for stateless transforms", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r399373286", "createdAt": "2020-03-27T16:04:24Z", "author": {"login": "agavra"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -40,25 +57,143 @@ private ListQueriesExecutor() { }\n   ) {\n     final ListQueries listQueries = statement.getStatement();\n     if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n+      return executeExtended(\n+          listQueries,\n+          statement,\n+          sessionProperties,\n+          executionContext,\n+          serviceContext);\n+    }\n+\n+    final List<RunningQuery> runningQueries = executionContext.getPersistentQueries()\n+        .stream()\n+        .map(q -> {\n+          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n+          return new RunningQuery(\n+              q.getStatementString(),\n+              ImmutableSet.of(q.getSinkName().text()),\n+              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n+              q.getQueryId(),\n+              kafkaStreamsStateCount\n+          );\n+        }).collect(Collectors.toList());\n+\n+    final Map<String, RunningQuery> queryToRunningQuery = runningQueries.stream().collect(\n+        Collectors.toMap(\n+            query -> query.getId().toString(),\n+            query -> query));\n+\n+    if (!sessionProperties.getInternalRequest()) {\n+      final Set<HostInfo> hosts =\n+          DiscoverRemoteHostsUtil.getRemoteHosts(\n+              executionContext.getPersistentQueries(),\n+              sessionProperties.getKsqlHostInfo());\n+\n+      hosts.forEach(hostInfo -> {\n+        final KsqlEntityList response = serviceContext.getKsqlClient()\n+            .makeKsqlRequestWithRequestProperties(\n+                ServerUtil.buildRemoteUri(\n+                    sessionProperties.getLocalUrl(),\n+                    hostInfo.host(),\n+                    hostInfo.port()\n+                ),\n+                statement.getStatementText(),\n+                Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+            .getResponse();\n+\n+        response.forEach(remoteQueries -> {\n+          final List<RunningQuery> queries = ((Queries) remoteQueries).getQueries();\n+          queries.forEach(q -> {\n+            final String queryId = q.getId().toString();\n+            \n+            // If the query has already been discovered, update the KafkaStreamsStateCount object\n+            if (queryToRunningQuery.containsKey(queryId)) {\n+              q.getState().getState()\n+                  .forEach((state, count) ->", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5271edf3d2fbf858bde71926fedd246edd9fa693"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTM4MjQ0MA==", "bodyText": "for SerDe of the maps, I would recommend using:\n    Map<String, String> pairs = Splitter.on(\",\").withKeyValueSeparator(\":\").split(serialized);\n    state =  pairs.entrySet().stream()\n        .collect(Collectors.toMap(\n            e -> KafkaStreams.State.valueOf(e.getKey()),\n            e -> Integer.parseInt(e.getValue()),\n            (v1, v2) -> {throw new IllegalStateException(\"duplicate keys\")},\n            TreeMap::new\n        ));\nAnd you can use the correspond method to serialize: Joiner.on(\",\").withKeyValueSeparator(\":\").join(values);", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r399382440", "createdAt": "2020-03-27T16:18:20Z", "author": {"login": "agavra"}, "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java", "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.entity;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n+import com.fasterxml.jackson.annotation.JsonValue;\n+import io.confluent.ksql.util.KsqlConstants;\n+import io.confluent.ksql.util.KsqlException;\n+\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.TreeMap;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+\n+/**\n+ * Used to keep track of a the state of KafkaStreams application\n+ * across multiple servers. Used in {@link RunningQuery}.\n+ */\n+@JsonIgnoreProperties(ignoreUnknown = true)\n+public class KafkaStreamsStateCount {\n+  \n+  // Use a TreeMap so toString() will always return the same string\n+  private final TreeMap<KafkaStreams.State, Integer> state;\n+\n+  public KafkaStreamsStateCount() {\n+    this.state = returnTreeMap();\n+  }\n+\n+  @JsonCreator\n+  public KafkaStreamsStateCount(final String serializedPair) {\n+    final String [] parts = serializedPair.split(\",\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5271edf3d2fbf858bde71926fedd246edd9fa693"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTM4NzMyNQ==", "bodyText": "a lot of this seems duplicated from above, can we simplify it?", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r399387325", "createdAt": "2020-03-27T16:25:28Z", "author": {"login": "agavra"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -40,25 +57,143 @@ private ListQueriesExecutor() { }\n   ) {\n     final ListQueries listQueries = statement.getStatement();\n     if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n+      return executeExtended(\n+          listQueries,\n+          statement,\n+          sessionProperties,\n+          executionContext,\n+          serviceContext);\n+    }\n+\n+    final List<RunningQuery> runningQueries = executionContext.getPersistentQueries()\n+        .stream()\n+        .map(q -> {\n+          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n+          return new RunningQuery(\n+              q.getStatementString(),\n+              ImmutableSet.of(q.getSinkName().text()),\n+              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n+              q.getQueryId(),\n+              kafkaStreamsStateCount\n+          );\n+        }).collect(Collectors.toList());\n+\n+    final Map<String, RunningQuery> queryToRunningQuery = runningQueries.stream().collect(\n+        Collectors.toMap(\n+            query -> query.getId().toString(),\n+            query -> query));\n+\n+    if (!sessionProperties.getInternalRequest()) {\n+      final Set<HostInfo> hosts =\n+          DiscoverRemoteHostsUtil.getRemoteHosts(\n+              executionContext.getPersistentQueries(),\n+              sessionProperties.getKsqlHostInfo());\n+\n+      hosts.forEach(hostInfo -> {\n+        final KsqlEntityList response = serviceContext.getKsqlClient()\n+            .makeKsqlRequestWithRequestProperties(\n+                ServerUtil.buildRemoteUri(\n+                    sessionProperties.getLocalUrl(),\n+                    hostInfo.host(),\n+                    hostInfo.port()\n+                ),\n+                statement.getStatementText(),\n+                Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+            .getResponse();\n+\n+        response.forEach(remoteQueries -> {\n+          final List<RunningQuery> queries = ((Queries) remoteQueries).getQueries();\n+          queries.forEach(q -> {\n+            final String queryId = q.getId().toString();\n+            \n+            // If the query has already been discovered, update the KafkaStreamsStateCount object\n+            if (queryToRunningQuery.containsKey(queryId)) {\n+              q.getState().getState()\n+                  .forEach((state, count) ->\n+                      queryToRunningQuery\n+                          .get(queryId)\n+                          .getState()\n+                          .updateStateCount(state, count));\n+            } else {\n+              queryToRunningQuery.put(queryId, q);\n+            }\n+          });\n+        });\n+      });\n     }\n \n     return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n         statement.getStatementText(),\n-        executionContext.getPersistentQueries()\n-            .stream()\n-            .map(q -> new RunningQuery(\n-                q.getStatementString(),\n-                ImmutableSet.of(q.getSinkName().text()),\n-                ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n-                q.getQueryId(),\n-                Optional.of(q.getState())\n-            ))\n-            .collect(Collectors.toList())));\n+        new ArrayList<>(queryToRunningQuery.values())));\n   }\n \n-}\n+  private static Optional<KsqlEntity> executeExtended(\n+      final ListQueries listQueries,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final SessionProperties sessionProperties,\n+      final KsqlExecutionContext executionContext,\n+      final ServiceContext serviceContext\n+  ) {\n+    final List<QueryDescription> queryDescriptions = \n+        executionContext.getPersistentQueries().stream()\n+            .map(query -> {\n+              final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n+              ksqlHostQueryState.put(\n+                  new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n+                  query.getState());\n+              return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n+            }).collect(Collectors.toList());\n+\n+    final Map<String, QueryDescription> queryToQueryDescription =\n+        queryDescriptions.stream().collect(\n+            Collectors.toMap(\n+                query -> query.getId().toString(),\n+                query -> query));\n+\n+    if (!sessionProperties.getInternalRequest()) {\n+      final Set<HostInfo> hosts =\n+          DiscoverRemoteHostsUtil.getRemoteHosts(\n+              executionContext.getPersistentQueries(),\n+              sessionProperties.getKsqlHostInfo());\n+\n+      hosts.forEach(hostInfo -> {\n+        final KsqlEntityList response = \n+            serviceContext.getKsqlClient().makeKsqlRequestWithRequestProperties(\n+                ServerUtil.buildRemoteUri(\n+                    sessionProperties.getLocalUrl(),\n+                    hostInfo.host(),\n+                    hostInfo.port()\n+                ),\n+                statement.getStatementText(),\n+                Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true)\n+        ).getResponse();\n+\n+        response.forEach(remoteQueries -> {\n+          final List<QueryDescription> queries =\n+              ((QueryDescriptionList) remoteQueries).getQueryDescriptions();\n+\n+          queries.forEach(q -> {\n+            final String queryId = q.getId().toString();\n+\n+            // If the query has already been discovered, add to the ksqlQueryHostState mapping", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5271edf3d2fbf858bde71926fedd246edd9fa693"}, "originalPosition": 175}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTM4NzY3Nw==", "bodyText": "what happens if there's an error with this? also I believe we have an async execute call on ksql client. Can we use that instead so that we don't handle them one at a time? (as your comment in the description mentions)", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r399387677", "createdAt": "2020-03-27T16:26:03Z", "author": {"login": "agavra"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -40,25 +57,143 @@ private ListQueriesExecutor() { }\n   ) {\n     final ListQueries listQueries = statement.getStatement();\n     if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n+      return executeExtended(\n+          listQueries,\n+          statement,\n+          sessionProperties,\n+          executionContext,\n+          serviceContext);\n+    }\n+\n+    final List<RunningQuery> runningQueries = executionContext.getPersistentQueries()\n+        .stream()\n+        .map(q -> {\n+          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n+          return new RunningQuery(\n+              q.getStatementString(),\n+              ImmutableSet.of(q.getSinkName().text()),\n+              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n+              q.getQueryId(),\n+              kafkaStreamsStateCount\n+          );\n+        }).collect(Collectors.toList());\n+\n+    final Map<String, RunningQuery> queryToRunningQuery = runningQueries.stream().collect(\n+        Collectors.toMap(\n+            query -> query.getId().toString(),\n+            query -> query));\n+\n+    if (!sessionProperties.getInternalRequest()) {\n+      final Set<HostInfo> hosts =\n+          DiscoverRemoteHostsUtil.getRemoteHosts(\n+              executionContext.getPersistentQueries(),\n+              sessionProperties.getKsqlHostInfo());\n+\n+      hosts.forEach(hostInfo -> {\n+        final KsqlEntityList response = serviceContext.getKsqlClient()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5271edf3d2fbf858bde71926fedd246edd9fa693"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTM5MDQ1NA==", "bodyText": "instead of actually spinning up a rest app, which takes forever and probably tests more than we want to test - can we make this test mock out any network communication? I think adding an integration for this is overkill as it's a relatively minor feature and we'd be testing way more than we need to", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r399390454", "createdAt": "2020-03-27T16:30:12Z", "author": {"login": "agavra"}, "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.integration;\n+\n+import static io.confluent.ksql.rest.integration.HighAvailabilityTestUtil.waitForClusterToBeDiscovered;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.containsInAnyOrder;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.is;\n+\n+import io.confluent.common.utils.IntegrationTest;\n+import io.confluent.ksql.integration.IntegrationTestHarness;\n+import io.confluent.ksql.integration.Retry;\n+import io.confluent.ksql.rest.entity.KsqlEntity;\n+import io.confluent.ksql.rest.entity.KsqlHostInfoEntity;\n+import io.confluent.ksql.rest.entity.Queries;\n+import io.confluent.ksql.rest.entity.QueryDescription;\n+import io.confluent.ksql.rest.entity.QueryDescriptionList;\n+import io.confluent.ksql.rest.entity.RunningQuery;\n+import io.confluent.ksql.rest.server.KsqlRestConfig;\n+import io.confluent.ksql.rest.server.TestKsqlRestApp;\n+import io.confluent.ksql.serde.FormatFactory;\n+import io.confluent.ksql.test.util.secure.ClientTrustStore;\n+import io.confluent.ksql.util.PageViewDataProvider;\n+\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+import kafka.zookeeper.ZooKeeperClientException;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.RuleChain;\n+\n+@Category({IntegrationTest.class})\n+public class ShowQueriesMultiNodeFunctionalTest {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5271edf3d2fbf858bde71926fedd246edd9fa693"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTM5MTU1Mw==", "bodyText": "can we test the exceptional cases here as well? and follow Given/When/Then for all tests?", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r399391553", "createdAt": "2020-03-27T16:32:02Z", "author": {"login": "agavra"}, "path": "ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCountTest.java", "diffHunk": "@@ -0,0 +1,89 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.entity;\n+\n+import static org.hamcrest.CoreMatchers.containsString;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+\n+import io.confluent.ksql.util.KsqlException;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+@SuppressWarnings(\"SameParameterValue\")\n+public class KafkaStreamsStateCountTest {\n+\n+  KafkaStreamsStateCount kafkaStreamsStateCount;\n+  \n+  @Before\n+  public void setup() {\n+    kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+  }\n+\n+  @Test\n+  public void shouldUpdateExistingStateCount() {\n+    kafkaStreamsStateCount.updateStateCount(KafkaStreams.State.RUNNING, 2);\n+    assertThat(\n+        kafkaStreamsStateCount.getState().get(KafkaStreams.State.RUNNING),\n+        is(2));\n+    kafkaStreamsStateCount.updateStateCount(KafkaStreams.State.RUNNING, 4);\n+    assertThat(\n+        kafkaStreamsStateCount.getState().get(KafkaStreams.State.RUNNING),\n+        is(6));\n+  }\n+\n+  @Test\n+  public void shouldToString() {\n+    kafkaStreamsStateCount.updateStateCount(KafkaStreams.State.RUNNING, 2);\n+    assertThat(\n+        kafkaStreamsStateCount.toString(),\n+        is(\"RUNNING:2\"));\n+    kafkaStreamsStateCount.updateStateCount(KafkaStreams.State.NOT_RUNNING, 1);\n+    assertThat(\n+        kafkaStreamsStateCount.toString(),\n+        is(\"NOT_RUNNING:1, RUNNING:2\"));\n+  }\n+\n+  @Test\n+  public void shouldConvertStringToKafkaStreamsStateCount() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5271edf3d2fbf858bde71926fedd246edd9fa693"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTM5MjIxMg==", "bodyText": "I believe you can use EnumMap here - as the order is deterministic based on the ordering of the State enum ordinal", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r399392212", "createdAt": "2020-03-27T16:33:03Z", "author": {"login": "agavra"}, "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java", "diffHunk": "@@ -0,0 +1,130 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.entity;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n+import com.fasterxml.jackson.annotation.JsonValue;\n+import io.confluent.ksql.util.KsqlConstants;\n+import io.confluent.ksql.util.KsqlException;\n+\n+import java.util.Comparator;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.TreeMap;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+\n+/**\n+ * Used to keep track of a the state of KafkaStreams application\n+ * across multiple servers. Used in {@link RunningQuery}.\n+ */\n+@JsonIgnoreProperties(ignoreUnknown = true)\n+public class KafkaStreamsStateCount {\n+  \n+  // Use a TreeMap so toString() will always return the same string\n+  private final TreeMap<KafkaStreams.State, Integer> state;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5271edf3d2fbf858bde71926fedd246edd9fa693"}, "originalPosition": 39}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgzMDM0MDAy", "url": "https://github.com/confluentinc/ksql/pull/4875#pullrequestreview-383034002", "createdAt": "2020-03-27T16:51:45Z", "commit": {"oid": "5271edf3d2fbf858bde71926fedd246edd9fa693"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "5271edf3d2fbf858bde71926fedd246edd9fa693", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/5271edf3d2fbf858bde71926fedd246edd9fa693", "committedDate": "2020-03-27T00:55:25Z", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement"}, "afterCommit": {"oid": "35a707ccf27366ed8f44f71aa302c7159d3826ad", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/35a707ccf27366ed8f44f71aa302c7159d3826ad", "committedDate": "2020-03-27T18:41:31Z", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0ed27bc8171ce76e841d46712489850297584de9", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/0ed27bc8171ce76e841d46712489850297584de9", "committedDate": "2020-03-28T21:04:36Z", "message": "address comments"}, "afterCommit": {"oid": "15fc917b558b649851a97563869bc2b80ec8d0a0", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/15fc917b558b649851a97563869bc2b80ec8d0a0", "committedDate": "2020-03-29T16:31:38Z", "message": "address comments"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "15fc917b558b649851a97563869bc2b80ec8d0a0", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/15fc917b558b649851a97563869bc2b80ec8d0a0", "committedDate": "2020-03-29T16:31:38Z", "message": "address comments"}, "afterCommit": {"oid": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "committedDate": "2020-03-30T17:33:52Z", "message": "address comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg0NTg1NjAx", "url": "https://github.com/confluentinc/ksql/pull/4875#pullrequestreview-384585601", "createdAt": "2020-03-31T10:06:52Z", "commit": {"oid": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d"}, "state": "COMMENTED", "comments": {"totalCount": 32, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxMDowNjo1MlrOF-OfEA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQxMzowNjoyMlrOF-U0uA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDc5MzM2MA==", "bodyText": "What's the proposed new output?", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400793360", "createdAt": "2020-03-31T10:06:52Z", "author": {"login": "big-andy-coates"}, "path": "docs-md/developer-guide/ksqldb-reference/show-queries.md", "diffHunk": "@@ -13,13 +13,15 @@ Synopsis\n --------\r\n \r\n ```sql\r\n-SHOW QUERIES;\r\n+SHOW | LIST QUERIES [EXTENDED];\r\n ```\r\n \r\n Description\r\n -----------\r\n \r\n-List the running persistent queries.\r\n+`SHOW QUERIES` lists queries running in the cluster.\r\n+\r\n+`SHOW QUERIES EXTENDED` lists queries running in the cluster in more detail.\r\n \r\n Example\r\n -------\r", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTA0NTMzOA=="}, "originalCommit": {"oid": "5271edf3d2fbf858bde71926fedd246edd9fa693"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDc5NDQwNA==", "bodyText": "nit: toString is superfluous here.", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400794404", "createdAt": "2020-03-31T10:08:36Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java", "diffHunk": "@@ -530,7 +530,7 @@ private void printQueries(\n       ));\n       for (final RunningQuery writeQuery : queries) {\n         writer().println(writeQuery.getId().getId()\n-            + \" (\" + writeQuery.getState().orElse(\"N/A\")\n+            + \" (\" + writeQuery.getState().toString()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDc5NDkwMg==", "bodyText": "The test would be less coupled to KafkaStreamsStateCount if you use a mock.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              private KafkaStreamsStateCount kafkaStreamsStateCount;\n          \n          \n            \n              @Mock(name = \"RUNNING:1, ERROR:2\")\n          \n          \n            \n              private KafkaStreamsStateCount kafkaStreamsStateCount;\n          \n      \n    \n    \n  \n\nThen kafkaStreamsStateCount.toString() will return RUNNING:1, ERROR:2, which you can check for in your test.\nNow if the output of toString changes you don't need to update this test.", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400794902", "createdAt": "2020-03-31T10:09:32Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-cli/src/test/java/io/confluent/ksql/cli/console/ConsoleTest.java", "diffHunk": "@@ -129,6 +131,7 @@\n       1,\n       \"statement\"\n   );\n+  private KafkaStreamsStateCount kafkaStreamsStateCount;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgwMzA1Nw==", "bodyText": "This looks a lot like interface bloat to me.  It looks like what you needed to do was add an additional map parameter to the existing makeKsqlRequest method.  Instead you've added a whole new method.\nThis has two disadvantages:\n\nimplementations of the interface now need to implement an additional method\nusers to the interface may need to check the implementation to work out what the two methods do so they can work out which to call.\n\nThink what would happen in a year of twos time if this pattern was followed when people added a few more variants to add additional parameters?  The result is a bloated interface which is hard to use and to implement.\nA better way....\nQ: Is there any difference between calling:\nmakeKsqlRequest(uri, sql);\n// or\nmakeKsqlRequestWithRequestProperties(uri, sql, emptyMap);\nI'm guessing / hoping not.\nIf this is the case, I'd suggest one of two approaches:\n\nAdd the new param to the existing makeKsqlRequest method and default all existing calls to passing an ImmutableMap.of() for the new param, i.e. passing an empty map.\nHave two separate methods, but provide a default implementation for one that calls the other:\n\npublic interface SimpleKsqlClient {\n  \n default RestResponse<KsqlEntityList> makeKsqlRequest(\n      URI serverEndPoint,\n      String sql\n  ) {\n    return makeKsqlRequest(serverEndPoint, sql, ImmutableMap.of());\n  }\n\n   RestResponse<KsqlEntityList> makeKsqlRequest(\n      URI serverEndPoint,\n      String sql,\n      Map<String, ?> props\n  );\n}\nOf these, my preference would be for the first option as this solves both issues, where as the second option only removes the need for implementations to implement a second method, while still leaving users of the interface to work out which method they need to call.", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400803057", "createdAt": "2020-03-31T10:23:06Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java", "diffHunk": "@@ -34,6 +34,19 @@\n       String sql\n   );\n \n+  /**\n+   * Send a request to remote Ksql server.\n+   * @param serverEndPoint the remote destination\n+   * @param sql the sql statement\n+   * @param requestProperties the request metadata provided by the server\n+   * @return the result of sql statement execution\n+   */\n+  RestResponse<KsqlEntityList> makeKsqlRequestWithRequestProperties(\n+      URI serverEndPoint,\n+      String sql,\n+      Map<String, ?> requestProperties\n+  );\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgwNTY1NQ==", "bodyText": "nit: duplicate code. Why not create the map in the calling function and pass it down, rather than passing sessionProperites?", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400805655", "createdAt": "2020-03-31T10:27:34Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ExplainExecutor.java", "diffHunk": "@@ -118,20 +125,29 @@ private static QueryDescription explainStatement(\n               new IllegalStateException(\"The provided statement did not run a ksql query\"));\n     }\n \n-    return QueryDescriptionFactory.forQueryMetadata(metadata);\n+    return QueryDescriptionFactory.forQueryMetadata(\n+        metadata,\n+        Collections.singletonMap(\n+            new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n+            metadata.getState()));\n   }\n \n   private static QueryDescription explainQuery(\n       final String queryId,\n-      final KsqlExecutionContext executionContext\n+      final KsqlExecutionContext executionContext,\n+      final SessionProperties sessionProperties\n   ) {\n     final PersistentQueryMetadata metadata = executionContext\n         .getPersistentQuery(new QueryId(queryId))\n         .orElseThrow(() -> new KsqlException(\n             \"Query with id:\" + queryId + \" does not exist, \"\n                 + \"use SHOW QUERIES to view the full set of queries.\"));\n \n-    return QueryDescriptionFactory.forQueryMetadata(metadata);\n+    return QueryDescriptionFactory.forQueryMetadata(\n+        metadata,\n+        Collections.singletonMap(\n+            new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n+            metadata.getState()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d"}, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgxMDE5Mw==", "bodyText": "This is called sessionProperties on the receiving end... consider calling it sessionProperties here?", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400810193", "createdAt": "2020-03-31T10:35:22Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-execution/src/main/java/io/confluent/ksql/services/SimpleKsqlClient.java", "diffHunk": "@@ -34,6 +34,19 @@\n       String sql\n   );\n \n+  /**\n+   * Send a request to remote Ksql server.\n+   * @param serverEndPoint the remote destination\n+   * @param sql the sql statement\n+   * @param requestProperties the request metadata provided by the server\n+   * @return the result of sql statement execution\n+   */\n+  RestResponse<KsqlEntityList> makeKsqlRequestWithRequestProperties(\n+      URI serverEndPoint,\n+      String sql,\n+      Map<String, ?> requestProperties", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgxNDk3OQ==", "bodyText": "Humm... silently excluding results on failure is probably not ideal.  Better to capture this information and return it as part of the result, e.g. have a list of unresponsive hosts.", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400814979", "createdAt": "2020-03-31T10:44:25Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -40,25 +63,169 @@ private ListQueriesExecutor() { }\n   ) {\n     final ListQueries listQueries = statement.getStatement();\n     if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n+      return executeExtended(\n+          statement,\n+          sessionProperties,\n+          executionContext,\n+          serviceContext);\n+    }\n+\n+    final List<RunningQuery> runningQueries = executionContext.getPersistentQueries()\n+        .stream()\n+        .map(q -> {\n+          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n+          return new RunningQuery(\n+              q.getStatementString(),\n+              ImmutableSet.of(q.getSinkName().text()),\n+              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n+              q.getQueryId(),\n+              kafkaStreamsStateCount\n+          );\n+        }).collect(Collectors.toList());\n+\n+    final Map<String, RunningQuery> queryToRunningQuery = runningQueries.stream().collect(\n+        Collectors.toMap(\n+            query -> query.getId().toString(),\n+            query -> query));\n+\n+    if (!sessionProperties.getInternalRequest()) {\n+      final Set<HostInfo> remoteHosts =\n+          DiscoverRemoteHostsUtil.getRemoteHosts(\n+              executionContext.getPersistentQueries(),\n+              sessionProperties.getKsqlHostInfo());\n+      \n+      if (remoteHosts.size() != 0) {\n+        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+        for (HostInfo host : remoteHosts) {\n+          futureRunningQueries.add(executorService.submit(() -> {\n+            final KsqlEntityList response = serviceContext.getKsqlClient()\n+                .makeKsqlRequestWithRequestProperties(\n+                    ServerUtil.buildRemoteUri(\n+                        sessionProperties.getLocalUrl(),\n+                        host.host(),\n+                        host.port()\n+                    ),\n+                    statement.getStatementText(),\n+                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+                .getResponse();\n+            return ((Queries) response.get(0)).getQueries();\n+          }));\n+        }\n+\n+        final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n+                new ConcurrentLinkedQueue<>();\n+        futureRunningQueries.forEach(future -> {\n+          try {\n+            remoteRunningQueries.addAll(future.get());\n+          } catch (final Exception e) {\n+            // If the future fails from a server, that result won't be included in the output", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d"}, "originalPosition": 108}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgxODQyNg==", "bodyText": "Rather than wrap values in new ArrayList, why not change Queries constructor to take a Collection and internally take a defensive immutable copy using ImmutableList.copyOf(queries)?", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400818426", "createdAt": "2020-03-31T10:51:14Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -40,25 +63,169 @@ private ListQueriesExecutor() { }\n   ) {\n     final ListQueries listQueries = statement.getStatement();\n     if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n+      return executeExtended(\n+          statement,\n+          sessionProperties,\n+          executionContext,\n+          serviceContext);\n+    }\n+\n+    final List<RunningQuery> runningQueries = executionContext.getPersistentQueries()\n+        .stream()\n+        .map(q -> {\n+          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n+          return new RunningQuery(\n+              q.getStatementString(),\n+              ImmutableSet.of(q.getSinkName().text()),\n+              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n+              q.getQueryId(),\n+              kafkaStreamsStateCount\n+          );\n+        }).collect(Collectors.toList());\n+\n+    final Map<String, RunningQuery> queryToRunningQuery = runningQueries.stream().collect(\n+        Collectors.toMap(\n+            query -> query.getId().toString(),\n+            query -> query));\n+\n+    if (!sessionProperties.getInternalRequest()) {\n+      final Set<HostInfo> remoteHosts =\n+          DiscoverRemoteHostsUtil.getRemoteHosts(\n+              executionContext.getPersistentQueries(),\n+              sessionProperties.getKsqlHostInfo());\n+      \n+      if (remoteHosts.size() != 0) {\n+        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+        for (HostInfo host : remoteHosts) {\n+          futureRunningQueries.add(executorService.submit(() -> {\n+            final KsqlEntityList response = serviceContext.getKsqlClient()\n+                .makeKsqlRequestWithRequestProperties(\n+                    ServerUtil.buildRemoteUri(\n+                        sessionProperties.getLocalUrl(),\n+                        host.host(),\n+                        host.port()\n+                    ),\n+                    statement.getStatementText(),\n+                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+                .getResponse();\n+            return ((Queries) response.get(0)).getQueries();\n+          }));\n+        }\n+\n+        final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n+                new ConcurrentLinkedQueue<>();\n+        futureRunningQueries.forEach(future -> {\n+          try {\n+            remoteRunningQueries.addAll(future.get());\n+          } catch (final Exception e) {\n+            // If the future fails from a server, that result won't be included in the output\n+          }\n+        });\n+\n+        for (RunningQuery q : remoteRunningQueries) {\n+          final String queryId = q.getId().toString();\n+\n+          // If the query has already been discovered, update the KafkaStreamsStateCount object\n+          if (queryToRunningQuery.containsKey(queryId)) {\n+            for (Map.Entry<KafkaStreams.State, Integer> entry :\n+                q.getState().getState().entrySet()) {\n+              queryToRunningQuery\n+                  .get(queryId)\n+                  .getState()\n+                  .updateStateCount(entry.getKey(), entry.getValue());\n+            }\n+          } else {\n+            queryToRunningQuery.put(queryId, q);\n+          }\n+        }\n+      }\n     }\n \n     return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n         statement.getStatementText(),\n-        executionContext.getPersistentQueries()\n-            .stream()\n-            .map(q -> new RunningQuery(\n-                q.getStatementString(),\n-                ImmutableSet.of(q.getSinkName().text()),\n-                ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n-                q.getQueryId(),\n-                Optional.of(q.getState())\n-            ))\n-            .collect(Collectors.toList())));\n+        new ArrayList<>(queryToRunningQuery.values())));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d"}, "originalPosition": 143}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgyMDI5Ng==", "bodyText": "nit: private", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400820296", "createdAt": "2020-03-31T10:54:33Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ExplainExecutorTest.java", "diffHunk": "@@ -37,21 +38,35 @@\n import io.confluent.ksql.serde.KeyFormat;\n import io.confluent.ksql.statement.ConfiguredStatement;\n import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.util.KsqlHostInfo;\n import io.confluent.ksql.util.PersistentQueryMetadata;\n+\n+import java.util.Collections;\n import java.util.Optional;\n+\n+import org.junit.Before;\n import org.junit.Rule;\n import org.junit.Test;\n import org.junit.rules.ExpectedException;\n import org.junit.runner.RunWith;\n+import org.mockito.Mock;\n import org.mockito.junit.MockitoJUnitRunner;\n \n @RunWith(MockitoJUnitRunner.class)\n public class ExplainExecutorTest {\n \n+  private static final KsqlHostInfo LOCAL_HOST = new KsqlHostInfo(\"host\", 8080);\n   @Rule\n   public final TemporaryEngine engine = new TemporaryEngine();\n   @Rule\n   public ExpectedException expectedException = ExpectedException.none();\n+  @Mock\n+  SessionProperties sessionProperties;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgyMDQ2OQ==", "bodyText": "nit: private", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400820469", "createdAt": "2020-03-31T10:54:53Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java", "diffHunk": "@@ -39,17 +41,39 @@\n import io.confluent.ksql.serde.KeyFormat;\n import io.confluent.ksql.statement.ConfiguredStatement;\n import io.confluent.ksql.util.PersistentQueryMetadata;\n+\n+import java.util.Collections;\n+import java.util.Map;\n import java.util.Optional;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.junit.Before;\n import org.junit.Rule;\n import org.junit.Test;\n import org.junit.runner.RunWith;\n+import org.mockito.Mock;\n import org.mockito.junit.MockitoJUnitRunner;\n \n @RunWith(MockitoJUnitRunner.class)\n public class ListQueriesExecutorTest {\n \n+  private static final KsqlHostInfoEntity LOCAL_HOST = new KsqlHostInfoEntity(\"some host\", 555);\n+  private static final KafkaStreams.State QUERY_STATE = KafkaStreams.State.RUNNING;\n+  private static final Map<KsqlHostInfoEntity, String> KSQL_HOST_INFO_MAP = Collections.singletonMap(LOCAL_HOST, QUERY_STATE.toString());\n   @Rule public final TemporaryEngine engine = new TemporaryEngine();\n \n+  @Mock\n+  SessionProperties sessionProperties;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgyMDczMA==", "bodyText": "nit: private, and prefer mock to actual instance, as this decouples this test from KafkaStreamsStateCount implementation.", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400820730", "createdAt": "2020-03-31T10:55:22Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutorTest.java", "diffHunk": "@@ -39,17 +41,39 @@\n import io.confluent.ksql.serde.KeyFormat;\n import io.confluent.ksql.statement.ConfiguredStatement;\n import io.confluent.ksql.util.PersistentQueryMetadata;\n+\n+import java.util.Collections;\n+import java.util.Map;\n import java.util.Optional;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.junit.Before;\n import org.junit.Rule;\n import org.junit.Test;\n import org.junit.runner.RunWith;\n+import org.mockito.Mock;\n import org.mockito.junit.MockitoJUnitRunner;\n \n @RunWith(MockitoJUnitRunner.class)\n public class ListQueriesExecutorTest {\n \n+  private static final KsqlHostInfoEntity LOCAL_HOST = new KsqlHostInfoEntity(\"some host\", 555);\n+  private static final KafkaStreams.State QUERY_STATE = KafkaStreams.State.RUNNING;\n+  private static final Map<KsqlHostInfoEntity, String> KSQL_HOST_INFO_MAP = Collections.singletonMap(LOCAL_HOST, QUERY_STATE.toString());\n   @Rule public final TemporaryEngine engine = new TemporaryEngine();\n \n+  @Mock\n+  SessionProperties sessionProperties;\n+\n+  KafkaStreamsStateCount kafkaStreamsStateCount;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgyMjUxOA==", "bodyText": "I actually think this is a worthwhile test, (replying to @agavra's comment). We need to test somewhere that two nodes can actually talk to each other to resolve the full list of states.  The more we mock out the less sure we are that this all functionally hangs together.\nAt the moment we don't have some centralised was of communicating between nodes with its own set of tests.  If we did, then I'd agree with this test testing too much.", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400822518", "createdAt": "2020-03-31T10:58:29Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.integration;\n+\n+import static io.confluent.ksql.rest.integration.HighAvailabilityTestUtil.waitForClusterToBeDiscovered;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.containsInAnyOrder;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.is;\n+\n+import io.confluent.common.utils.IntegrationTest;\n+import io.confluent.ksql.integration.IntegrationTestHarness;\n+import io.confluent.ksql.integration.Retry;\n+import io.confluent.ksql.rest.entity.KsqlEntity;\n+import io.confluent.ksql.rest.entity.KsqlHostInfoEntity;\n+import io.confluent.ksql.rest.entity.Queries;\n+import io.confluent.ksql.rest.entity.QueryDescription;\n+import io.confluent.ksql.rest.entity.QueryDescriptionList;\n+import io.confluent.ksql.rest.entity.RunningQuery;\n+import io.confluent.ksql.rest.server.KsqlRestConfig;\n+import io.confluent.ksql.rest.server.TestKsqlRestApp;\n+import io.confluent.ksql.serde.FormatFactory;\n+import io.confluent.ksql.test.util.secure.ClientTrustStore;\n+import io.confluent.ksql.util.PageViewDataProvider;\n+\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+import kafka.zookeeper.ZooKeeperClientException;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.RuleChain;\n+\n+@Category({IntegrationTest.class})\n+public class ShowQueriesMultiNodeFunctionalTest {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTM5MDQ1NA=="}, "originalCommit": {"oid": "5271edf3d2fbf858bde71926fedd246edd9fa693"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgyMzI1Ng==", "bodyText": "fyi: !remoteHosts.isEmpty() is often more efficient than remoteHosts.size() != 0.  The former only needs to check the first entry in the list. The latter may, depending on the collection implementation, need to iterate all entries to find the size.", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400823256", "createdAt": "2020-03-31T10:59:47Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -40,25 +63,169 @@ private ListQueriesExecutor() { }\n   ) {\n     final ListQueries listQueries = statement.getStatement();\n     if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n+      return executeExtended(\n+          statement,\n+          sessionProperties,\n+          executionContext,\n+          serviceContext);\n+    }\n+\n+    final List<RunningQuery> runningQueries = executionContext.getPersistentQueries()\n+        .stream()\n+        .map(q -> {\n+          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n+          return new RunningQuery(\n+              q.getStatementString(),\n+              ImmutableSet.of(q.getSinkName().text()),\n+              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n+              q.getQueryId(),\n+              kafkaStreamsStateCount\n+          );\n+        }).collect(Collectors.toList());\n+\n+    final Map<String, RunningQuery> queryToRunningQuery = runningQueries.stream().collect(\n+        Collectors.toMap(\n+            query -> query.getId().toString(),\n+            query -> query));\n+\n+    if (!sessionProperties.getInternalRequest()) {\n+      final Set<HostInfo> remoteHosts =\n+          DiscoverRemoteHostsUtil.getRemoteHosts(\n+              executionContext.getPersistentQueries(),\n+              sessionProperties.getKsqlHostInfo());\n+      \n+      if (remoteHosts.size() != 0) {\n+        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+        for (HostInfo host : remoteHosts) {\n+          futureRunningQueries.add(executorService.submit(() -> {\n+            final KsqlEntityList response = serviceContext.getKsqlClient()\n+                .makeKsqlRequestWithRequestProperties(\n+                    ServerUtil.buildRemoteUri(\n+                        sessionProperties.getLocalUrl(),\n+                        host.host(),\n+                        host.port()\n+                    ),\n+                    statement.getStatementText(),\n+                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+                .getResponse();\n+            return ((Queries) response.get(0)).getQueries();\n+          }));\n+        }\n+\n+        final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n+                new ConcurrentLinkedQueue<>();\n+        futureRunningQueries.forEach(future -> {\n+          try {\n+            remoteRunningQueries.addAll(future.get());\n+          } catch (final Exception e) {\n+            // If the future fails from a server, that result won't be included in the output\n+          }\n+        });\n+\n+        for (RunningQuery q : remoteRunningQueries) {\n+          final String queryId = q.getId().toString();\n+\n+          // If the query has already been discovered, update the KafkaStreamsStateCount object\n+          if (queryToRunningQuery.containsKey(queryId)) {\n+            for (Map.Entry<KafkaStreams.State, Integer> entry :\n+                q.getState().getState().entrySet()) {\n+              queryToRunningQuery\n+                  .get(queryId)\n+                  .getState()\n+                  .updateStateCount(entry.getKey(), entry.getValue());\n+            }\n+          } else {\n+            queryToRunningQuery.put(queryId, q);\n+          }\n+        }\n+      }\n     }\n \n     return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n         statement.getStatementText(),\n-        executionContext.getPersistentQueries()\n-            .stream()\n-            .map(q -> new RunningQuery(\n-                q.getStatementString(),\n-                ImmutableSet.of(q.getSinkName().text()),\n-                ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n-                q.getQueryId(),\n-                Optional.of(q.getState())\n-            ))\n-            .collect(Collectors.toList())));\n+        new ArrayList<>(queryToRunningQuery.values())));\n   }\n \n-}\n+  private static Optional<KsqlEntity> executeExtended(\n+      final ConfiguredStatement<ListQueries> statement,\n+      final SessionProperties sessionProperties,\n+      final KsqlExecutionContext executionContext,\n+      final ServiceContext serviceContext\n+  ) {\n+    final List<QueryDescription> queryDescriptions = \n+        executionContext.getPersistentQueries().stream()\n+            .map(query -> {\n+              final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n+              ksqlHostQueryState.put(\n+                  new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n+                  query.getState());\n+              return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n+            }).collect(Collectors.toList());\n+\n+    final Map<String, QueryDescription> queryToQueryDescription =\n+        queryDescriptions.stream().collect(\n+            Collectors.toMap(\n+                query -> query.getId().toString(),\n+                query -> query));\n+\n+    if (!sessionProperties.getInternalRequest()) {\n+      final Set<HostInfo> remoteHosts =\n+          DiscoverRemoteHostsUtil.getRemoteHosts(\n+              executionContext.getPersistentQueries(),\n+              sessionProperties.getKsqlHostInfo());\n+\n+      if (remoteHosts.size() != 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d"}, "originalPosition": 175}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgyNDE4Ng==", "bodyText": "Why create it as a List<QueryDescription> only to convert to a Map<String, QueryDescription>? Why not just create as a map initially?\nAlso, why not make the map stronger typed, e.g. Map<QueryId, QueryDescription>?", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400824186", "createdAt": "2020-03-31T11:01:36Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -40,25 +63,169 @@ private ListQueriesExecutor() { }\n   ) {\n     final ListQueries listQueries = statement.getStatement();\n     if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n+      return executeExtended(\n+          statement,\n+          sessionProperties,\n+          executionContext,\n+          serviceContext);\n+    }\n+\n+    final List<RunningQuery> runningQueries = executionContext.getPersistentQueries()\n+        .stream()\n+        .map(q -> {\n+          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n+          return new RunningQuery(\n+              q.getStatementString(),\n+              ImmutableSet.of(q.getSinkName().text()),\n+              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n+              q.getQueryId(),\n+              kafkaStreamsStateCount\n+          );\n+        }).collect(Collectors.toList());\n+\n+    final Map<String, RunningQuery> queryToRunningQuery = runningQueries.stream().collect(\n+        Collectors.toMap(\n+            query -> query.getId().toString(),\n+            query -> query));\n+\n+    if (!sessionProperties.getInternalRequest()) {\n+      final Set<HostInfo> remoteHosts =\n+          DiscoverRemoteHostsUtil.getRemoteHosts(\n+              executionContext.getPersistentQueries(),\n+              sessionProperties.getKsqlHostInfo());\n+      \n+      if (remoteHosts.size() != 0) {\n+        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+        for (HostInfo host : remoteHosts) {\n+          futureRunningQueries.add(executorService.submit(() -> {\n+            final KsqlEntityList response = serviceContext.getKsqlClient()\n+                .makeKsqlRequestWithRequestProperties(\n+                    ServerUtil.buildRemoteUri(\n+                        sessionProperties.getLocalUrl(),\n+                        host.host(),\n+                        host.port()\n+                    ),\n+                    statement.getStatementText(),\n+                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+                .getResponse();\n+            return ((Queries) response.get(0)).getQueries();\n+          }));\n+        }\n+\n+        final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n+                new ConcurrentLinkedQueue<>();\n+        futureRunningQueries.forEach(future -> {\n+          try {\n+            remoteRunningQueries.addAll(future.get());\n+          } catch (final Exception e) {\n+            // If the future fails from a server, that result won't be included in the output\n+          }\n+        });\n+\n+        for (RunningQuery q : remoteRunningQueries) {\n+          final String queryId = q.getId().toString();\n+\n+          // If the query has already been discovered, update the KafkaStreamsStateCount object\n+          if (queryToRunningQuery.containsKey(queryId)) {\n+            for (Map.Entry<KafkaStreams.State, Integer> entry :\n+                q.getState().getState().entrySet()) {\n+              queryToRunningQuery\n+                  .get(queryId)\n+                  .getState()\n+                  .updateStateCount(entry.getKey(), entry.getValue());\n+            }\n+          } else {\n+            queryToRunningQuery.put(queryId, q);\n+          }\n+        }\n+      }\n     }\n \n     return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n         statement.getStatementText(),\n-        executionContext.getPersistentQueries()\n-            .stream()\n-            .map(q -> new RunningQuery(\n-                q.getStatementString(),\n-                ImmutableSet.of(q.getSinkName().text()),\n-                ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n-                q.getQueryId(),\n-                Optional.of(q.getState())\n-            ))\n-            .collect(Collectors.toList())));\n+        new ArrayList<>(queryToRunningQuery.values())));\n   }\n \n-}\n+  private static Optional<KsqlEntity> executeExtended(\n+      final ConfiguredStatement<ListQueries> statement,\n+      final SessionProperties sessionProperties,\n+      final KsqlExecutionContext executionContext,\n+      final ServiceContext serviceContext\n+  ) {\n+    final List<QueryDescription> queryDescriptions = \n+        executionContext.getPersistentQueries().stream()\n+            .map(query -> {\n+              final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n+              ksqlHostQueryState.put(\n+                  new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n+                  query.getState());\n+              return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n+            }).collect(Collectors.toList());\n+\n+    final Map<String, QueryDescription> queryToQueryDescription =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d"}, "originalPosition": 163}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgzMjkyNw==", "bodyText": "These executor services are not being shutdown, so they're a resource leak!", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400832927", "createdAt": "2020-03-31T11:18:20Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -40,25 +63,169 @@ private ListQueriesExecutor() { }\n   ) {\n     final ListQueries listQueries = statement.getStatement();\n     if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n+      return executeExtended(\n+          statement,\n+          sessionProperties,\n+          executionContext,\n+          serviceContext);\n+    }\n+\n+    final List<RunningQuery> runningQueries = executionContext.getPersistentQueries()\n+        .stream()\n+        .map(q -> {\n+          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n+          return new RunningQuery(\n+              q.getStatementString(),\n+              ImmutableSet.of(q.getSinkName().text()),\n+              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n+              q.getQueryId(),\n+              kafkaStreamsStateCount\n+          );\n+        }).collect(Collectors.toList());\n+\n+    final Map<String, RunningQuery> queryToRunningQuery = runningQueries.stream().collect(\n+        Collectors.toMap(\n+            query -> query.getId().toString(),\n+            query -> query));\n+\n+    if (!sessionProperties.getInternalRequest()) {\n+      final Set<HostInfo> remoteHosts =\n+          DiscoverRemoteHostsUtil.getRemoteHosts(\n+              executionContext.getPersistentQueries(),\n+              sessionProperties.getKsqlHostInfo());\n+      \n+      if (remoteHosts.size() != 0) {\n+        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d"}, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgzNTQ5OQ==", "bodyText": "It may be sensible to add a timeout on this get() call, or at least ensure the ksqlClient is configured with sensible connect and read timeouts. We don't want this blocking indefinitely.", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400835499", "createdAt": "2020-03-31T11:23:19Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -40,25 +63,169 @@ private ListQueriesExecutor() { }\n   ) {\n     final ListQueries listQueries = statement.getStatement();\n     if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n+      return executeExtended(\n+          statement,\n+          sessionProperties,\n+          executionContext,\n+          serviceContext);\n+    }\n+\n+    final List<RunningQuery> runningQueries = executionContext.getPersistentQueries()\n+        .stream()\n+        .map(q -> {\n+          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n+          return new RunningQuery(\n+              q.getStatementString(),\n+              ImmutableSet.of(q.getSinkName().text()),\n+              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n+              q.getQueryId(),\n+              kafkaStreamsStateCount\n+          );\n+        }).collect(Collectors.toList());\n+\n+    final Map<String, RunningQuery> queryToRunningQuery = runningQueries.stream().collect(\n+        Collectors.toMap(\n+            query -> query.getId().toString(),\n+            query -> query));\n+\n+    if (!sessionProperties.getInternalRequest()) {\n+      final Set<HostInfo> remoteHosts =\n+          DiscoverRemoteHostsUtil.getRemoteHosts(\n+              executionContext.getPersistentQueries(),\n+              sessionProperties.getKsqlHostInfo());\n+      \n+      if (remoteHosts.size() != 0) {\n+        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+        for (HostInfo host : remoteHosts) {\n+          futureRunningQueries.add(executorService.submit(() -> {\n+            final KsqlEntityList response = serviceContext.getKsqlClient()\n+                .makeKsqlRequestWithRequestProperties(\n+                    ServerUtil.buildRemoteUri(\n+                        sessionProperties.getLocalUrl(),\n+                        host.host(),\n+                        host.port()\n+                    ),\n+                    statement.getStatementText(),\n+                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+                .getResponse();\n+            return ((Queries) response.get(0)).getQueries();\n+          }));\n+        }\n+\n+        final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =\n+                new ConcurrentLinkedQueue<>();\n+        futureRunningQueries.forEach(future -> {\n+          try {\n+            remoteRunningQueries.addAll(future.get());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d"}, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDgzOTE4OA==", "bodyText": ".getResponse throws unsupported operation on an error response!\nThis shouts \"Missing unit tests\" to me.  Can you add unit tests that:\na) return a failed RestResponse\nb) throw an exception from the Future.get.", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400839188", "createdAt": "2020-03-31T11:30:13Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -40,25 +63,169 @@ private ListQueriesExecutor() { }\n   ) {\n     final ListQueries listQueries = statement.getStatement();\n     if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n+      return executeExtended(\n+          statement,\n+          sessionProperties,\n+          executionContext,\n+          serviceContext);\n+    }\n+\n+    final List<RunningQuery> runningQueries = executionContext.getPersistentQueries()\n+        .stream()\n+        .map(q -> {\n+          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n+          return new RunningQuery(\n+              q.getStatementString(),\n+              ImmutableSet.of(q.getSinkName().text()),\n+              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n+              q.getQueryId(),\n+              kafkaStreamsStateCount\n+          );\n+        }).collect(Collectors.toList());\n+\n+    final Map<String, RunningQuery> queryToRunningQuery = runningQueries.stream().collect(\n+        Collectors.toMap(\n+            query -> query.getId().toString(),\n+            query -> query));\n+\n+    if (!sessionProperties.getInternalRequest()) {\n+      final Set<HostInfo> remoteHosts =\n+          DiscoverRemoteHostsUtil.getRemoteHosts(\n+              executionContext.getPersistentQueries(),\n+              sessionProperties.getKsqlHostInfo());\n+      \n+      if (remoteHosts.size() != 0) {\n+        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+        for (HostInfo host : remoteHosts) {\n+          futureRunningQueries.add(executorService.submit(() -> {\n+            final KsqlEntityList response = serviceContext.getKsqlClient()\n+                .makeKsqlRequestWithRequestProperties(\n+                    ServerUtil.buildRemoteUri(\n+                        sessionProperties.getLocalUrl(),\n+                        host.host(),\n+                        host.port()\n+                    ),\n+                    statement.getStatementText(),\n+                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+                .getResponse();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg1NTkxNQ==", "bodyText": "nit: does not throw InterruptedException", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400855915", "createdAt": "2020-03-31T12:01:02Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.integration;\n+\n+import static io.confluent.ksql.rest.integration.HighAvailabilityTestUtil.waitForClusterToBeDiscovered;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.containsInAnyOrder;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.is;\n+\n+import io.confluent.common.utils.IntegrationTest;\n+import io.confluent.ksql.integration.IntegrationTestHarness;\n+import io.confluent.ksql.integration.Retry;\n+import io.confluent.ksql.rest.entity.KsqlEntity;\n+import io.confluent.ksql.rest.entity.KsqlHostInfoEntity;\n+import io.confluent.ksql.rest.entity.Queries;\n+import io.confluent.ksql.rest.entity.QueryDescription;\n+import io.confluent.ksql.rest.entity.QueryDescriptionList;\n+import io.confluent.ksql.rest.entity.RunningQuery;\n+import io.confluent.ksql.rest.server.KsqlRestConfig;\n+import io.confluent.ksql.rest.server.TestKsqlRestApp;\n+import io.confluent.ksql.serde.FormatFactory;\n+import io.confluent.ksql.test.util.secure.ClientTrustStore;\n+import io.confluent.ksql.util.PageViewDataProvider;\n+\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+import kafka.zookeeper.ZooKeeperClientException;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.RuleChain;\n+\n+@Category({IntegrationTest.class})\n+public class ShowQueriesMultiNodeFunctionalTest {\n+\n+  private static final PageViewDataProvider PAGE_VIEWS_PROVIDER = new PageViewDataProvider();\n+  private static final String PAGE_VIEW_TOPIC = PAGE_VIEWS_PROVIDER.topicName();\n+  private static final String PAGE_VIEW_STREAM = PAGE_VIEWS_PROVIDER.kstreamName();\n+  private static final KsqlHostInfoEntity host0 = new KsqlHostInfoEntity(\"localhost\", 8088);\n+  private static final KsqlHostInfoEntity host1 = new KsqlHostInfoEntity(\"localhost\", 8089);\n+  private static final IntegrationTestHarness TEST_HARNESS = IntegrationTestHarness.build();\n+  private static final TestKsqlRestApp REST_APP_0 = TestKsqlRestApp\n+      .builder(TEST_HARNESS::kafkaBootstrapServers)\n+      .withProperty(KsqlRestConfig.LISTENERS_CONFIG, \"http://localhost:8088\")\n+      .withProperty(KsqlRestConfig.ADVERTISED_LISTENER_CONFIG, \"http://localhost:8088\")\n+      .withProperty(KsqlRestConfig.KSQL_HEARTBEAT_ENABLE_CONFIG, true)\n+      .withProperties(ClientTrustStore.trustStoreProps())\n+      .build();\n+  private static final TestKsqlRestApp REST_APP_1 = TestKsqlRestApp\n+      .builder(TEST_HARNESS::kafkaBootstrapServers)\n+      .withProperty(KsqlRestConfig.LISTENERS_CONFIG, \"http://localhost:8089\")\n+      .withProperty(KsqlRestConfig.ADVERTISED_LISTENER_CONFIG, \"http://localhost:8089\")\n+      .withProperty(KsqlRestConfig.KSQL_HEARTBEAT_ENABLE_CONFIG, true)\n+      .withProperties(ClientTrustStore.trustStoreProps())\n+      .build();\n+\n+  @ClassRule\n+  public static final RuleChain CHAIN = RuleChain\n+      .outerRule(Retry.of(3, ZooKeeperClientException.class, 3, TimeUnit.SECONDS))\n+      .around(TEST_HARNESS)\n+      .around(REST_APP_0)\n+      .around(REST_APP_1);\n+\n+  @BeforeClass\n+  public static void setUpClass() throws InterruptedException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d"}, "originalPosition": 81}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg1NzIzNQ==", "bodyText": "When I run this test I see this reported in the output:\njava.lang.UnsupportedOperationException: KSQL client is disabled\n\tat io.confluent.ksql.services.DisabledKsqlClient.makeAsyncHeartbeatRequest(DisabledKsqlClient.java:70)\n\tat io.confluent.ksql.rest.server.HeartbeatAgent$SendHeartbeatService.runOneIteration(HeartbeatAgent.java:322)\n\tat com.google.common.util.concurrent.AbstractScheduledService$ServiceDelegate$Task.run(AbstractScheduledService.java:193)\n\tat com.google.common.util.concurrent.Callables$4.run(Callables.java:119)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.runAndReset$$$capture(FutureTask.java:308)\n\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nWhich seems to suggest that maybe this isn't doing what you think it is.\nRather than relying on another feature to ensure the queries are running before proceeding, might it not be better to code the tests to await the expected final state?  This way, we can be sure that your change works even if heartbeats are disabled.\nTo achieve this, you can change your tests to use assertThatEventually, as I've shown below. assertThatEventually takes a Supplier which it polls to get a result.", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400857235", "createdAt": "2020-03-31T12:03:33Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.integration;\n+\n+import static io.confluent.ksql.rest.integration.HighAvailabilityTestUtil.waitForClusterToBeDiscovered;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.containsInAnyOrder;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.is;\n+\n+import io.confluent.common.utils.IntegrationTest;\n+import io.confluent.ksql.integration.IntegrationTestHarness;\n+import io.confluent.ksql.integration.Retry;\n+import io.confluent.ksql.rest.entity.KsqlEntity;\n+import io.confluent.ksql.rest.entity.KsqlHostInfoEntity;\n+import io.confluent.ksql.rest.entity.Queries;\n+import io.confluent.ksql.rest.entity.QueryDescription;\n+import io.confluent.ksql.rest.entity.QueryDescriptionList;\n+import io.confluent.ksql.rest.entity.RunningQuery;\n+import io.confluent.ksql.rest.server.KsqlRestConfig;\n+import io.confluent.ksql.rest.server.TestKsqlRestApp;\n+import io.confluent.ksql.serde.FormatFactory;\n+import io.confluent.ksql.test.util.secure.ClientTrustStore;\n+import io.confluent.ksql.util.PageViewDataProvider;\n+\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+import kafka.zookeeper.ZooKeeperClientException;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.RuleChain;\n+\n+@Category({IntegrationTest.class})\n+public class ShowQueriesMultiNodeFunctionalTest {\n+\n+  private static final PageViewDataProvider PAGE_VIEWS_PROVIDER = new PageViewDataProvider();\n+  private static final String PAGE_VIEW_TOPIC = PAGE_VIEWS_PROVIDER.topicName();\n+  private static final String PAGE_VIEW_STREAM = PAGE_VIEWS_PROVIDER.kstreamName();\n+  private static final KsqlHostInfoEntity host0 = new KsqlHostInfoEntity(\"localhost\", 8088);\n+  private static final KsqlHostInfoEntity host1 = new KsqlHostInfoEntity(\"localhost\", 8089);\n+  private static final IntegrationTestHarness TEST_HARNESS = IntegrationTestHarness.build();\n+  private static final TestKsqlRestApp REST_APP_0 = TestKsqlRestApp\n+      .builder(TEST_HARNESS::kafkaBootstrapServers)\n+      .withProperty(KsqlRestConfig.LISTENERS_CONFIG, \"http://localhost:8088\")\n+      .withProperty(KsqlRestConfig.ADVERTISED_LISTENER_CONFIG, \"http://localhost:8088\")\n+      .withProperty(KsqlRestConfig.KSQL_HEARTBEAT_ENABLE_CONFIG, true)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk3NzM1MQ=="}, "originalCommit": {"oid": "5271edf3d2fbf858bde71926fedd246edd9fa693"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg2NTY2MQ==", "bodyText": "I can replace this with a test that uses assertThatEventually which passes without any reliance on heartbeating:\n@Test\n  public void shouldShowAllQueries() {\n    // When:\n    final Supplier<String> app0Response = () -> getShowQueriesResult(REST_APP_0);\n    final Supplier<String> app1Response = () -> getShowQueriesResult(REST_APP_1);\n\n    // Then:\n    assertThatEventually(\"App0\", app0Response, is(\"RUNNING:2\"));\n    assertThatEventually(\"App1\", app1Response, is(\"RUNNING:2\"));\n  }\n\n  private static String getShowQueriesResult(final TestKsqlRestApp restApp) {\n    final List<KsqlEntity> results = RestIntegrationTestUtil.makeKsqlRequest(\n        restApp,\n        \"Show Queries;\"\n    );\n\n    if (results.size() != 1) {\n      return \"Expected 1 response, got \" + results.size();\n    }\n\n    final KsqlEntity result = results.get(0);\n\n    if (!(result instanceof Queries)) {\n      return \"Expected Queries, got \" + result;\n    }\n\n    final List<RunningQuery> runningQueries = ((Queries) result)\n        .getQueries();\n\n    if (runningQueries.size() != 1) {\n      return \"Expected 1 running query, got \" + runningQueries.size();\n    }\n\n    return runningQueries.get(0).getState().toString();\n  }\nSee if you can do the same for shouldShowAllQueriesExtended.", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400865661", "createdAt": "2020-03-31T12:18:06Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/integration/ShowQueriesMultiNodeFunctionalTest.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.integration;\n+\n+import static io.confluent.ksql.rest.integration.HighAvailabilityTestUtil.waitForClusterToBeDiscovered;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.containsInAnyOrder;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.is;\n+\n+import io.confluent.common.utils.IntegrationTest;\n+import io.confluent.ksql.integration.IntegrationTestHarness;\n+import io.confluent.ksql.integration.Retry;\n+import io.confluent.ksql.rest.entity.KsqlEntity;\n+import io.confluent.ksql.rest.entity.KsqlHostInfoEntity;\n+import io.confluent.ksql.rest.entity.Queries;\n+import io.confluent.ksql.rest.entity.QueryDescription;\n+import io.confluent.ksql.rest.entity.QueryDescriptionList;\n+import io.confluent.ksql.rest.entity.RunningQuery;\n+import io.confluent.ksql.rest.server.KsqlRestConfig;\n+import io.confluent.ksql.rest.server.TestKsqlRestApp;\n+import io.confluent.ksql.serde.FormatFactory;\n+import io.confluent.ksql.test.util.secure.ClientTrustStore;\n+import io.confluent.ksql.util.PageViewDataProvider;\n+\n+import java.util.List;\n+import java.util.concurrent.TimeUnit;\n+\n+import kafka.zookeeper.ZooKeeperClientException;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Test;\n+import org.junit.experimental.categories.Category;\n+import org.junit.rules.RuleChain;\n+\n+@Category({IntegrationTest.class})\n+public class ShowQueriesMultiNodeFunctionalTest {\n+\n+  private static final PageViewDataProvider PAGE_VIEWS_PROVIDER = new PageViewDataProvider();\n+  private static final String PAGE_VIEW_TOPIC = PAGE_VIEWS_PROVIDER.topicName();\n+  private static final String PAGE_VIEW_STREAM = PAGE_VIEWS_PROVIDER.kstreamName();\n+  private static final KsqlHostInfoEntity host0 = new KsqlHostInfoEntity(\"localhost\", 8088);\n+  private static final KsqlHostInfoEntity host1 = new KsqlHostInfoEntity(\"localhost\", 8089);\n+  private static final IntegrationTestHarness TEST_HARNESS = IntegrationTestHarness.build();\n+  private static final TestKsqlRestApp REST_APP_0 = TestKsqlRestApp\n+      .builder(TEST_HARNESS::kafkaBootstrapServers)\n+      .withProperty(KsqlRestConfig.LISTENERS_CONFIG, \"http://localhost:8088\")\n+      .withProperty(KsqlRestConfig.ADVERTISED_LISTENER_CONFIG, \"http://localhost:8088\")\n+      .withProperty(KsqlRestConfig.KSQL_HEARTBEAT_ENABLE_CONFIG, true)\n+      .withProperties(ClientTrustStore.trustStoreProps())\n+      .build();\n+  private static final TestKsqlRestApp REST_APP_1 = TestKsqlRestApp\n+      .builder(TEST_HARNESS::kafkaBootstrapServers)\n+      .withProperty(KsqlRestConfig.LISTENERS_CONFIG, \"http://localhost:8089\")\n+      .withProperty(KsqlRestConfig.ADVERTISED_LISTENER_CONFIG, \"http://localhost:8089\")\n+      .withProperty(KsqlRestConfig.KSQL_HEARTBEAT_ENABLE_CONFIG, true)\n+      .withProperties(ClientTrustStore.trustStoreProps())\n+      .build();\n+\n+  @ClassRule\n+  public static final RuleChain CHAIN = RuleChain\n+      .outerRule(Retry.of(3, ZooKeeperClientException.class, 3, TimeUnit.SECONDS))\n+      .around(TEST_HARNESS)\n+      .around(REST_APP_0)\n+      .around(REST_APP_1);\n+\n+  @BeforeClass\n+  public static void setUpClass() throws InterruptedException {\n+    TEST_HARNESS.ensureTopics(2, PAGE_VIEW_TOPIC);\n+    TEST_HARNESS.produceRows(PAGE_VIEW_TOPIC, PAGE_VIEWS_PROVIDER, FormatFactory.JSON);\n+    RestIntegrationTestUtil.createStream(REST_APP_0, PAGE_VIEWS_PROVIDER);\n+    RestIntegrationTestUtil.makeKsqlRequest(\n+        REST_APP_0,\n+        \"CREATE STREAM S AS SELECT * FROM \" + PAGE_VIEW_STREAM + \";\"\n+    );\n+    waitForClusterToBeDiscovered(REST_APP_0, 2);\n+  }\n+\n+  @Test\n+  public void shouldShowAllQueries() {\n+    final List<KsqlEntity> allEntities0 = RestIntegrationTestUtil.makeKsqlRequest(\n+        REST_APP_0,\n+        \"Show Queries;\"\n+    );\n+\n+    final List<RunningQuery> allRunningQueries0 = ((Queries) allEntities0.get(0)).getQueries();\n+    assertThat(allRunningQueries0.size(), equalTo(1));\n+    assertThat(allRunningQueries0.get(0).getState().toString(), is(\"RUNNING:2\"));\n+\n+    final List<KsqlEntity> allEntities1 = RestIntegrationTestUtil.makeKsqlRequest(\n+        REST_APP_1,\n+        \"Show Queries;\"\n+    );\n+\n+    final List<RunningQuery> allRunningQueries1 = ((Queries) allEntities1.get(0)).getQueries();\n+    assertThat(allRunningQueries1.size(), equalTo(1));\n+    assertThat(allRunningQueries0.get(0).getState().toString(), is(\"RUNNING:2\"));\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d"}, "originalPosition": 111}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg2NjcxMg==", "bodyText": "There is a lot of code duplication in this class.  Let's break it down and see how we can remove this duplication!\nIt seems to me that this class needs to be able to:\n- get the local node's running queries\n- get the local node's extended query info\n- scatter-gather either of the above requests to all nodes.\nAt the moment the scatter-gather code is duplicated: once for each of the type of info we need to get back. But the logic is the same!  Hence we should try to have only one copy of that logic.\nMy approach to this would to refactor the code so that there is a pair pf method to get the two different types of local info, a pair of methods to do the merging of the two different types and a single method for doing the scatter gather.\nIf we do all that, then we end up with something like:\npublic final class ListQueriesExecutor {\n\n  private static final Logger LOG = LoggerFactory.getLogger(ListQueriesExecutor.class);\n\n  private ListQueriesExecutor() {\n  }\n\n  public static Optional<KsqlEntity> execute(\n      final ConfiguredStatement<ListQueries> statement,\n      final SessionProperties sessionProperties,\n      final KsqlExecutionContext executionContext,\n      final ServiceContext serviceContext\n  ) {\n    final List<KsqlEntity> remoteResults =\n        scatterGather(statement, sessionProperties, executionContext, serviceContext);\n\n    return statement.getStatement().getShowExtended()\n        ? executeExtended(remoteResults, statement, sessionProperties, executionContext)\n        : executeSimple(remoteResults, statement, executionContext);\n  }\n\n  private static Optional<KsqlEntity> executeSimple(\n      final List<KsqlEntity> remoteResults,\n      final ConfiguredStatement<ListQueries> statement,\n      final KsqlExecutionContext executionContext\n  ) {\n    final Map<QueryId, RunningQuery> runningQueries = getLocalSimple(executionContext);\n\n    mergeSimple(remoteResults, runningQueries);\n\n    return Optional.of(new Queries(\n        statement.getStatementText(),\n        new ArrayList<>(runningQueries.values())));\n  }\n\n  private static Map<QueryId, RunningQuery> getLocalSimple(\n      final KsqlExecutionContext executionContext\n  ) {\n    return executionContext.getPersistentQueries()\n        .stream()\n        .map(q -> {\n          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n          return new RunningQuery(\n              q.getStatementString(),\n              ImmutableSet.of(q.getSinkName().text()),\n              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n              q.getQueryId(),\n              kafkaStreamsStateCount\n          );\n        }).collect(Collectors.toMap(RunningQuery::getId, Function.identity()));\n  }\n\n  private static void mergeSimple(\n      final List<KsqlEntity> remoteResults,\n      final Map<QueryId, RunningQuery> allResults\n  ) {\n    remoteResults.stream()\n        .map(Queries.class::cast)\n        .map(Queries::getQueries)\n        .flatMap(List::stream)\n        .forEach(rq ->\n            allResults.compute(rq.getId(), (id, existing) -> {\n              if (existing == null) {\n                return rq;\n              }\n\n              for (Entry<KafkaStreams.State, Integer> entry : rq.getState().getState().entrySet()) {\n                existing\n                    .getState()\n                    .updateStateCount(entry.getKey(), entry.getValue());\n              }\n\n              return existing;\n            })\n        );\n  }\n\n  private static Optional<KsqlEntity> executeExtended(\n      final List<KsqlEntity> remoteResults,\n      final ConfiguredStatement<ListQueries> statement,\n      final SessionProperties sessionProperties,\n      final KsqlExecutionContext executionContext\n  ) {\n    final Map<QueryId, QueryDescription> queryDescriptions =\n        getLocalExtended(sessionProperties, executionContext);\n\n    mergeExtended(remoteResults, queryDescriptions);\n\n    return Optional.of(new QueryDescriptionList(\n        statement.getStatementText(),\n        new ArrayList<>(queryDescriptions.values())));\n  }\n\n  private static Map<QueryId, QueryDescription> getLocalExtended(\n      final SessionProperties sessionProperties,\n      final KsqlExecutionContext executionContext\n  ) {\n    return executionContext.getPersistentQueries().stream()\n        .map(query -> {\n          final HashMap<KsqlHostInfoEntity, String> ksqlHostQueryState = new HashMap<>();\n          ksqlHostQueryState.put(\n              new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n              query.getState());\n          return QueryDescriptionFactory.forQueryMetadata(query, ksqlHostQueryState);\n        }).collect(Collectors.toMap(QueryDescription::getId, Function.identity()));\n  }\n\n  private static void mergeExtended(\n      final List<KsqlEntity> remoteResults,\n      final Map<QueryId, QueryDescription> allResults\n  ) {\n    remoteResults.stream()\n        .map(QueryDescriptionList.class::cast)\n        .map(QueryDescriptionList::getQueryDescriptions)\n        .flatMap(List::stream)\n        .forEach(qd ->\n            allResults.compute(qd.getId(), (id, existing) -> {\n              if (existing == null) {\n                return qd;\n              }\n\n              existing.getKsqlHostQueryState().putAll(qd.getKsqlHostQueryState());\n              return existing;\n            })\n        );\n  }\n\n  private static List<KsqlEntity> scatterGather(\n      final ConfiguredStatement<ListQueries> statement,\n      final SessionProperties sessionProperties,\n      final KsqlExecutionContext executionContext,\n      final ServiceContext serviceContext\n  ) {\n    if (sessionProperties.getInternalRequest()) {\n      return ImmutableList.of();\n    }\n\n    final Set<HostInfo> remoteHosts = DiscoverRemoteHostsUtil.getRemoteHosts(\n        executionContext.getPersistentQueries(),\n        sessionProperties.getKsqlHostInfo()\n    );\n\n    if (remoteHosts.isEmpty()) {\n      return ImmutableList.of();\n    }\n\n    final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n\n    try {\n      final SimpleKsqlClient ksqlClient = serviceContext.getKsqlClient();\n\n      final Map<HostInfo, Future<RestResponse<KsqlEntityList>>> futures = new HashMap<>();\n      for (HostInfo host : remoteHosts) {\n        final Future<RestResponse<KsqlEntityList>> f = executorService.submit(() -> ksqlClient\n            .makeKsqlRequestWithRequestProperties(\n                ServerUtil.buildRemoteUri(\n                    sessionProperties.getLocalUrl(),\n                    host.host(),\n                    host.port()\n                ),\n                statement.getStatementText(),\n                Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n        );\n\n        futures.put(host, f);\n      }\n\n      // Todo: we should NOT ignore these failed hosts:  we should include this in the response.\n      final List<HostInfo> failedHosts = new ArrayList<>();\n      final List<KsqlEntity> results = new ArrayList<>();\n      for (final Entry<HostInfo, Future<RestResponse<KsqlEntityList>>> e : futures.entrySet()) {\n        try {\n          final RestResponse<KsqlEntityList> response = e.getValue().get();\n          if (response.isErroneous()) {\n            LOG.warn(\"Failed to retrieve query info from host. host: {}, cause: {}\",\n                e.getKey(), response.getErrorMessage().getMessage());\n            failedHosts.add(e.getKey());\n          } else {\n            results.add(response.getResponse().get(0));\n          }\n        } catch (final Exception cause) {\n          LOG.warn(\"Failed to retrieve query info from host. host: \" + e.getKey(), cause);\n          failedHosts.add(e.getKey());\n        }\n      }\n\n      return results;\n    } finally {\n      executorService.shutdown();\n    }\n  }\n}", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400866712", "createdAt": "2020-03-31T12:19:35Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -40,25 +63,169 @@ private ListQueriesExecutor() { }\n   ) {\n     final ListQueries listQueries = statement.getStatement();\n     if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n+      return executeExtended(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg2ODY0Nw==", "bodyText": "Rather than create the KafkaStreamsStateCount here, why not just pass q.getState() to the RunningQuery constructor and internally create the KafkaStreamsStateCount instance?  Thereby removing code duplication...", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400868647", "createdAt": "2020-03-31T12:22:29Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -40,25 +63,169 @@ private ListQueriesExecutor() { }\n   ) {\n     final ListQueries listQueries = statement.getStatement();\n     if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n+      return executeExtended(\n+          statement,\n+          sessionProperties,\n+          executionContext,\n+          serviceContext);\n+    }\n+\n+    final List<RunningQuery> runningQueries = executionContext.getPersistentQueries()\n+        .stream()\n+        .map(q -> {\n+          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n+          return new RunningQuery(\n+              q.getStatementString(),\n+              ImmutableSet.of(q.getSinkName().text()),\n+              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n+              q.getQueryId(),\n+              kafkaStreamsStateCount\n+          );", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg2OTEzNg==", "bodyText": "No need for a concurrent collection type here. It's only being accessed by one thread...", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400869136", "createdAt": "2020-03-31T12:23:08Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -40,25 +63,169 @@ private ListQueriesExecutor() { }\n   ) {\n     final ListQueries listQueries = statement.getStatement();\n     if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n+      return executeExtended(\n+          statement,\n+          sessionProperties,\n+          executionContext,\n+          serviceContext);\n+    }\n+\n+    final List<RunningQuery> runningQueries = executionContext.getPersistentQueries()\n+        .stream()\n+        .map(q -> {\n+          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+          kafkaStreamsStateCount.updateStateCount(q.getState(), 1);\n+          return new RunningQuery(\n+              q.getStatementString(),\n+              ImmutableSet.of(q.getSinkName().text()),\n+              ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n+              q.getQueryId(),\n+              kafkaStreamsStateCount\n+          );\n+        }).collect(Collectors.toList());\n+\n+    final Map<String, RunningQuery> queryToRunningQuery = runningQueries.stream().collect(\n+        Collectors.toMap(\n+            query -> query.getId().toString(),\n+            query -> query));\n+\n+    if (!sessionProperties.getInternalRequest()) {\n+      final Set<HostInfo> remoteHosts =\n+          DiscoverRemoteHostsUtil.getRemoteHosts(\n+              executionContext.getPersistentQueries(),\n+              sessionProperties.getKsqlHostInfo());\n+      \n+      if (remoteHosts.size() != 0) {\n+        final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+        final List<Future<List<RunningQuery>>> futureRunningQueries = new ArrayList<>();\n+        for (HostInfo host : remoteHosts) {\n+          futureRunningQueries.add(executorService.submit(() -> {\n+            final KsqlEntityList response = serviceContext.getKsqlClient()\n+                .makeKsqlRequestWithRequestProperties(\n+                    ServerUtil.buildRemoteUri(\n+                        sessionProperties.getLocalUrl(),\n+                        host.host(),\n+                        host.port()\n+                    ),\n+                    statement.getStatementText(),\n+                    Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+                .getResponse();\n+            return ((Queries) response.get(0)).getQueries();\n+          }));\n+        }\n+\n+        final ConcurrentLinkedQueue<RunningQuery> remoteRunningQueries =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg3MTIwMg==", "bodyText": "Rather than change this, just make KsqlRequstConfig not log on construction.  You can do this by changing its constructor to pass false for the doLog param of AbstractConfig's constructor:\npublic KsqlRequestConfig(final Map<?, ?> props) {\n    super(CURRENT_DEF, props, false);\n  }", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400871202", "createdAt": "2020-03-31T12:26:17Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/KsqlResource.java", "diffHunk": "@@ -247,8 +247,9 @@ public Response handleKsqlStatements(\n           request,\n           distributedCmdResponseTimeout);\n \n-      final KsqlRequestConfig requestConfig =\n-          new KsqlRequestConfig(request.getRequestProperties());\n+      final boolean internalRequest =", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODk2OTQyOA=="}, "originalCommit": {"oid": "d0dc3c9e88cd0e986f3058c761ac1929836b07ce"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg3MTYwNg==", "bodyText": "Would be good to see tests added to cover when the passed map is NOT empty.", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400871606", "createdAt": "2020-03-31T12:26:59Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/entity/QueryDescriptionFactoryTest.java", "diffHunk": "@@ -117,7 +117,7 @@ public void setUp() {\n         queryCloseCallback,\n         closeTimeout);\n \n-    transientQueryDescription = QueryDescriptionFactory.forQueryMetadata(transientQuery);\n+    transientQueryDescription = QueryDescriptionFactory.forQueryMetadata(transientQuery, Collections.emptyMap());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg3NjI4MQ==", "bodyText": "There's no need to parse APPLICATION_SERVER: you can just build it with known host & port.\nplease try and avoid subclassing HashMap just to add an entry.  Just using ImmutableMap.\n\nprivate static final String APPLICATION_HOST = \"localhost\";\n  private static final int APPLICATION_PORT = 9099;\n  private static final String APPLICATION_SERVER = \"http://\" + APPLICATION_HOST + \":\" + APPLICATION_PORT;\n\n...\n\n@Test\n  public void shouldShowQueriesExtended() {\n    // Given:\n    final Map<String, Object> overriddenProperties =\n        Collections.singletonMap(\"ksql.streams.auto.offset.reset\", \"earliest\");\n\n    final List<PersistentQueryMetadata> queryMetadata = createQueries(\n        \"CREATE STREAM test_describe_1 AS SELECT * FROM test_stream;\" +\n            \"CREATE STREAM test_describe_2 AS SELECT * FROM test_stream;\", overriddenProperties);\n\n    // When:\n    final QueryDescriptionList descriptionList = makeSingleRequest(\n        \"SHOW QUERIES EXTENDED;\", QueryDescriptionList.class);\n\n    // Then:\n    final Map<KsqlHostInfoEntity, String> queryHostState = ImmutableMap.of(\n        new KsqlHostInfoEntity(APPLICATION_HOST, APPLICATION_PORT),\n        \"CREATED\"\n    );\n\n    assertThat(descriptionList.getQueryDescriptions(), containsInAnyOrder(\n        QueryDescriptionFactory.forQueryMetadata(queryMetadata.get(0), queryHostState),\n        QueryDescriptionFactory.forQueryMetadata(queryMetadata.get(1), queryHostState)));\n  }", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400876281", "createdAt": "2020-03-31T12:34:14Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/resources/KsqlResourceTest.java", "diffHunk": "@@ -539,10 +544,18 @@ public void shouldShowQueriesExtended() {\n     final QueryDescriptionList descriptionList = makeSingleRequest(\n         \"SHOW QUERIES EXTENDED;\", QueryDescriptionList.class);\n \n+    final HostInfo hostInfo = ServerUtil.parseHostInfo(APPLICATION_SERVER);\n+    final HashMap<KsqlHostInfoEntity, String> queryHostState = \n+        new HashMap<KsqlHostInfoEntity, String>(){{ \n+          put(\n+              new KsqlHostInfoEntity(hostInfo.host(), hostInfo.port()),\n+              \"CREATED\"\n+          );\n+    }};\n     // Then:\n     assertThat(descriptionList.getQueryDescriptions(), containsInAnyOrder(\n-        QueryDescriptionFactory.forQueryMetadata(queryMetadata.get(0)),\n-        QueryDescriptionFactory.forQueryMetadata(queryMetadata.get(1))));\n+        QueryDescriptionFactory.forQueryMetadata(queryMetadata.get(0), queryHostState),\n+        QueryDescriptionFactory.forQueryMetadata(queryMetadata.get(1), queryHostState)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg3NzExMw==", "bodyText": "The code would be a little cleaner If the KafkaStreamsStateCount constructor too the initial state, and used that to set that states count to 1.  You could then inline the construction.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                      final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n          \n          \n            \n                      kafkaStreamsStateCount.updateStateCount(md.getState(), 1);\n          \n          \n            \n                      final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount(md.getState());", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400877113", "createdAt": "2020-03-31T12:35:40Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-app/src/test/java/io/confluent/ksql/rest/server/resources/KsqlResourceTest.java", "diffHunk": "@@ -1981,14 +1994,17 @@ private PersistentQueryMetadata createQuery(\n \n     return createQueries(sql, overriddenProperties)\n         .stream()\n-        .map(md -> new RunningQuery(\n+        .map(md -> {\n+          final KafkaStreamsStateCount kafkaStreamsStateCount = new KafkaStreamsStateCount();\n+          kafkaStreamsStateCount.updateStateCount(md.getState(), 1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg3ODU4OQ==", "bodyText": "Why not just inline this? i.e. make all the code that calls this just call the new version with the extra map param?\n(In case you're unaware IntelliJ can do this for you: with cursor on the function name, right click -> refactor -> inline method)", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400878589", "createdAt": "2020-03-31T12:37:53Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-client/src/main/java/io/confluent/ksql/rest/client/KsqlTarget.java", "diffHunk": "@@ -138,23 +138,31 @@ public KsqlTarget properties(final Map<String, ?> properties) {\n \n   public RestResponse<KsqlEntityList> postKsqlRequest(\n       final String ksql,\n+      final Map<String, ?> requestProperties,\n       final Optional<Long> previousCommandSeqNum\n   ) {\n     return post(\n         KSQL_PATH,\n-        createKsqlRequest(ksql, Collections.emptyMap(), previousCommandSeqNum),\n+        createKsqlRequest(ksql, requestProperties, previousCommandSeqNum),\n         r -> deserialize(r.getBody(), KsqlEntityList.class)\n     );\n   }\n+  \n+  public RestResponse<KsqlEntityList> postKsqlRequest(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg4NTQ2Nw==", "bodyText": "Would be nice to decouple this class from KafkaStream.State.  This enum is encapsulated by QueryMetadata deliberately.  If you would rather an enum that a String, (and I can understand you would), then add a new KSQL QueryState enum.   (This will probably be needed by @rodesai's work on query state anyway).\nAlso consider renaming this class to QueryStateCounts, which is less coupled to KS.", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400885467", "createdAt": "2020-03-31T12:48:57Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java", "diffHunk": "@@ -0,0 +1,118 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.entity;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n+import com.fasterxml.jackson.annotation.JsonValue;\n+import io.confluent.ksql.util.KsqlException;\n+\n+import java.util.EnumMap;\n+import java.util.Map;\n+import java.util.Objects;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+\n+/**\n+ * Used to keep track of a the state of KafkaStreams application\n+ * across multiple servers. Used in {@link RunningQuery}.\n+ */\n+@JsonIgnoreProperties(ignoreUnknown = true)\n+public class KafkaStreamsStateCount {\n+  \n+  // Use a EnumMap so toString() will always return the same string\n+  private final EnumMap<KafkaStreams.State, Integer> state;\n+\n+  public KafkaStreamsStateCount() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg5MzgyOQ==", "bodyText": "I'm a little confused by this class.  Why does it have all this code to convert to and from a string representation in the form <state>: <count>, <state>: <count>?  Why not just return this as a JSON Object?  The Jackson does all the heavy lifting for you!\n {\n     \"CREATED\": 1,\n     \"RUNNING\": 2\n}\nThis can be achieved with:\n@JsonIgnoreProperties(ignoreUnknown = true)\npublic class KafkaStreamsStateCount {\n\n  private final Map<State, Integer> states;\n\n  public KafkaStreamsStateCount() {\n    this.states = new HashMap<>();\n  }\n\n  @SuppressWarnings(\"unused\") // Invoked by reflection\n  @JsonCreator\n  public KafkaStreamsStateCount(final Map<State, Integer> states) {\n    this.states = new HashMap<>(states);\n  }\n\n  public void updateStateCount(final String state, final int change) {\n    updateStateCount(KafkaStreams.State.valueOf(state), change);\n  }\n\n  public void updateStateCount(final KafkaStreams.State state, final int change) {\n    states.compute(state, (key, existing) ->\n        existing == null\n            ? change\n            : existing + change\n    );\n  }\n\n  @JsonValue\n  public Map<KafkaStreams.State, Integer> getState() {\n    return states;\n  }\n\n  @Override\n  public boolean equals(final Object o) {\n    if (this == o) {\n      return true;\n    }\n\n    if (o == null || getClass() != o.getClass()) {\n      return false;\n    }\n\n    final KafkaStreamsStateCount that = (KafkaStreamsStateCount) o;\n    return Objects.equals(states, that.states);\n  }\n\n  @Override\n  public int hashCode() {\n    return Objects.hash(states);\n  }\n}", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400893829", "createdAt": "2020-03-31T13:01:29Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCount.java", "diffHunk": "@@ -0,0 +1,118 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.entity;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n+import com.fasterxml.jackson.annotation.JsonValue;\n+import io.confluent.ksql.util.KsqlException;\n+\n+import java.util.EnumMap;\n+import java.util.Map;\n+import java.util.Objects;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+\n+/**\n+ * Used to keep track of a the state of KafkaStreams application\n+ * across multiple servers. Used in {@link RunningQuery}.\n+ */\n+@JsonIgnoreProperties(ignoreUnknown = true)\n+public class KafkaStreamsStateCount {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg5NjQ3NA==", "bodyText": "Might be worth keeping the old state for a while as this will allow backwards compatibility for older CLI versions... i.e.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  @JsonProperty(\"state\") final KafkaStreamsStateCount state\n          \n          \n            \n                  @JsonProperty(\"state\") final Optional<String> state, // Kept for backwards compatibility.\n          \n          \n            \n                  @JsonProperty(\"stateCounts\") final KafkaStreamsStateCount stateCounts\n          \n      \n    \n    \n  \n\nand just populate the state string somehow, e.g. using the stateCounts string representation?  I think this would work as I think the old CLI just outputs this string as-is. Need to check though.", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400896474", "createdAt": "2020-03-31T13:05:15Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java", "diffHunk": "@@ -31,15 +30,15 @@\n   private final Set<String> sinks;\n   private final Set<String> sinkKafkaTopics;\n   private final QueryId id;\n-  private final Optional<String> state;\n+  private final KafkaStreamsStateCount state;\n \n   @JsonCreator\n   public RunningQuery(\n       @JsonProperty(\"queryString\") final String queryString,\n       @JsonProperty(\"sinks\") final Set<String> sinks,\n       @JsonProperty(\"sinkKafkaTopics\") final Set<String> sinkKafkaTopics,\n       @JsonProperty(\"id\") final QueryId id,\n-      @JsonProperty(\"state\") final Optional<String> state\n+      @JsonProperty(\"state\") final KafkaStreamsStateCount state", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDg5NzIwOA==", "bodyText": "With the changes I suggested to make this object serialize as a JSON object you can add tests such as:\n@Test\n  public void shouldRoundTripWhenEmpty() {\n    // When:\n    final String json = assertDeserializedToSame(kafkaStreamsStateCount);\n\n    // Then:\n    assertThat(json, is(\"{}\"));\n  }\n\n  @Test\n  public void shouldRoundTripWhenNotEmpty() {\n    // Given:\n    kafkaStreamsStateCount.updateStateCount(State.RUNNING, 2);\n    kafkaStreamsStateCount.updateStateCount(State.CREATED, 10);\n\n    // When:\n    final String json = assertDeserializedToSame(kafkaStreamsStateCount);\n\n    // Then:\n    assertThat(json, is(\"{\"\n        + \"\\\"CREATED\\\":10,\"\n        + \"\\\"RUNNING\\\":2\"\n        + \"}\"));\n  }\n\n  private static String assertDeserializedToSame(final KafkaStreamsStateCount original) {\n    try {\n      final String json = MAPPER.writeValueAsString(original);\n\n      final KafkaStreamsStateCount deserialized = MAPPER\n          .readValue(json, KafkaStreamsStateCount.class);\n\n      assertThat(deserialized, is(original));\n\n      return json;\n    } catch (Exception e) {\n      throw new AssertionError(\"Failed to round trip\", e);\n    }\n  }", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r400897208", "createdAt": "2020-03-31T13:06:22Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/KafkaStreamsStateCountTest.java", "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.entity;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+\n+import io.confluent.ksql.util.KsqlException;\n+import org.apache.kafka.streams.KafkaStreams;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import java.util.Map;\n+\n+@SuppressWarnings(\"SameParameterValue\")\n+public class KafkaStreamsStateCountTest {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d"}, "originalPosition": 29}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/e99d44d4cf0cd800cc0dac964eccea7f3cac813d", "committedDate": "2020-03-30T17:33:52Z", "message": "address comments"}, "afterCommit": {"oid": "9abab589a7bfda4cc6a15271d0ea4807b974597f", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/9abab589a7bfda4cc6a15271d0ea4807b974597f", "committedDate": "2020-04-01T22:17:53Z", "message": "addressing more comments"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9abab589a7bfda4cc6a15271d0ea4807b974597f", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/9abab589a7bfda4cc6a15271d0ea4807b974597f", "committedDate": "2020-04-01T22:17:53Z", "message": "addressing more comments"}, "afterCommit": {"oid": "d4b8243ca0ae9157476193db226d7c0021976fb9", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/d4b8243ca0ae9157476193db226d7c0021976fb9", "committedDate": "2020-04-01T22:44:36Z", "message": "addressing more comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a904008a542ae27a43a2fb5bd255a54ae00fcd55", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/a904008a542ae27a43a2fb5bd255a54ae00fcd55", "committedDate": "2020-04-02T17:35:34Z", "message": "feat: scatter gather query status from all servers in cluster for 'SHOW QUERIES [EXTENDED]' statement"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4957a5c4a3edab330671adb712176c6e37cbd7da", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/4957a5c4a3edab330671adb712176c6e37cbd7da", "committedDate": "2020-04-02T17:35:34Z", "message": "address comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "653bc6806701e95d4493ff6bd261c220a095420c", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/653bc6806701e95d4493ff6bd261c220a095420c", "committedDate": "2020-04-02T17:35:34Z", "message": "addressing more comments"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d4b8243ca0ae9157476193db226d7c0021976fb9", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/d4b8243ca0ae9157476193db226d7c0021976fb9", "committedDate": "2020-04-01T22:44:36Z", "message": "addressing more comments"}, "afterCommit": {"oid": "41f17ebde495835e6e126d4203cc324e61ca58e3", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/41f17ebde495835e6e126d4203cc324e61ca58e3", "committedDate": "2020-04-02T22:21:49Z", "message": "refactor for backwards-compatability"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "41f17ebde495835e6e126d4203cc324e61ca58e3", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/41f17ebde495835e6e126d4203cc324e61ca58e3", "committedDate": "2020-04-02T22:21:49Z", "message": "refactor for backwards-compatability"}, "afterCommit": {"oid": "293e001f7a95180faa8acee22006e4dd023c41de", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/293e001f7a95180faa8acee22006e4dd023c41de", "committedDate": "2020-04-02T22:28:05Z", "message": "refactor for backwards-compatability"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "293e001f7a95180faa8acee22006e4dd023c41de", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/293e001f7a95180faa8acee22006e4dd023c41de", "committedDate": "2020-04-02T22:28:05Z", "message": "refactor for backwards-compatability"}, "afterCommit": {"oid": "f8004d34f95b5a57a89361eac2935c8eff9a12c4", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/f8004d34f95b5a57a89361eac2935c8eff9a12c4", "committedDate": "2020-04-02T23:10:36Z", "message": "refactor for backwards-compatability"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2b52197e3af9f3516cbd30435da8dd389a85c7a3", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/2b52197e3af9f3516cbd30435da8dd389a85c7a3", "committedDate": "2020-04-03T00:45:24Z", "message": "refactor for backwards-compatability"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f8004d34f95b5a57a89361eac2935c8eff9a12c4", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/f8004d34f95b5a57a89361eac2935c8eff9a12c4", "committedDate": "2020-04-02T23:10:36Z", "message": "refactor for backwards-compatability"}, "afterCommit": {"oid": "2b52197e3af9f3516cbd30435da8dd389a85c7a3", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/2b52197e3af9f3516cbd30435da8dd389a85c7a3", "committedDate": "2020-04-03T00:45:24Z", "message": "refactor for backwards-compatability"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9accdca6ec7371e5f66cd0cd4e47197d4ccd1d4e", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/9accdca6ec7371e5f66cd0cd4e47197d4ccd1d4e", "committedDate": "2020-04-03T07:01:39Z", "message": "refactor ListQueriesExecutor"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "4ea9efe3e94b7fa1320d3d54cb8b698cf5ed48fd", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/4ea9efe3e94b7fa1320d3d54cb8b698cf5ed48fd", "committedDate": "2020-04-03T06:58:21Z", "message": "refactor ListQueriesExecutor"}, "afterCommit": {"oid": "9accdca6ec7371e5f66cd0cd4e47197d4ccd1d4e", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/9accdca6ec7371e5f66cd0cd4e47197d4ccd1d4e", "committedDate": "2020-04-03T07:01:39Z", "message": "refactor ListQueriesExecutor"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c7be57d84e03eb8431b9b72aa7abe77aa8633b6a", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/c7be57d84e03eb8431b9b72aa7abe77aa8633b6a", "committedDate": "2020-04-03T19:15:48Z", "message": "more unit tests"}, "afterCommit": {"oid": "2094b3f1ad442ed2642e50820ce0ab00bb969683", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/2094b3f1ad442ed2642e50820ce0ab00bb969683", "committedDate": "2020-04-03T22:24:09Z", "message": "more unit tests"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "2094b3f1ad442ed2642e50820ce0ab00bb969683", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/2094b3f1ad442ed2642e50820ce0ab00bb969683", "committedDate": "2020-04-03T22:24:09Z", "message": "more unit tests"}, "afterCommit": {"oid": "8c62c220495be00a406c5f0936fda64c140109a4", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/8c62c220495be00a406c5f0936fda64c140109a4", "committedDate": "2020-04-03T22:44:50Z", "message": "more unit tests"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8c62c220495be00a406c5f0936fda64c140109a4", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/8c62c220495be00a406c5f0936fda64c140109a4", "committedDate": "2020-04-03T22:44:50Z", "message": "more unit tests"}, "afterCommit": {"oid": "27c42723a0ad44d98003cfdcc1f65bd15d7293d3", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/27c42723a0ad44d98003cfdcc1f65bd15d7293d3", "committedDate": "2020-04-03T22:45:28Z", "message": "more unit tests"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "27c42723a0ad44d98003cfdcc1f65bd15d7293d3", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/27c42723a0ad44d98003cfdcc1f65bd15d7293d3", "committedDate": "2020-04-03T22:45:28Z", "message": "more unit tests"}, "afterCommit": {"oid": "0d58bdfac00e58458eb64afbca33d5e729b3a5ca", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/0d58bdfac00e58458eb64afbca33d5e729b3a5ca", "committedDate": "2020-04-06T16:45:24Z", "message": "more unit tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1825fd40b7926520ef42fd9c83174d83fec182f3", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/1825fd40b7926520ef42fd9c83174d83fec182f3", "committedDate": "2020-04-06T17:32:26Z", "message": "more unit tests"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0d58bdfac00e58458eb64afbca33d5e729b3a5ca", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/0d58bdfac00e58458eb64afbca33d5e729b3a5ca", "committedDate": "2020-04-06T16:45:24Z", "message": "more unit tests"}, "afterCommit": {"oid": "1825fd40b7926520ef42fd9c83174d83fec182f3", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/1825fd40b7926520ef42fd9c83174d83fec182f3", "committedDate": "2020-04-06T17:32:26Z", "message": "more unit tests"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5MDIxNDky", "url": "https://github.com/confluentinc/ksql/pull/4875#pullrequestreview-389021492", "createdAt": "2020-04-07T11:22:55Z", "commit": {"oid": "1825fd40b7926520ef42fd9c83174d83fec182f3"}, "state": "APPROVED", "comments": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxMToyMjo1NVrOGB-93Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxMjowMzo1MlrOGCARYw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDczMzQwNQ==", "bodyText": "As per #4875 (comment), and note in summary, I don't think this should be swallowed.", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404733405", "createdAt": "2020-04-07T11:22:55Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -38,27 +69,215 @@ private ListQueriesExecutor() { }\n       final KsqlExecutionContext executionContext,\n       final ServiceContext serviceContext\n   ) {\n-    final ListQueries listQueries = statement.getStatement();\n-    if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n-    }\n+    final List<KsqlEntity> remoteResults =\n+        scatterGather(statement, sessionProperties, executionContext, serviceContext);\n \n-    return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n+    return statement.getStatement().getShowExtended()\n+        ? executeExtended(remoteResults, sessionProperties, statement, executionContext)\n+        : executeSimple(remoteResults, statement, executionContext);\n+  }\n+\n+  private static Optional<KsqlEntity> executeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, RunningQuery> runningQueries = getLocalSimple(executionContext);\n+\n+    mergeSimple(remoteResults, runningQueries);\n+\n+    return Optional.of(new Queries(\n         statement.getStatementText(),\n-        executionContext.getPersistentQueries()\n-            .stream()\n-            .map(q -> new RunningQuery(\n+        runningQueries.values().stream().map(runningQuery -> new RunningQuery(\n+            runningQuery.getQueryString(),\n+            runningQuery.getSinks(),\n+            runningQuery.getSinkKafkaTopics(),\n+            runningQuery.getId(),\n+            Optional.of(runningQuery.getStateCount().toString()),\n+            runningQuery.getStateCount()\n+        ))\n+        .collect(Collectors.toList())));\n+  }\n+\n+  private static Map<QueryId, RunningQuery> getLocalSimple(\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    return executionContext\n+        .getPersistentQueries()\n+        .stream()\n+        .collect(Collectors.toMap(\n+            PersistentQueryMetadata::getQueryId,\n+            q -> new RunningQuery(\n                 q.getStatementString(),\n                 ImmutableSet.of(q.getSinkName().text()),\n                 ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n                 q.getQueryId(),\n-                Optional.of(q.getState())\n-            ))\n-            .collect(Collectors.toList())));\n+                Optional.empty(),\n+                new QueryStateCount(\n+                    Collections.singletonMap(KafkaStreams.State.valueOf(q.getState()), 1)))\n+        ));\n   }\n \n-}\n+  private static void mergeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, RunningQuery> allResults\n+  ) {\n+    final List<RunningQuery> remoteRunningQueries = remoteResults.stream()\n+        .map(Queries.class::cast)\n+        .map(Queries::getQueries)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    \n+    for (RunningQuery q : remoteRunningQueries) {\n+      final QueryId queryId = q.getId();\n+\n+      // If the query has already been discovered, update the QueryStateCount object\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KafkaStreams.State, Integer> entry :\n+            q.getStateCount().getStates().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getStateCount()\n+              .updateStateCount(entry.getKey(), entry.getValue());\n+        }\n+      } else {\n+        allResults.put(queryId, q);\n+      }\n+    }\n+  }\n+  \n+  private static Optional<KsqlEntity> executeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final SessionProperties sessionProperties,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, QueryDescription> queryDescriptions =\n+        getLocalExtended(sessionProperties, executionContext);\n+\n+    mergeExtended(remoteResults, queryDescriptions);\n+\n+    return Optional.of(new QueryDescriptionList(\n+        statement.getStatementText(),\n+        queryDescriptions.values().stream().map(queryDescription -> \n+            new QueryDescription(\n+                queryDescription.getId(),\n+                queryDescription.getStatementText(),\n+                queryDescription.getWindowType(),\n+                queryDescription.getFields(),\n+                queryDescription.getSources(),\n+                queryDescription.getSinks(),\n+                queryDescription.getTopology(),\n+                queryDescription.getExecutionPlan(),\n+                queryDescription.getOverriddenProperties(),\n+                Optional.of(queryDescription.getKsqlHostQueryState().toString()),\n+                queryDescription.getKsqlHostQueryState()\n+            )\n+        ).collect(Collectors.toList())));\n+  }\n+\n+  private static Map<QueryId, QueryDescription> getLocalExtended(\n+      final SessionProperties sessionProperties,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    return executionContext\n+        .getPersistentQueries()\n+        .stream()\n+        .collect(Collectors.toMap(\n+            PersistentQueryMetadata::getQueryId,\n+            query -> QueryDescriptionFactory.forQueryMetadata(\n+                query,\n+                Collections.singletonMap(\n+                    new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n+                    query.getState()))));\n+  }\n+\n+  private static void mergeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, QueryDescription> allResults\n+  ) {\n+    final List<QueryDescription> remoteQueryDescriptions = remoteResults.stream()\n+        .map(QueryDescriptionList.class::cast)\n+        .map(QueryDescriptionList::getQueryDescriptions)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    for (QueryDescription q : remoteQueryDescriptions) {\n+      final QueryId queryId = q.getId();\n+\n+      // If the query has already been discovered, add to the ksqlQueryHostState mapping\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KsqlHostInfoEntity, String> entry :\n+            q.getKsqlHostQueryState().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getKsqlHostQueryState()\n+              .put(entry.getKey(), entry.getValue());\n+        }\n+      } else {\n+        allResults.put(queryId, q);\n+      }\n+    }\n+  }\n+\n+  private static List<KsqlEntity> scatterGather(\n+      final ConfiguredStatement<ListQueries> statement,\n+      final SessionProperties sessionProperties,\n+      final KsqlExecutionContext executionContext,\n+      final ServiceContext serviceContext\n+  ) {\n+    if (sessionProperties.getInternalRequest()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final Set<HostInfo> remoteHosts = DiscoverRemoteHostsUtil.getRemoteHosts(\n+        executionContext.getPersistentQueries(),\n+        sessionProperties.getKsqlHostInfo()\n+    );\n+\n+    if (remoteHosts.isEmpty()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+\n+    try {\n+      final SimpleKsqlClient ksqlClient = serviceContext.getKsqlClient();\n+\n+      final Map<HostInfo, Future<RestResponse<KsqlEntityList>>> futureResponses = new HashMap<>();\n+      for (HostInfo host : remoteHosts) {\n+        final Future<RestResponse<KsqlEntityList>> future = executorService.submit(() -> ksqlClient\n+            .makeKsqlRequest(\n+                ServerUtil.buildRemoteUri(\n+                    sessionProperties.getLocalUrl(),\n+                    host.host(),\n+                    host.port()\n+                ),\n+                statement.getStatementText(),\n+                Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+        );\n+\n+        futureResponses.put(host, future);\n+      }\n+      \n+      final List<KsqlEntity> results = new ArrayList<>();\n+      for (final Map.Entry<HostInfo, Future<RestResponse<KsqlEntityList>>> e\n+          : futureResponses.entrySet()) {\n+        try {\n+          final RestResponse<KsqlEntityList> response = e.getValue().get();\n+          if (response.isErroneous()) {\n+            LOG.warn(\"Error response from host. host: {}, cause: {}\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1825fd40b7926520ef42fd9c83174d83fec182f3"}, "originalPosition": 269}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDczMzQzNA==", "bodyText": "As per #4875 (comment), and note in summary, I don't think this should be swallowed.", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404733434", "createdAt": "2020-04-07T11:22:59Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -38,27 +69,215 @@ private ListQueriesExecutor() { }\n       final KsqlExecutionContext executionContext,\n       final ServiceContext serviceContext\n   ) {\n-    final ListQueries listQueries = statement.getStatement();\n-    if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n-    }\n+    final List<KsqlEntity> remoteResults =\n+        scatterGather(statement, sessionProperties, executionContext, serviceContext);\n \n-    return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n+    return statement.getStatement().getShowExtended()\n+        ? executeExtended(remoteResults, sessionProperties, statement, executionContext)\n+        : executeSimple(remoteResults, statement, executionContext);\n+  }\n+\n+  private static Optional<KsqlEntity> executeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, RunningQuery> runningQueries = getLocalSimple(executionContext);\n+\n+    mergeSimple(remoteResults, runningQueries);\n+\n+    return Optional.of(new Queries(\n         statement.getStatementText(),\n-        executionContext.getPersistentQueries()\n-            .stream()\n-            .map(q -> new RunningQuery(\n+        runningQueries.values().stream().map(runningQuery -> new RunningQuery(\n+            runningQuery.getQueryString(),\n+            runningQuery.getSinks(),\n+            runningQuery.getSinkKafkaTopics(),\n+            runningQuery.getId(),\n+            Optional.of(runningQuery.getStateCount().toString()),\n+            runningQuery.getStateCount()\n+        ))\n+        .collect(Collectors.toList())));\n+  }\n+\n+  private static Map<QueryId, RunningQuery> getLocalSimple(\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    return executionContext\n+        .getPersistentQueries()\n+        .stream()\n+        .collect(Collectors.toMap(\n+            PersistentQueryMetadata::getQueryId,\n+            q -> new RunningQuery(\n                 q.getStatementString(),\n                 ImmutableSet.of(q.getSinkName().text()),\n                 ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n                 q.getQueryId(),\n-                Optional.of(q.getState())\n-            ))\n-            .collect(Collectors.toList())));\n+                Optional.empty(),\n+                new QueryStateCount(\n+                    Collections.singletonMap(KafkaStreams.State.valueOf(q.getState()), 1)))\n+        ));\n   }\n \n-}\n+  private static void mergeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, RunningQuery> allResults\n+  ) {\n+    final List<RunningQuery> remoteRunningQueries = remoteResults.stream()\n+        .map(Queries.class::cast)\n+        .map(Queries::getQueries)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    \n+    for (RunningQuery q : remoteRunningQueries) {\n+      final QueryId queryId = q.getId();\n+\n+      // If the query has already been discovered, update the QueryStateCount object\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KafkaStreams.State, Integer> entry :\n+            q.getStateCount().getStates().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getStateCount()\n+              .updateStateCount(entry.getKey(), entry.getValue());\n+        }\n+      } else {\n+        allResults.put(queryId, q);\n+      }\n+    }\n+  }\n+  \n+  private static Optional<KsqlEntity> executeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final SessionProperties sessionProperties,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, QueryDescription> queryDescriptions =\n+        getLocalExtended(sessionProperties, executionContext);\n+\n+    mergeExtended(remoteResults, queryDescriptions);\n+\n+    return Optional.of(new QueryDescriptionList(\n+        statement.getStatementText(),\n+        queryDescriptions.values().stream().map(queryDescription -> \n+            new QueryDescription(\n+                queryDescription.getId(),\n+                queryDescription.getStatementText(),\n+                queryDescription.getWindowType(),\n+                queryDescription.getFields(),\n+                queryDescription.getSources(),\n+                queryDescription.getSinks(),\n+                queryDescription.getTopology(),\n+                queryDescription.getExecutionPlan(),\n+                queryDescription.getOverriddenProperties(),\n+                Optional.of(queryDescription.getKsqlHostQueryState().toString()),\n+                queryDescription.getKsqlHostQueryState()\n+            )\n+        ).collect(Collectors.toList())));\n+  }\n+\n+  private static Map<QueryId, QueryDescription> getLocalExtended(\n+      final SessionProperties sessionProperties,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    return executionContext\n+        .getPersistentQueries()\n+        .stream()\n+        .collect(Collectors.toMap(\n+            PersistentQueryMetadata::getQueryId,\n+            query -> QueryDescriptionFactory.forQueryMetadata(\n+                query,\n+                Collections.singletonMap(\n+                    new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n+                    query.getState()))));\n+  }\n+\n+  private static void mergeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, QueryDescription> allResults\n+  ) {\n+    final List<QueryDescription> remoteQueryDescriptions = remoteResults.stream()\n+        .map(QueryDescriptionList.class::cast)\n+        .map(QueryDescriptionList::getQueryDescriptions)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    for (QueryDescription q : remoteQueryDescriptions) {\n+      final QueryId queryId = q.getId();\n+\n+      // If the query has already been discovered, add to the ksqlQueryHostState mapping\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KsqlHostInfoEntity, String> entry :\n+            q.getKsqlHostQueryState().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getKsqlHostQueryState()\n+              .put(entry.getKey(), entry.getValue());\n+        }\n+      } else {\n+        allResults.put(queryId, q);\n+      }\n+    }\n+  }\n+\n+  private static List<KsqlEntity> scatterGather(\n+      final ConfiguredStatement<ListQueries> statement,\n+      final SessionProperties sessionProperties,\n+      final KsqlExecutionContext executionContext,\n+      final ServiceContext serviceContext\n+  ) {\n+    if (sessionProperties.getInternalRequest()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final Set<HostInfo> remoteHosts = DiscoverRemoteHostsUtil.getRemoteHosts(\n+        executionContext.getPersistentQueries(),\n+        sessionProperties.getKsqlHostInfo()\n+    );\n+\n+    if (remoteHosts.isEmpty()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+\n+    try {\n+      final SimpleKsqlClient ksqlClient = serviceContext.getKsqlClient();\n+\n+      final Map<HostInfo, Future<RestResponse<KsqlEntityList>>> futureResponses = new HashMap<>();\n+      for (HostInfo host : remoteHosts) {\n+        final Future<RestResponse<KsqlEntityList>> future = executorService.submit(() -> ksqlClient\n+            .makeKsqlRequest(\n+                ServerUtil.buildRemoteUri(\n+                    sessionProperties.getLocalUrl(),\n+                    host.host(),\n+                    host.port()\n+                ),\n+                statement.getStatementText(),\n+                Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+        );\n+\n+        futureResponses.put(host, future);\n+      }\n+      \n+      final List<KsqlEntity> results = new ArrayList<>();\n+      for (final Map.Entry<HostInfo, Future<RestResponse<KsqlEntityList>>> e\n+          : futureResponses.entrySet()) {\n+        try {\n+          final RestResponse<KsqlEntityList> response = e.getValue().get();\n+          if (response.isErroneous()) {\n+            LOG.warn(\"Error response from host. host: {}, cause: {}\",\n+                e.getKey(), response.getErrorMessage().getMessage());\n+          } else {\n+            results.add(response.getResponse().get(0));\n+          }\n+        } catch (final Exception cause) {\n+          LOG.warn(\"Failed to retrieve query info from host. host: \" + e.getKey(), cause);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1825fd40b7926520ef42fd9c83174d83fec182f3"}, "originalPosition": 275}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDczMzk1Nw==", "bodyText": "As per #4875 (comment):\n\nIt may be sensible to add a timeout on this get() call, or at least ensure the ksqlClient is configured with sensible connect and read timeouts. We don't want this blocking indefinitely.", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404733957", "createdAt": "2020-04-07T11:23:58Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -38,27 +69,215 @@ private ListQueriesExecutor() { }\n       final KsqlExecutionContext executionContext,\n       final ServiceContext serviceContext\n   ) {\n-    final ListQueries listQueries = statement.getStatement();\n-    if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n-    }\n+    final List<KsqlEntity> remoteResults =\n+        scatterGather(statement, sessionProperties, executionContext, serviceContext);\n \n-    return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n+    return statement.getStatement().getShowExtended()\n+        ? executeExtended(remoteResults, sessionProperties, statement, executionContext)\n+        : executeSimple(remoteResults, statement, executionContext);\n+  }\n+\n+  private static Optional<KsqlEntity> executeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, RunningQuery> runningQueries = getLocalSimple(executionContext);\n+\n+    mergeSimple(remoteResults, runningQueries);\n+\n+    return Optional.of(new Queries(\n         statement.getStatementText(),\n-        executionContext.getPersistentQueries()\n-            .stream()\n-            .map(q -> new RunningQuery(\n+        runningQueries.values().stream().map(runningQuery -> new RunningQuery(\n+            runningQuery.getQueryString(),\n+            runningQuery.getSinks(),\n+            runningQuery.getSinkKafkaTopics(),\n+            runningQuery.getId(),\n+            Optional.of(runningQuery.getStateCount().toString()),\n+            runningQuery.getStateCount()\n+        ))\n+        .collect(Collectors.toList())));\n+  }\n+\n+  private static Map<QueryId, RunningQuery> getLocalSimple(\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    return executionContext\n+        .getPersistentQueries()\n+        .stream()\n+        .collect(Collectors.toMap(\n+            PersistentQueryMetadata::getQueryId,\n+            q -> new RunningQuery(\n                 q.getStatementString(),\n                 ImmutableSet.of(q.getSinkName().text()),\n                 ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n                 q.getQueryId(),\n-                Optional.of(q.getState())\n-            ))\n-            .collect(Collectors.toList())));\n+                Optional.empty(),\n+                new QueryStateCount(\n+                    Collections.singletonMap(KafkaStreams.State.valueOf(q.getState()), 1)))\n+        ));\n   }\n \n-}\n+  private static void mergeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, RunningQuery> allResults\n+  ) {\n+    final List<RunningQuery> remoteRunningQueries = remoteResults.stream()\n+        .map(Queries.class::cast)\n+        .map(Queries::getQueries)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    \n+    for (RunningQuery q : remoteRunningQueries) {\n+      final QueryId queryId = q.getId();\n+\n+      // If the query has already been discovered, update the QueryStateCount object\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KafkaStreams.State, Integer> entry :\n+            q.getStateCount().getStates().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getStateCount()\n+              .updateStateCount(entry.getKey(), entry.getValue());\n+        }\n+      } else {\n+        allResults.put(queryId, q);\n+      }\n+    }\n+  }\n+  \n+  private static Optional<KsqlEntity> executeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final SessionProperties sessionProperties,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, QueryDescription> queryDescriptions =\n+        getLocalExtended(sessionProperties, executionContext);\n+\n+    mergeExtended(remoteResults, queryDescriptions);\n+\n+    return Optional.of(new QueryDescriptionList(\n+        statement.getStatementText(),\n+        queryDescriptions.values().stream().map(queryDescription -> \n+            new QueryDescription(\n+                queryDescription.getId(),\n+                queryDescription.getStatementText(),\n+                queryDescription.getWindowType(),\n+                queryDescription.getFields(),\n+                queryDescription.getSources(),\n+                queryDescription.getSinks(),\n+                queryDescription.getTopology(),\n+                queryDescription.getExecutionPlan(),\n+                queryDescription.getOverriddenProperties(),\n+                Optional.of(queryDescription.getKsqlHostQueryState().toString()),\n+                queryDescription.getKsqlHostQueryState()\n+            )\n+        ).collect(Collectors.toList())));\n+  }\n+\n+  private static Map<QueryId, QueryDescription> getLocalExtended(\n+      final SessionProperties sessionProperties,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    return executionContext\n+        .getPersistentQueries()\n+        .stream()\n+        .collect(Collectors.toMap(\n+            PersistentQueryMetadata::getQueryId,\n+            query -> QueryDescriptionFactory.forQueryMetadata(\n+                query,\n+                Collections.singletonMap(\n+                    new KsqlHostInfoEntity(sessionProperties.getKsqlHostInfo()),\n+                    query.getState()))));\n+  }\n+\n+  private static void mergeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, QueryDescription> allResults\n+  ) {\n+    final List<QueryDescription> remoteQueryDescriptions = remoteResults.stream()\n+        .map(QueryDescriptionList.class::cast)\n+        .map(QueryDescriptionList::getQueryDescriptions)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    for (QueryDescription q : remoteQueryDescriptions) {\n+      final QueryId queryId = q.getId();\n+\n+      // If the query has already been discovered, add to the ksqlQueryHostState mapping\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KsqlHostInfoEntity, String> entry :\n+            q.getKsqlHostQueryState().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getKsqlHostQueryState()\n+              .put(entry.getKey(), entry.getValue());\n+        }\n+      } else {\n+        allResults.put(queryId, q);\n+      }\n+    }\n+  }\n+\n+  private static List<KsqlEntity> scatterGather(\n+      final ConfiguredStatement<ListQueries> statement,\n+      final SessionProperties sessionProperties,\n+      final KsqlExecutionContext executionContext,\n+      final ServiceContext serviceContext\n+  ) {\n+    if (sessionProperties.getInternalRequest()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final Set<HostInfo> remoteHosts = DiscoverRemoteHostsUtil.getRemoteHosts(\n+        executionContext.getPersistentQueries(),\n+        sessionProperties.getKsqlHostInfo()\n+    );\n+\n+    if (remoteHosts.isEmpty()) {\n+      return ImmutableList.of();\n+    }\n+\n+    final ExecutorService executorService = Executors.newFixedThreadPool(remoteHosts.size());\n+\n+    try {\n+      final SimpleKsqlClient ksqlClient = serviceContext.getKsqlClient();\n+\n+      final Map<HostInfo, Future<RestResponse<KsqlEntityList>>> futureResponses = new HashMap<>();\n+      for (HostInfo host : remoteHosts) {\n+        final Future<RestResponse<KsqlEntityList>> future = executorService.submit(() -> ksqlClient\n+            .makeKsqlRequest(\n+                ServerUtil.buildRemoteUri(\n+                    sessionProperties.getLocalUrl(),\n+                    host.host(),\n+                    host.port()\n+                ),\n+                statement.getStatementText(),\n+                Collections.singletonMap(KsqlRequestConfig.KSQL_REQUEST_INTERNAL_REQUEST, true))\n+        );\n+\n+        futureResponses.put(host, future);\n+      }\n+      \n+      final List<KsqlEntity> results = new ArrayList<>();\n+      for (final Map.Entry<HostInfo, Future<RestResponse<KsqlEntityList>>> e\n+          : futureResponses.entrySet()) {\n+        try {\n+          final RestResponse<KsqlEntityList> response = e.getValue().get();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1825fd40b7926520ef42fd9c83174d83fec182f3"}, "originalPosition": 267}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDczNzQ2Mg==", "bodyText": "This creation of a new copy of each RunningQuery confused me at first. Then I realised you are probably doing this to set the legacy state field, right?   I've commented in RunningQuery explaining how you don't need to set state via the constructor - so this code to create new RunningQuerys can be removed.", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404737462", "createdAt": "2020-04-07T11:30:24Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -38,27 +69,215 @@ private ListQueriesExecutor() { }\n       final KsqlExecutionContext executionContext,\n       final ServiceContext serviceContext\n   ) {\n-    final ListQueries listQueries = statement.getStatement();\n-    if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n-    }\n+    final List<KsqlEntity> remoteResults =\n+        scatterGather(statement, sessionProperties, executionContext, serviceContext);\n \n-    return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n+    return statement.getStatement().getShowExtended()\n+        ? executeExtended(remoteResults, sessionProperties, statement, executionContext)\n+        : executeSimple(remoteResults, statement, executionContext);\n+  }\n+\n+  private static Optional<KsqlEntity> executeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, RunningQuery> runningQueries = getLocalSimple(executionContext);\n+\n+    mergeSimple(remoteResults, runningQueries);\n+\n+    return Optional.of(new Queries(\n         statement.getStatementText(),\n-        executionContext.getPersistentQueries()\n-            .stream()\n-            .map(q -> new RunningQuery(\n+        runningQueries.values().stream().map(runningQuery -> new RunningQuery(\n+            runningQuery.getQueryString(),\n+            runningQuery.getSinks(),\n+            runningQuery.getSinkKafkaTopics(),\n+            runningQuery.getId(),\n+            Optional.of(runningQuery.getStateCount().toString()),\n+            runningQuery.getStateCount()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1825fd40b7926520ef42fd9c83174d83fec182f3"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc0MTYwNg==", "bodyText": "A cleaner way (my bad) would be to remove this param from the constructor but to still have the getter. For example:\n  public Optional<String> getState() {\n    return stateCount.getStates().isEmpty()\n        ? Optional.empty()\n        : Optional.of(stateCount.toString());\n  }\n(You may even just be able to always return Optional.of(stateCount.toString())).\nI believe Jackson will then include state as a field in the json.  Though add a unit test for this.\nIf you're wondering how this can work, then remember we're keeping this field around for backwards compatibility and the old version of the CLI will have the old version of this class, which will still take state as a constructor param. Hence, all we need is the state in the Json. We don't need to be able to accept it as a constructor param any more.", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404741606", "createdAt": "2020-04-07T11:38:22Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/RunningQuery.java", "diffHunk": "@@ -32,20 +32,23 @@\n   private final Set<String> sinkKafkaTopics;\n   private final QueryId id;\n   private final Optional<String> state;\n+  private final QueryStateCount stateCount;\n \n   @JsonCreator\n   public RunningQuery(\n       @JsonProperty(\"queryString\") final String queryString,\n       @JsonProperty(\"sinks\") final Set<String> sinks,\n       @JsonProperty(\"sinkKafkaTopics\") final Set<String> sinkKafkaTopics,\n       @JsonProperty(\"id\") final QueryId id,\n-      @JsonProperty(\"state\") final Optional<String> state\n+      @JsonProperty(\"state\") final Optional<String> state, // Kept for backwards compatibility.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1825fd40b7926520ef42fd9c83174d83fec182f3"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc0MzcxNg==", "bodyText": "You can remove this code by following the same trick I've suggested for RunningQuery in QueryDescription.", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404743716", "createdAt": "2020-04-07T11:42:30Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListQueriesExecutor.java", "diffHunk": "@@ -38,27 +69,215 @@ private ListQueriesExecutor() { }\n       final KsqlExecutionContext executionContext,\n       final ServiceContext serviceContext\n   ) {\n-    final ListQueries listQueries = statement.getStatement();\n-    if (listQueries.getShowExtended()) {\n-      return Optional.of(new QueryDescriptionList(\n-          statement.getStatementText(),\n-          executionContext.getPersistentQueries().stream()\n-              .map(QueryDescriptionFactory::forQueryMetadata)\n-              .collect(Collectors.toList())));\n-    }\n+    final List<KsqlEntity> remoteResults =\n+        scatterGather(statement, sessionProperties, executionContext, serviceContext);\n \n-    return Optional.of(new io.confluent.ksql.rest.entity.Queries(\n+    return statement.getStatement().getShowExtended()\n+        ? executeExtended(remoteResults, sessionProperties, statement, executionContext)\n+        : executeSimple(remoteResults, statement, executionContext);\n+  }\n+\n+  private static Optional<KsqlEntity> executeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, RunningQuery> runningQueries = getLocalSimple(executionContext);\n+\n+    mergeSimple(remoteResults, runningQueries);\n+\n+    return Optional.of(new Queries(\n         statement.getStatementText(),\n-        executionContext.getPersistentQueries()\n-            .stream()\n-            .map(q -> new RunningQuery(\n+        runningQueries.values().stream().map(runningQuery -> new RunningQuery(\n+            runningQuery.getQueryString(),\n+            runningQuery.getSinks(),\n+            runningQuery.getSinkKafkaTopics(),\n+            runningQuery.getId(),\n+            Optional.of(runningQuery.getStateCount().toString()),\n+            runningQuery.getStateCount()\n+        ))\n+        .collect(Collectors.toList())));\n+  }\n+\n+  private static Map<QueryId, RunningQuery> getLocalSimple(\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    return executionContext\n+        .getPersistentQueries()\n+        .stream()\n+        .collect(Collectors.toMap(\n+            PersistentQueryMetadata::getQueryId,\n+            q -> new RunningQuery(\n                 q.getStatementString(),\n                 ImmutableSet.of(q.getSinkName().text()),\n                 ImmutableSet.of(q.getResultTopic().getKafkaTopicName()),\n                 q.getQueryId(),\n-                Optional.of(q.getState())\n-            ))\n-            .collect(Collectors.toList())));\n+                Optional.empty(),\n+                new QueryStateCount(\n+                    Collections.singletonMap(KafkaStreams.State.valueOf(q.getState()), 1)))\n+        ));\n   }\n \n-}\n+  private static void mergeSimple(\n+      final List<KsqlEntity> remoteResults,\n+      final Map<QueryId, RunningQuery> allResults\n+  ) {\n+    final List<RunningQuery> remoteRunningQueries = remoteResults.stream()\n+        .map(Queries.class::cast)\n+        .map(Queries::getQueries)\n+        .flatMap(List::stream)\n+        .collect(Collectors.toList());\n+    \n+    for (RunningQuery q : remoteRunningQueries) {\n+      final QueryId queryId = q.getId();\n+\n+      // If the query has already been discovered, update the QueryStateCount object\n+      if (allResults.containsKey(queryId)) {\n+        for (Map.Entry<KafkaStreams.State, Integer> entry :\n+            q.getStateCount().getStates().entrySet()) {\n+          allResults\n+              .get(queryId)\n+              .getStateCount()\n+              .updateStateCount(entry.getKey(), entry.getValue());\n+        }\n+      } else {\n+        allResults.put(queryId, q);\n+      }\n+    }\n+  }\n+  \n+  private static Optional<KsqlEntity> executeExtended(\n+      final List<KsqlEntity> remoteResults,\n+      final SessionProperties sessionProperties,\n+      final ConfiguredStatement<ListQueries> statement,\n+      final KsqlExecutionContext executionContext\n+  ) {\n+    final Map<QueryId, QueryDescription> queryDescriptions =\n+        getLocalExtended(sessionProperties, executionContext);\n+\n+    mergeExtended(remoteResults, queryDescriptions);\n+\n+    return Optional.of(new QueryDescriptionList(\n+        statement.getStatementText(),\n+        queryDescriptions.values().stream().map(queryDescription -> \n+            new QueryDescription(\n+                queryDescription.getId(),\n+                queryDescription.getStatementText(),\n+                queryDescription.getWindowType(),\n+                queryDescription.getFields(),\n+                queryDescription.getSources(),\n+                queryDescription.getSinks(),\n+                queryDescription.getTopology(),\n+                queryDescription.getExecutionPlan(),\n+                queryDescription.getOverriddenProperties(),\n+                Optional.of(queryDescription.getKsqlHostQueryState().toString()),\n+                queryDescription.getKsqlHostQueryState()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1825fd40b7926520ef42fd9c83174d83fec182f3"}, "originalPosition": 175}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc0NzIxNA==", "bodyText": "Consider adding an explanation of what the different statuses mean?  (Including UNRESPONSIVE when you do that).\nMind you, @rodesai is planning on simplifying the list... so maybe talk to him first.  I guess you can always add it and he can update it.", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404747214", "createdAt": "2020-04-07T11:49:15Z", "author": {"login": "big-andy-coates"}, "path": "docs-md/developer-guide/ksqldb-reference/show-queries.md", "diffHunk": "@@ -13,16 +13,80 @@ Synopsis\n --------\r\n \r\n ```sql\r\n-SHOW QUERIES;\r\n+SHOW | LIST QUERIES [EXTENDED];\r\n ```\r\n \r\n Description\r\n -----------\r\n \r\n-List the running persistent queries.\r\n+`SHOW QUERIES` lists queries running in the cluster.\r\n+\r\n+`SHOW QUERIES EXTENDED` lists queries running in the cluster in more detail.\r\n \r\n Example\r\n -------\r\n \r\n-TODO: example\r\n+```sql\r\n+ksql> show queries;\r\n+\r\n+ Query ID    | Status    | Sink Name | Sink Kafka Topic | Query String                                                                                                                                \r\n+------------------------------------------------------------------------------------------------------------\r\n+ CSAS_TEST_0 | RUNNING:2 | TEST      | TEST             | CREATE STREAM TEST WITH (KAFKA_TOPIC='TEST', PARTITIONS=1, REPLICAS=1) AS SELECT *FROM KSQL_PROCESSING_LOG KSQL_PROCESSING_LOG EMIT CHANGES; \r", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1825fd40b7926520ef42fd9c83174d83fec182f3"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc0OTM4MA==", "bodyText": "Just a suggestion, but...\nLet's say I'm running a 50 node cluster (!!!) and I know from running the none extended version of this command that 1 node is not happy. I'm running this command to find the one node's server name.... Searching through 50 of these host-status pairs will be a PITA.\nCan I suggest grouping the hosts by status?  (either server or client side, though server side is probably better). So that the output is more:\nHost Query Status.                 :  Running (49) : [host1, host2, host3, ... host 50]\n                                      Failed (1):  [host23]\n\nI think that would make your hard work much more useful to users.", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404749380", "createdAt": "2020-04-07T11:53:28Z", "author": {"login": "big-andy-coates"}, "path": "docs-md/developer-guide/ksqldb-reference/show-queries.md", "diffHunk": "@@ -13,16 +13,80 @@ Synopsis\n --------\r\n \r\n ```sql\r\n-SHOW QUERIES;\r\n+SHOW | LIST QUERIES [EXTENDED];\r\n ```\r\n \r\n Description\r\n -----------\r\n \r\n-List the running persistent queries.\r\n+`SHOW QUERIES` lists queries running in the cluster.\r\n+\r\n+`SHOW QUERIES EXTENDED` lists queries running in the cluster in more detail.\r\n \r\n Example\r\n -------\r\n \r\n-TODO: example\r\n+```sql\r\n+ksql> show queries;\r\n+\r\n+ Query ID    | Status    | Sink Name | Sink Kafka Topic | Query String                                                                                                                                \r\n+------------------------------------------------------------------------------------------------------------\r\n+ CSAS_TEST_0 | RUNNING:2 | TEST      | TEST             | CREATE STREAM TEST WITH (KAFKA_TOPIC='TEST', PARTITIONS=1, REPLICAS=1) AS SELECT *FROM KSQL_PROCESSING_LOG KSQL_PROCESSING_LOG EMIT CHANGES; \r\n+------------------------------------------------------------------------------------------------------------\r\n+For detailed information on a Query run: EXPLAIN <Query ID>;\r\n+```\r\n+\r\n+\r\n+```sql\r\n+ksql> show queries extended;\r\n+\r\n+ID                   : CSAS_TEST_0\r\n+SQL                  : CREATE STREAM TEST WITH (KAFKA_TOPIC='TEST', PARTITIONS=1, REPLICAS=1) AS SELECT *\r\n+FROM KSQL_PROCESSING_LOG KSQL_PROCESSING_LOG\r\n+EMIT CHANGES;\r\n+Host Query Status    : {192.168.1.6:8088=RUNNING, 192.168.1.6:8089=RUNNING}\r", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1825fd40b7926520ef42fd9c83174d83fec182f3"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc1Mjk3Mw==", "bodyText": "Exposes mutable state of object, i.e. breaks encapsulation. I think this should still ensure consistent ordering:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                return ksqlHostQueryState;\n          \n          \n            \n                return Collections.unmodifyableMap(ksqlHostQueryState);\n          \n      \n    \n    \n  \n\nIf not, then you can always just store a normal map in the field and return:\n  final Map<x, y> orderedMap = new TreeMap<>(Comparator.comparing(KsqlHostInfoEntity::toString))\n   orderedMap.putAll(ksqlHostQueryState);\nreturn orderedMap;", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404752973", "createdAt": "2020-04-07T12:00:15Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryDescription.java", "diffHunk": "@@ -110,6 +121,10 @@ public String getExecutionPlan() {\n     return state;\n   }\n \n+  public Map<KsqlHostInfoEntity, String> getKsqlHostQueryState() {\n+    return ksqlHostQueryState;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1825fd40b7926520ef42fd9c83174d83fec182f3"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc1MzE3NA==", "bodyText": "nit:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              private final TreeMap<KsqlHostInfoEntity, String> ksqlHostQueryState;\n          \n          \n            \n              private final Map<KsqlHostInfoEntity, String> ksqlHostQueryState;\n          \n      \n    \n    \n  \n\nIs sufficient, no?", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404753174", "createdAt": "2020-04-07T12:00:40Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryDescription.java", "diffHunk": "@@ -42,7 +45,9 @@\n   private final String executionPlan;\n   private final Map<String, Object> overriddenProperties;\n   private final Optional<String> state;\n+  private final TreeMap<KsqlHostInfoEntity, String> ksqlHostQueryState;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1825fd40b7926520ef42fd9c83174d83fec182f3"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc1MzgxMw==", "bodyText": "Would be good to add a unit test to test this is returning an ordered collection. (Or just JSON with ordered fields).", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404753813", "createdAt": "2020-04-07T12:01:56Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryDescription.java", "diffHunk": "@@ -68,6 +74,11 @@ public QueryDescription(\n     this.overriddenProperties = ImmutableMap.copyOf(Objects\n         .requireNonNull(overriddenProperties, \"overriddenProperties\"));\n     this.state = Objects.requireNonNull(state, \"state\");\n+    \n+    this.ksqlHostQueryState =\n+        new TreeMap<>(Comparator.comparing(KsqlHostInfoEntity::toString));\n+    this.ksqlHostQueryState\n+        .putAll(Objects.requireNonNull(ksqlHostQueryState, \"ksqlHostQueryState\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1825fd40b7926520ef42fd9c83174d83fec182f3"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc1Mzk5OA==", "bodyText": "Consider adding a unit test using EqualsTester if the class does not already have one.", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404753998", "createdAt": "2020-04-07T12:02:17Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryDescription.java", "diffHunk": "@@ -130,7 +145,8 @@ public boolean equals(final Object o) {\n         && Objects.equals(sources, that.sources)\n         && Objects.equals(sinks, that.sinks)\n         && Objects.equals(overriddenProperties, that.overriddenProperties)\n-        && Objects.equals(state, that.state);\n+        && Objects.equals(state, that.state)\n+        && Objects.equals(ksqlHostQueryState, that.ksqlHostQueryState);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1825fd40b7926520ef42fd9c83174d83fec182f3"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc1NDQ5OA==", "bodyText": "Breaks encapsulation by returning mutable object state.  As above, wrap in unmodifyableMap.", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404754498", "createdAt": "2020-04-07T12:03:17Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryStateCount.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.entity;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n+import com.fasterxml.jackson.annotation.JsonValue;\n+import com.google.common.base.Joiner;\n+\n+import java.util.EnumMap;\n+import java.util.Map;\n+import java.util.Objects;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+\n+/**\n+ * Used to keep track of a the state of KafkaStreams application\n+ * across multiple servers. Used in {@link RunningQuery}.\n+ */\n+@JsonIgnoreProperties(ignoreUnknown = true)\n+public class QueryStateCount {\n+  \n+  // Use a EnumMap so toString() will always return the same string\n+  private final EnumMap<KafkaStreams.State, Integer> states;\n+\n+  public QueryStateCount() {\n+    this.states = returnEnumMap();\n+  }\n+\n+  @SuppressWarnings(\"unused\") // Invoked by reflection\n+  @JsonCreator\n+  public QueryStateCount(final Map<KafkaStreams.State, Integer> states) {\n+    this.states = states.isEmpty() ? returnEnumMap() : new EnumMap<>(states);\n+  }\n+\n+  \n+  public void updateStateCount(final String state, final int change) {\n+    updateStateCount(KafkaStreams.State.valueOf(state), change);\n+  }\n+\n+  public void updateStateCount(final KafkaStreams.State state, final int change) {\n+    this.states.compute(state, (key, existing) ->\n+        existing == null\n+            ? change\n+            : existing + change);\n+    \n+  }\n+\n+  @JsonValue\n+  public Map<KafkaStreams.State, Integer> getStates() {\n+    return states;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1825fd40b7926520ef42fd9c83174d83fec182f3"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDc1NDc4Nw==", "bodyText": "Add test using EqualsTester.", "url": "https://github.com/confluentinc/ksql/pull/4875#discussion_r404754787", "createdAt": "2020-04-07T12:03:52Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryStateCount.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"; you may not use\n+ * this file except in compliance with the License. You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.entity;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n+import com.fasterxml.jackson.annotation.JsonValue;\n+import com.google.common.base.Joiner;\n+\n+import java.util.EnumMap;\n+import java.util.Map;\n+import java.util.Objects;\n+\n+import org.apache.kafka.streams.KafkaStreams;\n+\n+/**\n+ * Used to keep track of a the state of KafkaStreams application\n+ * across multiple servers. Used in {@link RunningQuery}.\n+ */\n+@JsonIgnoreProperties(ignoreUnknown = true)\n+public class QueryStateCount {\n+  \n+  // Use a EnumMap so toString() will always return the same string\n+  private final EnumMap<KafkaStreams.State, Integer> states;\n+\n+  public QueryStateCount() {\n+    this.states = returnEnumMap();\n+  }\n+\n+  @SuppressWarnings(\"unused\") // Invoked by reflection\n+  @JsonCreator\n+  public QueryStateCount(final Map<KafkaStreams.State, Integer> states) {\n+    this.states = states.isEmpty() ? returnEnumMap() : new EnumMap<>(states);\n+  }\n+\n+  \n+  public void updateStateCount(final String state, final int change) {\n+    updateStateCount(KafkaStreams.State.valueOf(state), change);\n+  }\n+\n+  public void updateStateCount(final KafkaStreams.State state, final int change) {\n+    this.states.compute(state, (key, existing) ->\n+        existing == null\n+            ? change\n+            : existing + change);\n+    \n+  }\n+\n+  @JsonValue\n+  public Map<KafkaStreams.State, Integer> getStates() {\n+    return states;\n+  }\n+\n+  @Override\n+  public boolean equals(final Object o) {\n+    if (this == o) {\n+      return true;\n+    }\n+\n+    if (o == null || getClass() != o.getClass()) {\n+      return false;\n+    }\n+\n+    final QueryStateCount that = (QueryStateCount) o;\n+    return Objects.equals(states, that.states);\n+  }\n+\n+  @Override\n+  public int hashCode() {\n+    return Objects.hash(states);\n+  }\n+\n+  @Override\n+  public String toString() {\n+    return Joiner.on(\",\").withKeyValueSeparator(\":\").join(this.states);\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1825fd40b7926520ef42fd9c83174d83fec182f3"}, "originalPosition": 89}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9c073b03ef0bd5f8b4c89218f245cbb60d99e118", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/9c073b03ef0bd5f8b4c89218f245cbb60d99e118", "committedDate": "2020-04-07T18:45:15Z", "message": "last refactor"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "89ca8cf5efd4155eb2f70d76cacd89a1b3261ed5", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/89ca8cf5efd4155eb2f70d76cacd89a1b3261ed5", "committedDate": "2020-04-07T18:01:43Z", "message": "last refactor"}, "afterCommit": {"oid": "9c073b03ef0bd5f8b4c89218f245cbb60d99e118", "author": {"user": {"login": "stevenpyzhang", "name": "Steven Zhang"}}, "url": "https://github.com/confluentinc/ksql/commit/9c073b03ef0bd5f8b4c89218f245cbb60d99e118", "committedDate": "2020-04-07T18:45:15Z", "message": "last refactor"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4912, "cost": 1, "resetAt": "2021-11-01T13:51:04Z"}}}