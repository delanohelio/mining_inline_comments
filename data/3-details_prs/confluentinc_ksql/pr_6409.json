{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTAxODMwNjE4", "number": 6409, "title": "feat: Add support for IN clause to pull queries", "bodyText": "Description\nAdds support for the IN clause to pull queries such that multiple keys can be fetched at once.  This can be used in conjunction with all of the existing window comparisions (e.g. windowstart, windowend).\nAn example of such a query is:\nCREATE STREAM INPUT (ID STRING KEY, IGNORED INT) WITH (kafka_topic='test_topic', value_format='JSON');\nCREATE TABLE AGGREGATE AS SELECT ID, COUNT(1) AS COUNT FROM INPUT GROUP BY ID;\n\nSELECT * FROM AGGREGATE WHERE ID IN ('12345', '39874', '45450');\n\nAnd you might get a response like this:\n+----------------------------------+----------------+\n|ID                                |COUNT           |\n+----------------------------------+----------------+\n|12345                             |8               |\n|45450                             |10              |\n\nFixes #6115\nTesting done\nRan unit tests and rest query validation tests.\nReviewer checklist\n\n Ensure docs are updated if necessary. (eg. if a user visible feature is being added or changed).\n Ensure relevant issues are linked (description should include text like \"Fixes #\")", "createdAt": "2020-10-12T21:29:39Z", "url": "https://github.com/confluentinc/ksql/pull/6409", "merged": true, "mergeCommit": {"oid": "d5fc3658a8d7df1fe267a416dfcd3e0721b8a9c4"}, "closed": true, "closedAt": "2020-10-22T03:16:00Z", "author": {"login": "AlanConfluent"}, "timelineItems": {"totalCount": 33, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdR9Ad4AFqTUwNjk4NTkzOQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdU0el-AFqTUxNDIwODk2Ng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA2OTg1OTM5", "url": "https://github.com/confluentinc/ksql/pull/6409#pullrequestreview-506985939", "createdAt": "2020-10-12T23:58:40Z", "commit": {"oid": "dadec8e9b9e5a81bbb022aa8bc03634652fcb449"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMlQyMzo1ODo0MFrOHgQ_VQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMlQyMzo1ODo0MFrOHgQ_VQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzU5NDgzNw==", "bodyText": "The pullQueryContext is the same, the only thing that changes are the keys right?You could avoid creating a new object and just set the keys in each iteration.", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r503594837", "createdAt": "2020-10-12T23:58:40Z", "author": {"login": "vpapavas"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java", "diffHunk": "@@ -224,26 +230,48 @@ public PullQueryResult execute(\n           .getMaterialization(queryId, contextStacker)\n           .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n \n-      final Struct key = asKeyStruct(whereInfo.keyBound, query.getPhysicalSchema());\n+      final List<Optional<KsqlNode>> sourceNodes = new ArrayList<>();\n+      final List<List<?>> tableRows = new ArrayList<>();\n+      final List<LogicalSchema> schemas = new ArrayList<>();\n+      final List<Future<PullQueryResult>> futures = new ArrayList<>();\n+      final List<List<Struct>> keysByLocation = mat.locator().groupByLocation(\n+          whereInfo.keysBound.stream()\n+              .map(keyBound -> asKeyStruct(keyBound, query.getPhysicalSchema()))\n+              .collect(Collectors.toList()));\n+\n+      for (List<Struct> keys : keysByLocation) {\n+        final PullQueryContext pullQueryContext = new PullQueryContext(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dadec8e9b9e5a81bbb022aa8bc03634652fcb449"}, "originalPosition": 61}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA2OTg2NTc3", "url": "https://github.com/confluentinc/ksql/pull/6409#pullrequestreview-506986577", "createdAt": "2020-10-13T00:00:58Z", "commit": {"oid": "dadec8e9b9e5a81bbb022aa8bc03634652fcb449"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QwMDowMDo1OFrOHgRBlQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QwMDowMDo1OFrOHgRBlQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzU5NTQxMw==", "bodyText": "Why don't you return besides they keys also the active, standby per group? This way you wouldn't need to do locate twice basically.", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r503595413", "createdAt": "2020-10-13T00:00:58Z", "author": {"login": "vpapavas"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java", "diffHunk": "@@ -224,26 +230,48 @@ public PullQueryResult execute(\n           .getMaterialization(queryId, contextStacker)\n           .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n \n-      final Struct key = asKeyStruct(whereInfo.keyBound, query.getPhysicalSchema());\n+      final List<Optional<KsqlNode>> sourceNodes = new ArrayList<>();\n+      final List<List<?>> tableRows = new ArrayList<>();\n+      final List<LogicalSchema> schemas = new ArrayList<>();\n+      final List<Future<PullQueryResult>> futures = new ArrayList<>();\n+      final List<List<Struct>> keysByLocation = mat.locator().groupByLocation(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dadec8e9b9e5a81bbb022aa8bc03634652fcb449"}, "originalPosition": 55}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA2OTg2OTM4", "url": "https://github.com/confluentinc/ksql/pull/6409#pullrequestreview-506986938", "createdAt": "2020-10-13T00:02:16Z", "commit": {"oid": "dadec8e9b9e5a81bbb022aa8bc03634652fcb449"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QwMDowMjoxN1rOHgRCzQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QwMDowMjoxN1rOHgRCzQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzU5NTcyNQ==", "bodyText": "It seems that you assume that all keys in the group are routed to the same standby but that's not the case, since they might belong to different partitions.", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r503595725", "createdAt": "2020-10-13T00:02:17Z", "author": {"login": "vpapavas"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java", "diffHunk": "@@ -271,8 +308,9 @@ private PullQueryResult handlePullQuery(\n   ) {\n     // Get active and standby nodes for this key\n     final Locator locator = pullQueryContext.mat.locator();\n+    final Struct key = Iterables.getLast(pullQueryContext.keys);\n     final List<KsqlNode> filteredAndOrderedNodes = locator.locate(\n-        pullQueryContext.key,\n+        key,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dadec8e9b9e5a81bbb022aa8bc03634652fcb449"}, "originalPosition": 135}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA2OTg5MTk1", "url": "https://github.com/confluentinc/ksql/pull/6409#pullrequestreview-506989195", "createdAt": "2020-10-13T00:09:56Z", "commit": {"oid": "dadec8e9b9e5a81bbb022aa8bc03634652fcb449"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QwMDowOTo1NlrOHgRKpg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QwMDowOTo1NlrOHgRKpg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzU5NzczNA==", "bodyText": "Here you group keys based on the node that hosts the active partition. However, the keys may belong to different partitions and hence the standby may be different for keys in the same group. I think you should group them per <active, standby> combination else when we do the routing, we cannot assume that all keys go to the same standby  (when active dead)", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r503597734", "createdAt": "2020-10-13T00:09:56Z", "author": {"login": "vpapavas"}, "path": "ksqldb-streams/src/main/java/io/confluent/ksql/execution/streams/materialization/ks/KsLocator.java", "diffHunk": "@@ -118,6 +123,21 @@\n     return filteredHosts;\n   }\n \n+  @Override\n+  public List<List<Struct>> groupByLocation(final List<Struct> keys) {\n+    final Map<String, List<Struct>> groups = new HashMap<>();\n+    for (Struct key : keys) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dadec8e9b9e5a81bbb022aa8bc03634652fcb449"}, "originalPosition": 20}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA2OTkxNjQy", "url": "https://github.com/confluentinc/ksql/pull/6409#pullrequestreview-506991642", "createdAt": "2020-10-13T00:18:31Z", "commit": {"oid": "dadec8e9b9e5a81bbb022aa8bc03634652fcb449"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QwMDoxODozMlrOHgRTMw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QwMDoxODozMlrOHgRTMw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzU5OTkyMw==", "bodyText": "What's the benefit of having this class versus adding one more entry in the ComparisonTarget? Seems a lot of work for achieving the same functionality?", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r503599923", "createdAt": "2020-10-13T00:18:32Z", "author": {"login": "vpapavas"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java", "diffHunk": "@@ -761,19 +827,78 @@ private static Instant asInstant(final Expression other) {\n   }\n \n   private enum ComparisonTarget {\n-    KEYCOL,\n     WINDOWSTART,\n     WINDOWEND\n   }\n \n-  private static Map<ComparisonTarget, List<ComparisonExpression>> extractComparisons(\n+  private static class KeyAndWindowBounds {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dadec8e9b9e5a81bbb022aa8bc03634652fcb449"}, "originalPosition": 360}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA2OTk0NTYw", "url": "https://github.com/confluentinc/ksql/pull/6409#pullrequestreview-506994560", "createdAt": "2020-10-13T00:29:17Z", "commit": {"oid": "dadec8e9b9e5a81bbb022aa8bc03634652fcb449"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QwMDoyOToxN1rOHgRdzQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QwMDoyOToxN1rOHgRdzQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzYwMjYzNw==", "bodyText": "Shouldn't there be some error handling here? What happens if a thread dies due to an uncaught exception? We would like to fail the entire query and not return partial results, right? Maybe handle something like this:\n        try {\n            future.get();\n        } catch (InterruptedException e) {\n            Thread.currentThread().interrupt();\n        } catch (ExecutionException e) {\n            // Extract the actual exception from its wrapper\n            Throwable t = e.getCause();\n            System.err.println(\"Uncaught exception is detected! \" + t\n                    + \" st: \" + Arrays.toString(t.getStackTrace()));\n            // ... Handle the exception\n        }", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r503602637", "createdAt": "2020-10-13T00:29:17Z", "author": {"login": "vpapavas"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java", "diffHunk": "@@ -224,26 +230,48 @@ public PullQueryResult execute(\n           .getMaterialization(queryId, contextStacker)\n           .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n \n-      final Struct key = asKeyStruct(whereInfo.keyBound, query.getPhysicalSchema());\n+      final List<Optional<KsqlNode>> sourceNodes = new ArrayList<>();\n+      final List<List<?>> tableRows = new ArrayList<>();\n+      final List<LogicalSchema> schemas = new ArrayList<>();\n+      final List<Future<PullQueryResult>> futures = new ArrayList<>();\n+      final List<List<Struct>> keysByLocation = mat.locator().groupByLocation(\n+          whereInfo.keysBound.stream()\n+              .map(keyBound -> asKeyStruct(keyBound, query.getPhysicalSchema()))\n+              .collect(Collectors.toList()));\n+\n+      for (List<Struct> keys : keysByLocation) {\n+        final PullQueryContext pullQueryContext = new PullQueryContext(\n+            keys,\n+            mat,\n+            analysis,\n+            whereInfo,\n+            queryId,\n+            contextStacker,\n+            pullQueryMetrics);\n+\n+        futures.add(executorService.submit(() -> handlePullQuery(\n+            statement,\n+            executionContext,\n+            serviceContext,\n+            pullQueryContext,\n+            routingOptions\n+        )));\n \n-      final PullQueryContext pullQueryContext = new PullQueryContext(\n-          key,\n-          mat,\n-          analysis,\n-          whereInfo,\n-          queryId,\n-          contextStacker,\n-          pullQueryMetrics);\n+      }\n+      for (Future<PullQueryResult> future : futures) {\n+        final PullQueryResult result = future.get();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dadec8e9b9e5a81bbb022aa8bc03634652fcb449"}, "originalPosition": 88}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA4ODI4OTEy", "url": "https://github.com/confluentinc/ksql/pull/6409#pullrequestreview-508828912", "createdAt": "2020-10-14T23:00:18Z", "commit": {"oid": "beb105b8f097b92482913ba27b540d137ed01a33"}, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQyMzowMDoxOFrOHhpkmg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xNFQyMzo0NTowMlrOHhrbZg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTA0NjE3MA==", "bodyText": "very soon we're going to support all expression types as keys (including structs) and we already support DECIMAL keys. I'm not entirely sure that this approach will work then since it's not always possible to take a java object and convert it into an expression as the inverse conversion is lossy. Is it possible to extract the original expression when we construct the List<Struct> keys instead of mapping it to Java objects?", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r505046170", "createdAt": "2020-10-14T23:00:18Z", "author": {"login": "agavra"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/engine/rewrite/PullQueryKeyUpdater.java", "diffHunk": "@@ -0,0 +1,106 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.engine.rewrite;\n+\n+import com.google.common.collect.Iterables;\n+import io.confluent.ksql.engine.rewrite.ExpressionTreeRewriter.Context;\n+import io.confluent.ksql.execution.expression.tree.DoubleLiteral;\n+import io.confluent.ksql.execution.expression.tree.Expression;\n+import io.confluent.ksql.execution.expression.tree.InListExpression;\n+import io.confluent.ksql.execution.expression.tree.InPredicate;\n+import io.confluent.ksql.execution.expression.tree.IntegerLiteral;\n+import io.confluent.ksql.execution.expression.tree.LongLiteral;\n+import io.confluent.ksql.execution.expression.tree.StringLiteral;\n+import io.confluent.ksql.execution.expression.tree.VisitParentExpressionVisitor;\n+import io.confluent.ksql.parser.tree.Query;\n+import io.confluent.ksql.parser.tree.Statement;\n+import io.confluent.ksql.util.KsqlException;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.connect.data.Field;\n+import org.apache.kafka.connect.data.Schema;\n+import org.apache.kafka.connect.data.Struct;\n+\n+/**\n+ * Takes a configured statement and rewrites it to update the keys requested.  This only works if\n+ * the query uses the IN keyword.\n+ * This is required because when fetching multiple keys using the IN keyword, a given host may be\n+ * the active for one partition and standby for another partition, and if you issue a query\n+ * requesting keys from both partitions while using ksql.query.pull.enable.standby.reads=true,\n+ * you'll fetch stale values unintentionally.\n+ */\n+public final class PullQueryKeyUpdater {\n+\n+  private PullQueryKeyUpdater() {}\n+\n+  /**\n+   * Returns a Statement with the IN expression updated to include only the given keys.\n+   * @param statement the original statement.\n+   * @param keys the keys to include\n+   * @return The updated statement\n+   */\n+  public static Statement update(\n+      final Query statement,\n+      final List<Struct> keys) {\n+    final BiFunction<Expression, Void, Expression> expressionRewriter =\n+        (e, v) -> ExpressionTreeRewriter.rewriteWith(\n+            new ExpressionRewriterPlugin(keys)::process, e, v);\n+    return (Statement) new StatementRewriter<>(expressionRewriter, (n, c) -> Optional.empty())\n+        .rewrite(statement, null);\n+  }\n+\n+  private static final class ExpressionRewriterPlugin extends\n+      VisitParentExpressionVisitor<Optional<Expression>, Context<Void>> {\n+\n+    private final List<Struct> keys;\n+\n+    ExpressionRewriterPlugin(final List<Struct> keys) {\n+      super(Optional.empty());\n+      this.keys = keys;\n+    }\n+\n+    @Override\n+    public Optional<Expression> visitInPredicate(final InPredicate node, final Context<Void> ctx) {\n+      final List<Expression> values = keys.stream().map(k -> {\n+        final Field field = Iterables.getOnlyElement(k.schema().fields());\n+        return convertToExpression(field.schema(), k.get(field));\n+      }).collect(Collectors.toList());\n+      final InListExpression inList\n+          = new InListExpression(node.getValueList().getLocation(), values);\n+      return Optional.of(new InPredicate(node.getLocation(), node.getValue(), inList));\n+    }\n+\n+    private Expression convertToExpression(final Schema schema, final Object value) {\n+      switch (schema.type()) {\n+        case STRING:\n+          return new StringLiteral((String) value);\n+        case INT8:\n+        case INT16:\n+        case INT32:\n+          return new IntegerLiteral((int) value);\n+        case INT64:\n+          return new LongLiteral((long) value);\n+        case FLOAT32:\n+        case FLOAT64:\n+          return new DoubleLiteral((double) value);\n+        default:\n+          throw new KsqlException(\"Unknown key type \" + schema.type());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "beb105b8f097b92482913ba27b540d137ed01a33"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTA1MDY4OA==", "bodyText": "is there any requirement that the pull query result is reproducible? it seems like we add rows to the result based on the order of the nodes that we request, but those nodes can host different partitions at different times. I think it's reasonable to not guarantee ordering, but food for thought (and probably should be documented)", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r505050688", "createdAt": "2020-10-14T23:07:03Z", "author": {"login": "agavra"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java", "diffHunk": "@@ -224,36 +234,73 @@ public PullQueryResult execute(\n           .getMaterialization(queryId, contextStacker)\n           .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n \n-      final Struct key = asKeyStruct(whereInfo.keyBound, query.getPhysicalSchema());\n+      final List<Optional<KsqlNode>> sourceNodes = new ArrayList<>();\n+      final List<List<?>> tableRows = new ArrayList<>();\n+      final List<LogicalSchema> schemas = new ArrayList<>();\n+      final List<Future<PullQueryResult>> futures = new ArrayList<>();\n+      final List<Struct> keys = whereInfo.keysBound.stream()\n+          .map(keyBound -> asKeyStruct(keyBound, query.getPhysicalSchema()))\n+          .collect(ImmutableList.toImmutableList());\n+      final List<KsqlNodeList> nodeLists = mat.locator().locate(\n+          keys,\n+          routingOptions,\n+          routingFilterFactory\n+      );\n \n-      final PullQueryContext pullQueryContext = new PullQueryContext(\n-          key,\n-          mat,\n-          analysis,\n-          whereInfo,\n-          queryId,\n-          contextStacker,\n-          pullQueryMetrics);\n+      for (KsqlNodeList ksqlNodeList : nodeLists) {\n+        final PullQueryContext pullQueryContext = new PullQueryContext(\n+            ksqlNodeList.getKeys(),\n+            mat,\n+            analysis,\n+            whereInfo,\n+            queryId,\n+            contextStacker,\n+            pullQueryMetrics);\n+\n+        futures.add(executorService.submit(() -> handlePullQuery(\n+            statement,\n+            executionContext,\n+            serviceContext,\n+            pullQueryContext,\n+            ksqlNodeList.getNodes(),\n+            routingOptions\n+        )));\n \n-      final PullQueryResult result = handlePullQuery(\n-          statement,\n-          executionContext,\n-          serviceContext,\n-          pullQueryContext,\n-          routingOptions\n-      );\n+      }\n+      for (Future<PullQueryResult> future : futures) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "beb105b8f097b92482913ba27b540d137ed01a33"}, "originalPosition": 131}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTA1MzM0Ng==", "bodyText": "calling interrupt is what causes the InterruptedException\n\nI think you probably meant this, but just a small clarification here - Thread.currentThread().interrupt() does not directly cause an InterruptedException. It just sets an interrupt flag on the thread's state, and then any blocking code is expected to check that flag and raise an InterruptedException when it notices that flag. There is no guarantee that calling interupt will actually do anything (especially if there's misbehaving client code). It's a cooperative strategy.", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r505053346", "createdAt": "2020-10-14T23:10:53Z", "author": {"login": "agavra"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java", "diffHunk": "@@ -224,26 +230,48 @@ public PullQueryResult execute(\n           .getMaterialization(queryId, contextStacker)\n           .orElseThrow(() -> notMaterializedException(getSourceName(analysis)));\n \n-      final Struct key = asKeyStruct(whereInfo.keyBound, query.getPhysicalSchema());\n+      final List<Optional<KsqlNode>> sourceNodes = new ArrayList<>();\n+      final List<List<?>> tableRows = new ArrayList<>();\n+      final List<LogicalSchema> schemas = new ArrayList<>();\n+      final List<Future<PullQueryResult>> futures = new ArrayList<>();\n+      final List<List<Struct>> keysByLocation = mat.locator().groupByLocation(\n+          whereInfo.keysBound.stream()\n+              .map(keyBound -> asKeyStruct(keyBound, query.getPhysicalSchema()))\n+              .collect(Collectors.toList()));\n+\n+      for (List<Struct> keys : keysByLocation) {\n+        final PullQueryContext pullQueryContext = new PullQueryContext(\n+            keys,\n+            mat,\n+            analysis,\n+            whereInfo,\n+            queryId,\n+            contextStacker,\n+            pullQueryMetrics);\n+\n+        futures.add(executorService.submit(() -> handlePullQuery(\n+            statement,\n+            executionContext,\n+            serviceContext,\n+            pullQueryContext,\n+            routingOptions\n+        )));\n \n-      final PullQueryContext pullQueryContext = new PullQueryContext(\n-          key,\n-          mat,\n-          analysis,\n-          whereInfo,\n-          queryId,\n-          contextStacker,\n-          pullQueryMetrics);\n+      }\n+      for (Future<PullQueryResult> future : futures) {\n+        final PullQueryResult result = future.get();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzYwMjYzNw=="}, "originalCommit": {"oid": "dadec8e9b9e5a81bbb022aa8bc03634652fcb449"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTA1NzI0Ng==", "bodyText": "nit: probably makes sense to make this Optional<List<KsqlNode>> instead of List<Optional<KsqlNode>> to prevent creating a list of empty optionals in the non-debug case. And then you can also use Collections#nCopies to make it a little more readable", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r505057246", "createdAt": "2020-10-14T23:16:28Z", "author": {"login": "agavra"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java", "diffHunk": "@@ -289,11 +329,14 @@ private PullQueryResult handlePullQuery(\n     // increasing order of lag.\n     for (KsqlNode node : filteredAndOrderedNodes) {\n       try {\n+        final TableRows rows\n+            = routeQuery(node, statement, executionContext, serviceContext, pullQueryContext);\n         final Optional<KsqlNode> debugNode = Optional.ofNullable(\n             routingOptions.isDebugRequest() ? node : null);\n-        return new PullQueryResult(\n-            routeQuery(node, statement, executionContext, serviceContext, pullQueryContext),\n-            debugNode);\n+        final List<Optional<KsqlNode>> debugNodes = rows.getRows().stream()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "beb105b8f097b92482913ba27b540d137ed01a33"}, "originalPosition": 200}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTA2MjI2MA==", "bodyText": "I'm worried this approach doesn't scale well for things other than IN queries (not to mention that it feels hacky). Instead, it probably makes sense to have a way to specify that a pull query (internally routed only) should only read from certain partitions. Otherwise, how would we handle things like range queries? I can't \"rewrite\" the range query and avoid the risk of reading standby data.\nGenerally, I think it might make sense to think about communicating pull queries internally using something other than just the SQL statement.", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r505062260", "createdAt": "2020-10-14T23:23:53Z", "author": {"login": "agavra"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java", "diffHunk": "@@ -389,8 +438,14 @@ private static TableRows queryRowsLocally(\n   private static TableRows forwardTo(\n       final KsqlNode owner,\n       final ConfiguredStatement<Query> statement,\n-      final ServiceContext serviceContext\n+      final ServiceContext serviceContext,\n+      final PullQueryContext pullQueryContext\n   ) {\n+    // Rewrite the expression to only query for the particular keys we care about for this node.\n+    // Otherwise, we'll risk reading standby data for other partitions.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "beb105b8f097b92482913ba27b540d137ed01a33"}, "originalPosition": 259}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTA2NDk1OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    throw new KsqlException(\"Ony comparison to literals is currently supported: \"\n          \n          \n            \n                    throw new KsqlException(\"Only comparison to literals is currently supported: \"", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r505064959", "createdAt": "2020-10-14T23:27:58Z", "author": {"login": "agavra"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java", "diffHunk": "@@ -535,44 +590,65 @@ private static WhereInfo extractWhereInfo(\n     final Expression where = analysis.getWhereExpression()\n         .orElseThrow(() -> invalidWhereClauseException(\"Missing WHERE clause\", windowed));\n \n-    final Map<ComparisonTarget, List<ComparisonExpression>> comparisons =\n-        extractComparisons(where, query);\n-\n-    final List<ComparisonExpression> keyComparison = comparisons.get(ComparisonTarget.KEYCOL);\n-    if (keyComparison == null) {\n+    final KeyAndWindowBounds keyAndWindowBounds = extractComparisons(where, query);\n+    final List<ComparisonExpression> keyComparison = keyAndWindowBounds.getKeyColExpression();\n+    final List<InPredicate> inPredicate = keyAndWindowBounds.getInPredicate();\n+    if (keyComparison.size() == 0 && inPredicate.size() == 0) {\n       throw invalidWhereClauseException(\"WHERE clause missing key column\", windowed);\n+    } else if ((keyComparison.size() + inPredicate.size()) > 1) {\n+      throw invalidWhereClauseException(\"Multiple bounds on key column\", windowed);\n     }\n \n-    final Object key = extractKeyWhereClause(\n-        keyComparison,\n-        windowed,\n-        query.getLogicalSchema()\n-    );\n+    final List<Object> keys;\n+    if (keyComparison.size() > 0) {\n+      keys = ImmutableList.of(\n+          extractKeyWhereClause(keyComparison, windowed, query.getLogicalSchema()));\n+    } else {\n+      keys = extractKeysFromInPredicate(inPredicate, windowed, query.getLogicalSchema());\n+    }\n \n     if (!windowed) {\n-      if (comparisons.size() > 1) {\n+      if (keyAndWindowBounds.getWindowStartExpression().size() > 0\n+          || keyAndWindowBounds.getWindowEndExpression().size() > 0) {\n         throw invalidWhereClauseException(\"Unsupported WHERE clause\", false);\n       }\n \n-      return new WhereInfo(key, Optional.empty());\n+      return new WhereInfo(keys, Optional.empty());\n     }\n \n     final WindowBounds windowBounds =\n-        extractWhereClauseWindowBounds(comparisons);\n+        extractWhereClauseWindowBounds(keyAndWindowBounds);\n \n-    return new WhereInfo(key, Optional.of(windowBounds));\n+    return new WhereInfo(keys, Optional.of(windowBounds));\n   }\n \n-  private static Object extractKeyWhereClause(\n-      final List<ComparisonExpression> comparisons,\n+  private static List<Object> extractKeysFromInPredicate(\n+      final List<InPredicate> inPredicates,\n       final boolean windowed,\n       final LogicalSchema schema\n   ) {\n-    if (comparisons.size() != 1) {\n-      throw invalidWhereClauseException(\"Multiple bounds on key column\", windowed);\n+    final InPredicate inPredicate = Iterables.getLast(inPredicates);\n+    final List<Object> result = new ArrayList<>();\n+    for (Expression expression : inPredicate.getValueList().getValues()) {\n+      if (!(expression instanceof Literal)) {\n+        throw new KsqlException(\"Ony comparison to literals is currently supported: \"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "beb105b8f097b92482913ba27b540d137ed01a33"}, "originalPosition": 383}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNTA3NjU4Mg==", "bodyText": "nit: computeIfAbsent returns the result of the compute, so you could just\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  groups.computeIfAbsent(filteredHosts, nl -> new ArrayList<>());\n          \n          \n            \n                  groups.get(filteredHosts).add(key);\n          \n          \n            \n                  groups.computeIfAbsent(filteredHosts, nl -> new ArrayList<>()).add(key);", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r505076582", "createdAt": "2020-10-14T23:45:02Z", "author": {"login": "agavra"}, "path": "ksqldb-streams/src/main/java/io/confluent/ksql/execution/streams/materialization/ks/KsLocator.java", "diffHunk": "@@ -68,54 +74,61 @@\n   }\n \n   @Override\n-  public List<KsqlNode> locate(\n-      final Struct key,\n+  public List<KsqlNodeList> locate(\n+      final List<Struct> keys,\n       final RoutingOptions routingOptions,\n       final RoutingFilterFactory routingFilterFactory\n   ) {\n-    final KeyQueryMetadata metadata = kafkaStreams\n-        .queryMetadataForKey(stateStoreName, key, keySerializer);\n-\n-    // Fail fast if Streams not ready. Let client handle it\n-    if (metadata == KeyQueryMetadata.NOT_AVAILABLE) {\n-      LOG.debug(\"KeyQueryMetadata not available for state store {} and key {}\",\n-                stateStoreName, key);\n-      throw new MaterializationException(String.format(\n-          \"KeyQueryMetadata not available for state store %s and key %s\", stateStoreName, key));\n-    }\n+    final Map<ImmutableList<KsqlNode>, List<Struct>> groups = new HashMap<>();\n+    for (Struct key : keys) {\n+      final KeyQueryMetadata metadata = kafkaStreams\n+          .queryMetadataForKey(stateStoreName, key, keySerializer);\n+\n+      // Fail fast if Streams not ready. Let client handle it\n+      if (metadata == KeyQueryMetadata.NOT_AVAILABLE) {\n+        LOG.debug(\"KeyQueryMetadata not available for state store {} and key {}\",\n+            stateStoreName, key);\n+        throw new MaterializationException(String.format(\n+            \"KeyQueryMetadata not available for state store %s and key %s\", stateStoreName, key));\n+      }\n \n-    LOG.debug(\"Handling pull query for key {} in partition {} of state store {}.\",\n-              key, metadata.partition(), stateStoreName);\n-    \n-    final HostInfo activeHost = metadata.activeHost();\n-    final Set<HostInfo> standByHosts = metadata.standbyHosts();\n-\n-    // If the lookup is for a forwarded request, only filter localhost\n-    List<KsqlHostInfo> allHosts = null;\n-    if (routingOptions.skipForwardRequest()) {\n-      LOG.debug(\"Before filtering: Local host {} \", localHost);\n-      allHosts = ImmutableList.of(new KsqlHostInfo(localHost.getHost(), localHost.getPort()));\n-    } else {\n-      LOG.debug(\"Before filtering: Active host {} , standby hosts {}\", activeHost, standByHosts);\n-      allHosts = Stream.concat(Stream.of(activeHost), standByHosts.stream())\n-          .map(this::asKsqlHost)\n-          .collect(Collectors.toList());\n+      LOG.debug(\"Handling pull query for key {} in partition {} of state store {}.\",\n+          key, metadata.partition(), stateStoreName);\n+      final HostInfo activeHost = metadata.activeHost();\n+      final Set<HostInfo> standByHosts = metadata.standbyHosts();\n+\n+      // If the lookup is for a forwarded request, only filter localhost\n+      List<KsqlHostInfo> allHosts = null;\n+      if (routingOptions.skipForwardRequest()) {\n+        LOG.debug(\"Before filtering: Local host {} \", localHost);\n+        allHosts = ImmutableList.of(new KsqlHostInfo(localHost.getHost(), localHost.getPort()));\n+      } else {\n+        LOG.debug(\"Before filtering: Active host {} , standby hosts {}\", activeHost, standByHosts);\n+        allHosts = Stream.concat(Stream.of(activeHost), standByHosts.stream())\n+            .map(this::asKsqlHost)\n+            .collect(Collectors.toList());\n+      }\n+      final RoutingFilter routingFilter = routingFilterFactory.createRoutingFilter(routingOptions,\n+          allHosts, activeHost, applicationId, stateStoreName, metadata.partition());\n+\n+      // Filter out hosts based on active, liveness and max lag filters.\n+      // The list is ordered by routing preference: active node is first, then standby nodes.\n+      // If heartbeat is not enabled, all hosts are considered alive.\n+      // If the request is forwarded internally from another ksql server, only the max lag filter\n+      // is applied.\n+      final ImmutableList<KsqlNode> filteredHosts = allHosts.stream()\n+          .filter(routingFilter::filter)\n+          .map(this::asNode)\n+          .collect(ImmutableList.toImmutableList());\n+\n+      LOG.debug(\"Filtered and ordered hosts: {}\", filteredHosts);\n+\n+      groups.computeIfAbsent(filteredHosts, nl -> new ArrayList<>());\n+      groups.get(filteredHosts).add(key);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "beb105b8f097b92482913ba27b540d137ed01a33"}, "originalPosition": 103}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "74f95f8286ada5c7ce51aee10b03615a086f3065", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/74f95f8286ada5c7ce51aee10b03615a086f3065", "committedDate": "2020-10-16T22:02:37Z", "message": "Basic version"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "332017dcb31ee51be6991679b834e8a2cdf46925", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/332017dcb31ee51be6991679b834e8a2cdf46925", "committedDate": "2020-10-16T22:02:37Z", "message": "Groups queries by location"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6b8970512b59b4b5249f80b041b7f06545bfa235", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/6b8970512b59b4b5249f80b041b7f06545bfa235", "committedDate": "2020-10-16T22:02:37Z", "message": "Makes it multithreaded"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "db742d1981f69fe2cac152d64093eba66e7a3d95", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/db742d1981f69fe2cac152d64093eba66e7a3d95", "committedDate": "2020-10-16T22:02:37Z", "message": "Reworked to work with window functions"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e02ab188ed3b4f1f0eaf09768585bf4b56c10dc7", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/e02ab188ed3b4f1f0eaf09768585bf4b56c10dc7", "committedDate": "2020-10-16T22:02:37Z", "message": "Gets tests working"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "41f34c1a8c14713ab3df1320e63087c224c4f757", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/41f34c1a8c14713ab3df1320e63087c224c4f757", "committedDate": "2020-10-16T22:02:38Z", "message": "mvn validate"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "40ee19af6560f097a2959358fa21ddb0f37baba9", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/40ee19af6560f097a2959358fa21ddb0f37baba9", "committedDate": "2020-10-16T22:02:38Z", "message": "Adds rest query validation tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cd573e08a7ca45d4072ac4bbc3f838ae0ad3d9c7", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/cd573e08a7ca45d4072ac4bbc3f838ae0ad3d9c7", "committedDate": "2020-10-16T22:02:38Z", "message": "Fixes test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f505f71f657b1c7351864c67ea8870f119b45406", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/f505f71f657b1c7351864c67ea8870f119b45406", "committedDate": "2020-10-16T22:02:38Z", "message": "Feedback"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4b662c8c3a32b2562a9532836000dea955cc162d", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/4b662c8c3a32b2562a9532836000dea955cc162d", "committedDate": "2020-10-16T22:02:38Z", "message": "Revert change to RestQueryTranslationTest"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fb493c2dde16c2238003ad95e6dbed5459059659", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/fb493c2dde16c2238003ad95e6dbed5459059659", "committedDate": "2020-10-16T22:02:38Z", "message": "Changes to reorganize by host each time"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1a55d1f807dcff3631edb2fbb3a8e949481b2cc2", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/1a55d1f807dcff3631edb2fbb3a8e949481b2cc2", "committedDate": "2020-10-16T22:02:38Z", "message": "Changed to using partition rather than rewriting keys"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c13a9c8b9790b986fc81f35c05546d3cb798a652", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/c13a9c8b9790b986fc81f35c05546d3cb798a652", "committedDate": "2020-10-16T22:02:38Z", "message": "Removes key dups"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4888c5752f3fc7a22bf8d2078cacefbd2eb8be31", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/4888c5752f3fc7a22bf8d2078cacefbd2eb8be31", "committedDate": "2020-10-16T22:02:38Z", "message": "Uncomments KsLocatorTest.java and adds a case"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "54f835998ab81a43eb2ccea2f7d84ef24da1a0ae", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/54f835998ab81a43eb2ccea2f7d84ef24da1a0ae", "committedDate": "2020-10-16T22:05:34Z", "message": "Ups threads to 100"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "028419a99c374961ef8020e2247c50ed49df7709", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/028419a99c374961ef8020e2247c50ed49df7709", "committedDate": "2020-10-15T23:21:08Z", "message": "Uncomments KsLocatorTest.java and adds a case"}, "afterCommit": {"oid": "54f835998ab81a43eb2ccea2f7d84ef24da1a0ae", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/54f835998ab81a43eb2ccea2f7d84ef24da1a0ae", "committedDate": "2020-10-16T22:05:34Z", "message": "Ups threads to 100"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f721ccbe4f514c0499424ad7a05d58b8d9cf91a2", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/f721ccbe4f514c0499424ad7a05d58b8d9cf91a2", "committedDate": "2020-10-19T21:38:37Z", "message": "Fixes RestQueryTranslationTest"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTEyOTk3NDU2", "url": "https://github.com/confluentinc/ksql/pull/6409#pullrequestreview-512997456", "createdAt": "2020-10-20T18:02:03Z", "commit": {"oid": "f721ccbe4f514c0499424ad7a05d58b8d9cf91a2"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMFQxODowNDowMlrOHlKj5w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMFQxODowNDowMlrOHlKj5w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODczMjM5MQ==", "bodyText": "It's normal for the IN operator to support some level of coercion of types. I see you've handled INT -> BIGINT. But, strangely, it's also normal to support STRING -> .  Of course, we don't have to support this. But those used to sql may expect it...", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r508732391", "createdAt": "2020-10-20T18:04:02Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-functional-tests/src/test/resources/rest-query-validation-tests/pull-queries-against-materialized-aggregates.json", "diffHunk": "@@ -1540,6 +1540,404 @@\n           {\"header\":{\"schema\":\"`ID` INTEGER KEY, `COUNT` BIGINT\"}}\n         ]}\n       ]\n+    },\n+    {\n+      \"name\": \"non-windowed IN key lookup - STRING\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, IGNORED INT) WITH (kafka_topic='test_topic', value_format='JSON');\",\n+        \"CREATE TABLE AGGREGATE AS SELECT ID, COUNT(1) AS COUNT FROM INPUT GROUP BY ID;\",\n+        \"SELECT * FROM AGGREGATE WHERE ID IN ('10', '8');\",\n+        \"SELECT * FROM AGGREGATE WHERE ID IN ('missing', 'missing again');\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"test_topic\", \"timestamp\": 12345, \"key\": \"11\", \"value\": {}},\n+        {\"topic\": \"test_topic\", \"timestamp\": 12365, \"key\": \"10\", \"value\": {}},\n+        {\"topic\": \"test_topic\", \"timestamp\": 12366, \"key\": \"9\", \"value\": {}},\n+        {\"topic\": \"test_topic\", \"timestamp\": 12367, \"key\": \"8\", \"value\": {}},\n+        {\"topic\": \"test_topic\", \"timestamp\": 12368, \"key\": \"12\", \"value\": {}}\n+      ],\n+      \"responses\": [\n+        {\"admin\": {\"@type\": \"currentStatus\"}},\n+        {\"admin\": {\"@type\": \"currentStatus\"}},\n+        {\"query\": [\n+          {\"header\":{\"schema\":\"`ID` STRING KEY, `COUNT` BIGINT\"}},\n+          {\"row\":{\"columns\":[\"10\", 1]}},\n+          {\"row\":{\"columns\":[\"8\", 1]}}\n+        ]},\n+        {\"query\": [\n+          {\"header\":{\"schema\":\"`ID` STRING KEY, `COUNT` BIGINT\"}}\n+        ]}\n+      ]\n+    },\n+    {\n+      \"name\": \"non-windowed IN key lookup - INT\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID INT KEY, IGNORED INT) WITH (kafka_topic='test_topic', value_format='JSON');\",\n+        \"CREATE TABLE AGGREGATE AS SELECT ID, COUNT(1) AS COUNT FROM INPUT GROUP BY ID;\",\n+        \"SELECT * FROM AGGREGATE WHERE ID IN (10, 8);\",\n+        \"SELECT * FROM AGGREGATE WHERE ID IN (123369, 123370);\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"test_topic\", \"timestamp\": 12345, \"key\": 11, \"value\": {}},\n+        {\"topic\": \"test_topic\", \"timestamp\": 12365, \"key\": 10, \"value\": {}},\n+        {\"topic\": \"test_topic\", \"timestamp\": 12366, \"key\": 9, \"value\": {}},\n+        {\"topic\": \"test_topic\", \"timestamp\": 12367, \"key\": 8, \"value\": {}},\n+        {\"topic\": \"test_topic\", \"timestamp\": 12368, \"key\": 12, \"value\": {}}\n+      ],\n+      \"responses\": [\n+        {\"admin\": {\"@type\": \"currentStatus\"}},\n+        {\"admin\": {\"@type\": \"currentStatus\"}},\n+        {\"query\": [\n+          {\"header\":{\"schema\":\"`ID` INTEGER KEY, `COUNT` BIGINT\"}},\n+          {\"row\":{\"columns\":[10, 1]}},\n+          {\"row\":{\"columns\":[8, 1]}}\n+        ]},\n+        {\"query\": [\n+          {\"header\":{\"schema\":\"`ID` INTEGER KEY, `COUNT` BIGINT\"}}\n+        ]}\n+      ]\n+    },\n+    {\n+      \"name\": \"non-windowed IN key lookup - BIGINT\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID BIGINT KEY, IGNORED INT) WITH (kafka_topic='test_topic', value_format='JSON');\",\n+        \"CREATE TABLE AGGREGATE AS SELECT ID, COUNT(1) AS COUNT FROM INPUT GROUP BY ID;\",\n+        \"SELECT * FROM AGGREGATE WHERE ID IN (10, 8);\",\n+        \"SELECT * FROM AGGREGATE WHERE ID IN (123369, 123370);\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"test_topic\", \"timestamp\": 12345, \"key\": 11, \"value\": {}},\n+        {\"topic\": \"test_topic\", \"timestamp\": 12365, \"key\": 10, \"value\": {}},\n+        {\"topic\": \"test_topic\", \"timestamp\": 12366, \"key\": 9, \"value\": {}},\n+        {\"topic\": \"test_topic\", \"timestamp\": 12367, \"key\": 8, \"value\": {}},\n+        {\"topic\": \"test_topic\", \"timestamp\": 12368, \"key\": 12, \"value\": {}}\n+      ],\n+      \"responses\": [\n+        {\"admin\": {\"@type\": \"currentStatus\"}},\n+        {\"admin\": {\"@type\": \"currentStatus\"}},\n+        {\"query\": [\n+          {\"header\":{\"schema\":\"`ID` BIGINT KEY, `COUNT` BIGINT\"}},\n+          {\"row\":{\"columns\":[10, 1]}},\n+          {\"row\":{\"columns\":[8, 1]}}\n+        ]},\n+        {\"query\": [\n+          {\"header\":{\"schema\":\"`ID` BIGINT KEY, `COUNT` BIGINT\"}}\n+        ]}\n+      ]\n+    },\n+    {\n+      \"name\": \"non-windowed IN key lookup - DOUBLE\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID DOUBLE KEY, IGNORED INT) WITH (kafka_topic='test_topic', value_format='JSON');\",\n+        \"CREATE TABLE AGGREGATE AS SELECT ID, COUNT(1) AS COUNT FROM INPUT GROUP BY ID;\",\n+        \"SELECT * FROM AGGREGATE WHERE ID IN (10, 8.0);\",\n+        \"SELECT * FROM AGGREGATE WHERE ID IN (1.0E1, 8);\",\n+        \"SELECT * FROM AGGREGATE WHERE ID IN (123369, 123370);\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"test_topic\", \"timestamp\": 12345, \"key\": 11.0, \"value\": {}},\n+        {\"topic\": \"test_topic\", \"timestamp\": 12365, \"key\": 10.0, \"value\": {}},\n+        {\"topic\": \"test_topic\", \"timestamp\": 12366, \"key\": 9.0, \"value\": {}},\n+        {\"topic\": \"test_topic\", \"timestamp\": 12367, \"key\": 8.0, \"value\": {}},\n+        {\"topic\": \"test_topic\", \"timestamp\": 12368, \"key\": 12.0, \"value\": {}}\n+      ],\n+      \"responses\": [\n+        {\"admin\": {\"@type\": \"currentStatus\"}},\n+        {\"admin\": {\"@type\": \"currentStatus\"}},\n+        {\"query\": [\n+          {\"header\":{\"schema\":\"`ID` DOUBLE KEY, `COUNT` BIGINT\"}},\n+          {\"row\":{\"columns\":[10.0, 1]}},\n+          {\"row\":{\"columns\":[8.0, 1]}}\n+        ]},\n+        {\"query\": [\n+          {\"header\":{\"schema\":\"`ID` DOUBLE KEY, `COUNT` BIGINT\"}},\n+          {\"row\":{\"columns\":[10.0, 1]}},\n+          {\"row\":{\"columns\":[8.0, 1]}}\n+        ]},\n+        {\"query\": [\n+          {\"header\":{\"schema\":\"`ID` DOUBLE KEY, `COUNT` BIGINT\"}}\n+        ]}\n+      ]\n+    },\n+    {\n+      \"name\": \"non-windowed IN lookup on wrong type\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID INT KEY, IGNORED INT) WITH (kafka_topic='test_topic', value_format='JSON');\",\n+        \"CREATE TABLE AGGREGATE AS SELECT ID, COUNT(1) AS COUNT FROM INPUT GROUP BY ID;\",\n+        \"SELECT * FROM AGGREGATE WHERE ID IN ('10', 8);\"\n+      ],\n+      \"expectedError\": {\n+        \"type\": \"io.confluent.ksql.rest.entity.KsqlStatementErrorMessage\",\n+        \"message\": \"'10' can not be converted to the type of the key column: ID INTEGER KEY\",\n+        \"status\": 400\n+      }\n+    },", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f721ccbe4f514c0499424ad7a05d58b8d9cf91a2"}, "originalPosition": 135}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTEzMDExODA3", "url": "https://github.com/confluentinc/ksql/pull/6409#pullrequestreview-513011807", "createdAt": "2020-10-20T18:20:32Z", "commit": {"oid": "f721ccbe4f514c0499424ad7a05d58b8d9cf91a2"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMFQxODoyMDozMlrOHlLL8w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMFQxODoyMDozMlrOHlLL8w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODc0MjY0Mw==", "bodyText": "We really need to add some comments in the code. I am having a hard time following and trying to understand what it does, and I already know what it is supposed to do :-P", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r508742643", "createdAt": "2020-10-20T18:20:32Z", "author": {"login": "vpapavas"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java", "diffHunk": "@@ -265,45 +294,104 @@ void checkRateLimit() {\n     }\n   }\n \n-  private PullQueryResult handlePullQuery(\n+  @VisibleForTesting\n+  interface RouteQuery {\n+    TableRows routeQuery(\n+        KsqlNode node,\n+        ConfiguredStatement<Query> statement,\n+        KsqlExecutionContext executionContext,\n+        ServiceContext serviceContext,\n+        PullQueryContext pullQueryContext\n+    );\n+  }\n+\n+  @VisibleForTesting\n+  static PullQueryResult handlePullQuery(\n       final ConfiguredStatement<Query> statement,\n       final KsqlExecutionContext executionContext,\n       final ServiceContext serviceContext,\n-      final PullQueryContext pullQueryContext,\n-      final RoutingOptions routingOptions\n-  ) {\n-    // Get active and standby nodes for this key\n-    final Locator locator = pullQueryContext.mat.locator();\n-    final List<KsqlNode> filteredAndOrderedNodes = locator.locate(\n-        pullQueryContext.key,\n-        routingOptions,\n-        routingFilterFactory\n-    );\n-\n-    if (filteredAndOrderedNodes.isEmpty()) {\n+      final RoutingOptions routingOptions,\n+      final Function<List<KsqlLocation>, PullQueryContext> contextFactory,\n+      final QueryId queryId,\n+      final List<KsqlLocation> locations,\n+      final ExecutorService executorService,\n+      final RouteQuery routeQuery\n+  ) throws InterruptedException {\n+    final boolean anyPartitionsEmpty = locations.stream()\n+        .anyMatch(location -> location.getNodes().isEmpty());\n+    if (anyPartitionsEmpty) {\n       LOG.debug(\"Unable to execute pull query: {}. All nodes are dead or exceed max allowed lag.\",\n-                statement.getStatementText());\n+          statement.getStatementText());\n       throw new MaterializationException(String.format(\n           \"Unable to execute pull query %s. All nodes are dead or exceed max allowed lag.\",\n           statement.getStatementText()));\n     }\n \n-    // Nodes are ordered by preference: active is first if alive then standby nodes in\n-    // increasing order of lag.\n-    for (KsqlNode node : filteredAndOrderedNodes) {\n-      try {\n-        final Optional<KsqlNode> debugNode = Optional.ofNullable(\n-            routingOptions.isDebugRequest() ? node : null);\n+    final List<KsqlNode> sourceNodes = new ArrayList<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f721ccbe4f514c0499424ad7a05d58b8d9cf91a2"}, "originalPosition": 183}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTEzMDEyNTY0", "url": "https://github.com/confluentinc/ksql/pull/6409#pullrequestreview-513012564", "createdAt": "2020-10-20T18:21:31Z", "commit": {"oid": "f721ccbe4f514c0499424ad7a05d58b8d9cf91a2"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMFQxODoyMTozMlrOHlLOVw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMFQxODoyMTozMlrOHlLOVw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODc0MzI1NQ==", "bodyText": "Consider adding a more descriptive error message so that we know at which point in the code the query failed and why.", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r508743255", "createdAt": "2020-10-20T18:21:32Z", "author": {"login": "vpapavas"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java", "diffHunk": "@@ -265,45 +294,104 @@ void checkRateLimit() {\n     }\n   }\n \n-  private PullQueryResult handlePullQuery(\n+  @VisibleForTesting\n+  interface RouteQuery {\n+    TableRows routeQuery(\n+        KsqlNode node,\n+        ConfiguredStatement<Query> statement,\n+        KsqlExecutionContext executionContext,\n+        ServiceContext serviceContext,\n+        PullQueryContext pullQueryContext\n+    );\n+  }\n+\n+  @VisibleForTesting\n+  static PullQueryResult handlePullQuery(\n       final ConfiguredStatement<Query> statement,\n       final KsqlExecutionContext executionContext,\n       final ServiceContext serviceContext,\n-      final PullQueryContext pullQueryContext,\n-      final RoutingOptions routingOptions\n-  ) {\n-    // Get active and standby nodes for this key\n-    final Locator locator = pullQueryContext.mat.locator();\n-    final List<KsqlNode> filteredAndOrderedNodes = locator.locate(\n-        pullQueryContext.key,\n-        routingOptions,\n-        routingFilterFactory\n-    );\n-\n-    if (filteredAndOrderedNodes.isEmpty()) {\n+      final RoutingOptions routingOptions,\n+      final Function<List<KsqlLocation>, PullQueryContext> contextFactory,\n+      final QueryId queryId,\n+      final List<KsqlLocation> locations,\n+      final ExecutorService executorService,\n+      final RouteQuery routeQuery\n+  ) throws InterruptedException {\n+    final boolean anyPartitionsEmpty = locations.stream()\n+        .anyMatch(location -> location.getNodes().isEmpty());\n+    if (anyPartitionsEmpty) {\n       LOG.debug(\"Unable to execute pull query: {}. All nodes are dead or exceed max allowed lag.\",\n-                statement.getStatementText());\n+          statement.getStatementText());\n       throw new MaterializationException(String.format(\n           \"Unable to execute pull query %s. All nodes are dead or exceed max allowed lag.\",\n           statement.getStatementText()));\n     }\n \n-    // Nodes are ordered by preference: active is first if alive then standby nodes in\n-    // increasing order of lag.\n-    for (KsqlNode node : filteredAndOrderedNodes) {\n-      try {\n-        final Optional<KsqlNode> debugNode = Optional.ofNullable(\n-            routingOptions.isDebugRequest() ? node : null);\n+    final List<KsqlNode> sourceNodes = new ArrayList<>();\n+    final List<List<?>> tableRows = new ArrayList<>();\n+    final List<LogicalSchema> schemas = new ArrayList<>();\n+    List<KsqlLocation> remainingLocations = ImmutableList.copyOf(locations);\n+    for (int round = 0; ; round++) {\n+      final Map<KsqlNode, List<KsqlLocation>> groupedByHost\n+          = groupByHost(statement, remainingLocations, round);\n+\n+      final Map<KsqlNode, Future<PullQueryResult>> futures = new LinkedHashMap<>();\n+      for (Map.Entry<KsqlNode, List<KsqlLocation>> entry : groupedByHost.entrySet()) {\n+        final KsqlNode node = entry.getKey();\n+        final PullQueryContext pullQueryContext = contextFactory.apply(entry.getValue());\n+\n+        futures.put(node, executorService.submit(() ->  {\n+          final TableRows rows = routeQuery.routeQuery(\n+              node, statement, executionContext, serviceContext, pullQueryContext);\n+          final Optional<List<KsqlNode>> debugNodes = Optional.ofNullable(\n+              routingOptions.isDebugRequest()\n+                  ? Collections.nCopies(rows.getRows().size(), node) : null);\n+          return new PullQueryResult(rows, debugNodes);\n+        }));\n+      }\n+\n+      final ImmutableList.Builder<KsqlLocation> nextRoundRemaining = ImmutableList.builder();\n+      for (Map.Entry<KsqlNode, Future<PullQueryResult>>  entry : futures.entrySet()) {\n+        final Future<PullQueryResult> future = entry.getValue();\n+        final KsqlNode node = entry.getKey();\n+        try {\n+          final PullQueryResult result = future.get();\n+          result.getSourceNodes().ifPresent(sourceNodes::addAll);\n+          schemas.add(result.getTableRows().getSchema());\n+          tableRows.addAll(result.getTableRows().getRows());\n+        } catch (ExecutionException e) {\n+          LOG.debug(\"Error routing query {} to host {} at timestamp {} with exception {}\",\n+              statement.getStatementText(), node, System.currentTimeMillis(), e.getCause());\n+          nextRoundRemaining.addAll(groupedByHost.get(node));\n+        }\n+      }\n+      remainingLocations = nextRoundRemaining.build();\n+\n+      if (remainingLocations.size() == 0) {\n+        validateSchemas(schemas);\n         return new PullQueryResult(\n-            routeQuery(node, statement, executionContext, serviceContext, pullQueryContext),\n-            debugNode);\n-      } catch (Exception t) {\n-        LOG.debug(\"Error routing query {} to host {} at timestamp {} with exception {}\",\n-                  statement.getStatementText(), node, System.currentTimeMillis(), t);\n+            new TableRows(statement.getStatementText(), queryId, Iterables.getLast(schemas),\n+                tableRows),\n+            sourceNodes.isEmpty() ? Optional.empty() : Optional.of(sourceNodes));\n       }\n     }\n-    throw new MaterializationException(String.format(\n-        \"Unable to execute pull query: %s\", statement.getStatementText()));\n+  }\n+\n+  private static Map<KsqlNode, List<KsqlLocation>> groupByHost(\n+      final ConfiguredStatement<Query> statement,\n+      final List<KsqlLocation> locations,\n+      final int round) {\n+    final Map<KsqlNode, List<KsqlLocation>> groupedByHost = new LinkedHashMap<>();\n+    for (KsqlLocation location : locations) {\n+      // If one of the partitions required is out of nodes, then we cannot continue.\n+      if (round >= location.getNodes().size()) {\n+        throw new MaterializationException(String.format(\n+            \"Unable to execute pull query: %s\", statement.getStatementText()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f721ccbe4f514c0499424ad7a05d58b8d9cf91a2"}, "originalPosition": 249}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTEzMDQ5MTA2", "url": "https://github.com/confluentinc/ksql/pull/6409#pullrequestreview-513049106", "createdAt": "2020-10-20T19:07:11Z", "commit": {"oid": "f721ccbe4f514c0499424ad7a05d58b8d9cf91a2"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMFQxOTowNzoxMlrOHlNCJA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMFQxOTowNzoxMlrOHlNCJA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODc3MjkwMA==", "bodyText": "What this method does, is group all locations per the same host, which if round=0, will be the active. So, all locations (all keys) that have the same host as active will we grouped together. Then, in the second round, for any keys that the active failed, we will get the standby that is second in ordering.", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r508772900", "createdAt": "2020-10-20T19:07:12Z", "author": {"login": "vpapavas"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/PullQueryExecutor.java", "diffHunk": "@@ -265,45 +294,104 @@ void checkRateLimit() {\n     }\n   }\n \n-  private PullQueryResult handlePullQuery(\n+  @VisibleForTesting\n+  interface RouteQuery {\n+    TableRows routeQuery(\n+        KsqlNode node,\n+        ConfiguredStatement<Query> statement,\n+        KsqlExecutionContext executionContext,\n+        ServiceContext serviceContext,\n+        PullQueryContext pullQueryContext\n+    );\n+  }\n+\n+  @VisibleForTesting\n+  static PullQueryResult handlePullQuery(\n       final ConfiguredStatement<Query> statement,\n       final KsqlExecutionContext executionContext,\n       final ServiceContext serviceContext,\n-      final PullQueryContext pullQueryContext,\n-      final RoutingOptions routingOptions\n-  ) {\n-    // Get active and standby nodes for this key\n-    final Locator locator = pullQueryContext.mat.locator();\n-    final List<KsqlNode> filteredAndOrderedNodes = locator.locate(\n-        pullQueryContext.key,\n-        routingOptions,\n-        routingFilterFactory\n-    );\n-\n-    if (filteredAndOrderedNodes.isEmpty()) {\n+      final RoutingOptions routingOptions,\n+      final Function<List<KsqlLocation>, PullQueryContext> contextFactory,\n+      final QueryId queryId,\n+      final List<KsqlLocation> locations,\n+      final ExecutorService executorService,\n+      final RouteQuery routeQuery\n+  ) throws InterruptedException {\n+    final boolean anyPartitionsEmpty = locations.stream()\n+        .anyMatch(location -> location.getNodes().isEmpty());\n+    if (anyPartitionsEmpty) {\n       LOG.debug(\"Unable to execute pull query: {}. All nodes are dead or exceed max allowed lag.\",\n-                statement.getStatementText());\n+          statement.getStatementText());\n       throw new MaterializationException(String.format(\n           \"Unable to execute pull query %s. All nodes are dead or exceed max allowed lag.\",\n           statement.getStatementText()));\n     }\n \n-    // Nodes are ordered by preference: active is first if alive then standby nodes in\n-    // increasing order of lag.\n-    for (KsqlNode node : filteredAndOrderedNodes) {\n-      try {\n-        final Optional<KsqlNode> debugNode = Optional.ofNullable(\n-            routingOptions.isDebugRequest() ? node : null);\n+    final List<KsqlNode> sourceNodes = new ArrayList<>();\n+    final List<List<?>> tableRows = new ArrayList<>();\n+    final List<LogicalSchema> schemas = new ArrayList<>();\n+    List<KsqlLocation> remainingLocations = ImmutableList.copyOf(locations);\n+    for (int round = 0; ; round++) {\n+      final Map<KsqlNode, List<KsqlLocation>> groupedByHost\n+          = groupByHost(statement, remainingLocations, round);\n+\n+      final Map<KsqlNode, Future<PullQueryResult>> futures = new LinkedHashMap<>();\n+      for (Map.Entry<KsqlNode, List<KsqlLocation>> entry : groupedByHost.entrySet()) {\n+        final KsqlNode node = entry.getKey();\n+        final PullQueryContext pullQueryContext = contextFactory.apply(entry.getValue());\n+\n+        futures.put(node, executorService.submit(() ->  {\n+          final TableRows rows = routeQuery.routeQuery(\n+              node, statement, executionContext, serviceContext, pullQueryContext);\n+          final Optional<List<KsqlNode>> debugNodes = Optional.ofNullable(\n+              routingOptions.isDebugRequest()\n+                  ? Collections.nCopies(rows.getRows().size(), node) : null);\n+          return new PullQueryResult(rows, debugNodes);\n+        }));\n+      }\n+\n+      final ImmutableList.Builder<KsqlLocation> nextRoundRemaining = ImmutableList.builder();\n+      for (Map.Entry<KsqlNode, Future<PullQueryResult>>  entry : futures.entrySet()) {\n+        final Future<PullQueryResult> future = entry.getValue();\n+        final KsqlNode node = entry.getKey();\n+        try {\n+          final PullQueryResult result = future.get();\n+          result.getSourceNodes().ifPresent(sourceNodes::addAll);\n+          schemas.add(result.getTableRows().getSchema());\n+          tableRows.addAll(result.getTableRows().getRows());\n+        } catch (ExecutionException e) {\n+          LOG.debug(\"Error routing query {} to host {} at timestamp {} with exception {}\",\n+              statement.getStatementText(), node, System.currentTimeMillis(), e.getCause());\n+          nextRoundRemaining.addAll(groupedByHost.get(node));\n+        }\n+      }\n+      remainingLocations = nextRoundRemaining.build();\n+\n+      if (remainingLocations.size() == 0) {\n+        validateSchemas(schemas);\n         return new PullQueryResult(\n-            routeQuery(node, statement, executionContext, serviceContext, pullQueryContext),\n-            debugNode);\n-      } catch (Exception t) {\n-        LOG.debug(\"Error routing query {} to host {} at timestamp {} with exception {}\",\n-                  statement.getStatementText(), node, System.currentTimeMillis(), t);\n+            new TableRows(statement.getStatementText(), queryId, Iterables.getLast(schemas),\n+                tableRows),\n+            sourceNodes.isEmpty() ? Optional.empty() : Optional.of(sourceNodes));\n       }\n     }\n-    throw new MaterializationException(String.format(\n-        \"Unable to execute pull query: %s\", statement.getStatementText()));\n+  }\n+\n+  private static Map<KsqlNode, List<KsqlLocation>> groupByHost(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f721ccbe4f514c0499424ad7a05d58b8d9cf91a2"}, "originalPosition": 240}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTEzMDcyMjY3", "url": "https://github.com/confluentinc/ksql/pull/6409#pullrequestreview-513072267", "createdAt": "2020-10-20T19:40:46Z", "commit": {"oid": "f721ccbe4f514c0499424ad7a05d58b8d9cf91a2"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMFQxOTo0MDo0NlrOHlOJQg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMFQxOTo0MDo0NlrOHlOJQg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODc5MTEwNg==", "bodyText": "Why do you need to know the partitions here? Is it because you don't know which partitions are active and which standbys? If so, we can get this information with KafkaStreams.allMetadata().  If we know what each partition is, then for a forwarded request, we know we need to access the standby partitions whereas for a non-forwarded only the active ones. This could avoid sending the partitions over the network causing overhead.", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r508791106", "createdAt": "2020-10-20T19:40:46Z", "author": {"login": "vpapavas"}, "path": "ksqldb-streams/src/main/java/io/confluent/ksql/execution/streams/materialization/ks/KsLocator.java", "diffHunk": "@@ -68,28 +73,64 @@\n   }\n \n   @Override\n-  public List<KsqlNode> locate(\n-      final Struct key,\n+  public List<KsqlLocation> locate(\n+      final List<Struct> keys,\n       final RoutingOptions routingOptions,\n       final RoutingFilterFactory routingFilterFactory\n   ) {\n-    final KeyQueryMetadata metadata = kafkaStreams\n-        .queryMetadataForKey(stateStoreName, key, keySerializer);\n-\n-    // Fail fast if Streams not ready. Let client handle it\n-    if (metadata == KeyQueryMetadata.NOT_AVAILABLE) {\n-      LOG.debug(\"KeyQueryMetadata not available for state store {} and key {}\",\n-                stateStoreName, key);\n-      throw new MaterializationException(String.format(\n-          \"KeyQueryMetadata not available for state store %s and key %s\", stateStoreName, key));\n-    }\n+    // Maintain request order for reproducibility by using a LinkedHashMap, even though it's\n+    // not a guarantee of the API.\n+    final Map<Integer, List<KsqlNode>> locationsByPartition = new LinkedHashMap<>();\n+    final Map<Integer, Set<Struct>> keysByPartition = new HashMap<>();\n+    final Set<Integer> filterPartitions = routingOptions.getPartitions();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f721ccbe4f514c0499424ad7a05d58b8d9cf91a2"}, "originalPosition": 39}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTEzMDgzMzU2", "url": "https://github.com/confluentinc/ksql/pull/6409#pullrequestreview-513083356", "createdAt": "2020-10-20T19:56:25Z", "commit": {"oid": "f721ccbe4f514c0499424ad7a05d58b8d9cf91a2"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMFQxOTo1NjoyNlrOHlOr6g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMFQxOTo1NjoyNlrOHlOr6g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwODc5OTk3OA==", "bodyText": "Can we make this loop cheaper for forwarded requests if we do send the partitions in the request?", "url": "https://github.com/confluentinc/ksql/pull/6409#discussion_r508799978", "createdAt": "2020-10-20T19:56:26Z", "author": {"login": "vpapavas"}, "path": "ksqldb-streams/src/main/java/io/confluent/ksql/execution/streams/materialization/ks/KsLocator.java", "diffHunk": "@@ -68,28 +73,64 @@\n   }\n \n   @Override\n-  public List<KsqlNode> locate(\n-      final Struct key,\n+  public List<KsqlLocation> locate(\n+      final List<Struct> keys,\n       final RoutingOptions routingOptions,\n       final RoutingFilterFactory routingFilterFactory\n   ) {\n-    final KeyQueryMetadata metadata = kafkaStreams\n-        .queryMetadataForKey(stateStoreName, key, keySerializer);\n-\n-    // Fail fast if Streams not ready. Let client handle it\n-    if (metadata == KeyQueryMetadata.NOT_AVAILABLE) {\n-      LOG.debug(\"KeyQueryMetadata not available for state store {} and key {}\",\n-                stateStoreName, key);\n-      throw new MaterializationException(String.format(\n-          \"KeyQueryMetadata not available for state store %s and key %s\", stateStoreName, key));\n-    }\n+    // Maintain request order for reproducibility by using a LinkedHashMap, even though it's\n+    // not a guarantee of the API.\n+    final Map<Integer, List<KsqlNode>> locationsByPartition = new LinkedHashMap<>();\n+    final Map<Integer, Set<Struct>> keysByPartition = new HashMap<>();\n+    final Set<Integer> filterPartitions = routingOptions.getPartitions();\n+    for (Struct key : keys) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f721ccbe4f514c0499424ad7a05d58b8d9cf91a2"}, "originalPosition": 40}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "09a06dd90822b7aa3cf52550fddb5240df513111", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/09a06dd90822b7aa3cf52550fddb5240df513111", "committedDate": "2020-10-20T23:10:25Z", "message": "Adds Comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d59cdfbc39aa1314995eeeaf5503c9f66dd04158", "author": {"user": {"login": "AlanConfluent", "name": "Alan Sheinberg"}}, "url": "https://github.com/confluentinc/ksql/commit/d59cdfbc39aa1314995eeeaf5503c9f66dd04158", "committedDate": "2020-10-21T20:45:08Z", "message": "Renames KsqlLocation to KsqlPartitionLocation"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE0MjA4OTY2", "url": "https://github.com/confluentinc/ksql/pull/6409#pullrequestreview-514208966", "createdAt": "2020-10-21T21:44:12Z", "commit": {"oid": "d59cdfbc39aa1314995eeeaf5503c9f66dd04158"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4629, "cost": 1, "resetAt": "2021-11-01T13:51:04Z"}}}