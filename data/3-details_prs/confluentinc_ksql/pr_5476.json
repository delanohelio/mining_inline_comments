{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDIyOTE3NTMw", "number": 5476, "title": "feat: Add consumer offsets to DESCRIBE EXTENDED", "bodyText": "Description\nFix #3604\nTesting done\n\nUnit tests covering new options, with consumer offsets\n\nReviewer checklist\n\n Ensure docs are updated if necessary. (eg. if a user visible feature is being added or changed).\n Ensure relevant issues are linked (description should include text like \"Fixes #\")\n\nMissing functionality\n\n Get groupId from Source\n Set timeout for Kafka Admin operations", "createdAt": "2020-05-25T22:52:33Z", "url": "https://github.com/confluentinc/ksql/pull/5476", "merged": true, "mergeCommit": {"oid": "9ce3c9746d21d544e6d39dde4c2b6932d738a5e0"}, "closed": true, "closedAt": "2020-08-07T14:22:43Z", "author": {"login": "jeqo"}, "timelineItems": {"totalCount": 82, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABclLKAfABqjMzNzUzOTk5NDg=", "endCursor": "Y3Vyc29yOnYyOpPPAAABc8jxAygH2gAyNDIyOTE3NTMwOmNhMDA3ZGE5OWMwYzc4N2EzNDYxNTRhNWM3ZjliNDc0Y2NhMWMxNjM=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "31548ac70a992297d2ee629b08989f3fc52c9610", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/31548ac70a992297d2ee629b08989f3fc52c9610", "committedDate": "2020-05-26T20:47:58Z", "message": "add unit tests"}, "afterCommit": {"oid": "257c4d061db59030377aec97793cc6389efa935c", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/257c4d061db59030377aec97793cc6389efa935c", "committedDate": "2020-05-26T21:00:58Z", "message": "add unit tests"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4NjkxMDM5", "url": "https://github.com/confluentinc/ksql/pull/5476#pullrequestreview-418691039", "createdAt": "2020-05-26T21:26:06Z", "commit": {"oid": "257c4d061db59030377aec97793cc6389efa935c"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQyMToyNjowNlrOGaw42w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQyMToyOTo1MFrOGaw_fA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcxNzE0Nw==", "bodyText": "This is the only naive way I've found so far to get the consumer group id. Would love some feedback on how to get this in a proper/better way.", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r430717147", "createdAt": "2020-05-26T21:26:06Z", "author": {"login": "jeqo"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListSourceExecutor.java", "diffHunk": "@@ -191,14 +200,42 @@ private static SourceDescriptionWithWarnings describeSource(\n       ), statementText);\n     }\n \n+    List<RunningQuery> sourceQueries = getQueries(ksqlEngine,\n+        q -> q.getSourceNames().contains(dataSource.getName()));\n+    List<RunningQuery> sinkQueries = getQueries(ksqlEngine,\n+        q -> q.getSinkName().equals(dataSource.getName()));\n+\n     Optional<org.apache.kafka.clients.admin.TopicDescription> topicDescription = Optional.empty();\n+    Optional<ConsumerGroupDescription> consumerGroupDescription = Optional.empty();\n+    Map<TopicPartition, OffsetAndMetadata> topicAndConsumerOffsets = new LinkedHashMap<>();\n+    Map<TopicPartition, ListOffsetsResultInfo> topicAndStartOffsets = new LinkedHashMap<>();\n+    Map<TopicPartition, ListOffsetsResultInfo> topicAndEndOffsets = new LinkedHashMap<>();\n     final List<KsqlWarning> warnings = new LinkedList<>();\n     if (extended) {\n       try {\n         topicDescription = Optional.of(\n             serviceContext.getTopicClient().describeTopic(dataSource.getKafkaTopicName())\n         );\n-      } catch (final KafkaException | KafkaResponseGetFailedException e) {\n+        String serviceId = \"default\"; //FIXME not sure how to get this\n+        if (sourceQueries.isEmpty()){\n+          consumerGroupDescription = Optional.empty();\n+        } else {\n+          String queryId = sourceQueries.get(0).getId().toString();\n+          String consumerGroupId = \"_confluent-ksql-\" + serviceId + \"_\" + KsqlConfig.KSQL_PERSISTENT_QUERY_NAME_PREFIX_DEFAULT + queryId; //FIXME there should be a better way to build this", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "257c4d061db59030377aec97793cc6389efa935c"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcxNzUxOA==", "bodyText": "Would be possible to get more than one source query?", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r430717518", "createdAt": "2020-05-26T21:26:58Z", "author": {"login": "jeqo"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListSourceExecutor.java", "diffHunk": "@@ -191,14 +200,42 @@ private static SourceDescriptionWithWarnings describeSource(\n       ), statementText);\n     }\n \n+    List<RunningQuery> sourceQueries = getQueries(ksqlEngine,\n+        q -> q.getSourceNames().contains(dataSource.getName()));\n+    List<RunningQuery> sinkQueries = getQueries(ksqlEngine,\n+        q -> q.getSinkName().equals(dataSource.getName()));\n+\n     Optional<org.apache.kafka.clients.admin.TopicDescription> topicDescription = Optional.empty();\n+    Optional<ConsumerGroupDescription> consumerGroupDescription = Optional.empty();\n+    Map<TopicPartition, OffsetAndMetadata> topicAndConsumerOffsets = new LinkedHashMap<>();\n+    Map<TopicPartition, ListOffsetsResultInfo> topicAndStartOffsets = new LinkedHashMap<>();\n+    Map<TopicPartition, ListOffsetsResultInfo> topicAndEndOffsets = new LinkedHashMap<>();\n     final List<KsqlWarning> warnings = new LinkedList<>();\n     if (extended) {\n       try {\n         topicDescription = Optional.of(\n             serviceContext.getTopicClient().describeTopic(dataSource.getKafkaTopicName())\n         );\n-      } catch (final KafkaException | KafkaResponseGetFailedException e) {\n+        String serviceId = \"default\"; //FIXME not sure how to get this\n+        if (sourceQueries.isEmpty()){\n+          consumerGroupDescription = Optional.empty();\n+        } else {\n+          String queryId = sourceQueries.get(0).getId().toString();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "257c4d061db59030377aec97793cc6389efa935c"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcxODU3Nw==", "bodyText": "Currently using blocking get(). Probably should use a timeout, just not sure what's the best way to pass through the value from config or somewhere else", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r430718577", "createdAt": "2020-05-26T21:29:13Z", "author": {"login": "jeqo"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListSourceExecutor.java", "diffHunk": "@@ -191,14 +200,42 @@ private static SourceDescriptionWithWarnings describeSource(\n       ), statementText);\n     }\n \n+    List<RunningQuery> sourceQueries = getQueries(ksqlEngine,\n+        q -> q.getSourceNames().contains(dataSource.getName()));\n+    List<RunningQuery> sinkQueries = getQueries(ksqlEngine,\n+        q -> q.getSinkName().equals(dataSource.getName()));\n+\n     Optional<org.apache.kafka.clients.admin.TopicDescription> topicDescription = Optional.empty();\n+    Optional<ConsumerGroupDescription> consumerGroupDescription = Optional.empty();\n+    Map<TopicPartition, OffsetAndMetadata> topicAndConsumerOffsets = new LinkedHashMap<>();\n+    Map<TopicPartition, ListOffsetsResultInfo> topicAndStartOffsets = new LinkedHashMap<>();\n+    Map<TopicPartition, ListOffsetsResultInfo> topicAndEndOffsets = new LinkedHashMap<>();\n     final List<KsqlWarning> warnings = new LinkedList<>();\n     if (extended) {\n       try {\n         topicDescription = Optional.of(\n             serviceContext.getTopicClient().describeTopic(dataSource.getKafkaTopicName())\n         );\n-      } catch (final KafkaException | KafkaResponseGetFailedException e) {\n+        String serviceId = \"default\"; //FIXME not sure how to get this\n+        if (sourceQueries.isEmpty()){\n+          consumerGroupDescription = Optional.empty();\n+        } else {\n+          String queryId = sourceQueries.get(0).getId().toString();\n+          String consumerGroupId = \"_confluent-ksql-\" + serviceId + \"_\" + KsqlConfig.KSQL_PERSISTENT_QUERY_NAME_PREFIX_DEFAULT + queryId; //FIXME there should be a better way to build this\n+          consumerGroupDescription = Optional.of(\n+              serviceContext.getAdminClient().describeConsumerGroups(Collections.singletonList(consumerGroupId)).describedGroups().get(consumerGroupId).get()\n+          );\n+          topicAndConsumerOffsets = serviceContext.getAdminClient().listConsumerGroupOffsets(consumerGroupId).partitionsToOffsetAndMetadata().get();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "257c4d061db59030377aec97793cc6389efa935c"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcxODg0NA==", "bodyText": "Not sure how to get this from config.", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r430718844", "createdAt": "2020-05-26T21:29:50Z", "author": {"login": "jeqo"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListSourceExecutor.java", "diffHunk": "@@ -191,14 +200,42 @@ private static SourceDescriptionWithWarnings describeSource(\n       ), statementText);\n     }\n \n+    List<RunningQuery> sourceQueries = getQueries(ksqlEngine,\n+        q -> q.getSourceNames().contains(dataSource.getName()));\n+    List<RunningQuery> sinkQueries = getQueries(ksqlEngine,\n+        q -> q.getSinkName().equals(dataSource.getName()));\n+\n     Optional<org.apache.kafka.clients.admin.TopicDescription> topicDescription = Optional.empty();\n+    Optional<ConsumerGroupDescription> consumerGroupDescription = Optional.empty();\n+    Map<TopicPartition, OffsetAndMetadata> topicAndConsumerOffsets = new LinkedHashMap<>();\n+    Map<TopicPartition, ListOffsetsResultInfo> topicAndStartOffsets = new LinkedHashMap<>();\n+    Map<TopicPartition, ListOffsetsResultInfo> topicAndEndOffsets = new LinkedHashMap<>();\n     final List<KsqlWarning> warnings = new LinkedList<>();\n     if (extended) {\n       try {\n         topicDescription = Optional.of(\n             serviceContext.getTopicClient().describeTopic(dataSource.getKafkaTopicName())\n         );\n-      } catch (final KafkaException | KafkaResponseGetFailedException e) {\n+        String serviceId = \"default\"; //FIXME not sure how to get this", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "257c4d061db59030377aec97793cc6389efa935c"}, "originalPosition": 47}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIxMjY3MzMy", "url": "https://github.com/confluentinc/ksql/pull/5476#pullrequestreview-421267332", "createdAt": "2020-05-29T20:28:53Z", "commit": {"oid": "257c4d061db59030377aec97793cc6389efa935c"}, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQyMDoyODo1NFrOGcrHlw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQyMDo0MzoyM1rOGcrfFg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjcxOTc2Nw==", "bodyText": "nit: our checkstyle should enforce some things like local variables being final whenever possible, you can run mvn checkstyle:checkstyle to make sure that your code passes all checkstyle checks", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r432719767", "createdAt": "2020-05-29T20:28:54Z", "author": {"login": "agavra"}, "path": "ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java", "diffHunk": "@@ -618,6 +619,27 @@ private void printSourceDescription(final SourceDescription source) {\n         \"Statistics of the local KSQL server interaction with the Kafka topic \"\n             + source.getTopic()\n     ));\n+    Optional<SourceConsumerOffsets> consumerGroupOffsetsOptional = source.getConsumerGroupOffsets();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "257c4d061db59030377aec97793cc6389efa935c"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjcyMTQ1Ng==", "bodyText": "we should not be passing the real admin client to the sandbox - otherwise it becomes possible for the sandbox to make real changes to the kafka cluster. I recommend instead following the pattern of the above Sandboxes and create a proxy that proxies the admin client for read-only commands.\nBetter yet, I think it might make sense to bake this into the KafkaTopicClient, which already has an api for describeTopic", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r432721456", "createdAt": "2020-05-29T20:32:57Z", "author": {"login": "agavra"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/services/SandboxedServiceContext.java", "diffHunk": "@@ -46,29 +48,33 @@ public static SandboxedServiceContext create(final ServiceContext serviceContext\n     final SchemaRegistryClient schemaRegistryClient =\n         SandboxedSchemaRegistryClient.createProxy(serviceContext.getSchemaRegistryClient());\n     final ConnectClient connectClient = SandboxConnectClient.createProxy();\n+    final Admin adminClient = serviceContext.getAdminClient();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "257c4d061db59030377aec97793cc6389efa935c"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjcyMjI4NQ==", "bodyText": "I think it would make sense to encapsulate all of this into a single class and have one Map<TopicPartition, SourceConsumerOffsets>", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r432722285", "createdAt": "2020-05-29T20:35:01Z", "author": {"login": "agavra"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/entity/SourceDescriptionFactory.java", "diffHunk": "@@ -34,7 +41,11 @@ public static SourceDescription create(\n       final boolean extended,\n       final List<RunningQuery> readQueries,\n       final List<RunningQuery> writeQueries,\n-      final Optional<TopicDescription> topicDescription\n+      final Optional<TopicDescription> topicDescription,\n+      final Optional<ConsumerGroupDescription> consumerGroupDescription,\n+      final Map<TopicPartition, ListOffsetsResultInfo> topicAndStartOffsets,\n+      final Map<TopicPartition, ListOffsetsResultInfo> topicAndEndOffsets,\n+      final Map<TopicPartition, OffsetAndMetadata> topicAndConsumerOffsets", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "257c4d061db59030377aec97793cc6389efa935c"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjcyMzU1Nw==", "bodyText": "I think you're looking for KsqlConfig.KSQL_SERVICE_ID_CONFIG the config is availabile in the ConfigureStatement class", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r432723557", "createdAt": "2020-05-29T20:38:02Z", "author": {"login": "agavra"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListSourceExecutor.java", "diffHunk": "@@ -191,14 +200,42 @@ private static SourceDescriptionWithWarnings describeSource(\n       ), statementText);\n     }\n \n+    List<RunningQuery> sourceQueries = getQueries(ksqlEngine,\n+        q -> q.getSourceNames().contains(dataSource.getName()));\n+    List<RunningQuery> sinkQueries = getQueries(ksqlEngine,\n+        q -> q.getSinkName().equals(dataSource.getName()));\n+\n     Optional<org.apache.kafka.clients.admin.TopicDescription> topicDescription = Optional.empty();\n+    Optional<ConsumerGroupDescription> consumerGroupDescription = Optional.empty();\n+    Map<TopicPartition, OffsetAndMetadata> topicAndConsumerOffsets = new LinkedHashMap<>();\n+    Map<TopicPartition, ListOffsetsResultInfo> topicAndStartOffsets = new LinkedHashMap<>();\n+    Map<TopicPartition, ListOffsetsResultInfo> topicAndEndOffsets = new LinkedHashMap<>();\n     final List<KsqlWarning> warnings = new LinkedList<>();\n     if (extended) {\n       try {\n         topicDescription = Optional.of(\n             serviceContext.getTopicClient().describeTopic(dataSource.getKafkaTopicName())\n         );\n-      } catch (final KafkaException | KafkaResponseGetFailedException e) {\n+        String serviceId = \"default\"; //FIXME not sure how to get this", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcxODg0NA=="}, "originalCommit": {"oid": "257c4d061db59030377aec97793cc6389efa935c"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjcyMzg3MA==", "bodyText": "yes, this is in the case of a JOIN you could possibly have more than one source query - it would be good to test a JOIN scenario end to end", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r432723870", "createdAt": "2020-05-29T20:38:52Z", "author": {"login": "agavra"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListSourceExecutor.java", "diffHunk": "@@ -191,14 +200,42 @@ private static SourceDescriptionWithWarnings describeSource(\n       ), statementText);\n     }\n \n+    List<RunningQuery> sourceQueries = getQueries(ksqlEngine,\n+        q -> q.getSourceNames().contains(dataSource.getName()));\n+    List<RunningQuery> sinkQueries = getQueries(ksqlEngine,\n+        q -> q.getSinkName().equals(dataSource.getName()));\n+\n     Optional<org.apache.kafka.clients.admin.TopicDescription> topicDescription = Optional.empty();\n+    Optional<ConsumerGroupDescription> consumerGroupDescription = Optional.empty();\n+    Map<TopicPartition, OffsetAndMetadata> topicAndConsumerOffsets = new LinkedHashMap<>();\n+    Map<TopicPartition, ListOffsetsResultInfo> topicAndStartOffsets = new LinkedHashMap<>();\n+    Map<TopicPartition, ListOffsetsResultInfo> topicAndEndOffsets = new LinkedHashMap<>();\n     final List<KsqlWarning> warnings = new LinkedList<>();\n     if (extended) {\n       try {\n         topicDescription = Optional.of(\n             serviceContext.getTopicClient().describeTopic(dataSource.getKafkaTopicName())\n         );\n-      } catch (final KafkaException | KafkaResponseGetFailedException e) {\n+        String serviceId = \"default\"; //FIXME not sure how to get this\n+        if (sourceQueries.isEmpty()){\n+          consumerGroupDescription = Optional.empty();\n+        } else {\n+          String queryId = sourceQueries.get(0).getId().toString();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcxNzUxOA=="}, "originalCommit": {"oid": "257c4d061db59030377aec97793cc6389efa935c"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjcyNTMxNw==", "bodyText": "I think this is the same as StreamsConfig.APPLICATION_ID_CONFIG in the QueryMetadata.getStreamsProperties, but I'd need to double check that", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r432725317", "createdAt": "2020-05-29T20:42:20Z", "author": {"login": "agavra"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListSourceExecutor.java", "diffHunk": "@@ -191,14 +200,42 @@ private static SourceDescriptionWithWarnings describeSource(\n       ), statementText);\n     }\n \n+    List<RunningQuery> sourceQueries = getQueries(ksqlEngine,\n+        q -> q.getSourceNames().contains(dataSource.getName()));\n+    List<RunningQuery> sinkQueries = getQueries(ksqlEngine,\n+        q -> q.getSinkName().equals(dataSource.getName()));\n+\n     Optional<org.apache.kafka.clients.admin.TopicDescription> topicDescription = Optional.empty();\n+    Optional<ConsumerGroupDescription> consumerGroupDescription = Optional.empty();\n+    Map<TopicPartition, OffsetAndMetadata> topicAndConsumerOffsets = new LinkedHashMap<>();\n+    Map<TopicPartition, ListOffsetsResultInfo> topicAndStartOffsets = new LinkedHashMap<>();\n+    Map<TopicPartition, ListOffsetsResultInfo> topicAndEndOffsets = new LinkedHashMap<>();\n     final List<KsqlWarning> warnings = new LinkedList<>();\n     if (extended) {\n       try {\n         topicDescription = Optional.of(\n             serviceContext.getTopicClient().describeTopic(dataSource.getKafkaTopicName())\n         );\n-      } catch (final KafkaException | KafkaResponseGetFailedException e) {\n+        String serviceId = \"default\"; //FIXME not sure how to get this\n+        if (sourceQueries.isEmpty()){\n+          consumerGroupDescription = Optional.empty();\n+        } else {\n+          String queryId = sourceQueries.get(0).getId().toString();\n+          String consumerGroupId = \"_confluent-ksql-\" + serviceId + \"_\" + KsqlConfig.KSQL_PERSISTENT_QUERY_NAME_PREFIX_DEFAULT + queryId; //FIXME there should be a better way to build this", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDcxNzE0Nw=="}, "originalCommit": {"oid": "257c4d061db59030377aec97793cc6389efa935c"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjcyNTc4Mg==", "bodyText": "as mentioned above, it would be nice to encapsulate this into the KafkaTopicClient (I think, I'm not 100% sure anymore - cc @big-andy-coates for his thoughts on this one)", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r432725782", "createdAt": "2020-05-29T20:43:23Z", "author": {"login": "agavra"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListSourceExecutor.java", "diffHunk": "@@ -191,14 +200,42 @@ private static SourceDescriptionWithWarnings describeSource(\n       ), statementText);\n     }\n \n+    List<RunningQuery> sourceQueries = getQueries(ksqlEngine,\n+        q -> q.getSourceNames().contains(dataSource.getName()));\n+    List<RunningQuery> sinkQueries = getQueries(ksqlEngine,\n+        q -> q.getSinkName().equals(dataSource.getName()));\n+\n     Optional<org.apache.kafka.clients.admin.TopicDescription> topicDescription = Optional.empty();\n+    Optional<ConsumerGroupDescription> consumerGroupDescription = Optional.empty();\n+    Map<TopicPartition, OffsetAndMetadata> topicAndConsumerOffsets = new LinkedHashMap<>();\n+    Map<TopicPartition, ListOffsetsResultInfo> topicAndStartOffsets = new LinkedHashMap<>();\n+    Map<TopicPartition, ListOffsetsResultInfo> topicAndEndOffsets = new LinkedHashMap<>();\n     final List<KsqlWarning> warnings = new LinkedList<>();\n     if (extended) {\n       try {\n         topicDescription = Optional.of(\n             serviceContext.getTopicClient().describeTopic(dataSource.getKafkaTopicName())\n         );\n-      } catch (final KafkaException | KafkaResponseGetFailedException e) {\n+        String serviceId = \"default\"; //FIXME not sure how to get this\n+        if (sourceQueries.isEmpty()){\n+          consumerGroupDescription = Optional.empty();\n+        } else {\n+          String queryId = sourceQueries.get(0).getId().toString();\n+          String consumerGroupId = \"_confluent-ksql-\" + serviceId + \"_\" + KsqlConfig.KSQL_PERSISTENT_QUERY_NAME_PREFIX_DEFAULT + queryId; //FIXME there should be a better way to build this\n+          consumerGroupDescription = Optional.of(\n+              serviceContext.getAdminClient().describeConsumerGroups(Collections.singletonList(consumerGroupId)).describedGroups().get(consumerGroupId).get()\n+          );\n+          topicAndConsumerOffsets = serviceContext.getAdminClient().listConsumerGroupOffsets(consumerGroupId).partitionsToOffsetAndMetadata().get();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "257c4d061db59030377aec97793cc6389efa935c"}, "originalPosition": 56}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "257c4d061db59030377aec97793cc6389efa935c", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/257c4d061db59030377aec97793cc6389efa935c", "committedDate": "2020-05-26T21:00:58Z", "message": "add unit tests"}, "afterCommit": {"oid": "457a5f6146ba64aebfb1865a9a936736b633f29d", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/457a5f6146ba64aebfb1865a9a936736b633f29d", "committedDate": "2020-06-01T21:55:20Z", "message": "add unit tests"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d4845b4e85f813c94fd63394e373d3bac36e1a13", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/d4845b4e85f813c94fd63394e373d3bac36e1a13", "committedDate": "2020-06-02T08:34:50Z", "message": "fix: checkstyle"}, "afterCommit": {"oid": "14eb7a77ae6b46159c8f8516ed14c923e4a5f38d", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/14eb7a77ae6b46159c8f8516ed14c923e4a5f38d", "committedDate": "2020-06-03T22:03:32Z", "message": "fix: checkstyle"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDI1NDg2MTg3", "url": "https://github.com/confluentinc/ksql/pull/5476#pullrequestreview-425486187", "createdAt": "2020-06-05T17:24:10Z", "commit": {"oid": "46263e21f6feb7f38dc7e745de1fc9c9c7079e3a"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQxNzoyNDoxMFrOGf28Fw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQxNzozODoyOFrOGjMZdg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA1OTE1OQ==", "bodyText": "what was the motivation behind passing in a supplier? It looks like we open ourselves to accidentally creating a new admin client each time we make any describe/list request, which could potentially be expensive (I'm not sure how it manages handshakes/connection management with the Kafka broker)\nin most places, it looks like we're just passing in () -> adminClient anyway - but there are a few places we aren't. would be good to audit and understand if this is necessary", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r436059159", "createdAt": "2020-06-05T17:24:10Z", "author": {"login": "agavra"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/services/KafkaConsumerGroupClientImpl.java", "diffHunk": "@@ -52,7 +56,10 @@ public ConsumerGroupSummary describeConsumerGroup(final String group) {\n     try {\n       final Map<String, ConsumerGroupDescription> groups = ExecutorUtil\n           .executeWithRetries(\n-              () -> adminClient.describeConsumerGroups(Collections.singleton(group)).all().get(),\n+              () -> adminClient.get()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46263e21f6feb7f38dc7e745de1fc9c9c7079e3a"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA2MDIzNA==", "bodyText": "nit: any reason we need a LinkedHashMap? is ordering important?", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r436060234", "createdAt": "2020-06-05T17:26:23Z", "author": {"login": "agavra"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/services/KafkaTopicClientImpl.java", "diffHunk": "@@ -311,6 +316,27 @@ public void deleteInternalTopics(final String applicationId) {\n     }\n   }\n \n+  @Override\n+  public Map<TopicPartition, ListOffsetsResultInfo> listTopicOffsets(\n+      final String topicName,\n+      final OffsetSpec offsetSpec\n+  ) {\n+    final TopicDescription topicDescription = describeTopic(topicName);\n+    final Map<TopicPartition, OffsetSpec> offsetsRequest = new LinkedHashMap<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46263e21f6feb7f38dc7e745de1fc9c9c7079e3a"}, "originalPosition": 73}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA5OTAwNA==", "bodyText": "A single source can have multiple read-from and write-to queries:\nQueries that read from this STREAM\n-----------------------------------\nCSAS_BAZ_7 (RUNNING) : CREATE STREAM BAZ WITH (KAFKA_TOPIC='BAZ', PARTITIONS=1, REPLICAS=1) AS SELECT * FROM FOO FOO INNER JOIN BAR BAR WITHIN 10 SECONDS ON ((FOO.ID = BAR.ID)) EMIT CHANGES;\nINSERTQUERY_0 (RUNNING) : INSERT INTO foo SELECT * FROM bar;\n\nFor query topology and execution plan please run: EXPLAIN <QueryId>\n\nQueries that write from this STREAM\n-----------------------------------\nINSERTQUERY_9 (RUNNING) : INSERT INTO bar SELECT * FROM foo;\nINSERTQUERY_13 (RUNNING) : INSERT INTO bar SELECT id from bob;\nBasically you can have insert into statements running left and right. In this case, there will be different consumer IDs fro each of the queries.", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r436099004", "createdAt": "2020-06-05T18:37:54Z", "author": {"login": "agavra"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListSourceExecutor.java", "diffHunk": "@@ -191,13 +210,49 @@ private static SourceDescriptionWithWarnings describeSource(\n       ), statementText);\n     }\n \n-    Optional<org.apache.kafka.clients.admin.TopicDescription> topicDescription = Optional.empty();\n+    final List<RunningQuery> sourceQueries = getQueries(ksqlEngine,\n+        q -> q.getSourceNames().contains(dataSource.getName()));\n+    final List<RunningQuery> sinkQueries = getQueries(ksqlEngine,\n+        q -> q.getSinkName().equals(dataSource.getName()));\n+\n+    Optional<org.apache.kafka.clients.admin.TopicDescription> topicDescriptionOptional = Optional\n+        .empty();\n+    Optional<SourceConsumerGroupOffsets> sourceConsumerOffsets = Optional.empty();\n     final List<KsqlWarning> warnings = new LinkedList<>();\n     if (extended) {\n       try {\n-        topicDescription = Optional.of(\n-            serviceContext.getTopicClient().describeTopic(dataSource.getKafkaTopicName())\n-        );\n+        final String kafkaTopicName = dataSource.getKafkaTopicName();\n+        final TopicDescription topicDescription = serviceContext.getTopicClient()\n+            .describeTopic(kafkaTopicName);\n+        topicDescriptionOptional = Optional.of(topicDescription);\n+        if (!sourceQueries.isEmpty()) {\n+          final QueryId queryId = sourceQueries.get(0).getId();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46263e21f6feb7f38dc7e745de1fc9c9c7079e3a"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTU1NDQ4Nw==", "bodyText": "when will these be null and is 0 a good default?", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r439554487", "createdAt": "2020-06-12T17:34:07Z", "author": {"login": "agavra"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListSourceExecutor.java", "diffHunk": "@@ -208,13 +263,50 @@ private static SourceDescriptionWithWarnings describeSource(\n         SourceDescriptionFactory.create(\n             dataSource,\n             extended,\n-            getQueries(ksqlEngine, q -> q.getSourceNames().contains(dataSource.getName())),\n-            getQueries(ksqlEngine, q -> q.getSinkName().equals(dataSource.getName())),\n-            topicDescription\n+            sourceQueries,\n+            sinkQueries,\n+            topicDescriptionOptional,\n+            sourceConsumerOffsets\n         )\n     );\n   }\n \n+  private static List<SourceConsumerGroupOffset> consumerOffsets(\n+      final TopicDescription topicDescription,\n+      final Map<TopicPartition, ListOffsetsResultInfo> topicAndStartOffsets,\n+      final Map<TopicPartition, ListOffsetsResultInfo> topicAndEndOffsets,\n+      final Map<TopicPartition, OffsetAndMetadata> topicAndConsumerOffsets\n+  ) {\n+    final List<SourceConsumerGroupOffset> sourceConsumerGroupOffsets = new ArrayList<>();\n+    for (TopicPartitionInfo topicPartitionInfo : topicDescription.partitions()) {\n+      final TopicPartition tp = new TopicPartition(topicDescription.name(),\n+          topicPartitionInfo.partition());\n+      final ListOffsetsResultInfo startOffsetResultInfo = topicAndStartOffsets.get(tp);\n+      final ListOffsetsResultInfo endOffsetResultInfo = topicAndEndOffsets.get(tp);\n+      final OffsetAndMetadata offsetAndMetadata = topicAndConsumerOffsets.get(tp);\n+      sourceConsumerGroupOffsets.add(\n+          new SourceConsumerGroupOffset(\n+              topicPartitionInfo.partition(),\n+              startOffsetResultInfo != null ? startOffsetResultInfo.offset() : 0,\n+              endOffsetResultInfo != null ? endOffsetResultInfo.offset() : 0,\n+              offsetAndMetadata != null ? offsetAndMetadata.offset() : 0", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46263e21f6feb7f38dc7e745de1fc9c9c7079e3a"}, "originalPosition": 179}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTU1NTAwNA==", "bodyText": "we should extract this to a utility class and reuse it in QueryExecutor (and ditto below)", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r439555004", "createdAt": "2020-06-12T17:35:14Z", "author": {"login": "agavra"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListSourceExecutor.java", "diffHunk": "@@ -208,13 +263,50 @@ private static SourceDescriptionWithWarnings describeSource(\n         SourceDescriptionFactory.create(\n             dataSource,\n             extended,\n-            getQueries(ksqlEngine, q -> q.getSourceNames().contains(dataSource.getName())),\n-            getQueries(ksqlEngine, q -> q.getSinkName().equals(dataSource.getName())),\n-            topicDescription\n+            sourceQueries,\n+            sinkQueries,\n+            topicDescriptionOptional,\n+            sourceConsumerOffsets\n         )\n     );\n   }\n \n+  private static List<SourceConsumerGroupOffset> consumerOffsets(\n+      final TopicDescription topicDescription,\n+      final Map<TopicPartition, ListOffsetsResultInfo> topicAndStartOffsets,\n+      final Map<TopicPartition, ListOffsetsResultInfo> topicAndEndOffsets,\n+      final Map<TopicPartition, OffsetAndMetadata> topicAndConsumerOffsets\n+  ) {\n+    final List<SourceConsumerGroupOffset> sourceConsumerGroupOffsets = new ArrayList<>();\n+    for (TopicPartitionInfo topicPartitionInfo : topicDescription.partitions()) {\n+      final TopicPartition tp = new TopicPartition(topicDescription.name(),\n+          topicPartitionInfo.partition());\n+      final ListOffsetsResultInfo startOffsetResultInfo = topicAndStartOffsets.get(tp);\n+      final ListOffsetsResultInfo endOffsetResultInfo = topicAndEndOffsets.get(tp);\n+      final OffsetAndMetadata offsetAndMetadata = topicAndConsumerOffsets.get(tp);\n+      sourceConsumerGroupOffsets.add(\n+          new SourceConsumerGroupOffset(\n+              topicPartitionInfo.partition(),\n+              startOffsetResultInfo != null ? startOffsetResultInfo.offset() : 0,\n+              endOffsetResultInfo != null ? endOffsetResultInfo.offset() : 0,\n+              offsetAndMetadata != null ? offsetAndMetadata.offset() : 0\n+          ));\n+    }\n+    return sourceConsumerGroupOffsets;\n+  }\n+\n+  private static String getServiceId(final KsqlConfig ksqlConfig) {\n+    return ReservedInternalTopics.KSQL_INTERNAL_TOPIC_PREFIX\n+        + ksqlConfig.getString(KsqlConfig.KSQL_SERVICE_ID_CONFIG);\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46263e21f6feb7f38dc7e745de1fc9c9c7079e3a"}, "originalPosition": 188}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTU1NjQ3MA==", "bodyText": "we should add at least one test where this isn't empty to make sure equals/hashcode properly include it", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r439556470", "createdAt": "2020-06-12T17:38:28Z", "author": {"login": "agavra"}, "path": "ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/SourceDescriptionTest.java", "diffHunk": "@@ -53,117 +54,117 @@ public void shouldImplementHashCodeAndEqualsProperty() {\n                     SOME_STRING, Optional.empty(), readQueries, writeQueries, fields, SOME_STRING,\n                     SOME_STRING, SOME_STRING, SOME_STRING,\n                     SOME_BOOL, SOME_STRING, SOME_STRING, SOME_STRING, SOME_INT, SOME_INT,\n-                    SOME_STRING),\n+                    SOME_STRING, Optional.empty()),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46263e21f6feb7f38dc7e745de1fc9c9c7079e3a"}, "originalPosition": 13}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "46263e21f6feb7f38dc7e745de1fc9c9c7079e3a", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/46263e21f6feb7f38dc7e745de1fc9c9c7079e3a", "committedDate": "2020-06-04T21:34:21Z", "message": "fix: moar checkstyling"}, "afterCommit": {"oid": "f628d074e28aaedf5b6eea83f4f6a22192382db2", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/f628d074e28aaedf5b6eea83f4f6a22192382db2", "committedDate": "2020-06-16T22:08:02Z", "message": "fix: moar checkstyling"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM3Mzg4NDQ0", "url": "https://github.com/confluentinc/ksql/pull/5476#pullrequestreview-437388444", "createdAt": "2020-06-25T11:04:44Z", "commit": {"oid": "d7de0def3b0a72ffff8a6916978e3d588facf0cf"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 15, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNVQxMTowNDo0NFrOGo12mw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNVQxMTozNzowNlrOGo2xyA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTQ3ODU1NQ==", "bodyText": "This method is not returning what the name suggests.  It's not returning the service id, (which would be just ksqlConfig.getString(KsqlConfig.KSQL_SERVICE_ID_CONFIG).\nInstead, its returning the service id prefixed with KSQL_INTERNAL_TOPIC_PREFIX.\nI see you've moved this from another class, but I still think this isn't what we want.  KsqlConfig doesn't need to know about ReservedInternalTopics.\nThis is only needed to construct the query application id. Would you mind moving code into a QueryApplicationId util class? e.g.\n/**\n * Util for creating query application ids.\n */\npublic final class QueryApplicationId {\n\n  private QueryApplicationId() {\n  }\n\n  public static String getQueryApplicationId(\n      final KsqlConfig config,\n      final boolean persistent,\n      final QueryId queryId\n  ) {\n    final String serviceId = config.getString(KsqlConfig.KSQL_SERVICE_ID_CONFIG);\n\n    final String configName = persistent\n        ? KsqlConfig.KSQL_PERSISTENT_QUERY_NAME_PREFIX_CONFIG\n        : KsqlConfig.KSQL_TRANSIENT_QUERY_NAME_PREFIX_CONFIG;\n    \n    final String queryPrefix = config.getString(configName);\n    \n    return ReservedInternalTopics.KSQL_INTERNAL_TOPIC_PREFIX\n        + serviceId\n        + queryPrefix\n        + queryId;\n  }\n}\nThereby decoupling KqlConfig from any notion of internal topics, and also streamlining the existing code.", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r445478555", "createdAt": "2020-06-25T11:04:44Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-common/src/main/java/io/confluent/ksql/util/KsqlConfig.java", "diffHunk": "@@ -949,4 +949,9 @@ public KsqlConfig overrideBreakingConfigsWithOriginalValues(final Map<String, ?>\n     SslConfigs.addClientSslSupport(sslConfig);\n     return sslConfig.names();\n   }\n+\n+  public static String getServiceId(KsqlConfig ksqlConfig) {\n+    return ReservedInternalTopics.KSQL_INTERNAL_TOPIC_PREFIX\n+        + ksqlConfig.getString(KsqlConfig.KSQL_SERVICE_ID_CONFIG);\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d7de0def3b0a72ffff8a6916978e3d588facf0cf"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTQ4MDcwMQ==", "bodyText": "Yeah, this follows the same patterns as KafkaTopicClient.  The Memorized supplier pattern is used to avoid Admin Clients being instantiated, potentially per request due to different user credentials, during service context creation.  Admin client instantiation is expensive and should be done lazily, as is the case here.", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r445480701", "createdAt": "2020-06-25T11:09:12Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/services/KafkaConsumerGroupClientImpl.java", "diffHunk": "@@ -52,7 +56,10 @@ public ConsumerGroupSummary describeConsumerGroup(final String group) {\n     try {\n       final Map<String, ConsumerGroupDescription> groups = ExecutorUtil\n           .executeWithRetries(\n-              () -> adminClient.describeConsumerGroups(Collections.singleton(group)).all().get(),\n+              () -> adminClient.get()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjA1OTE1OQ=="}, "originalCommit": {"oid": "46263e21f6feb7f38dc7e745de1fc9c9c7079e3a"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTQ4MjM3Ng==", "bodyText": "I think you need something move like to give a better error message to the user on failure:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                } catch (final Exception e) {\n          \n          \n            \n                  throw new KafkaResponseGetFailedException(\n          \n          \n            \n                      \"Failed to get offsets for Kafka Topic \" + topicName, e);\n          \n          \n            \n                }\n          \n          \n            \n               } catch (final TopicAuthorizationException e) {\n          \n          \n            \n                  final Set<String> topics = partitions.stream()\n          \n          \n            \n                      .map(TopicPartition::topic)\n          \n          \n            \n                      .collect(Collectors.toSet());\n          \n          \n            \n            \n          \n          \n            \n                  throw new KsqlTopicAuthorizationException(\n          \n          \n            \n                      AclOperation.DESCRIBE, topics);\n          \n          \n            \n                } catch (final ExecutionException e) {\n          \n          \n            \n                  throw new KafkaResponseGetFailedException(\n          \n          \n            \n                      \"Failed to get topic offsets. partitions: \" + partitions, e.getCause());\n          \n          \n            \n                } catch (final Exception e) {\n          \n          \n            \n                  throw new KafkaResponseGetFailedException(\n          \n          \n            \n                      \"Failed to get topic offsets. partitions: \" + partitions, e);\n          \n          \n            \n                }", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r445482376", "createdAt": "2020-06-25T11:12:50Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/services/KafkaTopicClientImpl.java", "diffHunk": "@@ -311,6 +316,27 @@ public void deleteInternalTopics(final String applicationId) {\n     }\n   }\n \n+  @Override\n+  public Map<TopicPartition, ListOffsetsResultInfo> listTopicOffsets(\n+      final String topicName,\n+      final OffsetSpec offsetSpec\n+  ) {\n+    final TopicDescription topicDescription = describeTopic(topicName);\n+    final Map<TopicPartition, OffsetSpec> offsetsRequest = new HashMap<>();\n+    for (TopicPartitionInfo tpInfo : topicDescription.partitions()) {\n+      final TopicPartition tp = new TopicPartition(topicName, tpInfo.partition());\n+      offsetsRequest.put(tp, offsetSpec);\n+    }\n+    try {\n+      return ExecutorUtil.executeWithRetries(\n+          () -> adminClient.get().listOffsets(offsetsRequest).all().get(),\n+          RetryBehaviour.ON_RETRYABLE);\n+    } catch (final Exception e) {\n+      throw new KafkaResponseGetFailedException(\n+          \"Failed to get offsets for Kafka Topic \" + topicName, e);\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d7de0def3b0a72ffff8a6916978e3d588facf0cf"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTQ4NDU3Ng==", "bodyText": "don't return null.  The contract is to throw an exception, e.g. KafkaResponseGetFailedException, on an unknown group.  (Not that the contract is documented!).", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r445484576", "createdAt": "2020-06-25T11:17:39Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-engine/src/test/java/io/confluent/ksql/services/FakeKafkaConsumerGroupClient.java", "diffHunk": "@@ -0,0 +1,46 @@\n+package io.confluent.ksql.services;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableSet;\n+import java.util.Collections;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.TopicPartition;\n+\n+public class FakeKafkaConsumerGroupClient implements KafkaConsumerGroupClient {\n+\n+  private static final List<String> groups = ImmutableList.of(\"cg1\", \"cg2\");\n+\n+  @Override\n+  public List<String> listGroups() {\n+    return groups;\n+  }\n+\n+  @Override\n+  public ConsumerGroupSummary describeConsumerGroup(String group) {\n+    if (groups.contains(group)) {\n+      Set<ConsumerSummary> instances = ImmutableSet.of(\n+          new ConsumerSummary(group + \"-1\"),\n+          new ConsumerSummary(group + \"-2\")\n+      );\n+      return new ConsumerGroupSummary(instances);\n+    } else {\n+      return null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d7de0def3b0a72ffff8a6916978e3d588facf0cf"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTQ4NDgwOQ==", "bodyText": "Likewise.... throw on unknown group.", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r445484809", "createdAt": "2020-06-25T11:18:06Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-engine/src/test/java/io/confluent/ksql/services/FakeKafkaConsumerGroupClient.java", "diffHunk": "@@ -0,0 +1,46 @@\n+package io.confluent.ksql.services;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableSet;\n+import java.util.Collections;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.TopicPartition;\n+\n+public class FakeKafkaConsumerGroupClient implements KafkaConsumerGroupClient {\n+\n+  private static final List<String> groups = ImmutableList.of(\"cg1\", \"cg2\");\n+\n+  @Override\n+  public List<String> listGroups() {\n+    return groups;\n+  }\n+\n+  @Override\n+  public ConsumerGroupSummary describeConsumerGroup(String group) {\n+    if (groups.contains(group)) {\n+      Set<ConsumerSummary> instances = ImmutableSet.of(\n+          new ConsumerSummary(group + \"-1\"),\n+          new ConsumerSummary(group + \"-2\")\n+      );\n+      return new ConsumerGroupSummary(instances);\n+    } else {\n+      return null;\n+    }\n+  }\n+\n+  @Override\n+  public Map<TopicPartition, OffsetAndMetadata> listConsumerGroupOffsets(String group) {\n+    if (groups.contains(group)) {\n+      Map<TopicPartition, OffsetAndMetadata> offsets = new LinkedHashMap<>();\n+      offsets.put(new TopicPartition(\"topic1\", 0), new OffsetAndMetadata(10));\n+      offsets.put(new TopicPartition(\"topic1\", 1), new OffsetAndMetadata(11));\n+      return offsets;\n+    } else {\n+      return Collections.emptyMap();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d7de0def3b0a72ffff8a6916978e3d588facf0cf"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTQ4NTA2NQ==", "bodyText": "As before - throw on unknown group", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r445485065", "createdAt": "2020-06-25T11:18:38Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-functional-tests/src/main/java/io/confluent/ksql/test/tools/stubs/StubKafkaConsumerGroupClient.java", "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Copyright 2018 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.test.tools.stubs;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableSet;\n+import io.confluent.ksql.services.KafkaConsumerGroupClient;\n+import java.util.Collections;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.TopicPartition;\n+\n+public class StubKafkaConsumerGroupClient implements KafkaConsumerGroupClient {\n+\n+  private static final List<String> groups = ImmutableList.of(\"cg1\", \"cg2\");\n+\n+  @Override\n+  public List<String> listGroups() {\n+    return groups;\n+  }\n+\n+  @Override\n+  public ConsumerGroupSummary describeConsumerGroup(final String group) {\n+    if (groups.contains(group)) {\n+      final Set<ConsumerSummary> instances = ImmutableSet.of(\n+          new ConsumerSummary(group + \"-1\"),\n+          new ConsumerSummary(group + \"-2\")\n+      );\n+      return new ConsumerGroupSummary(instances);\n+    } else {\n+      return null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d7de0def3b0a72ffff8a6916978e3d588facf0cf"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTQ4NTA4OA==", "bodyText": "As before - throw on unknown group", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r445485088", "createdAt": "2020-06-25T11:18:42Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-functional-tests/src/main/java/io/confluent/ksql/test/tools/stubs/StubKafkaConsumerGroupClient.java", "diffHunk": "@@ -0,0 +1,62 @@\n+/*\n+ * Copyright 2018 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.test.tools.stubs;\n+\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.ImmutableSet;\n+import io.confluent.ksql.services.KafkaConsumerGroupClient;\n+import java.util.Collections;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import org.apache.kafka.clients.consumer.OffsetAndMetadata;\n+import org.apache.kafka.common.TopicPartition;\n+\n+public class StubKafkaConsumerGroupClient implements KafkaConsumerGroupClient {\n+\n+  private static final List<String> groups = ImmutableList.of(\"cg1\", \"cg2\");\n+\n+  @Override\n+  public List<String> listGroups() {\n+    return groups;\n+  }\n+\n+  @Override\n+  public ConsumerGroupSummary describeConsumerGroup(final String group) {\n+    if (groups.contains(group)) {\n+      final Set<ConsumerSummary> instances = ImmutableSet.of(\n+          new ConsumerSummary(group + \"-1\"),\n+          new ConsumerSummary(group + \"-2\")\n+      );\n+      return new ConsumerGroupSummary(instances);\n+    } else {\n+      return null;\n+    }\n+  }\n+\n+  @Override\n+  public Map<TopicPartition, OffsetAndMetadata> listConsumerGroupOffsets(final String group) {\n+    if (groups.contains(group)) {\n+      final Map<TopicPartition, OffsetAndMetadata> offsets = new LinkedHashMap<>();\n+      offsets.put(new TopicPartition(\"topic1\", 0), new OffsetAndMetadata(10));\n+      offsets.put(new TopicPartition(\"topic1\", 1), new OffsetAndMetadata(11));\n+      return offsets;\n+    } else {\n+      return Collections.emptyMap();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d7de0def3b0a72ffff8a6916978e3d588facf0cf"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTQ4NTY3MQ==", "bodyText": "Can you extend this error handling, as suggestted above for another function, to return more helpful error messages to the user please?\n\nadd catch block for auth errors\nadd catch block to unwrap execution errors.", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r445485671", "createdAt": "2020-06-25T11:19:56Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/services/KafkaConsumerGroupClientImpl.java", "diffHunk": "@@ -73,4 +80,18 @@ public ConsumerGroupSummary describeConsumerGroup(final String group) {\n       throw new KafkaResponseGetFailedException(\"Failed to describe Kafka consumer groups\", e);\n     }\n   }\n+\n+  @Override\n+  public Map<TopicPartition, OffsetAndMetadata> listConsumerGroupOffsets(final String group) {\n+    try {\n+      return ExecutorUtil.executeWithRetries(\n+          () -> adminClient.get()\n+              .listConsumerGroupOffsets(group)\n+              .partitionsToOffsetAndMetadata()\n+              .get(),\n+          RetryBehaviour.ON_RETRYABLE);\n+    } catch (final Exception e) {\n+      throw new KafkaResponseGetFailedException(\"Failed to retrieve Kafka consumer groups\", e);\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d7de0def3b0a72ffff8a6916978e3d588facf0cf"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTQ4Njk2Ng==", "bodyText": "nit: validate params that will be stored in object state; ensuring object does not get into an invalid state.\ni.e. Objects.requireNonNull", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r445486966", "createdAt": "2020-06-25T11:22:43Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/SourceConsumerGroupOffsets.java", "diffHunk": "@@ -0,0 +1,71 @@\n+/*\n+ * Copyright 2018 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.entity;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import java.util.List;\n+import java.util.Objects;\n+\n+@JsonIgnoreProperties(ignoreUnknown = true)\n+public class SourceConsumerGroupOffsets {\n+  private final String groupId;\n+  private final String kafkaTopic;\n+  private final List<SourceConsumerGroupOffset> offsets;\n+\n+  @JsonCreator\n+  public SourceConsumerGroupOffsets(\n+      @JsonProperty(\"groupId\") final String groupId,\n+      @JsonProperty(\"kafkaTopic\") final String kafkaTopic,\n+      @JsonProperty(\"offsets\") final List<SourceConsumerGroupOffset> offsets\n+  ) {\n+    this.groupId = groupId;\n+    this.kafkaTopic = kafkaTopic;\n+    this.offsets = offsets;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d7de0def3b0a72ffff8a6916978e3d588facf0cf"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTQ4Nzg2Ng==", "bodyText": "Feels like a good candidate to move into its own function.", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r445487866", "createdAt": "2020-06-25T11:24:44Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListSourceExecutor.java", "diffHunk": "@@ -191,13 +208,46 @@ private static SourceDescriptionWithWarnings describeSource(\n       ), statementText);\n     }\n \n-    Optional<org.apache.kafka.clients.admin.TopicDescription> topicDescription = Optional.empty();\n+    final List<RunningQuery> sourceQueries = getQueries(ksqlEngine,\n+        q -> q.getSourceNames().contains(dataSource.getName()));\n+    final List<RunningQuery> sinkQueries = getQueries(ksqlEngine,\n+        q -> q.getSinkName().equals(dataSource.getName()));\n+\n+    Optional<org.apache.kafka.clients.admin.TopicDescription> topicDescriptionOptional = Optional\n+        .empty();\n+    final List<SourceConsumerGroupOffsets> sourceConsumerOffsets = new ArrayList<>();\n     final List<KsqlWarning> warnings = new LinkedList<>();\n     if (extended) {\n       try {\n-        topicDescription = Optional.of(\n-            serviceContext.getTopicClient().describeTopic(dataSource.getKafkaTopicName())\n-        );\n+        final String kafkaTopicName = dataSource.getKafkaTopicName();\n+        final TopicDescription topicDescription = serviceContext.getTopicClient()\n+                .describeTopic(kafkaTopicName);\n+        topicDescriptionOptional = Optional.of(topicDescription);\n+        for (RunningQuery sourceQuery : sourceQueries) {\n+          final QueryId queryId = sourceQuery.getId();\n+          final String persistenceQueryPrefix =\n+              ksqlConfig.getString(KsqlConfig.KSQL_PERSISTENT_QUERY_NAME_PREFIX_CONFIG);\n+          final String applicationId = getQueryApplicationId(\n+              KsqlConfig.getServiceId(ksqlConfig),\n+              persistenceQueryPrefix,\n+              queryId\n+          );\n+          final Map<TopicPartition, OffsetAndMetadata> topicAndConsumerOffsets =\n+              serviceContext.getConsumerGroupClient().listConsumerGroupOffsets(applicationId);\n+          final Map<TopicPartition, ListOffsetsResultInfo> topicAndStartOffsets =\n+              serviceContext.getTopicClient().listTopicStartOffsets(kafkaTopicName);\n+          final Map<TopicPartition, ListOffsetsResultInfo> topicAndEndOffsets =\n+              serviceContext.getTopicClient().listTopicEndOffsets(kafkaTopicName);\n+          sourceConsumerOffsets.add(\n+              new SourceConsumerGroupOffsets(\n+                  applicationId,\n+                  topicDescription.name(),\n+                  consumerOffsets(\n+                      topicDescription,\n+                      topicAndStartOffsets,\n+                      topicAndEndOffsets,\n+                      topicAndConsumerOffsets)));\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d7de0def3b0a72ffff8a6916978e3d588facf0cf"}, "originalPosition": 135}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTQ4OTgzNw==", "bodyText": "I think this is a bug: this is getting the offsets of the data source's sink topic, i.e. kafkaTopicName and comparing this to the consumer group offsets of queries writing into the sink topic.  Those queries won't be consuming kafkaTopicName, they'll be producing to it.\nOr am I missing somethinng?", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r445489837", "createdAt": "2020-06-25T11:28:52Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListSourceExecutor.java", "diffHunk": "@@ -191,13 +208,46 @@ private static SourceDescriptionWithWarnings describeSource(\n       ), statementText);\n     }\n \n-    Optional<org.apache.kafka.clients.admin.TopicDescription> topicDescription = Optional.empty();\n+    final List<RunningQuery> sourceQueries = getQueries(ksqlEngine,\n+        q -> q.getSourceNames().contains(dataSource.getName()));\n+    final List<RunningQuery> sinkQueries = getQueries(ksqlEngine,\n+        q -> q.getSinkName().equals(dataSource.getName()));\n+\n+    Optional<org.apache.kafka.clients.admin.TopicDescription> topicDescriptionOptional = Optional\n+        .empty();\n+    final List<SourceConsumerGroupOffsets> sourceConsumerOffsets = new ArrayList<>();\n     final List<KsqlWarning> warnings = new LinkedList<>();\n     if (extended) {\n       try {\n-        topicDescription = Optional.of(\n-            serviceContext.getTopicClient().describeTopic(dataSource.getKafkaTopicName())\n-        );\n+        final String kafkaTopicName = dataSource.getKafkaTopicName();\n+        final TopicDescription topicDescription = serviceContext.getTopicClient()\n+                .describeTopic(kafkaTopicName);\n+        topicDescriptionOptional = Optional.of(topicDescription);\n+        for (RunningQuery sourceQuery : sourceQueries) {\n+          final QueryId queryId = sourceQuery.getId();\n+          final String persistenceQueryPrefix =\n+              ksqlConfig.getString(KsqlConfig.KSQL_PERSISTENT_QUERY_NAME_PREFIX_CONFIG);\n+          final String applicationId = getQueryApplicationId(\n+              KsqlConfig.getServiceId(ksqlConfig),\n+              persistenceQueryPrefix,\n+              queryId\n+          );\n+          final Map<TopicPartition, OffsetAndMetadata> topicAndConsumerOffsets =\n+              serviceContext.getConsumerGroupClient().listConsumerGroupOffsets(applicationId);\n+          final Map<TopicPartition, ListOffsetsResultInfo> topicAndStartOffsets =\n+              serviceContext.getTopicClient().listTopicStartOffsets(kafkaTopicName);\n+          final Map<TopicPartition, ListOffsetsResultInfo> topicAndEndOffsets =\n+              serviceContext.getTopicClient().listTopicEndOffsets(kafkaTopicName);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d7de0def3b0a72ffff8a6916978e3d588facf0cf"}, "originalPosition": 125}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTQ5MDQzOQ==", "bodyText": "nit: inline this.", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r445490439", "createdAt": "2020-06-25T11:30:05Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListSourceExecutor.java", "diffHunk": "@@ -191,13 +208,46 @@ private static SourceDescriptionWithWarnings describeSource(\n       ), statementText);\n     }\n \n-    Optional<org.apache.kafka.clients.admin.TopicDescription> topicDescription = Optional.empty();\n+    final List<RunningQuery> sourceQueries = getQueries(ksqlEngine,\n+        q -> q.getSourceNames().contains(dataSource.getName()));\n+    final List<RunningQuery> sinkQueries = getQueries(ksqlEngine,\n+        q -> q.getSinkName().equals(dataSource.getName()));\n+\n+    Optional<org.apache.kafka.clients.admin.TopicDescription> topicDescriptionOptional = Optional\n+        .empty();\n+    final List<SourceConsumerGroupOffsets> sourceConsumerOffsets = new ArrayList<>();\n     final List<KsqlWarning> warnings = new LinkedList<>();\n     if (extended) {\n       try {\n-        topicDescription = Optional.of(\n-            serviceContext.getTopicClient().describeTopic(dataSource.getKafkaTopicName())\n-        );\n+        final String kafkaTopicName = dataSource.getKafkaTopicName();\n+        final TopicDescription topicDescription = serviceContext.getTopicClient()\n+                .describeTopic(kafkaTopicName);\n+        topicDescriptionOptional = Optional.of(topicDescription);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d7de0def3b0a72ffff8a6916978e3d588facf0cf"}, "originalPosition": 110}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTQ5MjU3NA==", "bodyText": "nit: validate params that will be stored in object state; ensuring object does not get into an invalid state.\ni.e. ensure none of these are negative:\nPreconditions.checkArgument(partition <= 0, \"invalid partition: \" +. partition);\n // etc", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r445492574", "createdAt": "2020-06-25T11:34:43Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/SourceConsumerGroupOffset.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Copyright 2018 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.entity;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import java.util.Objects;\n+\n+@JsonIgnoreProperties(ignoreUnknown = true)\n+public class SourceConsumerGroupOffset {\n+\n+  private final int partition;\n+  private final long logStartOffset;\n+  private final long logEndOffset;\n+  private final long consumerOffset;\n+\n+  @JsonCreator\n+  public SourceConsumerGroupOffset(\n+      @JsonProperty(\"partition\") final int partition,\n+      @JsonProperty(\"logStartOffset\") final long logStartOffset,\n+      @JsonProperty(\"logEndOffset\") final long logEndOffset,\n+      @JsonProperty(\"consumerOffset\") final long consumerOffset\n+  ) {\n+    this.partition = partition;\n+    this.logStartOffset = logStartOffset;\n+    this.logEndOffset = logEndOffset;\n+    this.consumerOffset = consumerOffset;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d7de0def3b0a72ffff8a6916978e3d588facf0cf"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTQ5MzQyOQ==", "bodyText": "nit: Prefer ImmutableList.copyOf to Collections.unmodifiableList.", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r445493429", "createdAt": "2020-06-25T11:36:28Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/SourceDescription.java", "diffHunk": "@@ -88,6 +90,8 @@ public SourceDescription(\n     this.partitions = partitions;\n     this.replication = replication;\n     this.statement = Objects.requireNonNull(statement, \"statement\");\n+    this.consumerGroupsOffsets = Collections.unmodifiableList(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d7de0def3b0a72ffff8a6916978e3d588facf0cf"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTQ5MzcwNA==", "bodyText": "This exposes mutable state of the object, which breaks encapsulation.  Please use ImmutableList.copyOf in the constructor.", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r445493704", "createdAt": "2020-06-25T11:37:06Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/SourceConsumerGroupOffsets.java", "diffHunk": "@@ -0,0 +1,71 @@\n+/*\n+ * Copyright 2018 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.entity;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import java.util.List;\n+import java.util.Objects;\n+\n+@JsonIgnoreProperties(ignoreUnknown = true)\n+public class SourceConsumerGroupOffsets {\n+  private final String groupId;\n+  private final String kafkaTopic;\n+  private final List<SourceConsumerGroupOffset> offsets;\n+\n+  @JsonCreator\n+  public SourceConsumerGroupOffsets(\n+      @JsonProperty(\"groupId\") final String groupId,\n+      @JsonProperty(\"kafkaTopic\") final String kafkaTopic,\n+      @JsonProperty(\"offsets\") final List<SourceConsumerGroupOffset> offsets\n+  ) {\n+    this.groupId = groupId;\n+    this.kafkaTopic = kafkaTopic;\n+    this.offsets = offsets;\n+  }\n+\n+  public String getGroupId() {\n+    return groupId;\n+  }\n+\n+  public String getKafkaTopic() {\n+    return kafkaTopic;\n+  }\n+\n+  public List<SourceConsumerGroupOffset> getOffsets() {\n+    return offsets;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d7de0def3b0a72ffff8a6916978e3d588facf0cf"}, "originalPosition": 50}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d7de0def3b0a72ffff8a6916978e3d588facf0cf", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/d7de0def3b0a72ffff8a6916978e3d588facf0cf", "committedDate": "2020-06-17T19:52:15Z", "message": "turn to static"}, "afterCommit": {"oid": "8c33496cafc3e689efbe6c45d1bd0e46f8c7fc5f", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/8c33496cafc3e689efbe6c45d1bd0e46f8c7fc5f", "committedDate": "2020-07-06T20:57:25Z", "message": "turn to static"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d795becb3948f8388cb74d75cb7985b694ef606c", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/d795becb3948f8388cb74d75cb7985b694ef606c", "committedDate": "2020-07-11T13:12:40Z", "message": "fix sandboxed topic client mapping test"}, "afterCommit": {"oid": "c68155154523f7e8fcdad0096f47d5148c112a85", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/c68155154523f7e8fcdad0096f47d5148c112a85", "committedDate": "2020-07-11T16:16:59Z", "message": "fix sandboxed topic client mapping test"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2ODA5MjYw", "url": "https://github.com/confluentinc/ksql/pull/5476#pullrequestreview-446809260", "createdAt": "2020-07-11T15:19:47Z", "commit": {"oid": "d795becb3948f8388cb74d75cb7985b694ef606c"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMVQxNToxOTo0N1rOGwNbaQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMVQxNToyMTo1MFrOGwNcSg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzIwNDg0MQ==", "bodyText": "@big-andy-coates should we also add time suffix_ as in:\n  private static String addTimeSuffix(final String original) {\n    return String.format(\"%s_%d\", original, System.currentTimeMillis());\n  }", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r453204841", "createdAt": "2020-07-11T15:19:47Z", "author": {"login": "jeqo"}, "path": "ksqldb-common/src/main/java/io/confluent/ksql/util/QueryApplicationId.java", "diffHunk": "@@ -0,0 +1,46 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.util;\n+\n+import io.confluent.ksql.query.QueryId;\n+\n+/**\n+ * Util to build query application ids.\n+ */\n+public final class QueryApplicationId {\n+\n+  private QueryApplicationId() {\n+  }\n+\n+  public static String build(\n+      final KsqlConfig config,\n+      final boolean persistent,\n+      final QueryId queryId\n+  ) {\n+    final String serviceId = config.getString(KsqlConfig.KSQL_SERVICE_ID_CONFIG);\n+\n+    final String configName = persistent\n+        ? KsqlConfig.KSQL_PERSISTENT_QUERY_NAME_PREFIX_CONFIG\n+        : KsqlConfig.KSQL_TRANSIENT_QUERY_NAME_PREFIX_CONFIG;\n+\n+    final String queryPrefix = config.getString(configName);\n+\n+    return ReservedInternalTopics.KSQL_INTERNAL_TOPIC_PREFIX\n+        + serviceId\n+        + queryPrefix\n+        + queryId;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d795becb3948f8388cb74d75cb7985b694ef606c"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzIwNTA2Ng==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  throw new KafkaResponseGetFailedException(\"Failed to retrieve Kafka consumer groups\", e);\n          \n          \n            \n                  throw new KafkaResponseGetFailedException(\"Failed to list Kafka consumer groups offsets\", e);", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r453205066", "createdAt": "2020-07-11T15:21:50Z", "author": {"login": "jeqo"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/services/KafkaConsumerGroupClientImpl.java", "diffHunk": "@@ -68,9 +77,27 @@ public ConsumerGroupSummary describeConsumerGroup(final String group) {\n                   })).collect(Collectors.toSet());\n \n       return new ConsumerGroupSummary(results);\n+    } catch (final GroupAuthorizationException e) {\n+      throw new KsqlGroupAuthorizationException(AclOperation.DESCRIBE, group);\n+    } catch (final Exception e) {\n+      throw new KafkaResponseGetFailedException(\n+          \"Failed to describe Kafka consumer groups: \" + group, e);\n+    }\n+  }\n \n+  @Override\n+  public Map<TopicPartition, OffsetAndMetadata> listConsumerGroupOffsets(final String group) {\n+    try {\n+      return ExecutorUtil.executeWithRetries(\n+          () -> adminClient.get()\n+              .listConsumerGroupOffsets(group)\n+              .partitionsToOffsetAndMetadata()\n+              .get(),\n+          RetryBehaviour.ON_RETRYABLE);\n+    } catch (final GroupAuthorizationException e) {\n+      throw new KsqlGroupAuthorizationException(AclOperation.DESCRIBE, group);\n     } catch (final Exception e) {\n-      throw new KafkaResponseGetFailedException(\"Failed to describe Kafka consumer groups\", e);\n+      throw new KafkaResponseGetFailedException(\"Failed to retrieve Kafka consumer groups\", e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d795becb3948f8388cb74d75cb7985b694ef606c"}, "originalPosition": 90}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b5cda02ff8879010b9c543b8b09073daa73580be", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/b5cda02ff8879010b9c543b8b09073daa73580be", "committedDate": "2020-07-11T21:26:50Z", "message": "fix preconditions"}, "afterCommit": {"oid": "4b3964d4c21dbe30996a0efc747d74801b73d559", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/4b3964d4c21dbe30996a0efc747d74801b73d559", "committedDate": "2020-07-15T09:27:43Z", "message": "fix preconditions"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ac636f8a43eff4b05c0d11a469a3911a7def426f", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/ac636f8a43eff4b05c0d11a469a3911a7def426f", "committedDate": "2020-07-15T09:45:05Z", "message": "fix call to sourcedescription"}, "afterCommit": {"oid": "086c4b0be3b8a22ac7e23d2d1a6e1e19d22dd795", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/086c4b0be3b8a22ac7e23d2d1a6e1e19d22dd795", "committedDate": "2020-07-22T15:53:28Z", "message": "fix call to sourcedescription"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU4NDY0NDEx", "url": "https://github.com/confluentinc/ksql/pull/5476#pullrequestreview-458464411", "createdAt": "2020-07-30T14:36:59Z", "commit": {"oid": "086c4b0be3b8a22ac7e23d2d1a6e1e19d22dd795"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxNDozNjo1OVrOG5l-Ew==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxNDo1MToxM1rOG5mnYg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA0NDExNQ==", "bodyText": "Class would benefit from a couple of tests!  Maybe one test for persistent and one for transient.", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r463044115", "createdAt": "2020-07-30T14:36:59Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-common/src/main/java/io/confluent/ksql/util/QueryApplicationId.java", "diffHunk": "@@ -0,0 +1,46 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.util;\n+\n+import io.confluent.ksql.query.QueryId;\n+\n+/**\n+ * Util to build query application ids.\n+ */\n+public final class QueryApplicationId {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "086c4b0be3b8a22ac7e23d2d1a6e1e19d22dd795"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA0NDM1OQ==", "bodyText": "Good call. Makes sense to have this method append the time suffix for transient queries, i.e. when !persistent.", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r463044359", "createdAt": "2020-07-30T14:37:18Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-common/src/main/java/io/confluent/ksql/util/QueryApplicationId.java", "diffHunk": "@@ -0,0 +1,46 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.util;\n+\n+import io.confluent.ksql.query.QueryId;\n+\n+/**\n+ * Util to build query application ids.\n+ */\n+public final class QueryApplicationId {\n+\n+  private QueryApplicationId() {\n+  }\n+\n+  public static String build(\n+      final KsqlConfig config,\n+      final boolean persistent,\n+      final QueryId queryId\n+  ) {\n+    final String serviceId = config.getString(KsqlConfig.KSQL_SERVICE_ID_CONFIG);\n+\n+    final String configName = persistent\n+        ? KsqlConfig.KSQL_PERSISTENT_QUERY_NAME_PREFIX_CONFIG\n+        : KsqlConfig.KSQL_TRANSIENT_QUERY_NAME_PREFIX_CONFIG;\n+\n+    final String queryPrefix = config.getString(configName);\n+\n+    return ReservedInternalTopics.KSQL_INTERNAL_TOPIC_PREFIX\n+        + serviceId\n+        + queryPrefix\n+        + queryId;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzIwNDg0MQ=="}, "originalCommit": {"oid": "d795becb3948f8388cb74d75cb7985b694ef606c"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA0OTI0OQ==", "bodyText": "nit: commented out code.", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r463049249", "createdAt": "2020-07-30T14:43:59Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-engine/src/test/java/io/confluent/ksql/services/KafkaTopicClientImplTest.java", "diffHunk": "@@ -747,6 +817,29 @@ private void givenTopicConfigs(\n     };\n   }\n \n+  private Answer<ListOffsetsResult> listTopicOffsets() {\n+    return inv -> {\n+      final ListOffsetsResult result = mock(ListOffsetsResult.class);\n+      when(result.all()).thenReturn(KafkaFuture.completedFuture(ImmutableMap.of(\n+          new TopicPartition(\"topicA\", 0),\n+          new ListOffsetsResultInfo(100L, 0L, Optional.empty()))));\n+      return result;\n+    };\n+  }\n+\n+  private Answer<ListOffsetsResult> listTopicOffsets(final Exception e) {\n+    return inv -> {\n+      final ListOffsetsResult result = mock(ListOffsetsResult.class);\n+      final KafkaFuture<Map<TopicPartition, ListOffsetsResultInfo>> f = failedFuture(e);\n+      when(result.all()).thenReturn(f);\n+//      return new ListOffsetsResult(\n+//          ImmutableMap.of(\n+//              new TopicPartition(\"topicA\", 0),\n+//              new ListOffsetsResultInfo(100L, 0L, Optional.empty())));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "086c4b0be3b8a22ac7e23d2d1a6e1e19d22dd795"}, "originalPosition": 125}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA1MDUwMw==", "bodyText": "Can you add tests to SupportedMethods for these new methods?", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r463050503", "createdAt": "2020-07-30T14:45:33Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-engine/src/test/java/io/confluent/ksql/services/SandboxedKafkaTopicClientTest.java", "diffHunk": "@@ -78,6 +78,8 @@ private SandboxedKafkaTopicClientTest() {\n           .ignore(\"describeTopic\", String.class)\n           .ignore(\"describeTopics\", Collection.class)\n           .ignore(\"deleteTopics\", Collection.class)\n+          .ignore(\"listTopicsStartOffsets\", Collection.class)\n+          .ignore(\"listTopicsEndOffsets\", Collection.class)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "086c4b0be3b8a22ac7e23d2d1a6e1e19d22dd795"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA1MzQwMQ==", "bodyText": "nit: validate params that will be stored in object state; ensuring object does not get into an invalid state.\ni.e. Objects.requireNonNull", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r463053401", "createdAt": "2020-07-30T14:49:28Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/QueryOffsetSummary.java", "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Copyright 2018 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.rest.entity;\n+\n+import com.fasterxml.jackson.annotation.JsonCreator;\n+import com.fasterxml.jackson.annotation.JsonIgnoreProperties;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.google.common.collect.ImmutableList;\n+import java.util.List;\n+import java.util.Objects;\n+\n+@JsonIgnoreProperties(ignoreUnknown = true)\n+public class QueryOffsetSummary {\n+  private final String groupId;\n+  private final String kafkaTopic;\n+  private final List<ConsumerPartitionOffsets> offsets;\n+\n+  @JsonCreator\n+  public QueryOffsetSummary(\n+      @JsonProperty(\"groupId\") final String groupId,\n+      @JsonProperty(\"kafkaTopic\") final String kafkaTopic,\n+      @JsonProperty(\"offsets\") final List<ConsumerPartitionOffsets> offsets\n+  ) {\n+    this.groupId = groupId;\n+    this.kafkaTopic = kafkaTopic;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "086c4b0be3b8a22ac7e23d2d1a6e1e19d22dd795"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA1NDY5MA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                this.queryOffsetSummaries = Collections.unmodifiableList(\n          \n          \n            \n                this.queryOffsetSummaries = ImmutableList.copyOf(", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r463054690", "createdAt": "2020-07-30T14:51:13Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-model/src/main/java/io/confluent/ksql/rest/entity/SourceDescription.java", "diffHunk": "@@ -88,6 +90,8 @@ public SourceDescription(\n     this.partitions = partitions;\n     this.replication = replication;\n     this.statement = Objects.requireNonNull(statement, \"statement\");\n+    this.queryOffsetSummaries = Collections.unmodifiableList(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "086c4b0be3b8a22ac7e23d2d1a6e1e19d22dd795"}, "originalPosition": 43}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU4NDc5NDU5", "url": "https://github.com/confluentinc/ksql/pull/5476#pullrequestreview-458479459", "createdAt": "2020-07-30T14:52:41Z", "commit": {"oid": "086c4b0be3b8a22ac7e23d2d1a6e1e19d22dd795"}, "state": "APPROVED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxNDo1Mjo0MVrOG5mrgQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQxNToyNTo1MVrOG5oI6g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA1NTc0NQ==", "bodyText": "nit: Can you add a new equality group where the summaries are different please?", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r463055745", "createdAt": "2020-07-30T14:52:41Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-model/src/test/java/io/confluent/ksql/rest/entity/SourceDescriptionTest.java", "diffHunk": "@@ -39,131 +39,141 @@\n     private RunningQuery query2;\n     @Mock\n     private FieldInfo fieldInfo;\n+    @Mock\n+    private QueryOffsetSummary summary;\n \n     @SuppressWarnings(\"UnstableApiUsage\")\n     @Test\n     public void shouldImplementHashCodeAndEqualsProperty() {\n         final List<RunningQuery> readQueries = Collections.singletonList(query1);\n         final List<RunningQuery> writeQueries = Collections.singletonList(query2);\n         final List<FieldInfo> fields = Collections.singletonList(fieldInfo);\n+        final List<QueryOffsetSummary> summaries = Collections.singletonList(summary);\n \n         new EqualsTester()\n             .addEqualityGroup(\n                 new SourceDescription(\n                     SOME_STRING, Optional.empty(), readQueries, writeQueries, fields, SOME_STRING,\n                     SOME_STRING, SOME_STRING, SOME_STRING,\n                     SOME_BOOL, SOME_STRING, SOME_STRING, SOME_STRING, SOME_INT, SOME_INT,\n-                    SOME_STRING),\n+                    SOME_STRING, summaries),\n                 new SourceDescription(\n                     SOME_STRING, Optional.empty(), readQueries, writeQueries, fields, SOME_STRING,\n                     SOME_STRING, SOME_STRING, SOME_STRING,\n                     SOME_BOOL, SOME_STRING, SOME_STRING, SOME_STRING, SOME_INT, SOME_INT,\n-                    SOME_STRING)\n+                    SOME_STRING, summaries)\n             )\n             .addEqualityGroup(\n                 new SourceDescription(\n                     \"diff\", Optional.of(WindowType.SESSION), readQueries, writeQueries, fields,\n                     SOME_STRING, SOME_STRING, SOME_STRING, SOME_STRING,\n                     SOME_BOOL, SOME_STRING, SOME_STRING, SOME_STRING, SOME_INT, SOME_INT,\n-                    SOME_STRING)\n+                    SOME_STRING, summaries)\n             )\n             .addEqualityGroup(\n                 new SourceDescription(\n                     SOME_STRING, Optional.empty(), ImmutableList.of(), writeQueries, fields,\n                     SOME_STRING, SOME_STRING, SOME_STRING, SOME_STRING,\n                     SOME_BOOL, SOME_STRING, SOME_STRING, SOME_STRING, SOME_INT, SOME_INT,\n-                    SOME_STRING)\n+                    SOME_STRING, summaries)\n             )\n             .addEqualityGroup(\n                 new SourceDescription(\n                     SOME_STRING, Optional.empty(), readQueries, ImmutableList.of(), fields,\n                     SOME_STRING, SOME_STRING, SOME_STRING, SOME_STRING,\n                     SOME_BOOL, SOME_STRING, SOME_STRING, SOME_STRING, SOME_INT, SOME_INT,\n-                    SOME_STRING)\n+                    SOME_STRING, summaries)\n             )\n             .addEqualityGroup(\n                 new SourceDescription(\n                     SOME_STRING, Optional.empty(), readQueries, writeQueries, ImmutableList.of(),\n                     SOME_STRING, SOME_STRING, SOME_STRING, SOME_STRING,\n                     SOME_BOOL, SOME_STRING, SOME_STRING, SOME_STRING, SOME_INT, SOME_INT,\n-                    SOME_STRING)\n+                    SOME_STRING, summaries)\n+            )\n+            .addEqualityGroup(\n+                new SourceDescription(\n+                    SOME_STRING, Optional.empty(), readQueries, writeQueries, fields,\n+                    SOME_STRING, SOME_STRING, SOME_STRING, SOME_STRING,\n+                    SOME_BOOL, SOME_STRING, SOME_STRING, SOME_STRING, SOME_INT, SOME_INT,\n+                    SOME_STRING, ImmutableList.of())\n             )\n             .addEqualityGroup(\n                 new SourceDescription(\n                     SOME_STRING, Optional.empty(), readQueries, writeQueries, fields, \"diff\",\n                     SOME_STRING, SOME_STRING, SOME_STRING,\n                     SOME_BOOL, SOME_STRING, SOME_STRING, SOME_STRING, SOME_INT, SOME_INT,\n-                    SOME_STRING)\n+                    SOME_STRING, summaries)\n             )\n             .addEqualityGroup(\n                 new SourceDescription(\n                     SOME_STRING, Optional.empty(), readQueries, writeQueries, fields, SOME_STRING,\n                      \"diff\", SOME_STRING, SOME_STRING,\n                     SOME_BOOL, SOME_STRING, SOME_STRING, SOME_STRING, SOME_INT, SOME_INT,\n-                    SOME_STRING)\n+                    SOME_STRING, summaries)\n             )\n             .addEqualityGroup(\n                 new SourceDescription(\n                     SOME_STRING, Optional.empty(), readQueries, writeQueries, fields, SOME_STRING,\n                     SOME_STRING, \"diff\", SOME_STRING,\n                     SOME_BOOL, SOME_STRING, SOME_STRING, SOME_STRING, SOME_INT, SOME_INT,\n-                    SOME_STRING)\n+                    SOME_STRING, summaries)\n             )\n             .addEqualityGroup(\n                 new SourceDescription(\n                     SOME_STRING, Optional.empty(), readQueries, writeQueries, fields, SOME_STRING,\n                     SOME_STRING, SOME_STRING, \"diff\",\n                     SOME_BOOL, SOME_STRING, SOME_STRING, SOME_STRING, SOME_INT, SOME_INT,\n-                    SOME_STRING)\n+                    SOME_STRING, summaries)\n             )\n             .addEqualityGroup(\n                 new SourceDescription(\n                     SOME_STRING, Optional.empty(), readQueries, writeQueries, fields, SOME_STRING,\n                     SOME_STRING, SOME_STRING, SOME_STRING,\n                     SOME_BOOL, \"diff\", SOME_STRING, SOME_STRING, SOME_INT, SOME_INT,\n-                    SOME_STRING)\n+                    SOME_STRING, summaries)\n             )\n             .addEqualityGroup(\n                 new SourceDescription(\n                     SOME_STRING, Optional.empty(), readQueries, writeQueries, fields, SOME_STRING,\n                     SOME_STRING, SOME_STRING, SOME_STRING,\n                     !SOME_BOOL, SOME_STRING, SOME_STRING, SOME_STRING, SOME_INT, SOME_INT,\n-                    SOME_STRING)\n+                    SOME_STRING, summaries)\n             )\n             .addEqualityGroup(\n                 new SourceDescription(\n                     SOME_STRING, Optional.empty(), readQueries, writeQueries, fields, SOME_STRING,\n                     SOME_STRING, SOME_STRING, SOME_STRING,\n                     SOME_BOOL, SOME_STRING, \"diff\", SOME_STRING, SOME_INT, SOME_INT,\n-                    SOME_STRING)\n+                    SOME_STRING, summaries)\n             )\n             .addEqualityGroup(\n                 new SourceDescription(\n                     SOME_STRING, Optional.empty(), readQueries, writeQueries, fields, SOME_STRING,\n                     SOME_STRING, SOME_STRING, SOME_STRING,\n                     SOME_BOOL, SOME_STRING, SOME_STRING, \"diff\", SOME_INT, SOME_INT,\n-                    SOME_STRING)\n+                    SOME_STRING, summaries)\n             )\n             .addEqualityGroup(\n                 new SourceDescription(\n                     SOME_STRING, Optional.empty(), readQueries, writeQueries, fields, SOME_STRING,\n                     SOME_STRING, SOME_STRING, SOME_STRING,\n                     SOME_BOOL, SOME_STRING, SOME_STRING, SOME_STRING, SOME_INT + 1, SOME_INT,\n-                    SOME_STRING)\n+                    SOME_STRING, summaries)\n             )\n             .addEqualityGroup(\n                 new SourceDescription(\n                     SOME_STRING, Optional.empty(), readQueries, writeQueries, fields, SOME_STRING,\n                     SOME_STRING, SOME_STRING, SOME_STRING,\n                     SOME_BOOL, SOME_STRING, SOME_STRING, SOME_STRING, SOME_INT, SOME_INT + 1,\n-                    SOME_STRING)\n+                    SOME_STRING, summaries)\n             )\n             .addEqualityGroup(\n                 new SourceDescription(\n                     SOME_STRING, Optional.empty(), readQueries, writeQueries, fields, SOME_STRING,\n                     SOME_STRING, SOME_STRING, SOME_STRING,\n                     SOME_BOOL, SOME_STRING, SOME_STRING, SOME_STRING, SOME_INT, SOME_INT,\n-                    \"diff\")\n+                    \"diff\", summaries)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "086c4b0be3b8a22ac7e23d2d1a6e1e19d22dd795"}, "originalPosition": 155}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA2MTEwOA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                          .orElse(-1)));\n          \n          \n            \n                          .orElse(0)));\n          \n      \n    \n    \n  \n\n??", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r463061108", "createdAt": "2020-07-30T14:59:59Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java", "diffHunk": "@@ -614,6 +616,33 @@ private void printSourceDescription(final SourceDescription source) {\n         \"Statistics of the local KSQL server interaction with the Kafka topic \"\n             + source.getTopic()\n     ));\n+    for (QueryOffsetSummary queryOffsetSummary : source.getQueryOffsetSummaries()) {\n+      writer().println();\n+      writer().println(String.format(\"%-20s : %s\",\n+          \"Consumer Group\", queryOffsetSummary.getGroupId()));\n+      writer().println(String.format(\"%-20s : %s\",\n+          \"Kafka topic\", queryOffsetSummary.getKafkaTopic()));\n+      writer().println(String.format(\"%-20s : %s\",\n+          \"Max lag\", queryOffsetSummary.getOffsets().stream()\n+              .mapToLong(s -> s.getLogEndOffset() - s.getConsumerOffset())\n+              .max()\n+              .orElse(-1)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "086c4b0be3b8a22ac7e23d2d1a6e1e19d22dd795"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA2NDA0MQ==", "bodyText": "Rather than adding a whole new test, just enhance shouldPrintTopicDescribeExtended a non-empty list in as the last parameter of the SourceDescriptionEntity constructor.", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r463064041", "createdAt": "2020-07-30T15:03:54Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-cli/src/test/java/io/confluent/ksql/cli/console/ConsoleTest.java", "diffHunk": "@@ -1135,6 +1139,175 @@ public void testPrintExecuptionPlan() {\n     }\n   }\n \n+  @Test\n+  public void shouldPrintTopicDescribeExtendedWithConsumerOffsets() {\n+    // Given:\n+    final List<RunningQuery> readQueries = ImmutableList.of(\n+        new RunningQuery(\"read query\", ImmutableSet.of(\"sink1\"), ImmutableSet.of(\"sink1 topic\"), new QueryId(\"readId\"), queryStatusCount, KsqlConstants.KsqlQueryType.PERSISTENT)\n+    );\n+    final List<RunningQuery> writeQueries = ImmutableList.of(\n+        new RunningQuery(\"write query\", ImmutableSet.of(\"sink2\"), ImmutableSet.of(\"sink2 topic\"), new QueryId(\"writeId\"), queryStatusCount, KsqlConstants.KsqlQueryType.PERSISTENT)\n+    );\n+\n+    final KsqlEntityList entityList = new KsqlEntityList(ImmutableList.of(\n+        new SourceDescriptionEntity(\n+            \"e\",\n+            new SourceDescription(\n+                \"TestSource\",\n+                Optional.empty(),\n+                readQueries,\n+                writeQueries,\n+                buildTestSchema(SqlTypes.STRING),\n+                DataSourceType.KTABLE.getKsqlType(),\n+                \"2000-01-01\",\n+                \"stats\",\n+                \"errors\",\n+                true,\n+                \"kafka\",\n+                \"avro\",\n+                \"kadka-topic\",\n+                2, 1,\n+                \"sql statement text\",\n+                ImmutableList.of(\n+                    new QueryOffsetSummary(\n+                        \"consumer1\",\n+                        \"kadka-topic\",\n+                        ImmutableList.of(\n+                            new ConsumerPartitionOffsets(0, 100, 900, 800),\n+                            new ConsumerPartitionOffsets(1, 50, 900, 900)\n+                        ))\n+                )),\n+            Collections.emptyList()\n+        ))\n+    );\n+\n+    // When:\n+    console.printKsqlEntityList(entityList);\n+\n+    // Then:\n+    final String output = terminal.getOutputString();\n+    if (console.getOutputFormat() == OutputFormat.JSON) {\n+      assertThat(output, is(\"[ {\" + NEWLINE\n+          + \"  \\\"@type\\\" : \\\"sourceDescription\\\",\" + NEWLINE\n+          + \"  \\\"statementText\\\" : \\\"e\\\",\" + NEWLINE\n+          + \"  \\\"sourceDescription\\\" : {\" + NEWLINE\n+          + \"    \\\"name\\\" : \\\"TestSource\\\",\" + NEWLINE\n+          + \"    \\\"windowType\\\" : null,\" + NEWLINE\n+          + \"    \\\"readQueries\\\" : [ {\" + NEWLINE\n+          + \"      \\\"queryString\\\" : \\\"read query\\\",\" + NEWLINE\n+          + \"      \\\"sinks\\\" : [ \\\"sink1\\\" ],\" + NEWLINE\n+          + \"      \\\"sinkKafkaTopics\\\" : [ \\\"sink1 topic\\\" ],\" + NEWLINE\n+          + \"      \\\"id\\\" : \\\"readId\\\",\" + NEWLINE\n+          + \"      \\\"statusCount\\\" : {\" + NEWLINE\n+          + \"        \\\"RUNNING\\\" : 1,\" + NEWLINE\n+          + \"        \\\"ERROR\\\" : 2\" + NEWLINE\n+          + \"      },\" + NEWLINE\n+          + \"      \\\"queryType\\\" : \\\"PERSISTENT\\\",\" + NEWLINE\n+          + \"      \\\"state\\\" : \\\"\" + AGGREGATE_STATUS +\"\\\"\" + NEWLINE\n+          + \"    } ],\" + NEWLINE\n+          + \"    \\\"writeQueries\\\" : [ {\" + NEWLINE\n+          + \"      \\\"queryString\\\" : \\\"write query\\\",\" + NEWLINE\n+          + \"      \\\"sinks\\\" : [ \\\"sink2\\\" ],\" + NEWLINE\n+          + \"      \\\"sinkKafkaTopics\\\" : [ \\\"sink2 topic\\\" ],\" + NEWLINE\n+          + \"      \\\"id\\\" : \\\"writeId\\\",\" + NEWLINE\n+          + \"      \\\"statusCount\\\" : {\" + NEWLINE\n+          + \"        \\\"RUNNING\\\" : 1,\" + NEWLINE\n+          + \"        \\\"ERROR\\\" : 2\" + NEWLINE\n+          + \"      },\" + NEWLINE\n+          + \"      \\\"queryType\\\" : \\\"PERSISTENT\\\",\" + NEWLINE\n+          + \"      \\\"state\\\" : \\\"\" + AGGREGATE_STATUS +\"\\\"\" + NEWLINE\n+          + \"    } ],\" + NEWLINE\n+          + \"    \\\"fields\\\" : [ {\" + NEWLINE\n+          + \"      \\\"name\\\" : \\\"ROWKEY\\\",\" + NEWLINE\n+          + \"      \\\"schema\\\" : {\" + NEWLINE\n+          + \"        \\\"type\\\" : \\\"STRING\\\",\" + NEWLINE\n+          + \"        \\\"fields\\\" : null,\" + NEWLINE\n+          + \"        \\\"memberSchema\\\" : null\" + NEWLINE\n+          + \"      },\" + NEWLINE\n+          + \"      \\\"type\\\" : \\\"KEY\\\"\" + NEWLINE\n+          + \"    }, {\" + NEWLINE\n+          + \"      \\\"name\\\" : \\\"f_0\\\",\" + NEWLINE\n+          + \"      \\\"schema\\\" : {\" + NEWLINE\n+          + \"        \\\"type\\\" : \\\"STRING\\\",\" + NEWLINE\n+          + \"        \\\"fields\\\" : null,\" + NEWLINE\n+          + \"        \\\"memberSchema\\\" : null\" + NEWLINE\n+          + \"      }\" + NEWLINE\n+          + \"    } ],\" + NEWLINE\n+          + \"    \\\"type\\\" : \\\"TABLE\\\",\" + NEWLINE\n+          + \"    \\\"timestamp\\\" : \\\"2000-01-01\\\",\" + NEWLINE\n+          + \"    \\\"statistics\\\" : \\\"stats\\\",\" + NEWLINE\n+          + \"    \\\"errorStats\\\" : \\\"errors\\\",\" + NEWLINE\n+          + \"    \\\"extended\\\" : true,\" + NEWLINE\n+          + \"    \\\"keyFormat\\\" : \\\"kafka\\\",\" + NEWLINE\n+          + \"    \\\"valueFormat\\\" : \\\"avro\\\",\" + NEWLINE\n+          + \"    \\\"topic\\\" : \\\"kadka-topic\\\",\" + NEWLINE\n+          + \"    \\\"partitions\\\" : 2,\" + NEWLINE\n+          + \"    \\\"replication\\\" : 1,\" + NEWLINE\n+          + \"    \\\"statement\\\" : \\\"sql statement text\\\",\" + NEWLINE\n+          + \"    \\\"queryOffsetSummaries\\\" : [ {\" + NEWLINE\n+          + \"      \\\"groupId\\\" : \\\"consumer1\\\",\" + NEWLINE\n+          + \"      \\\"kafkaTopic\\\" : \\\"kadka-topic\\\",\" + NEWLINE\n+          + \"      \\\"offsets\\\" : [ {\" + NEWLINE\n+          + \"        \\\"partition\\\" : 0,\" + NEWLINE\n+          + \"        \\\"logStartOffset\\\" : 100,\" + NEWLINE\n+          + \"        \\\"logEndOffset\\\" : 900,\" + NEWLINE\n+          + \"        \\\"consumerOffset\\\" : 800\" + NEWLINE\n+          + \"      }, {\" + NEWLINE\n+          + \"        \\\"partition\\\" : 1,\" + NEWLINE\n+          + \"        \\\"logStartOffset\\\" : 50,\" + NEWLINE\n+          + \"        \\\"logEndOffset\\\" : 900,\" + NEWLINE\n+          + \"        \\\"consumerOffset\\\" : 900\" + NEWLINE\n+          + \"      } ]\" + NEWLINE\n+          + \"    } ]\" + NEWLINE\n+          + \"  },\" + NEWLINE\n+          + \"  \\\"warnings\\\" : [ ]\" + NEWLINE\n+          + \"} ]\" + NEWLINE));\n+    } else {\n+      assertThat(output, is(\"\" + NEWLINE\n+          + \"Name                 : TestSource\" + NEWLINE\n+          + \"Type                 : TABLE\" + NEWLINE\n+          + \"Timestamp field      : 2000-01-01\" + NEWLINE\n+          + \"Key format           : kafka\" + NEWLINE\n+          + \"Value format         : avro\" + NEWLINE\n+          + \"Kafka topic          : kadka-topic (partitions: 2, replication: 1)\" + NEWLINE\n+          + \"Statement            : sql statement text\" + NEWLINE\n+          + \"\" + NEWLINE\n+          + \" Field  | Type                           \" + NEWLINE\n+          + \"-----------------------------------------\" + NEWLINE\n+          + \" ROWKEY | VARCHAR(STRING)  (primary key) \" + NEWLINE\n+          + \" f_0    | VARCHAR(STRING)                \" + NEWLINE\n+          + \"-----------------------------------------\" + NEWLINE\n+          + \"\" + NEWLINE\n+          + \"Queries that read from this TABLE\" + NEWLINE\n+          + \"-----------------------------------\" + NEWLINE\n+          + \"readId (\" + AGGREGATE_STATUS +\") : read query\" + NEWLINE\n+          + \"\\n\"\n+          + \"For query topology and execution plan please run: EXPLAIN <QueryId>\" + NEWLINE\n+          + \"\" + NEWLINE\n+          + \"Queries that write from this TABLE\" + NEWLINE\n+          + \"-----------------------------------\" + NEWLINE\n+          + \"writeId (\" + AGGREGATE_STATUS + \") : write query\" + NEWLINE\n+          + \"\\n\"\n+          + \"For query topology and execution plan please run: EXPLAIN <QueryId>\" + NEWLINE\n+          + \"\" + NEWLINE\n+          + \"Local runtime statistics\" + NEWLINE\n+          + \"------------------------\" + NEWLINE\n+          + \"stats\" + NEWLINE\n+          + \"errors\" + NEWLINE\n+          + \"(Statistics of the local KSQL server interaction with the Kafka topic kadka-topic)\" + NEWLINE\n+          + NEWLINE\n+          + \"Consumer Group       : consumer1\" + NEWLINE\n+          + \"Kafka topic          : kadka-topic\" + NEWLINE\n+          + \"Max lag              : 100\" + NEWLINE\n+          + NEWLINE\n+          + \" Partition | Start Offset | End Offset | Offset | Lag \" + NEWLINE\n+          + \"------------------------------------------------------\" + NEWLINE\n+          + \" 0         | 100          | 900        | 800    | 100 \" + NEWLINE\n+          + \" 1         | 50           | 900        | 900    | 0   \" + NEWLINE\n+          + \"------------------------------------------------------\" + NEWLINE));\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "086c4b0be3b8a22ac7e23d2d1a6e1e19d22dd795"}, "originalPosition": 221}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA2NzE1NQ==", "bodyText": "This inheritance smells!  A group is not a topic. So why inherit from TopicAuthorizationException?  Maybe consider inheriting from GroupAuthorizationException?", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r463067155", "createdAt": "2020-07-30T15:08:24Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/exception/KsqlGroupAuthorizationException.java", "diffHunk": "@@ -0,0 +1,36 @@\n+/*\n+ * Copyright 2019 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.exception;\n+\n+import org.apache.commons.lang3.StringUtils;\n+import org.apache.kafka.common.acl.AclOperation;\n+import org.apache.kafka.common.errors.TopicAuthorizationException;\n+\n+/**\n+ * Used to return custom error messages when TopicAuthorizationException returned from Kafka\n+ */\n+public class KsqlGroupAuthorizationException extends TopicAuthorizationException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "086c4b0be3b8a22ac7e23d2d1a6e1e19d22dd795"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA2OTIwOA==", "bodyText": "sourceQueries and sinkQueries may be a little counterintuitive.  Can you rename sourceQueries -> readQueries, i.e. queries that read from this source and sinkQueries -> writeQueries i.e. queries that write to this source.", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r463069208", "createdAt": "2020-07-30T15:11:22Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListSourceExecutor.java", "diffHunk": "@@ -191,13 +213,21 @@ private static SourceDescriptionWithWarnings describeSource(\n       ), statementText);\n     }\n \n-    Optional<org.apache.kafka.clients.admin.TopicDescription> topicDescription = Optional.empty();\n+    final List<RunningQuery> sourceQueries = getQueries(ksqlEngine,\n+        q -> q.getSourceNames().contains(dataSource.getName()));\n+    final List<RunningQuery> sinkQueries = getQueries(ksqlEngine,\n+        q -> q.getSinkName().equals(dataSource.getName()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "086c4b0be3b8a22ac7e23d2d1a6e1e19d22dd795"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA3ODk5Mw==", "bodyText": "Under what situations would this be null?", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r463078993", "createdAt": "2020-07-30T15:24:54Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListSourceExecutor.java", "diffHunk": "@@ -208,13 +238,86 @@ private static SourceDescriptionWithWarnings describeSource(\n         SourceDescriptionFactory.create(\n             dataSource,\n             extended,\n-            getQueries(ksqlEngine, q -> q.getSourceNames().contains(dataSource.getName())),\n-            getQueries(ksqlEngine, q -> q.getSinkName().equals(dataSource.getName())),\n-            topicDescription\n+            sourceQueries,\n+            sinkQueries,\n+            topicDescription,\n+            sourceConsumerOffsets\n         )\n     );\n   }\n \n+  private static List<QueryOffsetSummary> offsetSummaries(\n+      final KsqlConfig ksqlConfig,\n+      final ServiceContext serviceContext,\n+      final List<RunningQuery> sinkQueries\n+  ) {\n+    final List<QueryOffsetSummary> sourceConsumerOffsets = new ArrayList<>();\n+    final Map<String, Map<TopicPartition, OffsetAndMetadata>> offsetsPerQuery =\n+        new HashMap<>(sinkQueries.size());\n+    final Map<String, Set<String>> topicsPerQuery = new HashMap<>();\n+    final Set<String> allTopics = new HashSet<>();\n+    // Get topics and offsets per running query\n+    for (RunningQuery query : sinkQueries) {\n+      final QueryId queryId = query.getId();\n+      final String applicationId =\n+          QueryApplicationId.build(ksqlConfig, true, queryId);\n+      final Map<TopicPartition, OffsetAndMetadata> topicAndConsumerOffsets =\n+          serviceContext.getConsumerGroupClient().listConsumerGroupOffsets(applicationId);\n+      offsetsPerQuery.put(applicationId, topicAndConsumerOffsets);\n+      final Set<String> topics = topicAndConsumerOffsets.keySet().stream()\n+          .map(TopicPartition::topic)\n+          .collect(Collectors.toSet());\n+      topicsPerQuery.put(applicationId, topics);\n+      allTopics.addAll(topics);\n+    }\n+    // Get topics descriptions and start/end offsets\n+    final Map<String, TopicDescription> sourceTopicDescriptions =\n+        serviceContext.getTopicClient().describeTopics(allTopics);\n+    final Map<TopicPartition, Long> topicAndStartOffsets =\n+        serviceContext.getTopicClient().listTopicsStartOffsets(allTopics);\n+    final Map<TopicPartition, Long> topicAndEndOffsets =\n+        serviceContext.getTopicClient().listTopicsEndOffsets(allTopics);\n+    // Build consumer offsets summary\n+    for (Entry<String, Set<String>> entry : topicsPerQuery.entrySet()) {\n+      for (String topic : entry.getValue()) {\n+        sourceConsumerOffsets.add(\n+            new QueryOffsetSummary(\n+                entry.getKey(),\n+                topic,\n+                consumerPartitionOffsets(\n+                    sourceTopicDescriptions.get(topic),\n+                    topicAndStartOffsets,\n+                    topicAndEndOffsets,\n+                    offsetsPerQuery.get(entry.getKey()))));\n+      }\n+    }\n+    return sourceConsumerOffsets;\n+  }\n+\n+  private static List<ConsumerPartitionOffsets> consumerPartitionOffsets(\n+      final TopicDescription topicDescription,\n+      final Map<TopicPartition, Long> topicAndStartOffsets,\n+      final Map<TopicPartition, Long> topicAndEndOffsets,\n+      final Map<TopicPartition, OffsetAndMetadata> topicAndConsumerOffsets\n+  ) {\n+    final List<ConsumerPartitionOffsets> consumerPartitionOffsets = new ArrayList<>();\n+    for (TopicPartitionInfo topicPartitionInfo : topicDescription.partitions()) {\n+      final TopicPartition tp = new TopicPartition(topicDescription.name(),\n+          topicPartitionInfo.partition());\n+      final Long startOffsetResultInfo = topicAndStartOffsets.get(tp);\n+      final Long endOffsetResultInfo = topicAndEndOffsets.get(tp);\n+      final OffsetAndMetadata offsetAndMetadata = topicAndConsumerOffsets.get(tp);\n+      consumerPartitionOffsets.add(\n+          new ConsumerPartitionOffsets(\n+              topicPartitionInfo.partition(),\n+              startOffsetResultInfo,\n+              endOffsetResultInfo,\n+              offsetAndMetadata != null ? offsetAndMetadata.offset() : 0", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "086c4b0be3b8a22ac7e23d2d1a6e1e19d22dd795"}, "originalPosition": 198}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA3OTU3MA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                List<QueryOffsetSummary> sourceConsumerOffsets = new ArrayList<>();\n          \n          \n            \n                List<QueryOffsetSummary> queryOffsetSummaries = new ArrayList<>();", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r463079570", "createdAt": "2020-07-30T15:25:43Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListSourceExecutor.java", "diffHunk": "@@ -191,13 +213,21 @@ private static SourceDescriptionWithWarnings describeSource(\n       ), statementText);\n     }\n \n-    Optional<org.apache.kafka.clients.admin.TopicDescription> topicDescription = Optional.empty();\n+    final List<RunningQuery> sourceQueries = getQueries(ksqlEngine,\n+        q -> q.getSourceNames().contains(dataSource.getName()));\n+    final List<RunningQuery> sinkQueries = getQueries(ksqlEngine,\n+        q -> q.getSinkName().equals(dataSource.getName()));\n+\n+    Optional<org.apache.kafka.clients.admin.TopicDescription> topicDescription =\n+        Optional.empty();\n+    List<QueryOffsetSummary> sourceConsumerOffsets = new ArrayList<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "086c4b0be3b8a22ac7e23d2d1a6e1e19d22dd795"}, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzA3OTY1OA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                final List<QueryOffsetSummary> sourceConsumerOffsets = new ArrayList<>();\n          \n          \n            \n                final List<QueryOffsetSummary> queryOffsetSummaries = new ArrayList<>();", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r463079658", "createdAt": "2020-07-30T15:25:51Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-rest-app/src/main/java/io/confluent/ksql/rest/server/execution/ListSourceExecutor.java", "diffHunk": "@@ -208,13 +238,86 @@ private static SourceDescriptionWithWarnings describeSource(\n         SourceDescriptionFactory.create(\n             dataSource,\n             extended,\n-            getQueries(ksqlEngine, q -> q.getSourceNames().contains(dataSource.getName())),\n-            getQueries(ksqlEngine, q -> q.getSinkName().equals(dataSource.getName())),\n-            topicDescription\n+            sourceQueries,\n+            sinkQueries,\n+            topicDescription,\n+            sourceConsumerOffsets\n         )\n     );\n   }\n \n+  private static List<QueryOffsetSummary> offsetSummaries(\n+      final KsqlConfig ksqlConfig,\n+      final ServiceContext serviceContext,\n+      final List<RunningQuery> sinkQueries\n+  ) {\n+    final List<QueryOffsetSummary> sourceConsumerOffsets = new ArrayList<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "086c4b0be3b8a22ac7e23d2d1a6e1e19d22dd795"}, "originalPosition": 137}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "400d80a95e1e1a04d15cf0d356b26d581511f8ae", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/400d80a95e1e1a04d15cf0d356b26d581511f8ae", "committedDate": "2020-08-05T12:42:46Z", "message": "Apply suggestions from code review\n\nCo-authored-by: Andy Coates <8012398+big-andy-coates@users.noreply.github.com>"}, "afterCommit": {"oid": "f63b2c07befd90df020b6cac091124b56bc2b958", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/f63b2c07befd90df020b6cac091124b56bc2b958", "committedDate": "2020-08-05T12:40:32Z", "message": "fix call to sourcedescription"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDYyNDgxNjY5", "url": "https://github.com/confluentinc/ksql/pull/5476#pullrequestreview-462481669", "createdAt": "2020-08-06T12:44:40Z", "commit": {"oid": "cafb125bb984eb42c39002b01d1251dbbe4e0191"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQxMjo0NDo0MVrOG8x3NA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQxMjo0NDo0MVrOG8x3NA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjM4NDY5Mg==", "bodyText": "Would be good to have some kind of heading here, e.g.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                for (QueryOffsetSummary queryOffsetSummary : source.getQueryOffsetSummaries()) {\n          \n          \n            \n                writer().println(\"Consumers:\");\n          \n          \n            \n                writer().println(\"\");\n          \n          \n            \n                \n          \n          \n            \n                for (QueryOffsetSummary queryOffsetSummary : source.getQueryOffsetSummaries()) {", "url": "https://github.com/confluentinc/ksql/pull/5476#discussion_r466384692", "createdAt": "2020-08-06T12:44:41Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-cli/src/main/java/io/confluent/ksql/cli/console/Console.java", "diffHunk": "@@ -614,6 +616,33 @@ private void printSourceDescription(final SourceDescription source) {\n         \"Statistics of the local KSQL server interaction with the Kafka topic \"\n             + source.getTopic()\n     ));\n+    for (QueryOffsetSummary queryOffsetSummary : source.getQueryOffsetSummaries()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cafb125bb984eb42c39002b01d1251dbbe4e0191"}, "originalPosition": 49}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "27a04e02910eb07c59c98451804a4f39f59b2b4b", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/27a04e02910eb07c59c98451804a4f39f59b2b4b", "committedDate": "2020-08-07T09:30:37Z", "message": "introduce source consumer offsets"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b02f1f93f79992989e435e2caec6ea6024c1dddb", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/b02f1f93f79992989e435e2caec6ea6024c1dddb", "committedDate": "2020-08-07T09:30:37Z", "message": "successfully build a response"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fba70db82dfaf34fe4dff1756d5336328f265958", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/fba70db82dfaf34fe4dff1756d5336328f265958", "committedDate": "2020-08-07T09:30:38Z", "message": "feature working"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9eefb4a20978e17a71e10c332f81d66e392e72b7", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/9eefb4a20978e17a71e10c332f81d66e392e72b7", "committedDate": "2020-08-07T09:30:38Z", "message": "enforce offsets only for sources"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9f41e5d2a79fc803c350ff378ec43d2bf28a72bf", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/9f41e5d2a79fc803c350ff378ec43d2bf28a72bf", "committedDate": "2020-08-07T09:30:38Z", "message": "add unit tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "26678084932bbbc8fb438735f93c6e0254d5927a", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/26678084932bbbc8fb438735f93c6e0254d5927a", "committedDate": "2020-08-07T09:30:39Z", "message": "fix: apply checkstyle feedback"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "67923114cabb2dc37fce00fce1814e4f04e743d3", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/67923114cabb2dc37fce00fce1814e4f04e743d3", "committedDate": "2020-08-07T09:30:39Z", "message": "fix: remove unused import"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "14a30b7216e3b6ec380e96315a3855c34e304679", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/14a30b7216e3b6ec380e96315a3855c34e304679", "committedDate": "2020-08-07T09:30:39Z", "message": "fix: replace appId mapping based on QueryExecutor"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b11860838678b54da7181fd1f44cadbb67fd5acd", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/b11860838678b54da7181fd1f44cadbb67fd5acd", "committedDate": "2020-08-07T09:30:39Z", "message": "fix: checkstyle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fd1d86a2ba641d9359e79e8761882c3d1a4bb0d9", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/fd1d86a2ba641d9359e79e8761882c3d1a4bb0d9", "committedDate": "2020-08-07T09:30:40Z", "message": "refactor"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a4386209baca380208340e9d2cf0596d832f18ad", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/a4386209baca380208340e9d2cf0596d832f18ad", "committedDate": "2020-08-07T09:30:40Z", "message": "chore: add final"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0a1ce04abe0d090a3d5fda2447f0b6758e6bcac0", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/0a1ce04abe0d090a3d5fda2447f0b6758e6bcac0", "committedDate": "2020-08-07T09:30:40Z", "message": "elevate consumer group client to service\n\nreuse existing client to support list cg offsets"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "074849bfec34e4dd666a51d45cd6a60cc8131247", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/074849bfec34e4dd666a51d45cd6a60cc8131247", "committedDate": "2020-08-07T09:30:40Z", "message": "fix: checkstyle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "309e3dc7aa25b5983060acce6e80cf7007f97336", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/309e3dc7aa25b5983060acce6e80cf7007f97336", "committedDate": "2020-08-07T09:30:41Z", "message": "fix: checkstyle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "708da6ea057ed963f39385f21287f237d28e0f41", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/708da6ea057ed963f39385f21287f237d28e0f41", "committedDate": "2020-08-07T09:30:41Z", "message": "fix: failing sandboxed tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "51c3beff0c8245fa19502899d1234a6ea2452378", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/51c3beff0c8245fa19502899d1234a6ea2452378", "committedDate": "2020-08-07T09:30:41Z", "message": "fix: more failing sandboxed tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a9d3a4f9e3ca2cabf3d3c7823bf503125e86abcc", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/a9d3a4f9e3ca2cabf3d3c7823bf503125e86abcc", "committedDate": "2020-08-07T09:30:41Z", "message": "fix: renaming to cg"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "96915c369eced97b26670e959e4bd9a08bf9429c", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/96915c369eced97b26670e959e4bd9a08bf9429c", "committedDate": "2020-08-07T09:30:42Z", "message": "fix: moar checkstyling"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cf2f9898472152e407a96ca2ba1a5f4f7fa76ed9", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/cf2f9898472152e407a96ca2ba1a5f4f7fa76ed9", "committedDate": "2020-08-07T09:30:42Z", "message": "fix: moar checkstyling"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9d90b2474082e1da6467730bd6518d1b98445780", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/9d90b2474082e1da6467730bd6518d1b98445780", "committedDate": "2020-08-07T09:30:42Z", "message": "replace linked for hashmap"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8ce48c55db5bb8ecf0ac9a814dcf3be36cacd258", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/8ce48c55db5bb8ecf0ac9a814dcf3be36cacd258", "committedDate": "2020-08-07T09:30:42Z", "message": "from optional to list of offsets"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "72e1de8935ed1fe9cd94569dce875782cdc2090a", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/72e1de8935ed1fe9cd94569dce875782cdc2090a", "committedDate": "2020-08-07T09:30:43Z", "message": "fix topic description empty when no sources"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "84b17606bf5634b962e2349e97f9f0d194b72fc3", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/84b17606bf5634b962e2349e97f9f0d194b72fc3", "committedDate": "2020-08-07T09:30:43Z", "message": "abstract getServiceId for reusage"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d6b8c0ddd63b800bfbbc72ffc30bfc819b3d99c4", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/d6b8c0ddd63b800bfbbc72ffc30bfc819b3d99c4", "committedDate": "2020-08-07T09:30:43Z", "message": "fix checkstyle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8409f2c3178d1ccdd4141ef1abdf9f5af5cef0ee", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/8409f2c3178d1ccdd4141ef1abdf9f5af5cef0ee", "committedDate": "2020-08-07T09:30:44Z", "message": "turn to static"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8eaa8e1362825d9fd1d30ac617943adb0fff9d7d", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/8eaa8e1362825d9fd1d30ac617943adb0fff9d7d", "committedDate": "2020-08-07T09:30:44Z", "message": "improve authz exception handling\n\nCo-authored-by: Andy Coates <8012398+big-andy-coates@users.noreply.github.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fb0450ec54c6a5fd46e72fdf99bb1084c4e22949", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/fb0450ec54c6a5fd46e72fdf99bb1084c4e22949", "committedDate": "2020-08-07T09:30:44Z", "message": "refactor describe based on sink queries;"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ff6515ac66d1f6e34612a8c32f9602d1fffe3924", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/ff6515ac66d1f6e34612a8c32f9602d1fffe3924", "committedDate": "2020-08-07T09:30:45Z", "message": "apply andys feedback"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "43ba2f5218f49f4b55bf0e1ad9c933297b49da95", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/43ba2f5218f49f4b55bf0e1ad9c933297b49da95", "committedDate": "2020-08-07T09:30:45Z", "message": "fix checkstyle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2eba55b1d575f5a915cd815c8174631b05a0a809", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/2eba55b1d575f5a915cd815c8174631b05a0a809", "committedDate": "2020-08-07T09:30:45Z", "message": "rename to represent offsets better"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "567af3dcb8eea3151a0cead3fc48d2afed2e9fb7", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/567af3dcb8eea3151a0cead3fc48d2afed2e9fb7", "committedDate": "2020-08-07T09:30:46Z", "message": "fix: checkstyle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3824c1c636e304f64c02c4ba3c263af2601483c5", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/3824c1c636e304f64c02c4ba3c263af2601483c5", "committedDate": "2020-08-07T09:30:46Z", "message": "fix: checkstyle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f914c1cb31f3eef6067047ce13d6efe9bf62112e", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/f914c1cb31f3eef6067047ce13d6efe9bf62112e", "committedDate": "2020-08-07T09:30:46Z", "message": "fix sandboxed topic client mapping test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9cfb380900843ae3557d25d9d2087d218e3bc1d7", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/9cfb380900843ae3557d25d9d2087d218e3bc1d7", "committedDate": "2020-08-07T09:30:46Z", "message": "nit: rename back var"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "adccb696823a8356b17589132e8c38fa95d91588", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/adccb696823a8356b17589132e8c38fa95d91588", "committedDate": "2020-08-07T09:30:46Z", "message": "more renaming"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7c6f6f935d56778fc37fb81e6d0195feb910f255", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/7c6f6f935d56778fc37fb81e6d0195feb910f255", "committedDate": "2020-08-07T09:30:47Z", "message": "test sourceDescription"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "65fc9c7140c7f9657ca00b58652a24606718578e", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/65fc9c7140c7f9657ca00b58652a24606718578e", "committedDate": "2020-08-07T09:30:47Z", "message": "test kafka consumer group client"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5aad5c9d23cf72edd3357a81b9d38b9f0554f9c8", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/5aad5c9d23cf72edd3357a81b9d38b9f0554f9c8", "committedDate": "2020-08-07T09:30:47Z", "message": "test kafka topic client list offsets"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4fb003ca9174b9b1ddd61ae80abb68607a1781f8", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/4fb003ca9174b9b1ddd61ae80abb68607a1781f8", "committedDate": "2020-08-07T09:30:48Z", "message": "add preconditions for offsets"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7155b67f142fe217eb50c80a2d8666088427959a", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/7155b67f142fe217eb50c80a2d8666088427959a", "committedDate": "2020-08-07T09:30:48Z", "message": "improve exception msg"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ae505f884a269809fb8cfea600af5f45468a0cae", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/ae505f884a269809fb8cfea600af5f45468a0cae", "committedDate": "2020-08-07T09:30:48Z", "message": "fix preconditions"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c2657ff187a25e7785fe79a7bcf80bd61b28690c", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/c2657ff187a25e7785fe79a7bcf80bd61b28690c", "committedDate": "2020-08-07T09:30:48Z", "message": "fix call to sourcedescription"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "aa59da8f816644aa0bd0008444d229327cced13b", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/aa59da8f816644aa0bd0008444d229327cced13b", "committedDate": "2020-08-07T09:30:48Z", "message": "fix exception inheritance"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c75732d686bf570b6e6639a902766fd2707096f7", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/c75732d686bf570b6e6639a902766fd2707096f7", "committedDate": "2020-08-07T09:30:49Z", "message": "fix var naming"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0cbcefffddb85da52e6a226703271c9ebb68e17c", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/0cbcefffddb85da52e6a226703271c9ebb68e17c", "committedDate": "2020-08-07T09:30:49Z", "message": "comment when offset and meta == null"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d8063f189f40949742cdf0aa935478f222a7df91", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/d8063f189f40949742cdf0aa935478f222a7df91", "committedDate": "2020-08-07T09:30:49Z", "message": "move time suffix"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f1dad37e8ed5e6befeea8503252d9d9328ebc1e6", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/f1dad37e8ed5e6befeea8503252d9d9328ebc1e6", "committedDate": "2020-08-07T09:30:49Z", "message": "test query app id builder"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e6e4ab6cabeaa0404d2eb2d8d4c817fcf0d2e6c8", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/e6e4ab6cabeaa0404d2eb2d8d4c817fcf0d2e6c8", "committedDate": "2020-08-07T09:30:50Z", "message": "fix: remove commented out code"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bd0d51754929de356a0dafb1c112974255ad2563", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/bd0d51754929de356a0dafb1c112974255ad2563", "committedDate": "2020-08-07T09:30:50Z", "message": "validate objects non null"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fba0a7552fd7c0d16b9ba61c7ce120b46d9acfc0", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/fba0a7552fd7c0d16b9ba61c7ce120b46d9acfc0", "committedDate": "2020-08-07T09:30:50Z", "message": "add tests to list offsets"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e34555f99f830a34e0008cb85b6bf93789d90898", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/e34555f99f830a34e0008cb85b6bf93789d90898", "committedDate": "2020-08-07T09:30:50Z", "message": "add test when offsets differ"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "46c547306c6bda5652343f9c64ba7f8a993d2596", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/46c547306c6bda5652343f9c64ba7f8a993d2596", "committedDate": "2020-08-07T09:30:51Z", "message": "converge tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "04f517a6b9455e32256a07eab3566da62eef3b21", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/04f517a6b9455e32256a07eab3566da62eef3b21", "committedDate": "2020-08-07T09:30:51Z", "message": "fix checkstyle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "480e7c4c970cc0e87283f646166c42bd809abe8c", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/480e7c4c970cc0e87283f646166c42bd809abe8c", "committedDate": "2020-08-07T09:30:51Z", "message": "fix issues with long instantiation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c3f5eb44e00f0695aaa3ce706ed30902ae35b8da", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/c3f5eb44e00f0695aaa3ce706ed30902ae35b8da", "committedDate": "2020-08-07T09:30:51Z", "message": "fix checkstyle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dc97ede39b8d64bc19b668ae4c9a8261292035a9", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/dc97ede39b8d64bc19b668ae4c9a8261292035a9", "committedDate": "2020-08-07T09:30:52Z", "message": "map consumer groups to topics"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "03d0cfce38c81edb5b2b38d1d22a85c081aee471", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/03d0cfce38c81edb5b2b38d1d22a85c081aee471", "committedDate": "2020-08-07T09:30:52Z", "message": "fix console tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "32b3df5adb764f9741d45e07206467ab8bb7b287", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/32b3df5adb764f9741d45e07206467ab8bb7b287", "committedDate": "2020-08-07T09:30:52Z", "message": "add topic offsets summary"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8e4612f322e51f91f7874bd2e41a3bd678bbcf45", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/8e4612f322e51f91f7874bd2e41a3bd678bbcf45", "committedDate": "2020-08-07T09:30:52Z", "message": "fix unused import"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1976131610ecd78453962327ca4b87fb5148de71", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/1976131610ecd78453962327ca4b87fb5148de71", "committedDate": "2020-08-07T09:30:53Z", "message": "fix console test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6f213a86749a033019ae8a26932f999f27f6b800", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/6f213a86749a033019ae8a26932f999f27f6b800", "committedDate": "2020-08-07T10:50:00Z", "message": "fix json format"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "40fbd3ff53715ff793ca2744ea723fbab9dbf92a", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/40fbd3ff53715ff793ca2744ea723fbab9dbf92a", "committedDate": "2020-08-07T09:17:20Z", "message": "fix console test"}, "afterCommit": {"oid": "6f213a86749a033019ae8a26932f999f27f6b800", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/6f213a86749a033019ae8a26932f999f27f6b800", "committedDate": "2020-08-07T10:50:00Z", "message": "fix json format"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "40a484a21fbcb542ab8da24d80aa9562c05cd06d", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/40a484a21fbcb542ab8da24d80aa9562c05cd06d", "committedDate": "2020-08-07T11:38:39Z", "message": "fix groupId mapping"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "082b5d243b9c5bac48ba6406a91619046cea77fa", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/082b5d243b9c5bac48ba6406a91619046cea77fa", "committedDate": "2020-08-07T11:47:24Z", "message": "fix import"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ca007da99c0c787a346154a5c7f9b474cca1c163", "author": {"user": {"login": "jeqo", "name": "Jorge Esteban Quilcate Otoya"}}, "url": "https://github.com/confluentinc/ksql/commit/ca007da99c0c787a346154a5c7f9b474cca1c163", "committedDate": "2020-08-07T12:41:45Z", "message": "fix json order"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4679, "cost": 1, "resetAt": "2021-11-01T13:51:04Z"}}}