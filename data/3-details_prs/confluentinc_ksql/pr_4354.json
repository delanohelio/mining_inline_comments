{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzY0ODQ1NTE2", "number": 4354, "title": "feat: Integrate reactive streams TCK and improvements to our reactive streams implementations", "bodyText": "Description\nThis PR:\n\nAbstracts out our subscriber and publisher implementations into two classes: BufferedPublisher and ReactiveSubscriber which handle most of the streams plumbing and can be used used as the basis of other publisher/subscriber implementations.\nIntegrates the reactive streams TCK to help check that our implementations are spec compliant.\nIntroduces some more API tests\nIntroduces a couple of unit test classes for BufferedPublisher and ReactiveSubscriber (although the TCK does the bulk of the testing).\nVarious other bits of refactoring\nMore javadocs\nUpdated license headers to 2020\nA few other bits I'm sure\n\nTesting done\nTCK tests. More API tests. More unit tests.\nReviewer checklist\n\n Ensure docs are updated if necessary. (eg. if a user visible feature is being added or changed).\n Ensure relevant issues are linked (description should include text like \"Fixes #\")", "createdAt": "2020-01-20T13:53:40Z", "url": "https://github.com/confluentinc/ksql/pull/4354", "merged": true, "mergeCommit": {"oid": "0edfd2480f42167fe9b4065edcabe699348fa7cc"}, "closed": true, "closedAt": "2020-01-23T08:50:50Z", "author": {"login": "purplefox"}, "timelineItems": {"totalCount": 24, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABb7OAQsgH2gAyMzY0ODQ1NTE2OjJiMzliNzJiNzE5OTZhYjZhNzgwMTM3YzJmNGY5OTI2N2YwM2IzNDA=", "endCursor": "Y3Vyc29yOnYyOpPPAAABb9LF1JAFqTM0NzIwOTM5Mw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "2b39b72b71996ab6a780137c2f4f99267f03b340", "author": {"user": {"login": "purplefox", "name": "Tim Fox"}}, "url": "https://github.com/confluentinc/ksql/commit/2b39b72b71996ab6a780137c2f4f99267f03b340", "committedDate": "2020-01-17T12:35:25Z", "message": "interim"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0671d13b64724b4e35e8851de11442dfd39c0413", "author": {"user": {"login": "purplefox", "name": "Tim Fox"}}, "url": "https://github.com/confluentinc/ksql/commit/0671d13b64724b4e35e8851de11442dfd39c0413", "committedDate": "2020-01-17T12:35:25Z", "message": "resolved merge"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0164953725100a5753292720dd013f5579e555ff", "author": {"user": {"login": "purplefox", "name": "Tim Fox"}}, "url": "https://github.com/confluentinc/ksql/commit/0164953725100a5753292720dd013f5579e555ff", "committedDate": "2020-01-17T12:35:25Z", "message": "more work on publishers"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4367440274f10657dec181c040306fd846f8a05c", "author": {"user": {"login": "purplefox", "name": "Tim Fox"}}, "url": "https://github.com/confluentinc/ksql/commit/4367440274f10657dec181c040306fd846f8a05c", "committedDate": "2020-01-18T11:35:41Z", "message": "More work on reactive stuff"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ef199950a9c8e2e480f1548326705b19e58cbea9", "author": {"user": {"login": "purplefox", "name": "Tim Fox"}}, "url": "https://github.com/confluentinc/ksql/commit/ef199950a9c8e2e480f1548326705b19e58cbea9", "committedDate": "2020-01-18T20:03:59Z", "message": "Update copyright"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "04f84934f8cda8f2a7c3baf12a239d342deef0c0", "author": {"user": {"login": "purplefox", "name": "Tim Fox"}}, "url": "https://github.com/confluentinc/ksql/commit/04f84934f8cda8f2a7c3baf12a239d342deef0c0", "committedDate": "2020-01-19T11:42:16Z", "message": "Get puboisher passing tck"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "41d24c176c7093c2c6e03c2b136976594318e03c", "author": {"user": {"login": "purplefox", "name": "Tim Fox"}}, "url": "https://github.com/confluentinc/ksql/commit/41d24c176c7093c2c6e03c2b136976594318e03c", "committedDate": "2020-01-19T15:46:21Z", "message": "more tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0eab0ab4c49cc4bf71269ca3bc214c1975a63c42", "author": {"user": {"login": "purplefox", "name": "Tim Fox"}}, "url": "https://github.com/confluentinc/ksql/commit/0eab0ab4c49cc4bf71269ca3bc214c1975a63c42", "committedDate": "2020-01-20T13:01:18Z", "message": "More work on impl and tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "812a11345b13fe4bce4d475b20872719e2bcd1aa", "author": {"user": {"login": "purplefox", "name": "Tim Fox"}}, "url": "https://github.com/confluentinc/ksql/commit/812a11345b13fe4bce4d475b20872719e2bcd1aa", "committedDate": "2020-01-20T13:52:15Z", "message": "a few tweaks"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "71f0fc10af0c18608faac2f900eea3a53e39ef94", "author": {"user": {"login": "purplefox", "name": "Tim Fox"}}, "url": "https://github.com/confluentinc/ksql/commit/71f0fc10af0c18608faac2f900eea3a53e39ef94", "committedDate": "2020-01-20T14:43:05Z", "message": "some tests for malformed json etc"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "be3cc5863b16722aecd3975d70c75e146e4a0aff", "author": {"user": {"login": "purplefox", "name": "Tim Fox"}}, "url": "https://github.com/confluentinc/ksql/commit/be3cc5863b16722aecd3975d70c75e146e4a0aff", "committedDate": "2020-01-20T15:11:44Z", "message": "javadoc tweak"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "54485c924fdfca37dc2aa75ea1a301e66ed8612c", "author": {"user": {"login": "purplefox", "name": "Tim Fox"}}, "url": "https://github.com/confluentinc/ksql/commit/54485c924fdfca37dc2aa75ea1a301e66ed8612c", "committedDate": "2020-01-20T17:20:57Z", "message": "removed TODO"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8d5db75f4fd775899bb144ae2237b1a782edcb55", "author": {"user": {"login": "purplefox", "name": "Tim Fox"}}, "url": "https://github.com/confluentinc/ksql/commit/8d5db75f4fd775899bb144ae2237b1a782edcb55", "committedDate": "2020-01-20T17:49:35Z", "message": "Mainly javddoc"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7e1cf290e7ffcb04d6cadec0051706e18fce4a3b", "author": {"user": {"login": "purplefox", "name": "Tim Fox"}}, "url": "https://github.com/confluentinc/ksql/commit/7e1cf290e7ffcb04d6cadec0051706e18fce4a3b", "committedDate": "2020-01-20T18:40:24Z", "message": "some more tweaks"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3a18773a4d0249072ff66488df9ce2e115708525", "author": {"user": {"login": "purplefox", "name": "Tim Fox"}}, "url": "https://github.com/confluentinc/ksql/commit/3a18773a4d0249072ff66488df9ce2e115708525", "committedDate": "2020-01-20T21:22:48Z", "message": "fixed bug in batched delivery"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3ba0d8a04f8ce7312a273230cc748f14d7def04b", "author": {"user": {"login": "purplefox", "name": "Tim Fox"}}, "url": "https://github.com/confluentinc/ksql/commit/3ba0d8a04f8ce7312a273230cc748f14d7def04b", "committedDate": "2020-01-21T15:46:32Z", "message": "fixed race"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ2MjUzMzE3", "url": "https://github.com/confluentinc/ksql/pull/4354#pullrequestreview-346253317", "createdAt": "2020-01-21T23:05:17Z", "commit": {"oid": "3ba0d8a04f8ce7312a273230cc748f14d7def04b"}, "state": "COMMENTED", "comments": {"totalCount": 19, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMVQyMzowNToxOFrOFgLxfw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQwMToyMTowNlrOFgODLQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTI5MTY0Nw==", "bodyText": "is there any way to avoid the testNG dependency? I've found that having both in a project causes... confusion.\n\nThe TCK is implemented using plain Java (1.6) and TestNG tests, and should be possible to use from other JVM-based languages and testing libraries.", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369291647", "createdAt": "2020-01-21T23:05:18Z", "author": {"login": "agavra"}, "path": "ksql-api/pom.xml", "diffHunk": "@@ -93,6 +94,24 @@\n       <version>${project.version}</version>\n       <scope>test</scope>\n     </dependency>\n+    <dependency>\n+      <groupId>org.reactivestreams</groupId>\n+      <artifactId>reactive-streams-tck</artifactId>\n+      <version>${reactive-streams.version}</version>\n+      <scope>test</scope>\n+    </dependency>\n+    <dependency>\n+      <groupId>org.testng</groupId>\n+      <artifactId>testng</artifactId>\n+      <version>6.11</version>\n+      <scope>test</scope>\n+    </dependency>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ba0d8a04f8ce7312a273230cc748f14d7def04b"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMxMTEzOQ==", "bodyText": "it'd be nice to describe what this means and give an error message that's a little more actionable? What can cause this to happen?", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369311139", "createdAt": "2020-01-22T00:10:28Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ReactiveSubscriber.java", "diffHunk": "@@ -0,0 +1,176 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.Objects;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams subscriber which handles much of the plumbing for you. Override {@link\n+ * #afterSubscribe}, {@link #handleValue}, {@link #handleComplete} and {@link #handleError} to\n+ * create your specific implementation.\n+ *\n+ * @param <T> The type of the value\n+ */\n+public class ReactiveSubscriber<T> implements Subscriber<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ReactiveSubscriber.class);\n+\n+  protected final Context context;\n+  private Subscription subscription;\n+  private boolean complete;\n+\n+  /**\n+   * Construct a ReactiveSubscriber\n+   *\n+   * @param context The Vert.x context to use for the subscriber - the subscriber code will always\n+   *                be executed on this context. This ensures the code is never executed\n+   *                concurrently by more than one thread.\n+   */\n+  public ReactiveSubscriber(final Context context) {\n+    this.context = context;\n+  }\n+\n+  @Override\n+  public void onSubscribe(final Subscription s) {\n+    Objects.requireNonNull(s);\n+    context.runOnContext(v -> doOnSubscribe(s));\n+  }\n+\n+  @Override\n+  public void onNext(final T t) {\n+    Objects.requireNonNull(t);\n+    context.runOnContext(v -> doOnNext(t));\n+  }\n+\n+  @Override\n+  public void onError(final Throwable t) {\n+    Objects.requireNonNull(t);\n+    context.runOnContext(v -> doOnError(t));\n+  }\n+\n+  @Override\n+  public void onComplete() {\n+    context.runOnContext(v -> doOnComplete());\n+  }\n+\n+  protected void afterSubscribe(final Subscription subscription) {\n+  }\n+\n+  protected void handleValue(final T t) {\n+  }\n+\n+  protected void handleComplete() {\n+  }\n+\n+  protected void handleError(final Throwable t) {\n+  }\n+\n+  private void doOnSubscribe(final Subscription subscription) {\n+    checkContext();\n+    if (this.subscription != null) {\n+      try {\n+        // Cancel the new subscription\n+        subscription.cancel();\n+      } catch (final Throwable t) {\n+        final Exception e =\n+            new IllegalStateException(\"Exceptions must not be thrown from cancel\");\n+        logError(e);\n+      }\n+    }\n+    this.subscription = subscription;\n+    afterSubscribe(subscription);\n+  }\n+\n+  private void doOnNext(final T val) {\n+    checkContext();\n+    if (complete) {\n+      return;\n+    }\n+    if (subscription == null) {\n+      final Exception e = new IllegalStateException(\n+          \"onNext must be called without request being called\");\n+      logError(e);\n+    }\n+    try {\n+      handleValue(val);\n+    } catch (final Throwable t) {\n+      complete();\n+      onError(t);\n+    }\n+  }\n+\n+  private void doOnError(final Throwable t) {\n+    checkContext();\n+    if (subscription == null) {\n+      logError(new IllegalStateException(\"onError must not be called before onSubscribe\"));\n+    } else {\n+      complete = true;\n+      handleError(t);\n+    }\n+  }\n+\n+  private void doOnComplete() {\n+    checkContext();\n+    if (subscription == null) {\n+      logError(new IllegalStateException(\"onComplete must not be called before onSubscribe\"));\n+    } else {\n+      complete = true;\n+      handleComplete();\n+    }\n+  }\n+\n+  protected void makeRequest(final long l) {\n+    checkContext();\n+    try {\n+      subscription.request(l);\n+    } catch (Throwable t) {\n+      final Exception e =\n+          new IllegalStateException(\"Exceptions must not be thrown from request\");\n+      logError(e);\n+    }\n+  }\n+\n+  protected void complete() {\n+    checkContext();\n+    complete = true;\n+    if (subscription != null) {\n+      try {\n+        subscription.cancel();\n+      } catch (final Throwable t) {\n+        final Exception e =\n+            new IllegalStateException(\"Exceptions must not be thrown from cancel\");\n+        logError(e);\n+      }\n+    }\n+  }\n+\n+  protected void checkContext() {\n+    if (Vertx.currentContext() != context) {\n+      throw new IllegalStateException(\"On wrong context\");\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ba0d8a04f8ce7312a273230cc748f14d7def04b"}, "originalPosition": 169}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMxMTU5NQ==", "bodyText": "I'm confused about the concurrency model of Subscribers - earlier there were some synchronized blocks and now I don't see them. Can you document what the concurrency requirements are? This is especially important if people are going to be implementing sub-classes of this.", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369311595", "createdAt": "2020-01-22T00:12:06Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ReactiveSubscriber.java", "diffHunk": "@@ -0,0 +1,176 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.Objects;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams subscriber which handles much of the plumbing for you. Override {@link\n+ * #afterSubscribe}, {@link #handleValue}, {@link #handleComplete} and {@link #handleError} to\n+ * create your specific implementation.\n+ *\n+ * @param <T> The type of the value\n+ */\n+public class ReactiveSubscriber<T> implements Subscriber<T> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ba0d8a04f8ce7312a273230cc748f14d7def04b"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMxMTgyNg==", "bodyText": "can we make all of the overridden methods final? that way implementations don't accidentally override", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369311826", "createdAt": "2020-01-22T00:12:57Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ReactiveSubscriber.java", "diffHunk": "@@ -0,0 +1,176 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.Objects;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams subscriber which handles much of the plumbing for you. Override {@link\n+ * #afterSubscribe}, {@link #handleValue}, {@link #handleComplete} and {@link #handleError} to\n+ * create your specific implementation.\n+ *\n+ * @param <T> The type of the value\n+ */\n+public class ReactiveSubscriber<T> implements Subscriber<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ReactiveSubscriber.class);\n+\n+  protected final Context context;\n+  private Subscription subscription;\n+  private boolean complete;\n+\n+  /**\n+   * Construct a ReactiveSubscriber\n+   *\n+   * @param context The Vert.x context to use for the subscriber - the subscriber code will always\n+   *                be executed on this context. This ensures the code is never executed\n+   *                concurrently by more than one thread.\n+   */\n+  public ReactiveSubscriber(final Context context) {\n+    this.context = context;\n+  }\n+\n+  @Override\n+  public void onSubscribe(final Subscription s) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ba0d8a04f8ce7312a273230cc748f14d7def04b"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMxMjk0MQ==", "bodyText": "it seems like every method is supposed to check the context first. can we just make that method private and have all of the main action methods (i.e. onError, onComplete) call checkContext inside the runOnContext block?", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369312941", "createdAt": "2020-01-22T00:16:59Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ReactiveSubscriber.java", "diffHunk": "@@ -0,0 +1,176 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.Objects;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams subscriber which handles much of the plumbing for you. Override {@link\n+ * #afterSubscribe}, {@link #handleValue}, {@link #handleComplete} and {@link #handleError} to\n+ * create your specific implementation.\n+ *\n+ * @param <T> The type of the value\n+ */\n+public class ReactiveSubscriber<T> implements Subscriber<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ReactiveSubscriber.class);\n+\n+  protected final Context context;\n+  private Subscription subscription;\n+  private boolean complete;\n+\n+  /**\n+   * Construct a ReactiveSubscriber\n+   *\n+   * @param context The Vert.x context to use for the subscriber - the subscriber code will always\n+   *                be executed on this context. This ensures the code is never executed\n+   *                concurrently by more than one thread.\n+   */\n+  public ReactiveSubscriber(final Context context) {\n+    this.context = context;\n+  }\n+\n+  @Override\n+  public void onSubscribe(final Subscription s) {\n+    Objects.requireNonNull(s);\n+    context.runOnContext(v -> doOnSubscribe(s));\n+  }\n+\n+  @Override\n+  public void onNext(final T t) {\n+    Objects.requireNonNull(t);\n+    context.runOnContext(v -> doOnNext(t));\n+  }\n+\n+  @Override\n+  public void onError(final Throwable t) {\n+    Objects.requireNonNull(t);\n+    context.runOnContext(v -> doOnError(t));\n+  }\n+\n+  @Override\n+  public void onComplete() {\n+    context.runOnContext(v -> doOnComplete());\n+  }\n+\n+  protected void afterSubscribe(final Subscription subscription) {\n+  }\n+\n+  protected void handleValue(final T t) {\n+  }\n+\n+  protected void handleComplete() {\n+  }\n+\n+  protected void handleError(final Throwable t) {\n+  }\n+\n+  private void doOnSubscribe(final Subscription subscription) {\n+    checkContext();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ba0d8a04f8ce7312a273230cc748f14d7def04b"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMxMzM1Nw==", "bodyText": "we should make sure that we propagate t into this error message so at least we know what happened", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369313357", "createdAt": "2020-01-22T00:18:17Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ReactiveSubscriber.java", "diffHunk": "@@ -0,0 +1,176 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.Objects;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams subscriber which handles much of the plumbing for you. Override {@link\n+ * #afterSubscribe}, {@link #handleValue}, {@link #handleComplete} and {@link #handleError} to\n+ * create your specific implementation.\n+ *\n+ * @param <T> The type of the value\n+ */\n+public class ReactiveSubscriber<T> implements Subscriber<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ReactiveSubscriber.class);\n+\n+  protected final Context context;\n+  private Subscription subscription;\n+  private boolean complete;\n+\n+  /**\n+   * Construct a ReactiveSubscriber\n+   *\n+   * @param context The Vert.x context to use for the subscriber - the subscriber code will always\n+   *                be executed on this context. This ensures the code is never executed\n+   *                concurrently by more than one thread.\n+   */\n+  public ReactiveSubscriber(final Context context) {\n+    this.context = context;\n+  }\n+\n+  @Override\n+  public void onSubscribe(final Subscription s) {\n+    Objects.requireNonNull(s);\n+    context.runOnContext(v -> doOnSubscribe(s));\n+  }\n+\n+  @Override\n+  public void onNext(final T t) {\n+    Objects.requireNonNull(t);\n+    context.runOnContext(v -> doOnNext(t));\n+  }\n+\n+  @Override\n+  public void onError(final Throwable t) {\n+    Objects.requireNonNull(t);\n+    context.runOnContext(v -> doOnError(t));\n+  }\n+\n+  @Override\n+  public void onComplete() {\n+    context.runOnContext(v -> doOnComplete());\n+  }\n+\n+  protected void afterSubscribe(final Subscription subscription) {\n+  }\n+\n+  protected void handleValue(final T t) {\n+  }\n+\n+  protected void handleComplete() {\n+  }\n+\n+  protected void handleError(final Throwable t) {\n+  }\n+\n+  private void doOnSubscribe(final Subscription subscription) {\n+    checkContext();\n+    if (this.subscription != null) {\n+      try {\n+        // Cancel the new subscription\n+        subscription.cancel();\n+      } catch (final Throwable t) {\n+        final Exception e =\n+            new IllegalStateException(\"Exceptions must not be thrown from cancel\");\n+        logError(e);\n+      }\n+    }\n+    this.subscription = subscription;\n+    afterSubscribe(subscription);\n+  }\n+\n+  private void doOnNext(final T val) {\n+    checkContext();\n+    if (complete) {\n+      return;\n+    }\n+    if (subscription == null) {\n+      final Exception e = new IllegalStateException(\n+          \"onNext must be called without request being called\");\n+      logError(e);\n+    }\n+    try {\n+      handleValue(val);\n+    } catch (final Throwable t) {\n+      complete();\n+      onError(t);\n+    }\n+  }\n+\n+  private void doOnError(final Throwable t) {\n+    checkContext();\n+    if (subscription == null) {\n+      logError(new IllegalStateException(\"onError must not be called before onSubscribe\"));\n+    } else {\n+      complete = true;\n+      handleError(t);\n+    }\n+  }\n+\n+  private void doOnComplete() {\n+    checkContext();\n+    if (subscription == null) {\n+      logError(new IllegalStateException(\"onComplete must not be called before onSubscribe\"));\n+    } else {\n+      complete = true;\n+      handleComplete();\n+    }\n+  }\n+\n+  protected void makeRequest(final long l) {\n+    checkContext();\n+    try {\n+      subscription.request(l);\n+    } catch (Throwable t) {\n+      final Exception e =\n+          new IllegalStateException(\"Exceptions must not be thrown from request\");\n+      logError(e);\n+    }\n+  }\n+\n+  protected void complete() {\n+    checkContext();\n+    complete = true;\n+    if (subscription != null) {\n+      try {\n+        subscription.cancel();\n+      } catch (final Throwable t) {\n+        final Exception e =\n+            new IllegalStateException(\"Exceptions must not be thrown from cancel\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ba0d8a04f8ce7312a273230cc748f14d7def04b"}, "originalPosition": 160}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMxMzY2MA==", "bodyText": "I have a preference for protected methods to be either abstract, empty or final - is there a reason any of these methods can't be final?", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369313660", "createdAt": "2020-01-22T00:19:15Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ReactiveSubscriber.java", "diffHunk": "@@ -0,0 +1,176 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.Objects;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams subscriber which handles much of the plumbing for you. Override {@link\n+ * #afterSubscribe}, {@link #handleValue}, {@link #handleComplete} and {@link #handleError} to\n+ * create your specific implementation.\n+ *\n+ * @param <T> The type of the value\n+ */\n+public class ReactiveSubscriber<T> implements Subscriber<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ReactiveSubscriber.class);\n+\n+  protected final Context context;\n+  private Subscription subscription;\n+  private boolean complete;\n+\n+  /**\n+   * Construct a ReactiveSubscriber\n+   *\n+   * @param context The Vert.x context to use for the subscriber - the subscriber code will always\n+   *                be executed on this context. This ensures the code is never executed\n+   *                concurrently by more than one thread.\n+   */\n+  public ReactiveSubscriber(final Context context) {\n+    this.context = context;\n+  }\n+\n+  @Override\n+  public void onSubscribe(final Subscription s) {\n+    Objects.requireNonNull(s);\n+    context.runOnContext(v -> doOnSubscribe(s));\n+  }\n+\n+  @Override\n+  public void onNext(final T t) {\n+    Objects.requireNonNull(t);\n+    context.runOnContext(v -> doOnNext(t));\n+  }\n+\n+  @Override\n+  public void onError(final Throwable t) {\n+    Objects.requireNonNull(t);\n+    context.runOnContext(v -> doOnError(t));\n+  }\n+\n+  @Override\n+  public void onComplete() {\n+    context.runOnContext(v -> doOnComplete());\n+  }\n+\n+  protected void afterSubscribe(final Subscription subscription) {\n+  }\n+\n+  protected void handleValue(final T t) {\n+  }\n+\n+  protected void handleComplete() {\n+  }\n+\n+  protected void handleError(final Throwable t) {\n+  }\n+\n+  private void doOnSubscribe(final Subscription subscription) {\n+    checkContext();\n+    if (this.subscription != null) {\n+      try {\n+        // Cancel the new subscription\n+        subscription.cancel();\n+      } catch (final Throwable t) {\n+        final Exception e =\n+            new IllegalStateException(\"Exceptions must not be thrown from cancel\");\n+        logError(e);\n+      }\n+    }\n+    this.subscription = subscription;\n+    afterSubscribe(subscription);\n+  }\n+\n+  private void doOnNext(final T val) {\n+    checkContext();\n+    if (complete) {\n+      return;\n+    }\n+    if (subscription == null) {\n+      final Exception e = new IllegalStateException(\n+          \"onNext must be called without request being called\");\n+      logError(e);\n+    }\n+    try {\n+      handleValue(val);\n+    } catch (final Throwable t) {\n+      complete();\n+      onError(t);\n+    }\n+  }\n+\n+  private void doOnError(final Throwable t) {\n+    checkContext();\n+    if (subscription == null) {\n+      logError(new IllegalStateException(\"onError must not be called before onSubscribe\"));\n+    } else {\n+      complete = true;\n+      handleError(t);\n+    }\n+  }\n+\n+  private void doOnComplete() {\n+    checkContext();\n+    if (subscription == null) {\n+      logError(new IllegalStateException(\"onComplete must not be called before onSubscribe\"));\n+    } else {\n+      complete = true;\n+      handleComplete();\n+    }\n+  }\n+\n+  protected void makeRequest(final long l) {\n+    checkContext();\n+    try {\n+      subscription.request(l);\n+    } catch (Throwable t) {\n+      final Exception e =\n+          new IllegalStateException(\"Exceptions must not be thrown from request\");\n+      logError(e);\n+    }\n+  }\n+\n+  protected void complete() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ba0d8a04f8ce7312a273230cc748f14d7def04b"}, "originalPosition": 152}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMxNDgwNQ==", "bodyText": "we're cancelling the new subscription, and then setting it to be the current subscription? is this the intended behavior?", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369314805", "createdAt": "2020-01-22T00:23:39Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ReactiveSubscriber.java", "diffHunk": "@@ -0,0 +1,176 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.Objects;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams subscriber which handles much of the plumbing for you. Override {@link\n+ * #afterSubscribe}, {@link #handleValue}, {@link #handleComplete} and {@link #handleError} to\n+ * create your specific implementation.\n+ *\n+ * @param <T> The type of the value\n+ */\n+public class ReactiveSubscriber<T> implements Subscriber<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ReactiveSubscriber.class);\n+\n+  protected final Context context;\n+  private Subscription subscription;\n+  private boolean complete;\n+\n+  /**\n+   * Construct a ReactiveSubscriber\n+   *\n+   * @param context The Vert.x context to use for the subscriber - the subscriber code will always\n+   *                be executed on this context. This ensures the code is never executed\n+   *                concurrently by more than one thread.\n+   */\n+  public ReactiveSubscriber(final Context context) {\n+    this.context = context;\n+  }\n+\n+  @Override\n+  public void onSubscribe(final Subscription s) {\n+    Objects.requireNonNull(s);\n+    context.runOnContext(v -> doOnSubscribe(s));\n+  }\n+\n+  @Override\n+  public void onNext(final T t) {\n+    Objects.requireNonNull(t);\n+    context.runOnContext(v -> doOnNext(t));\n+  }\n+\n+  @Override\n+  public void onError(final Throwable t) {\n+    Objects.requireNonNull(t);\n+    context.runOnContext(v -> doOnError(t));\n+  }\n+\n+  @Override\n+  public void onComplete() {\n+    context.runOnContext(v -> doOnComplete());\n+  }\n+\n+  protected void afterSubscribe(final Subscription subscription) {\n+  }\n+\n+  protected void handleValue(final T t) {\n+  }\n+\n+  protected void handleComplete() {\n+  }\n+\n+  protected void handleError(final Throwable t) {\n+  }\n+\n+  private void doOnSubscribe(final Subscription subscription) {\n+    checkContext();\n+    if (this.subscription != null) {\n+      try {\n+        // Cancel the new subscription\n+        subscription.cancel();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ba0d8a04f8ce7312a273230cc748f14d7def04b"}, "originalPosition": 92}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMxODEzOA==", "bodyText": "I just realized that we send acks before we handle the inserts - what if we crash between sending the acks and handling the make request?", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369318138", "createdAt": "2020-01-22T00:36:38Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "diffHunk": "@@ -17,96 +17,107 @@\n \n import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n \n+import io.vertx.core.Context;\n import io.vertx.core.buffer.Buffer;\n import io.vertx.core.http.HttpServerResponse;\n import io.vertx.core.json.JsonObject;\n-import java.util.Objects;\n-import org.reactivestreams.Subscriber;\n import org.reactivestreams.Subscription;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n /**\n- * As the stream of inserts is processed by the back-end, it communicates success (or failure) of\n- * each insert by sending a stream of acks back in the other direction. This class is the subscriber\n- * which subscribes to that stream of acks and sends them back to the client. It's a reactive\n- * streams subscriber so implements back pressure.\n+ * A reactive streams subscriber that subscribes to publishers of acks. As it receive acks it writes\n+ * them to the HTTP response.\n  */\n-public class AcksSubscriber implements Subscriber<Void> {\n+public class AcksSubscriber extends ReactiveSubscriber<JsonObject> {\n \n-  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n-  private static final int BATCH_SIZE = 4;\n   private static final Buffer ACK_RESPONSE_LINE = new JsonObject().put(\"status\", \"ok\").toBuffer()\n       .appendString(\"\\n\");\n+  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n+  private static final int REQUEST_BATCH_SIZE = 1000;\n \n   private final HttpServerResponse response;\n-  private Subscription subscription;\n-  private long tokens;\n   private Long insertsSent;\n   private long acksSent;\n+  private boolean drainHandlerSet;\n+  private Subscription subscription;\n+  private boolean cancelled;\n \n-  public AcksSubscriber(final HttpServerResponse response) {\n-    this.response = Objects.requireNonNull(response);\n+  public AcksSubscriber(final Context context, final HttpServerResponse response) {\n+    super(context);\n+    this.response = response;\n   }\n \n   @Override\n-  public synchronized void onSubscribe(final Subscription subscription) {\n-    Objects.requireNonNull(subscription);\n-    if (this.subscription != null) {\n-      throw new IllegalStateException(\"Already subscribed\");\n-    }\n+  protected void afterSubscribe(final Subscription subscription) {\n+    makeRequest(REQUEST_BATCH_SIZE);\n     this.subscription = subscription;\n-    checkRequestTokens();\n   }\n \n   @Override\n-  public synchronized void onNext(final Void vo) {\n-    if (tokens == 0) {\n-      throw new IllegalStateException(\"Unsolicited data\");\n+  public void handleValue(final JsonObject value) {\n+    checkContext();\n+    if (cancelled) {\n+      return;\n     }\n     response.write(ACK_RESPONSE_LINE);\n     acksSent++;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ba0d8a04f8ce7312a273230cc748f14d7def04b"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMxOTA2Nw==", "bodyText": "this seems flipped from usual APIs which return true on the success condition and false when it fails.", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369319067", "createdAt": "2020-01-22T00:40:18Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/BufferedPublisher.java", "diffHunk": "@@ -0,0 +1,284 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.ArrayDeque;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Objects;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams publisher which can buffer received elements before sending them to it's\n+ * subscriber.\n+ *\n+ * @param <T> The type of the element\n+ */\n+public class BufferedPublisher<T> implements Publisher<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(BufferedPublisher.class);\n+  public static final int SEND_MAX_BATCH_SIZE = 10;\n+  public static final int DEFAULT_BUFFER_MAX_SIZE = 100;\n+\n+  private final Context ctx;\n+  private final Queue<T> buffer = new ArrayDeque<>();\n+  private final int bufferMaxSize;\n+  private Subscriber<? super T> subscriber;\n+  private long demand;\n+  private boolean cancelled;\n+  private Runnable drainHandler;\n+  private boolean complete;\n+  private boolean completing;\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx The Vert.x context to use for the publisher - the publisher code must always be\n+   *            executed on this context. This ensures the code is never executed concurrently by\n+   *            more than one thread.\n+   */\n+  public BufferedPublisher(final Context ctx) {\n+    this(ctx, Collections.emptySet(), DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer) {\n+    this(ctx, initialBuffer, DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param bufferMaxSize Indicative max number of elements to store in the buffer. Note that this\n+   *                      is not enforced, but it used to determine what to return from the accept\n+   *                      method so the caller can stop sending more and set a drainHandler to be\n+   *                      notified when the buffer is cleared\n+   */\n+  public BufferedPublisher(final Context ctx, final int bufferMaxSize) {\n+    this(ctx, Collections.emptySet(), bufferMaxSize);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   * @param bufferMaxSize Indicative max number of elements to buffer\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer,\n+      final int bufferMaxSize) {\n+    this.ctx = ctx;\n+    this.buffer.addAll(initialBuffer);\n+    this.bufferMaxSize = bufferMaxSize;\n+  }\n+\n+  /**\n+   * Provide an element to the publisher. The publisher will attempt to deliver it to it's\n+   * subscriber (if any). The publisher will buffer it internally if it can't deliver it\n+   * immediately.\n+   *\n+   * @param t The element\n+   * @return true if the internal buffer is 'full'. I.e. if number of elements is >= bufferMaxSize.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ba0d8a04f8ce7312a273230cc748f14d7def04b"}, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMyMDk0Ng==", "bodyText": "same comment as above - can these methods be made final?", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369320946", "createdAt": "2020-01-22T00:47:49Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/BufferedPublisher.java", "diffHunk": "@@ -0,0 +1,284 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.ArrayDeque;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Objects;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams publisher which can buffer received elements before sending them to it's\n+ * subscriber.\n+ *\n+ * @param <T> The type of the element\n+ */\n+public class BufferedPublisher<T> implements Publisher<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(BufferedPublisher.class);\n+  public static final int SEND_MAX_BATCH_SIZE = 10;\n+  public static final int DEFAULT_BUFFER_MAX_SIZE = 100;\n+\n+  private final Context ctx;\n+  private final Queue<T> buffer = new ArrayDeque<>();\n+  private final int bufferMaxSize;\n+  private Subscriber<? super T> subscriber;\n+  private long demand;\n+  private boolean cancelled;\n+  private Runnable drainHandler;\n+  private boolean complete;\n+  private boolean completing;\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx The Vert.x context to use for the publisher - the publisher code must always be\n+   *            executed on this context. This ensures the code is never executed concurrently by\n+   *            more than one thread.\n+   */\n+  public BufferedPublisher(final Context ctx) {\n+    this(ctx, Collections.emptySet(), DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer) {\n+    this(ctx, initialBuffer, DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param bufferMaxSize Indicative max number of elements to store in the buffer. Note that this\n+   *                      is not enforced, but it used to determine what to return from the accept\n+   *                      method so the caller can stop sending more and set a drainHandler to be\n+   *                      notified when the buffer is cleared\n+   */\n+  public BufferedPublisher(final Context ctx, final int bufferMaxSize) {\n+    this(ctx, Collections.emptySet(), bufferMaxSize);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   * @param bufferMaxSize Indicative max number of elements to buffer\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer,\n+      final int bufferMaxSize) {\n+    this.ctx = ctx;\n+    this.buffer.addAll(initialBuffer);\n+    this.bufferMaxSize = bufferMaxSize;\n+  }\n+\n+  /**\n+   * Provide an element to the publisher. The publisher will attempt to deliver it to it's\n+   * subscriber (if any). The publisher will buffer it internally if it can't deliver it\n+   * immediately.\n+   *\n+   * @param t The element\n+   * @return true if the internal buffer is 'full'. I.e. if number of elements is >= bufferMaxSize.\n+   */\n+  public boolean accept(final T t) {\n+    checkContext();\n+    if (completing) {\n+      throw new IllegalStateException(\"Cannot call accept after complete is called\");\n+    }\n+    if (demand == 0 || cancelled) {\n+      buffer.add(t);\n+    } else {\n+      doOnNext(t);\n+    }\n+    return buffer.size() >= bufferMaxSize;\n+  }\n+\n+  /**\n+   * If you set a drain handler. It will be called if, after delivery is attempted there are zero\n+   * elements buffered internally and there is demand from the subscriber for more elements.\n+   *\n+   * @param handler The handler\n+   */\n+  public void drainHandler(final Runnable handler) {\n+    checkContext();\n+    this.drainHandler = handler;\n+  }\n+\n+  /**\n+   * Mark the incoming stream of elements as complete. This means onComplete will be called on any\n+   * subscriber after any buffered messages have been delivered. Once complete has been called no\n+   * further elements will be accepted\n+   */\n+  public void complete() {\n+    checkContext();\n+    if (cancelled || complete) {\n+      return;\n+    }\n+    completing = true;\n+    if (buffer.isEmpty() && subscriber != null) {\n+      sendComplete();\n+    } else {\n+      complete = true;\n+    }\n+  }\n+\n+  /**\n+   * Subscribe a subscriber to this publisher. The publisher will allow at most one subscriber.\n+   *\n+   * @param subscriber The subscriber\n+   */\n+  @Override\n+  public void subscribe(final Subscriber<? super T> subscriber) {\n+    Objects.requireNonNull(subscriber);\n+    if (Vertx.currentContext() == ctx) {\n+      doSubscribe(subscriber);\n+    } else {\n+      ctx.runOnContext(v -> doSubscribe(subscriber));\n+    }\n+  }\n+\n+  /**\n+   * Hook to allow subclasses to inject errors etc.\n+   * This will be called before onNext is called on the subscriber to deliver an element\n+   *\n+   * @return true if processing should continue\n+   */\n+  protected boolean beforeOnNext() {\n+    return true;\n+  }\n+\n+  protected void sendError(final Exception e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ba0d8a04f8ce7312a273230cc748f14d7def04b"}, "originalPosition": 176}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMyNDQzMg==", "bodyText": "I'm confused by this - according to the Subscriber docs (and your assertion above), n is a strictly positive number. Looking at where demand is set, I don't see how this can be less than 1.", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369324432", "createdAt": "2020-01-22T01:02:07Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/BufferedPublisher.java", "diffHunk": "@@ -0,0 +1,284 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.ArrayDeque;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Objects;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams publisher which can buffer received elements before sending them to it's\n+ * subscriber.\n+ *\n+ * @param <T> The type of the element\n+ */\n+public class BufferedPublisher<T> implements Publisher<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(BufferedPublisher.class);\n+  public static final int SEND_MAX_BATCH_SIZE = 10;\n+  public static final int DEFAULT_BUFFER_MAX_SIZE = 100;\n+\n+  private final Context ctx;\n+  private final Queue<T> buffer = new ArrayDeque<>();\n+  private final int bufferMaxSize;\n+  private Subscriber<? super T> subscriber;\n+  private long demand;\n+  private boolean cancelled;\n+  private Runnable drainHandler;\n+  private boolean complete;\n+  private boolean completing;\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx The Vert.x context to use for the publisher - the publisher code must always be\n+   *            executed on this context. This ensures the code is never executed concurrently by\n+   *            more than one thread.\n+   */\n+  public BufferedPublisher(final Context ctx) {\n+    this(ctx, Collections.emptySet(), DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer) {\n+    this(ctx, initialBuffer, DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param bufferMaxSize Indicative max number of elements to store in the buffer. Note that this\n+   *                      is not enforced, but it used to determine what to return from the accept\n+   *                      method so the caller can stop sending more and set a drainHandler to be\n+   *                      notified when the buffer is cleared\n+   */\n+  public BufferedPublisher(final Context ctx, final int bufferMaxSize) {\n+    this(ctx, Collections.emptySet(), bufferMaxSize);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   * @param bufferMaxSize Indicative max number of elements to buffer\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer,\n+      final int bufferMaxSize) {\n+    this.ctx = ctx;\n+    this.buffer.addAll(initialBuffer);\n+    this.bufferMaxSize = bufferMaxSize;\n+  }\n+\n+  /**\n+   * Provide an element to the publisher. The publisher will attempt to deliver it to it's\n+   * subscriber (if any). The publisher will buffer it internally if it can't deliver it\n+   * immediately.\n+   *\n+   * @param t The element\n+   * @return true if the internal buffer is 'full'. I.e. if number of elements is >= bufferMaxSize.\n+   */\n+  public boolean accept(final T t) {\n+    checkContext();\n+    if (completing) {\n+      throw new IllegalStateException(\"Cannot call accept after complete is called\");\n+    }\n+    if (demand == 0 || cancelled) {\n+      buffer.add(t);\n+    } else {\n+      doOnNext(t);\n+    }\n+    return buffer.size() >= bufferMaxSize;\n+  }\n+\n+  /**\n+   * If you set a drain handler. It will be called if, after delivery is attempted there are zero\n+   * elements buffered internally and there is demand from the subscriber for more elements.\n+   *\n+   * @param handler The handler\n+   */\n+  public void drainHandler(final Runnable handler) {\n+    checkContext();\n+    this.drainHandler = handler;\n+  }\n+\n+  /**\n+   * Mark the incoming stream of elements as complete. This means onComplete will be called on any\n+   * subscriber after any buffered messages have been delivered. Once complete has been called no\n+   * further elements will be accepted\n+   */\n+  public void complete() {\n+    checkContext();\n+    if (cancelled || complete) {\n+      return;\n+    }\n+    completing = true;\n+    if (buffer.isEmpty() && subscriber != null) {\n+      sendComplete();\n+    } else {\n+      complete = true;\n+    }\n+  }\n+\n+  /**\n+   * Subscribe a subscriber to this publisher. The publisher will allow at most one subscriber.\n+   *\n+   * @param subscriber The subscriber\n+   */\n+  @Override\n+  public void subscribe(final Subscriber<? super T> subscriber) {\n+    Objects.requireNonNull(subscriber);\n+    if (Vertx.currentContext() == ctx) {\n+      doSubscribe(subscriber);\n+    } else {\n+      ctx.runOnContext(v -> doSubscribe(subscriber));\n+    }\n+  }\n+\n+  /**\n+   * Hook to allow subclasses to inject errors etc.\n+   * This will be called before onNext is called on the subscriber to deliver an element\n+   *\n+   * @return true if processing should continue\n+   */\n+  protected boolean beforeOnNext() {\n+    return true;\n+  }\n+\n+  protected void sendError(final Exception e) {\n+    checkContext();\n+    try {\n+      subscriber.onError(e);\n+      cancelled = true;\n+    } catch (Throwable t) {\n+      logError(\"Exceptions must not be thrown from onError\", t);\n+    }\n+  }\n+\n+  private void sendComplete() {\n+    try {\n+      cancelled = true;\n+      subscriber.onComplete();\n+    } catch (Throwable t) {\n+      logError(\"Exceptions must not be thrown from onComplete\", t);\n+    }\n+  }\n+\n+  private void doSubscribe(final Subscriber<? super T> subscriber) {\n+    this.subscriber = subscriber;\n+    try {\n+      subscriber.onSubscribe(new Sub());\n+    } catch (final Throwable t) {\n+      sendError(new IllegalStateException(\"Exceptions must not be thrown from onSubscribe\", t));\n+    }\n+  }\n+\n+  private void checkContext() {\n+    if (Vertx.currentContext() != ctx) {\n+      throw new IllegalStateException(\"On wrong context\");\n+    }\n+  }\n+\n+  private void doSend() {\n+    int numSent = 0;\n+    while (!cancelled && demand > 0 && !buffer.isEmpty()) {\n+      if (numSent < SEND_MAX_BATCH_SIZE) {\n+        final T val = buffer.poll();\n+        doOnNext(val);\n+        numSent++;\n+      } else {\n+        // Schedule another batch async\n+        ctx.runOnContext(v -> doSend());\n+        break;\n+      }\n+    }\n+\n+    if (buffer.isEmpty() && !cancelled) {\n+      if (complete) {\n+        sendComplete();\n+      } else if (demand > 0 && drainHandler != null) {\n+        final Runnable handler = drainHandler;\n+        ctx.runOnContext(v -> handler.run());\n+        drainHandler = null;\n+      }\n+    }\n+  }\n+\n+  private void doOnNext(final T val) {\n+    if (!beforeOnNext()) {\n+      return;\n+    }\n+    try {\n+      subscriber.onNext(val);\n+    } catch (final Throwable t) {\n+      logError(\"Exceptions must not be thrown from onNext\", t);\n+    }\n+    // If demand == Long.MAX_VALUE this means \"infinite demand\"\n+    if (demand != Long.MAX_VALUE) {\n+      demand--;\n+    }\n+  }\n+\n+  private void logError(final String message, final Throwable t) {\n+    log.error(message, t);\n+    cancelled = true;\n+  }\n+\n+  private void doRequest(final long n) {\n+    if (n <= 0) {\n+      sendError(new IllegalArgumentException(\"Amount requested must be > 0\"));\n+    } else if (demand + n < 1) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ba0d8a04f8ce7312a273230cc748f14d7def04b"}, "originalPosition": 258}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMyNTI3MA==", "bodyText": "it feels like there should be some synchronization in this class? also do we have any guarantees about when this will be scheduled?", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369325270", "createdAt": "2020-01-22T01:05:38Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/BufferedPublisher.java", "diffHunk": "@@ -0,0 +1,284 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.ArrayDeque;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Objects;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams publisher which can buffer received elements before sending them to it's\n+ * subscriber.\n+ *\n+ * @param <T> The type of the element\n+ */\n+public class BufferedPublisher<T> implements Publisher<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(BufferedPublisher.class);\n+  public static final int SEND_MAX_BATCH_SIZE = 10;\n+  public static final int DEFAULT_BUFFER_MAX_SIZE = 100;\n+\n+  private final Context ctx;\n+  private final Queue<T> buffer = new ArrayDeque<>();\n+  private final int bufferMaxSize;\n+  private Subscriber<? super T> subscriber;\n+  private long demand;\n+  private boolean cancelled;\n+  private Runnable drainHandler;\n+  private boolean complete;\n+  private boolean completing;\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx The Vert.x context to use for the publisher - the publisher code must always be\n+   *            executed on this context. This ensures the code is never executed concurrently by\n+   *            more than one thread.\n+   */\n+  public BufferedPublisher(final Context ctx) {\n+    this(ctx, Collections.emptySet(), DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer) {\n+    this(ctx, initialBuffer, DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param bufferMaxSize Indicative max number of elements to store in the buffer. Note that this\n+   *                      is not enforced, but it used to determine what to return from the accept\n+   *                      method so the caller can stop sending more and set a drainHandler to be\n+   *                      notified when the buffer is cleared\n+   */\n+  public BufferedPublisher(final Context ctx, final int bufferMaxSize) {\n+    this(ctx, Collections.emptySet(), bufferMaxSize);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   * @param bufferMaxSize Indicative max number of elements to buffer\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer,\n+      final int bufferMaxSize) {\n+    this.ctx = ctx;\n+    this.buffer.addAll(initialBuffer);\n+    this.bufferMaxSize = bufferMaxSize;\n+  }\n+\n+  /**\n+   * Provide an element to the publisher. The publisher will attempt to deliver it to it's\n+   * subscriber (if any). The publisher will buffer it internally if it can't deliver it\n+   * immediately.\n+   *\n+   * @param t The element\n+   * @return true if the internal buffer is 'full'. I.e. if number of elements is >= bufferMaxSize.\n+   */\n+  public boolean accept(final T t) {\n+    checkContext();\n+    if (completing) {\n+      throw new IllegalStateException(\"Cannot call accept after complete is called\");\n+    }\n+    if (demand == 0 || cancelled) {\n+      buffer.add(t);\n+    } else {\n+      doOnNext(t);\n+    }\n+    return buffer.size() >= bufferMaxSize;\n+  }\n+\n+  /**\n+   * If you set a drain handler. It will be called if, after delivery is attempted there are zero\n+   * elements buffered internally and there is demand from the subscriber for more elements.\n+   *\n+   * @param handler The handler\n+   */\n+  public void drainHandler(final Runnable handler) {\n+    checkContext();\n+    this.drainHandler = handler;\n+  }\n+\n+  /**\n+   * Mark the incoming stream of elements as complete. This means onComplete will be called on any\n+   * subscriber after any buffered messages have been delivered. Once complete has been called no\n+   * further elements will be accepted\n+   */\n+  public void complete() {\n+    checkContext();\n+    if (cancelled || complete) {\n+      return;\n+    }\n+    completing = true;\n+    if (buffer.isEmpty() && subscriber != null) {\n+      sendComplete();\n+    } else {\n+      complete = true;\n+    }\n+  }\n+\n+  /**\n+   * Subscribe a subscriber to this publisher. The publisher will allow at most one subscriber.\n+   *\n+   * @param subscriber The subscriber\n+   */\n+  @Override\n+  public void subscribe(final Subscriber<? super T> subscriber) {\n+    Objects.requireNonNull(subscriber);\n+    if (Vertx.currentContext() == ctx) {\n+      doSubscribe(subscriber);\n+    } else {\n+      ctx.runOnContext(v -> doSubscribe(subscriber));\n+    }\n+  }\n+\n+  /**\n+   * Hook to allow subclasses to inject errors etc.\n+   * This will be called before onNext is called on the subscriber to deliver an element\n+   *\n+   * @return true if processing should continue\n+   */\n+  protected boolean beforeOnNext() {\n+    return true;\n+  }\n+\n+  protected void sendError(final Exception e) {\n+    checkContext();\n+    try {\n+      subscriber.onError(e);\n+      cancelled = true;\n+    } catch (Throwable t) {\n+      logError(\"Exceptions must not be thrown from onError\", t);\n+    }\n+  }\n+\n+  private void sendComplete() {\n+    try {\n+      cancelled = true;\n+      subscriber.onComplete();\n+    } catch (Throwable t) {\n+      logError(\"Exceptions must not be thrown from onComplete\", t);\n+    }\n+  }\n+\n+  private void doSubscribe(final Subscriber<? super T> subscriber) {\n+    this.subscriber = subscriber;\n+    try {\n+      subscriber.onSubscribe(new Sub());\n+    } catch (final Throwable t) {\n+      sendError(new IllegalStateException(\"Exceptions must not be thrown from onSubscribe\", t));\n+    }\n+  }\n+\n+  private void checkContext() {\n+    if (Vertx.currentContext() != ctx) {\n+      throw new IllegalStateException(\"On wrong context\");\n+    }\n+  }\n+\n+  private void doSend() {\n+    int numSent = 0;\n+    while (!cancelled && demand > 0 && !buffer.isEmpty()) {\n+      if (numSent < SEND_MAX_BATCH_SIZE) {\n+        final T val = buffer.poll();\n+        doOnNext(val);\n+        numSent++;\n+      } else {\n+        // Schedule another batch async\n+        ctx.runOnContext(v -> doSend());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ba0d8a04f8ce7312a273230cc748f14d7def04b"}, "originalPosition": 219}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMyNTY0MQ==", "bodyText": "if it's cancelled, why would I add it to the buffer?", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369325641", "createdAt": "2020-01-22T01:07:05Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/BufferedPublisher.java", "diffHunk": "@@ -0,0 +1,284 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.ArrayDeque;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Objects;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams publisher which can buffer received elements before sending them to it's\n+ * subscriber.\n+ *\n+ * @param <T> The type of the element\n+ */\n+public class BufferedPublisher<T> implements Publisher<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(BufferedPublisher.class);\n+  public static final int SEND_MAX_BATCH_SIZE = 10;\n+  public static final int DEFAULT_BUFFER_MAX_SIZE = 100;\n+\n+  private final Context ctx;\n+  private final Queue<T> buffer = new ArrayDeque<>();\n+  private final int bufferMaxSize;\n+  private Subscriber<? super T> subscriber;\n+  private long demand;\n+  private boolean cancelled;\n+  private Runnable drainHandler;\n+  private boolean complete;\n+  private boolean completing;\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx The Vert.x context to use for the publisher - the publisher code must always be\n+   *            executed on this context. This ensures the code is never executed concurrently by\n+   *            more than one thread.\n+   */\n+  public BufferedPublisher(final Context ctx) {\n+    this(ctx, Collections.emptySet(), DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer) {\n+    this(ctx, initialBuffer, DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param bufferMaxSize Indicative max number of elements to store in the buffer. Note that this\n+   *                      is not enforced, but it used to determine what to return from the accept\n+   *                      method so the caller can stop sending more and set a drainHandler to be\n+   *                      notified when the buffer is cleared\n+   */\n+  public BufferedPublisher(final Context ctx, final int bufferMaxSize) {\n+    this(ctx, Collections.emptySet(), bufferMaxSize);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   * @param bufferMaxSize Indicative max number of elements to buffer\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer,\n+      final int bufferMaxSize) {\n+    this.ctx = ctx;\n+    this.buffer.addAll(initialBuffer);\n+    this.bufferMaxSize = bufferMaxSize;\n+  }\n+\n+  /**\n+   * Provide an element to the publisher. The publisher will attempt to deliver it to it's\n+   * subscriber (if any). The publisher will buffer it internally if it can't deliver it\n+   * immediately.\n+   *\n+   * @param t The element\n+   * @return true if the internal buffer is 'full'. I.e. if number of elements is >= bufferMaxSize.\n+   */\n+  public boolean accept(final T t) {\n+    checkContext();\n+    if (completing) {\n+      throw new IllegalStateException(\"Cannot call accept after complete is called\");\n+    }\n+    if (demand == 0 || cancelled) {\n+      buffer.add(t);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ba0d8a04f8ce7312a273230cc748f14d7def04b"}, "originalPosition": 115}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMyNzA1NQ==", "bodyText": "is it possible that we will never send the complete? it seems like if subscriber that was set never calls request, we won't increase our demand and we will never the buffered elements", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369327055", "createdAt": "2020-01-22T01:12:52Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/BufferedPublisher.java", "diffHunk": "@@ -0,0 +1,284 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.ArrayDeque;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Objects;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams publisher which can buffer received elements before sending them to it's\n+ * subscriber.\n+ *\n+ * @param <T> The type of the element\n+ */\n+public class BufferedPublisher<T> implements Publisher<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(BufferedPublisher.class);\n+  public static final int SEND_MAX_BATCH_SIZE = 10;\n+  public static final int DEFAULT_BUFFER_MAX_SIZE = 100;\n+\n+  private final Context ctx;\n+  private final Queue<T> buffer = new ArrayDeque<>();\n+  private final int bufferMaxSize;\n+  private Subscriber<? super T> subscriber;\n+  private long demand;\n+  private boolean cancelled;\n+  private Runnable drainHandler;\n+  private boolean complete;\n+  private boolean completing;\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx The Vert.x context to use for the publisher - the publisher code must always be\n+   *            executed on this context. This ensures the code is never executed concurrently by\n+   *            more than one thread.\n+   */\n+  public BufferedPublisher(final Context ctx) {\n+    this(ctx, Collections.emptySet(), DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer) {\n+    this(ctx, initialBuffer, DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param bufferMaxSize Indicative max number of elements to store in the buffer. Note that this\n+   *                      is not enforced, but it used to determine what to return from the accept\n+   *                      method so the caller can stop sending more and set a drainHandler to be\n+   *                      notified when the buffer is cleared\n+   */\n+  public BufferedPublisher(final Context ctx, final int bufferMaxSize) {\n+    this(ctx, Collections.emptySet(), bufferMaxSize);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   * @param bufferMaxSize Indicative max number of elements to buffer\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer,\n+      final int bufferMaxSize) {\n+    this.ctx = ctx;\n+    this.buffer.addAll(initialBuffer);\n+    this.bufferMaxSize = bufferMaxSize;\n+  }\n+\n+  /**\n+   * Provide an element to the publisher. The publisher will attempt to deliver it to it's\n+   * subscriber (if any). The publisher will buffer it internally if it can't deliver it\n+   * immediately.\n+   *\n+   * @param t The element\n+   * @return true if the internal buffer is 'full'. I.e. if number of elements is >= bufferMaxSize.\n+   */\n+  public boolean accept(final T t) {\n+    checkContext();\n+    if (completing) {\n+      throw new IllegalStateException(\"Cannot call accept after complete is called\");\n+    }\n+    if (demand == 0 || cancelled) {\n+      buffer.add(t);\n+    } else {\n+      doOnNext(t);\n+    }\n+    return buffer.size() >= bufferMaxSize;\n+  }\n+\n+  /**\n+   * If you set a drain handler. It will be called if, after delivery is attempted there are zero\n+   * elements buffered internally and there is demand from the subscriber for more elements.\n+   *\n+   * @param handler The handler\n+   */\n+  public void drainHandler(final Runnable handler) {\n+    checkContext();\n+    this.drainHandler = handler;\n+  }\n+\n+  /**\n+   * Mark the incoming stream of elements as complete. This means onComplete will be called on any\n+   * subscriber after any buffered messages have been delivered. Once complete has been called no\n+   * further elements will be accepted\n+   */\n+  public void complete() {\n+    checkContext();\n+    if (cancelled || complete) {\n+      return;\n+    }\n+    completing = true;\n+    if (buffer.isEmpty() && subscriber != null) {\n+      sendComplete();\n+    } else {\n+      complete = true;\n+    }\n+  }\n+\n+  /**\n+   * Subscribe a subscriber to this publisher. The publisher will allow at most one subscriber.\n+   *\n+   * @param subscriber The subscriber\n+   */\n+  @Override\n+  public void subscribe(final Subscriber<? super T> subscriber) {\n+    Objects.requireNonNull(subscriber);\n+    if (Vertx.currentContext() == ctx) {\n+      doSubscribe(subscriber);\n+    } else {\n+      ctx.runOnContext(v -> doSubscribe(subscriber));\n+    }\n+  }\n+\n+  /**\n+   * Hook to allow subclasses to inject errors etc.\n+   * This will be called before onNext is called on the subscriber to deliver an element\n+   *\n+   * @return true if processing should continue\n+   */\n+  protected boolean beforeOnNext() {\n+    return true;\n+  }\n+\n+  protected void sendError(final Exception e) {\n+    checkContext();\n+    try {\n+      subscriber.onError(e);\n+      cancelled = true;\n+    } catch (Throwable t) {\n+      logError(\"Exceptions must not be thrown from onError\", t);\n+    }\n+  }\n+\n+  private void sendComplete() {\n+    try {\n+      cancelled = true;\n+      subscriber.onComplete();\n+    } catch (Throwable t) {\n+      logError(\"Exceptions must not be thrown from onComplete\", t);\n+    }\n+  }\n+\n+  private void doSubscribe(final Subscriber<? super T> subscriber) {\n+    this.subscriber = subscriber;\n+    try {\n+      subscriber.onSubscribe(new Sub());\n+    } catch (final Throwable t) {\n+      sendError(new IllegalStateException(\"Exceptions must not be thrown from onSubscribe\", t));\n+    }\n+  }\n+\n+  private void checkContext() {\n+    if (Vertx.currentContext() != ctx) {\n+      throw new IllegalStateException(\"On wrong context\");\n+    }\n+  }\n+\n+  private void doSend() {\n+    int numSent = 0;\n+    while (!cancelled && demand > 0 && !buffer.isEmpty()) {\n+      if (numSent < SEND_MAX_BATCH_SIZE) {\n+        final T val = buffer.poll();\n+        doOnNext(val);\n+        numSent++;\n+      } else {\n+        // Schedule another batch async\n+        ctx.runOnContext(v -> doSend());\n+        break;\n+      }\n+    }\n+\n+    if (buffer.isEmpty() && !cancelled) {\n+      if (complete) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ba0d8a04f8ce7312a273230cc748f14d7def04b"}, "originalPosition": 225}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMyNzI4OQ==", "bodyText": "we should explicitly comment that this is a \"one time use\" function - after called once, it won't be called without another call to drainHandler", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369327289", "createdAt": "2020-01-22T01:13:53Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/BufferedPublisher.java", "diffHunk": "@@ -0,0 +1,284 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.ArrayDeque;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Objects;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams publisher which can buffer received elements before sending them to it's\n+ * subscriber.\n+ *\n+ * @param <T> The type of the element\n+ */\n+public class BufferedPublisher<T> implements Publisher<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(BufferedPublisher.class);\n+  public static final int SEND_MAX_BATCH_SIZE = 10;\n+  public static final int DEFAULT_BUFFER_MAX_SIZE = 100;\n+\n+  private final Context ctx;\n+  private final Queue<T> buffer = new ArrayDeque<>();\n+  private final int bufferMaxSize;\n+  private Subscriber<? super T> subscriber;\n+  private long demand;\n+  private boolean cancelled;\n+  private Runnable drainHandler;\n+  private boolean complete;\n+  private boolean completing;\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx The Vert.x context to use for the publisher - the publisher code must always be\n+   *            executed on this context. This ensures the code is never executed concurrently by\n+   *            more than one thread.\n+   */\n+  public BufferedPublisher(final Context ctx) {\n+    this(ctx, Collections.emptySet(), DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer) {\n+    this(ctx, initialBuffer, DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param bufferMaxSize Indicative max number of elements to store in the buffer. Note that this\n+   *                      is not enforced, but it used to determine what to return from the accept\n+   *                      method so the caller can stop sending more and set a drainHandler to be\n+   *                      notified when the buffer is cleared\n+   */\n+  public BufferedPublisher(final Context ctx, final int bufferMaxSize) {\n+    this(ctx, Collections.emptySet(), bufferMaxSize);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   * @param bufferMaxSize Indicative max number of elements to buffer\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer,\n+      final int bufferMaxSize) {\n+    this.ctx = ctx;\n+    this.buffer.addAll(initialBuffer);\n+    this.bufferMaxSize = bufferMaxSize;\n+  }\n+\n+  /**\n+   * Provide an element to the publisher. The publisher will attempt to deliver it to it's\n+   * subscriber (if any). The publisher will buffer it internally if it can't deliver it\n+   * immediately.\n+   *\n+   * @param t The element\n+   * @return true if the internal buffer is 'full'. I.e. if number of elements is >= bufferMaxSize.\n+   */\n+  public boolean accept(final T t) {\n+    checkContext();\n+    if (completing) {\n+      throw new IllegalStateException(\"Cannot call accept after complete is called\");\n+    }\n+    if (demand == 0 || cancelled) {\n+      buffer.add(t);\n+    } else {\n+      doOnNext(t);\n+    }\n+    return buffer.size() >= bufferMaxSize;\n+  }\n+\n+  /**\n+   * If you set a drain handler. It will be called if, after delivery is attempted there are zero\n+   * elements buffered internally and there is demand from the subscriber for more elements.\n+   *\n+   * @param handler The handler\n+   */\n+  public void drainHandler(final Runnable handler) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ba0d8a04f8ce7312a273230cc748f14d7def04b"}, "originalPosition": 128}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMyNzk5OA==", "bodyText": "there are still quite a few relevant comments on #4320 that I still see are relevant. Can you please go through them and make sure they are addressed or comment there dismissing them?", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369327998", "createdAt": "2020-01-22T01:17:04Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyHandler.java", "diffHunk": "@@ -79,16 +89,35 @@ public void handleBodyBuffer(final Buffer buff) {\n         return;\n       }\n       final JsonObject properties = args.getJsonObject(\"properties\");\n-      routingContext.request().endHandler(this::handleBodyEnd);\n-      acksSubscriber = acks ? new AcksSubscriber(routingContext.response()) : null;\n+      acksSubscriber = acks ? new AcksSubscriber(ctx, routingContext.response()) : null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ba0d8a04f8ce7312a273230cc748f14d7def04b"}, "originalPosition": 81}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMyODY3MQ==", "bodyText": "this isn't a particularly actionable message. can we improve on it by explaining why it's invalid?", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369328671", "createdAt": "2020-01-22T01:19:51Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerUtils.java", "diffHunk": "@@ -32,14 +37,29 @@ private ServerUtils() {\n \n   public static void handleError(final HttpServerResponse response, final int statusCode,\n       final int errorCode, final String errMsg) {\n-    final JsonObject errResponse = new JsonObject().put(\"status\", \"error\")\n+    final JsonObject errResponse = createErrResponse(errorCode, errMsg);\n+    response.setStatusCode(statusCode).end(errResponse.toBuffer());\n+  }\n+\n+  public static JsonObject createErrResponse(final int errorCode, final String errMsg) {\n+    return new JsonObject().put(\"status\", \"error\")\n         .put(\"errorCode\", errorCode)\n         .put(\"message\", errMsg);\n-    response.setStatusCode(statusCode).end(errResponse.toBuffer());\n   }\n \n   public static void unhandledExceptonHandler(final Throwable t) {\n     log.error(\"Unhandled exception\", t);\n   }\n \n+  public static JsonObject decodeJsonObject(final Buffer buffer,\n+      final RoutingContext routingContext) {\n+    try {\n+      return new JsonObject(buffer);\n+    } catch (DecodeException e) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_INVALID_JSON,\n+          \"Invalid JSON in request args\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ba0d8a04f8ce7312a273230cc748f14d7def04b"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMyODk0MQ==", "bodyText": "can we have this return Optional to indicate that this can return null?", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369328941", "createdAt": "2020-01-22T01:21:06Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerUtils.java", "diffHunk": "@@ -32,14 +37,29 @@ private ServerUtils() {\n \n   public static void handleError(final HttpServerResponse response, final int statusCode,\n       final int errorCode, final String errMsg) {\n-    final JsonObject errResponse = new JsonObject().put(\"status\", \"error\")\n+    final JsonObject errResponse = createErrResponse(errorCode, errMsg);\n+    response.setStatusCode(statusCode).end(errResponse.toBuffer());\n+  }\n+\n+  public static JsonObject createErrResponse(final int errorCode, final String errMsg) {\n+    return new JsonObject().put(\"status\", \"error\")\n         .put(\"errorCode\", errorCode)\n         .put(\"message\", errMsg);\n-    response.setStatusCode(statusCode).end(errResponse.toBuffer());\n   }\n \n   public static void unhandledExceptonHandler(final Throwable t) {\n     log.error(\"Unhandled exception\", t);\n   }\n \n+  public static JsonObject decodeJsonObject(final Buffer buffer,\n+      final RoutingContext routingContext) {\n+    try {\n+      return new JsonObject(buffer);\n+    } catch (DecodeException e) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_INVALID_JSON,\n+          \"Invalid JSON in request args\");\n+      return null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ba0d8a04f8ce7312a273230cc748f14d7def04b"}, "originalPosition": 41}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8419a8b321aea510a82d303c655235306393cf08", "author": {"user": {"login": "purplefox", "name": "Tim Fox"}}, "url": "https://github.com/confluentinc/ksql/commit/8419a8b321aea510a82d303c655235306393cf08", "committedDate": "2020-01-22T09:38:33Z", "message": "Review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1eb4cd594e90f9ce2b4fe1e90f06fec781b8fb0f", "author": {"user": {"login": "purplefox", "name": "Tim Fox"}}, "url": "https://github.com/confluentinc/ksql/commit/1eb4cd594e90f9ce2b4fe1e90f06fec781b8fb0f", "committedDate": "2020-01-22T10:06:39Z", "message": "More review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bb9ff315edee26c2bc64aef3e6b125a364414f6f", "author": {"user": {"login": "purplefox", "name": "Tim Fox"}}, "url": "https://github.com/confluentinc/ksql/commit/bb9ff315edee26c2bc64aef3e6b125a364414f6f", "committedDate": "2020-01-22T10:54:31Z", "message": "check on duplicate queryID"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c56e85fda5bf8d6f14d234fb3b124f0eeaac96a1", "author": {"user": {"login": "purplefox", "name": "Tim Fox"}}, "url": "https://github.com/confluentinc/ksql/commit/c56e85fda5bf8d6f14d234fb3b124f0eeaac96a1", "committedDate": "2020-01-22T10:59:49Z", "message": "better check on duplicate queryID"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ2OTA4ODgz", "url": "https://github.com/confluentinc/ksql/pull/4354#pullrequestreview-346908883", "createdAt": "2020-01-22T21:17:24Z", "commit": {"oid": "c56e85fda5bf8d6f14d234fb3b124f0eeaac96a1"}, "state": "APPROVED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQyMToxNzoyNFrOFgrShA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMlQyMTo1OToxOVrOFgsc7A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTgwODAwNA==", "bodyText": "same comment as the previous PR, I'm not sure this is out of date. tl;dr I think we should rename this requestClose(final long expectedAcks) and to change insertsSent to expectedAcks\n\nIt took me some time to understand what this API does. Does it indicate that we've completed all the inserts we want to send? Do we expect it to be called more than once? Maybe we can name it requestClose(final long expectedAcks). Would also help to have javadoc around here.\nAlso instead of using a single Long to indicate two things: both that we should close and the value of acks expected, I think it would be safer (avoid unboxing a null value) and easier to read if we split it into a flag boolean closeRequested and long expectedAcks.", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369808004", "createdAt": "2020-01-22T21:17:24Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "diffHunk": "@@ -17,96 +17,107 @@\n \n import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n \n+import io.vertx.core.Context;\n import io.vertx.core.buffer.Buffer;\n import io.vertx.core.http.HttpServerResponse;\n import io.vertx.core.json.JsonObject;\n-import java.util.Objects;\n-import org.reactivestreams.Subscriber;\n import org.reactivestreams.Subscription;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n /**\n- * As the stream of inserts is processed by the back-end, it communicates success (or failure) of\n- * each insert by sending a stream of acks back in the other direction. This class is the subscriber\n- * which subscribes to that stream of acks and sends them back to the client. It's a reactive\n- * streams subscriber so implements back pressure.\n+ * A reactive streams subscriber that subscribes to publishers of acks. As it receive acks it writes\n+ * them to the HTTP response.\n  */\n-public class AcksSubscriber implements Subscriber<Void> {\n+public class AcksSubscriber extends ReactiveSubscriber<JsonObject> {\n \n-  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n-  private static final int BATCH_SIZE = 4;\n   private static final Buffer ACK_RESPONSE_LINE = new JsonObject().put(\"status\", \"ok\").toBuffer()\n       .appendString(\"\\n\");\n+  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n+  private static final int REQUEST_BATCH_SIZE = 1000;\n \n   private final HttpServerResponse response;\n-  private Subscription subscription;\n-  private long tokens;\n   private Long insertsSent;\n   private long acksSent;\n+  private boolean drainHandlerSet;\n+  private Subscription subscription;\n+  private boolean cancelled;\n \n-  public AcksSubscriber(final HttpServerResponse response) {\n-    this.response = Objects.requireNonNull(response);\n+  public AcksSubscriber(final Context context, final HttpServerResponse response) {\n+    super(context);\n+    this.response = response;\n   }\n \n   @Override\n-  public synchronized void onSubscribe(final Subscription subscription) {\n-    Objects.requireNonNull(subscription);\n-    if (this.subscription != null) {\n-      throw new IllegalStateException(\"Already subscribed\");\n-    }\n+  protected void afterSubscribe(final Subscription subscription) {\n+    makeRequest(REQUEST_BATCH_SIZE);\n     this.subscription = subscription;\n-    checkRequestTokens();\n   }\n \n   @Override\n-  public synchronized void onNext(final Void vo) {\n-    if (tokens == 0) {\n-      throw new IllegalStateException(\"Unsolicited data\");\n+  public void handleValue(final JsonObject value) {\n+    checkContext();\n+    if (cancelled) {\n+      return;\n     }\n     response.write(ACK_RESPONSE_LINE);\n     acksSent++;\n-    tokens--;\n     if (insertsSent != null && insertsSent == acksSent) {\n       close();\n     } else if (response.writeQueueFull()) {\n-      response.drainHandler(v -> checkRequestTokens());\n+      if (!drainHandlerSet) {\n+        response.drainHandler(v -> {\n+          drainHandlerSet = false;\n+          checkMakeRequest();\n+        });\n+        drainHandlerSet = true;\n+      }\n     } else {\n-      checkRequestTokens();\n-    }\n-  }\n-\n-  synchronized void insertsSent(final long num) {\n-    this.insertsSent = num;\n-    if (acksSent == num) {\n-      close();\n+      checkMakeRequest();\n     }\n   }\n \n-  private void close() {\n+  @Override\n+  public void handleComplete() {\n     response.end();\n-    subscription.cancel();\n-  }\n-\n-  private void checkRequestTokens() {\n-    if (tokens == 0) {\n-      tokens = BATCH_SIZE;\n-      subscription.request(BATCH_SIZE);\n-    }\n   }\n \n   @Override\n-  public synchronized void onError(final Throwable t) {\n+  public void handleError(final Throwable t) {\n+    if (cancelled) {\n+      return;\n+    }\n     log.error(\"Error in processing inserts\", t);\n     final JsonObject err = new JsonObject().put(\"status\", \"error\")\n         .put(\"errorCode\", ERROR_CODE_INTERNAL_ERROR)\n         .put(\"message\", \"Error in processing inserts\");\n-    subscription.cancel();\n     response.end(err.toBuffer());\n   }\n \n-  @Override\n-  public synchronized void onComplete() {\n+  public void cancel() {\n+    checkContext();\n+    cancelled = true;\n+    if (subscription != null) {\n+      subscription.cancel();\n+    }\n+  }\n+\n+  private void checkMakeRequest() {\n+    if (acksSent % REQUEST_BATCH_SIZE == 0) {\n+      makeRequest(REQUEST_BATCH_SIZE);\n+    }\n+  }\n+\n+  private void close() {\n     response.end();\n+    complete();\n+  }\n+\n+  void insertsSent(final long num) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c56e85fda5bf8d6f14d234fb3b124f0eeaac96a1"}, "originalPosition": 145}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTgxNDI4Ng==", "bodyText": "ack - makes sense given that we still add it to the buffer in either scenario.", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369814286", "createdAt": "2020-01-22T21:31:06Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/BufferedPublisher.java", "diffHunk": "@@ -0,0 +1,284 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.ArrayDeque;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Objects;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams publisher which can buffer received elements before sending them to it's\n+ * subscriber.\n+ *\n+ * @param <T> The type of the element\n+ */\n+public class BufferedPublisher<T> implements Publisher<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(BufferedPublisher.class);\n+  public static final int SEND_MAX_BATCH_SIZE = 10;\n+  public static final int DEFAULT_BUFFER_MAX_SIZE = 100;\n+\n+  private final Context ctx;\n+  private final Queue<T> buffer = new ArrayDeque<>();\n+  private final int bufferMaxSize;\n+  private Subscriber<? super T> subscriber;\n+  private long demand;\n+  private boolean cancelled;\n+  private Runnable drainHandler;\n+  private boolean complete;\n+  private boolean completing;\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx The Vert.x context to use for the publisher - the publisher code must always be\n+   *            executed on this context. This ensures the code is never executed concurrently by\n+   *            more than one thread.\n+   */\n+  public BufferedPublisher(final Context ctx) {\n+    this(ctx, Collections.emptySet(), DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer) {\n+    this(ctx, initialBuffer, DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param bufferMaxSize Indicative max number of elements to store in the buffer. Note that this\n+   *                      is not enforced, but it used to determine what to return from the accept\n+   *                      method so the caller can stop sending more and set a drainHandler to be\n+   *                      notified when the buffer is cleared\n+   */\n+  public BufferedPublisher(final Context ctx, final int bufferMaxSize) {\n+    this(ctx, Collections.emptySet(), bufferMaxSize);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   * @param bufferMaxSize Indicative max number of elements to buffer\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer,\n+      final int bufferMaxSize) {\n+    this.ctx = ctx;\n+    this.buffer.addAll(initialBuffer);\n+    this.bufferMaxSize = bufferMaxSize;\n+  }\n+\n+  /**\n+   * Provide an element to the publisher. The publisher will attempt to deliver it to it's\n+   * subscriber (if any). The publisher will buffer it internally if it can't deliver it\n+   * immediately.\n+   *\n+   * @param t The element\n+   * @return true if the internal buffer is 'full'. I.e. if number of elements is >= bufferMaxSize.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMxOTA2Nw=="}, "originalCommit": {"oid": "3ba0d8a04f8ce7312a273230cc748f14d7def04b"}, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTgxODE2Nw==", "bodyText": "\ud83d\ude02", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369818167", "createdAt": "2020-01-22T21:39:44Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/Server.java", "diffHunk": "@@ -93,18 +93,22 @@ public synchronized void stop() {\n     }\n   }\n \n-  QueryID registerQuery(final QuerySubscriber querySubscriber) {\n+  ApiQueryID registerQuery(final QuerySubscriber querySubscriber) {\n     Objects.requireNonNull(querySubscriber);\n-    final QueryID queryID = new QueryID();\n-    queries.put(queryID, querySubscriber);\n+    final ApiQueryID queryID = new ApiQueryID();\n+    if (queries.putIfAbsent(queryID, querySubscriber) != null) {\n+      // It should never happen\n+      // https://stackoverflow.com/questions/2513573/how-good-is-javas-uuid-randomuuid", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c56e85fda5bf8d6f14d234fb3b124f0eeaac96a1"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTgxOTc5MA==", "bodyText": "is this used anywhere?", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369819790", "createdAt": "2020-01-22T21:43:19Z", "author": {"login": "agavra"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerVerticle.java", "diffHunk": "@@ -168,30 +174,39 @@ private void handleCloseQuery(final RoutingContext routingContext) {\n     routingContext.response().end();\n   }\n \n+  private static void connectBodyHandler(final Context ctx, final Endpoints endpoints,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c56e85fda5bf8d6f14d234fb3b124f0eeaac96a1"}, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTgyMjgxMA==", "bodyText": "it seems like most if not all the tests in this class can follow Given/When/Then. For these one's it's trivial:\n// When\nloadPublisher(10);\n\n// Then:\nshouldDeliver(1,1);", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369822810", "createdAt": "2020-01-22T21:49:53Z", "author": {"login": "agavra"}, "path": "ksql-api/src/test/java/io/confluent/ksql/api/BufferedPublisherTest.java", "diffHunk": "@@ -0,0 +1,430 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api;\n+\n+\n+import static io.confluent.ksql.test.util.AssertEventually.assertThatEventually;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.hasSize;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.notNullValue;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.hamcrest.core.IsInstanceOf.instanceOf;\n+\n+import io.confluent.ksql.api.TestUtils.AsyncAssert;\n+import io.confluent.ksql.api.server.BufferedPublisher;\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+\n+/**\n+ * More BufferedPublisher testing occurs in the TCK tests\n+ */\n+public class BufferedPublisherTest {\n+\n+  private Vertx vertx;\n+  private Context context;\n+  private BufferedPublisher<String> publisher;\n+\n+  @Before\n+  public void setUp() {\n+    vertx = Vertx.vertx();\n+    context = vertx.getOrCreateContext();\n+    publisher = new BufferedPublisher<>(context);\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    vertx.close();\n+  }\n+\n+  @Test\n+  public void shouldCallOnSubscribe() throws Exception {\n+    TestSubscriber subscriber = new TestSubscriber(context);\n+    subscribeOnContext(subscriber);\n+    assertThat(subscriber.getSub(), is(notNullValue()));\n+  }\n+\n+  @Test\n+  public void shouldDeliverOneRecordWhenOneIsRequested() throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c56e85fda5bf8d6f14d234fb3b124f0eeaac96a1"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTgyNzA1Mg==", "bodyText": "\ud83d\ude09 (and the @author below)", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r369827052", "createdAt": "2020-01-22T21:59:19Z", "author": {"login": "agavra"}, "path": "ksql-api/src/test/java/io/confluent/ksql/api/tck/ReactiveSubscriberBlackboxVerificationTest.java", "diffHunk": "@@ -0,0 +1,67 @@\n+/*\n+ * Copyright 2014 Red Hat, Inc.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c56e85fda5bf8d6f14d234fb3b124f0eeaac96a1"}, "originalPosition": 2}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a37e469a95e67886bc7648a9e8c2cdee6f887c9a", "author": {"user": {"login": "purplefox", "name": "Tim Fox"}}, "url": "https://github.com/confluentinc/ksql/commit/a37e469a95e67886bc7648a9e8c2cdee6f887c9a", "committedDate": "2020-01-23T07:58:22Z", "message": "review updates"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ3MjA5Mzkz", "url": "https://github.com/confluentinc/ksql/pull/4354#pullrequestreview-347209393", "createdAt": "2020-01-23T10:54:23Z", "commit": {"oid": "c56e85fda5bf8d6f14d234fb3b124f0eeaac96a1"}, "state": "COMMENTED", "comments": {"totalCount": 26, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yM1QxMDo1NDoyM1rOFg6IvQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yM1QxNDoxNDoyN1rOFg_k-w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA1MTI2MQ==", "bodyText": "nit: validate parameters.", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370051261", "createdAt": "2020-01-23T10:54:23Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "diffHunk": "@@ -17,96 +17,107 @@\n \n import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n \n+import io.vertx.core.Context;\n import io.vertx.core.buffer.Buffer;\n import io.vertx.core.http.HttpServerResponse;\n import io.vertx.core.json.JsonObject;\n-import java.util.Objects;\n-import org.reactivestreams.Subscriber;\n import org.reactivestreams.Subscription;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n /**\n- * As the stream of inserts is processed by the back-end, it communicates success (or failure) of\n- * each insert by sending a stream of acks back in the other direction. This class is the subscriber\n- * which subscribes to that stream of acks and sends them back to the client. It's a reactive\n- * streams subscriber so implements back pressure.\n+ * A reactive streams subscriber that subscribes to publishers of acks. As it receive acks it writes\n+ * them to the HTTP response.\n  */\n-public class AcksSubscriber implements Subscriber<Void> {\n+public class AcksSubscriber extends ReactiveSubscriber<JsonObject> {\n \n-  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n-  private static final int BATCH_SIZE = 4;\n   private static final Buffer ACK_RESPONSE_LINE = new JsonObject().put(\"status\", \"ok\").toBuffer()\n       .appendString(\"\\n\");\n+  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n+  private static final int REQUEST_BATCH_SIZE = 1000;\n \n   private final HttpServerResponse response;\n-  private Subscription subscription;\n-  private long tokens;\n   private Long insertsSent;\n   private long acksSent;\n+  private boolean drainHandlerSet;\n+  private Subscription subscription;\n+  private boolean cancelled;\n \n-  public AcksSubscriber(final HttpServerResponse response) {\n-    this.response = Objects.requireNonNull(response);\n+  public AcksSubscriber(final Context context, final HttpServerResponse response) {\n+    super(context);\n+    this.response = response;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c56e85fda5bf8d6f14d234fb3b124f0eeaac96a1"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA1MzI1Mg==", "bodyText": "Bit of a PITA they don't have a JUnit version, but, meh, works for me.", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370053252", "createdAt": "2020-01-23T10:58:46Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/pom.xml", "diffHunk": "@@ -93,6 +94,24 @@\n       <version>${project.version}</version>\n       <scope>test</scope>\n     </dependency>\n+    <dependency>\n+      <groupId>org.reactivestreams</groupId>\n+      <artifactId>reactive-streams-tck</artifactId>\n+      <version>${reactive-streams.version}</version>\n+      <scope>test</scope>\n+    </dependency>\n+    <dependency>\n+      <groupId>org.testng</groupId>\n+      <artifactId>testng</artifactId>\n+      <version>6.11</version>\n+      <scope>test</scope>\n+    </dependency>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTI5MTY0Nw=="}, "originalCommit": {"oid": "3ba0d8a04f8ce7312a273230cc748f14d7def04b"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA1NjY3Ng==", "bodyText": "ReactiveSubscriber already has a subscription field.  Rather than add another here, would it not be cleaner to either:\na. expose the subscription on the base class to derived classes through a protected getter, or\nb. (given this class only tracks the field to call cancel, add a cancel method to the base class\n???", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370056676", "createdAt": "2020-01-23T11:07:16Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "diffHunk": "@@ -17,96 +17,107 @@\n \n import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n \n+import io.vertx.core.Context;\n import io.vertx.core.buffer.Buffer;\n import io.vertx.core.http.HttpServerResponse;\n import io.vertx.core.json.JsonObject;\n-import java.util.Objects;\n-import org.reactivestreams.Subscriber;\n import org.reactivestreams.Subscription;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n /**\n- * As the stream of inserts is processed by the back-end, it communicates success (or failure) of\n- * each insert by sending a stream of acks back in the other direction. This class is the subscriber\n- * which subscribes to that stream of acks and sends them back to the client. It's a reactive\n- * streams subscriber so implements back pressure.\n+ * A reactive streams subscriber that subscribes to publishers of acks. As it receive acks it writes\n+ * them to the HTTP response.\n  */\n-public class AcksSubscriber implements Subscriber<Void> {\n+public class AcksSubscriber extends ReactiveSubscriber<JsonObject> {\n \n-  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n-  private static final int BATCH_SIZE = 4;\n   private static final Buffer ACK_RESPONSE_LINE = new JsonObject().put(\"status\", \"ok\").toBuffer()\n       .appendString(\"\\n\");\n+  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n+  private static final int REQUEST_BATCH_SIZE = 1000;\n \n   private final HttpServerResponse response;\n-  private Subscription subscription;\n-  private long tokens;\n   private Long insertsSent;\n   private long acksSent;\n+  private boolean drainHandlerSet;\n+  private Subscription subscription;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c56e85fda5bf8d6f14d234fb3b124f0eeaac96a1"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA1ODA3Mg==", "bodyText": "Forgive my lack of knowledge of vert.x, just wanted to check that the lambda passed here will always be called back on the same context/thread, i.e. just checking we're not missing a volatile.", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370058072", "createdAt": "2020-01-23T11:10:43Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "diffHunk": "@@ -17,96 +17,107 @@\n \n import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n \n+import io.vertx.core.Context;\n import io.vertx.core.buffer.Buffer;\n import io.vertx.core.http.HttpServerResponse;\n import io.vertx.core.json.JsonObject;\n-import java.util.Objects;\n-import org.reactivestreams.Subscriber;\n import org.reactivestreams.Subscription;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n /**\n- * As the stream of inserts is processed by the back-end, it communicates success (or failure) of\n- * each insert by sending a stream of acks back in the other direction. This class is the subscriber\n- * which subscribes to that stream of acks and sends them back to the client. It's a reactive\n- * streams subscriber so implements back pressure.\n+ * A reactive streams subscriber that subscribes to publishers of acks. As it receive acks it writes\n+ * them to the HTTP response.\n  */\n-public class AcksSubscriber implements Subscriber<Void> {\n+public class AcksSubscriber extends ReactiveSubscriber<JsonObject> {\n \n-  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n-  private static final int BATCH_SIZE = 4;\n   private static final Buffer ACK_RESPONSE_LINE = new JsonObject().put(\"status\", \"ok\").toBuffer()\n       .appendString(\"\\n\");\n+  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n+  private static final int REQUEST_BATCH_SIZE = 1000;\n \n   private final HttpServerResponse response;\n-  private Subscription subscription;\n-  private long tokens;\n   private Long insertsSent;\n   private long acksSent;\n+  private boolean drainHandlerSet;\n+  private Subscription subscription;\n+  private boolean cancelled;\n \n-  public AcksSubscriber(final HttpServerResponse response) {\n-    this.response = Objects.requireNonNull(response);\n+  public AcksSubscriber(final Context context, final HttpServerResponse response) {\n+    super(context);\n+    this.response = response;\n   }\n \n   @Override\n-  public synchronized void onSubscribe(final Subscription subscription) {\n-    Objects.requireNonNull(subscription);\n-    if (this.subscription != null) {\n-      throw new IllegalStateException(\"Already subscribed\");\n-    }\n+  protected void afterSubscribe(final Subscription subscription) {\n+    makeRequest(REQUEST_BATCH_SIZE);\n     this.subscription = subscription;\n-    checkRequestTokens();\n   }\n \n   @Override\n-  public synchronized void onNext(final Void vo) {\n-    if (tokens == 0) {\n-      throw new IllegalStateException(\"Unsolicited data\");\n+  public void handleValue(final JsonObject value) {\n+    checkContext();\n+    if (cancelled) {\n+      return;\n     }\n     response.write(ACK_RESPONSE_LINE);\n     acksSent++;\n-    tokens--;\n     if (insertsSent != null && insertsSent == acksSent) {\n       close();\n     } else if (response.writeQueueFull()) {\n-      response.drainHandler(v -> checkRequestTokens());\n+      if (!drainHandlerSet) {\n+        response.drainHandler(v -> {\n+          drainHandlerSet = false;\n+          checkMakeRequest();\n+        });\n+        drainHandlerSet = true;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c56e85fda5bf8d6f14d234fb3b124f0eeaac96a1"}, "originalPosition": 81}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA2Mjc1Nw==", "bodyText": "Looking at the logic here it feels like there may be an edge case, or it may be just my lack of experience with vert.x:\nIt looks like the logic is:\nif the write queue is full, then set up a callback, once, to call checkMakeRequest and clear the flag. Sounds good, except that we're requesting batches of 1000, so isn't there a chance that handleValue is going to be called another 999 times and call response.write even though the queue is full?  What will happen in such a situation?", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370062757", "createdAt": "2020-01-23T11:22:03Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "diffHunk": "@@ -17,96 +17,107 @@\n \n import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n \n+import io.vertx.core.Context;\n import io.vertx.core.buffer.Buffer;\n import io.vertx.core.http.HttpServerResponse;\n import io.vertx.core.json.JsonObject;\n-import java.util.Objects;\n-import org.reactivestreams.Subscriber;\n import org.reactivestreams.Subscription;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n /**\n- * As the stream of inserts is processed by the back-end, it communicates success (or failure) of\n- * each insert by sending a stream of acks back in the other direction. This class is the subscriber\n- * which subscribes to that stream of acks and sends them back to the client. It's a reactive\n- * streams subscriber so implements back pressure.\n+ * A reactive streams subscriber that subscribes to publishers of acks. As it receive acks it writes\n+ * them to the HTTP response.\n  */\n-public class AcksSubscriber implements Subscriber<Void> {\n+public class AcksSubscriber extends ReactiveSubscriber<JsonObject> {\n \n-  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n-  private static final int BATCH_SIZE = 4;\n   private static final Buffer ACK_RESPONSE_LINE = new JsonObject().put(\"status\", \"ok\").toBuffer()\n       .appendString(\"\\n\");\n+  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n+  private static final int REQUEST_BATCH_SIZE = 1000;\n \n   private final HttpServerResponse response;\n-  private Subscription subscription;\n-  private long tokens;\n   private Long insertsSent;\n   private long acksSent;\n+  private boolean drainHandlerSet;\n+  private Subscription subscription;\n+  private boolean cancelled;\n \n-  public AcksSubscriber(final HttpServerResponse response) {\n-    this.response = Objects.requireNonNull(response);\n+  public AcksSubscriber(final Context context, final HttpServerResponse response) {\n+    super(context);\n+    this.response = response;\n   }\n \n   @Override\n-  public synchronized void onSubscribe(final Subscription subscription) {\n-    Objects.requireNonNull(subscription);\n-    if (this.subscription != null) {\n-      throw new IllegalStateException(\"Already subscribed\");\n-    }\n+  protected void afterSubscribe(final Subscription subscription) {\n+    makeRequest(REQUEST_BATCH_SIZE);\n     this.subscription = subscription;\n-    checkRequestTokens();\n   }\n \n   @Override\n-  public synchronized void onNext(final Void vo) {\n-    if (tokens == 0) {\n-      throw new IllegalStateException(\"Unsolicited data\");\n+  public void handleValue(final JsonObject value) {\n+    checkContext();\n+    if (cancelled) {\n+      return;\n     }\n     response.write(ACK_RESPONSE_LINE);\n     acksSent++;\n-    tokens--;\n     if (insertsSent != null && insertsSent == acksSent) {\n       close();\n     } else if (response.writeQueueFull()) {\n-      response.drainHandler(v -> checkRequestTokens());\n+      if (!drainHandlerSet) {\n+        response.drainHandler(v -> {\n+          drainHandlerSet = false;\n+          checkMakeRequest();\n+        });\n+        drainHandlerSet = true;\n+      }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c56e85fda5bf8d6f14d234fb3b124f0eeaac96a1"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA2NjY4Nw==", "bodyText": "noticed you've dropped the synchronized.  Is this method now always called on the same thread as the main logic? If so, shouldn't we have a checkContext call here?", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370066687", "createdAt": "2020-01-23T11:32:14Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "diffHunk": "@@ -17,96 +17,107 @@\n \n import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n \n+import io.vertx.core.Context;\n import io.vertx.core.buffer.Buffer;\n import io.vertx.core.http.HttpServerResponse;\n import io.vertx.core.json.JsonObject;\n-import java.util.Objects;\n-import org.reactivestreams.Subscriber;\n import org.reactivestreams.Subscription;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n /**\n- * As the stream of inserts is processed by the back-end, it communicates success (or failure) of\n- * each insert by sending a stream of acks back in the other direction. This class is the subscriber\n- * which subscribes to that stream of acks and sends them back to the client. It's a reactive\n- * streams subscriber so implements back pressure.\n+ * A reactive streams subscriber that subscribes to publishers of acks. As it receive acks it writes\n+ * them to the HTTP response.\n  */\n-public class AcksSubscriber implements Subscriber<Void> {\n+public class AcksSubscriber extends ReactiveSubscriber<JsonObject> {\n \n-  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n-  private static final int BATCH_SIZE = 4;\n   private static final Buffer ACK_RESPONSE_LINE = new JsonObject().put(\"status\", \"ok\").toBuffer()\n       .appendString(\"\\n\");\n+  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n+  private static final int REQUEST_BATCH_SIZE = 1000;\n \n   private final HttpServerResponse response;\n-  private Subscription subscription;\n-  private long tokens;\n   private Long insertsSent;\n   private long acksSent;\n+  private boolean drainHandlerSet;\n+  private Subscription subscription;\n+  private boolean cancelled;\n \n-  public AcksSubscriber(final HttpServerResponse response) {\n-    this.response = Objects.requireNonNull(response);\n+  public AcksSubscriber(final Context context, final HttpServerResponse response) {\n+    super(context);\n+    this.response = response;\n   }\n \n   @Override\n-  public synchronized void onSubscribe(final Subscription subscription) {\n-    Objects.requireNonNull(subscription);\n-    if (this.subscription != null) {\n-      throw new IllegalStateException(\"Already subscribed\");\n-    }\n+  protected void afterSubscribe(final Subscription subscription) {\n+    makeRequest(REQUEST_BATCH_SIZE);\n     this.subscription = subscription;\n-    checkRequestTokens();\n   }\n \n   @Override\n-  public synchronized void onNext(final Void vo) {\n-    if (tokens == 0) {\n-      throw new IllegalStateException(\"Unsolicited data\");\n+  public void handleValue(final JsonObject value) {\n+    checkContext();\n+    if (cancelled) {\n+      return;\n     }\n     response.write(ACK_RESPONSE_LINE);\n     acksSent++;\n-    tokens--;\n     if (insertsSent != null && insertsSent == acksSent) {\n       close();\n     } else if (response.writeQueueFull()) {\n-      response.drainHandler(v -> checkRequestTokens());\n+      if (!drainHandlerSet) {\n+        response.drainHandler(v -> {\n+          drainHandlerSet = false;\n+          checkMakeRequest();\n+        });\n+        drainHandlerSet = true;\n+      }\n     } else {\n-      checkRequestTokens();\n-    }\n-  }\n-\n-  synchronized void insertsSent(final long num) {\n-    this.insertsSent = num;\n-    if (acksSent == num) {\n-      close();\n+      checkMakeRequest();\n     }\n   }\n \n-  private void close() {\n+  @Override\n+  public void handleComplete() {\n     response.end();\n-    subscription.cancel();\n-  }\n-\n-  private void checkRequestTokens() {\n-    if (tokens == 0) {\n-      tokens = BATCH_SIZE;\n-      subscription.request(BATCH_SIZE);\n-    }\n   }\n \n   @Override\n-  public synchronized void onError(final Throwable t) {\n+  public void handleError(final Throwable t) {\n+    if (cancelled) {\n+      return;\n+    }\n     log.error(\"Error in processing inserts\", t);\n     final JsonObject err = new JsonObject().put(\"status\", \"error\")\n         .put(\"errorCode\", ERROR_CODE_INTERNAL_ERROR)\n         .put(\"message\", \"Error in processing inserts\");\n-    subscription.cancel();\n     response.end(err.toBuffer());\n   }\n \n-  @Override\n-  public synchronized void onComplete() {\n+  public void cancel() {\n+    checkContext();\n+    cancelled = true;\n+    if (subscription != null) {\n+      subscription.cancel();\n+    }\n+  }\n+\n+  private void checkMakeRequest() {\n+    if (acksSent % REQUEST_BATCH_SIZE == 0) {\n+      makeRequest(REQUEST_BATCH_SIZE);\n+    }\n+  }\n+\n+  private void close() {\n     response.end();\n+    complete();\n+  }\n+\n+  void insertsSent(final long num) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c56e85fda5bf8d6f14d234fb3b124f0eeaac96a1"}, "originalPosition": 145}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA2ODcyNA==", "bodyText": "Purely out of interest.... what was involved in picking this number?", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370068724", "createdAt": "2020-01-23T11:37:24Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "diffHunk": "@@ -17,96 +17,107 @@\n \n import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n \n+import io.vertx.core.Context;\n import io.vertx.core.buffer.Buffer;\n import io.vertx.core.http.HttpServerResponse;\n import io.vertx.core.json.JsonObject;\n-import java.util.Objects;\n-import org.reactivestreams.Subscriber;\n import org.reactivestreams.Subscription;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n /**\n- * As the stream of inserts is processed by the back-end, it communicates success (or failure) of\n- * each insert by sending a stream of acks back in the other direction. This class is the subscriber\n- * which subscribes to that stream of acks and sends them back to the client. It's a reactive\n- * streams subscriber so implements back pressure.\n+ * A reactive streams subscriber that subscribes to publishers of acks. As it receive acks it writes\n+ * them to the HTTP response.\n  */\n-public class AcksSubscriber implements Subscriber<Void> {\n+public class AcksSubscriber extends ReactiveSubscriber<JsonObject> {\n \n-  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n-  private static final int BATCH_SIZE = 4;\n   private static final Buffer ACK_RESPONSE_LINE = new JsonObject().put(\"status\", \"ok\").toBuffer()\n       .appendString(\"\\n\");\n+  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n+  private static final int REQUEST_BATCH_SIZE = 1000;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c56e85fda5bf8d6f14d234fb3b124f0eeaac96a1"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA3MDIxMA==", "bodyText": "nit: validate params, i.e. null check ctx, positive bufferMaxSize", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370070210", "createdAt": "2020-01-23T11:41:22Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/BufferedPublisher.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.ArrayDeque;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Objects;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams publisher which can buffer received elements before sending them to it's\n+ * subscriber. The state for this publisher will always be accessed on the same Vert.x context so\n+ * does not require synchronization\n+ *\n+ * @param <T> The type of the element\n+ */\n+public class BufferedPublisher<T> implements Publisher<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(BufferedPublisher.class);\n+  public static final int SEND_MAX_BATCH_SIZE = 10;\n+  public static final int DEFAULT_BUFFER_MAX_SIZE = 100;\n+\n+  private final Context ctx;\n+  private final Queue<T> buffer = new ArrayDeque<>();\n+  private final int bufferMaxSize;\n+  private Subscriber<? super T> subscriber;\n+  private long demand;\n+  private boolean cancelled;\n+  private Runnable drainHandler;\n+  private boolean complete;\n+  private boolean completing;\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx The Vert.x context to use for the publisher - the publisher code must always be\n+   *            executed on this context. This ensures the code is never executed concurrently by\n+   *            more than one thread.\n+   */\n+  public BufferedPublisher(final Context ctx) {\n+    this(ctx, Collections.emptySet(), DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer) {\n+    this(ctx, initialBuffer, DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param bufferMaxSize Indicative max number of elements to store in the buffer. Note that this\n+   *                      is not enforced, but it used to determine what to return from the accept\n+   *                      method so the caller can stop sending more and set a drainHandler to be\n+   *                      notified when the buffer is cleared\n+   */\n+  public BufferedPublisher(final Context ctx, final int bufferMaxSize) {\n+    this(ctx, Collections.emptySet(), bufferMaxSize);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   * @param bufferMaxSize Indicative max number of elements to buffer\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer,\n+      final int bufferMaxSize) {\n+    this.ctx = ctx;\n+    this.buffer.addAll(initialBuffer);\n+    this.bufferMaxSize = bufferMaxSize;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c56e85fda5bf8d6f14d234fb3b124f0eeaac96a1"}, "originalPosition": 99}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA3MDkwNA==", "bodyText": "second check of cancelled is always going to be false. Second if can just be:\nif (demand == 0)", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370070904", "createdAt": "2020-01-23T11:43:09Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/BufferedPublisher.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.ArrayDeque;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Objects;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams publisher which can buffer received elements before sending them to it's\n+ * subscriber. The state for this publisher will always be accessed on the same Vert.x context so\n+ * does not require synchronization\n+ *\n+ * @param <T> The type of the element\n+ */\n+public class BufferedPublisher<T> implements Publisher<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(BufferedPublisher.class);\n+  public static final int SEND_MAX_BATCH_SIZE = 10;\n+  public static final int DEFAULT_BUFFER_MAX_SIZE = 100;\n+\n+  private final Context ctx;\n+  private final Queue<T> buffer = new ArrayDeque<>();\n+  private final int bufferMaxSize;\n+  private Subscriber<? super T> subscriber;\n+  private long demand;\n+  private boolean cancelled;\n+  private Runnable drainHandler;\n+  private boolean complete;\n+  private boolean completing;\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx The Vert.x context to use for the publisher - the publisher code must always be\n+   *            executed on this context. This ensures the code is never executed concurrently by\n+   *            more than one thread.\n+   */\n+  public BufferedPublisher(final Context ctx) {\n+    this(ctx, Collections.emptySet(), DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer) {\n+    this(ctx, initialBuffer, DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param bufferMaxSize Indicative max number of elements to store in the buffer. Note that this\n+   *                      is not enforced, but it used to determine what to return from the accept\n+   *                      method so the caller can stop sending more and set a drainHandler to be\n+   *                      notified when the buffer is cleared\n+   */\n+  public BufferedPublisher(final Context ctx, final int bufferMaxSize) {\n+    this(ctx, Collections.emptySet(), bufferMaxSize);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   * @param bufferMaxSize Indicative max number of elements to buffer\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer,\n+      final int bufferMaxSize) {\n+    this.ctx = ctx;\n+    this.buffer.addAll(initialBuffer);\n+    this.bufferMaxSize = bufferMaxSize;\n+  }\n+\n+  /**\n+   * Provide an element to the publisher. The publisher will attempt to deliver it to it's\n+   * subscriber (if any). The publisher will buffer it internally if it can't deliver it\n+   * immediately.\n+   *\n+   * @param t The element\n+   * @return true if the internal buffer is 'full'. I.e. if number of elements is >= bufferMaxSize.\n+   */\n+  public boolean accept(final T t) {\n+    checkContext();\n+    if (completing) {\n+      throw new IllegalStateException(\"Cannot call accept after complete is called\");\n+    }\n+    if (!cancelled) {\n+      if (demand == 0 || cancelled) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c56e85fda5bf8d6f14d234fb3b124f0eeaac96a1"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA3MjA4Mw==", "bodyText": "There's potential for someone to come along and add another call to this method, unintentionally overwriting a pre-existing handler, right?  Might it be safer to throw something here if the handler is already set? e.g.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                this.drainHandler = handler;\n          \n          \n            \n                if (this.drainHandler != 0) {\n          \n          \n            \n                    throw new IllegalStateException(\"drain handler already set\");\n          \n          \n            \n                }\n          \n          \n            \n                this.drainHandler = Objects.requireNoneNull(handler);", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370072083", "createdAt": "2020-01-23T11:46:14Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/BufferedPublisher.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.ArrayDeque;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Objects;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams publisher which can buffer received elements before sending them to it's\n+ * subscriber. The state for this publisher will always be accessed on the same Vert.x context so\n+ * does not require synchronization\n+ *\n+ * @param <T> The type of the element\n+ */\n+public class BufferedPublisher<T> implements Publisher<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(BufferedPublisher.class);\n+  public static final int SEND_MAX_BATCH_SIZE = 10;\n+  public static final int DEFAULT_BUFFER_MAX_SIZE = 100;\n+\n+  private final Context ctx;\n+  private final Queue<T> buffer = new ArrayDeque<>();\n+  private final int bufferMaxSize;\n+  private Subscriber<? super T> subscriber;\n+  private long demand;\n+  private boolean cancelled;\n+  private Runnable drainHandler;\n+  private boolean complete;\n+  private boolean completing;\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx The Vert.x context to use for the publisher - the publisher code must always be\n+   *            executed on this context. This ensures the code is never executed concurrently by\n+   *            more than one thread.\n+   */\n+  public BufferedPublisher(final Context ctx) {\n+    this(ctx, Collections.emptySet(), DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer) {\n+    this(ctx, initialBuffer, DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param bufferMaxSize Indicative max number of elements to store in the buffer. Note that this\n+   *                      is not enforced, but it used to determine what to return from the accept\n+   *                      method so the caller can stop sending more and set a drainHandler to be\n+   *                      notified when the buffer is cleared\n+   */\n+  public BufferedPublisher(final Context ctx, final int bufferMaxSize) {\n+    this(ctx, Collections.emptySet(), bufferMaxSize);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   * @param bufferMaxSize Indicative max number of elements to buffer\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer,\n+      final int bufferMaxSize) {\n+    this.ctx = ctx;\n+    this.buffer.addAll(initialBuffer);\n+    this.bufferMaxSize = bufferMaxSize;\n+  }\n+\n+  /**\n+   * Provide an element to the publisher. The publisher will attempt to deliver it to it's\n+   * subscriber (if any). The publisher will buffer it internally if it can't deliver it\n+   * immediately.\n+   *\n+   * @param t The element\n+   * @return true if the internal buffer is 'full'. I.e. if number of elements is >= bufferMaxSize.\n+   */\n+  public boolean accept(final T t) {\n+    checkContext();\n+    if (completing) {\n+      throw new IllegalStateException(\"Cannot call accept after complete is called\");\n+    }\n+    if (!cancelled) {\n+      if (demand == 0 || cancelled) {\n+        buffer.add(t);\n+      } else {\n+        doOnNext(t);\n+      }\n+    }\n+    return buffer.size() >= bufferMaxSize;\n+  }\n+\n+  /**\n+   * If you set a drain handler. It will be called if, after delivery is attempted there are zero\n+   * elements buffered internally and there is demand from the subscriber for more elements. Drain\n+   * handlers are one shot handlers, after being it will never be called more than once.\n+   *\n+   * @param handler The handler\n+   */\n+  public void drainHandler(final Runnable handler) {\n+    checkContext();\n+    this.drainHandler = handler;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c56e85fda5bf8d6f14d234fb3b124f0eeaac96a1"}, "originalPosition": 134}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA3MjQ4Mw==", "bodyText": "should this maybe be:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                if (cancelled || complete) {\n          \n          \n            \n                if (cancelled || completing) {\n          \n      \n    \n    \n  \n\n???", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370072483", "createdAt": "2020-01-23T11:47:15Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/BufferedPublisher.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.ArrayDeque;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Objects;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams publisher which can buffer received elements before sending them to it's\n+ * subscriber. The state for this publisher will always be accessed on the same Vert.x context so\n+ * does not require synchronization\n+ *\n+ * @param <T> The type of the element\n+ */\n+public class BufferedPublisher<T> implements Publisher<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(BufferedPublisher.class);\n+  public static final int SEND_MAX_BATCH_SIZE = 10;\n+  public static final int DEFAULT_BUFFER_MAX_SIZE = 100;\n+\n+  private final Context ctx;\n+  private final Queue<T> buffer = new ArrayDeque<>();\n+  private final int bufferMaxSize;\n+  private Subscriber<? super T> subscriber;\n+  private long demand;\n+  private boolean cancelled;\n+  private Runnable drainHandler;\n+  private boolean complete;\n+  private boolean completing;\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx The Vert.x context to use for the publisher - the publisher code must always be\n+   *            executed on this context. This ensures the code is never executed concurrently by\n+   *            more than one thread.\n+   */\n+  public BufferedPublisher(final Context ctx) {\n+    this(ctx, Collections.emptySet(), DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer) {\n+    this(ctx, initialBuffer, DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param bufferMaxSize Indicative max number of elements to store in the buffer. Note that this\n+   *                      is not enforced, but it used to determine what to return from the accept\n+   *                      method so the caller can stop sending more and set a drainHandler to be\n+   *                      notified when the buffer is cleared\n+   */\n+  public BufferedPublisher(final Context ctx, final int bufferMaxSize) {\n+    this(ctx, Collections.emptySet(), bufferMaxSize);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   * @param bufferMaxSize Indicative max number of elements to buffer\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer,\n+      final int bufferMaxSize) {\n+    this.ctx = ctx;\n+    this.buffer.addAll(initialBuffer);\n+    this.bufferMaxSize = bufferMaxSize;\n+  }\n+\n+  /**\n+   * Provide an element to the publisher. The publisher will attempt to deliver it to it's\n+   * subscriber (if any). The publisher will buffer it internally if it can't deliver it\n+   * immediately.\n+   *\n+   * @param t The element\n+   * @return true if the internal buffer is 'full'. I.e. if number of elements is >= bufferMaxSize.\n+   */\n+  public boolean accept(final T t) {\n+    checkContext();\n+    if (completing) {\n+      throw new IllegalStateException(\"Cannot call accept after complete is called\");\n+    }\n+    if (!cancelled) {\n+      if (demand == 0 || cancelled) {\n+        buffer.add(t);\n+      } else {\n+        doOnNext(t);\n+      }\n+    }\n+    return buffer.size() >= bufferMaxSize;\n+  }\n+\n+  /**\n+   * If you set a drain handler. It will be called if, after delivery is attempted there are zero\n+   * elements buffered internally and there is demand from the subscriber for more elements. Drain\n+   * handlers are one shot handlers, after being it will never be called more than once.\n+   *\n+   * @param handler The handler\n+   */\n+  public void drainHandler(final Runnable handler) {\n+    checkContext();\n+    this.drainHandler = handler;\n+  }\n+\n+  /**\n+   * Mark the incoming stream of elements as complete. This means onComplete will be called on any\n+   * subscriber after any buffered messages have been delivered. Once complete has been called no\n+   * further elements will be accepted\n+   */\n+  public void complete() {\n+    checkContext();\n+    if (cancelled || complete) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c56e85fda5bf8d6f14d234fb3b124f0eeaac96a1"}, "originalPosition": 144}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA3NTQ5MQ==", "bodyText": "Is delimiting records by \\n safe?  What if an insert wanted to insert a string that contained a newline character?\nI'm guessing this is OK as the JSON would need the line separator converted to a literal \"\\n\".  But maybe worth adding a test to cover this case.", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370075491", "createdAt": "2020-01-23T11:54:31Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyHandler.java", "diffHunk": "@@ -34,38 +38,44 @@\n  * (also encoded as UTF-8 text) each representing a row to insert. The last JSON object must be\n  * followed by a new-line.\n  */\n-public class InsertsBodyParser {\n+public class InsertsBodyHandler {\n \n+  private final Context ctx;\n   private final Endpoints endpoints;\n   private final RoutingContext routingContext;\n-  private boolean readArguments;\n-  private InsertsPublisher publisher;\n+  private final RecordParser recordParser;\n+  private boolean hasReadArguments;\n+  private BufferedPublisher<JsonObject> publisher;\n   private long rowsReceived;\n   private AcksSubscriber acksSubscriber;\n \n-  public InsertsBodyParser(final Endpoints endpoints, final RoutingContext routingContext) {\n+  public InsertsBodyHandler(final Context ctx, final Endpoints endpoints,\n+      final RoutingContext routingContext) {\n+    this.ctx = ctx;\n     this.endpoints = Objects.requireNonNull(endpoints);\n     this.routingContext = Objects.requireNonNull(routingContext);\n-    routingContext.response().endHandler(v -> {\n-      if (publisher != null) {\n-        publisher.close();\n-      }\n-    });\n+    this.recordParser = RecordParser.newDelimited(\"\\n\", routingContext.request());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c56e85fda5bf8d6f14d234fb3b124f0eeaac96a1"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA3ODcxMg==", "bodyText": "Consider replacing comment with a constant, e.g.\nprivate static final long INFINITE_DEMAND = Long.MAX;\n\n....\n\nif (demand != INFINITE_DEMAND) {\n   demand--;\n}", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370078712", "createdAt": "2020-01-23T12:02:40Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/BufferedPublisher.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.ArrayDeque;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Objects;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams publisher which can buffer received elements before sending them to it's\n+ * subscriber. The state for this publisher will always be accessed on the same Vert.x context so\n+ * does not require synchronization\n+ *\n+ * @param <T> The type of the element\n+ */\n+public class BufferedPublisher<T> implements Publisher<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(BufferedPublisher.class);\n+  public static final int SEND_MAX_BATCH_SIZE = 10;\n+  public static final int DEFAULT_BUFFER_MAX_SIZE = 100;\n+\n+  private final Context ctx;\n+  private final Queue<T> buffer = new ArrayDeque<>();\n+  private final int bufferMaxSize;\n+  private Subscriber<? super T> subscriber;\n+  private long demand;\n+  private boolean cancelled;\n+  private Runnable drainHandler;\n+  private boolean complete;\n+  private boolean completing;\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx The Vert.x context to use for the publisher - the publisher code must always be\n+   *            executed on this context. This ensures the code is never executed concurrently by\n+   *            more than one thread.\n+   */\n+  public BufferedPublisher(final Context ctx) {\n+    this(ctx, Collections.emptySet(), DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer) {\n+    this(ctx, initialBuffer, DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param bufferMaxSize Indicative max number of elements to store in the buffer. Note that this\n+   *                      is not enforced, but it used to determine what to return from the accept\n+   *                      method so the caller can stop sending more and set a drainHandler to be\n+   *                      notified when the buffer is cleared\n+   */\n+  public BufferedPublisher(final Context ctx, final int bufferMaxSize) {\n+    this(ctx, Collections.emptySet(), bufferMaxSize);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   * @param bufferMaxSize Indicative max number of elements to buffer\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer,\n+      final int bufferMaxSize) {\n+    this.ctx = ctx;\n+    this.buffer.addAll(initialBuffer);\n+    this.bufferMaxSize = bufferMaxSize;\n+  }\n+\n+  /**\n+   * Provide an element to the publisher. The publisher will attempt to deliver it to it's\n+   * subscriber (if any). The publisher will buffer it internally if it can't deliver it\n+   * immediately.\n+   *\n+   * @param t The element\n+   * @return true if the internal buffer is 'full'. I.e. if number of elements is >= bufferMaxSize.\n+   */\n+  public boolean accept(final T t) {\n+    checkContext();\n+    if (completing) {\n+      throw new IllegalStateException(\"Cannot call accept after complete is called\");\n+    }\n+    if (!cancelled) {\n+      if (demand == 0 || cancelled) {\n+        buffer.add(t);\n+      } else {\n+        doOnNext(t);\n+      }\n+    }\n+    return buffer.size() >= bufferMaxSize;\n+  }\n+\n+  /**\n+   * If you set a drain handler. It will be called if, after delivery is attempted there are zero\n+   * elements buffered internally and there is demand from the subscriber for more elements. Drain\n+   * handlers are one shot handlers, after being it will never be called more than once.\n+   *\n+   * @param handler The handler\n+   */\n+  public void drainHandler(final Runnable handler) {\n+    checkContext();\n+    this.drainHandler = handler;\n+  }\n+\n+  /**\n+   * Mark the incoming stream of elements as complete. This means onComplete will be called on any\n+   * subscriber after any buffered messages have been delivered. Once complete has been called no\n+   * further elements will be accepted\n+   */\n+  public void complete() {\n+    checkContext();\n+    if (cancelled || complete) {\n+      return;\n+    }\n+    completing = true;\n+    if (buffer.isEmpty() && subscriber != null) {\n+      sendComplete();\n+    } else {\n+      complete = true;\n+    }\n+  }\n+\n+  /**\n+   * Subscribe a subscriber to this publisher. The publisher will allow at most one subscriber.\n+   *\n+   * @param subscriber The subscriber\n+   */\n+  @Override\n+  public void subscribe(final Subscriber<? super T> subscriber) {\n+    Objects.requireNonNull(subscriber);\n+    if (Vertx.currentContext() == ctx) {\n+      doSubscribe(subscriber);\n+    } else {\n+      ctx.runOnContext(v -> doSubscribe(subscriber));\n+    }\n+  }\n+\n+  /**\n+   * Hook to allow subclasses to inject errors etc.\n+   * This will be called before onNext is called on the subscriber to deliver an element\n+   *\n+   * @return true if processing should continue\n+   */\n+  protected boolean beforeOnNext() {\n+    return true;\n+  }\n+\n+  protected final void sendError(final Exception e) {\n+    checkContext();\n+    try {\n+      subscriber.onError(e);\n+      cancelled = true;\n+    } catch (Throwable t) {\n+      logError(\"Exceptions must not be thrown from onError\", t);\n+    }\n+  }\n+\n+  private void sendComplete() {\n+    try {\n+      cancelled = true;\n+      subscriber.onComplete();\n+    } catch (Throwable t) {\n+      logError(\"Exceptions must not be thrown from onComplete\", t);\n+    }\n+  }\n+\n+  private void doSubscribe(final Subscriber<? super T> subscriber) {\n+    this.subscriber = subscriber;\n+    try {\n+      subscriber.onSubscribe(new Sub());\n+    } catch (final Throwable t) {\n+      sendError(new IllegalStateException(\"Exceptions must not be thrown from onSubscribe\", t));\n+    }\n+  }\n+\n+  private void checkContext() {\n+    if (Vertx.currentContext() != ctx) {\n+      throw new IllegalStateException(\"On wrong context\");\n+    }\n+  }\n+\n+  private void doSend() {\n+    int numSent = 0;\n+    while (!cancelled && demand > 0 && !buffer.isEmpty()) {\n+      if (numSent < SEND_MAX_BATCH_SIZE) {\n+        final T val = buffer.poll();\n+        doOnNext(val);\n+        numSent++;\n+      } else {\n+        // Schedule another batch async\n+        ctx.runOnContext(v -> doSend());\n+        break;\n+      }\n+    }\n+\n+    if (buffer.isEmpty() && !cancelled) {\n+      if (complete) {\n+        sendComplete();\n+      } else if (demand > 0 && drainHandler != null) {\n+        final Runnable handler = drainHandler;\n+        ctx.runOnContext(v -> handler.run());\n+        drainHandler = null;\n+      }\n+    }\n+  }\n+\n+  private void doOnNext(final T val) {\n+    if (!beforeOnNext()) {\n+      return;\n+    }\n+    try {\n+      subscriber.onNext(val);\n+    } catch (final Throwable t) {\n+      logError(\"Exceptions must not be thrown from onNext\", t);\n+    }\n+    // If demand == Long.MAX_VALUE this means \"infinite demand\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a37e469a95e67886bc7648a9e8c2cdee6f887c9a"}, "originalPosition": 248}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA3OTMzOA==", "bodyText": "Consider using constant mentioned above:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                  demand = Long.MAX_VALUE;\n          \n          \n            \n                  demand = INFINITE_DEMAND;", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370079338", "createdAt": "2020-01-23T12:04:14Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/BufferedPublisher.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.ArrayDeque;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Objects;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams publisher which can buffer received elements before sending them to it's\n+ * subscriber. The state for this publisher will always be accessed on the same Vert.x context so\n+ * does not require synchronization\n+ *\n+ * @param <T> The type of the element\n+ */\n+public class BufferedPublisher<T> implements Publisher<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(BufferedPublisher.class);\n+  public static final int SEND_MAX_BATCH_SIZE = 10;\n+  public static final int DEFAULT_BUFFER_MAX_SIZE = 100;\n+\n+  private final Context ctx;\n+  private final Queue<T> buffer = new ArrayDeque<>();\n+  private final int bufferMaxSize;\n+  private Subscriber<? super T> subscriber;\n+  private long demand;\n+  private boolean cancelled;\n+  private Runnable drainHandler;\n+  private boolean complete;\n+  private boolean completing;\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx The Vert.x context to use for the publisher - the publisher code must always be\n+   *            executed on this context. This ensures the code is never executed concurrently by\n+   *            more than one thread.\n+   */\n+  public BufferedPublisher(final Context ctx) {\n+    this(ctx, Collections.emptySet(), DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer) {\n+    this(ctx, initialBuffer, DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param bufferMaxSize Indicative max number of elements to store in the buffer. Note that this\n+   *                      is not enforced, but it used to determine what to return from the accept\n+   *                      method so the caller can stop sending more and set a drainHandler to be\n+   *                      notified when the buffer is cleared\n+   */\n+  public BufferedPublisher(final Context ctx, final int bufferMaxSize) {\n+    this(ctx, Collections.emptySet(), bufferMaxSize);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   * @param bufferMaxSize Indicative max number of elements to buffer\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer,\n+      final int bufferMaxSize) {\n+    this.ctx = ctx;\n+    this.buffer.addAll(initialBuffer);\n+    this.bufferMaxSize = bufferMaxSize;\n+  }\n+\n+  /**\n+   * Provide an element to the publisher. The publisher will attempt to deliver it to it's\n+   * subscriber (if any). The publisher will buffer it internally if it can't deliver it\n+   * immediately.\n+   *\n+   * @param t The element\n+   * @return true if the internal buffer is 'full'. I.e. if number of elements is >= bufferMaxSize.\n+   */\n+  public boolean accept(final T t) {\n+    checkContext();\n+    if (completing) {\n+      throw new IllegalStateException(\"Cannot call accept after complete is called\");\n+    }\n+    if (!cancelled) {\n+      if (demand == 0 || cancelled) {\n+        buffer.add(t);\n+      } else {\n+        doOnNext(t);\n+      }\n+    }\n+    return buffer.size() >= bufferMaxSize;\n+  }\n+\n+  /**\n+   * If you set a drain handler. It will be called if, after delivery is attempted there are zero\n+   * elements buffered internally and there is demand from the subscriber for more elements. Drain\n+   * handlers are one shot handlers, after being it will never be called more than once.\n+   *\n+   * @param handler The handler\n+   */\n+  public void drainHandler(final Runnable handler) {\n+    checkContext();\n+    this.drainHandler = handler;\n+  }\n+\n+  /**\n+   * Mark the incoming stream of elements as complete. This means onComplete will be called on any\n+   * subscriber after any buffered messages have been delivered. Once complete has been called no\n+   * further elements will be accepted\n+   */\n+  public void complete() {\n+    checkContext();\n+    if (cancelled || complete) {\n+      return;\n+    }\n+    completing = true;\n+    if (buffer.isEmpty() && subscriber != null) {\n+      sendComplete();\n+    } else {\n+      complete = true;\n+    }\n+  }\n+\n+  /**\n+   * Subscribe a subscriber to this publisher. The publisher will allow at most one subscriber.\n+   *\n+   * @param subscriber The subscriber\n+   */\n+  @Override\n+  public void subscribe(final Subscriber<? super T> subscriber) {\n+    Objects.requireNonNull(subscriber);\n+    if (Vertx.currentContext() == ctx) {\n+      doSubscribe(subscriber);\n+    } else {\n+      ctx.runOnContext(v -> doSubscribe(subscriber));\n+    }\n+  }\n+\n+  /**\n+   * Hook to allow subclasses to inject errors etc.\n+   * This will be called before onNext is called on the subscriber to deliver an element\n+   *\n+   * @return true if processing should continue\n+   */\n+  protected boolean beforeOnNext() {\n+    return true;\n+  }\n+\n+  protected final void sendError(final Exception e) {\n+    checkContext();\n+    try {\n+      subscriber.onError(e);\n+      cancelled = true;\n+    } catch (Throwable t) {\n+      logError(\"Exceptions must not be thrown from onError\", t);\n+    }\n+  }\n+\n+  private void sendComplete() {\n+    try {\n+      cancelled = true;\n+      subscriber.onComplete();\n+    } catch (Throwable t) {\n+      logError(\"Exceptions must not be thrown from onComplete\", t);\n+    }\n+  }\n+\n+  private void doSubscribe(final Subscriber<? super T> subscriber) {\n+    this.subscriber = subscriber;\n+    try {\n+      subscriber.onSubscribe(new Sub());\n+    } catch (final Throwable t) {\n+      sendError(new IllegalStateException(\"Exceptions must not be thrown from onSubscribe\", t));\n+    }\n+  }\n+\n+  private void checkContext() {\n+    if (Vertx.currentContext() != ctx) {\n+      throw new IllegalStateException(\"On wrong context\");\n+    }\n+  }\n+\n+  private void doSend() {\n+    int numSent = 0;\n+    while (!cancelled && demand > 0 && !buffer.isEmpty()) {\n+      if (numSent < SEND_MAX_BATCH_SIZE) {\n+        final T val = buffer.poll();\n+        doOnNext(val);\n+        numSent++;\n+      } else {\n+        // Schedule another batch async\n+        ctx.runOnContext(v -> doSend());\n+        break;\n+      }\n+    }\n+\n+    if (buffer.isEmpty() && !cancelled) {\n+      if (complete) {\n+        sendComplete();\n+      } else if (demand > 0 && drainHandler != null) {\n+        final Runnable handler = drainHandler;\n+        ctx.runOnContext(v -> handler.run());\n+        drainHandler = null;\n+      }\n+    }\n+  }\n+\n+  private void doOnNext(final T val) {\n+    if (!beforeOnNext()) {\n+      return;\n+    }\n+    try {\n+      subscriber.onNext(val);\n+    } catch (final Throwable t) {\n+      logError(\"Exceptions must not be thrown from onNext\", t);\n+    }\n+    // If demand == Long.MAX_VALUE this means \"infinite demand\"\n+    if (demand != Long.MAX_VALUE) {\n+      demand--;\n+    }\n+  }\n+\n+  private void logError(final String message, final Throwable t) {\n+    log.error(message, t);\n+    cancelled = true;\n+  }\n+\n+  private void doRequest(final long n) {\n+    if (n <= 0) {\n+      sendError(new IllegalArgumentException(\"Amount requested must be > 0\"));\n+    } else if (demand + n < 1) {\n+      // Catch overflow and set to \"infinite\"\n+      demand = Long.MAX_VALUE;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a37e469a95e67886bc7648a9e8c2cdee6f887c9a"}, "originalPosition": 264}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA4MTAxNg==", "bodyText": "Intent might be clearer with something like:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                } else if (demand + n < 1) {\n          \n          \n            \n                } else if (n > Long.MAX_VALUE - demand) {\n          \n      \n    \n    \n  \n\nBut no biggie.", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370081016", "createdAt": "2020-01-23T12:08:36Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/BufferedPublisher.java", "diffHunk": "@@ -0,0 +1,289 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.ArrayDeque;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Objects;\n+import java.util.Queue;\n+import org.reactivestreams.Publisher;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams publisher which can buffer received elements before sending them to it's\n+ * subscriber. The state for this publisher will always be accessed on the same Vert.x context so\n+ * does not require synchronization\n+ *\n+ * @param <T> The type of the element\n+ */\n+public class BufferedPublisher<T> implements Publisher<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(BufferedPublisher.class);\n+  public static final int SEND_MAX_BATCH_SIZE = 10;\n+  public static final int DEFAULT_BUFFER_MAX_SIZE = 100;\n+\n+  private final Context ctx;\n+  private final Queue<T> buffer = new ArrayDeque<>();\n+  private final int bufferMaxSize;\n+  private Subscriber<? super T> subscriber;\n+  private long demand;\n+  private boolean cancelled;\n+  private Runnable drainHandler;\n+  private boolean complete;\n+  private boolean completing;\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx The Vert.x context to use for the publisher - the publisher code must always be\n+   *            executed on this context. This ensures the code is never executed concurrently by\n+   *            more than one thread.\n+   */\n+  public BufferedPublisher(final Context ctx) {\n+    this(ctx, Collections.emptySet(), DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer) {\n+    this(ctx, initialBuffer, DEFAULT_BUFFER_MAX_SIZE);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param bufferMaxSize Indicative max number of elements to store in the buffer. Note that this\n+   *                      is not enforced, but it used to determine what to return from the accept\n+   *                      method so the caller can stop sending more and set a drainHandler to be\n+   *                      notified when the buffer is cleared\n+   */\n+  public BufferedPublisher(final Context ctx, final int bufferMaxSize) {\n+    this(ctx, Collections.emptySet(), bufferMaxSize);\n+  }\n+\n+  /**\n+   * Construct a BufferedPublisher\n+   *\n+   * @param ctx           The Vert.x context to use for the publisher\n+   * @param initialBuffer A collection of elements to initialise the buffer with\n+   * @param bufferMaxSize Indicative max number of elements to buffer\n+   */\n+  public BufferedPublisher(final Context ctx, final Collection<T> initialBuffer,\n+      final int bufferMaxSize) {\n+    this.ctx = ctx;\n+    this.buffer.addAll(initialBuffer);\n+    this.bufferMaxSize = bufferMaxSize;\n+  }\n+\n+  /**\n+   * Provide an element to the publisher. The publisher will attempt to deliver it to it's\n+   * subscriber (if any). The publisher will buffer it internally if it can't deliver it\n+   * immediately.\n+   *\n+   * @param t The element\n+   * @return true if the internal buffer is 'full'. I.e. if number of elements is >= bufferMaxSize.\n+   */\n+  public boolean accept(final T t) {\n+    checkContext();\n+    if (completing) {\n+      throw new IllegalStateException(\"Cannot call accept after complete is called\");\n+    }\n+    if (!cancelled) {\n+      if (demand == 0 || cancelled) {\n+        buffer.add(t);\n+      } else {\n+        doOnNext(t);\n+      }\n+    }\n+    return buffer.size() >= bufferMaxSize;\n+  }\n+\n+  /**\n+   * If you set a drain handler. It will be called if, after delivery is attempted there are zero\n+   * elements buffered internally and there is demand from the subscriber for more elements. Drain\n+   * handlers are one shot handlers, after being it will never be called more than once.\n+   *\n+   * @param handler The handler\n+   */\n+  public void drainHandler(final Runnable handler) {\n+    checkContext();\n+    this.drainHandler = handler;\n+  }\n+\n+  /**\n+   * Mark the incoming stream of elements as complete. This means onComplete will be called on any\n+   * subscriber after any buffered messages have been delivered. Once complete has been called no\n+   * further elements will be accepted\n+   */\n+  public void complete() {\n+    checkContext();\n+    if (cancelled || complete) {\n+      return;\n+    }\n+    completing = true;\n+    if (buffer.isEmpty() && subscriber != null) {\n+      sendComplete();\n+    } else {\n+      complete = true;\n+    }\n+  }\n+\n+  /**\n+   * Subscribe a subscriber to this publisher. The publisher will allow at most one subscriber.\n+   *\n+   * @param subscriber The subscriber\n+   */\n+  @Override\n+  public void subscribe(final Subscriber<? super T> subscriber) {\n+    Objects.requireNonNull(subscriber);\n+    if (Vertx.currentContext() == ctx) {\n+      doSubscribe(subscriber);\n+    } else {\n+      ctx.runOnContext(v -> doSubscribe(subscriber));\n+    }\n+  }\n+\n+  /**\n+   * Hook to allow subclasses to inject errors etc.\n+   * This will be called before onNext is called on the subscriber to deliver an element\n+   *\n+   * @return true if processing should continue\n+   */\n+  protected boolean beforeOnNext() {\n+    return true;\n+  }\n+\n+  protected final void sendError(final Exception e) {\n+    checkContext();\n+    try {\n+      subscriber.onError(e);\n+      cancelled = true;\n+    } catch (Throwable t) {\n+      logError(\"Exceptions must not be thrown from onError\", t);\n+    }\n+  }\n+\n+  private void sendComplete() {\n+    try {\n+      cancelled = true;\n+      subscriber.onComplete();\n+    } catch (Throwable t) {\n+      logError(\"Exceptions must not be thrown from onComplete\", t);\n+    }\n+  }\n+\n+  private void doSubscribe(final Subscriber<? super T> subscriber) {\n+    this.subscriber = subscriber;\n+    try {\n+      subscriber.onSubscribe(new Sub());\n+    } catch (final Throwable t) {\n+      sendError(new IllegalStateException(\"Exceptions must not be thrown from onSubscribe\", t));\n+    }\n+  }\n+\n+  private void checkContext() {\n+    if (Vertx.currentContext() != ctx) {\n+      throw new IllegalStateException(\"On wrong context\");\n+    }\n+  }\n+\n+  private void doSend() {\n+    int numSent = 0;\n+    while (!cancelled && demand > 0 && !buffer.isEmpty()) {\n+      if (numSent < SEND_MAX_BATCH_SIZE) {\n+        final T val = buffer.poll();\n+        doOnNext(val);\n+        numSent++;\n+      } else {\n+        // Schedule another batch async\n+        ctx.runOnContext(v -> doSend());\n+        break;\n+      }\n+    }\n+\n+    if (buffer.isEmpty() && !cancelled) {\n+      if (complete) {\n+        sendComplete();\n+      } else if (demand > 0 && drainHandler != null) {\n+        final Runnable handler = drainHandler;\n+        ctx.runOnContext(v -> handler.run());\n+        drainHandler = null;\n+      }\n+    }\n+  }\n+\n+  private void doOnNext(final T val) {\n+    if (!beforeOnNext()) {\n+      return;\n+    }\n+    try {\n+      subscriber.onNext(val);\n+    } catch (final Throwable t) {\n+      logError(\"Exceptions must not be thrown from onNext\", t);\n+    }\n+    // If demand == Long.MAX_VALUE this means \"infinite demand\"\n+    if (demand != Long.MAX_VALUE) {\n+      demand--;\n+    }\n+  }\n+\n+  private void logError(final String message, final Throwable t) {\n+    log.error(message, t);\n+    cancelled = true;\n+  }\n+\n+  private void doRequest(final long n) {\n+    if (n <= 0) {\n+      sendError(new IllegalArgumentException(\"Amount requested must be > 0\"));\n+    } else if (demand + n < 1) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a37e469a95e67886bc7648a9e8c2cdee6f887c9a"}, "originalPosition": 262}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDA4MzAyNQ==", "bodyText": "Can this not make use of decodeJsonObject? e.g. something like:\nfinal JsonObject row = decodeJsonObject(buff, routingContext);\nif (row == null) {\n   acksSubscriber.cancel();\n   return;\n}", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370083025", "createdAt": "2020-01-23T12:13:27Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyHandler.java", "diffHunk": "@@ -79,16 +89,35 @@ public void handleBodyBuffer(final Buffer buff) {\n         return;\n       }\n       final JsonObject properties = args.getJsonObject(\"properties\");\n-      routingContext.request().endHandler(this::handleBodyEnd);\n-      acksSubscriber = acks ? new AcksSubscriber(routingContext.response()) : null;\n+      acksSubscriber = acks ? new AcksSubscriber(ctx, routingContext.response()) : null;\n       final InsertsSubscriber insertsSubscriber = endpoints\n           .createInsertsSubscriber(target, properties, acksSubscriber);\n-      publisher = new InsertsPublisher();\n+      publisher = new BufferedPublisher<>(ctx);\n+\n+      // This forces response headers to be written so we know we send a 200 OK\n+      // This is important if we subsequently find an error in the stream\n+      routingContext.response().write(\"\");\n+\n       publisher.subscribe(insertsSubscriber);\n     } else if (publisher != null) {\n-      final JsonObject row = new JsonObject(buff);\n-      publisher.receiveRow(row);\n+      final JsonObject row;\n+      try {\n+        row = new JsonObject(buff);\n+      } catch (DecodeException e) {\n+        final JsonObject errResponse = ServerUtils\n+            .createErrResponse(ErrorCodes.ERROR_CODE_INVALID_JSON,\n+                \"Invalid JSON in inserts stream\");\n+        routingContext.response().write(errResponse.toBuffer().appendString(\"\\n\")).end();\n+        acksSubscriber.cancel();\n+        return;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a37e469a95e67886bc7648a9e8c2cdee6f887c9a"}, "originalPosition": 108}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEyMDE2MQ==", "bodyText": "There's a very simple state machine encoded in this handleBodyBuffermethod. If we were to move the implementation of each step into a separate method II think that state machine would be more obvious, e.g.\npublic void handleBodyBuffer(final Buffer buff) {\n    if (!hasReadArguments) {\n        readArguments(buff);\n    } else if (publisher != null) {\n       publishInsert(buff);\n    } else {\n        // Do nothing as failed to initialize, likely due to invalid request.\n    }\n}", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370120161", "createdAt": "2020-01-23T13:37:27Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/InsertsBodyHandler.java", "diffHunk": "@@ -34,38 +38,44 @@\n  * (also encoded as UTF-8 text) each representing a row to insert. The last JSON object must be\n  * followed by a new-line.\n  */\n-public class InsertsBodyParser {\n+public class InsertsBodyHandler {\n \n+  private final Context ctx;\n   private final Endpoints endpoints;\n   private final RoutingContext routingContext;\n-  private boolean readArguments;\n-  private InsertsPublisher publisher;\n+  private final RecordParser recordParser;\n+  private boolean hasReadArguments;\n+  private BufferedPublisher<JsonObject> publisher;\n   private long rowsReceived;\n   private AcksSubscriber acksSubscriber;\n \n-  public InsertsBodyParser(final Endpoints endpoints, final RoutingContext routingContext) {\n+  public InsertsBodyHandler(final Context ctx, final Endpoints endpoints,\n+      final RoutingContext routingContext) {\n+    this.ctx = ctx;\n     this.endpoints = Objects.requireNonNull(endpoints);\n     this.routingContext = Objects.requireNonNull(routingContext);\n-    routingContext.response().endHandler(v -> {\n-      if (publisher != null) {\n-        publisher.close();\n-      }\n-    });\n+    this.recordParser = RecordParser.newDelimited(\"\\n\", routingContext.request());\n   }\n \n   public void handleBodyEnd(final Void v) {\n-    if (acksSubscriber == null) {\n-      routingContext.response().end();\n-    } else {\n-      // We close the response after the stream of acks has been sent\n-      acksSubscriber.insertsSent(rowsReceived);\n+    if (publisher != null) {\n+      publisher.complete();\n+      if (acksSubscriber == null) {\n+        routingContext.response().end();\n+      } else {\n+        // We close the response after the stream of acks has been sent\n+        acksSubscriber.insertsSent(rowsReceived);\n+      }\n     }\n   }\n \n   public void handleBodyBuffer(final Buffer buff) {\n-    if (!readArguments) {\n-      final JsonObject args = new JsonObject(buff);\n-      readArguments = true;\n+    if (!hasReadArguments) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a37e469a95e67886bc7648a9e8c2cdee6f887c9a"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEyMTA0NA==", "bodyText": "nit: validate parameters that will be stored in fields.", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370121044", "createdAt": "2020-01-23T13:39:18Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ReactiveSubscriber.java", "diffHunk": "@@ -0,0 +1,198 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api.server;\n+\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.Objects;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * A reactive streams subscriber which handles much of the plumbing for you. Override {@link\n+ * #afterSubscribe}, {@link #handleValue}, {@link #handleComplete} and {@link #handleError} to\n+ * create your specific implementation. The state for this subscriber will always be accessed on the\n+ * same Vert.x context so does not require synchronization\n+ *\n+ * @param <T> The type of the value\n+ */\n+public class ReactiveSubscriber<T> implements Subscriber<T> {\n+\n+  private static final Logger log = LoggerFactory.getLogger(ReactiveSubscriber.class);\n+\n+  protected final Context context;\n+  private Subscription subscription;\n+  private boolean complete;\n+\n+  /**\n+   * Construct a ReactiveSubscriber\n+   *\n+   * @param context The Vert.x context to use for the subscriber - the subscriber code will always\n+   *                be executed on this context. This ensures the code is never executed\n+   *                concurrently by more than one thread.\n+   */\n+  public ReactiveSubscriber(final Context context) {\n+    this.context = context;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a37e469a95e67886bc7648a9e8c2cdee6f887c9a"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEyMjQwOA==", "bodyText": "Might be worth pulling the cancel functionality out into a new base class, e.g. CancelableSubcriber", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370122408", "createdAt": "2020-01-23T13:41:53Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/AcksSubscriber.java", "diffHunk": "@@ -17,96 +17,107 @@\n \n import static io.confluent.ksql.api.server.ErrorCodes.ERROR_CODE_INTERNAL_ERROR;\n \n+import io.vertx.core.Context;\n import io.vertx.core.buffer.Buffer;\n import io.vertx.core.http.HttpServerResponse;\n import io.vertx.core.json.JsonObject;\n-import java.util.Objects;\n-import org.reactivestreams.Subscriber;\n import org.reactivestreams.Subscription;\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n /**\n- * As the stream of inserts is processed by the back-end, it communicates success (or failure) of\n- * each insert by sending a stream of acks back in the other direction. This class is the subscriber\n- * which subscribes to that stream of acks and sends them back to the client. It's a reactive\n- * streams subscriber so implements back pressure.\n+ * A reactive streams subscriber that subscribes to publishers of acks. As it receive acks it writes\n+ * them to the HTTP response.\n  */\n-public class AcksSubscriber implements Subscriber<Void> {\n+public class AcksSubscriber extends ReactiveSubscriber<JsonObject> {\n \n-  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n-  private static final int BATCH_SIZE = 4;\n   private static final Buffer ACK_RESPONSE_LINE = new JsonObject().put(\"status\", \"ok\").toBuffer()\n       .appendString(\"\\n\");\n+  private static final Logger log = LoggerFactory.getLogger(AcksSubscriber.class);\n+  private static final int REQUEST_BATCH_SIZE = 1000;\n \n   private final HttpServerResponse response;\n-  private Subscription subscription;\n-  private long tokens;\n   private Long insertsSent;\n   private long acksSent;\n+  private boolean drainHandlerSet;\n+  private Subscription subscription;\n+  private boolean cancelled;\n \n-  public AcksSubscriber(final HttpServerResponse response) {\n-    this.response = Objects.requireNonNull(response);\n+  public AcksSubscriber(final Context context, final HttpServerResponse response) {\n+    super(context);\n+    this.response = response;\n   }\n \n   @Override\n-  public synchronized void onSubscribe(final Subscription subscription) {\n-    Objects.requireNonNull(subscription);\n-    if (this.subscription != null) {\n-      throw new IllegalStateException(\"Already subscribed\");\n-    }\n+  protected void afterSubscribe(final Subscription subscription) {\n+    makeRequest(REQUEST_BATCH_SIZE);\n     this.subscription = subscription;\n-    checkRequestTokens();\n   }\n \n   @Override\n-  public synchronized void onNext(final Void vo) {\n-    if (tokens == 0) {\n-      throw new IllegalStateException(\"Unsolicited data\");\n+  public void handleValue(final JsonObject value) {\n+    checkContext();\n+    if (cancelled) {\n+      return;\n     }\n     response.write(ACK_RESPONSE_LINE);\n     acksSent++;\n-    tokens--;\n     if (insertsSent != null && insertsSent == acksSent) {\n       close();\n     } else if (response.writeQueueFull()) {\n-      response.drainHandler(v -> checkRequestTokens());\n+      if (!drainHandlerSet) {\n+        response.drainHandler(v -> {\n+          drainHandlerSet = false;\n+          checkMakeRequest();\n+        });\n+        drainHandlerSet = true;\n+      }\n     } else {\n-      checkRequestTokens();\n-    }\n-  }\n-\n-  synchronized void insertsSent(final long num) {\n-    this.insertsSent = num;\n-    if (acksSent == num) {\n-      close();\n+      checkMakeRequest();\n     }\n   }\n \n-  private void close() {\n+  @Override\n+  public void handleComplete() {\n     response.end();\n-    subscription.cancel();\n-  }\n-\n-  private void checkRequestTokens() {\n-    if (tokens == 0) {\n-      tokens = BATCH_SIZE;\n-      subscription.request(BATCH_SIZE);\n-    }\n   }\n \n   @Override\n-  public synchronized void onError(final Throwable t) {\n+  public void handleError(final Throwable t) {\n+    if (cancelled) {\n+      return;\n+    }\n     log.error(\"Error in processing inserts\", t);\n     final JsonObject err = new JsonObject().put(\"status\", \"error\")\n         .put(\"errorCode\", ERROR_CODE_INTERNAL_ERROR)\n         .put(\"message\", \"Error in processing inserts\");\n-    subscription.cancel();\n     response.end(err.toBuffer());\n   }\n \n-  @Override\n-  public synchronized void onComplete() {\n+  public void cancel() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a37e469a95e67886bc7648a9e8c2cdee6f887c9a"}, "originalPosition": 126}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEyNjU3NA==", "bodyText": "The rest of the code base generally avoids returning nulls from public methods, preferring to encode the optionality of the result into the type system.  It would be nice if you're code followed this convention as well.\nYes, this results in the need to call .get() or .orElse(), but also provides a compile time check that callers handle the null case.   Thus reducing the risk of latent bugs due to calling code not handling null return values.\nSo, for example, you can still use it like this:\nfinal JsonObject requestBody = decodeJsonObject(routingContext.getBody(), routingContext).orElse(null);\n    if (requestBody == null) {\n      return;\n    }", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370126574", "createdAt": "2020-01-23T13:49:43Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/main/java/io/confluent/ksql/api/server/ServerUtils.java", "diffHunk": "@@ -32,14 +37,29 @@ private ServerUtils() {\n \n   public static void handleError(final HttpServerResponse response, final int statusCode,\n       final int errorCode, final String errMsg) {\n-    final JsonObject errResponse = new JsonObject().put(\"status\", \"error\")\n+    final JsonObject errResponse = createErrResponse(errorCode, errMsg);\n+    response.setStatusCode(statusCode).end(errResponse.toBuffer());\n+  }\n+\n+  public static JsonObject createErrResponse(final int errorCode, final String errMsg) {\n+    return new JsonObject().put(\"status\", \"error\")\n         .put(\"errorCode\", errorCode)\n         .put(\"message\", errMsg);\n-    response.setStatusCode(statusCode).end(errResponse.toBuffer());\n   }\n \n   public static void unhandledExceptonHandler(final Throwable t) {\n     log.error(\"Unhandled exception\", t);\n   }\n \n+  public static JsonObject decodeJsonObject(final Buffer buffer,\n+      final RoutingContext routingContext) {\n+    try {\n+      return new JsonObject(buffer);\n+    } catch (DecodeException e) {\n+      handleError(routingContext.response(), 400, ERROR_CODE_INVALID_JSON,\n+          \"Invalid JSON in request args\");\n+      return null;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTMyODk0MQ=="}, "originalCommit": {"oid": "3ba0d8a04f8ce7312a273230cc748f14d7def04b"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEzMDg3Ng==", "bodyText": "do we really need to check both?", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370130876", "createdAt": "2020-01-23T13:57:37Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "diffHunk": "@@ -545,6 +548,70 @@ public void shouldHandleErrorInProcessingInserts() throws Exception {\n     assertTrue(testEndpoints.getInsertsSubscriber().isCompleted());\n   }\n \n+  @Test\n+  public void shouldRejectMalformedJsonInInsertsStreamArgs() throws Exception {\n+    shouldRejectMalformedJsonInArgs(\"/inserts-stream\");\n+  }\n+\n+  @Test\n+  public void shouldHandleMalformedJsonInInsertsStream() throws Exception {\n+\n+    JsonObject params = new JsonObject().put(\"target\", \"test-stream\").put(\"acks\", true);\n+\n+    List<JsonObject> rows = generateInsertRows();\n+    Buffer requestBody = Buffer.buffer();\n+    requestBody.appendBuffer(params.toBuffer()).appendString(\"\\n\");\n+    for (int i = 0; i < rows.size() - 1; i++) {\n+      JsonObject row = rows.get(i);\n+      requestBody.appendBuffer(row.toBuffer()).appendString(\"\\n\");\n+    }\n+    // Malformed row for the last one\n+    requestBody.appendString(\"{ijqwdijqw\");\n+\n+    // The HTTP response will be OK as the error is later in the stream after response\n+    // headers have been written\n+    HttpResponse<Buffer> response = sendRequest(\"/inserts-stream\", requestBody);\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a37e469a95e67886bc7648a9e8c2cdee6f887c9a"}, "originalPosition": 164}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEzMjA2MA==", "bodyText": "From a useability point of view, how does the user know which insert statement contained invalid JSON?  Could we include the text maybe?", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370132060", "createdAt": "2020-01-23T13:59:31Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/test/java/io/confluent/ksql/api/ApiTest.java", "diffHunk": "@@ -545,6 +548,70 @@ public void shouldHandleErrorInProcessingInserts() throws Exception {\n     assertTrue(testEndpoints.getInsertsSubscriber().isCompleted());\n   }\n \n+  @Test\n+  public void shouldRejectMalformedJsonInInsertsStreamArgs() throws Exception {\n+    shouldRejectMalformedJsonInArgs(\"/inserts-stream\");\n+  }\n+\n+  @Test\n+  public void shouldHandleMalformedJsonInInsertsStream() throws Exception {\n+\n+    JsonObject params = new JsonObject().put(\"target\", \"test-stream\").put(\"acks\", true);\n+\n+    List<JsonObject> rows = generateInsertRows();\n+    Buffer requestBody = Buffer.buffer();\n+    requestBody.appendBuffer(params.toBuffer()).appendString(\"\\n\");\n+    for (int i = 0; i < rows.size() - 1; i++) {\n+      JsonObject row = rows.get(i);\n+      requestBody.appendBuffer(row.toBuffer()).appendString(\"\\n\");\n+    }\n+    // Malformed row for the last one\n+    requestBody.appendString(\"{ijqwdijqw\");\n+\n+    // The HTTP response will be OK as the error is later in the stream after response\n+    // headers have been written\n+    HttpResponse<Buffer> response = sendRequest(\"/inserts-stream\", requestBody);\n+    assertEquals(200, response.statusCode());\n+    assertEquals(\"OK\", response.statusMessage());\n+\n+    String responseBody = response.bodyAsString();\n+    InsertsResponse insertsResponse = new InsertsResponse(responseBody);\n+    validateError(ERROR_CODE_INVALID_JSON, \"Invalid JSON in inserts stream\", insertsResponse.error);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a37e469a95e67886bc7648a9e8c2cdee6f887c9a"}, "originalPosition": 168}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDEzNTc5NA==", "bodyText": "What's the benefit of accepting a supplier, rather than the actual value, given the code immediately calls get() on the supplier, and only calls get() once?  Surely this can be simplified to just take the actual value?", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370135794", "createdAt": "2020-01-23T14:06:16Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/test/java/io/confluent/ksql/api/TestUtils.java", "diffHunk": "@@ -0,0 +1,51 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.function.Supplier;\n+import org.hamcrest.Matcher;\n+\n+public class TestUtils {\n+\n+  public static void awaitLatch(CountDownLatch latch) throws Exception {\n+    assertThat(latch.await(2000, TimeUnit.MILLISECONDS), is(true));\n+  }\n+\n+  public static class AsyncAssert {\n+\n+    private AssertionError error;\n+\n+    public synchronized <T> void assertAsync(Supplier<? extends T> actualSupplier,\n+        Matcher<? super T> expected) {\n+      try {\n+        assertThat(actualSupplier.get(), expected);\n+      } catch (AssertionError e) {\n+        error = e;\n+      }\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a37e469a95e67886bc7648a9e8c2cdee6f887c9a"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0MDA3Mg==", "bodyText": "Unnecessary override: this can just be deleted, right?", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370140072", "createdAt": "2020-01-23T14:13:50Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/test/java/io/confluent/ksql/api/BufferedPublisherTest.java", "diffHunk": "@@ -0,0 +1,430 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api;\n+\n+\n+import static io.confluent.ksql.test.util.AssertEventually.assertThatEventually;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.hasSize;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.notNullValue;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.hamcrest.core.IsInstanceOf.instanceOf;\n+\n+import io.confluent.ksql.api.TestUtils.AsyncAssert;\n+import io.confluent.ksql.api.server.BufferedPublisher;\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+\n+/**\n+ * More BufferedPublisher testing occurs in the TCK tests\n+ */\n+public class BufferedPublisherTest {\n+\n+  private Vertx vertx;\n+  private Context context;\n+  private BufferedPublisher<String> publisher;\n+\n+  @Before\n+  public void setUp() {\n+    vertx = Vertx.vertx();\n+    context = vertx.getOrCreateContext();\n+    publisher = new BufferedPublisher<>(context);\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    vertx.close();\n+  }\n+\n+  @Test\n+  public void shouldCallOnSubscribe() throws Exception {\n+    TestSubscriber subscriber = new TestSubscriber(context);\n+    subscribeOnContext(subscriber);\n+    assertThat(subscriber.getSub(), is(notNullValue()));\n+  }\n+\n+  @Test\n+  public void shouldDeliverOneRecordWhenOneIsRequested() throws Exception {\n+    loadPublisher(10);\n+    shouldDeliver(1, 1);\n+  }\n+\n+  @Test\n+  public void shouldDeliverSevenRecordsWhenSevenIsRequested() throws Exception {\n+    loadPublisher(10);\n+    shouldDeliver(7, 7);\n+  }\n+\n+  @Test\n+  public void shouldDeliverAllRecordsWhenAllAreRequested() throws Exception {\n+    loadPublisher(10);\n+    shouldDeliver(10, 10);\n+  }\n+\n+  @Test\n+  public void shouldDeliverAllRecordsWhenMoreAreRequested() throws Exception {\n+    loadPublisher(10);\n+    shouldDeliver(15, 10);\n+  }\n+\n+  @Test\n+  public void shouldDeliverMoreThanMaxSendBatchSize() throws Exception {\n+    int num = 2 * BufferedPublisher.SEND_MAX_BATCH_SIZE;\n+    loadPublisher(num);\n+    shouldDeliver(num, num);\n+  }\n+\n+  @Test\n+  public void shouldDeliverAllRequestingOneByOne() throws Exception {\n+    loadPublisher(10);\n+    TestSubscriber subscriber = new TestSubscriber(context) {\n+\n+      @Override\n+      public synchronized void onSubscribe(final Subscription sub) {\n+        super.onSubscribe(sub);\n+        sub.request(1);\n+      }\n+\n+      @Override\n+      public synchronized void onNext(final String value) {\n+        super.onNext(value);\n+        getSub().request(1);\n+      }\n+    };\n+    subscribeOnContext(subscriber);\n+    assertThatEventually(subscriber::getValues, hasSize(10));\n+    for (int i = 0; i < 10; i++) {\n+      assertThat(subscriber.getValues().get(i), equalTo(\"record\" + i));\n+    }\n+    assertThat(subscriber.isCompleted(), equalTo(false));\n+    assertThat(subscriber.getError(), is(nullValue()));\n+  }\n+\n+  @Test\n+  public void shouldFailWhenZeroRequested() throws Exception {\n+    loadPublisher(10);\n+    TestSubscriber subscriber = new TestSubscriber(context) {\n+\n+      @Override\n+      public synchronized void onSubscribe(final Subscription sub) {\n+        super.onSubscribe(sub);\n+        sub.request(0);\n+      }\n+    };\n+    subscribeOnContext(subscriber);\n+    assertThatEventually(subscriber::getError, is(notNullValue()));\n+    assertThat(subscriber.getValues(), hasSize(0));\n+    assertThat(subscriber.getError(), instanceOf(IllegalArgumentException.class));\n+  }\n+\n+  @Test\n+  public void shouldFailWhenNegativeRequested() throws Exception {\n+    loadPublisher(10);\n+    TestSubscriber subscriber = new TestSubscriber(context) {\n+\n+      @Override\n+      public synchronized void onSubscribe(final Subscription sub) {\n+        super.onSubscribe(sub);\n+        sub.request(-1);\n+      }\n+    };\n+    subscribeOnContext(subscriber);\n+    assertThatEventually(subscriber::getError, is(notNullValue()));\n+    assertThat(subscriber.getValues(), hasSize(0));\n+    assertThat(subscriber.getError(), instanceOf(IllegalArgumentException.class));\n+  }\n+\n+  @Test\n+  public void shouldCompleteWhenNoRecords() throws Exception {\n+    TestSubscriber subscriber = new TestSubscriber(context);\n+    subscribeOnContext(subscriber);\n+    execOnContextAndWait(publisher::complete);\n+    assertThatEventually(subscriber::isCompleted, equalTo(true));\n+  }\n+\n+  @Test\n+  public void shouldCompleteAfterDeliveringRecords() throws Exception {\n+    loadPublisher(10);\n+    AsyncAssert asyncAssert = new AsyncAssert();\n+    TestSubscriber subscriber = new TestSubscriber(context) {\n+      @Override\n+      public synchronized void onSubscribe(final Subscription sub) {\n+        super.onSubscribe(sub);\n+        sub.request(1);\n+      }\n+\n+      @Override\n+      public synchronized void onNext(final String value) {\n+        super.onNext(value);\n+        asyncAssert.assertAsync(this::isCompleted, equalTo(false));\n+        getSub().request(1);\n+      }\n+\n+      @Override\n+      public synchronized void onComplete() {\n+        super.onComplete();\n+      }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a37e469a95e67886bc7648a9e8c2cdee6f887c9a"}, "originalPosition": 190}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0MDEyNQ==", "bodyText": "Unnecessary override: this can just be deleted, right?", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370140125", "createdAt": "2020-01-23T14:13:56Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/test/java/io/confluent/ksql/api/BufferedPublisherTest.java", "diffHunk": "@@ -0,0 +1,430 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api;\n+\n+\n+import static io.confluent.ksql.test.util.AssertEventually.assertThatEventually;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.hasSize;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.notNullValue;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.hamcrest.core.IsInstanceOf.instanceOf;\n+\n+import io.confluent.ksql.api.TestUtils.AsyncAssert;\n+import io.confluent.ksql.api.server.BufferedPublisher;\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+\n+/**\n+ * More BufferedPublisher testing occurs in the TCK tests\n+ */\n+public class BufferedPublisherTest {\n+\n+  private Vertx vertx;\n+  private Context context;\n+  private BufferedPublisher<String> publisher;\n+\n+  @Before\n+  public void setUp() {\n+    vertx = Vertx.vertx();\n+    context = vertx.getOrCreateContext();\n+    publisher = new BufferedPublisher<>(context);\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    vertx.close();\n+  }\n+\n+  @Test\n+  public void shouldCallOnSubscribe() throws Exception {\n+    TestSubscriber subscriber = new TestSubscriber(context);\n+    subscribeOnContext(subscriber);\n+    assertThat(subscriber.getSub(), is(notNullValue()));\n+  }\n+\n+  @Test\n+  public void shouldDeliverOneRecordWhenOneIsRequested() throws Exception {\n+    loadPublisher(10);\n+    shouldDeliver(1, 1);\n+  }\n+\n+  @Test\n+  public void shouldDeliverSevenRecordsWhenSevenIsRequested() throws Exception {\n+    loadPublisher(10);\n+    shouldDeliver(7, 7);\n+  }\n+\n+  @Test\n+  public void shouldDeliverAllRecordsWhenAllAreRequested() throws Exception {\n+    loadPublisher(10);\n+    shouldDeliver(10, 10);\n+  }\n+\n+  @Test\n+  public void shouldDeliverAllRecordsWhenMoreAreRequested() throws Exception {\n+    loadPublisher(10);\n+    shouldDeliver(15, 10);\n+  }\n+\n+  @Test\n+  public void shouldDeliverMoreThanMaxSendBatchSize() throws Exception {\n+    int num = 2 * BufferedPublisher.SEND_MAX_BATCH_SIZE;\n+    loadPublisher(num);\n+    shouldDeliver(num, num);\n+  }\n+\n+  @Test\n+  public void shouldDeliverAllRequestingOneByOne() throws Exception {\n+    loadPublisher(10);\n+    TestSubscriber subscriber = new TestSubscriber(context) {\n+\n+      @Override\n+      public synchronized void onSubscribe(final Subscription sub) {\n+        super.onSubscribe(sub);\n+        sub.request(1);\n+      }\n+\n+      @Override\n+      public synchronized void onNext(final String value) {\n+        super.onNext(value);\n+        getSub().request(1);\n+      }\n+    };\n+    subscribeOnContext(subscriber);\n+    assertThatEventually(subscriber::getValues, hasSize(10));\n+    for (int i = 0; i < 10; i++) {\n+      assertThat(subscriber.getValues().get(i), equalTo(\"record\" + i));\n+    }\n+    assertThat(subscriber.isCompleted(), equalTo(false));\n+    assertThat(subscriber.getError(), is(nullValue()));\n+  }\n+\n+  @Test\n+  public void shouldFailWhenZeroRequested() throws Exception {\n+    loadPublisher(10);\n+    TestSubscriber subscriber = new TestSubscriber(context) {\n+\n+      @Override\n+      public synchronized void onSubscribe(final Subscription sub) {\n+        super.onSubscribe(sub);\n+        sub.request(0);\n+      }\n+    };\n+    subscribeOnContext(subscriber);\n+    assertThatEventually(subscriber::getError, is(notNullValue()));\n+    assertThat(subscriber.getValues(), hasSize(0));\n+    assertThat(subscriber.getError(), instanceOf(IllegalArgumentException.class));\n+  }\n+\n+  @Test\n+  public void shouldFailWhenNegativeRequested() throws Exception {\n+    loadPublisher(10);\n+    TestSubscriber subscriber = new TestSubscriber(context) {\n+\n+      @Override\n+      public synchronized void onSubscribe(final Subscription sub) {\n+        super.onSubscribe(sub);\n+        sub.request(-1);\n+      }\n+    };\n+    subscribeOnContext(subscriber);\n+    assertThatEventually(subscriber::getError, is(notNullValue()));\n+    assertThat(subscriber.getValues(), hasSize(0));\n+    assertThat(subscriber.getError(), instanceOf(IllegalArgumentException.class));\n+  }\n+\n+  @Test\n+  public void shouldCompleteWhenNoRecords() throws Exception {\n+    TestSubscriber subscriber = new TestSubscriber(context);\n+    subscribeOnContext(subscriber);\n+    execOnContextAndWait(publisher::complete);\n+    assertThatEventually(subscriber::isCompleted, equalTo(true));\n+  }\n+\n+  @Test\n+  public void shouldCompleteAfterDeliveringRecords() throws Exception {\n+    loadPublisher(10);\n+    AsyncAssert asyncAssert = new AsyncAssert();\n+    TestSubscriber subscriber = new TestSubscriber(context) {\n+      @Override\n+      public synchronized void onSubscribe(final Subscription sub) {\n+        super.onSubscribe(sub);\n+        sub.request(1);\n+      }\n+\n+      @Override\n+      public synchronized void onNext(final String value) {\n+        super.onNext(value);\n+        asyncAssert.assertAsync(this::isCompleted, equalTo(false));\n+        getSub().request(1);\n+      }\n+\n+      @Override\n+      public synchronized void onComplete() {\n+        super.onComplete();\n+      }\n+    };\n+    subscribeOnContext(subscriber);\n+    execOnContextAndWait(publisher::complete);\n+    assertThatEventually(subscriber::isCompleted, equalTo(true));\n+    assertThat(subscriber.getValues(), hasSize(10));\n+    for (int i = 0; i < 10; i++) {\n+      assertThat(subscriber.getValues().get(i), equalTo(\"record\" + i));\n+    }\n+    asyncAssert.throwAssert();\n+  }\n+\n+  @Test\n+  public void shouldCompleteAfterDeliveringRecordsNoBuffering() throws Exception {\n+    AsyncAssert asyncAssertOnNext = new AsyncAssert();\n+    TestSubscriber subscriber = new TestSubscriber(context) {\n+      @Override\n+      public synchronized void onSubscribe(final Subscription sub) {\n+        super.onSubscribe(sub);\n+        sub.request(1);\n+      }\n+\n+      @Override\n+      public synchronized void onNext(final String value) {\n+        super.onNext(value);\n+        asyncAssertOnNext.assertAsync(this::isCompleted, equalTo(false));\n+        getSub().request(1);\n+      }\n+\n+      @Override\n+      public synchronized void onComplete() {\n+        super.onComplete();\n+      }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a37e469a95e67886bc7648a9e8c2cdee6f887c9a"}, "originalPosition": 222}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDE0MDQxMQ==", "bodyText": "If you had TestSubscriber's constructor take the initial request size you could simplify a lot of these tests.", "url": "https://github.com/confluentinc/ksql/pull/4354#discussion_r370140411", "createdAt": "2020-01-23T14:14:27Z", "author": {"login": "big-andy-coates"}, "path": "ksql-api/src/test/java/io/confluent/ksql/api/BufferedPublisherTest.java", "diffHunk": "@@ -0,0 +1,430 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.api;\n+\n+\n+import static io.confluent.ksql.test.util.AssertEventually.assertThatEventually;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.hasSize;\n+import static org.hamcrest.Matchers.is;\n+import static org.hamcrest.Matchers.notNullValue;\n+import static org.hamcrest.Matchers.nullValue;\n+import static org.hamcrest.core.IsInstanceOf.instanceOf;\n+\n+import io.confluent.ksql.api.TestUtils.AsyncAssert;\n+import io.confluent.ksql.api.server.BufferedPublisher;\n+import io.vertx.core.Context;\n+import io.vertx.core.Vertx;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.reactivestreams.Subscriber;\n+import org.reactivestreams.Subscription;\n+\n+/**\n+ * More BufferedPublisher testing occurs in the TCK tests\n+ */\n+public class BufferedPublisherTest {\n+\n+  private Vertx vertx;\n+  private Context context;\n+  private BufferedPublisher<String> publisher;\n+\n+  @Before\n+  public void setUp() {\n+    vertx = Vertx.vertx();\n+    context = vertx.getOrCreateContext();\n+    publisher = new BufferedPublisher<>(context);\n+  }\n+\n+  @After\n+  public void tearDown() {\n+    vertx.close();\n+  }\n+\n+  @Test\n+  public void shouldCallOnSubscribe() throws Exception {\n+    TestSubscriber subscriber = new TestSubscriber(context);\n+    subscribeOnContext(subscriber);\n+    assertThat(subscriber.getSub(), is(notNullValue()));\n+  }\n+\n+  @Test\n+  public void shouldDeliverOneRecordWhenOneIsRequested() throws Exception {\n+    loadPublisher(10);\n+    shouldDeliver(1, 1);\n+  }\n+\n+  @Test\n+  public void shouldDeliverSevenRecordsWhenSevenIsRequested() throws Exception {\n+    loadPublisher(10);\n+    shouldDeliver(7, 7);\n+  }\n+\n+  @Test\n+  public void shouldDeliverAllRecordsWhenAllAreRequested() throws Exception {\n+    loadPublisher(10);\n+    shouldDeliver(10, 10);\n+  }\n+\n+  @Test\n+  public void shouldDeliverAllRecordsWhenMoreAreRequested() throws Exception {\n+    loadPublisher(10);\n+    shouldDeliver(15, 10);\n+  }\n+\n+  @Test\n+  public void shouldDeliverMoreThanMaxSendBatchSize() throws Exception {\n+    int num = 2 * BufferedPublisher.SEND_MAX_BATCH_SIZE;\n+    loadPublisher(num);\n+    shouldDeliver(num, num);\n+  }\n+\n+  @Test\n+  public void shouldDeliverAllRequestingOneByOne() throws Exception {\n+    loadPublisher(10);\n+    TestSubscriber subscriber = new TestSubscriber(context) {\n+\n+      @Override\n+      public synchronized void onSubscribe(final Subscription sub) {\n+        super.onSubscribe(sub);\n+        sub.request(1);\n+      }\n+\n+      @Override\n+      public synchronized void onNext(final String value) {\n+        super.onNext(value);\n+        getSub().request(1);\n+      }\n+    };\n+    subscribeOnContext(subscriber);\n+    assertThatEventually(subscriber::getValues, hasSize(10));\n+    for (int i = 0; i < 10; i++) {\n+      assertThat(subscriber.getValues().get(i), equalTo(\"record\" + i));\n+    }\n+    assertThat(subscriber.isCompleted(), equalTo(false));\n+    assertThat(subscriber.getError(), is(nullValue()));\n+  }\n+\n+  @Test\n+  public void shouldFailWhenZeroRequested() throws Exception {\n+    loadPublisher(10);\n+    TestSubscriber subscriber = new TestSubscriber(context) {\n+\n+      @Override\n+      public synchronized void onSubscribe(final Subscription sub) {\n+        super.onSubscribe(sub);\n+        sub.request(0);\n+      }\n+    };\n+    subscribeOnContext(subscriber);\n+    assertThatEventually(subscriber::getError, is(notNullValue()));\n+    assertThat(subscriber.getValues(), hasSize(0));\n+    assertThat(subscriber.getError(), instanceOf(IllegalArgumentException.class));\n+  }\n+\n+  @Test\n+  public void shouldFailWhenNegativeRequested() throws Exception {\n+    loadPublisher(10);\n+    TestSubscriber subscriber = new TestSubscriber(context) {\n+\n+      @Override\n+      public synchronized void onSubscribe(final Subscription sub) {\n+        super.onSubscribe(sub);\n+        sub.request(-1);\n+      }\n+    };\n+    subscribeOnContext(subscriber);\n+    assertThatEventually(subscriber::getError, is(notNullValue()));\n+    assertThat(subscriber.getValues(), hasSize(0));\n+    assertThat(subscriber.getError(), instanceOf(IllegalArgumentException.class));\n+  }\n+\n+  @Test\n+  public void shouldCompleteWhenNoRecords() throws Exception {\n+    TestSubscriber subscriber = new TestSubscriber(context);\n+    subscribeOnContext(subscriber);\n+    execOnContextAndWait(publisher::complete);\n+    assertThatEventually(subscriber::isCompleted, equalTo(true));\n+  }\n+\n+  @Test\n+  public void shouldCompleteAfterDeliveringRecords() throws Exception {\n+    loadPublisher(10);\n+    AsyncAssert asyncAssert = new AsyncAssert();\n+    TestSubscriber subscriber = new TestSubscriber(context) {\n+      @Override\n+      public synchronized void onSubscribe(final Subscription sub) {\n+        super.onSubscribe(sub);\n+        sub.request(1);\n+      }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a37e469a95e67886bc7648a9e8c2cdee6f887c9a"}, "originalPosition": 178}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 119, "cost": 1, "resetAt": "2021-11-01T13:07:16Z"}}}