{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzczMzYyNzcy", "number": 4507, "title": "chore: Primitive Keys comes to PRINT TOPIC", "bodyText": "Description\nFixes: #4258\nThis change makes PRINT TOPIC output not just the format of the value, but also the key.\nOutput used to look like:\n    Format:JSON\n    {\"ROWTIME\":1544042630406,\"ROWKEY\":\"1\",\"type\":\"key1\",\"data\":{\"timestamp\":\"2018-12-21 23:58:42.1\",\"field-a\":1,\"field-b\":\"first-value-for-key1\"}}\n    ...\n\nThe old version tried to represent the whole row as a JSON Object, or Avro record, etc.  Going forward this doesn't make sense as there are two formats at play: key and value, and they are generally different.\nIt now looks like:\n    Key format: KAFKA (STRING)\n    Value format: JSON\n    rowtime: 02/10/2020 20:26:44 GMT, key: \"1\", value: {\"type\":\"key1\",\"data\":{\"timestamp\":\"2018-12-21 23:58:42.1\",\"field-a\":1,\"field-b\":\"first-value-for-key1\"}}\n    ...\n\nNote: the 'Key format' and 'Value format' a the top.\nNote: row format is now rowtime: <string timestamp>, key: <key>, value: <value>. Where:\n\n<string timestamp> is the timestamp of the record, formatted as string in local tz. (All formats but JSON already did this - now its standard)\n<key> is the formatted key output.\n<value> is the formatted value output.\n\nThere is also very basic mixed mode detection: it no longer just checks one record to determine formats. It now checks the whole batch and if the formats vary it displays them as MIXED and formats them as strings.\nLimitations:\n\nThere is no way to distinguish between a serialized DOUBLE vs BIGINT vs an 8-char STRING.\nThere is no way to distinguish between a serialized INT vs 4-char STRING.\n\nThere's not much we can do about the DOUBLE/BIGINT thing - it just defaults to formatting them as BIGINT, as that'll be way more common, and the format is displayed as KAFKA (BIGINT or DOUBLE).\nThe overlap with certain length STRING values is more of an issue. This likely needs more work. Ideally, PRINT would track the set of possible formats and narrow that down as it sees more records, e.g. if it repeatedly saw 4 bytes of data, it's probably an INT, where as if the first 5 records have 4 bytes, but then it changes to 7, then 1, then it's probably a STRING. etc.\nNot sure how the UX would work here though.   We could output 'possible formats per row' and narrow this down as we go.  Thoughts welcome.\nHow to review:\nCommits:\n\nRefactors PRINT TOPIC to:\n\nprep for key formats\nstandardized output, regardless of format, to: rowkey: <ts>, key: <key>, value: <value>.\nformat is no longer determined from first record: first batch is inspected\nadded MIXED format, where format varies per-row.  This defaults to formatting as a string.\nPRINT TOPIC no longer filters out null values. Each record in the topic results in a output row, which will help highlight data issues.\noutputs a message if it failed to deserialize a record, which will help highlight data issues.\nformatting is now lazy, meaning we avoid the formatting cost where INTERVAL != 1\n\n\nOutputs the key's format as well as the existing value's format.\nAdds KAFKA format\nChanges some text layout and fixes some tests.\n\nTesting done\nTests enhanced, added + manual\nReviewer checklist\n\n Ensure docs are updated if necessary. (eg. if a user visible feature is being added or changed).\n Ensure relevant issues are linked (description should include text like \"Fixes #\")", "createdAt": "2020-02-10T21:28:39Z", "url": "https://github.com/confluentinc/ksql/pull/4507", "merged": true, "mergeCommit": {"oid": "b4a0864a5e68014d0cef8718422665ceb0caac26"}, "closed": true, "closedAt": "2020-02-11T20:07:20Z", "author": {"login": "big-andy-coates"}, "timelineItems": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcDD94vAH2gAyMzczMzYyNzcyOmQyYThiMWNkNmI4MjY3Y2YxNWMxODlmMWQ0MmVhYWUwMDlkZDM2NzM=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcDXJm9AFqTM1NjkyNzY0MQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "d2a8b1cd6b8267cf15c189f1d42eaae009dd3673", "author": {"user": {"login": "big-andy-coates", "name": "Andy Coates"}}, "url": "https://github.com/confluentinc/ksql/commit/d2a8b1cd6b8267cf15c189f1d42eaae009dd3673", "committedDate": "2020-02-10T21:25:10Z", "message": "chore: refactor PRINT TOPIC functionality\n\n - prep for key formats\n - standardized output, regardless of format, to: `rowkey: <ts>, key: <key>, value: <value>`.\n - format is no longer determined from first record: first batch is inspected\n - added MIXED format, where format varies per-row.  This defaults to formatting as a string.\n - PRINT TOPIC no longer filters out null values. Each record in the topic results in a output row, which will help highlight data issues.\n - outputs a message if it failed to deserialize a record, which will help highlight data issues.\n - formatting is now lazy, meaning we avoid the formatting cost where INTERVAL != 1"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b772d877ba665fbfbe709c35b81e3b01f00a72c3", "author": {"user": {"login": "big-andy-coates", "name": "Andy Coates"}}, "url": "https://github.com/confluentinc/ksql/commit/b772d877ba665fbfbe709c35b81e3b01f00a72c3", "committedDate": "2020-02-10T22:17:40Z", "message": "chore: output KEY format"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f2ed450c3d36d4642faafa52d9e11e4c42da420f", "author": {"user": {"login": "big-andy-coates", "name": "Andy Coates"}}, "url": "https://github.com/confluentinc/ksql/commit/f2ed450c3d36d4642faafa52d9e11e4c42da420f", "committedDate": "2020-02-10T23:17:56Z", "message": "chore: add KAFKA format"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7beca3c9d325edade23cf3daa006cbcd44302682", "author": {"user": {"login": "big-andy-coates", "name": "Andy Coates"}}, "url": "https://github.com/confluentinc/ksql/commit/7beca3c9d325edade23cf3daa006cbcd44302682", "committedDate": "2020-02-10T23:26:59Z", "message": "chore: tidy up"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a1c0637858918ef5c437e9e6027b01a37561c735", "author": {"user": {"login": "big-andy-coates", "name": "Andy Coates"}}, "url": "https://github.com/confluentinc/ksql/commit/a1c0637858918ef5c437e9e6027b01a37561c735", "committedDate": "2020-02-11T00:03:06Z", "message": "docs: update docs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "34c973b1e317a9ca7f3c8b9e70d2a0be4853654d", "author": {"user": {"login": "big-andy-coates", "name": "Andy Coates"}}, "url": "https://github.com/confluentinc/ksql/commit/34c973b1e317a9ca7f3c8b9e70d2a0be4853654d", "committedDate": "2020-02-11T00:03:52Z", "message": "chore: remove outstanding todos\n\nfor another PR..."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU2MzU1MjI2", "url": "https://github.com/confluentinc/ksql/pull/4507#pullrequestreview-356355226", "createdAt": "2020-02-11T00:13:02Z", "commit": {"oid": "34c973b1e317a9ca7f3c8b9e70d2a0be4853654d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMVQwMDoxMzowMlrOFn6Kbw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMVQwMDoxMzowMlrOFn6Kbw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzM5MTcyNw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            ksqlDB will attempt to determine the format of the data in the topic and wil output what its thinks is\n          \n          \n            \n            ksqlDB attempts to determine the format of the data in the topic and outputs what it thinks are", "url": "https://github.com/confluentinc/ksql/pull/4507#discussion_r377391727", "createdAt": "2020-02-11T00:13:02Z", "author": {"login": "JimGalasyn"}, "path": "docs-md/developer-guide/ksqldb-reference/print.md", "diffHunk": "@@ -39,13 +39,24 @@ The following statement shows how to print all of the records in a topic named\n PRINT ksql__commands FROM BEGINNING;\r\n ```\r\n \r\n+ksqlDB will attempt to determine the format of the data in the topic and wil output what its thinks is\r", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "34c973b1e317a9ca7f3c8b9e70d2a0be4853654d"}, "originalPosition": 4}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU2MzU1NTMx", "url": "https://github.com/confluentinc/ksql/pull/4507#pullrequestreview-356355531", "createdAt": "2020-02-11T00:13:50Z", "commit": {"oid": "34c973b1e317a9ca7f3c8b9e70d2a0be4853654d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMVQwMDoxMzo1MFrOFn6LVw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMVQwMDoxMzo1MFrOFn6LVw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzM5MTk1OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n               For example, it is not possible to distinguish between serialized `BIGINT` and `DOUBLE`s, as\n          \n          \n            \n               For example, it is not possible to distinguish between serialized `BIGINT` and `DOUBLE` values, because", "url": "https://github.com/confluentinc/ksql/pull/4507#discussion_r377391959", "createdAt": "2020-02-11T00:13:50Z", "author": {"login": "JimGalasyn"}, "path": "docs-md/developer-guide/ksqldb-reference/print.md", "diffHunk": "@@ -39,13 +39,24 @@ The following statement shows how to print all of the records in a topic named\n PRINT ksql__commands FROM BEGINNING;\r\n ```\r\n \r\n+ksqlDB will attempt to determine the format of the data in the topic and wil output what its thinks is\r\n+the key and value formats at the top of the output.\r\n+\r\n+!!! note\r\n+   Attempting to determine a data format from only the serialized bytes is not an exact science!\r\n+   For example, it is not possible to distinguish between serialized `BIGINT` and `DOUBLE`s, as\r", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "34c973b1e317a9ca7f3c8b9e70d2a0be4853654d"}, "originalPosition": 9}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU2MzU1Njcz", "url": "https://github.com/confluentinc/ksql/pull/4507#pullrequestreview-356355673", "createdAt": "2020-02-11T00:14:17Z", "commit": {"oid": "34c973b1e317a9ca7f3c8b9e70d2a0be4853654d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMVQwMDoxNDoxN1rOFn6LyQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMVQwMDoxNDoxN1rOFn6LyQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzM5MjA3Mw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n               they both occupy 8 bytes. Short strings can also be mistaken for serialized numbers.\n          \n          \n            \n               they both occupy eight bytes. Short strings can also be mistaken for serialized numbers.", "url": "https://github.com/confluentinc/ksql/pull/4507#discussion_r377392073", "createdAt": "2020-02-11T00:14:17Z", "author": {"login": "JimGalasyn"}, "path": "docs-md/developer-guide/ksqldb-reference/print.md", "diffHunk": "@@ -39,13 +39,24 @@ The following statement shows how to print all of the records in a topic named\n PRINT ksql__commands FROM BEGINNING;\r\n ```\r\n \r\n+ksqlDB will attempt to determine the format of the data in the topic and wil output what its thinks is\r\n+the key and value formats at the top of the output.\r\n+\r\n+!!! note\r\n+   Attempting to determine a data format from only the serialized bytes is not an exact science!\r\n+   For example, it is not possible to distinguish between serialized `BIGINT` and `DOUBLE`s, as\r\n+   they both occupy 8 bytes. Short strings can also be mistaken for serialized numbers.\r", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "34c973b1e317a9ca7f3c8b9e70d2a0be4853654d"}, "originalPosition": 10}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU2MzU2MTk3", "url": "https://github.com/confluentinc/ksql/pull/4507#pullrequestreview-356356197", "createdAt": "2020-02-11T00:15:46Z", "commit": {"oid": "34c973b1e317a9ca7f3c8b9e70d2a0be4853654d"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cc623bebb23bf6393b350381c684121790cc77c9", "author": {"user": {"login": "big-andy-coates", "name": "Andy Coates"}}, "url": "https://github.com/confluentinc/ksql/commit/cc623bebb23bf6393b350381c684121790cc77c9", "committedDate": "2020-02-11T09:01:00Z", "message": "chore: changes requested by Jim"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8498603c6d58ce4e424c93196c2c28b9735277eb", "author": {"user": {"login": "big-andy-coates", "name": "Andy Coates"}}, "url": "https://github.com/confluentinc/ksql/commit/8498603c6d58ce4e424c93196c2c28b9735277eb", "committedDate": "2020-02-11T19:26:53Z", "message": "chore: fix spotbugs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ee087d12132cf8d798167953fcd3ee99cfd3f59e", "author": {"user": {"login": "big-andy-coates", "name": "Andy Coates"}}, "url": "https://github.com/confluentinc/ksql/commit/ee087d12132cf8d798167953fcd3ee99cfd3f59e", "committedDate": "2020-02-11T19:30:25Z", "message": "docs: fix quoting on examples"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzU2OTI3NjQx", "url": "https://github.com/confluentinc/ksql/pull/4507#pullrequestreview-356927641", "createdAt": "2020-02-11T19:21:45Z", "commit": {"oid": "cc623bebb23bf6393b350381c684121790cc77c9"}, "state": "APPROVED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMVQxOToyMTo0NlrOFoV61g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMVQxOTo0NDo1N1rOFoWqxQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzg0NjQ4Ng==", "bodyText": "nit (not your code): constants for 3 and 1 (no idea what these mean \ud83d\ude02 )", "url": "https://github.com/confluentinc/ksql/pull/4507#discussion_r377846486", "createdAt": "2020-02-11T19:21:46Z", "author": {"login": "agavra"}, "path": "ksql-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/TopicStream.java", "diffHunk": "@@ -52,96 +60,196 @@ private TopicStream() {\n \n     private final KafkaAvroDeserializer avroDeserializer;\n     private final String topicName;\n-    private final DateFormat dateFormat =\n-        SimpleDateFormat.getDateTimeInstance(3, 1, Locale.getDefault());\n+    private final DateFormat dateFormat;\n+\n+    private Optional<Formatter> keyFormatter = Optional.empty();\n+    private Optional<Formatter> valueFormatter = Optional.empty();\n \n-    private Formatter formatter;\n+    public RecordFormatter(\n+        final SchemaRegistryClient schemaRegistryClient,\n+        final String topicName\n+    ) {\n+      this(\n+          schemaRegistryClient,\n+          topicName,\n+          SimpleDateFormat.getDateTimeInstance(3, 1, Locale.getDefault())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc623bebb23bf6393b350381c684121790cc77c9"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzg0NzQ5OA==", "bodyText": "nit(personal preference): for internal variables I actually prefer nulls to Optionals as we're not exposing it anywhere and then we don't need to keep calling get everywhere when we know it'll be not-null at that point", "url": "https://github.com/confluentinc/ksql/pull/4507#discussion_r377847498", "createdAt": "2020-02-11T19:23:33Z", "author": {"login": "agavra"}, "path": "ksql-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/TopicStream.java", "diffHunk": "@@ -52,96 +60,196 @@ private TopicStream() {\n \n     private final KafkaAvroDeserializer avroDeserializer;\n     private final String topicName;\n-    private final DateFormat dateFormat =\n-        SimpleDateFormat.getDateTimeInstance(3, 1, Locale.getDefault());\n+    private final DateFormat dateFormat;\n+\n+    private Optional<Formatter> keyFormatter = Optional.empty();\n+    private Optional<Formatter> valueFormatter = Optional.empty();\n \n-    private Formatter formatter;\n+    public RecordFormatter(\n+        final SchemaRegistryClient schemaRegistryClient,\n+        final String topicName\n+    ) {\n+      this(\n+          schemaRegistryClient,\n+          topicName,\n+          SimpleDateFormat.getDateTimeInstance(3, 1, Locale.getDefault())\n+      );\n+    }\n \n-    public RecordFormatter(final SchemaRegistryClient schemaRegistryClient,\n-                           final String topicName) {\n-      this.topicName = Objects.requireNonNull(topicName, \"topicName\");\n+    @VisibleForTesting\n+    RecordFormatter(\n+        final SchemaRegistryClient schemaRegistryClient,\n+        final String topicName,\n+        final DateFormat dateFormat\n+    ) {\n+      this.topicName = requireNonNull(topicName, \"topicName\");\n       this.avroDeserializer = new KafkaAvroDeserializer(schemaRegistryClient);\n+      this.dateFormat = requireNonNull(dateFormat, \"dateFormat\");\n     }\n \n-    public List<String> format(final ConsumerRecords<String, Bytes> records) {\n-      return StreamSupport\n-          .stream(records.records(topicName).spliterator(), false)\n-          .filter(Objects::nonNull)\n-          .filter(r -> r.value() != null)\n-          .filter(r -> r.value().get() != null)\n-          .filter(r -> r.value().get().length != 0)\n-          .map((record) -> {\n-            if (formatter == null) {\n-              formatter = getFormatter(record);\n-            }\n-            try {\n-              return formatter.print(record);\n-            } catch (IOException e) {\n-              log.warn(\"Exception formatting record\", e);\n-              return null;\n-            }\n-          })\n-          .filter(Objects::nonNull)\n+    public List<Supplier<String>> format(final Iterable<ConsumerRecord<Bytes, Bytes>> records) {\n+      if (!keyFormatter.isPresent()) {\n+        keyFormatter = getKeyFormatter(records);\n+      }\n+\n+      if (!valueFormatter.isPresent()) {\n+        valueFormatter = getValueFormatter(records);\n+      }\n+\n+      return StreamSupport.stream(records.spliterator(), false)\n+          .map(this::delayedFormat)\n           .collect(Collectors.toList());\n     }\n \n-    public Format getFormat() {\n-      return formatter == null ? Format.UNDEFINED : formatter.getFormat();\n+    @SuppressWarnings(\"OptionalGetWithoutIsPresent\") // will not be empty if needed", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc623bebb23bf6393b350381c684121790cc77c9"}, "originalPosition": 113}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzg1MTc0OA==", "bodyText": "can you add some documentation on how this \"algorithm\" works? i.e. explain how it chooses the formatter, what the default is and the batching mechanism", "url": "https://github.com/confluentinc/ksql/pull/4507#discussion_r377851748", "createdAt": "2020-02-11T19:31:20Z", "author": {"login": "agavra"}, "path": "ksql-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/TopicStream.java", "diffHunk": "@@ -52,96 +60,196 @@ private TopicStream() {\n \n     private final KafkaAvroDeserializer avroDeserializer;\n     private final String topicName;\n-    private final DateFormat dateFormat =\n-        SimpleDateFormat.getDateTimeInstance(3, 1, Locale.getDefault());\n+    private final DateFormat dateFormat;\n+\n+    private Optional<Formatter> keyFormatter = Optional.empty();\n+    private Optional<Formatter> valueFormatter = Optional.empty();\n \n-    private Formatter formatter;\n+    public RecordFormatter(\n+        final SchemaRegistryClient schemaRegistryClient,\n+        final String topicName\n+    ) {\n+      this(\n+          schemaRegistryClient,\n+          topicName,\n+          SimpleDateFormat.getDateTimeInstance(3, 1, Locale.getDefault())\n+      );\n+    }\n \n-    public RecordFormatter(final SchemaRegistryClient schemaRegistryClient,\n-                           final String topicName) {\n-      this.topicName = Objects.requireNonNull(topicName, \"topicName\");\n+    @VisibleForTesting\n+    RecordFormatter(\n+        final SchemaRegistryClient schemaRegistryClient,\n+        final String topicName,\n+        final DateFormat dateFormat\n+    ) {\n+      this.topicName = requireNonNull(topicName, \"topicName\");\n       this.avroDeserializer = new KafkaAvroDeserializer(schemaRegistryClient);\n+      this.dateFormat = requireNonNull(dateFormat, \"dateFormat\");\n     }\n \n-    public List<String> format(final ConsumerRecords<String, Bytes> records) {\n-      return StreamSupport\n-          .stream(records.records(topicName).spliterator(), false)\n-          .filter(Objects::nonNull)\n-          .filter(r -> r.value() != null)\n-          .filter(r -> r.value().get() != null)\n-          .filter(r -> r.value().get().length != 0)\n-          .map((record) -> {\n-            if (formatter == null) {\n-              formatter = getFormatter(record);\n-            }\n-            try {\n-              return formatter.print(record);\n-            } catch (IOException e) {\n-              log.warn(\"Exception formatting record\", e);\n-              return null;\n-            }\n-          })\n-          .filter(Objects::nonNull)\n+    public List<Supplier<String>> format(final Iterable<ConsumerRecord<Bytes, Bytes>> records) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc623bebb23bf6393b350381c684121790cc77c9"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzg1MjM3Mg==", "bodyText": "I'm not sure I understand why we needed to turn this into a String?", "url": "https://github.com/confluentinc/ksql/pull/4507#discussion_r377852372", "createdAt": "2020-02-11T19:32:36Z", "author": {"login": "agavra"}, "path": "ksql-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/TopicStream.java", "diffHunk": "@@ -52,96 +60,196 @@ private TopicStream() {\n \n     private final KafkaAvroDeserializer avroDeserializer;\n     private final String topicName;\n-    private final DateFormat dateFormat =\n-        SimpleDateFormat.getDateTimeInstance(3, 1, Locale.getDefault());\n+    private final DateFormat dateFormat;\n+\n+    private Optional<Formatter> keyFormatter = Optional.empty();\n+    private Optional<Formatter> valueFormatter = Optional.empty();\n \n-    private Formatter formatter;\n+    public RecordFormatter(\n+        final SchemaRegistryClient schemaRegistryClient,\n+        final String topicName\n+    ) {\n+      this(\n+          schemaRegistryClient,\n+          topicName,\n+          SimpleDateFormat.getDateTimeInstance(3, 1, Locale.getDefault())\n+      );\n+    }\n \n-    public RecordFormatter(final SchemaRegistryClient schemaRegistryClient,\n-                           final String topicName) {\n-      this.topicName = Objects.requireNonNull(topicName, \"topicName\");\n+    @VisibleForTesting\n+    RecordFormatter(\n+        final SchemaRegistryClient schemaRegistryClient,\n+        final String topicName,\n+        final DateFormat dateFormat\n+    ) {\n+      this.topicName = requireNonNull(topicName, \"topicName\");\n       this.avroDeserializer = new KafkaAvroDeserializer(schemaRegistryClient);\n+      this.dateFormat = requireNonNull(dateFormat, \"dateFormat\");\n     }\n \n-    public List<String> format(final ConsumerRecords<String, Bytes> records) {\n-      return StreamSupport\n-          .stream(records.records(topicName).spliterator(), false)\n-          .filter(Objects::nonNull)\n-          .filter(r -> r.value() != null)\n-          .filter(r -> r.value().get() != null)\n-          .filter(r -> r.value().get().length != 0)\n-          .map((record) -> {\n-            if (formatter == null) {\n-              formatter = getFormatter(record);\n-            }\n-            try {\n-              return formatter.print(record);\n-            } catch (IOException e) {\n-              log.warn(\"Exception formatting record\", e);\n-              return null;\n-            }\n-          })\n-          .filter(Objects::nonNull)\n+    public List<Supplier<String>> format(final Iterable<ConsumerRecord<Bytes, Bytes>> records) {\n+      if (!keyFormatter.isPresent()) {\n+        keyFormatter = getKeyFormatter(records);\n+      }\n+\n+      if (!valueFormatter.isPresent()) {\n+        valueFormatter = getValueFormatter(records);\n+      }\n+\n+      return StreamSupport.stream(records.spliterator(), false)\n+          .map(this::delayedFormat)\n           .collect(Collectors.toList());\n     }\n \n-    public Format getFormat() {\n-      return formatter == null ? Format.UNDEFINED : formatter.getFormat();\n+    @SuppressWarnings(\"OptionalGetWithoutIsPresent\") // will not be empty if needed\n+    private Supplier<String> delayedFormat(final ConsumerRecord<Bytes, Bytes> record) {\n+      return () -> {\n+        try {\n+          final String rowTime = record.timestamp() == ConsumerRecord.NO_TIMESTAMP\n+              ? \"N/A\"\n+              : dateFormat.format(new Date(record.timestamp()));\n+\n+          final String rowKey = record.key() == null || record.key().get() == null\n+              ? \"<null>\"\n+              : keyFormatter.get().print(record.key());\n+\n+          final String value = record.value() == null || record.value().get() == null\n+              ? \"<null>\"\n+              : valueFormatter.get().print(record.value());\n+\n+          return \"rowtime: \" + rowTime\n+              + \", \" + \"key: \" + rowKey\n+              + \", value: \" + value;\n+        } catch (IOException e) {\n+          log.warn(\"Exception formatting record\", e);\n+          return \"Failed to parse row\";\n+        }\n+      };\n+    }\n+\n+    public String getKeyFormat() {\n+      return keyFormatter\n+          .map(Formatter::getFormat)\n+          .orElse(Format.UNDEFINED.toString());\n+    }\n+\n+    public String getValueFormat() {\n+      return valueFormatter\n+          .map(Formatter::getFormat)\n+          .orElse(Format.UNDEFINED.toString());\n+    }\n+\n+    private Optional<Formatter> getKeyFormatter(\n+        final Iterable<ConsumerRecord<Bytes, Bytes>> records\n+    ) {\n+      if (Iterables.isEmpty(records)) {\n+        return Optional.empty();\n+      }\n+\n+      final Stream<Bytes> valueStream = StreamSupport\n+          .stream(records.spliterator(), false)\n+          .map(ConsumerRecord::key);\n+\n+      return findFormatter(valueStream);\n+    }\n+\n+    private Optional<Formatter> getValueFormatter(\n+        final Iterable<ConsumerRecord<Bytes, Bytes>> records\n+    ) {\n+      if (Iterables.isEmpty(records)) {\n+        return Optional.empty();\n+      }\n+\n+      final Stream<Bytes> valueStream = StreamSupport\n+          .stream(records.spliterator(), false)\n+          .map(ConsumerRecord::value);\n+\n+      return findFormatter(valueStream);\n+    }\n+\n+    private Optional<Formatter> findFormatter(final Stream<Bytes> dataStream) {\n+      final List<Formatter> formatters = dataStream\n+          .filter(Objects::nonNull)\n+          .filter(d -> d.get() != null)\n+          .map(this::findFormatter)\n+          .collect(Collectors.toList());\n+\n+      final Set<String> formats = formatters.stream()\n+          .map(Formatter::getFormat)\n+          .collect(Collectors.toSet());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc623bebb23bf6393b350381c684121790cc77c9"}, "originalPosition": 188}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzg1MzA4NA==", "bodyText": "nit: getKeyFormatName", "url": "https://github.com/confluentinc/ksql/pull/4507#discussion_r377853084", "createdAt": "2020-02-11T19:34:07Z", "author": {"login": "agavra"}, "path": "ksql-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/TopicStream.java", "diffHunk": "@@ -52,96 +60,196 @@ private TopicStream() {\n \n     private final KafkaAvroDeserializer avroDeserializer;\n     private final String topicName;\n-    private final DateFormat dateFormat =\n-        SimpleDateFormat.getDateTimeInstance(3, 1, Locale.getDefault());\n+    private final DateFormat dateFormat;\n+\n+    private Optional<Formatter> keyFormatter = Optional.empty();\n+    private Optional<Formatter> valueFormatter = Optional.empty();\n \n-    private Formatter formatter;\n+    public RecordFormatter(\n+        final SchemaRegistryClient schemaRegistryClient,\n+        final String topicName\n+    ) {\n+      this(\n+          schemaRegistryClient,\n+          topicName,\n+          SimpleDateFormat.getDateTimeInstance(3, 1, Locale.getDefault())\n+      );\n+    }\n \n-    public RecordFormatter(final SchemaRegistryClient schemaRegistryClient,\n-                           final String topicName) {\n-      this.topicName = Objects.requireNonNull(topicName, \"topicName\");\n+    @VisibleForTesting\n+    RecordFormatter(\n+        final SchemaRegistryClient schemaRegistryClient,\n+        final String topicName,\n+        final DateFormat dateFormat\n+    ) {\n+      this.topicName = requireNonNull(topicName, \"topicName\");\n       this.avroDeserializer = new KafkaAvroDeserializer(schemaRegistryClient);\n+      this.dateFormat = requireNonNull(dateFormat, \"dateFormat\");\n     }\n \n-    public List<String> format(final ConsumerRecords<String, Bytes> records) {\n-      return StreamSupport\n-          .stream(records.records(topicName).spliterator(), false)\n-          .filter(Objects::nonNull)\n-          .filter(r -> r.value() != null)\n-          .filter(r -> r.value().get() != null)\n-          .filter(r -> r.value().get().length != 0)\n-          .map((record) -> {\n-            if (formatter == null) {\n-              formatter = getFormatter(record);\n-            }\n-            try {\n-              return formatter.print(record);\n-            } catch (IOException e) {\n-              log.warn(\"Exception formatting record\", e);\n-              return null;\n-            }\n-          })\n-          .filter(Objects::nonNull)\n+    public List<Supplier<String>> format(final Iterable<ConsumerRecord<Bytes, Bytes>> records) {\n+      if (!keyFormatter.isPresent()) {\n+        keyFormatter = getKeyFormatter(records);\n+      }\n+\n+      if (!valueFormatter.isPresent()) {\n+        valueFormatter = getValueFormatter(records);\n+      }\n+\n+      return StreamSupport.stream(records.spliterator(), false)\n+          .map(this::delayedFormat)\n           .collect(Collectors.toList());\n     }\n \n-    public Format getFormat() {\n-      return formatter == null ? Format.UNDEFINED : formatter.getFormat();\n+    @SuppressWarnings(\"OptionalGetWithoutIsPresent\") // will not be empty if needed\n+    private Supplier<String> delayedFormat(final ConsumerRecord<Bytes, Bytes> record) {\n+      return () -> {\n+        try {\n+          final String rowTime = record.timestamp() == ConsumerRecord.NO_TIMESTAMP\n+              ? \"N/A\"\n+              : dateFormat.format(new Date(record.timestamp()));\n+\n+          final String rowKey = record.key() == null || record.key().get() == null\n+              ? \"<null>\"\n+              : keyFormatter.get().print(record.key());\n+\n+          final String value = record.value() == null || record.value().get() == null\n+              ? \"<null>\"\n+              : valueFormatter.get().print(record.value());\n+\n+          return \"rowtime: \" + rowTime\n+              + \", \" + \"key: \" + rowKey\n+              + \", value: \" + value;\n+        } catch (IOException e) {\n+          log.warn(\"Exception formatting record\", e);\n+          return \"Failed to parse row\";\n+        }\n+      };\n+    }\n+\n+    public String getKeyFormat() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc623bebb23bf6393b350381c684121790cc77c9"}, "originalPosition": 139}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzg1MzU2OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                String getFormat();\n          \n          \n            \n                String getFormatName();", "url": "https://github.com/confluentinc/ksql/pull/4507#discussion_r377853569", "createdAt": "2020-02-11T19:35:07Z", "author": {"login": "agavra"}, "path": "ksql-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/TopicStream.java", "diffHunk": "@@ -52,96 +60,196 @@ private TopicStream() {\n \n     private final KafkaAvroDeserializer avroDeserializer;\n     private final String topicName;\n-    private final DateFormat dateFormat =\n-        SimpleDateFormat.getDateTimeInstance(3, 1, Locale.getDefault());\n+    private final DateFormat dateFormat;\n+\n+    private Optional<Formatter> keyFormatter = Optional.empty();\n+    private Optional<Formatter> valueFormatter = Optional.empty();\n \n-    private Formatter formatter;\n+    public RecordFormatter(\n+        final SchemaRegistryClient schemaRegistryClient,\n+        final String topicName\n+    ) {\n+      this(\n+          schemaRegistryClient,\n+          topicName,\n+          SimpleDateFormat.getDateTimeInstance(3, 1, Locale.getDefault())\n+      );\n+    }\n \n-    public RecordFormatter(final SchemaRegistryClient schemaRegistryClient,\n-                           final String topicName) {\n-      this.topicName = Objects.requireNonNull(topicName, \"topicName\");\n+    @VisibleForTesting\n+    RecordFormatter(\n+        final SchemaRegistryClient schemaRegistryClient,\n+        final String topicName,\n+        final DateFormat dateFormat\n+    ) {\n+      this.topicName = requireNonNull(topicName, \"topicName\");\n       this.avroDeserializer = new KafkaAvroDeserializer(schemaRegistryClient);\n+      this.dateFormat = requireNonNull(dateFormat, \"dateFormat\");\n     }\n \n-    public List<String> format(final ConsumerRecords<String, Bytes> records) {\n-      return StreamSupport\n-          .stream(records.records(topicName).spliterator(), false)\n-          .filter(Objects::nonNull)\n-          .filter(r -> r.value() != null)\n-          .filter(r -> r.value().get() != null)\n-          .filter(r -> r.value().get().length != 0)\n-          .map((record) -> {\n-            if (formatter == null) {\n-              formatter = getFormatter(record);\n-            }\n-            try {\n-              return formatter.print(record);\n-            } catch (IOException e) {\n-              log.warn(\"Exception formatting record\", e);\n-              return null;\n-            }\n-          })\n-          .filter(Objects::nonNull)\n+    public List<Supplier<String>> format(final Iterable<ConsumerRecord<Bytes, Bytes>> records) {\n+      if (!keyFormatter.isPresent()) {\n+        keyFormatter = getKeyFormatter(records);\n+      }\n+\n+      if (!valueFormatter.isPresent()) {\n+        valueFormatter = getValueFormatter(records);\n+      }\n+\n+      return StreamSupport.stream(records.spliterator(), false)\n+          .map(this::delayedFormat)\n           .collect(Collectors.toList());\n     }\n \n-    public Format getFormat() {\n-      return formatter == null ? Format.UNDEFINED : formatter.getFormat();\n+    @SuppressWarnings(\"OptionalGetWithoutIsPresent\") // will not be empty if needed\n+    private Supplier<String> delayedFormat(final ConsumerRecord<Bytes, Bytes> record) {\n+      return () -> {\n+        try {\n+          final String rowTime = record.timestamp() == ConsumerRecord.NO_TIMESTAMP\n+              ? \"N/A\"\n+              : dateFormat.format(new Date(record.timestamp()));\n+\n+          final String rowKey = record.key() == null || record.key().get() == null\n+              ? \"<null>\"\n+              : keyFormatter.get().print(record.key());\n+\n+          final String value = record.value() == null || record.value().get() == null\n+              ? \"<null>\"\n+              : valueFormatter.get().print(record.value());\n+\n+          return \"rowtime: \" + rowTime\n+              + \", \" + \"key: \" + rowKey\n+              + \", value: \" + value;\n+        } catch (IOException e) {\n+          log.warn(\"Exception formatting record\", e);\n+          return \"Failed to parse row\";\n+        }\n+      };\n+    }\n+\n+    public String getKeyFormat() {\n+      return keyFormatter\n+          .map(Formatter::getFormat)\n+          .orElse(Format.UNDEFINED.toString());\n+    }\n+\n+    public String getValueFormat() {\n+      return valueFormatter\n+          .map(Formatter::getFormat)\n+          .orElse(Format.UNDEFINED.toString());\n+    }\n+\n+    private Optional<Formatter> getKeyFormatter(\n+        final Iterable<ConsumerRecord<Bytes, Bytes>> records\n+    ) {\n+      if (Iterables.isEmpty(records)) {\n+        return Optional.empty();\n+      }\n+\n+      final Stream<Bytes> valueStream = StreamSupport\n+          .stream(records.spliterator(), false)\n+          .map(ConsumerRecord::key);\n+\n+      return findFormatter(valueStream);\n+    }\n+\n+    private Optional<Formatter> getValueFormatter(\n+        final Iterable<ConsumerRecord<Bytes, Bytes>> records\n+    ) {\n+      if (Iterables.isEmpty(records)) {\n+        return Optional.empty();\n+      }\n+\n+      final Stream<Bytes> valueStream = StreamSupport\n+          .stream(records.spliterator(), false)\n+          .map(ConsumerRecord::value);\n+\n+      return findFormatter(valueStream);\n+    }\n+\n+    private Optional<Formatter> findFormatter(final Stream<Bytes> dataStream) {\n+      final List<Formatter> formatters = dataStream\n+          .filter(Objects::nonNull)\n+          .filter(d -> d.get() != null)\n+          .map(this::findFormatter)\n+          .collect(Collectors.toList());\n+\n+      final Set<String> formats = formatters.stream()\n+          .map(Formatter::getFormat)\n+          .collect(Collectors.toSet());\n+\n+      switch (formats.size()) {\n+        case 0:\n+          // No viable records (will try again with next batch):\n+          return Optional.empty();\n+\n+        case 1:\n+          // Single format:\n+          return Optional.of(formatters.get(0));\n+\n+        default:\n+          // Mixed format topic:\n+          return Format.MIXED.maybeGetFormatter(topicName, null, avroDeserializer);\n+      }\n     }\n \n-    private Formatter getFormatter(final ConsumerRecord<String, Bytes> record) {\n+    private Formatter findFormatter(final Bytes data) {\n       return Arrays.stream(Format.values())\n-          .map(f -> f.maybeGetFormatter(topicName, record, avroDeserializer, dateFormat))\n+          .map(f -> f.maybeGetFormatter(topicName, data, avroDeserializer))\n           .filter(Optional::isPresent)\n           .map(Optional::get)\n           .findFirst()\n-          .orElseThrow(() -> new RuntimeException(\"Unexpected\"));\n+          .orElseThrow(() -> new IllegalStateException(\"Unexpected\"));\n     }\n   }\n \n   interface Formatter {\n \n-    String print(ConsumerRecord<String, Bytes> consumerRecord) throws IOException;\n+    String print(Bytes data) throws IOException;\n \n-    Format getFormat();\n+    String getFormat();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc623bebb23bf6393b350381c684121790cc77c9"}, "originalPosition": 224}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzg1NzAyMQ==", "bodyText": "this comment is a little confusing - so what if they're indistinguishable? Are we returning Optional.empty because we'd rather default to DELIMITED than \"inline\" JSON?", "url": "https://github.com/confluentinc/ksql/pull/4507#discussion_r377857021", "createdAt": "2020-02-11T19:41:40Z", "author": {"login": "agavra"}, "path": "ksql-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/TopicStream.java", "diffHunk": "@@ -150,87 +258,128 @@ public Format getFormat() {\n       @Override\n       public Optional<Formatter> maybeGetFormatter(\n           final String topicName,\n-          final ConsumerRecord<String, Bytes> record,\n-          final KafkaAvroDeserializer avroDeserializer,\n-          final DateFormat dateFormat) {\n+          final Bytes data,\n+          final KafkaAvroDeserializer avroDeserializer\n+      ) {\n         try {\n-          final JsonNode jsonNode = JsonMapper.INSTANCE.mapper.readTree(record.value().toString());\n+          final JsonNode jsonNode = JsonMapper.INSTANCE.mapper.readTree(data.toString());\n \n-          // If the JsonNode is not structured like 'key:value', then do not use JSON to print\n-          // this value\n-          if (!(jsonNode instanceof ObjectNode)) {\n+          if (!(jsonNode instanceof ObjectNode) && !(jsonNode instanceof ArrayNode)) {\n+            // Other valid JSON types, e.g. NumericNode, BooleanNode, etc\n+            // are indistinguishable from single column delimited format:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc623bebb23bf6393b350381c684121790cc77c9"}, "originalPosition": 308}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3Nzg1ODc1Nw==", "bodyText": "is it possible that the format has changed between last time we did a format and now (e.g. first few records happened to deserialize as JSON, but actually it was KAFKA or something like that)? if so should we print it again?", "url": "https://github.com/confluentinc/ksql/pull/4507#discussion_r377858757", "createdAt": "2020-02-11T19:44:57Z", "author": {"login": "agavra"}, "path": "ksql-rest-app/src/main/java/io/confluent/ksql/rest/server/resources/streaming/TopicStreamWriter.java", "diffHunk": "@@ -60,59 +62,66 @@ public static TopicStreamWriter create(\n             serviceContext,\n             consumerProperties,\n             printTopic),\n-        printTopic.getTopic().toString(),\n+        printTopic.getTopic(),\n         printTopic.getIntervalValue(),\n         disconnectCheckInterval,\n         printTopic.getLimit());\n   }\n \n   TopicStreamWriter(\n       final SchemaRegistryClient schemaRegistryClient,\n-      final KafkaConsumer<String, Bytes> topicConsumer,\n+      final KafkaConsumer<Bytes, Bytes> topicConsumer,\n       final String topicName,\n       final long interval,\n       final Duration disconnectCheckInterval,\n       final OptionalInt limit\n   ) {\n-    this.topicConsumer = topicConsumer;\n-    this.schemaRegistryClient = schemaRegistryClient;\n-    this.topicName = topicName;\n+    this.topicConsumer = requireNonNull(topicConsumer, \"topicConsumer\");\n+    this.schemaRegistryClient = requireNonNull(schemaRegistryClient, \"schemaRegistryClient\");\n+    this.topicName = requireNonNull(topicName, \"topicName\");\n     this.interval = interval;\n-    this.limit = limit;\n-    this.disconnectCheckInterval = Objects\n-        .requireNonNull(disconnectCheckInterval, \"disconnectCheckInterval\");\n-\n+    this.limit = requireNonNull(limit, \"limit\");\n+    this.disconnectCheckInterval =\n+        requireNonNull(disconnectCheckInterval, \"disconnectCheckInterval\");\n     this.messagesWritten = 0;\n     this.messagesPolled = 0;\n+\n+    if (interval < 1) {\n+      throw new IllegalArgumentException(\"INTERVAL must be greater than one, but was: \" + interval);\n+    }\n   }\n \n   @Override\n   public void write(final OutputStream out) {\n     try {\n       final RecordFormatter formatter = new RecordFormatter(schemaRegistryClient, topicName);\n+\n       boolean printFormat = true;\n       while (true) {\n-        final ConsumerRecords<String, Bytes> records = topicConsumer.poll(disconnectCheckInterval);\n+        final ConsumerRecords<Bytes, Bytes> records = topicConsumer.poll(disconnectCheckInterval);\n         if (records.isEmpty()) {\n-          out.write(\"\\n\".getBytes(StandardCharsets.UTF_8));\n+          out.write(\"\\n\".getBytes(UTF_8));\n           out.flush();\n-        } else {\n-          final List<String> values = formatter.format(records);\n-          for (final String value : values) {\n-            if (printFormat) {\n-              printFormat = false;\n-              out.write((\"Format:\" + formatter.getFormat().name() + \"\\n\")\n-                            .getBytes(StandardCharsets.UTF_8));\n-            }\n-            if (messagesPolled++ % interval == 0) {\n-              messagesWritten++;\n-              out.write(value.getBytes(StandardCharsets.UTF_8));\n-              out.flush();\n-            }\n+          continue;\n+        }\n+\n+        final List<Supplier<String>> values = formatter.format(records.records(topicName));\n+        for (final Supplier<String> value : values) {\n+          if (printFormat) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cc623bebb23bf6393b350381c684121790cc77c9"}, "originalPosition": 109}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4, "cost": 1, "resetAt": "2021-11-01T13:07:16Z"}}}