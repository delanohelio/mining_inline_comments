{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg5NDA4NTY5", "number": 4782, "title": "feat: Implement latest_by_offset() UDAF", "bodyText": "Description\nPlease see #3985\nImplements latest_by_offset() UDAF which computes the latest value for a column. Latest being defined as offset order.\nTesting done\nAdded new unit test and QTT test\nReviewer checklist\n\n Ensure docs are updated if necessary. (eg. if a user visible feature is being added or changed).\n Ensure relevant issues are linked (description should include text like \"Fixes #\")", "createdAt": "2020-03-16T17:56:26Z", "url": "https://github.com/confluentinc/ksql/pull/4782", "merged": true, "mergeCommit": {"oid": "0c13bb0fb4b8baa72510e1f737f3d5eb8aaba8a1"}, "closed": true, "closedAt": "2020-03-17T16:25:09Z", "author": {"login": "purplefox"}, "timelineItems": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcOR_HkgH2gAyMzg5NDA4NTY5OmUyY2U5MDBmYjQ5MjQ0MzkxOTMyNmJiNzY2YmE5MGUwMGMzNDczOTc=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcOkaeFgH2gAyMzg5NDA4NTY5OjI0NGRjNjkxOGJiYjJiNjQ1YTliNTRiYTZhYzMzNzAyMzg1YTE2MjI=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "e2ce900fb492443919326bb766ba90e00c347397", "author": {"user": {"login": "purplefox", "name": "Tim Fox"}}, "url": "https://github.com/confluentinc/ksql/commit/e2ce900fb492443919326bb766ba90e00c347397", "committedDate": "2020-03-16T17:58:21Z", "message": "create latest_by_offset() udaf"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6243a5a4febe8298757045720dc1cdd74658609d", "author": {"user": {"login": "purplefox", "name": "Tim Fox"}}, "url": "https://github.com/confluentinc/ksql/commit/6243a5a4febe8298757045720dc1cdd74658609d", "committedDate": "2020-03-16T17:43:19Z", "message": "more stuff"}, "afterCommit": {"oid": "e2ce900fb492443919326bb766ba90e00c347397", "author": {"user": {"login": "purplefox", "name": "Tim Fox"}}, "url": "https://github.com/confluentinc/ksql/commit/e2ce900fb492443919326bb766ba90e00c347397", "committedDate": "2020-03-16T17:58:21Z", "message": "create latest_by_offset() udaf"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc1NDg2ODI2", "url": "https://github.com/confluentinc/ksql/pull/4782#pullrequestreview-375486826", "createdAt": "2020-03-16T18:36:54Z", "commit": {"oid": "e2ce900fb492443919326bb766ba90e00c347397"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQxODozNjo1NFrOF3BKYQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQxODozNjo1NFrOF3BKYQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzIzNTA0MQ==", "bodyText": "Can we use different input values for the two different keys please?  One could imagine this test passing even if the code didn't do things per-key...", "url": "https://github.com/confluentinc/ksql/pull/4782#discussion_r393235041", "createdAt": "2020-03-16T18:36:54Z", "author": {"login": "big-andy-coates"}, "path": "ksqldb-functional-tests/src/test/resources/query-validation-tests/latest-offset-udaf.json", "diffHunk": "@@ -0,0 +1,41 @@\n+{\n+  \"comments\": [\n+    \"Tests covering the use of the LATEST_BY_OFFSET aggregate function\"\n+  ],\n+  \"tests\": [\n+    {\n+      \"name\": \"latest by offset\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ROWKEY BIGINT KEY, ID BIGINT, F0 INT, F1 BIGINT, F2 DOUBLE, F3 BOOLEAN, F4 STRING) WITH (kafka_topic='test_topic', value_format='JSON', key='ID');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, LATEST_BY_OFFSET(F0) AS L0, LATEST_BY_OFFSET(F1) AS L1, LATEST_BY_OFFSET(F2) AS L2, LATEST_BY_OFFSET(F3) AS L3, LATEST_BY_OFFSET(F4) AS L4 FROM INPUT GROUP BY ID;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"test_topic\", \"key\": 0, \"value\": {\"ID\": 0, \"F0\": 12, \"F1\": 1000, \"F2\": 1.23, \"F3\": true, \"F4\": \"foo\"}},\n+        {\"topic\": \"test_topic\", \"key\": 1, \"value\": {\"ID\": 1, \"F0\": 12, \"F1\": 1000, \"F2\": 1.23, \"F3\": true, \"F4\": \"foo\"}},\n+        {\"topic\": \"test_topic\", \"key\": 0, \"value\": {\"ID\": 0, \"F0\": 21, \"F1\": 2000, \"F2\": 2.23, \"F3\": false, \"F4\": \"bar\"}},\n+        {\"topic\": \"test_topic\", \"key\": 1, \"value\": {\"ID\": 1, \"F0\": 21, \"F1\": 2000, \"F2\": 2.23, \"F3\": false, \"F4\": \"bar\"}}\n+      ],", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2ce900fb492443919326bb766ba90e00c347397"}, "originalPosition": 17}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc1NDg4MTc1", "url": "https://github.com/confluentinc/ksql/pull/4782#pullrequestreview-375488175", "createdAt": "2020-03-16T18:38:54Z", "commit": {"oid": "e2ce900fb492443919326bb766ba90e00c347397"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQxODozODo1NFrOF3BOsg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQxODozODo1NFrOF3BOsg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzIzNjE0Ng==", "bodyText": "why have all these lines changed?", "url": "https://github.com/confluentinc/ksql/pull/4782#discussion_r393236146", "createdAt": "2020-03-16T18:38:54Z", "author": {"login": "big-andy-coates"}, "path": "docs/developer-guide/syntax-reference.rst", "diffHunk": "@@ -2093,70 +2093,74 @@ convention is followed.\n Aggregate functions\n ===================\n \n-+------------------------+---------------------------+------------+---------------------------------------------------------------------+\n-| Function               | Example                   | Input Type | Description                                                         |\n-+========================+===========================+============+=====================================================================+\n-| COLLECT_LIST           | ``COLLECT_LIST(col1)``    | Stream,    | Return an array containing all the values of ``col1`` from each     |\n-|                        |                           | Table      | input row (for the specified grouping and time window, if any).     |\n-|                        |                           |            | Currently only works for simple types (not Map, Array, or Struct).  |\n-|                        |                           |            | This version limits the size of the result Array to a maximum of    |\n-|                        |                           |            | 1000 entries and any values beyond this limit are silently ignored. |\n-|                        |                           |            | When using with a window type of ``session``, it can sometimes      |\n-|                        |                           |            | happen that two session windows get merged together into one when a |\n-|                        |                           |            | late-arriving record with a timestamp between the two windows is    |\n-|                        |                           |            | processed. In this case the 1000 record limit is calculated by      |\n-|                        |                           |            | first considering all the records from the first window, then the   |\n-|                        |                           |            | late-arriving record, then the records from the second window in    |\n-|                        |                           |            | the order they were originally processed.                           |\n-+------------------------+---------------------------+------------+---------------------------------------------------------------------+\n-| COLLECT_SET            | ``COLLECT_SET(col1)``     | Stream     | Return an array containing the distinct values of ``col1`` from     |\n-|                        |                           |            | each input row (for the specified grouping and time window, if any).|\n-|                        |                           |            | Currently only works for simple types (not Map, Array, or Struct).  |\n-|                        |                           |            | This version limits the size of the result Array to a maximum of    |\n-|                        |                           |            | 1000 entries and any values beyond this limit are silently ignored. |\n-|                        |                           |            | When using with a window type of ``session``, it can sometimes      |\n-|                        |                           |            | happen that two session windows get merged together into one when a |\n-|                        |                           |            | late-arriving record with a timestamp between the two windows is    |\n-|                        |                           |            | processed. In this case the 1000 record limit is calculated by      |\n-|                        |                           |            | first considering all the records from the first window, then the   |\n-|                        |                           |            | late-arriving record, then the records from the second window in    |\n-|                        |                           |            | the order they were originally processed.                           |\n-+------------------------+---------------------------+------------+---------------------------------------------------------------------+\n-| COUNT                  | ``COUNT(col1)``,          | Stream,    | Count the number of rows. When ``col1`` is specified, the count     |\n-|                        | ``COUNT(*)``              | Table      | returned will be the number of rows where ``col1`` is non-null.     |\n-|                        |                           |            | When ``*`` is specified, the count returned will be the total       |\n-|                        |                           |            | number of rows.                                                     |\n-+------------------------+---------------------------+------------+---------------------------------------------------------------------+\n-| HISTOGRAM              | ``HISTOGRAM(col1)``       | Stream,    | Return a map containing the distinct String values of ``col1``      |\n-|                        |                           | Table      | mapped to the number of times each one occurs for the given window. |\n-|                        |                           |            | This version limits the number of distinct values which can be      |\n-|                        |                           |            | counted to 1000, beyond which any additional entries are ignored.   |\n-|                        |                           |            | When using with a window type of ``session``, it can sometimes      |\n-|                        |                           |            | happen that two session windows get merged together into one when a |\n-|                        |                           |            | late-arriving record with a timestamp between the two windows is    |\n-|                        |                           |            | processed. In this case the 1000 record limit is calculated by      |\n-|                        |                           |            | first considering all the records from the first window, then the   |\n-|                        |                           |            | late-arriving record, then the records from the second window in    |\n-|                        |                           |            | the order they were originally processed.                           |\n-+------------------------+---------------------------+------------+---------------------------------------------------------------------+\n-| AVERAGE                | ``AVG(col1)``             | Stream,    | Return the average value for a given column.                        |\n-|                        |                           | Table      | Note: rows where ``col1`` is null are ignored.                      |\n-+------------------------+---------------------------+------------+---------------------------------------------------------------------+\n-| MAX                    | ``MAX(col1)``             | Stream     | Return the maximum value for a given column and window.             |\n-|                        |                           |            | Note: rows where ``col1`` is null will be ignored.                  |\n-+------------------------+---------------------------+------------+---------------------------------------------------------------------+\n-| MIN                    | ``MIN(col1)``             | Stream     | Return the minimum value for a given column and window.             |\n-|                        |                           |            | Note: rows where ``col1`` is null will be ignored.                  |\n-+------------------------+---------------------------+------------+---------------------------------------------------------------------+\n-| SUM                    | ``SUM(col1)``             | Stream,    | Sums the column values                                              |\n-|                        |                           | Table      | Note: rows where ``col1`` is null will be ignored.                  |\n-+------------------------+---------------------------+------------+---------------------------------------------------------------------+\n-| TOPK                   | ``TOPK(col1, k)``         | Stream     | Return the Top *K* values for the given column and window           |\n-|                        |                           |            | Note: rows where ``col1`` is null will be ignored.                  |\n-+------------------------+---------------------------+------------+---------------------------------------------------------------------+\n-| TOPKDISTINCT           | ``TOPKDISTINCT(col1, k)`` | Stream     | Return the distinct Top *K* values for the given column and window  |\n-|                        |                           |            | Note: rows where ``col1`` is null will be ignored.                  |\n-+------------------------+---------------------------+------------+---------------------------------------------------------------------+\n++------------------------+----------------------------+------------+---------------------------------------------------------------------+\n+| Function               | Example                    | Input Type | Description                                                         |\n++========================+============================+============+=====================================================================+\n+| COLLECT_LIST           | ``COLLECT_LIST(col1)``     | Stream,    | Return an array containing all the values of ``col1`` from each     |\n+|                        |                            | Table      | input row (for the specified grouping and time window, if any).     |\n+|                        |                            |            | Currently only works for simple types (not Map, Array, or Struct).  |\n+|                        |                            |            | This version limits the size of the result Array to a maximum of    |\n+|                        |                            |            | 1000 entries and any values beyond this limit are silently ignored. |\n+|                        |                            |            | When using with a window type of ``session``, it can sometimes      |\n+|                        |                            |            | happen that two session windows get merged together into one when a |\n+|                        |                            |            | late-arriving record with a timestamp between the two windows is    |\n+|                        |                            |            | processed. In this case the 1000 record limit is calculated by      |\n+|                        |                            |            | first considering all the records from the first window, then the   |\n+|                        |                            |            | late-arriving record, then the records from the second window in    |\n+|                        |                            |            | the order they were originally processed.                           |\n++------------------------+----------------------------+------------+---------------------------------------------------------------------+\n+| COLLECT_SET            | ``COLLECT_SET(col1)``      | Stream     | Return an array containing the distinct values of ``col1`` from     |", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2ce900fb492443919326bb766ba90e00c347397"}, "originalPosition": 84}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc1NTg0NzA5", "url": "https://github.com/confluentinc/ksql/pull/4782#pullrequestreview-375584709", "createdAt": "2020-03-16T21:10:06Z", "commit": {"oid": "e2ce900fb492443919326bb766ba90e00c347397"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQyMToxMDowN1rOF3F3hA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNlQyMToxMDowN1rOF3F3hA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzMxMjEzMg==", "bodyText": "I know it's confusing, but the .rst docs are deprecated for new content, so if you could add this change to the Aggregate Functions topic in the markdown docs, that would be great.", "url": "https://github.com/confluentinc/ksql/pull/4782#discussion_r393312132", "createdAt": "2020-03-16T21:10:07Z", "author": {"login": "JimGalasyn"}, "path": "docs/developer-guide/syntax-reference.rst", "diffHunk": "@@ -2093,70 +2093,74 @@ convention is followed.\n Aggregate functions\n ===================\n \n-+------------------------+---------------------------+------------+---------------------------------------------------------------------+\n-| Function               | Example                   | Input Type | Description                                                         |\n-+========================+===========================+============+=====================================================================+\n-| COLLECT_LIST           | ``COLLECT_LIST(col1)``    | Stream,    | Return an array containing all the values of ``col1`` from each     |\n-|                        |                           | Table      | input row (for the specified grouping and time window, if any).     |\n-|                        |                           |            | Currently only works for simple types (not Map, Array, or Struct).  |\n-|                        |                           |            | This version limits the size of the result Array to a maximum of    |\n-|                        |                           |            | 1000 entries and any values beyond this limit are silently ignored. |\n-|                        |                           |            | When using with a window type of ``session``, it can sometimes      |\n-|                        |                           |            | happen that two session windows get merged together into one when a |\n-|                        |                           |            | late-arriving record with a timestamp between the two windows is    |\n-|                        |                           |            | processed. In this case the 1000 record limit is calculated by      |\n-|                        |                           |            | first considering all the records from the first window, then the   |\n-|                        |                           |            | late-arriving record, then the records from the second window in    |\n-|                        |                           |            | the order they were originally processed.                           |\n-+------------------------+---------------------------+------------+---------------------------------------------------------------------+\n-| COLLECT_SET            | ``COLLECT_SET(col1)``     | Stream     | Return an array containing the distinct values of ``col1`` from     |\n-|                        |                           |            | each input row (for the specified grouping and time window, if any).|\n-|                        |                           |            | Currently only works for simple types (not Map, Array, or Struct).  |\n-|                        |                           |            | This version limits the size of the result Array to a maximum of    |\n-|                        |                           |            | 1000 entries and any values beyond this limit are silently ignored. |\n-|                        |                           |            | When using with a window type of ``session``, it can sometimes      |\n-|                        |                           |            | happen that two session windows get merged together into one when a |\n-|                        |                           |            | late-arriving record with a timestamp between the two windows is    |\n-|                        |                           |            | processed. In this case the 1000 record limit is calculated by      |\n-|                        |                           |            | first considering all the records from the first window, then the   |\n-|                        |                           |            | late-arriving record, then the records from the second window in    |\n-|                        |                           |            | the order they were originally processed.                           |\n-+------------------------+---------------------------+------------+---------------------------------------------------------------------+\n-| COUNT                  | ``COUNT(col1)``,          | Stream,    | Count the number of rows. When ``col1`` is specified, the count     |\n-|                        | ``COUNT(*)``              | Table      | returned will be the number of rows where ``col1`` is non-null.     |\n-|                        |                           |            | When ``*`` is specified, the count returned will be the total       |\n-|                        |                           |            | number of rows.                                                     |\n-+------------------------+---------------------------+------------+---------------------------------------------------------------------+\n-| HISTOGRAM              | ``HISTOGRAM(col1)``       | Stream,    | Return a map containing the distinct String values of ``col1``      |\n-|                        |                           | Table      | mapped to the number of times each one occurs for the given window. |\n-|                        |                           |            | This version limits the number of distinct values which can be      |\n-|                        |                           |            | counted to 1000, beyond which any additional entries are ignored.   |\n-|                        |                           |            | When using with a window type of ``session``, it can sometimes      |\n-|                        |                           |            | happen that two session windows get merged together into one when a |\n-|                        |                           |            | late-arriving record with a timestamp between the two windows is    |\n-|                        |                           |            | processed. In this case the 1000 record limit is calculated by      |\n-|                        |                           |            | first considering all the records from the first window, then the   |\n-|                        |                           |            | late-arriving record, then the records from the second window in    |\n-|                        |                           |            | the order they were originally processed.                           |\n-+------------------------+---------------------------+------------+---------------------------------------------------------------------+\n-| AVERAGE                | ``AVG(col1)``             | Stream,    | Return the average value for a given column.                        |\n-|                        |                           | Table      | Note: rows where ``col1`` is null are ignored.                      |\n-+------------------------+---------------------------+------------+---------------------------------------------------------------------+\n-| MAX                    | ``MAX(col1)``             | Stream     | Return the maximum value for a given column and window.             |\n-|                        |                           |            | Note: rows where ``col1`` is null will be ignored.                  |\n-+------------------------+---------------------------+------------+---------------------------------------------------------------------+\n-| MIN                    | ``MIN(col1)``             | Stream     | Return the minimum value for a given column and window.             |\n-|                        |                           |            | Note: rows where ``col1`` is null will be ignored.                  |\n-+------------------------+---------------------------+------------+---------------------------------------------------------------------+\n-| SUM                    | ``SUM(col1)``             | Stream,    | Sums the column values                                              |\n-|                        |                           | Table      | Note: rows where ``col1`` is null will be ignored.                  |\n-+------------------------+---------------------------+------------+---------------------------------------------------------------------+\n-| TOPK                   | ``TOPK(col1, k)``         | Stream     | Return the Top *K* values for the given column and window           |\n-|                        |                           |            | Note: rows where ``col1`` is null will be ignored.                  |\n-+------------------------+---------------------------+------------+---------------------------------------------------------------------+\n-| TOPKDISTINCT           | ``TOPKDISTINCT(col1, k)`` | Stream     | Return the distinct Top *K* values for the given column and window  |\n-|                        |                           |            | Note: rows where ``col1`` is null will be ignored.                  |\n-+------------------------+---------------------------+------------+---------------------------------------------------------------------+\n++------------------------+----------------------------+------------+---------------------------------------------------------------------+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2ce900fb492443919326bb766ba90e00c347397"}, "originalPosition": 68}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc1NTg1Mjkw", "url": "https://github.com/confluentinc/ksql/pull/4782#pullrequestreview-375585290", "createdAt": "2020-03-16T21:11:09Z", "commit": {"oid": "e2ce900fb492443919326bb766ba90e00c347397"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a7d6ac4e82f4fa0bd7da509dfc3e929f3294e649", "author": {"user": {"login": "purplefox", "name": "Tim Fox"}}, "url": "https://github.com/confluentinc/ksql/commit/a7d6ac4e82f4fa0bd7da509dfc3e929f3294e649", "committedDate": "2020-03-17T06:19:38Z", "message": "revert to old version of docs rst"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "721e043f16bffdc617694c2896248ffaee388729", "author": {"user": {"login": "purplefox", "name": "Tim Fox"}}, "url": "https://github.com/confluentinc/ksql/commit/721e043f16bffdc617694c2896248ffaee388729", "committedDate": "2020-03-17T06:20:11Z", "message": "Added new docs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "244dc6918bbb2b645a9b54ba6ac33702385a1622", "author": {"user": {"login": "purplefox", "name": "Tim Fox"}}, "url": "https://github.com/confluentinc/ksql/commit/244dc6918bbb2b645a9b54ba6ac33702385a1622", "committedDate": "2020-03-17T15:26:31Z", "message": "Added test plan thingies"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 21, "cost": 1, "resetAt": "2021-11-01T13:07:16Z"}}}