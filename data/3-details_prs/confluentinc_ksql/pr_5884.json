{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDU3MzczNDM1", "number": 5884, "title": "feat: add suppress functionality", "bodyText": "Description\nWhat behavior do you want to change, why, how does your patch achieve the changes?\nSuppress functionality is now possible by specifying EMIT FINAL for a push query that has a windowed aggregation.\nTesting done\nDescribe the testing strategy. Unit and integration tests are expected for any behavior changes.\nQTT tests added in suppress.json as well as relevant JUnit tests added where applicable such as TableSuppressBuilderTest\nReviewer checklist\n\n Ensure docs are updated if necessary. (eg. if a user visible feature is being added or changed).\n Ensure relevant issues are linked (description should include text like \"Fixes #\")", "createdAt": "2020-07-27T20:03:09Z", "url": "https://github.com/confluentinc/ksql/pull/5884", "merged": true, "mergeCommit": {"oid": "2dbd9e84dd23b4857c377e2b6de1c502deb33b63"}, "closed": true, "closedAt": "2020-08-03T18:03:52Z", "author": {"login": "nae701"}, "timelineItems": {"totalCount": 17, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc5Gxp_AH2gAyNDU3MzczNDM1Ojc4MjY5NGZlMzA1NTFiZWU3MDA0MmIyNmUzN2I1ODI1M2VlYTU0YTQ=", "endCursor": "Y3Vyc29yOnYyOpPPAAABc7V0q4gFqTQ2MDIyNzYzOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "782694fe30551bee70042b26e37b58253eea54a4", "author": {"user": {"login": "nae701", "name": "Natea Eshetu Beshada"}}, "url": "https://github.com/confluentinc/ksql/commit/782694fe30551bee70042b26e37b58253eea54a4", "committedDate": "2020-07-27T19:13:26Z", "message": "add more qtt suppress tests\n\nchore: cherry-pick bd8c7fadf"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "68f03ddd443ab07bc53c415ed5430b92f18957ed", "author": {"user": {"login": "nae701", "name": "Natea Eshetu Beshada"}}, "url": "https://github.com/confluentinc/ksql/commit/68f03ddd443ab07bc53c415ed5430b92f18957ed", "committedDate": "2020-07-27T19:26:45Z", "message": "fix: add name for suppression\n\nchore: cherry-pick 37c"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d4b31536e51de00a795b77d5818fd9cca595ecf1", "author": {"user": {"login": "nae701", "name": "Natea Eshetu Beshada"}}, "url": "https://github.com/confluentinc/ksql/commit/d4b31536e51de00a795b77d5818fd9cca595ecf1", "committedDate": "2020-07-27T19:34:16Z", "message": "feat: implement suppress on ktable\n\nchore: cherrypick 30cc"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "08c01e86a4500d6c0668032770c615b99f15aefa", "author": {"user": {"login": "nae701", "name": "Natea Eshetu Beshada"}}, "url": "https://github.com/confluentinc/ksql/commit/08c01e86a4500d6c0668032770c615b99f15aefa", "committedDate": "2020-07-27T19:46:15Z", "message": "test: add default grace period tests\n\nchore: cherrypick cfd"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3f12926b76184c46127063d0a6906b0c6ef5a529", "author": {"user": {"login": "nae701", "name": "Natea Eshetu Beshada"}}, "url": "https://github.com/confluentinc/ksql/commit/3f12926b76184c46127063d0a6906b0c6ef5a529", "committedDate": "2020-07-27T19:56:57Z", "message": "chore: remove unused imports"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "934e79aba168460590f384ae21332f8b6529730f", "author": {"user": {"login": "nae701", "name": "Natea Eshetu Beshada"}}, "url": "https://github.com/confluentinc/ksql/commit/934e79aba168460590f384ae21332f8b6529730f", "committedDate": "2020-07-27T21:07:44Z", "message": "fix: regenerate correct schema"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "eb818b50cea0c436f927f91d83448562f1b8fc00", "author": {"user": {"login": "nae701", "name": "Natea Eshetu Beshada"}}, "url": "https://github.com/confluentinc/ksql/commit/eb818b50cea0c436f927f91d83448562f1b8fc00", "committedDate": "2020-07-27T22:26:37Z", "message": "chore: generate historical qtt plans"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU2MTkyMzQ5", "url": "https://github.com/confluentinc/ksql/pull/5884#pullrequestreview-456192349", "createdAt": "2020-07-27T23:01:39Z", "commit": {"oid": "934e79aba168460590f384ae21332f8b6529730f"}, "state": "COMMENTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QyMzowMTozOVrOG32jbw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yN1QyMzozMzo1N1rOG33NYw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTIxODY3MQ==", "bodyText": "I think this could benefit from a comment explaining why we're adding the transformValues here", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r461218671", "createdAt": "2020-07-27T23:01:39Z", "author": {"login": "agavra"}, "path": "ksqldb-streams/src/main/java/io/confluent/ksql/execution/streams/TableSuppressBuilder.java", "diffHunk": "@@ -15,17 +15,98 @@\n \n package io.confluent.ksql.execution.streams;\n \n+import com.google.common.annotations.VisibleForTesting;\n+import io.confluent.ksql.GenericRow;\n+import io.confluent.ksql.execution.builder.KsqlQueryBuilder;\n+import io.confluent.ksql.execution.context.QueryContext;\n import io.confluent.ksql.execution.plan.KTableHolder;\n-import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.execution.plan.KeySerdeFactory;\n+import io.confluent.ksql.execution.plan.TableSuppress;\n+import io.confluent.ksql.execution.streams.transform.KsTransformer;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.serde.SerdeOption;\n+import java.util.Set;\n+import java.util.function.BiFunction;\n+import org.apache.kafka.common.serialization.Serde;\n+import org.apache.kafka.common.utils.Bytes;\n+import org.apache.kafka.streams.kstream.KTable;\n+import org.apache.kafka.streams.kstream.Materialized;\n+import org.apache.kafka.streams.kstream.Suppressed;\n+import org.apache.kafka.streams.state.KeyValueStore;\n+\n \n public final class TableSuppressBuilder {\n \n-  private TableSuppressBuilder() {\n+  private static final String SUPPRESS_OP_NAME = \"Suppress\";\n+\n+  public TableSuppressBuilder() {\n   }\n \n-  public static <K> KTableHolder<K> build(\n-      final KTableHolder<K> table\n+  public <K> KTableHolder<K> build(\n+      final KTableHolder<K> table,\n+      final TableSuppress<K> step,\n+      final KsqlQueryBuilder queryBuilder,\n+      final KeySerdeFactory keySerdeFactory,\n+      final MaterializedFactory materializedFactory\n   ) {\n-    throw new KsqlException(\"EMIT FINAL is not yet supported\");\n+    return build(\n+        table,\n+        step,\n+        queryBuilder,\n+        keySerdeFactory,\n+        materializedFactory,\n+        PhysicalSchema::from\n+    );\n+  }\n+\n+  @VisibleForTesting\n+  @SuppressWarnings(\"unchecked\")\n+  <K> KTableHolder<K> build(\n+      final KTableHolder<K> table,\n+      final TableSuppress<K> step,\n+      final KsqlQueryBuilder queryBuilder,\n+      final KeySerdeFactory keySerdeFactory,\n+      final MaterializedFactory materializedFactory,\n+      final BiFunction<LogicalSchema, Set<SerdeOption>, PhysicalSchema> physicalSchemaFactory\n+  ) {\n+    final PhysicalSchema physicalSchema = physicalSchemaFactory.apply(\n+        table.getSchema(),\n+        step.getInternalFormats().getOptions()\n+    );\n+    final QueryContext queryContext = QueryContext.Stacker.of(\n+        step.getProperties().getQueryContext())\n+        .push(SUPPRESS_OP_NAME).getQueryContext();\n+    final Serde<GenericRow> valueSerde = queryBuilder.buildValueSerde(\n+        step.getInternalFormats().getValueFormat(),\n+        physicalSchema,\n+        queryContext\n+    );\n+    final Serde<K> keySerde = keySerdeFactory.buildKeySerde(\n+        step.getInternalFormats().getKeyFormat(),\n+        physicalSchema,\n+        queryContext\n+    );\n+    final Materialized<K, GenericRow, KeyValueStore<Bytes, byte[]>> materialized =\n+        materializedFactory.create(\n+            keySerde,\n+            valueSerde,\n+            SUPPRESS_OP_NAME\n+        );\n+\n+    final KTable<K, GenericRow> suppressed = table.getTable().transformValues(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "934e79aba168460590f384ae21332f8b6529730f"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTIxOTIyMw==", "bodyText": "is this used anywhere?", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r461219223", "createdAt": "2020-07-27T23:03:10Z", "author": {"login": "agavra"}, "path": "ksqldb-execution/src/main/java/io/confluent/ksql/execution/plan/TableSuppress.java", "diffHunk": "@@ -57,6 +63,14 @@ public RefinementInfo getRefinementInfo() {\n     return refinementInfo;\n   }\n \n+  public Formats getInternalFormats() {\n+    return internalFormats;\n+  }\n+\n+  public KsqlWindowExpression getWindowExpression() {\n+    return windowExpression;\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "934e79aba168460590f384ae21332f8b6529730f"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTIyMDI4Nw==", "bodyText": "just wondering, where did you pick this up? it's really cool - I think it's better than our standard @RunWith(MockitoJUnitRunner.class)", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r461220287", "createdAt": "2020-07-27T23:06:08Z", "author": {"login": "agavra"}, "path": "ksqldb-streams/src/test/java/io/confluent/ksql/execution/streams/TableSuppressBuilderTest.java", "diffHunk": "@@ -0,0 +1,132 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.execution.streams;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+import io.confluent.ksql.GenericRow;\n+import io.confluent.ksql.execution.builder.KsqlQueryBuilder;\n+import io.confluent.ksql.execution.context.QueryContext;\n+import io.confluent.ksql.execution.plan.ExecutionStep;\n+import io.confluent.ksql.execution.plan.ExecutionStepPropertiesV1;\n+import io.confluent.ksql.execution.plan.Formats;\n+import io.confluent.ksql.execution.plan.KTableHolder;\n+import io.confluent.ksql.execution.plan.KeySerdeFactory;\n+import io.confluent.ksql.execution.plan.TableSuppress;\n+import io.confluent.ksql.execution.windows.KsqlWindowExpression;\n+import io.confluent.ksql.function.FunctionRegistry;\n+import io.confluent.ksql.logging.processing.ProcessingLogger;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.serde.RefinementInfo;\n+import io.confluent.ksql.serde.SerdeOption;\n+import io.confluent.ksql.util.KsqlConfig;\n+import java.util.Set;\n+import java.util.function.BiFunction;\n+\n+import org.apache.kafka.common.serialization.Serde;\n+import org.apache.kafka.connect.data.Struct;\n+import org.apache.kafka.streams.kstream.KTable;\n+import org.apache.kafka.streams.kstream.Materialized;\n+import org.apache.kafka.streams.processor.StateStore;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.mockito.Mock;\n+import org.mockito.junit.MockitoJUnit;\n+import org.mockito.junit.MockitoRule;\n+\n+public class TableSuppressBuilderTest {\n+\n+  @Mock\n+  private KsqlQueryBuilder queryBuilder;\n+  @Mock\n+  private ExecutionStep<KTableHolder<Struct>> sourceStep;\n+  @Mock\n+  private KTable<Struct, GenericRow> sourceKTable;\n+  @Mock\n+  private KTable<Struct, GenericRow> preKTable;\n+  @Mock\n+  private KTable<Struct, GenericRow> suppressedKTable;\n+  @Mock\n+  private RefinementInfo refinementInfo;\n+  @Mock\n+  private Formats internalFormats;\n+  @Mock\n+  private KsqlWindowExpression windowExpression;\n+  @Mock\n+  private KeySerdeFactory<Struct> keySerdeFactory;\n+  @Mock\n+  private MaterializedFactory materializedFactory;\n+  @Mock\n+  private  PhysicalSchema physicalSchema;\n+  @Mock\n+  private  Serde<GenericRow> valueSerde;\n+  @Mock\n+  private  Serde<Struct> keySerde;\n+  @Mock\n+  private  Materialized<Object, GenericRow, StateStore> materialized;\n+  @Mock\n+  private KTableHolder<Struct> tableHolder;\n+  @Mock\n+  private KTableHolder<Struct> suppressedtable;\n+\n+  private final QueryContext queryContext = new QueryContext.Stacker()\n+      .push(\"bar\")\n+      .getQueryContext();\n+  private TableSuppress<Struct> tableSuppress;\n+  private BiFunction<LogicalSchema, Set<SerdeOption>, PhysicalSchema> physicalSchemaFactory;\n+  private TableSuppressBuilder builder;\n+\n+  @Rule\n+  public final MockitoRule mockitoRule = MockitoJUnit.rule();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "934e79aba168460590f384ae21332f8b6529730f"}, "originalPosition": 99}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTIyNDI1OA==", "bodyText": "it might be valuable to ensure that we're calling suppress with a FinalResultsSuppressionBuilder passed in. You can see usages of @Captor to see examples of how to use mockito to intercept the arguments being passed in and very that they're of the type you expect.\nThis is in contrast to other supressed instances we might be passing in in the future if we support things other than window close.", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r461224258", "createdAt": "2020-07-27T23:18:15Z", "author": {"login": "agavra"}, "path": "ksqldb-streams/src/test/java/io/confluent/ksql/execution/streams/TableSuppressBuilderTest.java", "diffHunk": "@@ -0,0 +1,132 @@\n+/*\n+ * Copyright 2020 Confluent Inc.\n+ *\n+ * Licensed under the Confluent Community License (the \"License\"); you may not use\n+ * this file except in compliance with the License.  You may obtain a copy of the\n+ * License at\n+ *\n+ * http://www.confluent.io/confluent-community-license\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OF ANY KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+\n+package io.confluent.ksql.execution.streams;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+import io.confluent.ksql.GenericRow;\n+import io.confluent.ksql.execution.builder.KsqlQueryBuilder;\n+import io.confluent.ksql.execution.context.QueryContext;\n+import io.confluent.ksql.execution.plan.ExecutionStep;\n+import io.confluent.ksql.execution.plan.ExecutionStepPropertiesV1;\n+import io.confluent.ksql.execution.plan.Formats;\n+import io.confluent.ksql.execution.plan.KTableHolder;\n+import io.confluent.ksql.execution.plan.KeySerdeFactory;\n+import io.confluent.ksql.execution.plan.TableSuppress;\n+import io.confluent.ksql.execution.windows.KsqlWindowExpression;\n+import io.confluent.ksql.function.FunctionRegistry;\n+import io.confluent.ksql.logging.processing.ProcessingLogger;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.serde.RefinementInfo;\n+import io.confluent.ksql.serde.SerdeOption;\n+import io.confluent.ksql.util.KsqlConfig;\n+import java.util.Set;\n+import java.util.function.BiFunction;\n+\n+import org.apache.kafka.common.serialization.Serde;\n+import org.apache.kafka.connect.data.Struct;\n+import org.apache.kafka.streams.kstream.KTable;\n+import org.apache.kafka.streams.kstream.Materialized;\n+import org.apache.kafka.streams.processor.StateStore;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.mockito.Mock;\n+import org.mockito.junit.MockitoJUnit;\n+import org.mockito.junit.MockitoRule;\n+\n+public class TableSuppressBuilderTest {\n+\n+  @Mock\n+  private KsqlQueryBuilder queryBuilder;\n+  @Mock\n+  private ExecutionStep<KTableHolder<Struct>> sourceStep;\n+  @Mock\n+  private KTable<Struct, GenericRow> sourceKTable;\n+  @Mock\n+  private KTable<Struct, GenericRow> preKTable;\n+  @Mock\n+  private KTable<Struct, GenericRow> suppressedKTable;\n+  @Mock\n+  private RefinementInfo refinementInfo;\n+  @Mock\n+  private Formats internalFormats;\n+  @Mock\n+  private KsqlWindowExpression windowExpression;\n+  @Mock\n+  private KeySerdeFactory<Struct> keySerdeFactory;\n+  @Mock\n+  private MaterializedFactory materializedFactory;\n+  @Mock\n+  private  PhysicalSchema physicalSchema;\n+  @Mock\n+  private  Serde<GenericRow> valueSerde;\n+  @Mock\n+  private  Serde<Struct> keySerde;\n+  @Mock\n+  private  Materialized<Object, GenericRow, StateStore> materialized;\n+  @Mock\n+  private KTableHolder<Struct> tableHolder;\n+  @Mock\n+  private KTableHolder<Struct> suppressedtable;\n+\n+  private final QueryContext queryContext = new QueryContext.Stacker()\n+      .push(\"bar\")\n+      .getQueryContext();\n+  private TableSuppress<Struct> tableSuppress;\n+  private BiFunction<LogicalSchema, Set<SerdeOption>, PhysicalSchema> physicalSchemaFactory;\n+  private TableSuppressBuilder builder;\n+\n+  @Rule\n+  public final MockitoRule mockitoRule = MockitoJUnit.rule();\n+\n+  @Before\n+  @SuppressWarnings(\"unchecked\")\n+  public void init() {\n+    final ExecutionStepPropertiesV1 properties = new ExecutionStepPropertiesV1(queryContext);\n+\n+    physicalSchemaFactory = (a,b) -> physicalSchema;\n+    when(queryBuilder.buildValueSerde(any(), any(), any())).thenReturn(valueSerde);\n+    when(keySerdeFactory.buildKeySerde(any(), any(), any())).thenReturn(keySerde);\n+    when(materializedFactory.create(any(), any(), any())).thenReturn(materialized);\n+\n+    when(tableHolder.getTable()).thenReturn(sourceKTable);\n+    when(sourceKTable.transformValues(any(), any(Materialized.class))).thenReturn(preKTable);\n+    when(preKTable.suppress(any())).thenReturn(suppressedKTable);\n+    when(tableHolder.withTable(any(),any())).thenReturn(suppressedtable);\n+\n+    tableSuppress = new TableSuppress<>(properties, sourceStep, refinementInfo, internalFormats, windowExpression);\n+    builder = new TableSuppressBuilder();\n+  }\n+\n+  @Test\n+  @SuppressWarnings(\"unchecked\")\n+  public void shouldSuppressSourceTable() {\n+    // When:\n+    final KTableHolder<Struct> result = builder.build(tableHolder, tableSuppress, queryBuilder, keySerdeFactory, materializedFactory, physicalSchemaFactory);\n+\n+    // Then:\n+    assertThat(result, is(suppressedtable));\n+    verify(sourceKTable).transformValues(any(),any(Materialized.class));\n+    verify(preKTable).suppress(any());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "934e79aba168460590f384ae21332f8b6529730f"}, "originalPosition": 129}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTIyNTUzMg==", "bodyText": "noting here in case the test doesn't come up later - what happens if we suppress with a tombstone? (e.g. the value coming in is entirely null, not a null column within the value)", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r461225532", "createdAt": "2020-07-27T23:21:55Z", "author": {"login": "agavra"}, "path": "ksqldb-functional-tests/src/test/resources/query-validation-tests/suppress.json", "diffHunk": "@@ -15,10 +92,222 @@\n         {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5},\n         {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0}\n       ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 4},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 2}\n+      ]\n+    },\n+    {\n+      \"name\": \"should handle null values\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "934e79aba168460590f384ae21332f8b6529730f"}, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTIyNjQ2Mg==", "bodyText": "how do we get a count of 2 here? I might be missing something, but I only see one value that should match (or is null timestamp treated as 0?):\n         {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r461226462", "createdAt": "2020-07-27T23:24:29Z", "author": {"login": "agavra"}, "path": "ksqldb-functional-tests/src/test/resources/query-validation-tests/suppress.json", "diffHunk": "@@ -15,10 +92,222 @@\n         {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5},\n         {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0}\n       ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 4},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 2}\n+      ]\n+    },\n+    {\n+      \"name\": \"should handle null values\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(COL1) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": null},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": null},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"key\": null, \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": null},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 2},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "934e79aba168460590f384ae21332f8b6529730f"}, "originalPosition": 111}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTIyNzA3MA==", "bodyText": "what if we made the third window start at a value in the middle instead of consecutive 0 -> 2 -> 4, like 10?", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r461227070", "createdAt": "2020-07-27T23:26:24Z", "author": {"login": "agavra"}, "path": "ksqldb-functional-tests/src/test/resources/query-validation-tests/suppress.json", "diffHunk": "@@ -15,10 +92,222 @@\n         {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5},\n         {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0}\n       ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 4},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 2}\n+      ]\n+    },\n+    {\n+      \"name\": \"should handle null values\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(COL1) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": null},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": null},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"key\": null, \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": null},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 2},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 2}\n+      ]\n+    },\n+    {\n+      \"name\": \"should drop events with no key\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\",\"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\",\"value\": {\"COL1\": \"v1\"},\"timestamp\": 5}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\",\"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 0}\n+      ]\n+    },\n+    {\n+      \"name\": \"should support final results for tumbling windows\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 4},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 2}\n+      ]\n+    },\n+    {\n+      \"name\": \"should support final results for tumbling windows with large jump\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 2 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 3},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 4},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 30}\n+\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 4},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 2},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 3},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 4, \"end\": 6, \"type\": \"time\"},\"timestamp\": 4}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "934e79aba168460590f384ae21332f8b6529730f"}, "originalPosition": 173}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTIyODEyNQ==", "bodyText": "we should test a session window that lasts longer than the session window size (e.g. 0,4,8 should all be in the same session window because the session gets extended). I'm also not sure it makes sense to have a session window with a grace period that's less than the session size so we should test a case where it's >= to the session size and in a future PR we might want to even fail if the grace period is less than the session size", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r461228125", "createdAt": "2020-07-27T23:29:52Z", "author": {"login": "agavra"}, "path": "ksqldb-functional-tests/src/test/resources/query-validation-tests/suppress.json", "diffHunk": "@@ -15,10 +92,222 @@\n         {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5},\n         {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0}\n       ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 4},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 2}\n+      ]\n+    },\n+    {\n+      \"name\": \"should handle null values\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(COL1) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": null},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": null},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"key\": null, \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": null},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 2},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 2}\n+      ]\n+    },\n+    {\n+      \"name\": \"should drop events with no key\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\",\"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\",\"value\": {\"COL1\": \"v1\"},\"timestamp\": 5}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\",\"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 0}\n+      ]\n+    },\n+    {\n+      \"name\": \"should support final results for tumbling windows\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 4},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 2}\n+      ]\n+    },\n+    {\n+      \"name\": \"should support final results for tumbling windows with large jump\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 2 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 3},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 4},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 30}\n+\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 4},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 2},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 3},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 4, \"end\": 6, \"type\": \"time\"},\"timestamp\": 4}\n+\n+      ]\n+    },\n+    {\n+      \"name\": \"should support final results for session windows\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW SESSION (5 MILLISECONDS, GRACE PERIOD 0 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "934e79aba168460590f384ae21332f8b6529730f"}, "originalPosition": 186}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTIyOTQxMQ==", "bodyText": "let's also test a suppress with a filter (WHERE clause)", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r461229411", "createdAt": "2020-07-27T23:33:57Z", "author": {"login": "agavra"}, "path": "ksqldb-functional-tests/src/test/resources/query-validation-tests/suppress.json", "diffHunk": "@@ -15,10 +92,222 @@\n         {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5},\n         {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0}\n       ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 4},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 2}\n+      ]\n+    },\n+    {\n+      \"name\": \"should handle null values\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(COL1) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": null},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": null},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"key\": null, \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": null},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 2},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 2}\n+      ]\n+    },\n+    {\n+      \"name\": \"should drop events with no key\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\",\"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\",\"value\": {\"COL1\": \"v1\"},\"timestamp\": 5}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\",\"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 0}\n+      ]\n+    },\n+    {\n+      \"name\": \"should support final results for tumbling windows\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 4},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 2}\n+      ]\n+    },\n+    {\n+      \"name\": \"should support final results for tumbling windows with large jump\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 2 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 3},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 4},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 30}\n+\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 4},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 2},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 3},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 4, \"end\": 6, \"type\": \"time\"},\"timestamp\": 4}\n+\n+      ]\n+    },\n+    {\n+      \"name\": \"should support final results for session windows\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW SESSION (5 MILLISECONDS, GRACE PERIOD 0 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k2\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 6},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 30}\n+\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 3},\"window\": {\"start\": 0, \"end\": 5, \"type\": \"session\"},\"timestamp\": 5},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k2\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 6, \"end\": 6, \"type\": \"session\"},\"timestamp\": 6}\n+      ]\n+    },\n+    {\n+      \"name\": \"should support final results for hopping windows\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW HOPPING (SIZE 5 MILLISECONDS,ADVANCE BY 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 6},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 10}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 4},\"window\": {\"start\": 0, \"end\": 5, \"type\": \"time\"}, \"timestamp\": 2},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 3},\"window\": {\"start\": 2, \"end\": 7, \"type\": \"time\"},\"timestamp\": 6},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 2},\"window\": {\"start\": 4, \"end\": 9, \"type\": \"time\"},\"timestamp\": 6}\n+      ]\n+    },\n+    {\n+      \"name\": \"should suppress multiple keys\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k2\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k2\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k2\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2}\n+\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 2},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k2\", \"value\": {\"COUNT\": 2},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 2}\n+      ]\n+    },\n+    {\n+      \"name\": \"should suppress after join\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "934e79aba168460590f384ae21332f8b6529730f"}, "originalPosition": 242}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "29f7ce1eefbfa18084b3a50875b91e561eb0e3ee", "author": {"user": {"login": "nae701", "name": "Natea Eshetu Beshada"}}, "url": "https://github.com/confluentinc/ksql/commit/29f7ce1eefbfa18084b3a50875b91e561eb0e3ee", "committedDate": "2020-07-28T16:52:39Z", "message": "chore: add comments for clarity"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU3MDY2MDEz", "url": "https://github.com/confluentinc/ksql/pull/5884#pullrequestreview-457066013", "createdAt": "2020-07-28T22:13:52Z", "commit": {"oid": "eb818b50cea0c436f927f91d83448562f1b8fc00"}, "state": "DISMISSED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQyMjoxMzo1MlrOG4hfaw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQyMjoxMzo1MlrOG4hfaw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTkyMjE1NQ==", "bodyText": "It looks like this is going to pass the name to Materialized and then pass the Materialized to transformValues, right? That's probably not what you want to do, since it will cause Streams to store a full extra copy of the table right before Suppress.\nI'm guessing you just wanted to pass the key and value serdes into Suppress, in which case, you can replace this with:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                final Materialized<K, GenericRow, KeyValueStore<Bytes, byte[]>> materialized =\n          \n          \n            \n                    materializedFactory.create(\n          \n          \n            \n                        keySerde,\n          \n          \n            \n                        valueSerde,\n          \n          \n            \n                        SUPPRESS_OP_NAME\n          \n          \n            \n                    );\n          \n          \n            \n                final Materialized<K, GenericRow, KeyValueStore<Bytes, byte[]>> materialized =\n          \n          \n            \n                    Materialized.with(\n          \n          \n            \n                        keySerde,\n          \n          \n            \n                        valueSerde\n          \n          \n            \n                    );\n          \n      \n    \n    \n  \n\nIt's a subtle and dangerous API, I know.", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r461922155", "createdAt": "2020-07-28T22:13:52Z", "author": {"login": "vvcephei"}, "path": "ksqldb-streams/src/main/java/io/confluent/ksql/execution/streams/TableSuppressBuilder.java", "diffHunk": "@@ -15,17 +15,98 @@\n \n package io.confluent.ksql.execution.streams;\n \n+import com.google.common.annotations.VisibleForTesting;\n+import io.confluent.ksql.GenericRow;\n+import io.confluent.ksql.execution.builder.KsqlQueryBuilder;\n+import io.confluent.ksql.execution.context.QueryContext;\n import io.confluent.ksql.execution.plan.KTableHolder;\n-import io.confluent.ksql.util.KsqlException;\n+import io.confluent.ksql.execution.plan.KeySerdeFactory;\n+import io.confluent.ksql.execution.plan.TableSuppress;\n+import io.confluent.ksql.execution.streams.transform.KsTransformer;\n+import io.confluent.ksql.schema.ksql.LogicalSchema;\n+import io.confluent.ksql.schema.ksql.PhysicalSchema;\n+import io.confluent.ksql.serde.SerdeOption;\n+import java.util.Set;\n+import java.util.function.BiFunction;\n+import org.apache.kafka.common.serialization.Serde;\n+import org.apache.kafka.common.utils.Bytes;\n+import org.apache.kafka.streams.kstream.KTable;\n+import org.apache.kafka.streams.kstream.Materialized;\n+import org.apache.kafka.streams.kstream.Suppressed;\n+import org.apache.kafka.streams.state.KeyValueStore;\n+\n \n public final class TableSuppressBuilder {\n \n-  private TableSuppressBuilder() {\n+  private static final String SUPPRESS_OP_NAME = \"Suppress\";\n+\n+  public TableSuppressBuilder() {\n   }\n \n-  public static <K> KTableHolder<K> build(\n-      final KTableHolder<K> table\n+  public <K> KTableHolder<K> build(\n+      final KTableHolder<K> table,\n+      final TableSuppress<K> step,\n+      final KsqlQueryBuilder queryBuilder,\n+      final KeySerdeFactory keySerdeFactory,\n+      final MaterializedFactory materializedFactory\n   ) {\n-    throw new KsqlException(\"EMIT FINAL is not yet supported\");\n+    return build(\n+        table,\n+        step,\n+        queryBuilder,\n+        keySerdeFactory,\n+        materializedFactory,\n+        PhysicalSchema::from\n+    );\n+  }\n+\n+  @VisibleForTesting\n+  @SuppressWarnings(\"unchecked\")\n+  <K> KTableHolder<K> build(\n+      final KTableHolder<K> table,\n+      final TableSuppress<K> step,\n+      final KsqlQueryBuilder queryBuilder,\n+      final KeySerdeFactory keySerdeFactory,\n+      final MaterializedFactory materializedFactory,\n+      final BiFunction<LogicalSchema, Set<SerdeOption>, PhysicalSchema> physicalSchemaFactory\n+  ) {\n+    final PhysicalSchema physicalSchema = physicalSchemaFactory.apply(\n+        table.getSchema(),\n+        step.getInternalFormats().getOptions()\n+    );\n+    final QueryContext queryContext = QueryContext.Stacker.of(\n+        step.getProperties().getQueryContext())\n+        .push(SUPPRESS_OP_NAME).getQueryContext();\n+    final Serde<GenericRow> valueSerde = queryBuilder.buildValueSerde(\n+        step.getInternalFormats().getValueFormat(),\n+        physicalSchema,\n+        queryContext\n+    );\n+    final Serde<K> keySerde = keySerdeFactory.buildKeySerde(\n+        step.getInternalFormats().getKeyFormat(),\n+        physicalSchema,\n+        queryContext\n+    );\n+    final Materialized<K, GenericRow, KeyValueStore<Bytes, byte[]>> materialized =\n+        materializedFactory.create(\n+            keySerde,\n+            valueSerde,\n+            SUPPRESS_OP_NAME\n+        );", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eb818b50cea0c436f927f91d83448562f1b8fc00"}, "originalPosition": 86}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "872f11ca17c3999c5d6016d2fbd5e403b5fc8682", "author": {"user": {"login": "nae701", "name": "Natea Eshetu Beshada"}}, "url": "https://github.com/confluentinc/ksql/commit/872f11ca17c3999c5d6016d2fbd5e403b5fc8682", "committedDate": "2020-07-29T00:43:33Z", "message": "fix: remove window expression and fix feedback"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU3MTQ4Mzc5", "url": "https://github.com/confluentinc/ksql/pull/5884#pullrequestreview-457148379", "createdAt": "2020-07-29T02:14:51Z", "commit": {"oid": "872f11ca17c3999c5d6016d2fbd5e403b5fc8682"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwMjoxNDo1MVrOG4mEkw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwMjoxNDo1MVrOG4mEkw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk5NzIwMw==", "bodyText": "Feel free to disregard this comment, but it seems like it would be easier to read these specs if there were one record per line.", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r461997203", "createdAt": "2020-07-29T02:14:51Z", "author": {"login": "vvcephei"}, "path": "ksqldb-functional-tests/src/test/resources/historical_plans/suppress_-_should_drop_events_with_no_key/6.1.0_1595888718687/spec.json", "diffHunk": "@@ -0,0 +1,154 @@\n+{\n+  \"version\" : \"6.1.0\",\n+  \"timestamp\" : 1595888718687,\n+  \"path\" : \"query-validation-tests/suppress.json\",\n+  \"schemas\" : {\n+    \"CTAS_OUTPUT_0.KsqlTopic.Source\" : \"STRUCT<COL1 VARCHAR> NOT NULL\",\n+    \"CTAS_OUTPUT_0.Aggregate.GroupBy\" : \"STRUCT<ID VARCHAR, ROWTIME BIGINT> NOT NULL\",\n+    \"CTAS_OUTPUT_0.Aggregate.Aggregate.Materialize\" : \"STRUCT<ID VARCHAR, ROWTIME BIGINT, KSQL_AGG_VARIABLE_0 BIGINT> NOT NULL\",\n+    \"CTAS_OUTPUT_0.Suppress.Suppress\" : \"STRUCT<COUNT BIGINT> NOT NULL\",\n+    \"CTAS_OUTPUT_0.OUTPUT\" : \"STRUCT<COUNT BIGINT> NOT NULL\"\n+  },\n+  \"testCase\" : {\n+    \"name\" : \"should drop events with no key\",\n+    \"inputs\" : [ {\n+      \"topic\" : \"input_topic\",\n+      \"key\" : \"k1\",\n+      \"value\" : {\n+        \"COL1\" : \"v1\"\n+      },\n+      \"timestamp\" : 0\n+    }, {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "872f11ca17c3999c5d6016d2fbd5e403b5fc8682"}, "originalPosition": 21}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7706f8e572bdddd04e68ff8c54fe43583949979d", "author": {"user": {"login": "nae701", "name": "Natea Eshetu Beshada"}}, "url": "https://github.com/confluentinc/ksql/commit/7706f8e572bdddd04e68ff8c54fe43583949979d", "committedDate": "2020-07-29T03:30:45Z", "message": "chore: remove unused window exp imports"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b6f3ae0b63b316dc22c7a81f4af4cf89f52b1104", "author": {"user": {"login": "nae701", "name": "Natea Eshetu Beshada"}}, "url": "https://github.com/confluentinc/ksql/commit/b6f3ae0b63b316dc22c7a81f4af4cf89f52b1104", "committedDate": "2020-07-29T04:51:55Z", "message": "chore: fix historical qtts suppress"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU3ODk0NDU1", "url": "https://github.com/confluentinc/ksql/pull/5884#pullrequestreview-457894455", "createdAt": "2020-07-29T21:01:33Z", "commit": {"oid": "b6f3ae0b63b316dc22c7a81f4af4cf89f52b1104"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMTowMTozM1rOG5KByw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMTowMTozM1rOG5KByw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU4NjMxNQ==", "bodyText": "testing GitHub IntelliJ integration", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r462586315", "createdAt": "2020-07-29T21:01:33Z", "author": {"login": "agavra"}, "path": "ksqldb-engine/src/main/java/io/confluent/ksql/planner/plan/SuppressNode.java", "diffHunk": "@@ -20,6 +20,7 @@\n import io.confluent.ksql.name.SourceName;\n import io.confluent.ksql.schema.ksql.LogicalSchema;\n import io.confluent.ksql.serde.RefinementInfo;\n+import io.confluent.ksql.serde.ValueFormat;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b6f3ae0b63b316dc22c7a81f4af4cf89f52b1104"}, "originalPosition": 4}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU3NjA0MDE4", "url": "https://github.com/confluentinc/ksql/pull/5884#pullrequestreview-457604018", "createdAt": "2020-07-29T14:53:13Z", "commit": {"oid": "b6f3ae0b63b316dc22c7a81f4af4cf89f52b1104"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxNDo1MzoxM1rOG48WYg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQxNjo0Mjo0M1rOG6PAfw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjM2MjIxMA==", "bodyText": "I'm sorry, but I'm not seeing how this example differs from the prior one. It seems like a 2ms tumbling window with no grace period should be emitted when that last record arrives at time 2. What have I missed?", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r462362210", "createdAt": "2020-07-29T14:53:13Z", "author": {"login": "vvcephei"}, "path": "ksqldb-functional-tests/src/test/resources/query-validation-tests/suppress.json", "diffHunk": "@@ -1,7 +1,83 @@\n {\n   \"tests\": [\n     {\n-      \"name\": \"Should Throw on Emit Final\",\n+      \"name\": \"should emit final result immediately at window end if grace is specified as zero\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 0 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 2},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1}\n+      ]\n+    },\n+    {\n+      \"name\": \"should not emit final result before window end if grace is specified as zero\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 0 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2}\n+      ],\n+      \"outputs\": [\n+      ]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b6f3ae0b63b316dc22c7a81f4af4cf89f52b1104"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjM2NjQzNA==", "bodyText": "Oh, I see, you mean we should see an output like this?\n{\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": null},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1}\n\nIf that is defined behavior we should probably have a test for it.", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r462366434", "createdAt": "2020-07-29T14:58:50Z", "author": {"login": "vvcephei"}, "path": "ksqldb-functional-tests/src/test/resources/query-validation-tests/suppress.json", "diffHunk": "@@ -15,10 +92,222 @@\n         {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5},\n         {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0}\n       ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 4},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 2}\n+      ]\n+    },\n+    {\n+      \"name\": \"should handle null values\",", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTIyNTUzMg=="}, "originalCommit": {"oid": "934e79aba168460590f384ae21332f8b6529730f"}, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzcxNDkxOQ==", "bodyText": "We should probably also add an event with an explicitly null key here.", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r463714919", "createdAt": "2020-07-31T16:39:24Z", "author": {"login": "vvcephei"}, "path": "ksqldb-functional-tests/src/test/resources/query-validation-tests/suppress.json", "diffHunk": "@@ -15,10 +91,239 @@\n         {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5},\n         {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0}\n       ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 4},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 2}\n+      ]\n+    },\n+    {\n+      \"name\": \"should handle null values\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(COL1) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": null},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": null},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"key\": null, \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 2}\n+      ]\n+    },\n+    {\n+      \"name\": \"should drop events with no key\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\",\"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\",\"value\": {\"COL1\": \"v1\"},\"timestamp\": 5}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\",\"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 0}\n+      ]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b6f3ae0b63b316dc22c7a81f4af4cf89f52b1104"}, "originalPosition": 129}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzcxNTAzNA==", "bodyText": "This looks out of place, given the name of this spec.", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r463715034", "createdAt": "2020-07-31T16:39:39Z", "author": {"login": "vvcephei"}, "path": "ksqldb-functional-tests/src/test/resources/query-validation-tests/suppress.json", "diffHunk": "@@ -15,10 +91,239 @@\n         {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5},\n         {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0}\n       ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 4},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 2}\n+      ]\n+    },\n+    {\n+      \"name\": \"should handle null values\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(COL1) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": null},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": null},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"key\": null, \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b6f3ae0b63b316dc22c7a81f4af4cf89f52b1104"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzcxNjQ3OQ==", "bodyText": "What do you think about also adding a test for join after suppression? I don't know if you're allowed to join windowed streams, which may disqualify this idea.", "url": "https://github.com/confluentinc/ksql/pull/5884#discussion_r463716479", "createdAt": "2020-07-31T16:42:43Z", "author": {"login": "vvcephei"}, "path": "ksqldb-functional-tests/src/test/resources/query-validation-tests/suppress.json", "diffHunk": "@@ -15,10 +91,239 @@\n         {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5},\n         {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0}\n       ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 4},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 2}\n+      ]\n+    },\n+    {\n+      \"name\": \"should handle null values\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(COL1) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": null},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": null},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"key\": null, \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 2}\n+      ]\n+    },\n+    {\n+      \"name\": \"should drop events with no key\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\",\"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\",\"value\": {\"COL1\": \"v1\"},\"timestamp\": 5}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\",\"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 0}\n+      ]\n+    },\n+    {\n+      \"name\": \"should support final results for tumbling windows\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 4},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 2}\n+      ]\n+    },\n+    {\n+      \"name\": \"should support final results for tumbling windows with large jump\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 2 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 3},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 10},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 30}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 4},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 2},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 3},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 10, \"end\": 12, \"type\": \"time\"},\"timestamp\": 10}\n+\n+      ]\n+    },\n+    {\n+      \"name\": \"should support final results for session windows\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW SESSION (5 MILLISECONDS, GRACE PERIOD 6 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 4},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 8},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 16},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 15},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 30}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 3},\"window\": {\"start\": 0, \"end\": 8, \"type\": \"session\"},\"timestamp\": 8},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 2},\"window\": {\"start\": 15, \"end\": 16, \"type\": \"session\"},\"timestamp\": 16}\n+      ]\n+    },\n+    {\n+      \"name\": \"should support final results for hopping windows\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW HOPPING (SIZE 5 MILLISECONDS,ADVANCE BY 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 6},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 10}\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 4},\"window\": {\"start\": 0, \"end\": 5, \"type\": \"time\"}, \"timestamp\": 2},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 3},\"window\": {\"start\": 2, \"end\": 7, \"type\": \"time\"},\"timestamp\": 6},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 2},\"window\": {\"start\": 4, \"end\": 9, \"type\": \"time\"},\"timestamp\": 6}\n+      ]\n+    },\n+    {\n+      \"name\": \"should suppress multiple keys\",\n+      \"statements\": [\n+        \"CREATE STREAM INPUT (ID STRING KEY, COL1 STRING) WITH (kafka_topic='input_topic',value_format='JSON');\",\n+        \"CREATE TABLE OUTPUT AS SELECT ID, COUNT(*) as COUNT FROM INPUT WINDOW TUMBLING (SIZE 2 MILLISECONDS, GRACE PERIOD 1 MILLISECONDS) GROUP BY ID EMIT FINAL;\"\n+      ],\n+      \"inputs\": [\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k2\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 1},\n+        {\"topic\": \"input_topic\", \"key\": \"k2\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 5},\n+        {\"topic\": \"input_topic\", \"key\": \"k1\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 0},\n+        {\"topic\": \"input_topic\", \"key\": \"k2\", \"value\": {\"COL1\": \"v1\"},\"timestamp\": 2}\n+\n+      ],\n+      \"outputs\": [\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 2},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k2\", \"value\": {\"COUNT\": 2},\"window\": {\"start\": 0, \"end\": 2, \"type\": \"time\"},\"timestamp\": 1},\n+        {\"topic\": \"OUTPUT\", \"key\": \"k1\", \"value\": {\"COUNT\": 1},\"window\": {\"start\": 2, \"end\": 4, \"type\": \"time\"},\"timestamp\": 2}\n+      ]\n+    },\n+    {\n+      \"name\": \"should suppress after join\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b6f3ae0b63b316dc22c7a81f4af4cf89f52b1104"}, "originalPosition": 239}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDYwMjI3NjM5", "url": "https://github.com/confluentinc/ksql/pull/5884#pullrequestreview-460227639", "createdAt": "2020-08-03T17:53:09Z", "commit": {"oid": "b6f3ae0b63b316dc22c7a81f4af4cf89f52b1104"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4761, "cost": 1, "resetAt": "2021-11-01T13:51:04Z"}}}