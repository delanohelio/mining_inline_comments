{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDA0NDY5Mjgy", "number": 1279, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQxNTo0NjoyMFrODykHhg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMFQxNDowMzoxOFrOD-O-nA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0MzQ3MTQyOnYy", "diffSide": "RIGHT", "path": "gremlin-dotnet/src/Gremlin.Net/Driver/ConnectionPool.cs", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQxNTo0NjoyMFrOGGruzg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQxNTo0NjoyMFrOGGruzg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTY2MTEzNA==", "bodyText": "There we some comments for this line on an earlier commit. I just want to sum them up here so we can include them in the review process of the PR:\n@idzmitry mentioned that adding a new dependency on Polly could be avoided by implementing the retry policy by ourselves.\n@spzSource suggested that it could make sense to add a random jitter to the exponential back-off here to avoid overloading the server when multiple clients try to reconnect at exactly the same intervals.", "url": "https://github.com/apache/tinkerpop/pull/1279#discussion_r409661134", "createdAt": "2020-04-16T15:46:20Z", "author": {"login": "FlorianHockmann"}, "path": "gremlin-dotnet/src/Gremlin.Net/Driver/ConnectionPool.cs", "diffHunk": "@@ -22,117 +22,156 @@\n #endregion\n \n using System;\n+using System.Collections.Concurrent;\n using System.Collections.Generic;\n using System.Threading;\n using System.Threading.Tasks;\n using Gremlin.Net.Driver.Exceptions;\n using Gremlin.Net.Process;\n+using Polly;\n \n namespace Gremlin.Net.Driver\n {\n     internal class ConnectionPool : IDisposable\n     {\n         private const int ConnectionIndexOverflowLimit = int.MaxValue - 1000000;\n         \n-        private readonly ConnectionFactory _connectionFactory;\n-        private readonly CopyOnWriteCollection<Connection> _connections = new CopyOnWriteCollection<Connection>();\n+        private readonly IConnectionFactory _connectionFactory;\n+        private readonly CopyOnWriteCollection<IConnection> _connections = new CopyOnWriteCollection<IConnection>();\n+\n+        private readonly ConcurrentDictionary<IConnection, byte> _deadConnections =\n+            new ConcurrentDictionary<IConnection, byte>();\n         private readonly int _poolSize;\n         private readonly int _maxInProcessPerConnection;\n         private int _connectionIndex;\n         private int _poolState;\n         private const int PoolIdle = 0;\n         private const int PoolPopulationInProgress = 1;\n \n-        public ConnectionPool(ConnectionFactory connectionFactory, ConnectionPoolSettings settings)\n+        public ConnectionPool(IConnectionFactory connectionFactory, ConnectionPoolSettings settings)\n         {\n             _connectionFactory = connectionFactory;\n             _poolSize = settings.PoolSize;\n             _maxInProcessPerConnection = settings.MaxInProcessPerConnection;\n-            PopulatePoolAsync().WaitUnwrap();\n+            ReplaceDeadConnectionsAsync().WaitUnwrap();\n         }\n         \n         public int NrConnections => _connections.Count;\n \n-        public async Task<IConnection> GetAvailableConnectionAsync()\n+        public IConnection GetAvailableConnection()\n         {\n-            await EnsurePoolIsPopulatedAsync().ConfigureAwait(false);\n-            return ProxiedConnection(GetConnectionFromPool());\n+            var connection = Policy.Handle<ServerUnavailableException>()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3fde9ee5d9eba167ec803f877f6e18afdffcfd48"}, "originalPosition": 49}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0MzQ4OTQ1OnYy", "diffSide": "RIGHT", "path": "gremlin-dotnet/src/Gremlin.Net/Driver/ConnectionPool.cs", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQxNTo1MDoyOFrOGGr6Sg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNlQxNTo1MDoyOFrOGGr6Sg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTY2NDA3NA==", "bodyText": "There was also a comment on this line in the earlier commit where @spzSource asked whether this recursive call could lead to a stack overflow. I answered also inline at that commit with an explanation of why I think that a stack overflow cannot happen here.", "url": "https://github.com/apache/tinkerpop/pull/1279#discussion_r409664074", "createdAt": "2020-04-16T15:50:28Z", "author": {"login": "FlorianHockmann"}, "path": "gremlin-dotnet/src/Gremlin.Net/Driver/ConnectionPool.cs", "diffHunk": "@@ -148,26 +187,39 @@ private void ProtectIndexFromOverflowing(int currentIndex)\n                 Interlocked.Exchange(ref _connectionIndex, 0);\n         }\n \n-        private void RemoveConnectionFromPool(Connection connection)\n+        private void ReplaceConnection(IConnection connection)\n         {\n-            if (_connections.TryRemove(connection))\n-                DefinitelyDestroyConnection(connection);\n+            RemoveConnectionFromPool(connection);\n+            TriggerReplacementOfDeadConnections();\n         }\n         \n-        private IConnection ProxiedConnection(Connection connection)\n+        private void RemoveConnectionFromPool(IConnection connection)\n         {\n-            return new ProxyConnection(connection, ReturnConnectionIfOpen);\n+            _deadConnections.TryAdd(connection, 0);\n         }\n \n-        private void ReturnConnectionIfOpen(Connection connection)\n+        private void TriggerReplacementOfDeadConnections()\n         {\n-            if (connection.IsOpen) return;\n-            ConsiderUnavailable();\n+            ReplaceClosedConnectionsAsync().Forget();\n         }\n \n-        private void ConsiderUnavailable()\n+        private async Task ReplaceClosedConnectionsAsync()\n         {\n-            CloseAndRemoveAllConnectionsAsync().WaitUnwrap();\n+            var poolWasPopulated = await EnsurePoolIsHealthyAsync().ConfigureAwait(false);\n+            // Another connection could have been removed already, check if another population is necessary\n+            if (poolWasPopulated)\n+                await ReplaceClosedConnectionsAsync().ConfigureAwait(false);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3fde9ee5d9eba167ec803f877f6e18afdffcfd48"}, "originalPosition": 214}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2NTgzNzA4OnYy", "diffSide": "RIGHT", "path": "docs/src/reference/gremlin-variants.asciidoc", "isResolved": true, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMFQxNDowMzoxOFrOGYNXWg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxNToxMDoyNFrOGbPZKA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODAzNzk3OA==", "bodyText": "NIT: Maybe we could use GetReconnectionAttempts() as a name?\nInstead of a number, it could return an IEnumerable<int>, that represents milliseconds to wait between each attempt.", "url": "https://github.com/apache/tinkerpop/pull/1279#discussion_r428037978", "createdAt": "2020-05-20T14:03:18Z", "author": {"login": "jorgebay"}, "path": "docs/src/reference/gremlin-variants.asciidoc", "diffHunk": "@@ -1090,10 +1090,13 @@ on the `ConnectionPoolSettings` instance that can be passed to the `GremlinClien\n |Key |Description |Default\n |PoolSize |The size of the connection pool. |4\n |MaxInProcessPerConnection |The maximum number of in-flight requests that can occur on a connection. |32\n+|GetOpenConnectionRetries |The number of retries to get an open connection from the pool to submit a request. |4", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "741deb71b0898e2af3e90161f601173e26dbdcbe"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTc4MzQ5MQ==", "bodyText": "Maybe we could use GetReconnectionAttempts() as a name?\n\nI also didn't like the name GetOpenConnectionRetries that much. ReconnectionAttempts sounds like a better name overall. I will probably omit the Get prefix as it's a property and the Get in GetOpenConnectionRetries meant the number of retries to get a connection.\n\nInstead of a number, it could return an IEnumerable, that represents milliseconds to wait between each attempt.\n\nDo you think that users want to configure the individual wait times explicitly instead of just using the default exponential back-off? And wouldn't an Action<int> (or Action<TimeSpan>) be even more flexible and easier to configure in that case?\nIf we let them configure an Action to compute the wait times, then it should probably be an additional option though as we would still need an option to configure the number of retries in general.", "url": "https://github.com/apache/tinkerpop/pull/1279#discussion_r429783491", "createdAt": "2020-05-25T07:48:01Z", "author": {"login": "FlorianHockmann"}, "path": "docs/src/reference/gremlin-variants.asciidoc", "diffHunk": "@@ -1090,10 +1090,13 @@ on the `ConnectionPoolSettings` instance that can be passed to the `GremlinClien\n |Key |Description |Default\n |PoolSize |The size of the connection pool. |4\n |MaxInProcessPerConnection |The maximum number of in-flight requests that can occur on a connection. |32\n+|GetOpenConnectionRetries |The number of retries to get an open connection from the pool to submit a request. |4", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODAzNzk3OA=="}, "originalCommit": {"oid": "741deb71b0898e2af3e90161f601173e26dbdcbe"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTc5ODk1Nw==", "bodyText": "It's true that exponential + jitter is what most people wants, my concern is whether we should allow users to configure the base delay, for example: users might want to start from 200ms, 400ms, 800ms and other people in the order of seconds.\nLooking at it a little bit more, maybe there should be two settings: \"number of attempts\" and \"base delay\".", "url": "https://github.com/apache/tinkerpop/pull/1279#discussion_r429798957", "createdAt": "2020-05-25T08:19:17Z", "author": {"login": "jorgebay"}, "path": "docs/src/reference/gremlin-variants.asciidoc", "diffHunk": "@@ -1090,10 +1090,13 @@ on the `ConnectionPoolSettings` instance that can be passed to the `GremlinClien\n |Key |Description |Default\n |PoolSize |The size of the connection pool. |4\n |MaxInProcessPerConnection |The maximum number of in-flight requests that can occur on a connection. |32\n+|GetOpenConnectionRetries |The number of retries to get an open connection from the pool to submit a request. |4", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODAzNzk3OA=="}, "originalCommit": {"oid": "741deb71b0898e2af3e90161f601173e26dbdcbe"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTgyNjc1NQ==", "bodyText": "So, we should introduce a constant factor for the exponential wait function? That would look like this:\nattempt => baseDelay * Math.Pow(2, attempt)\nand with baseDelay = TimeSpan.FromMilliseconds(100) they would get your wait times of 200ms, 400ms, 800ms, and so on.\nWith baseDelay = TimeSpan.FromSeconds(1) as the default we would get the current behaviour in this PR.", "url": "https://github.com/apache/tinkerpop/pull/1279#discussion_r429826755", "createdAt": "2020-05-25T09:14:48Z", "author": {"login": "FlorianHockmann"}, "path": "docs/src/reference/gremlin-variants.asciidoc", "diffHunk": "@@ -1090,10 +1090,13 @@ on the `ConnectionPoolSettings` instance that can be passed to the `GremlinClien\n |Key |Description |Default\n |PoolSize |The size of the connection pool. |4\n |MaxInProcessPerConnection |The maximum number of in-flight requests that can occur on a connection. |32\n+|GetOpenConnectionRetries |The number of retries to get an open connection from the pool to submit a request. |4", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODAzNzk3OA=="}, "originalCommit": {"oid": "741deb71b0898e2af3e90161f601173e26dbdcbe"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTgzMzE0Mg==", "bodyText": "yes, that would be awesome!", "url": "https://github.com/apache/tinkerpop/pull/1279#discussion_r429833142", "createdAt": "2020-05-25T09:27:12Z", "author": {"login": "jorgebay"}, "path": "docs/src/reference/gremlin-variants.asciidoc", "diffHunk": "@@ -1090,10 +1090,13 @@ on the `ConnectionPoolSettings` instance that can be passed to the `GremlinClien\n |Key |Description |Default\n |PoolSize |The size of the connection pool. |4\n |MaxInProcessPerConnection |The maximum number of in-flight requests that can occur on a connection. |32\n+|GetOpenConnectionRetries |The number of retries to get an open connection from the pool to submit a request. |4", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODAzNzk3OA=="}, "originalCommit": {"oid": "741deb71b0898e2af3e90161f601173e26dbdcbe"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTIxNjkzNg==", "bodyText": "I just pushed an update that includes these changes.", "url": "https://github.com/apache/tinkerpop/pull/1279#discussion_r431216936", "createdAt": "2020-05-27T15:10:24Z", "author": {"login": "FlorianHockmann"}, "path": "docs/src/reference/gremlin-variants.asciidoc", "diffHunk": "@@ -1090,10 +1090,13 @@ on the `ConnectionPoolSettings` instance that can be passed to the `GremlinClien\n |Key |Description |Default\n |PoolSize |The size of the connection pool. |4\n |MaxInProcessPerConnection |The maximum number of in-flight requests that can occur on a connection. |32\n+|GetOpenConnectionRetries |The number of retries to get an open connection from the pool to submit a request. |4", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODAzNzk3OA=="}, "originalCommit": {"oid": "741deb71b0898e2af3e90161f601173e26dbdcbe"}, "originalPosition": 4}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4172, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}