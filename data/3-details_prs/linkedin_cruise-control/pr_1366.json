{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTExOTQ0MTE5", "number": 1366, "title": "Added a metric sampler that fetches metrics from a Prometheus server endpoint.", "bodyText": "This PR resolves #1181.", "createdAt": "2020-10-29T01:06:02Z", "url": "https://github.com/linkedin/cruise-control/pull/1366", "merged": true, "mergeCommit": {"oid": "c0a3ba9c6c67bc99b016bfeb2f733910b261a8a2"}, "closed": true, "closedAt": "2020-11-03T23:03:03Z", "author": {"login": "wyuka"}, "timelineItems": {"totalCount": 15, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdXE5UJgH2gAyNTExOTQ0MTE5OjQwYjJlNzE5MTEwNTE0ZGI4YmU5NzQ1NzkyYThkYzQ4YzM2ZWIzOTU=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdZBG5lgFqTUyMjkyNzUzNQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "40b2e719110514db8be9745792a8dc48c36eb395", "author": {"user": {"login": "wyuka", "name": "Tirtha Chatterjee"}}, "url": "https://github.com/linkedin/cruise-control/commit/40b2e719110514db8be9745792a8dc48c36eb395", "committedDate": "2020-10-28T21:59:43Z", "message": "Added PrometheusMetricSampler to fetch cluster metrics from Prometheus server."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "512a181c321f630ec582740a03de6d36428f46f3", "author": {"user": {"login": "wyuka", "name": "Tirtha Chatterjee"}}, "url": "https://github.com/linkedin/cruise-control/commit/512a181c321f630ec582740a03de6d36428f46f3", "committedDate": "2020-10-28T22:03:26Z", "message": "Wildcard static imports."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a18e016c98774d2520fa6a6214370cf272e6adc0", "author": {"user": {"login": "wyuka", "name": "Tirtha Chatterjee"}}, "url": "https://github.com/linkedin/cruise-control/commit/a18e016c98774d2520fa6a6214370cf272e6adc0", "committedDate": "2020-10-29T00:39:01Z", "message": "Added configuration fields to wiki."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f48265d85b51861abcf87df9c36f15f6bffa6d03", "author": {"user": {"login": "wyuka", "name": "Tirtha Chatterjee"}}, "url": "https://github.com/linkedin/cruise-control/commit/f48265d85b51861abcf87df9c36f15f6bffa6d03", "committedDate": "2020-10-29T00:48:45Z", "message": "Added proper JavaDoc descriptions to classes."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "99ad11c61fd99fdb7be96b858bc8a687435cfa82", "author": {"user": {"login": "wyuka", "name": "Tirtha Chatterjee"}}, "url": "https://github.com/linkedin/cruise-control/commit/99ad11c61fd99fdb7be96b858bc8a687435cfa82", "committedDate": "2020-10-29T00:58:35Z", "message": "Fixed formatting."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a48cebdc4a03756c9d81d3eee421a3ad7b983e6a", "author": {"user": {"login": "wyuka", "name": "Tirtha Chatterjee"}}, "url": "https://github.com/linkedin/cruise-control/commit/a48cebdc4a03756c9d81d3eee421a3ad7b983e6a", "committedDate": "2020-10-29T01:05:53Z", "message": "Extracted reused values to constants in tests."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0d031702bbe2e35b02d89a82b9cf511be7a6cc65", "author": {"user": {"login": "wyuka", "name": "Tirtha Chatterjee"}}, "url": "https://github.com/linkedin/cruise-control/commit/0d031702bbe2e35b02d89a82b9cf511be7a6cc65", "committedDate": "2020-10-31T02:04:55Z", "message": "Do not fail sampling if Prometheus sampler sees bad QueryResult."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIxOTI2NTA0", "url": "https://github.com/linkedin/cruise-control/pull/1366#pullrequestreview-521926504", "createdAt": "2020-11-02T19:21:01Z", "commit": {"oid": "0d031702bbe2e35b02d89a82b9cf511be7a6cc65"}, "state": "COMMENTED", "comments": {"totalCount": 23, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMlQxOToyMTowMVrOHsSbXA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wMlQyMDo1NDoxOFrOHsVSGQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIwMTMwOA==", "bodyText": "Nit: 2017 -> 2020", "url": "https://github.com/linkedin/cruise-control/pull/1366#discussion_r516201308", "createdAt": "2020-11-02T19:21:01Z", "author": {"login": "efeg"}, "path": "cruise-control/src/main/java/com/linkedin/kafka/cruisecontrol/monitor/sampling/prometheus/InvalidPrometheusResultException.java", "diffHunk": "@@ -0,0 +1,18 @@\n+/*\n+ * Copyright 2017 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\"). See License in the project root for license information.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0d031702bbe2e35b02d89a82b9cf511be7a6cc65"}, "originalPosition": 2}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIwMzYwNg==", "bodyText": "Should InvalidPrometheusResultException extend from SamplingException? More specifically, what is the additional benefit of using InvalidPrometheusResultException rather than SamplingException?", "url": "https://github.com/linkedin/cruise-control/pull/1366#discussion_r516203606", "createdAt": "2020-11-02T19:25:30Z", "author": {"login": "efeg"}, "path": "cruise-control/src/main/java/com/linkedin/kafka/cruisecontrol/monitor/sampling/prometheus/InvalidPrometheusResultException.java", "diffHunk": "@@ -0,0 +1,18 @@\n+/*\n+ * Copyright 2017 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\"). See License in the project root for license information.\n+ */\n+\n+package com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus;\n+\n+import com.linkedin.kafka.cruisecontrol.exception.KafkaCruiseControlException;\n+\n+/**\n+ * The exception indicates that the broker with which the metric is associated could not be determined.\n+ */\n+public class InvalidPrometheusResultException extends KafkaCruiseControlException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0d031702bbe2e35b02d89a82b9cf511be7a6cc65"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIwNDY1Nw==", "bodyText": "Can we move the hardcoded string constants (e.g. \"/api/v1/query_range\", \"query\") to static variables?\nCan we indicate the expected values for parameters -- e.g. start and end requires UNIX timestamp in seconds (are they inclusive or exclusive?), step is in seconds.\nDoes step accepts values with a decimal point? Would the current integer division cause loss of accuracy?", "url": "https://github.com/linkedin/cruise-control/pull/1366#discussion_r516204657", "createdAt": "2020-11-02T19:27:26Z", "author": {"login": "efeg"}, "path": "cruise-control/src/main/java/com/linkedin/kafka/cruisecontrol/monitor/sampling/prometheus/PrometheusAdapter.java", "diffHunk": "@@ -0,0 +1,92 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\"). See License in the project root for license information.\n+ */\n+\n+package com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.net.URI;\n+import java.nio.charset.StandardCharsets;\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.commons.io.IOUtils;\n+import org.apache.http.HttpEntity;\n+import org.apache.http.HttpHost;\n+import org.apache.http.NameValuePair;\n+import org.apache.http.client.entity.UrlEncodedFormEntity;\n+import org.apache.http.client.methods.CloseableHttpResponse;\n+import org.apache.http.client.methods.HttpPost;\n+import org.apache.http.impl.client.CloseableHttpClient;\n+import org.apache.http.message.BasicNameValuePair;\n+import org.apache.http.util.EntityUtils;\n+\n+import com.google.gson.Gson;\n+\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusQueryResult;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusResponse;\n+\n+/**\n+ * This class provides an adapter to make queries to a Prometheus Server to fetch metric values.\n+ */\n+class PrometheusAdapter {\n+    private static final int MILLIS_IN_SECOND = 1000;\n+    private static final Gson GSON = new Gson();\n+\n+    private final CloseableHttpClient _httpClient;\n+    /* Visible for testing */\n+    final HttpHost _prometheusEndpoint;\n+    /* Visible for testing */\n+    final Integer _samplingIntervalMs;\n+\n+    public PrometheusAdapter(CloseableHttpClient httpClient,\n+                             HttpHost prometheusEndpoint,\n+                             Integer samplingIntervalMs) {\n+        _httpClient = httpClient;\n+        _prometheusEndpoint = prometheusEndpoint;\n+        _samplingIntervalMs = samplingIntervalMs;\n+    }\n+\n+    public List<PrometheusQueryResult> queryMetric(String queryString,\n+                                                   long startTimeMs,\n+                                                   long endTimeMs) throws IOException {\n+        URI queryUri = URI.create(_prometheusEndpoint.toURI() + \"/api/v1/query_range\");\n+        HttpPost httpPost = new HttpPost(queryUri);\n+\n+        List<NameValuePair> data = new ArrayList<>();\n+        data.add(new BasicNameValuePair(\"query\", queryString));\n+        data.add(new BasicNameValuePair(\"start\", String.valueOf(startTimeMs / MILLIS_IN_SECOND)));\n+        data.add(new BasicNameValuePair(\"end\", String.valueOf(endTimeMs / MILLIS_IN_SECOND)));\n+        data.add(new BasicNameValuePair(\"step\", String.valueOf(_samplingIntervalMs / MILLIS_IN_SECOND)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0d031702bbe2e35b02d89a82b9cf511be7a6cc65"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIwNjAwNg==", "bodyText": "200 -> HttpServletResponse.SC_OK", "url": "https://github.com/linkedin/cruise-control/pull/1366#discussion_r516206006", "createdAt": "2020-11-02T19:29:57Z", "author": {"login": "efeg"}, "path": "cruise-control/src/main/java/com/linkedin/kafka/cruisecontrol/monitor/sampling/prometheus/PrometheusAdapter.java", "diffHunk": "@@ -0,0 +1,92 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\"). See License in the project root for license information.\n+ */\n+\n+package com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.net.URI;\n+import java.nio.charset.StandardCharsets;\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.commons.io.IOUtils;\n+import org.apache.http.HttpEntity;\n+import org.apache.http.HttpHost;\n+import org.apache.http.NameValuePair;\n+import org.apache.http.client.entity.UrlEncodedFormEntity;\n+import org.apache.http.client.methods.CloseableHttpResponse;\n+import org.apache.http.client.methods.HttpPost;\n+import org.apache.http.impl.client.CloseableHttpClient;\n+import org.apache.http.message.BasicNameValuePair;\n+import org.apache.http.util.EntityUtils;\n+\n+import com.google.gson.Gson;\n+\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusQueryResult;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusResponse;\n+\n+/**\n+ * This class provides an adapter to make queries to a Prometheus Server to fetch metric values.\n+ */\n+class PrometheusAdapter {\n+    private static final int MILLIS_IN_SECOND = 1000;\n+    private static final Gson GSON = new Gson();\n+\n+    private final CloseableHttpClient _httpClient;\n+    /* Visible for testing */\n+    final HttpHost _prometheusEndpoint;\n+    /* Visible for testing */\n+    final Integer _samplingIntervalMs;\n+\n+    public PrometheusAdapter(CloseableHttpClient httpClient,\n+                             HttpHost prometheusEndpoint,\n+                             Integer samplingIntervalMs) {\n+        _httpClient = httpClient;\n+        _prometheusEndpoint = prometheusEndpoint;\n+        _samplingIntervalMs = samplingIntervalMs;\n+    }\n+\n+    public List<PrometheusQueryResult> queryMetric(String queryString,\n+                                                   long startTimeMs,\n+                                                   long endTimeMs) throws IOException {\n+        URI queryUri = URI.create(_prometheusEndpoint.toURI() + \"/api/v1/query_range\");\n+        HttpPost httpPost = new HttpPost(queryUri);\n+\n+        List<NameValuePair> data = new ArrayList<>();\n+        data.add(new BasicNameValuePair(\"query\", queryString));\n+        data.add(new BasicNameValuePair(\"start\", String.valueOf(startTimeMs / MILLIS_IN_SECOND)));\n+        data.add(new BasicNameValuePair(\"end\", String.valueOf(endTimeMs / MILLIS_IN_SECOND)));\n+        data.add(new BasicNameValuePair(\"step\", String.valueOf(_samplingIntervalMs / MILLIS_IN_SECOND)));\n+\n+        httpPost.setEntity(new UrlEncodedFormEntity(data));\n+        try (CloseableHttpResponse response = _httpClient.execute(httpPost)) {\n+            int responseCode = response.getStatusLine().getStatusCode();\n+            HttpEntity entity = response.getEntity();\n+            InputStream content = entity.getContent();\n+            String responseString = IOUtils.toString(content, StandardCharsets.UTF_8);\n+            if (responseCode != 200) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0d031702bbe2e35b02d89a82b9cf511be7a6cc65"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIwNjMwOQ==", "bodyText": "Do we allow null values for samplingIntervalMs? If not, can we use int rather than Integer?\nShould we add sanit checks to ensure that httpClient and prometheusEndpoint are not null?", "url": "https://github.com/linkedin/cruise-control/pull/1366#discussion_r516206309", "createdAt": "2020-11-02T19:30:35Z", "author": {"login": "efeg"}, "path": "cruise-control/src/main/java/com/linkedin/kafka/cruisecontrol/monitor/sampling/prometheus/PrometheusAdapter.java", "diffHunk": "@@ -0,0 +1,92 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\"). See License in the project root for license information.\n+ */\n+\n+package com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.net.URI;\n+import java.nio.charset.StandardCharsets;\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.commons.io.IOUtils;\n+import org.apache.http.HttpEntity;\n+import org.apache.http.HttpHost;\n+import org.apache.http.NameValuePair;\n+import org.apache.http.client.entity.UrlEncodedFormEntity;\n+import org.apache.http.client.methods.CloseableHttpResponse;\n+import org.apache.http.client.methods.HttpPost;\n+import org.apache.http.impl.client.CloseableHttpClient;\n+import org.apache.http.message.BasicNameValuePair;\n+import org.apache.http.util.EntityUtils;\n+\n+import com.google.gson.Gson;\n+\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusQueryResult;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusResponse;\n+\n+/**\n+ * This class provides an adapter to make queries to a Prometheus Server to fetch metric values.\n+ */\n+class PrometheusAdapter {\n+    private static final int MILLIS_IN_SECOND = 1000;\n+    private static final Gson GSON = new Gson();\n+\n+    private final CloseableHttpClient _httpClient;\n+    /* Visible for testing */\n+    final HttpHost _prometheusEndpoint;\n+    /* Visible for testing */\n+    final Integer _samplingIntervalMs;\n+\n+    public PrometheusAdapter(CloseableHttpClient httpClient,\n+                             HttpHost prometheusEndpoint,\n+                             Integer samplingIntervalMs) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0d031702bbe2e35b02d89a82b9cf511be7a6cc65"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIxNTI1OQ==", "bodyText": "Can we move the hardcoded string \"success\" to a static variable?", "url": "https://github.com/linkedin/cruise-control/pull/1366#discussion_r516215259", "createdAt": "2020-11-02T19:47:46Z", "author": {"login": "efeg"}, "path": "cruise-control/src/main/java/com/linkedin/kafka/cruisecontrol/monitor/sampling/prometheus/PrometheusAdapter.java", "diffHunk": "@@ -0,0 +1,92 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\"). See License in the project root for license information.\n+ */\n+\n+package com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.net.URI;\n+import java.nio.charset.StandardCharsets;\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.commons.io.IOUtils;\n+import org.apache.http.HttpEntity;\n+import org.apache.http.HttpHost;\n+import org.apache.http.NameValuePair;\n+import org.apache.http.client.entity.UrlEncodedFormEntity;\n+import org.apache.http.client.methods.CloseableHttpResponse;\n+import org.apache.http.client.methods.HttpPost;\n+import org.apache.http.impl.client.CloseableHttpClient;\n+import org.apache.http.message.BasicNameValuePair;\n+import org.apache.http.util.EntityUtils;\n+\n+import com.google.gson.Gson;\n+\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusQueryResult;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusResponse;\n+\n+/**\n+ * This class provides an adapter to make queries to a Prometheus Server to fetch metric values.\n+ */\n+class PrometheusAdapter {\n+    private static final int MILLIS_IN_SECOND = 1000;\n+    private static final Gson GSON = new Gson();\n+\n+    private final CloseableHttpClient _httpClient;\n+    /* Visible for testing */\n+    final HttpHost _prometheusEndpoint;\n+    /* Visible for testing */\n+    final Integer _samplingIntervalMs;\n+\n+    public PrometheusAdapter(CloseableHttpClient httpClient,\n+                             HttpHost prometheusEndpoint,\n+                             Integer samplingIntervalMs) {\n+        _httpClient = httpClient;\n+        _prometheusEndpoint = prometheusEndpoint;\n+        _samplingIntervalMs = samplingIntervalMs;\n+    }\n+\n+    public List<PrometheusQueryResult> queryMetric(String queryString,\n+                                                   long startTimeMs,\n+                                                   long endTimeMs) throws IOException {\n+        URI queryUri = URI.create(_prometheusEndpoint.toURI() + \"/api/v1/query_range\");\n+        HttpPost httpPost = new HttpPost(queryUri);\n+\n+        List<NameValuePair> data = new ArrayList<>();\n+        data.add(new BasicNameValuePair(\"query\", queryString));\n+        data.add(new BasicNameValuePair(\"start\", String.valueOf(startTimeMs / MILLIS_IN_SECOND)));\n+        data.add(new BasicNameValuePair(\"end\", String.valueOf(endTimeMs / MILLIS_IN_SECOND)));\n+        data.add(new BasicNameValuePair(\"step\", String.valueOf(_samplingIntervalMs / MILLIS_IN_SECOND)));\n+\n+        httpPost.setEntity(new UrlEncodedFormEntity(data));\n+        try (CloseableHttpResponse response = _httpClient.execute(httpPost)) {\n+            int responseCode = response.getStatusLine().getStatusCode();\n+            HttpEntity entity = response.getEntity();\n+            InputStream content = entity.getContent();\n+            String responseString = IOUtils.toString(content, StandardCharsets.UTF_8);\n+            if (responseCode != 200) {\n+                throw new IOException(String.format(\"Received non-success response code on Prometheus API HTTP call,\"\n+                                                    + \" response code = %s, response body = %s\",\n+                                                    responseCode, responseString));\n+            }\n+            PrometheusResponse prometheusResponse = GSON.fromJson(responseString, PrometheusResponse.class);\n+            if (prometheusResponse == null) {\n+                throw new IOException(String.format(\n+                    \"No response received from Prometheus API query, response body = %s\", responseString));\n+            }\n+\n+            if (!\"success\".equals(prometheusResponse.status())) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0d031702bbe2e35b02d89a82b9cf511be7a6cc65"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIyMjU2MQ==", "bodyText": "Nit: Can we use com.linkedin.kafka.cruisecontrol.KafkaCruiseControlUtils.SEC_TO_MS rather than introducing a new variable?", "url": "https://github.com/linkedin/cruise-control/pull/1366#discussion_r516222561", "createdAt": "2020-11-02T20:02:03Z", "author": {"login": "efeg"}, "path": "cruise-control/src/main/java/com/linkedin/kafka/cruisecontrol/monitor/sampling/prometheus/PrometheusMetricSampler.java", "diffHunk": "@@ -0,0 +1,269 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\"). See License in the project root for license information.\n+ */\n+\n+package com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.http.HttpHost;\n+import org.apache.http.impl.client.CloseableHttpClient;\n+import org.apache.http.impl.client.HttpClients;\n+import org.apache.kafka.common.Cluster;\n+import org.apache.kafka.common.Node;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.linkedin.cruisecontrol.common.config.ConfigDef;\n+import com.linkedin.cruisecontrol.common.config.ConfigException;\n+import com.linkedin.kafka.cruisecontrol.config.KafkaCruiseControlConfigUtils;\n+import com.linkedin.kafka.cruisecontrol.exception.SamplingException;\n+import com.linkedin.kafka.cruisecontrol.metricsreporter.metric.BrokerMetric;\n+import com.linkedin.kafka.cruisecontrol.metricsreporter.metric.PartitionMetric;\n+import com.linkedin.kafka.cruisecontrol.metricsreporter.metric.RawMetricType;\n+import com.linkedin.kafka.cruisecontrol.metricsreporter.metric.TopicMetric;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.AbstractMetricSampler;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricSamplerOptions;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusQueryResult;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusValue;\n+\n+import static com.linkedin.cruisecontrol.common.config.ConfigDef.Type.CLASS;\n+\n+/**\n+ * Metric sampler that fetches Kafka metrics from a Prometheus server and converts them to samples.\n+ */\n+public class PrometheusMetricSampler extends AbstractMetricSampler {\n+    // Config name visible to tests\n+    static final String PROMETHEUS_SERVER_ENDPOINT_CONFIG = \"prometheus.server.endpoint\";\n+\n+    // Config name visible to tests\n+    static final String PROMETHEUS_QUERY_RESOLUTION_STEP_MS_CONFIG = \"prometheus.query.resolution.step.ms\";\n+    private static final Integer DEFAULT_PROMETHEUS_METRICS_SAMPLING_INTERVAL_MS = 60_000;\n+    private static final int MILLIS_IN_SECOND = 1000;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0d031702bbe2e35b02d89a82b9cf511be7a6cc65"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIyMzgxOA==", "bodyText": "Can we update the JavaDoc to indicate the configs that this class takes -- e.g. similar to the JavaDoc of the pluggable com.linkedin.kafka.cruisecontrol.detector.MaintenanceEventTopicReader?", "url": "https://github.com/linkedin/cruise-control/pull/1366#discussion_r516223818", "createdAt": "2020-11-02T20:04:39Z", "author": {"login": "efeg"}, "path": "cruise-control/src/main/java/com/linkedin/kafka/cruisecontrol/monitor/sampling/prometheus/PrometheusMetricSampler.java", "diffHunk": "@@ -0,0 +1,269 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\"). See License in the project root for license information.\n+ */\n+\n+package com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.http.HttpHost;\n+import org.apache.http.impl.client.CloseableHttpClient;\n+import org.apache.http.impl.client.HttpClients;\n+import org.apache.kafka.common.Cluster;\n+import org.apache.kafka.common.Node;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.linkedin.cruisecontrol.common.config.ConfigDef;\n+import com.linkedin.cruisecontrol.common.config.ConfigException;\n+import com.linkedin.kafka.cruisecontrol.config.KafkaCruiseControlConfigUtils;\n+import com.linkedin.kafka.cruisecontrol.exception.SamplingException;\n+import com.linkedin.kafka.cruisecontrol.metricsreporter.metric.BrokerMetric;\n+import com.linkedin.kafka.cruisecontrol.metricsreporter.metric.PartitionMetric;\n+import com.linkedin.kafka.cruisecontrol.metricsreporter.metric.RawMetricType;\n+import com.linkedin.kafka.cruisecontrol.metricsreporter.metric.TopicMetric;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.AbstractMetricSampler;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricSamplerOptions;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusQueryResult;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusValue;\n+\n+import static com.linkedin.cruisecontrol.common.config.ConfigDef.Type.CLASS;\n+\n+/**\n+ * Metric sampler that fetches Kafka metrics from a Prometheus server and converts them to samples.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0d031702bbe2e35b02d89a82b9cf511be7a6cc65"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIyNTAyMQ==", "bodyText": "Nit: Can we use com.linkedin.kafka.cruisecontrol.KafkaCruiseControlUtils.SEC_TO_MS rather than introducing a new variable?", "url": "https://github.com/linkedin/cruise-control/pull/1366#discussion_r516225021", "createdAt": "2020-11-02T20:06:59Z", "author": {"login": "efeg"}, "path": "cruise-control/src/main/java/com/linkedin/kafka/cruisecontrol/monitor/sampling/prometheus/PrometheusAdapter.java", "diffHunk": "@@ -0,0 +1,92 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\"). See License in the project root for license information.\n+ */\n+\n+package com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.net.URI;\n+import java.nio.charset.StandardCharsets;\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.commons.io.IOUtils;\n+import org.apache.http.HttpEntity;\n+import org.apache.http.HttpHost;\n+import org.apache.http.NameValuePair;\n+import org.apache.http.client.entity.UrlEncodedFormEntity;\n+import org.apache.http.client.methods.CloseableHttpResponse;\n+import org.apache.http.client.methods.HttpPost;\n+import org.apache.http.impl.client.CloseableHttpClient;\n+import org.apache.http.message.BasicNameValuePair;\n+import org.apache.http.util.EntityUtils;\n+\n+import com.google.gson.Gson;\n+\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusQueryResult;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusResponse;\n+\n+/**\n+ * This class provides an adapter to make queries to a Prometheus Server to fetch metric values.\n+ */\n+class PrometheusAdapter {\n+    private static final int MILLIS_IN_SECOND = 1000;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0d031702bbe2e35b02d89a82b9cf511be7a6cc65"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIyNjc0MA==", "bodyText": "Can we make this an int rather than Integer?", "url": "https://github.com/linkedin/cruise-control/pull/1366#discussion_r516226740", "createdAt": "2020-11-02T20:10:28Z", "author": {"login": "efeg"}, "path": "cruise-control/src/main/java/com/linkedin/kafka/cruisecontrol/monitor/sampling/prometheus/PrometheusMetricSampler.java", "diffHunk": "@@ -0,0 +1,269 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\"). See License in the project root for license information.\n+ */\n+\n+package com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.http.HttpHost;\n+import org.apache.http.impl.client.CloseableHttpClient;\n+import org.apache.http.impl.client.HttpClients;\n+import org.apache.kafka.common.Cluster;\n+import org.apache.kafka.common.Node;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.linkedin.cruisecontrol.common.config.ConfigDef;\n+import com.linkedin.cruisecontrol.common.config.ConfigException;\n+import com.linkedin.kafka.cruisecontrol.config.KafkaCruiseControlConfigUtils;\n+import com.linkedin.kafka.cruisecontrol.exception.SamplingException;\n+import com.linkedin.kafka.cruisecontrol.metricsreporter.metric.BrokerMetric;\n+import com.linkedin.kafka.cruisecontrol.metricsreporter.metric.PartitionMetric;\n+import com.linkedin.kafka.cruisecontrol.metricsreporter.metric.RawMetricType;\n+import com.linkedin.kafka.cruisecontrol.metricsreporter.metric.TopicMetric;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.AbstractMetricSampler;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricSamplerOptions;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusQueryResult;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusValue;\n+\n+import static com.linkedin.cruisecontrol.common.config.ConfigDef.Type.CLASS;\n+\n+/**\n+ * Metric sampler that fetches Kafka metrics from a Prometheus server and converts them to samples.\n+ */\n+public class PrometheusMetricSampler extends AbstractMetricSampler {\n+    // Config name visible to tests\n+    static final String PROMETHEUS_SERVER_ENDPOINT_CONFIG = \"prometheus.server.endpoint\";\n+\n+    // Config name visible to tests\n+    static final String PROMETHEUS_QUERY_RESOLUTION_STEP_MS_CONFIG = \"prometheus.query.resolution.step.ms\";\n+    private static final Integer DEFAULT_PROMETHEUS_METRICS_SAMPLING_INTERVAL_MS = 60_000;\n+    private static final int MILLIS_IN_SECOND = 1000;\n+\n+    // Config name visible to tests\n+    static final String PROMETHEUS_QUERY_SUPPLIER_CONFIG = \"prometheus.query.supplier\";\n+    private static final Class<?> DEFAULT_PROMETHEUS_QUERY_SUPPLIER = DefaultPrometheusQuerySupplier.class;\n+\n+    private static final Logger LOG = LoggerFactory.getLogger(PrometheusMetricSampler.class);\n+\n+    protected Integer _samplingIntervalMs;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0d031702bbe2e35b02d89a82b9cf511be7a6cc65"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIyNzU2Ng==", "bodyText": "Is this try catch block that throws IllegalArgumentException and catches it to throw ConfigException needed? Can't we drop the try-catch block and move the following ConfigException to here?\n            throw new ConfigException(\n                String.format(\"Prometheus endpoint URI is malformed, \"\n                              + \"expected schema://host:port, provided %s\", endpoint));", "url": "https://github.com/linkedin/cruise-control/pull/1366#discussion_r516227566", "createdAt": "2020-11-02T20:12:18Z", "author": {"login": "efeg"}, "path": "cruise-control/src/main/java/com/linkedin/kafka/cruisecontrol/monitor/sampling/prometheus/PrometheusMetricSampler.java", "diffHunk": "@@ -0,0 +1,269 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\"). See License in the project root for license information.\n+ */\n+\n+package com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.http.HttpHost;\n+import org.apache.http.impl.client.CloseableHttpClient;\n+import org.apache.http.impl.client.HttpClients;\n+import org.apache.kafka.common.Cluster;\n+import org.apache.kafka.common.Node;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.linkedin.cruisecontrol.common.config.ConfigDef;\n+import com.linkedin.cruisecontrol.common.config.ConfigException;\n+import com.linkedin.kafka.cruisecontrol.config.KafkaCruiseControlConfigUtils;\n+import com.linkedin.kafka.cruisecontrol.exception.SamplingException;\n+import com.linkedin.kafka.cruisecontrol.metricsreporter.metric.BrokerMetric;\n+import com.linkedin.kafka.cruisecontrol.metricsreporter.metric.PartitionMetric;\n+import com.linkedin.kafka.cruisecontrol.metricsreporter.metric.RawMetricType;\n+import com.linkedin.kafka.cruisecontrol.metricsreporter.metric.TopicMetric;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.AbstractMetricSampler;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricSamplerOptions;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusQueryResult;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusValue;\n+\n+import static com.linkedin.cruisecontrol.common.config.ConfigDef.Type.CLASS;\n+\n+/**\n+ * Metric sampler that fetches Kafka metrics from a Prometheus server and converts them to samples.\n+ */\n+public class PrometheusMetricSampler extends AbstractMetricSampler {\n+    // Config name visible to tests\n+    static final String PROMETHEUS_SERVER_ENDPOINT_CONFIG = \"prometheus.server.endpoint\";\n+\n+    // Config name visible to tests\n+    static final String PROMETHEUS_QUERY_RESOLUTION_STEP_MS_CONFIG = \"prometheus.query.resolution.step.ms\";\n+    private static final Integer DEFAULT_PROMETHEUS_METRICS_SAMPLING_INTERVAL_MS = 60_000;\n+    private static final int MILLIS_IN_SECOND = 1000;\n+\n+    // Config name visible to tests\n+    static final String PROMETHEUS_QUERY_SUPPLIER_CONFIG = \"prometheus.query.supplier\";\n+    private static final Class<?> DEFAULT_PROMETHEUS_QUERY_SUPPLIER = DefaultPrometheusQuerySupplier.class;\n+\n+    private static final Logger LOG = LoggerFactory.getLogger(PrometheusMetricSampler.class);\n+\n+    protected Integer _samplingIntervalMs;\n+    protected Map<String, Integer> _hostToBrokerIdMap = new HashMap<>();\n+    protected PrometheusAdapter _prometheusAdapter;\n+    protected Map<RawMetricType, String> _metricToPrometheusQueryMap;\n+\n+    @Override\n+    public void configure(Map<String, ?> configs) {\n+        super.configure(configs);\n+        configureSamplingInterval(configs);\n+        configurePrometheusAdapter(configs);\n+        configureQueryMap(configs);\n+    }\n+\n+    private void configureSamplingInterval(Map<String, ?> configs) {\n+        _samplingIntervalMs = DEFAULT_PROMETHEUS_METRICS_SAMPLING_INTERVAL_MS;\n+        if (configs.containsKey(PROMETHEUS_QUERY_RESOLUTION_STEP_MS_CONFIG)) {\n+            String samplingIntervalMsString = (String) configs.get(PROMETHEUS_QUERY_RESOLUTION_STEP_MS_CONFIG);\n+            try {\n+                _samplingIntervalMs = Integer.parseInt(samplingIntervalMsString);\n+            } catch (NumberFormatException e) {\n+                throw new ConfigException(\"%s config should be a positive number, provided %s\",\n+                    samplingIntervalMsString);\n+            }\n+\n+            if (_samplingIntervalMs <= 0) {\n+                throw new ConfigException(String.format(\"%s config should be set to positive,\"\n+                                                        + \" provided %d.\",\n+                                                        PROMETHEUS_QUERY_RESOLUTION_STEP_MS_CONFIG,\n+                                                        _samplingIntervalMs));\n+            }\n+        }\n+    }\n+\n+    private void configurePrometheusAdapter(Map<String, ?> configs) {\n+        final String endpoint = (String) configs.get(PROMETHEUS_SERVER_ENDPOINT_CONFIG);\n+        if (endpoint == null) {\n+            throw new ConfigException(String.format(\n+                \"%s config is required by Prometheus metric sampler\", PROMETHEUS_SERVER_ENDPOINT_CONFIG));\n+        }\n+\n+        try {\n+            HttpHost host = HttpHost.create(endpoint);\n+            if (host.getPort() < 0) {\n+                throw new IllegalArgumentException();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0d031702bbe2e35b02d89a82b9cf511be7a6cc65"}, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIzMTgwNw==", "bodyText": "Should this method relinquish underlying resources? -- e.g.\n        _hostToBrokerIdMap.clear();\n        _metricToPrometheusQueryMap.clear();", "url": "https://github.com/linkedin/cruise-control/pull/1366#discussion_r516231807", "createdAt": "2020-11-02T20:20:51Z", "author": {"login": "efeg"}, "path": "cruise-control/src/main/java/com/linkedin/kafka/cruisecontrol/monitor/sampling/prometheus/PrometheusMetricSampler.java", "diffHunk": "@@ -0,0 +1,269 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\"). See License in the project root for license information.\n+ */\n+\n+package com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.http.HttpHost;\n+import org.apache.http.impl.client.CloseableHttpClient;\n+import org.apache.http.impl.client.HttpClients;\n+import org.apache.kafka.common.Cluster;\n+import org.apache.kafka.common.Node;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.linkedin.cruisecontrol.common.config.ConfigDef;\n+import com.linkedin.cruisecontrol.common.config.ConfigException;\n+import com.linkedin.kafka.cruisecontrol.config.KafkaCruiseControlConfigUtils;\n+import com.linkedin.kafka.cruisecontrol.exception.SamplingException;\n+import com.linkedin.kafka.cruisecontrol.metricsreporter.metric.BrokerMetric;\n+import com.linkedin.kafka.cruisecontrol.metricsreporter.metric.PartitionMetric;\n+import com.linkedin.kafka.cruisecontrol.metricsreporter.metric.RawMetricType;\n+import com.linkedin.kafka.cruisecontrol.metricsreporter.metric.TopicMetric;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.AbstractMetricSampler;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricSamplerOptions;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusQueryResult;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusValue;\n+\n+import static com.linkedin.cruisecontrol.common.config.ConfigDef.Type.CLASS;\n+\n+/**\n+ * Metric sampler that fetches Kafka metrics from a Prometheus server and converts them to samples.\n+ */\n+public class PrometheusMetricSampler extends AbstractMetricSampler {\n+    // Config name visible to tests\n+    static final String PROMETHEUS_SERVER_ENDPOINT_CONFIG = \"prometheus.server.endpoint\";\n+\n+    // Config name visible to tests\n+    static final String PROMETHEUS_QUERY_RESOLUTION_STEP_MS_CONFIG = \"prometheus.query.resolution.step.ms\";\n+    private static final Integer DEFAULT_PROMETHEUS_METRICS_SAMPLING_INTERVAL_MS = 60_000;\n+    private static final int MILLIS_IN_SECOND = 1000;\n+\n+    // Config name visible to tests\n+    static final String PROMETHEUS_QUERY_SUPPLIER_CONFIG = \"prometheus.query.supplier\";\n+    private static final Class<?> DEFAULT_PROMETHEUS_QUERY_SUPPLIER = DefaultPrometheusQuerySupplier.class;\n+\n+    private static final Logger LOG = LoggerFactory.getLogger(PrometheusMetricSampler.class);\n+\n+    protected Integer _samplingIntervalMs;\n+    protected Map<String, Integer> _hostToBrokerIdMap = new HashMap<>();\n+    protected PrometheusAdapter _prometheusAdapter;\n+    protected Map<RawMetricType, String> _metricToPrometheusQueryMap;\n+\n+    @Override\n+    public void configure(Map<String, ?> configs) {\n+        super.configure(configs);\n+        configureSamplingInterval(configs);\n+        configurePrometheusAdapter(configs);\n+        configureQueryMap(configs);\n+    }\n+\n+    private void configureSamplingInterval(Map<String, ?> configs) {\n+        _samplingIntervalMs = DEFAULT_PROMETHEUS_METRICS_SAMPLING_INTERVAL_MS;\n+        if (configs.containsKey(PROMETHEUS_QUERY_RESOLUTION_STEP_MS_CONFIG)) {\n+            String samplingIntervalMsString = (String) configs.get(PROMETHEUS_QUERY_RESOLUTION_STEP_MS_CONFIG);\n+            try {\n+                _samplingIntervalMs = Integer.parseInt(samplingIntervalMsString);\n+            } catch (NumberFormatException e) {\n+                throw new ConfigException(\"%s config should be a positive number, provided %s\",\n+                    samplingIntervalMsString);\n+            }\n+\n+            if (_samplingIntervalMs <= 0) {\n+                throw new ConfigException(String.format(\"%s config should be set to positive,\"\n+                                                        + \" provided %d.\",\n+                                                        PROMETHEUS_QUERY_RESOLUTION_STEP_MS_CONFIG,\n+                                                        _samplingIntervalMs));\n+            }\n+        }\n+    }\n+\n+    private void configurePrometheusAdapter(Map<String, ?> configs) {\n+        final String endpoint = (String) configs.get(PROMETHEUS_SERVER_ENDPOINT_CONFIG);\n+        if (endpoint == null) {\n+            throw new ConfigException(String.format(\n+                \"%s config is required by Prometheus metric sampler\", PROMETHEUS_SERVER_ENDPOINT_CONFIG));\n+        }\n+\n+        try {\n+            HttpHost host = HttpHost.create(endpoint);\n+            if (host.getPort() < 0) {\n+                throw new IllegalArgumentException();\n+            }\n+            CloseableHttpClient httpClient = HttpClients.createDefault();\n+            _prometheusAdapter = new PrometheusAdapter(httpClient, host, _samplingIntervalMs);\n+        } catch (IllegalArgumentException ex) {\n+            throw new ConfigException(\n+                String.format(\"Prometheus endpoint URI is malformed, \"\n+                              + \"expected schema://host:port, provided %s\", endpoint));\n+        }\n+    }\n+\n+    private void configureQueryMap(Map<String, ?> configs) {\n+        String prometheusQuerySupplierClassName = (String) configs.get(PROMETHEUS_QUERY_SUPPLIER_CONFIG);\n+        Class<?> prometheusQuerySupplierClass = DEFAULT_PROMETHEUS_QUERY_SUPPLIER;\n+        if (prometheusQuerySupplierClassName != null) {\n+            prometheusQuerySupplierClass = (Class<?>) ConfigDef.parseType(PROMETHEUS_QUERY_SUPPLIER_CONFIG,\n+                prometheusQuerySupplierClassName, CLASS);\n+            if (!PrometheusQuerySupplier.class.isAssignableFrom(prometheusQuerySupplierClass)) {\n+                throw new ConfigException(String.format(\n+                    \"Invalid %s is provided to prometheus metric sampler, provided %s\",\n+                    PROMETHEUS_QUERY_SUPPLIER_CONFIG, prometheusQuerySupplierClass));\n+            }\n+        }\n+        PrometheusQuerySupplier prometheusQuerySupplier = KafkaCruiseControlConfigUtils.getConfiguredInstance(\n+            prometheusQuerySupplierClass, PrometheusQuerySupplier.class, Collections.emptyMap());\n+        _metricToPrometheusQueryMap = prometheusQuerySupplier.get();\n+    }\n+\n+    @Override\n+    public void close() {\n+        // do nothing", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0d031702bbe2e35b02d89a82b9cf511be7a6cc65"}, "originalPosition": 126}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIzNDQ5OA==", "bodyText": "Nit: Would (maybe a batched -- i.e. not individual) trace-level logging help with debugging potential issues?", "url": "https://github.com/linkedin/cruise-control/pull/1366#discussion_r516234498", "createdAt": "2020-11-02T20:26:36Z", "author": {"login": "efeg"}, "path": "cruise-control/src/main/java/com/linkedin/kafka/cruisecontrol/monitor/sampling/prometheus/PrometheusMetricSampler.java", "diffHunk": "@@ -0,0 +1,269 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\"). See License in the project root for license information.\n+ */\n+\n+package com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.http.HttpHost;\n+import org.apache.http.impl.client.CloseableHttpClient;\n+import org.apache.http.impl.client.HttpClients;\n+import org.apache.kafka.common.Cluster;\n+import org.apache.kafka.common.Node;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.linkedin.cruisecontrol.common.config.ConfigDef;\n+import com.linkedin.cruisecontrol.common.config.ConfigException;\n+import com.linkedin.kafka.cruisecontrol.config.KafkaCruiseControlConfigUtils;\n+import com.linkedin.kafka.cruisecontrol.exception.SamplingException;\n+import com.linkedin.kafka.cruisecontrol.metricsreporter.metric.BrokerMetric;\n+import com.linkedin.kafka.cruisecontrol.metricsreporter.metric.PartitionMetric;\n+import com.linkedin.kafka.cruisecontrol.metricsreporter.metric.RawMetricType;\n+import com.linkedin.kafka.cruisecontrol.metricsreporter.metric.TopicMetric;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.AbstractMetricSampler;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricSamplerOptions;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusQueryResult;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusValue;\n+\n+import static com.linkedin.cruisecontrol.common.config.ConfigDef.Type.CLASS;\n+\n+/**\n+ * Metric sampler that fetches Kafka metrics from a Prometheus server and converts them to samples.\n+ */\n+public class PrometheusMetricSampler extends AbstractMetricSampler {\n+    // Config name visible to tests\n+    static final String PROMETHEUS_SERVER_ENDPOINT_CONFIG = \"prometheus.server.endpoint\";\n+\n+    // Config name visible to tests\n+    static final String PROMETHEUS_QUERY_RESOLUTION_STEP_MS_CONFIG = \"prometheus.query.resolution.step.ms\";\n+    private static final Integer DEFAULT_PROMETHEUS_METRICS_SAMPLING_INTERVAL_MS = 60_000;\n+    private static final int MILLIS_IN_SECOND = 1000;\n+\n+    // Config name visible to tests\n+    static final String PROMETHEUS_QUERY_SUPPLIER_CONFIG = \"prometheus.query.supplier\";\n+    private static final Class<?> DEFAULT_PROMETHEUS_QUERY_SUPPLIER = DefaultPrometheusQuerySupplier.class;\n+\n+    private static final Logger LOG = LoggerFactory.getLogger(PrometheusMetricSampler.class);\n+\n+    protected Integer _samplingIntervalMs;\n+    protected Map<String, Integer> _hostToBrokerIdMap = new HashMap<>();\n+    protected PrometheusAdapter _prometheusAdapter;\n+    protected Map<RawMetricType, String> _metricToPrometheusQueryMap;\n+\n+    @Override\n+    public void configure(Map<String, ?> configs) {\n+        super.configure(configs);\n+        configureSamplingInterval(configs);\n+        configurePrometheusAdapter(configs);\n+        configureQueryMap(configs);\n+    }\n+\n+    private void configureSamplingInterval(Map<String, ?> configs) {\n+        _samplingIntervalMs = DEFAULT_PROMETHEUS_METRICS_SAMPLING_INTERVAL_MS;\n+        if (configs.containsKey(PROMETHEUS_QUERY_RESOLUTION_STEP_MS_CONFIG)) {\n+            String samplingIntervalMsString = (String) configs.get(PROMETHEUS_QUERY_RESOLUTION_STEP_MS_CONFIG);\n+            try {\n+                _samplingIntervalMs = Integer.parseInt(samplingIntervalMsString);\n+            } catch (NumberFormatException e) {\n+                throw new ConfigException(\"%s config should be a positive number, provided %s\",\n+                    samplingIntervalMsString);\n+            }\n+\n+            if (_samplingIntervalMs <= 0) {\n+                throw new ConfigException(String.format(\"%s config should be set to positive,\"\n+                                                        + \" provided %d.\",\n+                                                        PROMETHEUS_QUERY_RESOLUTION_STEP_MS_CONFIG,\n+                                                        _samplingIntervalMs));\n+            }\n+        }\n+    }\n+\n+    private void configurePrometheusAdapter(Map<String, ?> configs) {\n+        final String endpoint = (String) configs.get(PROMETHEUS_SERVER_ENDPOINT_CONFIG);\n+        if (endpoint == null) {\n+            throw new ConfigException(String.format(\n+                \"%s config is required by Prometheus metric sampler\", PROMETHEUS_SERVER_ENDPOINT_CONFIG));\n+        }\n+\n+        try {\n+            HttpHost host = HttpHost.create(endpoint);\n+            if (host.getPort() < 0) {\n+                throw new IllegalArgumentException();\n+            }\n+            CloseableHttpClient httpClient = HttpClients.createDefault();\n+            _prometheusAdapter = new PrometheusAdapter(httpClient, host, _samplingIntervalMs);\n+        } catch (IllegalArgumentException ex) {\n+            throw new ConfigException(\n+                String.format(\"Prometheus endpoint URI is malformed, \"\n+                              + \"expected schema://host:port, provided %s\", endpoint));\n+        }\n+    }\n+\n+    private void configureQueryMap(Map<String, ?> configs) {\n+        String prometheusQuerySupplierClassName = (String) configs.get(PROMETHEUS_QUERY_SUPPLIER_CONFIG);\n+        Class<?> prometheusQuerySupplierClass = DEFAULT_PROMETHEUS_QUERY_SUPPLIER;\n+        if (prometheusQuerySupplierClassName != null) {\n+            prometheusQuerySupplierClass = (Class<?>) ConfigDef.parseType(PROMETHEUS_QUERY_SUPPLIER_CONFIG,\n+                prometheusQuerySupplierClassName, CLASS);\n+            if (!PrometheusQuerySupplier.class.isAssignableFrom(prometheusQuerySupplierClass)) {\n+                throw new ConfigException(String.format(\n+                    \"Invalid %s is provided to prometheus metric sampler, provided %s\",\n+                    PROMETHEUS_QUERY_SUPPLIER_CONFIG, prometheusQuerySupplierClass));\n+            }\n+        }\n+        PrometheusQuerySupplier prometheusQuerySupplier = KafkaCruiseControlConfigUtils.getConfiguredInstance(\n+            prometheusQuerySupplierClass, PrometheusQuerySupplier.class, Collections.emptyMap());\n+        _metricToPrometheusQueryMap = prometheusQuerySupplier.get();\n+    }\n+\n+    @Override\n+    public void close() {\n+        // do nothing\n+    }\n+\n+    private Integer getBrokerIdForHostName(String host, Cluster cluster) {\n+        Integer cachedId = _hostToBrokerIdMap.get(host);\n+        if (cachedId != null) {\n+            return cachedId;\n+        }\n+        mapNodesToClusterId(cluster);\n+        return _hostToBrokerIdMap.get(host);\n+    }\n+\n+    private void mapNodesToClusterId(Cluster cluster) {\n+        for (Node node : cluster.nodes()) {\n+            _hostToBrokerIdMap.put(node.host(), node.id());\n+        }\n+    }\n+\n+    @Override\n+    protected int retrieveMetricsForProcessing(MetricSamplerOptions metricSamplerOptions) throws SamplingException {\n+        int metricsAdded = 0;\n+        for (Map.Entry<RawMetricType, String> metricToQueryEntry : _metricToPrometheusQueryMap.entrySet()) {\n+            final RawMetricType metricType = metricToQueryEntry.getKey();\n+            final String prometheusQuery = metricToQueryEntry.getValue();\n+            final List<PrometheusQueryResult> prometheusQueryResults;\n+            try {\n+                prometheusQueryResults = _prometheusAdapter.queryMetric(prometheusQuery,\n+                                                                        metricSamplerOptions.startTimeMs(),\n+                                                                        metricSamplerOptions.endTimeMs());\n+            } catch (IOException e) {\n+                LOG.error(\"Error when attempting to query Prometheus metrics\", e);\n+                throw new SamplingException(\"Could not query metrics from Prometheus\");\n+            }\n+            for (PrometheusQueryResult result : prometheusQueryResults) {\n+                try {\n+                    switch (metricType.metricScope()) {\n+                        case BROKER:\n+                            metricsAdded += addBrokerMetrics(metricSamplerOptions.cluster(), metricType, result);\n+                            break;\n+                        case TOPIC:\n+                            metricsAdded += addTopicMetrics(metricSamplerOptions.cluster(), metricType, result);\n+                            break;\n+                        case PARTITION:\n+                            metricsAdded += addPartitionMetrics(metricSamplerOptions.cluster(), metricType, result);\n+                            break;\n+                        default:\n+                            // Not supported.\n+                            break;\n+                    }\n+                } catch (InvalidPrometheusResultException e) {\n+                    /* We can ignore invalid or malformed Prometheus results, for example one which has a hostname\n+                    that could not be matched to any broker, or one where the topic name is null. Such records\n+                    will not be converted to metrics. There are valid use cases where this may occur - for instance,\n+                    when a Prometheus server store metrics from multiple Kafka clusters, in which case the hostname\n+                    may not correspond to any of this cluster's broker hosts.\n+\n+                    This can be really frequent, and hence, it would not make sense to fill the log entries by\n+                    logging this repeatedly.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0d031702bbe2e35b02d89a82b9cf511be7a6cc65"}, "originalPosition": 183}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIzNzAwOQ==", "bodyText": "Does it help to also log brokers found in Kafka cluster metadata as part of this message?", "url": "https://github.com/linkedin/cruise-control/pull/1366#discussion_r516237009", "createdAt": "2020-11-02T20:31:38Z", "author": {"login": "efeg"}, "path": "cruise-control/src/main/java/com/linkedin/kafka/cruisecontrol/monitor/sampling/prometheus/PrometheusMetricSampler.java", "diffHunk": "@@ -0,0 +1,269 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\"). See License in the project root for license information.\n+ */\n+\n+package com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus;\n+\n+import java.io.IOException;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.http.HttpHost;\n+import org.apache.http.impl.client.CloseableHttpClient;\n+import org.apache.http.impl.client.HttpClients;\n+import org.apache.kafka.common.Cluster;\n+import org.apache.kafka.common.Node;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import com.linkedin.cruisecontrol.common.config.ConfigDef;\n+import com.linkedin.cruisecontrol.common.config.ConfigException;\n+import com.linkedin.kafka.cruisecontrol.config.KafkaCruiseControlConfigUtils;\n+import com.linkedin.kafka.cruisecontrol.exception.SamplingException;\n+import com.linkedin.kafka.cruisecontrol.metricsreporter.metric.BrokerMetric;\n+import com.linkedin.kafka.cruisecontrol.metricsreporter.metric.PartitionMetric;\n+import com.linkedin.kafka.cruisecontrol.metricsreporter.metric.RawMetricType;\n+import com.linkedin.kafka.cruisecontrol.metricsreporter.metric.TopicMetric;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.AbstractMetricSampler;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricSamplerOptions;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusQueryResult;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusValue;\n+\n+import static com.linkedin.cruisecontrol.common.config.ConfigDef.Type.CLASS;\n+\n+/**\n+ * Metric sampler that fetches Kafka metrics from a Prometheus server and converts them to samples.\n+ */\n+public class PrometheusMetricSampler extends AbstractMetricSampler {\n+    // Config name visible to tests\n+    static final String PROMETHEUS_SERVER_ENDPOINT_CONFIG = \"prometheus.server.endpoint\";\n+\n+    // Config name visible to tests\n+    static final String PROMETHEUS_QUERY_RESOLUTION_STEP_MS_CONFIG = \"prometheus.query.resolution.step.ms\";\n+    private static final Integer DEFAULT_PROMETHEUS_METRICS_SAMPLING_INTERVAL_MS = 60_000;\n+    private static final int MILLIS_IN_SECOND = 1000;\n+\n+    // Config name visible to tests\n+    static final String PROMETHEUS_QUERY_SUPPLIER_CONFIG = \"prometheus.query.supplier\";\n+    private static final Class<?> DEFAULT_PROMETHEUS_QUERY_SUPPLIER = DefaultPrometheusQuerySupplier.class;\n+\n+    private static final Logger LOG = LoggerFactory.getLogger(PrometheusMetricSampler.class);\n+\n+    protected Integer _samplingIntervalMs;\n+    protected Map<String, Integer> _hostToBrokerIdMap = new HashMap<>();\n+    protected PrometheusAdapter _prometheusAdapter;\n+    protected Map<RawMetricType, String> _metricToPrometheusQueryMap;\n+\n+    @Override\n+    public void configure(Map<String, ?> configs) {\n+        super.configure(configs);\n+        configureSamplingInterval(configs);\n+        configurePrometheusAdapter(configs);\n+        configureQueryMap(configs);\n+    }\n+\n+    private void configureSamplingInterval(Map<String, ?> configs) {\n+        _samplingIntervalMs = DEFAULT_PROMETHEUS_METRICS_SAMPLING_INTERVAL_MS;\n+        if (configs.containsKey(PROMETHEUS_QUERY_RESOLUTION_STEP_MS_CONFIG)) {\n+            String samplingIntervalMsString = (String) configs.get(PROMETHEUS_QUERY_RESOLUTION_STEP_MS_CONFIG);\n+            try {\n+                _samplingIntervalMs = Integer.parseInt(samplingIntervalMsString);\n+            } catch (NumberFormatException e) {\n+                throw new ConfigException(\"%s config should be a positive number, provided %s\",\n+                    samplingIntervalMsString);\n+            }\n+\n+            if (_samplingIntervalMs <= 0) {\n+                throw new ConfigException(String.format(\"%s config should be set to positive,\"\n+                                                        + \" provided %d.\",\n+                                                        PROMETHEUS_QUERY_RESOLUTION_STEP_MS_CONFIG,\n+                                                        _samplingIntervalMs));\n+            }\n+        }\n+    }\n+\n+    private void configurePrometheusAdapter(Map<String, ?> configs) {\n+        final String endpoint = (String) configs.get(PROMETHEUS_SERVER_ENDPOINT_CONFIG);\n+        if (endpoint == null) {\n+            throw new ConfigException(String.format(\n+                \"%s config is required by Prometheus metric sampler\", PROMETHEUS_SERVER_ENDPOINT_CONFIG));\n+        }\n+\n+        try {\n+            HttpHost host = HttpHost.create(endpoint);\n+            if (host.getPort() < 0) {\n+                throw new IllegalArgumentException();\n+            }\n+            CloseableHttpClient httpClient = HttpClients.createDefault();\n+            _prometheusAdapter = new PrometheusAdapter(httpClient, host, _samplingIntervalMs);\n+        } catch (IllegalArgumentException ex) {\n+            throw new ConfigException(\n+                String.format(\"Prometheus endpoint URI is malformed, \"\n+                              + \"expected schema://host:port, provided %s\", endpoint));\n+        }\n+    }\n+\n+    private void configureQueryMap(Map<String, ?> configs) {\n+        String prometheusQuerySupplierClassName = (String) configs.get(PROMETHEUS_QUERY_SUPPLIER_CONFIG);\n+        Class<?> prometheusQuerySupplierClass = DEFAULT_PROMETHEUS_QUERY_SUPPLIER;\n+        if (prometheusQuerySupplierClassName != null) {\n+            prometheusQuerySupplierClass = (Class<?>) ConfigDef.parseType(PROMETHEUS_QUERY_SUPPLIER_CONFIG,\n+                prometheusQuerySupplierClassName, CLASS);\n+            if (!PrometheusQuerySupplier.class.isAssignableFrom(prometheusQuerySupplierClass)) {\n+                throw new ConfigException(String.format(\n+                    \"Invalid %s is provided to prometheus metric sampler, provided %s\",\n+                    PROMETHEUS_QUERY_SUPPLIER_CONFIG, prometheusQuerySupplierClass));\n+            }\n+        }\n+        PrometheusQuerySupplier prometheusQuerySupplier = KafkaCruiseControlConfigUtils.getConfiguredInstance(\n+            prometheusQuerySupplierClass, PrometheusQuerySupplier.class, Collections.emptyMap());\n+        _metricToPrometheusQueryMap = prometheusQuerySupplier.get();\n+    }\n+\n+    @Override\n+    public void close() {\n+        // do nothing\n+    }\n+\n+    private Integer getBrokerIdForHostName(String host, Cluster cluster) {\n+        Integer cachedId = _hostToBrokerIdMap.get(host);\n+        if (cachedId != null) {\n+            return cachedId;\n+        }\n+        mapNodesToClusterId(cluster);\n+        return _hostToBrokerIdMap.get(host);\n+    }\n+\n+    private void mapNodesToClusterId(Cluster cluster) {\n+        for (Node node : cluster.nodes()) {\n+            _hostToBrokerIdMap.put(node.host(), node.id());\n+        }\n+    }\n+\n+    @Override\n+    protected int retrieveMetricsForProcessing(MetricSamplerOptions metricSamplerOptions) throws SamplingException {\n+        int metricsAdded = 0;\n+        for (Map.Entry<RawMetricType, String> metricToQueryEntry : _metricToPrometheusQueryMap.entrySet()) {\n+            final RawMetricType metricType = metricToQueryEntry.getKey();\n+            final String prometheusQuery = metricToQueryEntry.getValue();\n+            final List<PrometheusQueryResult> prometheusQueryResults;\n+            try {\n+                prometheusQueryResults = _prometheusAdapter.queryMetric(prometheusQuery,\n+                                                                        metricSamplerOptions.startTimeMs(),\n+                                                                        metricSamplerOptions.endTimeMs());\n+            } catch (IOException e) {\n+                LOG.error(\"Error when attempting to query Prometheus metrics\", e);\n+                throw new SamplingException(\"Could not query metrics from Prometheus\");\n+            }\n+            for (PrometheusQueryResult result : prometheusQueryResults) {\n+                try {\n+                    switch (metricType.metricScope()) {\n+                        case BROKER:\n+                            metricsAdded += addBrokerMetrics(metricSamplerOptions.cluster(), metricType, result);\n+                            break;\n+                        case TOPIC:\n+                            metricsAdded += addTopicMetrics(metricSamplerOptions.cluster(), metricType, result);\n+                            break;\n+                        case PARTITION:\n+                            metricsAdded += addPartitionMetrics(metricSamplerOptions.cluster(), metricType, result);\n+                            break;\n+                        default:\n+                            // Not supported.\n+                            break;\n+                    }\n+                } catch (InvalidPrometheusResultException e) {\n+                    /* We can ignore invalid or malformed Prometheus results, for example one which has a hostname\n+                    that could not be matched to any broker, or one where the topic name is null. Such records\n+                    will not be converted to metrics. There are valid use cases where this may occur - for instance,\n+                    when a Prometheus server store metrics from multiple Kafka clusters, in which case the hostname\n+                    may not correspond to any of this cluster's broker hosts.\n+\n+                    This can be really frequent, and hence, it would not make sense to fill the log entries by\n+                    logging this repeatedly.\n+                     */\n+                }\n+            }\n+        }\n+        return metricsAdded;\n+    }\n+\n+    private int addBrokerMetrics(Cluster cluster, RawMetricType metricType, PrometheusQueryResult queryResult)\n+        throws InvalidPrometheusResultException {\n+        int brokerId = getBrokerId(cluster, queryResult);\n+\n+        int metricsAdded = 0;\n+        for (PrometheusValue value : queryResult.values()) {\n+            addMetricForProcessing(new BrokerMetric(metricType, value.epochSeconds() * MILLIS_IN_SECOND,\n+                                   brokerId, value.value()));\n+            metricsAdded++;\n+        }\n+        return metricsAdded;\n+    }\n+\n+    private int addTopicMetrics(Cluster cluster, RawMetricType metricType, PrometheusQueryResult queryResult)\n+        throws InvalidPrometheusResultException {\n+        int brokerId = getBrokerId(cluster, queryResult);\n+        String topic = getTopic(queryResult);\n+\n+        int metricsAdded = 0;\n+        for (PrometheusValue value : queryResult.values()) {\n+            addMetricForProcessing(new TopicMetric(metricType, value.epochSeconds() * MILLIS_IN_SECOND,\n+                                   brokerId, topic, value.value()));\n+            metricsAdded++;\n+        }\n+        return metricsAdded;\n+    }\n+\n+    private int addPartitionMetrics(Cluster cluster, RawMetricType metricType, PrometheusQueryResult queryResult)\n+        throws InvalidPrometheusResultException {\n+        int brokerId = getBrokerId(cluster, queryResult);\n+        String topic = getTopic(queryResult);\n+        int partition = getPartition(queryResult);\n+\n+        int metricsAdded = 0;\n+        for (PrometheusValue value : queryResult.values()) {\n+            addMetricForProcessing(new PartitionMetric(metricType, value.epochSeconds() * MILLIS_IN_SECOND,\n+                                   brokerId, topic, partition, value.value()));\n+            metricsAdded++;\n+        }\n+        return metricsAdded;\n+    }\n+\n+    private int getBrokerId(Cluster cluster, PrometheusQueryResult queryResult) throws\n+        InvalidPrometheusResultException {\n+        String hostPort = queryResult.metric().instance();\n+        if (hostPort == null) {\n+            throw new InvalidPrometheusResultException(\"Instance returned as part of Prometheus API response is null.\");\n+        }\n+        Integer brokerId;\n+\n+        String hostName = hostPort.split(\":\")[0];\n+        brokerId = getBrokerIdForHostName(hostName, cluster);\n+        if (brokerId == null) {\n+            throw new InvalidPrometheusResultException(String.format(\n+                \"Unexpected host %s, does not map to any broker found from Kafka cluster metadata.\", hostName));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0d031702bbe2e35b02d89a82b9cf511be7a6cc65"}, "originalPosition": 245}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjIzODk2Ng==", "bodyText": "Based on the way the PrometheusMetric is parsed, the _instance seems to have an expected format -- i.e. <host>:<port>. Is it acceptable to have a null or ill-formed instance? If not, should we add a sanity check to ensure that the input is well-formatted -- then we can drop sanity checks on the reader of instance()?", "url": "https://github.com/linkedin/cruise-control/pull/1366#discussion_r516238966", "createdAt": "2020-11-02T20:35:33Z", "author": {"login": "efeg"}, "path": "cruise-control/src/main/java/com/linkedin/kafka/cruisecontrol/monitor/sampling/prometheus/model/PrometheusMetric.java", "diffHunk": "@@ -0,0 +1,92 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\"). See License in the project root for license information.\n+ */\n+\n+package com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model;\n+\n+import java.util.Objects;\n+import javax.annotation.Nullable;\n+\n+import com.google.gson.annotations.SerializedName;\n+\n+public class PrometheusMetric {\n+    @SerializedName(\"__name__\")\n+    final private String _domainName;\n+    @SerializedName(\"instance\")\n+    final private String _instance;\n+    @SerializedName(\"job\")\n+    final private String _job;\n+    @SerializedName(\"name\")\n+    final private String _name;\n+    @SerializedName(\"topic\")\n+    final @Nullable private String _topic;\n+    @SerializedName(\"partition\")\n+    final @Nullable private String _partition;\n+\n+    public PrometheusMetric(\n+        String domainName, String instance, String job, String name,\n+        @Nullable String topic, @Nullable String partition) {\n+        _domainName = domainName;\n+        _instance = instance;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0d031702bbe2e35b02d89a82b9cf511be7a6cc65"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjI0NDM3OA==", "bodyText": "This function is never used -- what is its purpose (can we add some JavaDoc to this class to clarify)?", "url": "https://github.com/linkedin/cruise-control/pull/1366#discussion_r516244378", "createdAt": "2020-11-02T20:46:42Z", "author": {"login": "efeg"}, "path": "cruise-control/src/main/java/com/linkedin/kafka/cruisecontrol/monitor/sampling/prometheus/model/PrometheusData.java", "diffHunk": "@@ -0,0 +1,48 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\"). See License in the project root for license information.\n+ */\n+\n+package com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model;\n+\n+import java.util.List;\n+import java.util.Objects;\n+\n+import com.google.gson.annotations.SerializedName;\n+\n+public class PrometheusData {\n+    @SerializedName(\"resultType\")\n+    final private String _resultType;\n+    @SerializedName(\"result\")\n+    final private List<PrometheusQueryResult> _result;\n+\n+    public PrometheusData(String resultType, List<PrometheusQueryResult> result) {\n+        _resultType = resultType;\n+        _result = result;\n+    }\n+\n+    public String resultType() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0d031702bbe2e35b02d89a82b9cf511be7a6cc65"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjI0NTA5Mg==", "bodyText": "Nit: (applies to similar uses in other classes in this PR): private final is the preferred style over final private (see source). Should we use the preferred style?", "url": "https://github.com/linkedin/cruise-control/pull/1366#discussion_r516245092", "createdAt": "2020-11-02T20:48:11Z", "author": {"login": "efeg"}, "path": "cruise-control/src/main/java/com/linkedin/kafka/cruisecontrol/monitor/sampling/prometheus/model/PrometheusData.java", "diffHunk": "@@ -0,0 +1,48 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\"). See License in the project root for license information.\n+ */\n+\n+package com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model;\n+\n+import java.util.List;\n+import java.util.Objects;\n+\n+import com.google.gson.annotations.SerializedName;\n+\n+public class PrometheusData {\n+    @SerializedName(\"resultType\")\n+    final private String _resultType;\n+    @SerializedName(\"result\")\n+    final private List<PrometheusQueryResult> _result;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0d031702bbe2e35b02d89a82b9cf511be7a6cc65"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjI0NjQ0Nw==", "bodyText": "Can we add JavaDoc to class to describe its fields?", "url": "https://github.com/linkedin/cruise-control/pull/1366#discussion_r516246447", "createdAt": "2020-11-02T20:50:56Z", "author": {"login": "efeg"}, "path": "cruise-control/src/main/java/com/linkedin/kafka/cruisecontrol/monitor/sampling/prometheus/model/PrometheusResponse.java", "diffHunk": "@@ -0,0 +1,45 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\"). See License in the project root for license information.\n+ */\n+\n+package com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model;\n+\n+import java.util.Objects;\n+\n+import com.google.gson.annotations.SerializedName;\n+\n+public class PrometheusResponse {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0d031702bbe2e35b02d89a82b9cf511be7a6cc65"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjI0NjUyNw==", "bodyText": "Can we add JavaDoc to class to describe its fields?", "url": "https://github.com/linkedin/cruise-control/pull/1366#discussion_r516246527", "createdAt": "2020-11-02T20:51:05Z", "author": {"login": "efeg"}, "path": "cruise-control/src/main/java/com/linkedin/kafka/cruisecontrol/monitor/sampling/prometheus/model/PrometheusQueryResult.java", "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\"). See License in the project root for license information.\n+ */\n+\n+package com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model;\n+\n+import java.util.List;\n+import java.util.Objects;\n+\n+import com.google.gson.annotations.SerializedName;\n+\n+public class PrometheusQueryResult {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0d031702bbe2e35b02d89a82b9cf511be7a6cc65"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjI0NjYxNQ==", "bodyText": "Can we add JavaDoc to class to describe its fields?", "url": "https://github.com/linkedin/cruise-control/pull/1366#discussion_r516246615", "createdAt": "2020-11-02T20:51:16Z", "author": {"login": "efeg"}, "path": "cruise-control/src/main/java/com/linkedin/kafka/cruisecontrol/monitor/sampling/prometheus/model/PrometheusMetric.java", "diffHunk": "@@ -0,0 +1,92 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\"). See License in the project root for license information.\n+ */\n+\n+package com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model;\n+\n+import java.util.Objects;\n+import javax.annotation.Nullable;\n+\n+import com.google.gson.annotations.SerializedName;\n+\n+public class PrometheusMetric {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0d031702bbe2e35b02d89a82b9cf511be7a6cc65"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjI0NjcwMQ==", "bodyText": "Can we add JavaDoc to class to describe its fields?", "url": "https://github.com/linkedin/cruise-control/pull/1366#discussion_r516246701", "createdAt": "2020-11-02T20:51:26Z", "author": {"login": "efeg"}, "path": "cruise-control/src/main/java/com/linkedin/kafka/cruisecontrol/monitor/sampling/prometheus/model/PrometheusValue.java", "diffHunk": "@@ -0,0 +1,55 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\"). See License in the project root for license information.\n+ */\n+\n+package com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model;\n+\n+import java.util.Objects;\n+\n+import com.google.gson.annotations.JsonAdapter;\n+import com.google.gson.annotations.SerializedName;\n+\n+@JsonAdapter(PrometheusValueDeserializer.class)\n+public class PrometheusValue {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0d031702bbe2e35b02d89a82b9cf511be7a6cc65"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjI0NjkwOQ==", "bodyText": "Nit: this. prefix is redundant.", "url": "https://github.com/linkedin/cruise-control/pull/1366#discussion_r516246909", "createdAt": "2020-11-02T20:51:55Z", "author": {"login": "efeg"}, "path": "cruise-control/src/main/java/com/linkedin/kafka/cruisecontrol/monitor/sampling/prometheus/model/PrometheusValue.java", "diffHunk": "@@ -0,0 +1,55 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\"). See License in the project root for license information.\n+ */\n+\n+package com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model;\n+\n+import java.util.Objects;\n+\n+import com.google.gson.annotations.JsonAdapter;\n+import com.google.gson.annotations.SerializedName;\n+\n+@JsonAdapter(PrometheusValueDeserializer.class)\n+public class PrometheusValue {\n+    @SerializedName(\"epochSeconds\")\n+    private final long _epochSeconds;\n+    @SerializedName(\"value\")\n+    private final double _value;\n+\n+    public PrometheusValue(final long epochSeconds, final double value) {\n+        this._epochSeconds = epochSeconds;\n+        this._value = value;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0d031702bbe2e35b02d89a82b9cf511be7a6cc65"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjI0ODA4OQ==", "bodyText": "Nit: the indentation seems broken -- i.e. no arguments in the first line.", "url": "https://github.com/linkedin/cruise-control/pull/1366#discussion_r516248089", "createdAt": "2020-11-02T20:54:18Z", "author": {"login": "efeg"}, "path": "cruise-control/src/main/java/com/linkedin/kafka/cruisecontrol/monitor/sampling/prometheus/model/PrometheusValueDeserializer.java", "diffHunk": "@@ -0,0 +1,29 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\"). See License in the project root for license information.\n+ */\n+\n+package com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model;\n+\n+import java.lang.reflect.Type;\n+\n+import com.google.gson.JsonArray;\n+import com.google.gson.JsonDeserializationContext;\n+import com.google.gson.JsonDeserializer;\n+import com.google.gson.JsonElement;\n+import com.google.gson.JsonParseException;\n+\n+class PrometheusValueDeserializer implements JsonDeserializer<PrometheusValue> {\n+    @Override\n+    public PrometheusValue deserialize(\n+        JsonElement json, Type typeOfT,\n+        JsonDeserializationContext context) throws JsonParseException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0d031702bbe2e35b02d89a82b9cf511be7a6cc65"}, "originalPosition": 19}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "59de0f8c1d2fae839d97c3aa1e4f045190ce26c2", "author": {"user": {"login": "wyuka", "name": "Tirtha Chatterjee"}}, "url": "https://github.com/linkedin/cruise-control/commit/59de0f8c1d2fae839d97c3aa1e4f045190ce26c2", "committedDate": "2020-11-03T09:16:49Z", "message": "Fixed JavaDoc, removed unused fields from JSON POJOs."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bb3f55625b55254c91e53bdd503f471ea836e492", "author": {"user": {"login": "wyuka", "name": "Tirtha Chatterjee"}}, "url": "https://github.com/linkedin/cruise-control/commit/bb3f55625b55254c91e53bdd503f471ea836e492", "committedDate": "2020-11-03T09:19:32Z", "message": "Removed unused constants in test."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ca1565a1b87ba59171e87895707144a5340c7970", "author": {"user": {"login": "wyuka", "name": "Tirtha Chatterjee"}}, "url": "https://github.com/linkedin/cruise-control/commit/ca1565a1b87ba59171e87895707144a5340c7970", "committedDate": "2020-11-03T20:46:50Z", "message": "Added logging about invalid entries."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "54c5f23a36698fbb683631a52abca73a4ec695ba", "author": {"user": {"login": "wyuka", "name": "Tirtha Chatterjee"}}, "url": "https://github.com/linkedin/cruise-control/commit/54c5f23a36698fbb683631a52abca73a4ec695ba", "committedDate": "2020-11-03T20:58:08Z", "message": "Removed confusing overloading of the term 'metric samples'."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIyODY2OTYx", "url": "https://github.com/linkedin/cruise-control/pull/1366#pullrequestreview-522866961", "createdAt": "2020-11-03T20:55:04Z", "commit": {"oid": "ca1565a1b87ba59171e87895707144a5340c7970"}, "state": "COMMENTED", "comments": {"totalCount": 13, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QyMDo1NTowNFrOHtAHCQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QyMTo0MDowOFrOHtBaeA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjk0OTc2OQ==", "bodyText": "Nit: Can we use the QUERY_RANGE_API_PATH and SUCCESS from PrometheusAdapter?", "url": "https://github.com/linkedin/cruise-control/pull/1366#discussion_r516949769", "createdAt": "2020-11-03T20:55:04Z", "author": {"login": "efeg"}, "path": "cruise-control/src/test/java/com/linkedin/kafka/cruisecontrol/monitor/sampling/prometheus/PrometheusAdapterTest.java", "diffHunk": "@@ -0,0 +1,234 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\"). See License in the project root for license information.\n+ */\n+\n+package com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.util.Arrays;\n+import java.util.List;\n+import org.apache.http.HttpEntity;\n+import org.apache.http.HttpHost;\n+import org.apache.http.HttpRequest;\n+import org.apache.http.HttpResponse;\n+import org.apache.http.entity.StringEntity;\n+import org.apache.http.localserver.LocalServerTestBase;\n+import org.apache.http.protocol.HttpContext;\n+import org.apache.http.protocol.HttpRequestHandler;\n+import org.junit.Test;\n+\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusMetric;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusQueryResult;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusValue;\n+\n+import static org.junit.Assert.assertEquals;\n+\n+public class PrometheusAdapterTest extends LocalServerTestBase {\n+    private static final long START_TIME_MS = 1603301400000L;\n+    private static final long END_TIME_MS = 1603301459000L;\n+\n+    @Test\n+    public void testSuccessfulResponseDeserialized() throws Exception {\n+        this.serverBootstrap.registerHandler(\"/api/v1/query_range\", new HttpRequestHandler() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca1565a1b87ba59171e87895707144a5340c7970"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjk0OTkwMA==", "bodyText": "Nit (applies to other similar uses in this class): Can we use SC_OK?", "url": "https://github.com/linkedin/cruise-control/pull/1366#discussion_r516949900", "createdAt": "2020-11-03T20:55:19Z", "author": {"login": "efeg"}, "path": "cruise-control/src/test/java/com/linkedin/kafka/cruisecontrol/monitor/sampling/prometheus/PrometheusAdapterTest.java", "diffHunk": "@@ -0,0 +1,234 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\"). See License in the project root for license information.\n+ */\n+\n+package com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.util.Arrays;\n+import java.util.List;\n+import org.apache.http.HttpEntity;\n+import org.apache.http.HttpHost;\n+import org.apache.http.HttpRequest;\n+import org.apache.http.HttpResponse;\n+import org.apache.http.entity.StringEntity;\n+import org.apache.http.localserver.LocalServerTestBase;\n+import org.apache.http.protocol.HttpContext;\n+import org.apache.http.protocol.HttpRequestHandler;\n+import org.junit.Test;\n+\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusMetric;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusQueryResult;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusValue;\n+\n+import static org.junit.Assert.assertEquals;\n+\n+public class PrometheusAdapterTest extends LocalServerTestBase {\n+    private static final long START_TIME_MS = 1603301400000L;\n+    private static final long END_TIME_MS = 1603301459000L;\n+\n+    @Test\n+    public void testSuccessfulResponseDeserialized() throws Exception {\n+        this.serverBootstrap.registerHandler(\"/api/v1/query_range\", new HttpRequestHandler() {\n+            @Override public void handle(HttpRequest request, HttpResponse response, HttpContext context) {\n+                response.setStatusCode(200);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca1565a1b87ba59171e87895707144a5340c7970"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjk1MTAwOQ==", "bodyText": "Nit: Can we move the hardcoded query, start, end, step to static variables?", "url": "https://github.com/linkedin/cruise-control/pull/1366#discussion_r516951009", "createdAt": "2020-11-03T20:57:32Z", "author": {"login": "efeg"}, "path": "cruise-control/src/main/java/com/linkedin/kafka/cruisecontrol/monitor/sampling/prometheus/PrometheusAdapter.java", "diffHunk": "@@ -0,0 +1,104 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\"). See License in the project root for license information.\n+ */\n+\n+package com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.net.URI;\n+import java.nio.charset.StandardCharsets;\n+import java.util.ArrayList;\n+import java.util.List;\n+import javax.servlet.http.HttpServletResponse;\n+import org.apache.commons.io.IOUtils;\n+import org.apache.http.HttpEntity;\n+import org.apache.http.HttpHost;\n+import org.apache.http.NameValuePair;\n+import org.apache.http.client.entity.UrlEncodedFormEntity;\n+import org.apache.http.client.methods.CloseableHttpResponse;\n+import org.apache.http.client.methods.HttpPost;\n+import org.apache.http.impl.client.CloseableHttpClient;\n+import org.apache.http.message.BasicNameValuePair;\n+import org.apache.http.util.EntityUtils;\n+\n+import com.google.gson.Gson;\n+\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusQueryResult;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusResponse;\n+\n+import static com.linkedin.kafka.cruisecontrol.KafkaCruiseControlUtils.SEC_TO_MS;\n+\n+/**\n+ * This class provides an adapter to make queries to a Prometheus Server to fetch metric values.\n+ */\n+class PrometheusAdapter {\n+    private static final Gson GSON = new Gson();\n+    private static final String QUERY_RANGE_API_PATH = \"/api/v1/query_range\";\n+    private static final String SUCCESS = \"success\";\n+\n+    private final CloseableHttpClient _httpClient;\n+    /* Visible for testing */\n+    final HttpHost _prometheusEndpoint;\n+    /* Visible for testing */\n+    final int _samplingIntervalMs;\n+\n+    public PrometheusAdapter(CloseableHttpClient httpClient,\n+                             HttpHost prometheusEndpoint,\n+                             int samplingIntervalMs) {\n+        if (httpClient == null || prometheusEndpoint == null) {\n+            throw new IllegalArgumentException(\"httpClient or prometheusEndpoint cannot be null.\");\n+        }\n+        _httpClient = httpClient;\n+        _prometheusEndpoint = prometheusEndpoint;\n+        _samplingIntervalMs = samplingIntervalMs;\n+    }\n+\n+    public List<PrometheusQueryResult> queryMetric(String queryString,\n+                                                   long startTimeMs,\n+                                                   long endTimeMs) throws IOException {\n+        URI queryUri = URI.create(_prometheusEndpoint.toURI() + QUERY_RANGE_API_PATH);\n+        HttpPost httpPost = new HttpPost(queryUri);\n+\n+        List<NameValuePair> data = new ArrayList<>();\n+        data.add(new BasicNameValuePair(\"query\", queryString));\n+        /* \"start\" and \"end\" are expected to be unix timestamp in seconds (number of seconds since the Unix epoch).\n+         They accept values with a decimal point (up to 64 bits). The samples returned are inclusive of the \"end\"\n+         timestamp provided.\n+         */\n+        data.add(new BasicNameValuePair(\"start\", String.valueOf((double) startTimeMs / SEC_TO_MS)));\n+        data.add(new BasicNameValuePair(\"end\", String.valueOf((double) endTimeMs / SEC_TO_MS)));\n+        // step is expected to be in seconds, and accept values with a decimal point (up to 64 bits).\n+        data.add(new BasicNameValuePair(\"step\", String.valueOf((double) _samplingIntervalMs / SEC_TO_MS)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca1565a1b87ba59171e87895707144a5340c7970"}, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjk1Mzg5MQ==", "bodyText": "403 -> SC_FORBIDDEN?", "url": "https://github.com/linkedin/cruise-control/pull/1366#discussion_r516953891", "createdAt": "2020-11-03T21:03:34Z", "author": {"login": "efeg"}, "path": "cruise-control/src/test/java/com/linkedin/kafka/cruisecontrol/monitor/sampling/prometheus/PrometheusAdapterTest.java", "diffHunk": "@@ -0,0 +1,234 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\"). See License in the project root for license information.\n+ */\n+\n+package com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.util.Arrays;\n+import java.util.List;\n+import org.apache.http.HttpEntity;\n+import org.apache.http.HttpHost;\n+import org.apache.http.HttpRequest;\n+import org.apache.http.HttpResponse;\n+import org.apache.http.entity.StringEntity;\n+import org.apache.http.localserver.LocalServerTestBase;\n+import org.apache.http.protocol.HttpContext;\n+import org.apache.http.protocol.HttpRequestHandler;\n+import org.junit.Test;\n+\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusMetric;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusQueryResult;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusValue;\n+\n+import static org.junit.Assert.assertEquals;\n+\n+public class PrometheusAdapterTest extends LocalServerTestBase {\n+    private static final long START_TIME_MS = 1603301400000L;\n+    private static final long END_TIME_MS = 1603301459000L;\n+\n+    @Test\n+    public void testSuccessfulResponseDeserialized() throws Exception {\n+        this.serverBootstrap.registerHandler(\"/api/v1/query_range\", new HttpRequestHandler() {\n+            @Override public void handle(HttpRequest request, HttpResponse response, HttpContext context) {\n+                response.setStatusCode(200);\n+                response.setEntity(buildSuccessResponseEntity());\n+            }\n+        });\n+\n+        HttpHost httpHost = this.start();\n+        PrometheusAdapter prometheusAdapter\n+            = new PrometheusAdapter(this.httpclient, httpHost, 30000);\n+        final List<PrometheusQueryResult> prometheusQueryResults = prometheusAdapter.queryMetric(\n+            \"kafka_server_BrokerTopicMetrics_OneMinuteRate{name=\\\"BytesOutPerSec\\\",topic=\\\"\\\"}\",\n+            START_TIME_MS, END_TIME_MS);\n+\n+        assertEquals(expectedResults().toString(), prometheusQueryResults.toString());\n+        assertEquals(expectedResults(), prometheusQueryResults);\n+    }\n+\n+    private HttpEntity buildSuccessResponseEntity() {\n+        return new StringEntity(\"{\\n\"\n+            + \"    \\\"status\\\": \\\"success\\\",\\n\"\n+            + \"    \\\"data\\\": {\\n\"\n+            + \"        \\\"resultType\\\": \\\"matrix\\\",\\n\"\n+            + \"        \\\"result\\\": [\\n\"\n+            + \"            {\\n\"\n+            + \"                \\\"metric\\\": {\\n\"\n+            + \"                    \\\"__name__\\\": \\\"kafka_server_BrokerTopicMetrics_OneMinuteRate\\\",\\n\"\n+            + \"                    \\\"instance\\\": \\\"b-1.test-cluster.org:11001\\\",\\n\"\n+            + \"                    \\\"job\\\": \\\"jmx\\\",\\n\"\n+            + \"                    \\\"name\\\": \\\"BytesOutPerSec\\\"\\n\"\n+            + \"                },\\n\"\n+            + \"                \\\"values\\\": [\\n\"\n+            + \"                    [\\n\"\n+            + \"                        1603301400,\\n\"\n+            + \"                        \\\"1024\\\"\\n\"\n+            + \"                    ],\\n\"\n+            + \"                    [\\n\"\n+            + \"                        1603301430,\\n\"\n+            + \"                        \\\"2048\\\"\\n\"\n+            + \"                    ]\\n\"\n+            + \"                ]\\n\"\n+            + \"            },\\n\"\n+            + \"            {\\n\"\n+            + \"                \\\"metric\\\": {\\n\"\n+            + \"                    \\\"__name__\\\": \\\"kafka_server_BrokerTopicMetrics_OneMinuteRate\\\",\\n\"\n+            + \"                    \\\"instance\\\": \\\"b-2.test-cluster.org:11001\\\",\\n\"\n+            + \"                    \\\"job\\\": \\\"jmx\\\",\\n\"\n+            + \"                    \\\"name\\\": \\\"BytesOutPerSec\\\"\\n\"\n+            + \"                },\\n\"\n+            + \"                \\\"values\\\": [\\n\"\n+            + \"                    [\\n\"\n+            + \"                        1603301400,\\n\"\n+            + \"                        \\\"4096\\\"\\n\"\n+            + \"                    ],\\n\"\n+            + \"                    [\\n\"\n+            + \"                        1603301430,\\n\"\n+            + \"                        \\\"4096\\\"\\n\"\n+            + \"                    ]\\n\"\n+            + \"                ]\\n\"\n+            + \"            }\\n\"\n+            + \"        ]\\n\"\n+            + \"    }\\n\"\n+            + \"}\", StandardCharsets.UTF_8);\n+    }\n+\n+    private List<PrometheusQueryResult> expectedResults() {\n+        return Arrays.asList(\n+            new PrometheusQueryResult(\n+                new PrometheusMetric(\n+                    \"b-1.test-cluster.org:11001\",\n+                    null, null),\n+                Arrays.asList(\n+                    new PrometheusValue(1603301400L, 1024),\n+                    new PrometheusValue(1603301430L, 2048)\n+                )\n+            ),\n+            new PrometheusQueryResult(\n+                new PrometheusMetric(\n+                    \"b-2.test-cluster.org:11001\",\n+                    null, null),\n+                Arrays.asList(\n+                    new PrometheusValue(1603301400L, 4096),\n+                    new PrometheusValue(1603301430L, 4096)\n+                )\n+            )\n+        );\n+    }\n+\n+    @Test(expected = IOException.class)\n+    public void testFailureResponseWith200Code() throws Exception {\n+        this.serverBootstrap.registerHandler(\"/api/v1/query_range\", new HttpRequestHandler() {\n+            @Override public void handle(HttpRequest request, HttpResponse response, HttpContext context) {\n+                response.setStatusCode(200);\n+                response.setEntity(new StringEntity(\n+                    \"{\\\"status\\\": \\\"failure\\\", \\\"data\\\": {\\\"result\\\": []}}\", StandardCharsets.UTF_8));\n+            }\n+        });\n+\n+        HttpHost httpHost = this.start();\n+        PrometheusAdapter prometheusAdapter\n+            = new PrometheusAdapter(this.httpclient, httpHost, 30000);\n+\n+        prometheusAdapter.queryMetric(\n+            \"kafka_server_BrokerTopicMetrics_OneMinuteRate{name=\\\"BytesOutPerSec\\\",topic=\\\"\\\"}\",\n+            START_TIME_MS, END_TIME_MS);\n+    }\n+\n+    @Test(expected = IOException.class)\n+    public void testFailureResponseWith403Code() throws Exception {\n+        this.serverBootstrap.registerHandler(\"/api/v1/query_range\", new HttpRequestHandler() {\n+            @Override public void handle(HttpRequest request, HttpResponse response, HttpContext context) {\n+                response.setStatusCode(403);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca1565a1b87ba59171e87895707144a5340c7970"}, "originalPosition": 144}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjk1NDQ2MA==", "bodyText": "Nit: (applies to similar uses in this class) Can we move the hardcoded 30000 to a static variable?", "url": "https://github.com/linkedin/cruise-control/pull/1366#discussion_r516954460", "createdAt": "2020-11-03T21:04:45Z", "author": {"login": "efeg"}, "path": "cruise-control/src/test/java/com/linkedin/kafka/cruisecontrol/monitor/sampling/prometheus/PrometheusAdapterTest.java", "diffHunk": "@@ -0,0 +1,234 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\"). See License in the project root for license information.\n+ */\n+\n+package com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.util.Arrays;\n+import java.util.List;\n+import org.apache.http.HttpEntity;\n+import org.apache.http.HttpHost;\n+import org.apache.http.HttpRequest;\n+import org.apache.http.HttpResponse;\n+import org.apache.http.entity.StringEntity;\n+import org.apache.http.localserver.LocalServerTestBase;\n+import org.apache.http.protocol.HttpContext;\n+import org.apache.http.protocol.HttpRequestHandler;\n+import org.junit.Test;\n+\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusMetric;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusQueryResult;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusValue;\n+\n+import static org.junit.Assert.assertEquals;\n+\n+public class PrometheusAdapterTest extends LocalServerTestBase {\n+    private static final long START_TIME_MS = 1603301400000L;\n+    private static final long END_TIME_MS = 1603301459000L;\n+\n+    @Test\n+    public void testSuccessfulResponseDeserialized() throws Exception {\n+        this.serverBootstrap.registerHandler(\"/api/v1/query_range\", new HttpRequestHandler() {\n+            @Override public void handle(HttpRequest request, HttpResponse response, HttpContext context) {\n+                response.setStatusCode(200);\n+                response.setEntity(buildSuccessResponseEntity());\n+            }\n+        });\n+\n+        HttpHost httpHost = this.start();\n+        PrometheusAdapter prometheusAdapter\n+            = new PrometheusAdapter(this.httpclient, httpHost, 30000);\n+        final List<PrometheusQueryResult> prometheusQueryResults = prometheusAdapter.queryMetric(\n+            \"kafka_server_BrokerTopicMetrics_OneMinuteRate{name=\\\"BytesOutPerSec\\\",topic=\\\"\\\"}\",\n+            START_TIME_MS, END_TIME_MS);\n+\n+        assertEquals(expectedResults().toString(), prometheusQueryResults.toString());\n+        assertEquals(expectedResults(), prometheusQueryResults);\n+    }\n+\n+    private HttpEntity buildSuccessResponseEntity() {\n+        return new StringEntity(\"{\\n\"\n+            + \"    \\\"status\\\": \\\"success\\\",\\n\"\n+            + \"    \\\"data\\\": {\\n\"\n+            + \"        \\\"resultType\\\": \\\"matrix\\\",\\n\"\n+            + \"        \\\"result\\\": [\\n\"\n+            + \"            {\\n\"\n+            + \"                \\\"metric\\\": {\\n\"\n+            + \"                    \\\"__name__\\\": \\\"kafka_server_BrokerTopicMetrics_OneMinuteRate\\\",\\n\"\n+            + \"                    \\\"instance\\\": \\\"b-1.test-cluster.org:11001\\\",\\n\"\n+            + \"                    \\\"job\\\": \\\"jmx\\\",\\n\"\n+            + \"                    \\\"name\\\": \\\"BytesOutPerSec\\\"\\n\"\n+            + \"                },\\n\"\n+            + \"                \\\"values\\\": [\\n\"\n+            + \"                    [\\n\"\n+            + \"                        1603301400,\\n\"\n+            + \"                        \\\"1024\\\"\\n\"\n+            + \"                    ],\\n\"\n+            + \"                    [\\n\"\n+            + \"                        1603301430,\\n\"\n+            + \"                        \\\"2048\\\"\\n\"\n+            + \"                    ]\\n\"\n+            + \"                ]\\n\"\n+            + \"            },\\n\"\n+            + \"            {\\n\"\n+            + \"                \\\"metric\\\": {\\n\"\n+            + \"                    \\\"__name__\\\": \\\"kafka_server_BrokerTopicMetrics_OneMinuteRate\\\",\\n\"\n+            + \"                    \\\"instance\\\": \\\"b-2.test-cluster.org:11001\\\",\\n\"\n+            + \"                    \\\"job\\\": \\\"jmx\\\",\\n\"\n+            + \"                    \\\"name\\\": \\\"BytesOutPerSec\\\"\\n\"\n+            + \"                },\\n\"\n+            + \"                \\\"values\\\": [\\n\"\n+            + \"                    [\\n\"\n+            + \"                        1603301400,\\n\"\n+            + \"                        \\\"4096\\\"\\n\"\n+            + \"                    ],\\n\"\n+            + \"                    [\\n\"\n+            + \"                        1603301430,\\n\"\n+            + \"                        \\\"4096\\\"\\n\"\n+            + \"                    ]\\n\"\n+            + \"                ]\\n\"\n+            + \"            }\\n\"\n+            + \"        ]\\n\"\n+            + \"    }\\n\"\n+            + \"}\", StandardCharsets.UTF_8);\n+    }\n+\n+    private List<PrometheusQueryResult> expectedResults() {\n+        return Arrays.asList(\n+            new PrometheusQueryResult(\n+                new PrometheusMetric(\n+                    \"b-1.test-cluster.org:11001\",\n+                    null, null),\n+                Arrays.asList(\n+                    new PrometheusValue(1603301400L, 1024),\n+                    new PrometheusValue(1603301430L, 2048)\n+                )\n+            ),\n+            new PrometheusQueryResult(\n+                new PrometheusMetric(\n+                    \"b-2.test-cluster.org:11001\",\n+                    null, null),\n+                Arrays.asList(\n+                    new PrometheusValue(1603301400L, 4096),\n+                    new PrometheusValue(1603301430L, 4096)\n+                )\n+            )\n+        );\n+    }\n+\n+    @Test(expected = IOException.class)\n+    public void testFailureResponseWith200Code() throws Exception {\n+        this.serverBootstrap.registerHandler(\"/api/v1/query_range\", new HttpRequestHandler() {\n+            @Override public void handle(HttpRequest request, HttpResponse response, HttpContext context) {\n+                response.setStatusCode(200);\n+                response.setEntity(new StringEntity(\n+                    \"{\\\"status\\\": \\\"failure\\\", \\\"data\\\": {\\\"result\\\": []}}\", StandardCharsets.UTF_8));\n+            }\n+        });\n+\n+        HttpHost httpHost = this.start();\n+        PrometheusAdapter prometheusAdapter\n+            = new PrometheusAdapter(this.httpclient, httpHost, 30000);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca1565a1b87ba59171e87895707144a5340c7970"}, "originalPosition": 133}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjk1NDk4OQ==", "bodyText": "Should this builder be static?", "url": "https://github.com/linkedin/cruise-control/pull/1366#discussion_r516954989", "createdAt": "2020-11-03T21:05:38Z", "author": {"login": "efeg"}, "path": "cruise-control/src/test/java/com/linkedin/kafka/cruisecontrol/monitor/sampling/prometheus/PrometheusAdapterTest.java", "diffHunk": "@@ -0,0 +1,234 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\"). See License in the project root for license information.\n+ */\n+\n+package com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus;\n+\n+import java.io.IOException;\n+import java.nio.charset.StandardCharsets;\n+import java.util.Arrays;\n+import java.util.List;\n+import org.apache.http.HttpEntity;\n+import org.apache.http.HttpHost;\n+import org.apache.http.HttpRequest;\n+import org.apache.http.HttpResponse;\n+import org.apache.http.entity.StringEntity;\n+import org.apache.http.localserver.LocalServerTestBase;\n+import org.apache.http.protocol.HttpContext;\n+import org.apache.http.protocol.HttpRequestHandler;\n+import org.junit.Test;\n+\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusMetric;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusQueryResult;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusValue;\n+\n+import static org.junit.Assert.assertEquals;\n+\n+public class PrometheusAdapterTest extends LocalServerTestBase {\n+    private static final long START_TIME_MS = 1603301400000L;\n+    private static final long END_TIME_MS = 1603301459000L;\n+\n+    @Test\n+    public void testSuccessfulResponseDeserialized() throws Exception {\n+        this.serverBootstrap.registerHandler(\"/api/v1/query_range\", new HttpRequestHandler() {\n+            @Override public void handle(HttpRequest request, HttpResponse response, HttpContext context) {\n+                response.setStatusCode(200);\n+                response.setEntity(buildSuccessResponseEntity());\n+            }\n+        });\n+\n+        HttpHost httpHost = this.start();\n+        PrometheusAdapter prometheusAdapter\n+            = new PrometheusAdapter(this.httpclient, httpHost, 30000);\n+        final List<PrometheusQueryResult> prometheusQueryResults = prometheusAdapter.queryMetric(\n+            \"kafka_server_BrokerTopicMetrics_OneMinuteRate{name=\\\"BytesOutPerSec\\\",topic=\\\"\\\"}\",\n+            START_TIME_MS, END_TIME_MS);\n+\n+        assertEquals(expectedResults().toString(), prometheusQueryResults.toString());\n+        assertEquals(expectedResults(), prometheusQueryResults);\n+    }\n+\n+    private HttpEntity buildSuccessResponseEntity() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca1565a1b87ba59171e87895707144a5340c7970"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjk1OTU0Nw==", "bodyText": "Nit: Casting seems redundant.", "url": "https://github.com/linkedin/cruise-control/pull/1366#discussion_r516959547", "createdAt": "2020-11-03T21:15:07Z", "author": {"login": "efeg"}, "path": "cruise-control/src/test/java/com/linkedin/kafka/cruisecontrol/monitor/sampling/prometheus/PrometheusMetricSamplerTest.java", "diffHunk": "@@ -0,0 +1,491 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\"). See License in the project root for license information.\n+ */\n+\n+package com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus;\n+\n+import java.io.File;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.io.OutputStreamWriter;\n+import java.nio.charset.StandardCharsets;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.common.Cluster;\n+import org.apache.kafka.common.Node;\n+import org.apache.kafka.common.PartitionInfo;\n+import org.apache.kafka.common.TopicPartition;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import com.linkedin.cruisecontrol.common.config.ConfigException;\n+import com.linkedin.kafka.cruisecontrol.config.BrokerCapacityConfigFileResolver;\n+import com.linkedin.kafka.cruisecontrol.config.BrokerCapacityConfigResolver;\n+import com.linkedin.kafka.cruisecontrol.exception.SamplingException;\n+import com.linkedin.kafka.cruisecontrol.metricsreporter.metric.RawMetricType;\n+import com.linkedin.kafka.cruisecontrol.monitor.metricdefinition.KafkaMetricDef;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricSampler;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricSamplerOptions;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.holder.BrokerMetricSample;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.holder.PartitionEntity;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.holder.PartitionMetricSample;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusMetric;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusQueryResult;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusValue;\n+\n+import static com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.PrometheusMetricSampler.*;\n+import static org.easymock.EasyMock.*;\n+import static org.junit.Assert.*;\n+\n+/**\n+ * Unit test for {@link PrometheusMetricSampler} class.\n+ */\n+public class PrometheusMetricSamplerTest {\n+    private static final int MILLIS_IN_SECOND = 1000;\n+    private static final double DOUBLE_DELTA = 0.00000001;\n+    private static final double BYTES_IN_KB = 1024.0;\n+\n+    private static final int FIXED_VALUE = 94;\n+    private static final long START_EPOCH_SECONDS = 1603301400L;\n+    private static final long START_TIME_MS = START_EPOCH_SECONDS * MILLIS_IN_SECOND;\n+    private static final long END_TIME_MS = START_TIME_MS + 59 * MILLIS_IN_SECOND;\n+\n+    private static final int TOTAL_BROKERS = 3;\n+    private static final int TOTAL_PARTITIONS = 3;\n+\n+    private static final String TEST_TOPIC = \"test-topic\";\n+\n+    private PrometheusMetricSampler _prometheusMetricSampler;\n+    private PrometheusAdapter _prometheusAdapter;\n+    private Map<RawMetricType, String> _prometheusQueryMap;\n+\n+    /**\n+     * Set up mocks\n+     */\n+    @Before\n+    public void setUp() {\n+        _prometheusAdapter = mock(PrometheusAdapter.class);\n+        _prometheusMetricSampler = new PrometheusMetricSampler();\n+        _prometheusQueryMap = new DefaultPrometheusQuerySupplier().get();\n+    }\n+\n+    @Test(expected = ConfigException.class)\n+    public void testConfigureWithPrometheusEndpointNoPortFails() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"http://kafka-cluster-1.org\");\n+        addCapacityConfig(config);\n+        _prometheusMetricSampler.configure(config);\n+    }\n+\n+    @Test(expected = ConfigException.class)\n+    public void testConfigureWithPrometheusEndpointNegativePortFails() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"http://kafka-cluster-1.org:-20\");\n+        addCapacityConfig(config);\n+        _prometheusMetricSampler.configure(config);\n+    }\n+\n+    @Test\n+    public void testConfigureWithPrometheusEndpointNoSchemaDoesNotFail() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"kafka-cluster-1.org:9090\");\n+        addCapacityConfig(config);\n+        _prometheusMetricSampler.configure(config);\n+    }\n+\n+    @Test(expected = ConfigException.class)\n+    public void testConfigureWithNoPrometheusEndpointFails() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        addCapacityConfig(config);\n+        _prometheusMetricSampler.configure(config);\n+    }\n+\n+    @Test(expected = SamplingException.class)\n+    public void testGetSamplesQueryThrowsException() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"http://kafka-cluster-1.org:9090\");\n+        addCapacityConfig(config);\n+        _prometheusMetricSampler.configure(config);\n+\n+        MetricSamplerOptions metricSamplerOptions = buildMetricSamplerOptions();\n+        _prometheusMetricSampler._prometheusAdapter = _prometheusAdapter;\n+        expect(_prometheusAdapter.queryMetric(anyString(), anyLong(), anyLong()))\n+            .andThrow(new IOException(\"Exception in fetching metrics\"));\n+\n+        replay(_prometheusAdapter);\n+        _prometheusMetricSampler.getSamples(metricSamplerOptions);\n+    }\n+\n+    @Test\n+    public void testGetSamplesCustomPrometheusQuerySupplier() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"http://kafka-cluster-1.org:9090\");\n+        addCapacityConfig(config);\n+        config.put(PROMETHEUS_QUERY_SUPPLIER_CONFIG, TestQuerySupplier.class.getName());\n+        _prometheusMetricSampler.configure(config);\n+\n+        MetricSamplerOptions metricSamplerOptions = buildMetricSamplerOptions();\n+        _prometheusMetricSampler._prometheusAdapter = _prometheusAdapter;\n+\n+        expect(_prometheusAdapter.queryMetric(eq(TestQuerySupplier.TEST_QUERY), anyLong(), anyLong()))\n+            .andReturn(buildBrokerResults());\n+        replay(_prometheusAdapter);\n+\n+        _prometheusMetricSampler.getSamples(metricSamplerOptions);\n+\n+        verify(_prometheusAdapter);\n+    }\n+\n+    @Test(expected = ConfigException.class)\n+    public void testGetSamplesPrometheusQuerySupplierUnknownClass() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"http://kafka-cluster-1.org:9090\");\n+        addCapacityConfig(config);\n+        config.put(PROMETHEUS_QUERY_SUPPLIER_CONFIG, \"com.test.NonExistentClass\");\n+        _prometheusMetricSampler.configure(config);\n+    }\n+\n+    @Test(expected = ConfigException.class)\n+    public void testGetSamplesPrometheusQuerySupplierInvalidClass() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"http://kafka-cluster-1.org:9090\");\n+        addCapacityConfig(config);\n+        config.put(PROMETHEUS_QUERY_SUPPLIER_CONFIG, String.class.getName());\n+        _prometheusMetricSampler.configure(config);\n+    }\n+\n+    private MetricSamplerOptions buildMetricSamplerOptions() {\n+        return new MetricSamplerOptions(\n+            generateCluster(),\n+            generatePartitions(),\n+            START_TIME_MS,\n+            END_TIME_MS,\n+            MetricSampler.SamplingMode.ALL,\n+            KafkaMetricDef.commonMetricDef(),\n+            60000\n+        );\n+    }\n+\n+    @Test\n+    public void testGetSamplesSuccess() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"http://kafka-cluster-1.org:9090\");\n+        addCapacityConfig(config);\n+        _prometheusMetricSampler.configure(config);\n+\n+        MetricSamplerOptions metricSamplerOptions = buildMetricSamplerOptions();\n+        _prometheusMetricSampler._prometheusAdapter = _prometheusAdapter;\n+\n+        for (RawMetricType rawMetricType : _prometheusQueryMap.keySet()) {\n+            setupPrometheusAdapterMock(rawMetricType, buildBrokerResults(),\n+                buildTopicResults(), buildPartitionResults());\n+        }\n+\n+        replay(_prometheusAdapter);\n+        MetricSampler.Samples samples = _prometheusMetricSampler.getSamples(metricSamplerOptions);\n+\n+        assertSamplesValid(samples);\n+        verify(_prometheusAdapter);\n+    }\n+\n+    @Test\n+    public void testGetSamplesWithCustomSamplingInterval() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"http://kafka-cluster-1.org:9090\");\n+        config.put(PROMETHEUS_QUERY_RESOLUTION_STEP_MS_CONFIG, \"5000\");\n+        addCapacityConfig(config);\n+        _prometheusMetricSampler.configure(config);\n+        assertEquals(5000, (long) _prometheusMetricSampler._prometheusAdapter._samplingIntervalMs);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca1565a1b87ba59171e87895707144a5340c7970"}, "originalPosition": 205}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjk2NDMyOQ==", "bodyText": "Missing verify(_prometheusAdapter) for the replayed mock.", "url": "https://github.com/linkedin/cruise-control/pull/1366#discussion_r516964329", "createdAt": "2020-11-03T21:25:13Z", "author": {"login": "efeg"}, "path": "cruise-control/src/test/java/com/linkedin/kafka/cruisecontrol/monitor/sampling/prometheus/PrometheusMetricSamplerTest.java", "diffHunk": "@@ -0,0 +1,491 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\"). See License in the project root for license information.\n+ */\n+\n+package com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus;\n+\n+import java.io.File;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.io.OutputStreamWriter;\n+import java.nio.charset.StandardCharsets;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.common.Cluster;\n+import org.apache.kafka.common.Node;\n+import org.apache.kafka.common.PartitionInfo;\n+import org.apache.kafka.common.TopicPartition;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import com.linkedin.cruisecontrol.common.config.ConfigException;\n+import com.linkedin.kafka.cruisecontrol.config.BrokerCapacityConfigFileResolver;\n+import com.linkedin.kafka.cruisecontrol.config.BrokerCapacityConfigResolver;\n+import com.linkedin.kafka.cruisecontrol.exception.SamplingException;\n+import com.linkedin.kafka.cruisecontrol.metricsreporter.metric.RawMetricType;\n+import com.linkedin.kafka.cruisecontrol.monitor.metricdefinition.KafkaMetricDef;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricSampler;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricSamplerOptions;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.holder.BrokerMetricSample;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.holder.PartitionEntity;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.holder.PartitionMetricSample;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusMetric;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusQueryResult;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusValue;\n+\n+import static com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.PrometheusMetricSampler.*;\n+import static org.easymock.EasyMock.*;\n+import static org.junit.Assert.*;\n+\n+/**\n+ * Unit test for {@link PrometheusMetricSampler} class.\n+ */\n+public class PrometheusMetricSamplerTest {\n+    private static final int MILLIS_IN_SECOND = 1000;\n+    private static final double DOUBLE_DELTA = 0.00000001;\n+    private static final double BYTES_IN_KB = 1024.0;\n+\n+    private static final int FIXED_VALUE = 94;\n+    private static final long START_EPOCH_SECONDS = 1603301400L;\n+    private static final long START_TIME_MS = START_EPOCH_SECONDS * MILLIS_IN_SECOND;\n+    private static final long END_TIME_MS = START_TIME_MS + 59 * MILLIS_IN_SECOND;\n+\n+    private static final int TOTAL_BROKERS = 3;\n+    private static final int TOTAL_PARTITIONS = 3;\n+\n+    private static final String TEST_TOPIC = \"test-topic\";\n+\n+    private PrometheusMetricSampler _prometheusMetricSampler;\n+    private PrometheusAdapter _prometheusAdapter;\n+    private Map<RawMetricType, String> _prometheusQueryMap;\n+\n+    /**\n+     * Set up mocks\n+     */\n+    @Before\n+    public void setUp() {\n+        _prometheusAdapter = mock(PrometheusAdapter.class);\n+        _prometheusMetricSampler = new PrometheusMetricSampler();\n+        _prometheusQueryMap = new DefaultPrometheusQuerySupplier().get();\n+    }\n+\n+    @Test(expected = ConfigException.class)\n+    public void testConfigureWithPrometheusEndpointNoPortFails() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"http://kafka-cluster-1.org\");\n+        addCapacityConfig(config);\n+        _prometheusMetricSampler.configure(config);\n+    }\n+\n+    @Test(expected = ConfigException.class)\n+    public void testConfigureWithPrometheusEndpointNegativePortFails() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"http://kafka-cluster-1.org:-20\");\n+        addCapacityConfig(config);\n+        _prometheusMetricSampler.configure(config);\n+    }\n+\n+    @Test\n+    public void testConfigureWithPrometheusEndpointNoSchemaDoesNotFail() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"kafka-cluster-1.org:9090\");\n+        addCapacityConfig(config);\n+        _prometheusMetricSampler.configure(config);\n+    }\n+\n+    @Test(expected = ConfigException.class)\n+    public void testConfigureWithNoPrometheusEndpointFails() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        addCapacityConfig(config);\n+        _prometheusMetricSampler.configure(config);\n+    }\n+\n+    @Test(expected = SamplingException.class)\n+    public void testGetSamplesQueryThrowsException() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"http://kafka-cluster-1.org:9090\");\n+        addCapacityConfig(config);\n+        _prometheusMetricSampler.configure(config);\n+\n+        MetricSamplerOptions metricSamplerOptions = buildMetricSamplerOptions();\n+        _prometheusMetricSampler._prometheusAdapter = _prometheusAdapter;\n+        expect(_prometheusAdapter.queryMetric(anyString(), anyLong(), anyLong()))\n+            .andThrow(new IOException(\"Exception in fetching metrics\"));\n+\n+        replay(_prometheusAdapter);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca1565a1b87ba59171e87895707144a5340c7970"}, "originalPosition": 122}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjk2NTM2NA==", "bodyText": "Should these methods be static?", "url": "https://github.com/linkedin/cruise-control/pull/1366#discussion_r516965364", "createdAt": "2020-11-03T21:27:25Z", "author": {"login": "efeg"}, "path": "cruise-control/src/test/java/com/linkedin/kafka/cruisecontrol/monitor/sampling/prometheus/PrometheusMetricSamplerTest.java", "diffHunk": "@@ -0,0 +1,491 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\"). See License in the project root for license information.\n+ */\n+\n+package com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus;\n+\n+import java.io.File;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.io.OutputStreamWriter;\n+import java.nio.charset.StandardCharsets;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.common.Cluster;\n+import org.apache.kafka.common.Node;\n+import org.apache.kafka.common.PartitionInfo;\n+import org.apache.kafka.common.TopicPartition;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import com.linkedin.cruisecontrol.common.config.ConfigException;\n+import com.linkedin.kafka.cruisecontrol.config.BrokerCapacityConfigFileResolver;\n+import com.linkedin.kafka.cruisecontrol.config.BrokerCapacityConfigResolver;\n+import com.linkedin.kafka.cruisecontrol.exception.SamplingException;\n+import com.linkedin.kafka.cruisecontrol.metricsreporter.metric.RawMetricType;\n+import com.linkedin.kafka.cruisecontrol.monitor.metricdefinition.KafkaMetricDef;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricSampler;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricSamplerOptions;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.holder.BrokerMetricSample;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.holder.PartitionEntity;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.holder.PartitionMetricSample;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusMetric;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusQueryResult;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusValue;\n+\n+import static com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.PrometheusMetricSampler.*;\n+import static org.easymock.EasyMock.*;\n+import static org.junit.Assert.*;\n+\n+/**\n+ * Unit test for {@link PrometheusMetricSampler} class.\n+ */\n+public class PrometheusMetricSamplerTest {\n+    private static final int MILLIS_IN_SECOND = 1000;\n+    private static final double DOUBLE_DELTA = 0.00000001;\n+    private static final double BYTES_IN_KB = 1024.0;\n+\n+    private static final int FIXED_VALUE = 94;\n+    private static final long START_EPOCH_SECONDS = 1603301400L;\n+    private static final long START_TIME_MS = START_EPOCH_SECONDS * MILLIS_IN_SECOND;\n+    private static final long END_TIME_MS = START_TIME_MS + 59 * MILLIS_IN_SECOND;\n+\n+    private static final int TOTAL_BROKERS = 3;\n+    private static final int TOTAL_PARTITIONS = 3;\n+\n+    private static final String TEST_TOPIC = \"test-topic\";\n+\n+    private PrometheusMetricSampler _prometheusMetricSampler;\n+    private PrometheusAdapter _prometheusAdapter;\n+    private Map<RawMetricType, String> _prometheusQueryMap;\n+\n+    /**\n+     * Set up mocks\n+     */\n+    @Before\n+    public void setUp() {\n+        _prometheusAdapter = mock(PrometheusAdapter.class);\n+        _prometheusMetricSampler = new PrometheusMetricSampler();\n+        _prometheusQueryMap = new DefaultPrometheusQuerySupplier().get();\n+    }\n+\n+    @Test(expected = ConfigException.class)\n+    public void testConfigureWithPrometheusEndpointNoPortFails() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"http://kafka-cluster-1.org\");\n+        addCapacityConfig(config);\n+        _prometheusMetricSampler.configure(config);\n+    }\n+\n+    @Test(expected = ConfigException.class)\n+    public void testConfigureWithPrometheusEndpointNegativePortFails() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"http://kafka-cluster-1.org:-20\");\n+        addCapacityConfig(config);\n+        _prometheusMetricSampler.configure(config);\n+    }\n+\n+    @Test\n+    public void testConfigureWithPrometheusEndpointNoSchemaDoesNotFail() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"kafka-cluster-1.org:9090\");\n+        addCapacityConfig(config);\n+        _prometheusMetricSampler.configure(config);\n+    }\n+\n+    @Test(expected = ConfigException.class)\n+    public void testConfigureWithNoPrometheusEndpointFails() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        addCapacityConfig(config);\n+        _prometheusMetricSampler.configure(config);\n+    }\n+\n+    @Test(expected = SamplingException.class)\n+    public void testGetSamplesQueryThrowsException() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"http://kafka-cluster-1.org:9090\");\n+        addCapacityConfig(config);\n+        _prometheusMetricSampler.configure(config);\n+\n+        MetricSamplerOptions metricSamplerOptions = buildMetricSamplerOptions();\n+        _prometheusMetricSampler._prometheusAdapter = _prometheusAdapter;\n+        expect(_prometheusAdapter.queryMetric(anyString(), anyLong(), anyLong()))\n+            .andThrow(new IOException(\"Exception in fetching metrics\"));\n+\n+        replay(_prometheusAdapter);\n+        _prometheusMetricSampler.getSamples(metricSamplerOptions);\n+    }\n+\n+    @Test\n+    public void testGetSamplesCustomPrometheusQuerySupplier() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"http://kafka-cluster-1.org:9090\");\n+        addCapacityConfig(config);\n+        config.put(PROMETHEUS_QUERY_SUPPLIER_CONFIG, TestQuerySupplier.class.getName());\n+        _prometheusMetricSampler.configure(config);\n+\n+        MetricSamplerOptions metricSamplerOptions = buildMetricSamplerOptions();\n+        _prometheusMetricSampler._prometheusAdapter = _prometheusAdapter;\n+\n+        expect(_prometheusAdapter.queryMetric(eq(TestQuerySupplier.TEST_QUERY), anyLong(), anyLong()))\n+            .andReturn(buildBrokerResults());\n+        replay(_prometheusAdapter);\n+\n+        _prometheusMetricSampler.getSamples(metricSamplerOptions);\n+\n+        verify(_prometheusAdapter);\n+    }\n+\n+    @Test(expected = ConfigException.class)\n+    public void testGetSamplesPrometheusQuerySupplierUnknownClass() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"http://kafka-cluster-1.org:9090\");\n+        addCapacityConfig(config);\n+        config.put(PROMETHEUS_QUERY_SUPPLIER_CONFIG, \"com.test.NonExistentClass\");\n+        _prometheusMetricSampler.configure(config);\n+    }\n+\n+    @Test(expected = ConfigException.class)\n+    public void testGetSamplesPrometheusQuerySupplierInvalidClass() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"http://kafka-cluster-1.org:9090\");\n+        addCapacityConfig(config);\n+        config.put(PROMETHEUS_QUERY_SUPPLIER_CONFIG, String.class.getName());\n+        _prometheusMetricSampler.configure(config);\n+    }\n+\n+    private MetricSamplerOptions buildMetricSamplerOptions() {\n+        return new MetricSamplerOptions(\n+            generateCluster(),\n+            generatePartitions(),\n+            START_TIME_MS,\n+            END_TIME_MS,\n+            MetricSampler.SamplingMode.ALL,\n+            KafkaMetricDef.commonMetricDef(),\n+            60000\n+        );\n+    }\n+\n+    @Test\n+    public void testGetSamplesSuccess() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"http://kafka-cluster-1.org:9090\");\n+        addCapacityConfig(config);\n+        _prometheusMetricSampler.configure(config);\n+\n+        MetricSamplerOptions metricSamplerOptions = buildMetricSamplerOptions();\n+        _prometheusMetricSampler._prometheusAdapter = _prometheusAdapter;\n+\n+        for (RawMetricType rawMetricType : _prometheusQueryMap.keySet()) {\n+            setupPrometheusAdapterMock(rawMetricType, buildBrokerResults(),\n+                buildTopicResults(), buildPartitionResults());\n+        }\n+\n+        replay(_prometheusAdapter);\n+        MetricSampler.Samples samples = _prometheusMetricSampler.getSamples(metricSamplerOptions);\n+\n+        assertSamplesValid(samples);\n+        verify(_prometheusAdapter);\n+    }\n+\n+    @Test\n+    public void testGetSamplesWithCustomSamplingInterval() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"http://kafka-cluster-1.org:9090\");\n+        config.put(PROMETHEUS_QUERY_RESOLUTION_STEP_MS_CONFIG, \"5000\");\n+        addCapacityConfig(config);\n+        _prometheusMetricSampler.configure(config);\n+        assertEquals(5000, (long) _prometheusMetricSampler._prometheusAdapter._samplingIntervalMs);\n+    }\n+\n+    @Test(expected = ConfigException.class)\n+    public void testGetSamplesWithCustomMalformedSamplingInterval() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"http://kafka-cluster-1.org:9090\");\n+        config.put(PROMETHEUS_QUERY_RESOLUTION_STEP_MS_CONFIG, \"non-number\");\n+        addCapacityConfig(config);\n+        _prometheusMetricSampler.configure(config);\n+    }\n+\n+    @Test(expected = ConfigException.class)\n+    public void testGetSamplesWithCustomNegativeSamplingInterval() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"http://kafka-cluster-1.org:9090\");\n+        config.put(PROMETHEUS_QUERY_RESOLUTION_STEP_MS_CONFIG, \"-2000\");\n+        addCapacityConfig(config);\n+        _prometheusMetricSampler.configure(config);\n+    }\n+\n+    @Test\n+    public void testPrometheusQueryReturnsBadHostname() throws Exception {\n+        testPrometheusQueryReturnsInvalidResults(buildBrokerResultsWithBadHostname(),\n+                                             buildTopicResults(), buildPartitionResults());\n+    }\n+\n+    @Test\n+    public void testPrometheusQueryReturnsNullHostPort() throws Exception {\n+        testPrometheusQueryReturnsInvalidResults(buildBrokerResultsWithNullHostPort(),\n+            buildTopicResults(), buildPartitionResults());\n+    }\n+\n+    @Test\n+    public void testPrometheusQueryReturnsNullTopic() throws Exception {\n+        testPrometheusQueryReturnsInvalidResults(buildBrokerResults(),\n+            buildTopicResultsWithNullTopic(), buildPartitionResults());\n+    }\n+\n+    @Test\n+    public void testPrometheusQueryReturnsNullPartition() throws Exception {\n+        testPrometheusQueryReturnsInvalidResults(buildBrokerResults(),\n+            buildTopicResults(), buildPartitionResultsWithNullPartition());\n+    }\n+\n+    @Test\n+    public void testPrometheusQueryReturnsMalformedPartition() throws Exception {\n+        testPrometheusQueryReturnsInvalidResults(buildBrokerResults(),\n+            buildTopicResults(), buildPartitionResultsWithMalformedPartition());\n+    }\n+\n+    public void testPrometheusQueryReturnsInvalidResults(\n+        List<PrometheusQueryResult> brokerResults,\n+        List<PrometheusQueryResult> topicResults,\n+        List<PrometheusQueryResult> partitionResults) throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"http://kafka-cluster-1.org:9090\");\n+        addCapacityConfig(config);\n+        _prometheusMetricSampler.configure(config);\n+\n+        MetricSamplerOptions metricSamplerOptions = buildMetricSamplerOptions();\n+        _prometheusMetricSampler._prometheusAdapter = _prometheusAdapter;\n+        for (RawMetricType rawMetricType : _prometheusQueryMap.keySet()) {\n+            setupPrometheusAdapterMock(rawMetricType, brokerResults,\n+                topicResults, partitionResults);\n+        }\n+\n+        replay(_prometheusAdapter);\n+        _prometheusMetricSampler.getSamples(metricSamplerOptions);\n+    }\n+\n+    private void assertSamplesValid(MetricSampler.Samples samples) {\n+        assertEquals(TOTAL_BROKERS, samples.brokerMetricSamples().size());\n+        assertEquals(\n+            new HashSet<>(Arrays.asList(0, 1, 2)),\n+            samples.brokerMetricSamples().stream()\n+                .map(BrokerMetricSample::brokerId)\n+                .collect(Collectors.toSet()));\n+        samples.brokerMetricSamples().forEach(brokerMetricSample -> {\n+            assertEquals(FIXED_VALUE,\n+                         brokerMetricSample.metricValue(KafkaMetricDef.CPU_USAGE),\n+                DOUBLE_DELTA);\n+            assertEquals(FIXED_VALUE / BYTES_IN_KB,\n+                         brokerMetricSample.metricValue(KafkaMetricDef.LEADER_BYTES_OUT),\n+                DOUBLE_DELTA);\n+        });\n+\n+        assertEquals(TOTAL_BROKERS, samples.partitionMetricSamples().size());\n+        assertEquals(\n+            new HashSet<>(Arrays.asList(0, 1, 2)),\n+            samples.partitionMetricSamples().stream()\n+                .map(PartitionMetricSample::entity)\n+                .map(PartitionEntity::tp)\n+                .map(TopicPartition::partition)\n+                .collect(Collectors.toSet()));\n+\n+        samples.partitionMetricSamples().forEach(partitionMetricSample -> {\n+            assertEquals(TEST_TOPIC, partitionMetricSample.entity().tp().topic());\n+            assertEquals(FIXED_VALUE,\n+                         partitionMetricSample.metricValue(\n+                             KafkaMetricDef.commonMetricDefId(KafkaMetricDef.MESSAGE_IN_RATE)),\n+                DOUBLE_DELTA);\n+            assertEquals(FIXED_VALUE / BYTES_IN_KB,\n+                         partitionMetricSample.metricValue(\n+                         KafkaMetricDef.commonMetricDefId(KafkaMetricDef.LEADER_BYTES_IN)),\n+                DOUBLE_DELTA);\n+        });\n+    }\n+\n+    private void setupPrometheusAdapterMock(RawMetricType metricType,\n+                                            List<PrometheusQueryResult> brokerResults,\n+                                            List<PrometheusQueryResult> topicResults,\n+                                            List<PrometheusQueryResult> partitionResults) throws IOException {\n+        switch (metricType.metricScope()) {\n+            case BROKER:\n+                expect(_prometheusAdapter.queryMetric(eq(_prometheusQueryMap.get(metricType)), anyLong(), anyLong()))\n+                    .andReturn(brokerResults);\n+                break;\n+            case TOPIC:\n+                expect(_prometheusAdapter.queryMetric(eq(_prometheusQueryMap.get(metricType)), anyLong(), anyLong()))\n+                    .andReturn(topicResults);\n+                break;\n+            case PARTITION:\n+                expect(_prometheusAdapter.queryMetric(eq(_prometheusQueryMap.get(metricType)), anyLong(), anyLong()))\n+                    .andReturn(partitionResults);\n+                break;\n+            default:\n+                break;\n+        }\n+    }\n+\n+    private List<PrometheusQueryResult> buildBrokerResults() {\n+        List<PrometheusQueryResult> resultList = new ArrayList<>();\n+        for (int brokerId = 0; brokerId < TOTAL_BROKERS; brokerId++) {\n+            resultList.add(new PrometheusQueryResult(new PrometheusMetric(\n+                \"broker-\" + brokerId + \".test-cluster.org:11001\",\n+                null,\n+                null\n+            ), Arrays.asList(new PrometheusValue(START_EPOCH_SECONDS, FIXED_VALUE))));\n+        }\n+        return resultList;\n+    }\n+\n+    private List<PrometheusQueryResult> buildBrokerResultsWithBadHostname() {\n+        List<PrometheusQueryResult> resultList = new ArrayList<>();\n+        for (int brokerId = 0; brokerId < TOTAL_BROKERS; brokerId++) {\n+            resultList.add(new PrometheusQueryResult(new PrometheusMetric(\n+                \"broker-\" + brokerId + \".non-existent-cluster.org:11001\",\n+                null,\n+                null\n+            ), Arrays.asList(new PrometheusValue(START_EPOCH_SECONDS, FIXED_VALUE))));\n+        }\n+        return resultList;\n+    }\n+\n+    private List<PrometheusQueryResult> buildBrokerResultsWithNullHostPort() {\n+        List<PrometheusQueryResult> resultList = new ArrayList<>();\n+        for (int brokerId = 0; brokerId < TOTAL_BROKERS; brokerId++) {\n+            resultList.add(new PrometheusQueryResult(new PrometheusMetric(\n+                null,\n+                null,\n+                null\n+            ), Arrays.asList(new PrometheusValue(START_EPOCH_SECONDS, FIXED_VALUE))));\n+        }\n+        return resultList;\n+    }\n+\n+    private List<PrometheusQueryResult> buildTopicResults() {\n+        List<PrometheusQueryResult> resultList = new ArrayList<>();\n+        for (int brokerId = 0; brokerId < TOTAL_BROKERS; brokerId++) {\n+            resultList.add(new PrometheusQueryResult(new PrometheusMetric(\n+                \"broker-\" + brokerId + \".test-cluster.org:11001\",\n+                TEST_TOPIC,\n+                null\n+            ), Arrays.asList(new PrometheusValue(START_EPOCH_SECONDS, FIXED_VALUE))));\n+        }\n+        return resultList;\n+    }\n+\n+    private List<PrometheusQueryResult> buildTopicResultsWithNullTopic() {\n+        List<PrometheusQueryResult> resultList = new ArrayList<>();\n+        for (int brokerId = 0; brokerId < TOTAL_BROKERS; brokerId++) {\n+            resultList.add(new PrometheusQueryResult(new PrometheusMetric(\n+                \"broker-\" + brokerId + \".test-cluster.org:11001\",\n+                null,\n+                null\n+            ), Arrays.asList(new PrometheusValue(START_EPOCH_SECONDS, FIXED_VALUE))));\n+        }\n+        return resultList;\n+    }\n+\n+    private List<PrometheusQueryResult> buildPartitionResultsWithNullPartition() {\n+        List<PrometheusQueryResult> resultList = new ArrayList<>();\n+        for (int brokerId = 0; brokerId < TOTAL_BROKERS; brokerId++) {\n+            resultList.add(new PrometheusQueryResult(new PrometheusMetric(\n+                \"broker-\" + brokerId + \".test-cluster.org:11001\",\n+                TEST_TOPIC,\n+                null\n+            ), Arrays.asList(new PrometheusValue(START_EPOCH_SECONDS, FIXED_VALUE))));\n+        }\n+        return resultList;\n+    }\n+\n+    private List<PrometheusQueryResult> buildPartitionResultsWithMalformedPartition() {\n+        List<PrometheusQueryResult> resultList = new ArrayList<>();\n+        for (int brokerId = 0; brokerId < TOTAL_BROKERS; brokerId++) {\n+            resultList.add(new PrometheusQueryResult(new PrometheusMetric(\n+                \"broker-\" + brokerId + \".test-cluster.org:11001\",\n+                TEST_TOPIC,\n+                \"non-number\"\n+            ), Arrays.asList(new PrometheusValue(START_EPOCH_SECONDS, FIXED_VALUE))));\n+        }\n+        return resultList;\n+    }\n+\n+    private List<PrometheusQueryResult> buildPartitionResults() {\n+        List<PrometheusQueryResult> resultList = new ArrayList<>();\n+        for (int brokerId = 0; brokerId < TOTAL_BROKERS; brokerId++) {\n+            for (int partition = 0; partition < TOTAL_PARTITIONS; partition++) {\n+                resultList.add(new PrometheusQueryResult(new PrometheusMetric(\n+                    \"broker-\" + brokerId + \".test-cluster.org:11001\",\n+                    TEST_TOPIC,\n+                    String.valueOf(partition)\n+                ), Arrays.asList(new PrometheusValue(START_EPOCH_SECONDS, FIXED_VALUE))));\n+            }\n+        }\n+        return resultList;\n+    }\n+\n+    private void addCapacityConfig(Map<String, Object> config) throws IOException {\n+        File capacityConfigFile = File.createTempFile(\"capacityConfig\", \"json\");\n+        FileOutputStream fileOutputStream = new FileOutputStream(capacityConfigFile);\n+        try (OutputStreamWriter writer = new OutputStreamWriter(fileOutputStream, StandardCharsets.UTF_8)) {\n+            writer.write(\"{\\n\"\n+                + \"  \\\"brokerCapacities\\\":[\\n\"\n+                + \"    {\\n\"\n+                + \"      \\\"brokerId\\\": \\\"-1\\\",\\n\"\n+                + \"      \\\"capacity\\\": {\\n\"\n+                + \"        \\\"DISK\\\": \\\"100000\\\",\\n\"\n+                + \"        \\\"CPU\\\": {\\\"num.cores\\\": \\\"4\\\"},\\n\"\n+                + \"        \\\"NW_IN\\\": \\\"5000000\\\",\\n\"\n+                + \"        \\\"NW_OUT\\\": \\\"5000000\\\"\\n\"\n+                + \"      }\\n\"\n+                + \"    }\\n\"\n+                + \"  ]\\n\"\n+                + \"}\\n\");\n+        }\n+        config.put(\"capacity.config.file\", capacityConfigFile.getAbsolutePath());\n+        BrokerCapacityConfigResolver brokerCapacityConfigResolver = new BrokerCapacityConfigFileResolver();\n+        config.put(\"broker.capacity.config.resolver.object\", brokerCapacityConfigResolver);\n+        config.put(\"sampling.allow.cpu.capacity.estimation\", true);\n+        brokerCapacityConfigResolver.configure(config);\n+    }\n+\n+    private Set<TopicPartition> generatePartitions() {\n+        Set<TopicPartition> set = new HashSet<>();\n+        for (int partition = 0; partition < TOTAL_PARTITIONS; partition++) {\n+            TopicPartition topicPartition = new TopicPartition(TEST_TOPIC, partition);\n+            set.add(topicPartition);\n+        }\n+        return set;\n+    }\n+\n+    private Cluster generateCluster() {\n+        Node[] allNodes = new Node[TOTAL_BROKERS];\n+        Set<PartitionInfo> partitionInfo = new HashSet<>(TOTAL_BROKERS);\n+        for (int brokerId = 0; brokerId < TOTAL_BROKERS; brokerId++) {\n+            allNodes[brokerId] = new Node(brokerId, \"broker-\" + brokerId + \".test-cluster.org\", 9092);\n+        }\n+        for (int partitionId = 0; partitionId < TOTAL_PARTITIONS; partitionId++) {\n+            partitionInfo.add(new PartitionInfo(TEST_TOPIC, partitionId, allNodes[partitionId], allNodes, allNodes));\n+        }\n+        return new Cluster(\"cluster_id\", Arrays.asList(allNodes),\n+                           partitionInfo, Collections.emptySet(), Collections.emptySet());\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca1565a1b87ba59171e87895707144a5340c7970"}, "originalPosition": 479}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjk2NzYyMw==", "bodyText": "Nit: Applies to similar uses above: Should this be Collections.singletonList since it has a single element?", "url": "https://github.com/linkedin/cruise-control/pull/1366#discussion_r516967623", "createdAt": "2020-11-03T21:32:19Z", "author": {"login": "efeg"}, "path": "cruise-control/src/test/java/com/linkedin/kafka/cruisecontrol/monitor/sampling/prometheus/PrometheusMetricSamplerTest.java", "diffHunk": "@@ -0,0 +1,491 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\"). See License in the project root for license information.\n+ */\n+\n+package com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus;\n+\n+import java.io.File;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.io.OutputStreamWriter;\n+import java.nio.charset.StandardCharsets;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.common.Cluster;\n+import org.apache.kafka.common.Node;\n+import org.apache.kafka.common.PartitionInfo;\n+import org.apache.kafka.common.TopicPartition;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import com.linkedin.cruisecontrol.common.config.ConfigException;\n+import com.linkedin.kafka.cruisecontrol.config.BrokerCapacityConfigFileResolver;\n+import com.linkedin.kafka.cruisecontrol.config.BrokerCapacityConfigResolver;\n+import com.linkedin.kafka.cruisecontrol.exception.SamplingException;\n+import com.linkedin.kafka.cruisecontrol.metricsreporter.metric.RawMetricType;\n+import com.linkedin.kafka.cruisecontrol.monitor.metricdefinition.KafkaMetricDef;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricSampler;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricSamplerOptions;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.holder.BrokerMetricSample;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.holder.PartitionEntity;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.holder.PartitionMetricSample;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusMetric;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusQueryResult;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusValue;\n+\n+import static com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.PrometheusMetricSampler.*;\n+import static org.easymock.EasyMock.*;\n+import static org.junit.Assert.*;\n+\n+/**\n+ * Unit test for {@link PrometheusMetricSampler} class.\n+ */\n+public class PrometheusMetricSamplerTest {\n+    private static final int MILLIS_IN_SECOND = 1000;\n+    private static final double DOUBLE_DELTA = 0.00000001;\n+    private static final double BYTES_IN_KB = 1024.0;\n+\n+    private static final int FIXED_VALUE = 94;\n+    private static final long START_EPOCH_SECONDS = 1603301400L;\n+    private static final long START_TIME_MS = START_EPOCH_SECONDS * MILLIS_IN_SECOND;\n+    private static final long END_TIME_MS = START_TIME_MS + 59 * MILLIS_IN_SECOND;\n+\n+    private static final int TOTAL_BROKERS = 3;\n+    private static final int TOTAL_PARTITIONS = 3;\n+\n+    private static final String TEST_TOPIC = \"test-topic\";\n+\n+    private PrometheusMetricSampler _prometheusMetricSampler;\n+    private PrometheusAdapter _prometheusAdapter;\n+    private Map<RawMetricType, String> _prometheusQueryMap;\n+\n+    /**\n+     * Set up mocks\n+     */\n+    @Before\n+    public void setUp() {\n+        _prometheusAdapter = mock(PrometheusAdapter.class);\n+        _prometheusMetricSampler = new PrometheusMetricSampler();\n+        _prometheusQueryMap = new DefaultPrometheusQuerySupplier().get();\n+    }\n+\n+    @Test(expected = ConfigException.class)\n+    public void testConfigureWithPrometheusEndpointNoPortFails() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"http://kafka-cluster-1.org\");\n+        addCapacityConfig(config);\n+        _prometheusMetricSampler.configure(config);\n+    }\n+\n+    @Test(expected = ConfigException.class)\n+    public void testConfigureWithPrometheusEndpointNegativePortFails() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"http://kafka-cluster-1.org:-20\");\n+        addCapacityConfig(config);\n+        _prometheusMetricSampler.configure(config);\n+    }\n+\n+    @Test\n+    public void testConfigureWithPrometheusEndpointNoSchemaDoesNotFail() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"kafka-cluster-1.org:9090\");\n+        addCapacityConfig(config);\n+        _prometheusMetricSampler.configure(config);\n+    }\n+\n+    @Test(expected = ConfigException.class)\n+    public void testConfigureWithNoPrometheusEndpointFails() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        addCapacityConfig(config);\n+        _prometheusMetricSampler.configure(config);\n+    }\n+\n+    @Test(expected = SamplingException.class)\n+    public void testGetSamplesQueryThrowsException() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"http://kafka-cluster-1.org:9090\");\n+        addCapacityConfig(config);\n+        _prometheusMetricSampler.configure(config);\n+\n+        MetricSamplerOptions metricSamplerOptions = buildMetricSamplerOptions();\n+        _prometheusMetricSampler._prometheusAdapter = _prometheusAdapter;\n+        expect(_prometheusAdapter.queryMetric(anyString(), anyLong(), anyLong()))\n+            .andThrow(new IOException(\"Exception in fetching metrics\"));\n+\n+        replay(_prometheusAdapter);\n+        _prometheusMetricSampler.getSamples(metricSamplerOptions);\n+    }\n+\n+    @Test\n+    public void testGetSamplesCustomPrometheusQuerySupplier() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"http://kafka-cluster-1.org:9090\");\n+        addCapacityConfig(config);\n+        config.put(PROMETHEUS_QUERY_SUPPLIER_CONFIG, TestQuerySupplier.class.getName());\n+        _prometheusMetricSampler.configure(config);\n+\n+        MetricSamplerOptions metricSamplerOptions = buildMetricSamplerOptions();\n+        _prometheusMetricSampler._prometheusAdapter = _prometheusAdapter;\n+\n+        expect(_prometheusAdapter.queryMetric(eq(TestQuerySupplier.TEST_QUERY), anyLong(), anyLong()))\n+            .andReturn(buildBrokerResults());\n+        replay(_prometheusAdapter);\n+\n+        _prometheusMetricSampler.getSamples(metricSamplerOptions);\n+\n+        verify(_prometheusAdapter);\n+    }\n+\n+    @Test(expected = ConfigException.class)\n+    public void testGetSamplesPrometheusQuerySupplierUnknownClass() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"http://kafka-cluster-1.org:9090\");\n+        addCapacityConfig(config);\n+        config.put(PROMETHEUS_QUERY_SUPPLIER_CONFIG, \"com.test.NonExistentClass\");\n+        _prometheusMetricSampler.configure(config);\n+    }\n+\n+    @Test(expected = ConfigException.class)\n+    public void testGetSamplesPrometheusQuerySupplierInvalidClass() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"http://kafka-cluster-1.org:9090\");\n+        addCapacityConfig(config);\n+        config.put(PROMETHEUS_QUERY_SUPPLIER_CONFIG, String.class.getName());\n+        _prometheusMetricSampler.configure(config);\n+    }\n+\n+    private MetricSamplerOptions buildMetricSamplerOptions() {\n+        return new MetricSamplerOptions(\n+            generateCluster(),\n+            generatePartitions(),\n+            START_TIME_MS,\n+            END_TIME_MS,\n+            MetricSampler.SamplingMode.ALL,\n+            KafkaMetricDef.commonMetricDef(),\n+            60000\n+        );\n+    }\n+\n+    @Test\n+    public void testGetSamplesSuccess() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"http://kafka-cluster-1.org:9090\");\n+        addCapacityConfig(config);\n+        _prometheusMetricSampler.configure(config);\n+\n+        MetricSamplerOptions metricSamplerOptions = buildMetricSamplerOptions();\n+        _prometheusMetricSampler._prometheusAdapter = _prometheusAdapter;\n+\n+        for (RawMetricType rawMetricType : _prometheusQueryMap.keySet()) {\n+            setupPrometheusAdapterMock(rawMetricType, buildBrokerResults(),\n+                buildTopicResults(), buildPartitionResults());\n+        }\n+\n+        replay(_prometheusAdapter);\n+        MetricSampler.Samples samples = _prometheusMetricSampler.getSamples(metricSamplerOptions);\n+\n+        assertSamplesValid(samples);\n+        verify(_prometheusAdapter);\n+    }\n+\n+    @Test\n+    public void testGetSamplesWithCustomSamplingInterval() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"http://kafka-cluster-1.org:9090\");\n+        config.put(PROMETHEUS_QUERY_RESOLUTION_STEP_MS_CONFIG, \"5000\");\n+        addCapacityConfig(config);\n+        _prometheusMetricSampler.configure(config);\n+        assertEquals(5000, (long) _prometheusMetricSampler._prometheusAdapter._samplingIntervalMs);\n+    }\n+\n+    @Test(expected = ConfigException.class)\n+    public void testGetSamplesWithCustomMalformedSamplingInterval() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"http://kafka-cluster-1.org:9090\");\n+        config.put(PROMETHEUS_QUERY_RESOLUTION_STEP_MS_CONFIG, \"non-number\");\n+        addCapacityConfig(config);\n+        _prometheusMetricSampler.configure(config);\n+    }\n+\n+    @Test(expected = ConfigException.class)\n+    public void testGetSamplesWithCustomNegativeSamplingInterval() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"http://kafka-cluster-1.org:9090\");\n+        config.put(PROMETHEUS_QUERY_RESOLUTION_STEP_MS_CONFIG, \"-2000\");\n+        addCapacityConfig(config);\n+        _prometheusMetricSampler.configure(config);\n+    }\n+\n+    @Test\n+    public void testPrometheusQueryReturnsBadHostname() throws Exception {\n+        testPrometheusQueryReturnsInvalidResults(buildBrokerResultsWithBadHostname(),\n+                                             buildTopicResults(), buildPartitionResults());\n+    }\n+\n+    @Test\n+    public void testPrometheusQueryReturnsNullHostPort() throws Exception {\n+        testPrometheusQueryReturnsInvalidResults(buildBrokerResultsWithNullHostPort(),\n+            buildTopicResults(), buildPartitionResults());\n+    }\n+\n+    @Test\n+    public void testPrometheusQueryReturnsNullTopic() throws Exception {\n+        testPrometheusQueryReturnsInvalidResults(buildBrokerResults(),\n+            buildTopicResultsWithNullTopic(), buildPartitionResults());\n+    }\n+\n+    @Test\n+    public void testPrometheusQueryReturnsNullPartition() throws Exception {\n+        testPrometheusQueryReturnsInvalidResults(buildBrokerResults(),\n+            buildTopicResults(), buildPartitionResultsWithNullPartition());\n+    }\n+\n+    @Test\n+    public void testPrometheusQueryReturnsMalformedPartition() throws Exception {\n+        testPrometheusQueryReturnsInvalidResults(buildBrokerResults(),\n+            buildTopicResults(), buildPartitionResultsWithMalformedPartition());\n+    }\n+\n+    public void testPrometheusQueryReturnsInvalidResults(\n+        List<PrometheusQueryResult> brokerResults,\n+        List<PrometheusQueryResult> topicResults,\n+        List<PrometheusQueryResult> partitionResults) throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"http://kafka-cluster-1.org:9090\");\n+        addCapacityConfig(config);\n+        _prometheusMetricSampler.configure(config);\n+\n+        MetricSamplerOptions metricSamplerOptions = buildMetricSamplerOptions();\n+        _prometheusMetricSampler._prometheusAdapter = _prometheusAdapter;\n+        for (RawMetricType rawMetricType : _prometheusQueryMap.keySet()) {\n+            setupPrometheusAdapterMock(rawMetricType, brokerResults,\n+                topicResults, partitionResults);\n+        }\n+\n+        replay(_prometheusAdapter);\n+        _prometheusMetricSampler.getSamples(metricSamplerOptions);\n+    }\n+\n+    private void assertSamplesValid(MetricSampler.Samples samples) {\n+        assertEquals(TOTAL_BROKERS, samples.brokerMetricSamples().size());\n+        assertEquals(\n+            new HashSet<>(Arrays.asList(0, 1, 2)),\n+            samples.brokerMetricSamples().stream()\n+                .map(BrokerMetricSample::brokerId)\n+                .collect(Collectors.toSet()));\n+        samples.brokerMetricSamples().forEach(brokerMetricSample -> {\n+            assertEquals(FIXED_VALUE,\n+                         brokerMetricSample.metricValue(KafkaMetricDef.CPU_USAGE),\n+                DOUBLE_DELTA);\n+            assertEquals(FIXED_VALUE / BYTES_IN_KB,\n+                         brokerMetricSample.metricValue(KafkaMetricDef.LEADER_BYTES_OUT),\n+                DOUBLE_DELTA);\n+        });\n+\n+        assertEquals(TOTAL_BROKERS, samples.partitionMetricSamples().size());\n+        assertEquals(\n+            new HashSet<>(Arrays.asList(0, 1, 2)),\n+            samples.partitionMetricSamples().stream()\n+                .map(PartitionMetricSample::entity)\n+                .map(PartitionEntity::tp)\n+                .map(TopicPartition::partition)\n+                .collect(Collectors.toSet()));\n+\n+        samples.partitionMetricSamples().forEach(partitionMetricSample -> {\n+            assertEquals(TEST_TOPIC, partitionMetricSample.entity().tp().topic());\n+            assertEquals(FIXED_VALUE,\n+                         partitionMetricSample.metricValue(\n+                             KafkaMetricDef.commonMetricDefId(KafkaMetricDef.MESSAGE_IN_RATE)),\n+                DOUBLE_DELTA);\n+            assertEquals(FIXED_VALUE / BYTES_IN_KB,\n+                         partitionMetricSample.metricValue(\n+                         KafkaMetricDef.commonMetricDefId(KafkaMetricDef.LEADER_BYTES_IN)),\n+                DOUBLE_DELTA);\n+        });\n+    }\n+\n+    private void setupPrometheusAdapterMock(RawMetricType metricType,\n+                                            List<PrometheusQueryResult> brokerResults,\n+                                            List<PrometheusQueryResult> topicResults,\n+                                            List<PrometheusQueryResult> partitionResults) throws IOException {\n+        switch (metricType.metricScope()) {\n+            case BROKER:\n+                expect(_prometheusAdapter.queryMetric(eq(_prometheusQueryMap.get(metricType)), anyLong(), anyLong()))\n+                    .andReturn(brokerResults);\n+                break;\n+            case TOPIC:\n+                expect(_prometheusAdapter.queryMetric(eq(_prometheusQueryMap.get(metricType)), anyLong(), anyLong()))\n+                    .andReturn(topicResults);\n+                break;\n+            case PARTITION:\n+                expect(_prometheusAdapter.queryMetric(eq(_prometheusQueryMap.get(metricType)), anyLong(), anyLong()))\n+                    .andReturn(partitionResults);\n+                break;\n+            default:\n+                break;\n+        }\n+    }\n+\n+    private List<PrometheusQueryResult> buildBrokerResults() {\n+        List<PrometheusQueryResult> resultList = new ArrayList<>();\n+        for (int brokerId = 0; brokerId < TOTAL_BROKERS; brokerId++) {\n+            resultList.add(new PrometheusQueryResult(new PrometheusMetric(\n+                \"broker-\" + brokerId + \".test-cluster.org:11001\",\n+                null,\n+                null\n+            ), Arrays.asList(new PrometheusValue(START_EPOCH_SECONDS, FIXED_VALUE))));\n+        }\n+        return resultList;\n+    }\n+\n+    private List<PrometheusQueryResult> buildBrokerResultsWithBadHostname() {\n+        List<PrometheusQueryResult> resultList = new ArrayList<>();\n+        for (int brokerId = 0; brokerId < TOTAL_BROKERS; brokerId++) {\n+            resultList.add(new PrometheusQueryResult(new PrometheusMetric(\n+                \"broker-\" + brokerId + \".non-existent-cluster.org:11001\",\n+                null,\n+                null\n+            ), Arrays.asList(new PrometheusValue(START_EPOCH_SECONDS, FIXED_VALUE))));\n+        }\n+        return resultList;\n+    }\n+\n+    private List<PrometheusQueryResult> buildBrokerResultsWithNullHostPort() {\n+        List<PrometheusQueryResult> resultList = new ArrayList<>();\n+        for (int brokerId = 0; brokerId < TOTAL_BROKERS; brokerId++) {\n+            resultList.add(new PrometheusQueryResult(new PrometheusMetric(\n+                null,\n+                null,\n+                null\n+            ), Arrays.asList(new PrometheusValue(START_EPOCH_SECONDS, FIXED_VALUE))));\n+        }\n+        return resultList;\n+    }\n+\n+    private List<PrometheusQueryResult> buildTopicResults() {\n+        List<PrometheusQueryResult> resultList = new ArrayList<>();\n+        for (int brokerId = 0; brokerId < TOTAL_BROKERS; brokerId++) {\n+            resultList.add(new PrometheusQueryResult(new PrometheusMetric(\n+                \"broker-\" + brokerId + \".test-cluster.org:11001\",\n+                TEST_TOPIC,\n+                null\n+            ), Arrays.asList(new PrometheusValue(START_EPOCH_SECONDS, FIXED_VALUE))));\n+        }\n+        return resultList;\n+    }\n+\n+    private List<PrometheusQueryResult> buildTopicResultsWithNullTopic() {\n+        List<PrometheusQueryResult> resultList = new ArrayList<>();\n+        for (int brokerId = 0; brokerId < TOTAL_BROKERS; brokerId++) {\n+            resultList.add(new PrometheusQueryResult(new PrometheusMetric(\n+                \"broker-\" + brokerId + \".test-cluster.org:11001\",\n+                null,\n+                null\n+            ), Arrays.asList(new PrometheusValue(START_EPOCH_SECONDS, FIXED_VALUE))));\n+        }\n+        return resultList;\n+    }\n+\n+    private List<PrometheusQueryResult> buildPartitionResultsWithNullPartition() {\n+        List<PrometheusQueryResult> resultList = new ArrayList<>();\n+        for (int brokerId = 0; brokerId < TOTAL_BROKERS; brokerId++) {\n+            resultList.add(new PrometheusQueryResult(new PrometheusMetric(\n+                \"broker-\" + brokerId + \".test-cluster.org:11001\",\n+                TEST_TOPIC,\n+                null\n+            ), Arrays.asList(new PrometheusValue(START_EPOCH_SECONDS, FIXED_VALUE))));\n+        }\n+        return resultList;\n+    }\n+\n+    private List<PrometheusQueryResult> buildPartitionResultsWithMalformedPartition() {\n+        List<PrometheusQueryResult> resultList = new ArrayList<>();\n+        for (int brokerId = 0; brokerId < TOTAL_BROKERS; brokerId++) {\n+            resultList.add(new PrometheusQueryResult(new PrometheusMetric(\n+                \"broker-\" + brokerId + \".test-cluster.org:11001\",\n+                TEST_TOPIC,\n+                \"non-number\"\n+            ), Arrays.asList(new PrometheusValue(START_EPOCH_SECONDS, FIXED_VALUE))));\n+        }\n+        return resultList;\n+    }\n+\n+    private List<PrometheusQueryResult> buildPartitionResults() {\n+        List<PrometheusQueryResult> resultList = new ArrayList<>();\n+        for (int brokerId = 0; brokerId < TOTAL_BROKERS; brokerId++) {\n+            for (int partition = 0; partition < TOTAL_PARTITIONS; partition++) {\n+                resultList.add(new PrometheusQueryResult(new PrometheusMetric(\n+                    \"broker-\" + brokerId + \".test-cluster.org:11001\",\n+                    TEST_TOPIC,\n+                    String.valueOf(partition)\n+                ), Arrays.asList(new PrometheusValue(START_EPOCH_SECONDS, FIXED_VALUE))));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca1565a1b87ba59171e87895707144a5340c7970"}, "originalPosition": 428}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjk2NzkzMQ==", "bodyText": "Nit: Can we make this builder (and in general other builders in this class) static?", "url": "https://github.com/linkedin/cruise-control/pull/1366#discussion_r516967931", "createdAt": "2020-11-03T21:33:00Z", "author": {"login": "efeg"}, "path": "cruise-control/src/test/java/com/linkedin/kafka/cruisecontrol/monitor/sampling/prometheus/PrometheusMetricSamplerTest.java", "diffHunk": "@@ -0,0 +1,491 @@\n+/*\n+ * Copyright 2020 LinkedIn Corp. Licensed under the BSD 2-Clause License (the \"License\"). See License in the project root for license information.\n+ */\n+\n+package com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus;\n+\n+import java.io.File;\n+import java.io.FileOutputStream;\n+import java.io.IOException;\n+import java.io.OutputStreamWriter;\n+import java.nio.charset.StandardCharsets;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.kafka.common.Cluster;\n+import org.apache.kafka.common.Node;\n+import org.apache.kafka.common.PartitionInfo;\n+import org.apache.kafka.common.TopicPartition;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import com.linkedin.cruisecontrol.common.config.ConfigException;\n+import com.linkedin.kafka.cruisecontrol.config.BrokerCapacityConfigFileResolver;\n+import com.linkedin.kafka.cruisecontrol.config.BrokerCapacityConfigResolver;\n+import com.linkedin.kafka.cruisecontrol.exception.SamplingException;\n+import com.linkedin.kafka.cruisecontrol.metricsreporter.metric.RawMetricType;\n+import com.linkedin.kafka.cruisecontrol.monitor.metricdefinition.KafkaMetricDef;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricSampler;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.MetricSamplerOptions;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.holder.BrokerMetricSample;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.holder.PartitionEntity;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.holder.PartitionMetricSample;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusMetric;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusQueryResult;\n+import com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.model.PrometheusValue;\n+\n+import static com.linkedin.kafka.cruisecontrol.monitor.sampling.prometheus.PrometheusMetricSampler.*;\n+import static org.easymock.EasyMock.*;\n+import static org.junit.Assert.*;\n+\n+/**\n+ * Unit test for {@link PrometheusMetricSampler} class.\n+ */\n+public class PrometheusMetricSamplerTest {\n+    private static final int MILLIS_IN_SECOND = 1000;\n+    private static final double DOUBLE_DELTA = 0.00000001;\n+    private static final double BYTES_IN_KB = 1024.0;\n+\n+    private static final int FIXED_VALUE = 94;\n+    private static final long START_EPOCH_SECONDS = 1603301400L;\n+    private static final long START_TIME_MS = START_EPOCH_SECONDS * MILLIS_IN_SECOND;\n+    private static final long END_TIME_MS = START_TIME_MS + 59 * MILLIS_IN_SECOND;\n+\n+    private static final int TOTAL_BROKERS = 3;\n+    private static final int TOTAL_PARTITIONS = 3;\n+\n+    private static final String TEST_TOPIC = \"test-topic\";\n+\n+    private PrometheusMetricSampler _prometheusMetricSampler;\n+    private PrometheusAdapter _prometheusAdapter;\n+    private Map<RawMetricType, String> _prometheusQueryMap;\n+\n+    /**\n+     * Set up mocks\n+     */\n+    @Before\n+    public void setUp() {\n+        _prometheusAdapter = mock(PrometheusAdapter.class);\n+        _prometheusMetricSampler = new PrometheusMetricSampler();\n+        _prometheusQueryMap = new DefaultPrometheusQuerySupplier().get();\n+    }\n+\n+    @Test(expected = ConfigException.class)\n+    public void testConfigureWithPrometheusEndpointNoPortFails() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"http://kafka-cluster-1.org\");\n+        addCapacityConfig(config);\n+        _prometheusMetricSampler.configure(config);\n+    }\n+\n+    @Test(expected = ConfigException.class)\n+    public void testConfigureWithPrometheusEndpointNegativePortFails() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"http://kafka-cluster-1.org:-20\");\n+        addCapacityConfig(config);\n+        _prometheusMetricSampler.configure(config);\n+    }\n+\n+    @Test\n+    public void testConfigureWithPrometheusEndpointNoSchemaDoesNotFail() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"kafka-cluster-1.org:9090\");\n+        addCapacityConfig(config);\n+        _prometheusMetricSampler.configure(config);\n+    }\n+\n+    @Test(expected = ConfigException.class)\n+    public void testConfigureWithNoPrometheusEndpointFails() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        addCapacityConfig(config);\n+        _prometheusMetricSampler.configure(config);\n+    }\n+\n+    @Test(expected = SamplingException.class)\n+    public void testGetSamplesQueryThrowsException() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"http://kafka-cluster-1.org:9090\");\n+        addCapacityConfig(config);\n+        _prometheusMetricSampler.configure(config);\n+\n+        MetricSamplerOptions metricSamplerOptions = buildMetricSamplerOptions();\n+        _prometheusMetricSampler._prometheusAdapter = _prometheusAdapter;\n+        expect(_prometheusAdapter.queryMetric(anyString(), anyLong(), anyLong()))\n+            .andThrow(new IOException(\"Exception in fetching metrics\"));\n+\n+        replay(_prometheusAdapter);\n+        _prometheusMetricSampler.getSamples(metricSamplerOptions);\n+    }\n+\n+    @Test\n+    public void testGetSamplesCustomPrometheusQuerySupplier() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"http://kafka-cluster-1.org:9090\");\n+        addCapacityConfig(config);\n+        config.put(PROMETHEUS_QUERY_SUPPLIER_CONFIG, TestQuerySupplier.class.getName());\n+        _prometheusMetricSampler.configure(config);\n+\n+        MetricSamplerOptions metricSamplerOptions = buildMetricSamplerOptions();\n+        _prometheusMetricSampler._prometheusAdapter = _prometheusAdapter;\n+\n+        expect(_prometheusAdapter.queryMetric(eq(TestQuerySupplier.TEST_QUERY), anyLong(), anyLong()))\n+            .andReturn(buildBrokerResults());\n+        replay(_prometheusAdapter);\n+\n+        _prometheusMetricSampler.getSamples(metricSamplerOptions);\n+\n+        verify(_prometheusAdapter);\n+    }\n+\n+    @Test(expected = ConfigException.class)\n+    public void testGetSamplesPrometheusQuerySupplierUnknownClass() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"http://kafka-cluster-1.org:9090\");\n+        addCapacityConfig(config);\n+        config.put(PROMETHEUS_QUERY_SUPPLIER_CONFIG, \"com.test.NonExistentClass\");\n+        _prometheusMetricSampler.configure(config);\n+    }\n+\n+    @Test(expected = ConfigException.class)\n+    public void testGetSamplesPrometheusQuerySupplierInvalidClass() throws Exception {\n+        Map<String, Object> config = new HashMap<>();\n+        config.put(PROMETHEUS_SERVER_ENDPOINT_CONFIG, \"http://kafka-cluster-1.org:9090\");\n+        addCapacityConfig(config);\n+        config.put(PROMETHEUS_QUERY_SUPPLIER_CONFIG, String.class.getName());\n+        _prometheusMetricSampler.configure(config);\n+    }\n+\n+    private MetricSamplerOptions buildMetricSamplerOptions() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca1565a1b87ba59171e87895707144a5340c7970"}, "originalPosition": 164}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjk3MDMwNQ==", "bodyText": "Can we update the table of contents with this new title?", "url": "https://github.com/linkedin/cruise-control/pull/1366#discussion_r516970305", "createdAt": "2020-11-03T21:38:20Z", "author": {"login": "efeg"}, "path": "docs/wiki/User Guide/Configurations.md", "diffHunk": "@@ -232,6 +232,12 @@ We are still trying to improve cruise control. And following are some configurat\n | metric.reporter.topic                     | String | N         | \"__CruiseControlMetrics\"                                   | The exact topic name from which the sampler should be consuming the interested metrics from.                                             |\n | metric.reporter.sampler.group.id          | String | N         | 60,000                                                     | The consumer group id to use for the consumers to consume from the Kafka cluster.                                                        |\n \n+### PrometheusMetricSampler configurations", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca1565a1b87ba59171e87895707144a5340c7970"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjk3MTEyOA==", "bodyText": "Nit: This does not affect the correctness, but the placement of \"|\" in these two rows seem a little off. It would be great if we can align them properly.", "url": "https://github.com/linkedin/cruise-control/pull/1366#discussion_r516971128", "createdAt": "2020-11-03T21:40:08Z", "author": {"login": "efeg"}, "path": "docs/wiki/User Guide/Configurations.md", "diffHunk": "@@ -232,6 +232,12 @@ We are still trying to improve cruise control. And following are some configurat\n | metric.reporter.topic                     | String | N         | \"__CruiseControlMetrics\"                                   | The exact topic name from which the sampler should be consuming the interested metrics from.                                             |\n | metric.reporter.sampler.group.id          | String | N         | 60,000                                                     | The consumer group id to use for the consumers to consume from the Kafka cluster.                                                        |\n \n+### PrometheusMetricSampler configurations\n+| Name                                 | Type    | Required? | Default Value | Description                                                                                                                                                                                                |\n+|-------------------------------------------|--------|-----------|------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------|", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca1565a1b87ba59171e87895707144a5340c7970"}, "originalPosition": 6}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7f6686e20cce7a30ee78aa095add360b0b16974c", "author": {"user": {"login": "wyuka", "name": "Tirtha Chatterjee"}}, "url": "https://github.com/linkedin/cruise-control/commit/7f6686e20cce7a30ee78aa095add360b0b16974c", "committedDate": "2020-11-03T22:35:43Z", "message": "Fixed documentation, extracted constants."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIyOTI3NTM1", "url": "https://github.com/linkedin/cruise-control/pull/1366#pullrequestreview-522927535", "createdAt": "2020-11-03T22:42:47Z", "commit": {"oid": "7f6686e20cce7a30ee78aa095add360b0b16974c"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 91, "cost": 1, "resetAt": "2021-11-01T16:19:10Z"}}}