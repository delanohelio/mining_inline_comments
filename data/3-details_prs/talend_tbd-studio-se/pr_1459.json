{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDM2NDczMzQ4", "number": 1459, "title": "feat(TBD-10000): R2020-07: Support CDP Milestone II Dynamic Distro for CDP Data Center 7.x", "bodyText": "Please check if the PR fulfills these requirements\n\n The commit(s) message(s) follows our guidelines ?\n Unit tests for the Java changes have been added (for bug fixes / features) ?\n TUJ for the JavaJet changes have been added (for bug fixes / features) ?\n Docs have been added / updated (for bug fixes / features) ?\n The new code does not introduce new technical issues\n\nWhat is the current behavior? (You can also link to an open issue here)\nWhat is the new behavior?\nBREAKING CHANGE\nIf this PR contains a breaking change, please describe the impact and migration\npath for existing applications.\nIf not please remove this section.\nOther information:", "createdAt": "2020-06-18T13:27:13Z", "url": "https://github.com/Talend/tbd-studio-se/pull/1459", "merged": true, "mergeCommit": {"oid": "84ed04002f1c9b5adbd3e23d2b1bd3569751c568"}, "closed": true, "closedAt": "2020-07-16T08:06:22Z", "author": {"login": "Redwene"}, "timelineItems": {"totalCount": 27, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcseY0wgH2gAyNDM2NDczMzQ4OjU5NjBlY2Y1YmM3NjRlMjdmMWE4MjYyYzUzMWI5YzllYTQxMWZkZTk=", "endCursor": "Y3Vyc29yOnYyOpPPAAABc1aNXeAFqTQ0OTU4NjY2MA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "5960ecf5bc764e27f1a8262c531b9c9ea411fde9", "author": {"user": {"login": "Redwene", "name": "Redwene"}}, "url": "https://github.com/Talend/tbd-studio-se/commit/5960ecf5bc764e27f1a8262c531b9c9ea411fde9", "committedDate": "2020-06-18T13:23:01Z", "message": "sqoop part"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9a6c284baa93088d2a7386c783b30b832aea422a", "author": {"user": {"login": "Redwene", "name": "Redwene"}}, "url": "https://github.com/Talend/tbd-studio-se/commit/9a6c284baa93088d2a7386c783b30b832aea422a", "committedDate": "2020-06-29T06:29:01Z", "message": "Merge branch 'maintenance/7.3' of github.com:Talend/tbd-studio-se into redwene/TBD-10000"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fae0c69158c46c2ae9ef7fdf9a68ac5a6e93cd04", "author": {"user": {"login": "Redwene", "name": "Redwene"}}, "url": "https://github.com/Talend/tbd-studio-se/commit/fae0c69158c46c2ae9ef7fdf9a68ac5a6e93cd04", "committedDate": "2020-06-29T08:36:28Z", "message": "sqoop part"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b75663adb104efb4fb95e24ef7a3c5c86719f994", "author": {"user": {"login": "Redwene", "name": "Redwene"}}, "url": "https://github.com/Talend/tbd-studio-se/commit/b75663adb104efb4fb95e24ef7a3c5c86719f994", "committedDate": "2020-07-02T07:07:37Z", "message": "Merge branch 'maintenance/7.3' of github.com:Talend/tbd-studio-se into redwene/TBD-10000"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5f2cd4971307a76ae450adf573262ffa616c4524", "author": {"user": {"login": "Redwene", "name": "Redwene"}}, "url": "https://github.com/Talend/tbd-studio-se/commit/5f2cd4971307a76ae450adf573262ffa616c4524", "committedDate": "2020-07-03T08:38:10Z", "message": "sqoop and avro dependencies on cluster side"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "53acdca82b8efc9fe758ec103869e50b88383080", "author": {"user": {"login": "Redwene", "name": "Redwene"}}, "url": "https://github.com/Talend/tbd-studio-se/commit/53acdca82b8efc9fe758ec103869e50b88383080", "committedDate": "2020-07-03T08:44:24Z", "message": "missing refacto"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7c705d8773eba01e125938cba9463e505999cba4", "author": {"user": {"login": "Redwene", "name": "Redwene"}}, "url": "https://github.com/Talend/tbd-studio-se/commit/7c705d8773eba01e125938cba9463e505999cba4", "committedDate": "2020-07-03T14:23:03Z", "message": "missing sqoop lib"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c63bdd2a212cacfb361a6b741b69a0d27f6f3a23", "author": {"user": {"login": "Redwene", "name": "Redwene"}}, "url": "https://github.com/Talend/tbd-studio-se/commit/c63bdd2a212cacfb361a6b741b69a0d27f6f3a23", "committedDate": "2020-07-03T14:23:36Z", "message": "missing dependencies"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "32862e9face1e515d42562bcabb7f509dc0f3473", "author": {"user": {"login": "Redwene", "name": "Redwene"}}, "url": "https://github.com/Talend/tbd-studio-se/commit/32862e9face1e515d42562bcabb7f509dc0f3473", "committedDate": "2020-07-07T07:33:10Z", "message": "Merge branch 'maintenance/7.3' of github.com:Talend/tbd-studio-se into redwene/TBD-10000"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9c2318beaf44a3e44d9710a7083f2534644572f9", "author": {"user": {"login": "Redwene", "name": "Redwene"}}, "url": "https://github.com/Talend/tbd-studio-se/commit/9c2318beaf44a3e44d9710a7083f2534644572f9", "committedDate": "2020-07-07T08:00:09Z", "message": "sqoop issue java.lang.NoClassDefFoundError\norg/apache/avro/mapred/AvroWrapper"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "23995f38fb8d9cbfd67f8564d81c4fe3a71451e0", "author": {"user": {"login": "Redwene", "name": "Redwene"}}, "url": "https://github.com/Talend/tbd-studio-se/commit/23995f38fb8d9cbfd67f8564d81c4fe3a71451e0", "committedDate": "2020-07-14T06:58:32Z", "message": "Merge branch 'maintenance/7.3' of github.com:Talend/tbd-studio-se into redwene/TBD-10000"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a96340002e2c6c06a77152cfc186d133c39dc292", "author": {"user": {"login": "Redwene", "name": "Redwene"}}, "url": "https://github.com/Talend/tbd-studio-se/commit/a96340002e2c6c06a77152cfc186d133c39dc292", "committedDate": "2020-07-14T13:49:01Z", "message": "WIP impala on cdp"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2108c63e3904e42c1c38fa0c775658bb2ddd4bcc", "author": {"user": {"login": "Redwene", "name": "Redwene"}}, "url": "https://github.com/Talend/tbd-studio-se/commit/2108c63e3904e42c1c38fa0c775658bb2ddd4bcc", "committedDate": "2020-07-14T17:27:41Z", "message": "wip update the built-in template to support impala"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c1dc4ee4f52f576a8476f4f1e938f57aa41f8b3b", "author": {"user": {"login": "Redwene", "name": "Redwene"}}, "url": "https://github.com/Talend/tbd-studio-se/commit/c1dc4ee4f52f576a8476f4f1e938f57aa41f8b3b", "committedDate": "2020-07-14T17:29:54Z", "message": "delete unsued variables and add kerberos configuration"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4", "author": {"user": {"login": "Redwene", "name": "Redwene"}}, "url": "https://github.com/Talend/tbd-studio-se/commit/248d815b93ed618f59984e9133f128fa0327ded4", "committedDate": "2020-07-15T03:28:29Z", "message": "issue sqoop import with avro"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ4NzMxMjAx", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#pullrequestreview-448731201", "createdAt": "2020-07-15T08:19:33Z", "commit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQwODoxOTozM1rOGxzcJw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQwODozNTo0NVrOGx0Bvw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg3NjE5OQ==", "bodyText": "should not it be spark 24 ?", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r454876199", "createdAt": "2020-07-15T08:19:33Z", "author": {"login": "AlixMetivier"}, "path": "main/plugins/org.talend.hadoop.distribution.cdp/src/main/java/org/talend/hadoop/distribution/cdp/CDP7xDistributionTemplate.java", "diffHunk": "@@ -33,227 +34,253 @@\n import org.talend.hadoop.distribution.kudu.KuduVersion;\n \n @SuppressWarnings(\"nls\")\n-public class CDP7xDistributionTemplate extends AbstractDynamicCDPDistributionTemplate implements HDFSComponent, HBaseComponent,\n-        HCatalogComponent, MRComponent, HiveComponent, HiveOnSparkComponent, ImpalaComponent, SqoopComponent,\n- CDPSparkBatchComponent, SparkStreamingComponent, ICDP7xDistributionTemplate {\n-\n-    public final static String TEMPLATE_ID = \"CDP7xDistributionTemplate\";\n-  \n-    private final static String YARN_APPLICATION_CLASSPATH = \"/opt/cloudera/parcels/CDH/lib/spark/jars/*,\" + \n-    \t\t\"/opt/cloudera/parcels/CDH/lib/hive/lib/*,\" + \n-    \t\t\"/opt/cloudera/parcels/CDH/lib/impala/lib/*,\"+\n-    \t\t\"/opt/cloudera/parcels/CDH/lib/hbase/lib/*,\"+\n-    \t\t\"/opt/cloudera/parcels/CDH/lib/kudu/*\";\n-\n-    public CDP7xDistributionTemplate(DynamicPluginAdapter pluginAdapter) throws Exception {\n-        super(pluginAdapter);\n-    }\n-\n-    @Override\n-    public String getTemplateId() {\n-        return TEMPLATE_ID;\n-    }\n-\n-    @Override\n-    public String getYarnApplicationClasspath() {\n-    \treturn YARN_APPLICATION_CLASSPATH;\n-    }\n-    \n-    @Override\n-    public String generateSparkJarsPaths(List<String> commandLineJarsPaths) {\n-        return getYarnApplicationClasspath() ;\n-    }\n-    @Override\n-    public boolean doSupportSequenceFileShortType() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportNewHBaseAPI() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportCrossPlatformSubmission() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportImpersonation() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportEmbeddedMode() {\n-        return false;\n-    }\n-\n-    @Override\n-    public boolean doSupportStandaloneMode() {\n-        return super.doSupportStandaloneMode();\n-    }\n-   \n-    @Override\n-    public boolean doSupportHive1() {\n-        return false;\n-    }\n-\n-    @Override\n-    public boolean doSupportHive2() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportTezForHive() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportHBaseForHive() {\n-        return false;\n-    }\n-    @Override\n-    public boolean doSupportHBase2x() {\n-        return true;\n-    }\n-    @Override\n-    public boolean doSupportSSL() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportORCFormat() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportAvroFormat() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportParquetFormat() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportStoreAsParquet() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doJavaAPISupportStorePasswordInFile() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doJavaAPISqoopImportSupportDeleteTargetDir() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doJavaAPISqoopImportAllTablesSupportExcludeTable() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportClouderaNavigator() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportParquetOutput() {\n-        return true;\n-    }\n-\n-    @Override\n-    public Set<ESparkVersion> getSparkVersions() {\n-        Set<ESparkVersion> version = new HashSet<>();\n-        Set<ESparkVersion> sparkVersions = super.getSparkVersions();\n-        if (sparkVersions == null || sparkVersions.isEmpty()) {\n-            version.add(ESparkVersion.SPARK_2_2);\n-        } else {\n-            version.addAll(sparkVersions);\n-        }\n-        return version;\n-    }\n-\n-    @Override\n-    public boolean isExecutedThroughSparkJobServer() {\n-        return false;\n-    }\n-\n-    @Override\n-    public boolean doSupportSparkStandaloneMode() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportSparkYarnClientMode() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportDynamicMemoryAllocation() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportSSLwithKerberos() {\n-        return true;\n-    }\n-\n-    @Override\n-    public int getClouderaNavigatorAPIVersion() {\n-        return 9;\n-    }\n-\n-    @Override\n-    public boolean doSupportCheckpointing() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportBackpressure() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportAzureBlobStorage() {\n-        return true;\n-    }\n-\n-    @Override\n-    public short orderingWeight() {\n-        return 10;\n-    }\n-\n-    @Override\n-    public boolean doImportDynamoDBDependencies() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportAssumeRole() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportAvroDeflateProperties() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean useOldAWSAPI() {\n-        return false;\n-    }\n-\n-    @Override\n-    public String getSuffixParquetPackage() {\n-    \treturn \"org.apache.\";\n-    }\n-    @Override\n-    public KuduVersion getKuduVersion() {\n-        return KuduVersion.KUDU_1_12;\n-    }\n+public class CDP7xDistributionTemplate extends AbstractDynamicCDPDistributionTemplate\n+\t\timplements HDFSComponent, HBaseComponent, HCatalogComponent, MRComponent, HiveComponent, HiveOnSparkComponent,\n+\t\tImpalaComponent, SqoopComponent, CDPSparkBatchComponent, SparkStreamingComponent, ICDP7xDistributionTemplate {\n+\tprivate final static String SEPARATOR = \",\";\n+\tpublic final static String DEFAULT_LIB_ROOT = \"/opt/cloudera/parcels/CDH/lib\";\n+\tpublic final static String TEMPLATE_ID = \"CDP7xDistributionTemplate\";\n+\n+\tprivate final static String YARN_APPLICATION_CLASSPATH = \n+\t\t\tDEFAULT_LIB_ROOT + \"/spark/jars/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/hive/lib/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/impala/lib/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/hbase/lib/*\" + SEPARATOR\n+\t\t\t+ DEFAULT_LIB_ROOT + \"/sqoop/lib/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/kudu/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/hadoop-mapreduce/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/hadoop-yarn/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/hadoop-yarn/lib/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/avro/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/hadoop/lib/*\";\n+\n+\tpublic CDP7xDistributionTemplate(DynamicPluginAdapter pluginAdapter) throws Exception {\n+\t\tsuper(pluginAdapter);\n+\t}\n+\t@Override\n+\tpublic boolean doSupportImpalaConnector() {\n+\t\t\n+\t\treturn true;\n+\t}\n+\t@Override\n+\tpublic boolean doImpalaSupportSSL() {\n+\t\t\n+\t\treturn true;\n+\t}\n+\t@Override\n+\tpublic String getSqoopPackageName() {\n+\t\treturn ESqoopPackageName.ORG_APACHE_SQOOP.toString();\n+\t}\n+\n+\t@Override\n+\tpublic String getTemplateId() {\n+\t\treturn TEMPLATE_ID;\n+\t}\n+\n+\t@Override\n+\tpublic String getYarnApplicationClasspath() {\n+\t\treturn YARN_APPLICATION_CLASSPATH;\n+\t}\n+\n+\t@Override\n+\tpublic String generateSparkJarsPaths(List<String> commandLineJarsPaths) {\n+\t\treturn getYarnApplicationClasspath();\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportSequenceFileShortType() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportNewHBaseAPI() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportCrossPlatformSubmission() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportImpersonation() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportEmbeddedMode() {\n+\t\treturn false;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportStandaloneMode() {\n+\t\treturn super.doSupportStandaloneMode();\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportHive1() {\n+\t\treturn false;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportHive2() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportTezForHive() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportHBaseForHive() {\n+\t\treturn false;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportHBase2x() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportSSL() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportORCFormat() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportAvroFormat() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportParquetFormat() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportStoreAsParquet() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doJavaAPISupportStorePasswordInFile() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doJavaAPISqoopImportSupportDeleteTargetDir() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doJavaAPISqoopImportAllTablesSupportExcludeTable() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportClouderaNavigator() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportParquetOutput() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic Set<ESparkVersion> getSparkVersions() {\n+\t\tSet<ESparkVersion> version = new HashSet<>();\n+\t\tSet<ESparkVersion> sparkVersions = super.getSparkVersions();\n+\t\tif (sparkVersions == null || sparkVersions.isEmpty()) {\n+\t\t\tversion.add(ESparkVersion.SPARK_2_2);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "originalPosition": 398}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg3OTg4Mw==", "bodyText": "can not be the case, you removed IMPALA40 and IMPALA41 to be IMPALA", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r454879883", "createdAt": "2020-07-15T08:25:38Z", "author": {"login": "AlixMetivier"}, "path": "main/plugins/org.talend.designer.components.bigdata/components/tImpalaConnection/tImpalaConnectionUtil.javajet", "diffHunk": "@@ -0,0 +1,309 @@\n+<%\n+\tclass ConnectionUtil extends DefaultConnectionUtil {\n+\t\tprivate String javaDbDriver = \"org.apache.hadoop.hive.jdbc.HiveDriver\";\n+\t\tprivate org.talend.hadoop.distribution.component.HiveComponent hiveDistrib;\n+\t\tprivate boolean isCustom;\n+\n+\t\tpublic ConnectionUtil(org.talend.hadoop.distribution.component.HiveComponent hiveDistrib) {\n+\t\t\tthis.hiveDistrib = hiveDistrib;\n+\t\t\tthis.isCustom = hiveDistrib instanceof org.talend.hadoop.distribution.custom.CustomDistribution;\n+\t\t}\n+\n+\t\tpublic void createConnection(INode node) {\n+\t\t\tString connectionMode = ElementParameterParser.getValue(node, \"__CONNECTION_MODE__\");\n+\t\t\tString hiveVersion = ElementParameterParser.getValue(node, \"__HIVE_VERSION__\");\n+\t\t\tboolean useKrb = \"true\".equals(ElementParameterParser.getValue(node, \"__USE_KRB__\"));\n+\t\t\tboolean securityIsEnabled = useKrb && (isCustom || this.hiveDistrib.doSupportKerberos());\n+%>\n+\t\t\tconn_<%=cid%> = java.sql.DriverManager.getConnection(url_<%=cid%>);\n+<%\n+\t\t}\n+\n+\t\tpublic void createURL(INode node) {\n+\t\t\tsuper.createURL(node);\n+\n+\t\t\tString additionalJdbcSettings = ElementParameterParser.getValue(node, \"__IMPALA_ADDITIONAL_JDBC__\");\n+\t\t\t\n+\t\t\tString hiveVersion = ElementParameterParser.getValue(node, \"__HIVE_VERSION__\");\n+\t\t\tString fsDefaultName = \"fs.default.name\";\n+\t\t\tString impalaDriver = ElementParameterParser.getValue(node, \"__IMPALA_DRIVER__\");\n+\t\t\tString impalaDbProtocol = \"hive2\";\n+\n+\t\t\tboolean setMapredJT = \"true\".equals(ElementParameterParser.getValue(node, \"__SET_MAPRED_JT__\"));\n+\t\t\tboolean setNamenode = \"true\".equals(ElementParameterParser.getValue(node, \"__SET_FS_DEFAULT_NAME__\"));\n+\t\t\tList<Map<String, String>> hadoopProps = (List<Map<String,String>>)ElementParameterParser.getObjectValue(node, \"__HADOOP_ADVANCED_PROPERTIES__\");\n+\n+\t\t\tboolean useYarn = \"true\".equals(ElementParameterParser.getValue(node, \"__USE_YARN__\"));\n+\n+\t\t\tboolean useKrb = \"true\".equals(ElementParameterParser.getValue(node, \"__USE_KRB__\"));\n+\t\t\tboolean securityIsEnabled = useKrb && ( this.isCustom || this.hiveDistrib.doSupportKerberos() );\n+\t\t\tString impalaPrincipal = ElementParameterParser.getValue(node, \"__IMPALA_PRINCIPAL__\");\n+\t\t\t\n+\t\t\tboolean useKeytab = \"true\".equals(ElementParameterParser.getValue(node, \"__USE_KEYTAB__\"));\n+\t\t\tString userPrincipal = ElementParameterParser.getValue(node, \"__PRINCIPAL__\");\n+\t\t\tString keytabPath = ElementParameterParser.getValue(node, \"__KEYTAB_PATH__\");\n+\t\t\t\n+\t\t\tboolean useSsl = \"true\".equals(ElementParameterParser.getValue(node, \"__USE_SSL__\"));\n+\t\t\tString sslTrustStore = ElementParameterParser.getValue(node, \"__SSL_TRUST_STORE__\");\n+\t\t\tString sslStorepasswordFieldName = \"__SSL_TRUST_STORE_PASSWORD__\";\n+\n+\t\t\tboolean configureFromClassPath = \"true\".equals(ElementParameterParser.getValue(node, \"__CONFIGURATIONS_FROM_CLASSPATH__\"));\n+\t\t\tboolean storeByHBase = \"true\".equals(ElementParameterParser.getValue(node, \"__STORE_BY_HBASE__\"));\n+\t\t    \n+\n+\t\t\tif(impalaDriver!=null && !\"\".equals(impalaDriver.trim()) && (this.isCustom || this.hiveDistrib.doSupportHive2())) {\n+\t\t\t    impalaDriver = impalaDriver.toLowerCase();\n+\t\t\t\tif (\"hive2\".equalsIgnoreCase(impalaDriver)) {\n+\t\t\t\t\tjavaDbDriver = \"org.apache.hive.jdbc.HiveDriver\";\n+\t\t\t\t\timpalaDbProtocol=\"hive2\";\n+\t\t\t\t}\n+\t\t\t\tif (\"impala40\".equalsIgnoreCase(impalaDriver)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg3OTkxNg==", "bodyText": "can not be the case, you removed IMPALA40 and IMPALA41 to be IMPALA", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r454879916", "createdAt": "2020-07-15T08:25:43Z", "author": {"login": "AlixMetivier"}, "path": "main/plugins/org.talend.designer.components.bigdata/components/tImpalaConnection/tImpalaConnectionUtil.javajet", "diffHunk": "@@ -0,0 +1,309 @@\n+<%\n+\tclass ConnectionUtil extends DefaultConnectionUtil {\n+\t\tprivate String javaDbDriver = \"org.apache.hadoop.hive.jdbc.HiveDriver\";\n+\t\tprivate org.talend.hadoop.distribution.component.HiveComponent hiveDistrib;\n+\t\tprivate boolean isCustom;\n+\n+\t\tpublic ConnectionUtil(org.talend.hadoop.distribution.component.HiveComponent hiveDistrib) {\n+\t\t\tthis.hiveDistrib = hiveDistrib;\n+\t\t\tthis.isCustom = hiveDistrib instanceof org.talend.hadoop.distribution.custom.CustomDistribution;\n+\t\t}\n+\n+\t\tpublic void createConnection(INode node) {\n+\t\t\tString connectionMode = ElementParameterParser.getValue(node, \"__CONNECTION_MODE__\");\n+\t\t\tString hiveVersion = ElementParameterParser.getValue(node, \"__HIVE_VERSION__\");\n+\t\t\tboolean useKrb = \"true\".equals(ElementParameterParser.getValue(node, \"__USE_KRB__\"));\n+\t\t\tboolean securityIsEnabled = useKrb && (isCustom || this.hiveDistrib.doSupportKerberos());\n+%>\n+\t\t\tconn_<%=cid%> = java.sql.DriverManager.getConnection(url_<%=cid%>);\n+<%\n+\t\t}\n+\n+\t\tpublic void createURL(INode node) {\n+\t\t\tsuper.createURL(node);\n+\n+\t\t\tString additionalJdbcSettings = ElementParameterParser.getValue(node, \"__IMPALA_ADDITIONAL_JDBC__\");\n+\t\t\t\n+\t\t\tString hiveVersion = ElementParameterParser.getValue(node, \"__HIVE_VERSION__\");\n+\t\t\tString fsDefaultName = \"fs.default.name\";\n+\t\t\tString impalaDriver = ElementParameterParser.getValue(node, \"__IMPALA_DRIVER__\");\n+\t\t\tString impalaDbProtocol = \"hive2\";\n+\n+\t\t\tboolean setMapredJT = \"true\".equals(ElementParameterParser.getValue(node, \"__SET_MAPRED_JT__\"));\n+\t\t\tboolean setNamenode = \"true\".equals(ElementParameterParser.getValue(node, \"__SET_FS_DEFAULT_NAME__\"));\n+\t\t\tList<Map<String, String>> hadoopProps = (List<Map<String,String>>)ElementParameterParser.getObjectValue(node, \"__HADOOP_ADVANCED_PROPERTIES__\");\n+\n+\t\t\tboolean useYarn = \"true\".equals(ElementParameterParser.getValue(node, \"__USE_YARN__\"));\n+\n+\t\t\tboolean useKrb = \"true\".equals(ElementParameterParser.getValue(node, \"__USE_KRB__\"));\n+\t\t\tboolean securityIsEnabled = useKrb && ( this.isCustom || this.hiveDistrib.doSupportKerberos() );\n+\t\t\tString impalaPrincipal = ElementParameterParser.getValue(node, \"__IMPALA_PRINCIPAL__\");\n+\t\t\t\n+\t\t\tboolean useKeytab = \"true\".equals(ElementParameterParser.getValue(node, \"__USE_KEYTAB__\"));\n+\t\t\tString userPrincipal = ElementParameterParser.getValue(node, \"__PRINCIPAL__\");\n+\t\t\tString keytabPath = ElementParameterParser.getValue(node, \"__KEYTAB_PATH__\");\n+\t\t\t\n+\t\t\tboolean useSsl = \"true\".equals(ElementParameterParser.getValue(node, \"__USE_SSL__\"));\n+\t\t\tString sslTrustStore = ElementParameterParser.getValue(node, \"__SSL_TRUST_STORE__\");\n+\t\t\tString sslStorepasswordFieldName = \"__SSL_TRUST_STORE_PASSWORD__\";\n+\n+\t\t\tboolean configureFromClassPath = \"true\".equals(ElementParameterParser.getValue(node, \"__CONFIGURATIONS_FROM_CLASSPATH__\"));\n+\t\t\tboolean storeByHBase = \"true\".equals(ElementParameterParser.getValue(node, \"__STORE_BY_HBASE__\"));\n+\t\t    \n+\n+\t\t\tif(impalaDriver!=null && !\"\".equals(impalaDriver.trim()) && (this.isCustom || this.hiveDistrib.doSupportHive2())) {\n+\t\t\t    impalaDriver = impalaDriver.toLowerCase();\n+\t\t\t\tif (\"hive2\".equalsIgnoreCase(impalaDriver)) {\n+\t\t\t\t\tjavaDbDriver = \"org.apache.hive.jdbc.HiveDriver\";\n+\t\t\t\t\timpalaDbProtocol=\"hive2\";\n+\t\t\t\t}\n+\t\t\t\tif (\"impala40\".equalsIgnoreCase(impalaDriver)) {\n+\t\t\t\t\tjavaDbDriver = \"com.cloudera.impala.jdbc4.Driver\";\n+\t\t\t\t\timpalaDbProtocol=\"impala\";\n+\t\t\t\t}\t\n+\t\t\t\tif (\"impala41\".equalsIgnoreCase(impalaDriver)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg4MDQ2Mg==", "bodyText": "can not be the case, you removed IMPALA40 and IMPALA41 to be IMPALA", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r454880462", "createdAt": "2020-07-15T08:26:40Z", "author": {"login": "AlixMetivier"}, "path": "main/plugins/org.talend.designer.components.bigdata/components/tImpalaInput/tImpalaInput_begin.javajet", "diffHunk": "@@ -72,7 +72,7 @@\n \t\t\t    impalaDriver = impalaDriver.toLowerCase();\n \t\t\t\tif (\"hive2\".equalsIgnoreCase(impalaDriver)) {\n \t\t\t\t\tjavaDbDriver = \"org.apache.hive.jdbc.HiveDriver\";\n-\t\t\t\t\timpalaDbProtocol=\"hive2\";\n+\t\t\t\t\timpalaDbProtocol=\"impala\";\n \t\t\t\t}\n \t\t\t\tif (\"impala40\".equalsIgnoreCase(impalaDriver)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg4MjE2NA==", "bodyText": "why this change, is it for URI creation ?", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r454882164", "createdAt": "2020-07-15T08:29:25Z", "author": {"login": "AlixMetivier"}, "path": "main/plugins/org.talend.designer.components.bigdata/components/tImpalaConnection/tImpalaConnection_java.xml", "diffHunk": "@@ -74,7 +72,7 @@\n \t\t\n \t\t<PARAMETER NAME=\"USER\" FIELD=\"TEXT\" NUM_ROW=\"30\"\n \t\t\tREPOSITORY_VALUE=\"USERNAME\" GROUP=\"CONNECTION\" SHOW=\"true\">\n-\t\t\t<DEFAULT>\"\"</DEFAULT>\n+\t\t\t<DEFAULT></DEFAULT>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg4NTgyMw==", "bodyText": "org.talend.hadoop.distribution.component.HadoopComponent can be changed to org.talend.hadoop.distribution.component.HiveComponent to avoid the cast", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r454885823", "createdAt": "2020-07-15T08:35:45Z", "author": {"login": "AlixMetivier"}, "path": "main/plugins/org.talend.designer.components.bigdata/components/tImpalaConnection/tImpalaConnectionUtilImpalaDriver.javajet", "diffHunk": "@@ -0,0 +1,298 @@\n+<%\n+\n+\tclass ConnectionUtilImpala extends DefaultConnectionUtil {\n+      // use HiveComponent type to get all necessary methods but there is something to fix about the design on the current typing \n+\t\tprivate org.talend.hadoop.distribution.component.HiveComponent distrib = null;\n+\t\tprivate boolean isCustom;\n+    \n+\t\tpublic ConnectionUtilImpala(org.talend.hadoop.distribution.component.HadoopComponent distrib) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "originalPosition": 8}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ5MTgzOTQz", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#pullrequestreview-449183943", "createdAt": "2020-07-15T17:35:21Z", "commit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQxNzozNToyMlrOGyIljQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQxODowMDowNlrOGyJlGQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTIyMjY2OQ==", "bodyText": "I think this change will require a migration task.", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r455222669", "createdAt": "2020-07-15T17:35:22Z", "author": {"login": "lbourgeois"}, "path": "main/plugins/org.talend.designer.components.bigdata/components/tImpalaCreateTable/tImpalaCreateTable_java.xml", "diffHunk": "@@ -65,9 +65,7 @@\n \t\t\t<ITEMS DEFAULT=\"HIVE2\">\n \t\t\t\t<ITEM NAME=\"HIVE2\" VALUE=\"HIVE2\"\n \t\t\t\t\t  SHOW_IF=\"(HIVE_SERVER == 'HIVE2')\" />\n-\t\t\t\t<ITEM NAME=\"IMPALA40\" VALUE=\"IMPALA40\"\n-\t\t\t\t\t  SHOW_IF=\"(DISTRIBUTION=='CLOUDERA' AND DISTRIB[DISTRIBUTION, IMPALA_VERSION].doSupportImpalaConnector[])\" />\n-\t\t\t\t<ITEM NAME=\"IMPALA41\" VALUE=\"IMPALA41\"\n+\t\t\t\t<ITEM NAME=\"IMPALA\" VALUE=\"IMPALA\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTIyNTA4Ng==", "bodyText": "looks strange to see\nif (\"hive2\".equalsIgnoreCase(impalaDriver)) {impalaDbProtocol=\"impala\";}", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r455225086", "createdAt": "2020-07-15T17:37:36Z", "author": {"login": "lbourgeois"}, "path": "main/plugins/org.talend.designer.components.bigdata/components/tImpalaInput/tImpalaInput_begin.javajet", "diffHunk": "@@ -72,7 +72,7 @@\n \t\t\t    impalaDriver = impalaDriver.toLowerCase();\n \t\t\t\tif (\"hive2\".equalsIgnoreCase(impalaDriver)) {\n \t\t\t\t\tjavaDbDriver = \"org.apache.hive.jdbc.HiveDriver\";\n-\t\t\t\t\timpalaDbProtocol=\"hive2\";\n+\t\t\t\t\timpalaDbProtocol=\"impala\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTIzNTExOA==", "bodyText": "I don't get why this was moved to superinterface HaddopComponent.\nIt should stay in ImpalaComponent as it is related to Impala", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r455235118", "createdAt": "2020-07-15T17:54:08Z", "author": {"login": "lbourgeois"}, "path": "main/plugins/org.talend.hadoop.distribution/src/main/java/org/talend/hadoop/distribution/component/ImpalaComponent.java", "diffHunk": "@@ -18,17 +18,6 @@\n  */\n public interface ImpalaComponent extends HadoopComponent {\n \n-    /**\n-     * indicate if we support the impala native protocol.\n-     * connection with jdbc:impala://[Host]:[Port]/[Schema];[Property1]=[Value];[Property2]=[Value];\n-     * @return\n-     */\n-    default boolean doSupportImpalaConnector() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTIzNjc5Nw==", "bodyText": "Is it still CDH in path ?", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r455236797", "createdAt": "2020-07-15T17:56:35Z", "author": {"login": "lbourgeois"}, "path": "main/plugins/org.talend.hadoop.distribution.cdp/src/main/java/org/talend/hadoop/distribution/cdp/CDP7xDistributionTemplate.java", "diffHunk": "@@ -33,227 +34,253 @@\n import org.talend.hadoop.distribution.kudu.KuduVersion;\n \n @SuppressWarnings(\"nls\")\n-public class CDP7xDistributionTemplate extends AbstractDynamicCDPDistributionTemplate implements HDFSComponent, HBaseComponent,\n-        HCatalogComponent, MRComponent, HiveComponent, HiveOnSparkComponent, ImpalaComponent, SqoopComponent,\n- CDPSparkBatchComponent, SparkStreamingComponent, ICDP7xDistributionTemplate {\n-\n-    public final static String TEMPLATE_ID = \"CDP7xDistributionTemplate\";\n-  \n-    private final static String YARN_APPLICATION_CLASSPATH = \"/opt/cloudera/parcels/CDH/lib/spark/jars/*,\" + \n-    \t\t\"/opt/cloudera/parcels/CDH/lib/hive/lib/*,\" + \n-    \t\t\"/opt/cloudera/parcels/CDH/lib/impala/lib/*,\"+\n-    \t\t\"/opt/cloudera/parcels/CDH/lib/hbase/lib/*,\"+\n-    \t\t\"/opt/cloudera/parcels/CDH/lib/kudu/*\";\n-\n-    public CDP7xDistributionTemplate(DynamicPluginAdapter pluginAdapter) throws Exception {\n-        super(pluginAdapter);\n-    }\n-\n-    @Override\n-    public String getTemplateId() {\n-        return TEMPLATE_ID;\n-    }\n-\n-    @Override\n-    public String getYarnApplicationClasspath() {\n-    \treturn YARN_APPLICATION_CLASSPATH;\n-    }\n-    \n-    @Override\n-    public String generateSparkJarsPaths(List<String> commandLineJarsPaths) {\n-        return getYarnApplicationClasspath() ;\n-    }\n-    @Override\n-    public boolean doSupportSequenceFileShortType() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportNewHBaseAPI() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportCrossPlatformSubmission() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportImpersonation() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportEmbeddedMode() {\n-        return false;\n-    }\n-\n-    @Override\n-    public boolean doSupportStandaloneMode() {\n-        return super.doSupportStandaloneMode();\n-    }\n-   \n-    @Override\n-    public boolean doSupportHive1() {\n-        return false;\n-    }\n-\n-    @Override\n-    public boolean doSupportHive2() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportTezForHive() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportHBaseForHive() {\n-        return false;\n-    }\n-    @Override\n-    public boolean doSupportHBase2x() {\n-        return true;\n-    }\n-    @Override\n-    public boolean doSupportSSL() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportORCFormat() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportAvroFormat() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportParquetFormat() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportStoreAsParquet() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doJavaAPISupportStorePasswordInFile() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doJavaAPISqoopImportSupportDeleteTargetDir() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doJavaAPISqoopImportAllTablesSupportExcludeTable() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportClouderaNavigator() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportParquetOutput() {\n-        return true;\n-    }\n-\n-    @Override\n-    public Set<ESparkVersion> getSparkVersions() {\n-        Set<ESparkVersion> version = new HashSet<>();\n-        Set<ESparkVersion> sparkVersions = super.getSparkVersions();\n-        if (sparkVersions == null || sparkVersions.isEmpty()) {\n-            version.add(ESparkVersion.SPARK_2_2);\n-        } else {\n-            version.addAll(sparkVersions);\n-        }\n-        return version;\n-    }\n-\n-    @Override\n-    public boolean isExecutedThroughSparkJobServer() {\n-        return false;\n-    }\n-\n-    @Override\n-    public boolean doSupportSparkStandaloneMode() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportSparkYarnClientMode() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportDynamicMemoryAllocation() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportSSLwithKerberos() {\n-        return true;\n-    }\n-\n-    @Override\n-    public int getClouderaNavigatorAPIVersion() {\n-        return 9;\n-    }\n-\n-    @Override\n-    public boolean doSupportCheckpointing() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportBackpressure() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportAzureBlobStorage() {\n-        return true;\n-    }\n-\n-    @Override\n-    public short orderingWeight() {\n-        return 10;\n-    }\n-\n-    @Override\n-    public boolean doImportDynamoDBDependencies() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportAssumeRole() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportAvroDeflateProperties() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean useOldAWSAPI() {\n-        return false;\n-    }\n-\n-    @Override\n-    public String getSuffixParquetPackage() {\n-    \treturn \"org.apache.\";\n-    }\n-    @Override\n-    public KuduVersion getKuduVersion() {\n-        return KuduVersion.KUDU_1_12;\n-    }\n+public class CDP7xDistributionTemplate extends AbstractDynamicCDPDistributionTemplate\n+\t\timplements HDFSComponent, HBaseComponent, HCatalogComponent, MRComponent, HiveComponent, HiveOnSparkComponent,\n+\t\tImpalaComponent, SqoopComponent, CDPSparkBatchComponent, SparkStreamingComponent, ICDP7xDistributionTemplate {\n+\tprivate final static String SEPARATOR = \",\";\n+\tpublic final static String DEFAULT_LIB_ROOT = \"/opt/cloudera/parcels/CDH/lib\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "originalPosition": 239}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTIzODkzNw==", "bodyText": "I wonder why those Spark libs are not needed anymore and how they can't miss at job compilation", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r455238937", "createdAt": "2020-07-15T18:00:06Z", "author": {"login": "lbourgeois"}, "path": "main/plugins/org.talend.hadoop.distribution.cdp/resources/builtin/cdp/Cloudera_CDP_7_1_1.json", "diffHunk": "@@ -4702,90 +4534,18 @@\n         \"childNodes\" : [ ],\n         \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_protobuf_java_2_5_0_jar\",\n         \"tagName\" : \"library\"\n-      }, {\n-        \"childNodes\" : [ ],\n-        \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_py4j_0_10_7_jar\",\n-        \"tagName\" : \"library\"\n-      }, {\n-        \"childNodes\" : [ ],\n-        \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_pyrolite_4_13_jar\",\n-        \"tagName\" : \"library\"\n       }, {\n         \"childNodes\" : [ ],\n         \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_re2j_1_2_jar\",\n         \"tagName\" : \"library\"\n-      }, {\n-        \"childNodes\" : [ ],\n-        \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_reflections_0_9_10_jar\",\n-        \"tagName\" : \"library\"\n-      }, {\n-        \"childNodes\" : [ ],\n-        \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_scala_compiler_2_11_0_jar\",\n-        \"tagName\" : \"library\"\n-      }, {\n-        \"childNodes\" : [ ],\n-        \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_scala_library_2_11_12_jar\",\n-        \"tagName\" : \"library\"\n-      }, {\n-        \"childNodes\" : [ ],\n-        \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_scala_parser_combinators_2_11_1_1_0_jar\",\n-        \"tagName\" : \"library\"\n-      }, {\n-        \"childNodes\" : [ ],\n-        \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_scala_reflect_2_11_12_jar\",\n-        \"tagName\" : \"library\"\n-      }, {\n-        \"childNodes\" : [ ],\n-        \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_scala_xml_2_11_1_0_6_jar\",\n-        \"tagName\" : \"library\"\n-      }, {\n-        \"childNodes\" : [ ],\n-        \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_scalap_2_11_0_jar\",\n-        \"tagName\" : \"library\"\n-      }, {\n-        \"childNodes\" : [ ],\n-        \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_sketches_core_0_9_0_jar\",\n-        \"tagName\" : \"library\"\n       }, {\n         \"childNodes\" : [ ],\n         \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_slf4j_api_1_7_30_jar\",\n         \"tagName\" : \"library\"\n-      }, {\n-        \"childNodes\" : [ ],\n-        \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_snakeyaml_1_24_jar\",\n-        \"tagName\" : \"library\"\n       }, {\n         \"childNodes\" : [ ],\n         \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_snappy_java_1_1_7_5_jar\",\n         \"tagName\" : \"library\"\n-      }, {\n-        \"childNodes\" : [ ],\n-        \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_spark_core_2_11_2_4_0_7_1_1_0_565_jar\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "originalPosition": 436}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d4597cb6f8898bc29fab7b268b2d3d6ab8f8b557", "author": {"user": {"login": "Redwene", "name": "Redwene"}}, "url": "https://github.com/Talend/tbd-studio-se/commit/d4597cb6f8898bc29fab7b268b2d3d6ab8f8b557", "committedDate": "2020-07-16T04:56:06Z", "message": "fix default value"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a4fc1ece433eddc9265240179623bc4e06b147bb", "author": {"user": {"login": "Redwene", "name": "Redwene"}}, "url": "https://github.com/Talend/tbd-studio-se/commit/a4fc1ece433eddc9265240179623bc4e06b147bb", "committedDate": "2020-07-16T04:57:51Z", "message": "set log level for impala driver"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5569d60b2db0afef120c357e3fb85b65b1719bc7", "author": {"user": {"login": "Redwene", "name": "Redwene"}}, "url": "https://github.com/Talend/tbd-studio-se/commit/5569d60b2db0afef120c357e3fb85b65b1719bc7", "committedDate": "2020-07-16T05:28:21Z", "message": "use log activation from advanced setting"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "aef9c346b4effc1348bde8ba005d63547d65ccfe", "author": {"user": {"login": "Redwene", "name": "Redwene"}}, "url": "https://github.com/Talend/tbd-studio-se/commit/aef9c346b4effc1348bde8ba005d63547d65ccfe", "committedDate": "2020-07-16T05:29:48Z", "message": "modification following the PR ssl activation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a6494ed717d2ddb3c67cf76126500d1f6844a3f5", "author": {"user": {"login": "Redwene", "name": "Redwene"}}, "url": "https://github.com/Talend/tbd-studio-se/commit/a6494ed717d2ddb3c67cf76126500d1f6844a3f5", "committedDate": "2020-07-16T05:34:27Z", "message": "following alix's PR"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2990a05aff1e79f3b96aa948097edcce54819f6f", "author": {"user": {"login": "Redwene", "name": "Redwene"}}, "url": "https://github.com/Talend/tbd-studio-se/commit/2990a05aff1e79f3b96aa948097edcce54819f6f", "committedDate": "2020-07-16T05:37:21Z", "message": "Following Alix's review"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "48dca28999086f08bfeee6530dddc28317a478b6", "author": {"user": {"login": "Redwene", "name": "Redwene"}}, "url": "https://github.com/Talend/tbd-studio-se/commit/48dca28999086f08bfeee6530dddc28317a478b6", "committedDate": "2020-07-16T06:01:19Z", "message": "kerberos part"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "54c3c0daf4100c9ad701a18fcc1cc25b656c5600", "author": {"user": {"login": "Redwene", "name": "Redwene"}}, "url": "https://github.com/Talend/tbd-studio-se/commit/54c3c0daf4100c9ad701a18fcc1cc25b656c5600", "committedDate": "2020-07-16T07:22:35Z", "message": "fix issue No suitable driver found"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ5NTc2NjU3", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#pullrequestreview-449576657", "createdAt": "2020-07-16T07:28:25Z", "commit": {"oid": "54c3c0daf4100c9ad701a18fcc1cc25b656c5600"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ5NTg2NjYw", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#pullrequestreview-449586660", "createdAt": "2020-07-16T07:36:12Z", "commit": {"oid": "54c3c0daf4100c9ad701a18fcc1cc25b656c5600"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4772, "cost": 1, "resetAt": "2021-11-02T12:20:56Z"}}}