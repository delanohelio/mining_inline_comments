{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDM2NDczMzQ4", "number": 1459, "reviewThreads": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQwODoxOTozM1rOEOlBmg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQxODowMDowNlrOEOy90g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzNzIyMTM4OnYy", "diffSide": "RIGHT", "path": "main/plugins/org.talend.hadoop.distribution.cdp/src/main/java/org/talend/hadoop/distribution/cdp/CDP7xDistributionTemplate.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQwODoxOTozM1rOGxzcJw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQwNTozNToyNlrOGyawjg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg3NjE5OQ==", "bodyText": "should not it be spark 24 ?", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r454876199", "createdAt": "2020-07-15T08:19:33Z", "author": {"login": "AlixMetivier"}, "path": "main/plugins/org.talend.hadoop.distribution.cdp/src/main/java/org/talend/hadoop/distribution/cdp/CDP7xDistributionTemplate.java", "diffHunk": "@@ -33,227 +34,253 @@\n import org.talend.hadoop.distribution.kudu.KuduVersion;\n \n @SuppressWarnings(\"nls\")\n-public class CDP7xDistributionTemplate extends AbstractDynamicCDPDistributionTemplate implements HDFSComponent, HBaseComponent,\n-        HCatalogComponent, MRComponent, HiveComponent, HiveOnSparkComponent, ImpalaComponent, SqoopComponent,\n- CDPSparkBatchComponent, SparkStreamingComponent, ICDP7xDistributionTemplate {\n-\n-    public final static String TEMPLATE_ID = \"CDP7xDistributionTemplate\";\n-  \n-    private final static String YARN_APPLICATION_CLASSPATH = \"/opt/cloudera/parcels/CDH/lib/spark/jars/*,\" + \n-    \t\t\"/opt/cloudera/parcels/CDH/lib/hive/lib/*,\" + \n-    \t\t\"/opt/cloudera/parcels/CDH/lib/impala/lib/*,\"+\n-    \t\t\"/opt/cloudera/parcels/CDH/lib/hbase/lib/*,\"+\n-    \t\t\"/opt/cloudera/parcels/CDH/lib/kudu/*\";\n-\n-    public CDP7xDistributionTemplate(DynamicPluginAdapter pluginAdapter) throws Exception {\n-        super(pluginAdapter);\n-    }\n-\n-    @Override\n-    public String getTemplateId() {\n-        return TEMPLATE_ID;\n-    }\n-\n-    @Override\n-    public String getYarnApplicationClasspath() {\n-    \treturn YARN_APPLICATION_CLASSPATH;\n-    }\n-    \n-    @Override\n-    public String generateSparkJarsPaths(List<String> commandLineJarsPaths) {\n-        return getYarnApplicationClasspath() ;\n-    }\n-    @Override\n-    public boolean doSupportSequenceFileShortType() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportNewHBaseAPI() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportCrossPlatformSubmission() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportImpersonation() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportEmbeddedMode() {\n-        return false;\n-    }\n-\n-    @Override\n-    public boolean doSupportStandaloneMode() {\n-        return super.doSupportStandaloneMode();\n-    }\n-   \n-    @Override\n-    public boolean doSupportHive1() {\n-        return false;\n-    }\n-\n-    @Override\n-    public boolean doSupportHive2() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportTezForHive() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportHBaseForHive() {\n-        return false;\n-    }\n-    @Override\n-    public boolean doSupportHBase2x() {\n-        return true;\n-    }\n-    @Override\n-    public boolean doSupportSSL() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportORCFormat() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportAvroFormat() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportParquetFormat() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportStoreAsParquet() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doJavaAPISupportStorePasswordInFile() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doJavaAPISqoopImportSupportDeleteTargetDir() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doJavaAPISqoopImportAllTablesSupportExcludeTable() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportClouderaNavigator() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportParquetOutput() {\n-        return true;\n-    }\n-\n-    @Override\n-    public Set<ESparkVersion> getSparkVersions() {\n-        Set<ESparkVersion> version = new HashSet<>();\n-        Set<ESparkVersion> sparkVersions = super.getSparkVersions();\n-        if (sparkVersions == null || sparkVersions.isEmpty()) {\n-            version.add(ESparkVersion.SPARK_2_2);\n-        } else {\n-            version.addAll(sparkVersions);\n-        }\n-        return version;\n-    }\n-\n-    @Override\n-    public boolean isExecutedThroughSparkJobServer() {\n-        return false;\n-    }\n-\n-    @Override\n-    public boolean doSupportSparkStandaloneMode() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportSparkYarnClientMode() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportDynamicMemoryAllocation() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportSSLwithKerberos() {\n-        return true;\n-    }\n-\n-    @Override\n-    public int getClouderaNavigatorAPIVersion() {\n-        return 9;\n-    }\n-\n-    @Override\n-    public boolean doSupportCheckpointing() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportBackpressure() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportAzureBlobStorage() {\n-        return true;\n-    }\n-\n-    @Override\n-    public short orderingWeight() {\n-        return 10;\n-    }\n-\n-    @Override\n-    public boolean doImportDynamoDBDependencies() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportAssumeRole() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportAvroDeflateProperties() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean useOldAWSAPI() {\n-        return false;\n-    }\n-\n-    @Override\n-    public String getSuffixParquetPackage() {\n-    \treturn \"org.apache.\";\n-    }\n-    @Override\n-    public KuduVersion getKuduVersion() {\n-        return KuduVersion.KUDU_1_12;\n-    }\n+public class CDP7xDistributionTemplate extends AbstractDynamicCDPDistributionTemplate\n+\t\timplements HDFSComponent, HBaseComponent, HCatalogComponent, MRComponent, HiveComponent, HiveOnSparkComponent,\n+\t\tImpalaComponent, SqoopComponent, CDPSparkBatchComponent, SparkStreamingComponent, ICDP7xDistributionTemplate {\n+\tprivate final static String SEPARATOR = \",\";\n+\tpublic final static String DEFAULT_LIB_ROOT = \"/opt/cloudera/parcels/CDH/lib\";\n+\tpublic final static String TEMPLATE_ID = \"CDP7xDistributionTemplate\";\n+\n+\tprivate final static String YARN_APPLICATION_CLASSPATH = \n+\t\t\tDEFAULT_LIB_ROOT + \"/spark/jars/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/hive/lib/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/impala/lib/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/hbase/lib/*\" + SEPARATOR\n+\t\t\t+ DEFAULT_LIB_ROOT + \"/sqoop/lib/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/kudu/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/hadoop-mapreduce/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/hadoop-yarn/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/hadoop-yarn/lib/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/avro/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/hadoop/lib/*\";\n+\n+\tpublic CDP7xDistributionTemplate(DynamicPluginAdapter pluginAdapter) throws Exception {\n+\t\tsuper(pluginAdapter);\n+\t}\n+\t@Override\n+\tpublic boolean doSupportImpalaConnector() {\n+\t\t\n+\t\treturn true;\n+\t}\n+\t@Override\n+\tpublic boolean doImpalaSupportSSL() {\n+\t\t\n+\t\treturn true;\n+\t}\n+\t@Override\n+\tpublic String getSqoopPackageName() {\n+\t\treturn ESqoopPackageName.ORG_APACHE_SQOOP.toString();\n+\t}\n+\n+\t@Override\n+\tpublic String getTemplateId() {\n+\t\treturn TEMPLATE_ID;\n+\t}\n+\n+\t@Override\n+\tpublic String getYarnApplicationClasspath() {\n+\t\treturn YARN_APPLICATION_CLASSPATH;\n+\t}\n+\n+\t@Override\n+\tpublic String generateSparkJarsPaths(List<String> commandLineJarsPaths) {\n+\t\treturn getYarnApplicationClasspath();\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportSequenceFileShortType() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportNewHBaseAPI() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportCrossPlatformSubmission() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportImpersonation() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportEmbeddedMode() {\n+\t\treturn false;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportStandaloneMode() {\n+\t\treturn super.doSupportStandaloneMode();\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportHive1() {\n+\t\treturn false;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportHive2() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportTezForHive() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportHBaseForHive() {\n+\t\treturn false;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportHBase2x() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportSSL() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportORCFormat() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportAvroFormat() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportParquetFormat() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportStoreAsParquet() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doJavaAPISupportStorePasswordInFile() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doJavaAPISqoopImportSupportDeleteTargetDir() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doJavaAPISqoopImportAllTablesSupportExcludeTable() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportClouderaNavigator() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportParquetOutput() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic Set<ESparkVersion> getSparkVersions() {\n+\t\tSet<ESparkVersion> version = new HashSet<>();\n+\t\tSet<ESparkVersion> sparkVersions = super.getSparkVersions();\n+\t\tif (sparkVersions == null || sparkVersions.isEmpty()) {\n+\t\t\tversion.add(ESparkVersion.SPARK_2_2);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "originalPosition": 398}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ5OTU0MA==", "bodyText": "yes will fix it", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r455499540", "createdAt": "2020-07-16T04:14:40Z", "author": {"login": "Redwene"}, "path": "main/plugins/org.talend.hadoop.distribution.cdp/src/main/java/org/talend/hadoop/distribution/cdp/CDP7xDistributionTemplate.java", "diffHunk": "@@ -33,227 +34,253 @@\n import org.talend.hadoop.distribution.kudu.KuduVersion;\n \n @SuppressWarnings(\"nls\")\n-public class CDP7xDistributionTemplate extends AbstractDynamicCDPDistributionTemplate implements HDFSComponent, HBaseComponent,\n-        HCatalogComponent, MRComponent, HiveComponent, HiveOnSparkComponent, ImpalaComponent, SqoopComponent,\n- CDPSparkBatchComponent, SparkStreamingComponent, ICDP7xDistributionTemplate {\n-\n-    public final static String TEMPLATE_ID = \"CDP7xDistributionTemplate\";\n-  \n-    private final static String YARN_APPLICATION_CLASSPATH = \"/opt/cloudera/parcels/CDH/lib/spark/jars/*,\" + \n-    \t\t\"/opt/cloudera/parcels/CDH/lib/hive/lib/*,\" + \n-    \t\t\"/opt/cloudera/parcels/CDH/lib/impala/lib/*,\"+\n-    \t\t\"/opt/cloudera/parcels/CDH/lib/hbase/lib/*,\"+\n-    \t\t\"/opt/cloudera/parcels/CDH/lib/kudu/*\";\n-\n-    public CDP7xDistributionTemplate(DynamicPluginAdapter pluginAdapter) throws Exception {\n-        super(pluginAdapter);\n-    }\n-\n-    @Override\n-    public String getTemplateId() {\n-        return TEMPLATE_ID;\n-    }\n-\n-    @Override\n-    public String getYarnApplicationClasspath() {\n-    \treturn YARN_APPLICATION_CLASSPATH;\n-    }\n-    \n-    @Override\n-    public String generateSparkJarsPaths(List<String> commandLineJarsPaths) {\n-        return getYarnApplicationClasspath() ;\n-    }\n-    @Override\n-    public boolean doSupportSequenceFileShortType() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportNewHBaseAPI() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportCrossPlatformSubmission() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportImpersonation() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportEmbeddedMode() {\n-        return false;\n-    }\n-\n-    @Override\n-    public boolean doSupportStandaloneMode() {\n-        return super.doSupportStandaloneMode();\n-    }\n-   \n-    @Override\n-    public boolean doSupportHive1() {\n-        return false;\n-    }\n-\n-    @Override\n-    public boolean doSupportHive2() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportTezForHive() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportHBaseForHive() {\n-        return false;\n-    }\n-    @Override\n-    public boolean doSupportHBase2x() {\n-        return true;\n-    }\n-    @Override\n-    public boolean doSupportSSL() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportORCFormat() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportAvroFormat() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportParquetFormat() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportStoreAsParquet() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doJavaAPISupportStorePasswordInFile() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doJavaAPISqoopImportSupportDeleteTargetDir() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doJavaAPISqoopImportAllTablesSupportExcludeTable() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportClouderaNavigator() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportParquetOutput() {\n-        return true;\n-    }\n-\n-    @Override\n-    public Set<ESparkVersion> getSparkVersions() {\n-        Set<ESparkVersion> version = new HashSet<>();\n-        Set<ESparkVersion> sparkVersions = super.getSparkVersions();\n-        if (sparkVersions == null || sparkVersions.isEmpty()) {\n-            version.add(ESparkVersion.SPARK_2_2);\n-        } else {\n-            version.addAll(sparkVersions);\n-        }\n-        return version;\n-    }\n-\n-    @Override\n-    public boolean isExecutedThroughSparkJobServer() {\n-        return false;\n-    }\n-\n-    @Override\n-    public boolean doSupportSparkStandaloneMode() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportSparkYarnClientMode() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportDynamicMemoryAllocation() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportSSLwithKerberos() {\n-        return true;\n-    }\n-\n-    @Override\n-    public int getClouderaNavigatorAPIVersion() {\n-        return 9;\n-    }\n-\n-    @Override\n-    public boolean doSupportCheckpointing() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportBackpressure() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportAzureBlobStorage() {\n-        return true;\n-    }\n-\n-    @Override\n-    public short orderingWeight() {\n-        return 10;\n-    }\n-\n-    @Override\n-    public boolean doImportDynamoDBDependencies() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportAssumeRole() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportAvroDeflateProperties() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean useOldAWSAPI() {\n-        return false;\n-    }\n-\n-    @Override\n-    public String getSuffixParquetPackage() {\n-    \treturn \"org.apache.\";\n-    }\n-    @Override\n-    public KuduVersion getKuduVersion() {\n-        return KuduVersion.KUDU_1_12;\n-    }\n+public class CDP7xDistributionTemplate extends AbstractDynamicCDPDistributionTemplate\n+\t\timplements HDFSComponent, HBaseComponent, HCatalogComponent, MRComponent, HiveComponent, HiveOnSparkComponent,\n+\t\tImpalaComponent, SqoopComponent, CDPSparkBatchComponent, SparkStreamingComponent, ICDP7xDistributionTemplate {\n+\tprivate final static String SEPARATOR = \",\";\n+\tpublic final static String DEFAULT_LIB_ROOT = \"/opt/cloudera/parcels/CDH/lib\";\n+\tpublic final static String TEMPLATE_ID = \"CDP7xDistributionTemplate\";\n+\n+\tprivate final static String YARN_APPLICATION_CLASSPATH = \n+\t\t\tDEFAULT_LIB_ROOT + \"/spark/jars/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/hive/lib/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/impala/lib/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/hbase/lib/*\" + SEPARATOR\n+\t\t\t+ DEFAULT_LIB_ROOT + \"/sqoop/lib/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/kudu/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/hadoop-mapreduce/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/hadoop-yarn/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/hadoop-yarn/lib/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/avro/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/hadoop/lib/*\";\n+\n+\tpublic CDP7xDistributionTemplate(DynamicPluginAdapter pluginAdapter) throws Exception {\n+\t\tsuper(pluginAdapter);\n+\t}\n+\t@Override\n+\tpublic boolean doSupportImpalaConnector() {\n+\t\t\n+\t\treturn true;\n+\t}\n+\t@Override\n+\tpublic boolean doImpalaSupportSSL() {\n+\t\t\n+\t\treturn true;\n+\t}\n+\t@Override\n+\tpublic String getSqoopPackageName() {\n+\t\treturn ESqoopPackageName.ORG_APACHE_SQOOP.toString();\n+\t}\n+\n+\t@Override\n+\tpublic String getTemplateId() {\n+\t\treturn TEMPLATE_ID;\n+\t}\n+\n+\t@Override\n+\tpublic String getYarnApplicationClasspath() {\n+\t\treturn YARN_APPLICATION_CLASSPATH;\n+\t}\n+\n+\t@Override\n+\tpublic String generateSparkJarsPaths(List<String> commandLineJarsPaths) {\n+\t\treturn getYarnApplicationClasspath();\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportSequenceFileShortType() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportNewHBaseAPI() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportCrossPlatformSubmission() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportImpersonation() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportEmbeddedMode() {\n+\t\treturn false;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportStandaloneMode() {\n+\t\treturn super.doSupportStandaloneMode();\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportHive1() {\n+\t\treturn false;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportHive2() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportTezForHive() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportHBaseForHive() {\n+\t\treturn false;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportHBase2x() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportSSL() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportORCFormat() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportAvroFormat() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportParquetFormat() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportStoreAsParquet() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doJavaAPISupportStorePasswordInFile() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doJavaAPISqoopImportSupportDeleteTargetDir() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doJavaAPISqoopImportAllTablesSupportExcludeTable() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportClouderaNavigator() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportParquetOutput() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic Set<ESparkVersion> getSparkVersions() {\n+\t\tSet<ESparkVersion> version = new HashSet<>();\n+\t\tSet<ESparkVersion> sparkVersions = super.getSparkVersions();\n+\t\tif (sparkVersions == null || sparkVersions.isEmpty()) {\n+\t\t\tversion.add(ESparkVersion.SPARK_2_2);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg3NjE5OQ=="}, "originalCommit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "originalPosition": 398}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTUyMDM5OA==", "bodyText": "done", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r455520398", "createdAt": "2020-07-16T05:35:26Z", "author": {"login": "Redwene"}, "path": "main/plugins/org.talend.hadoop.distribution.cdp/src/main/java/org/talend/hadoop/distribution/cdp/CDP7xDistributionTemplate.java", "diffHunk": "@@ -33,227 +34,253 @@\n import org.talend.hadoop.distribution.kudu.KuduVersion;\n \n @SuppressWarnings(\"nls\")\n-public class CDP7xDistributionTemplate extends AbstractDynamicCDPDistributionTemplate implements HDFSComponent, HBaseComponent,\n-        HCatalogComponent, MRComponent, HiveComponent, HiveOnSparkComponent, ImpalaComponent, SqoopComponent,\n- CDPSparkBatchComponent, SparkStreamingComponent, ICDP7xDistributionTemplate {\n-\n-    public final static String TEMPLATE_ID = \"CDP7xDistributionTemplate\";\n-  \n-    private final static String YARN_APPLICATION_CLASSPATH = \"/opt/cloudera/parcels/CDH/lib/spark/jars/*,\" + \n-    \t\t\"/opt/cloudera/parcels/CDH/lib/hive/lib/*,\" + \n-    \t\t\"/opt/cloudera/parcels/CDH/lib/impala/lib/*,\"+\n-    \t\t\"/opt/cloudera/parcels/CDH/lib/hbase/lib/*,\"+\n-    \t\t\"/opt/cloudera/parcels/CDH/lib/kudu/*\";\n-\n-    public CDP7xDistributionTemplate(DynamicPluginAdapter pluginAdapter) throws Exception {\n-        super(pluginAdapter);\n-    }\n-\n-    @Override\n-    public String getTemplateId() {\n-        return TEMPLATE_ID;\n-    }\n-\n-    @Override\n-    public String getYarnApplicationClasspath() {\n-    \treturn YARN_APPLICATION_CLASSPATH;\n-    }\n-    \n-    @Override\n-    public String generateSparkJarsPaths(List<String> commandLineJarsPaths) {\n-        return getYarnApplicationClasspath() ;\n-    }\n-    @Override\n-    public boolean doSupportSequenceFileShortType() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportNewHBaseAPI() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportCrossPlatformSubmission() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportImpersonation() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportEmbeddedMode() {\n-        return false;\n-    }\n-\n-    @Override\n-    public boolean doSupportStandaloneMode() {\n-        return super.doSupportStandaloneMode();\n-    }\n-   \n-    @Override\n-    public boolean doSupportHive1() {\n-        return false;\n-    }\n-\n-    @Override\n-    public boolean doSupportHive2() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportTezForHive() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportHBaseForHive() {\n-        return false;\n-    }\n-    @Override\n-    public boolean doSupportHBase2x() {\n-        return true;\n-    }\n-    @Override\n-    public boolean doSupportSSL() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportORCFormat() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportAvroFormat() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportParquetFormat() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportStoreAsParquet() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doJavaAPISupportStorePasswordInFile() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doJavaAPISqoopImportSupportDeleteTargetDir() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doJavaAPISqoopImportAllTablesSupportExcludeTable() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportClouderaNavigator() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportParquetOutput() {\n-        return true;\n-    }\n-\n-    @Override\n-    public Set<ESparkVersion> getSparkVersions() {\n-        Set<ESparkVersion> version = new HashSet<>();\n-        Set<ESparkVersion> sparkVersions = super.getSparkVersions();\n-        if (sparkVersions == null || sparkVersions.isEmpty()) {\n-            version.add(ESparkVersion.SPARK_2_2);\n-        } else {\n-            version.addAll(sparkVersions);\n-        }\n-        return version;\n-    }\n-\n-    @Override\n-    public boolean isExecutedThroughSparkJobServer() {\n-        return false;\n-    }\n-\n-    @Override\n-    public boolean doSupportSparkStandaloneMode() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportSparkYarnClientMode() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportDynamicMemoryAllocation() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportSSLwithKerberos() {\n-        return true;\n-    }\n-\n-    @Override\n-    public int getClouderaNavigatorAPIVersion() {\n-        return 9;\n-    }\n-\n-    @Override\n-    public boolean doSupportCheckpointing() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportBackpressure() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportAzureBlobStorage() {\n-        return true;\n-    }\n-\n-    @Override\n-    public short orderingWeight() {\n-        return 10;\n-    }\n-\n-    @Override\n-    public boolean doImportDynamoDBDependencies() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportAssumeRole() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportAvroDeflateProperties() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean useOldAWSAPI() {\n-        return false;\n-    }\n-\n-    @Override\n-    public String getSuffixParquetPackage() {\n-    \treturn \"org.apache.\";\n-    }\n-    @Override\n-    public KuduVersion getKuduVersion() {\n-        return KuduVersion.KUDU_1_12;\n-    }\n+public class CDP7xDistributionTemplate extends AbstractDynamicCDPDistributionTemplate\n+\t\timplements HDFSComponent, HBaseComponent, HCatalogComponent, MRComponent, HiveComponent, HiveOnSparkComponent,\n+\t\tImpalaComponent, SqoopComponent, CDPSparkBatchComponent, SparkStreamingComponent, ICDP7xDistributionTemplate {\n+\tprivate final static String SEPARATOR = \",\";\n+\tpublic final static String DEFAULT_LIB_ROOT = \"/opt/cloudera/parcels/CDH/lib\";\n+\tpublic final static String TEMPLATE_ID = \"CDP7xDistributionTemplate\";\n+\n+\tprivate final static String YARN_APPLICATION_CLASSPATH = \n+\t\t\tDEFAULT_LIB_ROOT + \"/spark/jars/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/hive/lib/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/impala/lib/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/hbase/lib/*\" + SEPARATOR\n+\t\t\t+ DEFAULT_LIB_ROOT + \"/sqoop/lib/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/kudu/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/hadoop-mapreduce/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/hadoop-yarn/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/hadoop-yarn/lib/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/avro/*\" + SEPARATOR \n+\t\t\t+ DEFAULT_LIB_ROOT + \"/hadoop/lib/*\";\n+\n+\tpublic CDP7xDistributionTemplate(DynamicPluginAdapter pluginAdapter) throws Exception {\n+\t\tsuper(pluginAdapter);\n+\t}\n+\t@Override\n+\tpublic boolean doSupportImpalaConnector() {\n+\t\t\n+\t\treturn true;\n+\t}\n+\t@Override\n+\tpublic boolean doImpalaSupportSSL() {\n+\t\t\n+\t\treturn true;\n+\t}\n+\t@Override\n+\tpublic String getSqoopPackageName() {\n+\t\treturn ESqoopPackageName.ORG_APACHE_SQOOP.toString();\n+\t}\n+\n+\t@Override\n+\tpublic String getTemplateId() {\n+\t\treturn TEMPLATE_ID;\n+\t}\n+\n+\t@Override\n+\tpublic String getYarnApplicationClasspath() {\n+\t\treturn YARN_APPLICATION_CLASSPATH;\n+\t}\n+\n+\t@Override\n+\tpublic String generateSparkJarsPaths(List<String> commandLineJarsPaths) {\n+\t\treturn getYarnApplicationClasspath();\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportSequenceFileShortType() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportNewHBaseAPI() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportCrossPlatformSubmission() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportImpersonation() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportEmbeddedMode() {\n+\t\treturn false;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportStandaloneMode() {\n+\t\treturn super.doSupportStandaloneMode();\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportHive1() {\n+\t\treturn false;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportHive2() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportTezForHive() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportHBaseForHive() {\n+\t\treturn false;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportHBase2x() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportSSL() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportORCFormat() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportAvroFormat() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportParquetFormat() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportStoreAsParquet() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doJavaAPISupportStorePasswordInFile() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doJavaAPISqoopImportSupportDeleteTargetDir() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doJavaAPISqoopImportAllTablesSupportExcludeTable() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportClouderaNavigator() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic boolean doSupportParquetOutput() {\n+\t\treturn true;\n+\t}\n+\n+\t@Override\n+\tpublic Set<ESparkVersion> getSparkVersions() {\n+\t\tSet<ESparkVersion> version = new HashSet<>();\n+\t\tSet<ESparkVersion> sparkVersions = super.getSparkVersions();\n+\t\tif (sparkVersions == null || sparkVersions.isEmpty()) {\n+\t\t\tversion.add(ESparkVersion.SPARK_2_2);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg3NjE5OQ=="}, "originalCommit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "originalPosition": 398}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzNzI0NDkxOnYy", "diffSide": "RIGHT", "path": "main/plugins/org.talend.designer.components.bigdata/components/tImpalaConnection/tImpalaConnectionUtil.javajet", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQwODoyNTozOFrOGxzqiw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQwNTozODoxOFrOGyazhQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg3OTg4Mw==", "bodyText": "can not be the case, you removed IMPALA40 and IMPALA41 to be IMPALA", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r454879883", "createdAt": "2020-07-15T08:25:38Z", "author": {"login": "AlixMetivier"}, "path": "main/plugins/org.talend.designer.components.bigdata/components/tImpalaConnection/tImpalaConnectionUtil.javajet", "diffHunk": "@@ -0,0 +1,309 @@\n+<%\n+\tclass ConnectionUtil extends DefaultConnectionUtil {\n+\t\tprivate String javaDbDriver = \"org.apache.hadoop.hive.jdbc.HiveDriver\";\n+\t\tprivate org.talend.hadoop.distribution.component.HiveComponent hiveDistrib;\n+\t\tprivate boolean isCustom;\n+\n+\t\tpublic ConnectionUtil(org.talend.hadoop.distribution.component.HiveComponent hiveDistrib) {\n+\t\t\tthis.hiveDistrib = hiveDistrib;\n+\t\t\tthis.isCustom = hiveDistrib instanceof org.talend.hadoop.distribution.custom.CustomDistribution;\n+\t\t}\n+\n+\t\tpublic void createConnection(INode node) {\n+\t\t\tString connectionMode = ElementParameterParser.getValue(node, \"__CONNECTION_MODE__\");\n+\t\t\tString hiveVersion = ElementParameterParser.getValue(node, \"__HIVE_VERSION__\");\n+\t\t\tboolean useKrb = \"true\".equals(ElementParameterParser.getValue(node, \"__USE_KRB__\"));\n+\t\t\tboolean securityIsEnabled = useKrb && (isCustom || this.hiveDistrib.doSupportKerberos());\n+%>\n+\t\t\tconn_<%=cid%> = java.sql.DriverManager.getConnection(url_<%=cid%>);\n+<%\n+\t\t}\n+\n+\t\tpublic void createURL(INode node) {\n+\t\t\tsuper.createURL(node);\n+\n+\t\t\tString additionalJdbcSettings = ElementParameterParser.getValue(node, \"__IMPALA_ADDITIONAL_JDBC__\");\n+\t\t\t\n+\t\t\tString hiveVersion = ElementParameterParser.getValue(node, \"__HIVE_VERSION__\");\n+\t\t\tString fsDefaultName = \"fs.default.name\";\n+\t\t\tString impalaDriver = ElementParameterParser.getValue(node, \"__IMPALA_DRIVER__\");\n+\t\t\tString impalaDbProtocol = \"hive2\";\n+\n+\t\t\tboolean setMapredJT = \"true\".equals(ElementParameterParser.getValue(node, \"__SET_MAPRED_JT__\"));\n+\t\t\tboolean setNamenode = \"true\".equals(ElementParameterParser.getValue(node, \"__SET_FS_DEFAULT_NAME__\"));\n+\t\t\tList<Map<String, String>> hadoopProps = (List<Map<String,String>>)ElementParameterParser.getObjectValue(node, \"__HADOOP_ADVANCED_PROPERTIES__\");\n+\n+\t\t\tboolean useYarn = \"true\".equals(ElementParameterParser.getValue(node, \"__USE_YARN__\"));\n+\n+\t\t\tboolean useKrb = \"true\".equals(ElementParameterParser.getValue(node, \"__USE_KRB__\"));\n+\t\t\tboolean securityIsEnabled = useKrb && ( this.isCustom || this.hiveDistrib.doSupportKerberos() );\n+\t\t\tString impalaPrincipal = ElementParameterParser.getValue(node, \"__IMPALA_PRINCIPAL__\");\n+\t\t\t\n+\t\t\tboolean useKeytab = \"true\".equals(ElementParameterParser.getValue(node, \"__USE_KEYTAB__\"));\n+\t\t\tString userPrincipal = ElementParameterParser.getValue(node, \"__PRINCIPAL__\");\n+\t\t\tString keytabPath = ElementParameterParser.getValue(node, \"__KEYTAB_PATH__\");\n+\t\t\t\n+\t\t\tboolean useSsl = \"true\".equals(ElementParameterParser.getValue(node, \"__USE_SSL__\"));\n+\t\t\tString sslTrustStore = ElementParameterParser.getValue(node, \"__SSL_TRUST_STORE__\");\n+\t\t\tString sslStorepasswordFieldName = \"__SSL_TRUST_STORE_PASSWORD__\";\n+\n+\t\t\tboolean configureFromClassPath = \"true\".equals(ElementParameterParser.getValue(node, \"__CONFIGURATIONS_FROM_CLASSPATH__\"));\n+\t\t\tboolean storeByHBase = \"true\".equals(ElementParameterParser.getValue(node, \"__STORE_BY_HBASE__\"));\n+\t\t    \n+\n+\t\t\tif(impalaDriver!=null && !\"\".equals(impalaDriver.trim()) && (this.isCustom || this.hiveDistrib.doSupportHive2())) {\n+\t\t\t    impalaDriver = impalaDriver.toLowerCase();\n+\t\t\t\tif (\"hive2\".equalsIgnoreCase(impalaDriver)) {\n+\t\t\t\t\tjavaDbDriver = \"org.apache.hive.jdbc.HiveDriver\";\n+\t\t\t\t\timpalaDbProtocol=\"hive2\";\n+\t\t\t\t}\n+\t\t\t\tif (\"impala40\".equalsIgnoreCase(impalaDriver)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ5OTI4Mw==", "bodyText": "yes old code copy/paste. I will fix it", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r455499283", "createdAt": "2020-07-16T04:13:34Z", "author": {"login": "Redwene"}, "path": "main/plugins/org.talend.designer.components.bigdata/components/tImpalaConnection/tImpalaConnectionUtil.javajet", "diffHunk": "@@ -0,0 +1,309 @@\n+<%\n+\tclass ConnectionUtil extends DefaultConnectionUtil {\n+\t\tprivate String javaDbDriver = \"org.apache.hadoop.hive.jdbc.HiveDriver\";\n+\t\tprivate org.talend.hadoop.distribution.component.HiveComponent hiveDistrib;\n+\t\tprivate boolean isCustom;\n+\n+\t\tpublic ConnectionUtil(org.talend.hadoop.distribution.component.HiveComponent hiveDistrib) {\n+\t\t\tthis.hiveDistrib = hiveDistrib;\n+\t\t\tthis.isCustom = hiveDistrib instanceof org.talend.hadoop.distribution.custom.CustomDistribution;\n+\t\t}\n+\n+\t\tpublic void createConnection(INode node) {\n+\t\t\tString connectionMode = ElementParameterParser.getValue(node, \"__CONNECTION_MODE__\");\n+\t\t\tString hiveVersion = ElementParameterParser.getValue(node, \"__HIVE_VERSION__\");\n+\t\t\tboolean useKrb = \"true\".equals(ElementParameterParser.getValue(node, \"__USE_KRB__\"));\n+\t\t\tboolean securityIsEnabled = useKrb && (isCustom || this.hiveDistrib.doSupportKerberos());\n+%>\n+\t\t\tconn_<%=cid%> = java.sql.DriverManager.getConnection(url_<%=cid%>);\n+<%\n+\t\t}\n+\n+\t\tpublic void createURL(INode node) {\n+\t\t\tsuper.createURL(node);\n+\n+\t\t\tString additionalJdbcSettings = ElementParameterParser.getValue(node, \"__IMPALA_ADDITIONAL_JDBC__\");\n+\t\t\t\n+\t\t\tString hiveVersion = ElementParameterParser.getValue(node, \"__HIVE_VERSION__\");\n+\t\t\tString fsDefaultName = \"fs.default.name\";\n+\t\t\tString impalaDriver = ElementParameterParser.getValue(node, \"__IMPALA_DRIVER__\");\n+\t\t\tString impalaDbProtocol = \"hive2\";\n+\n+\t\t\tboolean setMapredJT = \"true\".equals(ElementParameterParser.getValue(node, \"__SET_MAPRED_JT__\"));\n+\t\t\tboolean setNamenode = \"true\".equals(ElementParameterParser.getValue(node, \"__SET_FS_DEFAULT_NAME__\"));\n+\t\t\tList<Map<String, String>> hadoopProps = (List<Map<String,String>>)ElementParameterParser.getObjectValue(node, \"__HADOOP_ADVANCED_PROPERTIES__\");\n+\n+\t\t\tboolean useYarn = \"true\".equals(ElementParameterParser.getValue(node, \"__USE_YARN__\"));\n+\n+\t\t\tboolean useKrb = \"true\".equals(ElementParameterParser.getValue(node, \"__USE_KRB__\"));\n+\t\t\tboolean securityIsEnabled = useKrb && ( this.isCustom || this.hiveDistrib.doSupportKerberos() );\n+\t\t\tString impalaPrincipal = ElementParameterParser.getValue(node, \"__IMPALA_PRINCIPAL__\");\n+\t\t\t\n+\t\t\tboolean useKeytab = \"true\".equals(ElementParameterParser.getValue(node, \"__USE_KEYTAB__\"));\n+\t\t\tString userPrincipal = ElementParameterParser.getValue(node, \"__PRINCIPAL__\");\n+\t\t\tString keytabPath = ElementParameterParser.getValue(node, \"__KEYTAB_PATH__\");\n+\t\t\t\n+\t\t\tboolean useSsl = \"true\".equals(ElementParameterParser.getValue(node, \"__USE_SSL__\"));\n+\t\t\tString sslTrustStore = ElementParameterParser.getValue(node, \"__SSL_TRUST_STORE__\");\n+\t\t\tString sslStorepasswordFieldName = \"__SSL_TRUST_STORE_PASSWORD__\";\n+\n+\t\t\tboolean configureFromClassPath = \"true\".equals(ElementParameterParser.getValue(node, \"__CONFIGURATIONS_FROM_CLASSPATH__\"));\n+\t\t\tboolean storeByHBase = \"true\".equals(ElementParameterParser.getValue(node, \"__STORE_BY_HBASE__\"));\n+\t\t    \n+\n+\t\t\tif(impalaDriver!=null && !\"\".equals(impalaDriver.trim()) && (this.isCustom || this.hiveDistrib.doSupportHive2())) {\n+\t\t\t    impalaDriver = impalaDriver.toLowerCase();\n+\t\t\t\tif (\"hive2\".equalsIgnoreCase(impalaDriver)) {\n+\t\t\t\t\tjavaDbDriver = \"org.apache.hive.jdbc.HiveDriver\";\n+\t\t\t\t\timpalaDbProtocol=\"hive2\";\n+\t\t\t\t}\n+\t\t\t\tif (\"impala40\".equalsIgnoreCase(impalaDriver)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg3OTg4Mw=="}, "originalCommit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTUyMTE1Nw==", "bodyText": "done", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r455521157", "createdAt": "2020-07-16T05:38:18Z", "author": {"login": "Redwene"}, "path": "main/plugins/org.talend.designer.components.bigdata/components/tImpalaConnection/tImpalaConnectionUtil.javajet", "diffHunk": "@@ -0,0 +1,309 @@\n+<%\n+\tclass ConnectionUtil extends DefaultConnectionUtil {\n+\t\tprivate String javaDbDriver = \"org.apache.hadoop.hive.jdbc.HiveDriver\";\n+\t\tprivate org.talend.hadoop.distribution.component.HiveComponent hiveDistrib;\n+\t\tprivate boolean isCustom;\n+\n+\t\tpublic ConnectionUtil(org.talend.hadoop.distribution.component.HiveComponent hiveDistrib) {\n+\t\t\tthis.hiveDistrib = hiveDistrib;\n+\t\t\tthis.isCustom = hiveDistrib instanceof org.talend.hadoop.distribution.custom.CustomDistribution;\n+\t\t}\n+\n+\t\tpublic void createConnection(INode node) {\n+\t\t\tString connectionMode = ElementParameterParser.getValue(node, \"__CONNECTION_MODE__\");\n+\t\t\tString hiveVersion = ElementParameterParser.getValue(node, \"__HIVE_VERSION__\");\n+\t\t\tboolean useKrb = \"true\".equals(ElementParameterParser.getValue(node, \"__USE_KRB__\"));\n+\t\t\tboolean securityIsEnabled = useKrb && (isCustom || this.hiveDistrib.doSupportKerberos());\n+%>\n+\t\t\tconn_<%=cid%> = java.sql.DriverManager.getConnection(url_<%=cid%>);\n+<%\n+\t\t}\n+\n+\t\tpublic void createURL(INode node) {\n+\t\t\tsuper.createURL(node);\n+\n+\t\t\tString additionalJdbcSettings = ElementParameterParser.getValue(node, \"__IMPALA_ADDITIONAL_JDBC__\");\n+\t\t\t\n+\t\t\tString hiveVersion = ElementParameterParser.getValue(node, \"__HIVE_VERSION__\");\n+\t\t\tString fsDefaultName = \"fs.default.name\";\n+\t\t\tString impalaDriver = ElementParameterParser.getValue(node, \"__IMPALA_DRIVER__\");\n+\t\t\tString impalaDbProtocol = \"hive2\";\n+\n+\t\t\tboolean setMapredJT = \"true\".equals(ElementParameterParser.getValue(node, \"__SET_MAPRED_JT__\"));\n+\t\t\tboolean setNamenode = \"true\".equals(ElementParameterParser.getValue(node, \"__SET_FS_DEFAULT_NAME__\"));\n+\t\t\tList<Map<String, String>> hadoopProps = (List<Map<String,String>>)ElementParameterParser.getObjectValue(node, \"__HADOOP_ADVANCED_PROPERTIES__\");\n+\n+\t\t\tboolean useYarn = \"true\".equals(ElementParameterParser.getValue(node, \"__USE_YARN__\"));\n+\n+\t\t\tboolean useKrb = \"true\".equals(ElementParameterParser.getValue(node, \"__USE_KRB__\"));\n+\t\t\tboolean securityIsEnabled = useKrb && ( this.isCustom || this.hiveDistrib.doSupportKerberos() );\n+\t\t\tString impalaPrincipal = ElementParameterParser.getValue(node, \"__IMPALA_PRINCIPAL__\");\n+\t\t\t\n+\t\t\tboolean useKeytab = \"true\".equals(ElementParameterParser.getValue(node, \"__USE_KEYTAB__\"));\n+\t\t\tString userPrincipal = ElementParameterParser.getValue(node, \"__PRINCIPAL__\");\n+\t\t\tString keytabPath = ElementParameterParser.getValue(node, \"__KEYTAB_PATH__\");\n+\t\t\t\n+\t\t\tboolean useSsl = \"true\".equals(ElementParameterParser.getValue(node, \"__USE_SSL__\"));\n+\t\t\tString sslTrustStore = ElementParameterParser.getValue(node, \"__SSL_TRUST_STORE__\");\n+\t\t\tString sslStorepasswordFieldName = \"__SSL_TRUST_STORE_PASSWORD__\";\n+\n+\t\t\tboolean configureFromClassPath = \"true\".equals(ElementParameterParser.getValue(node, \"__CONFIGURATIONS_FROM_CLASSPATH__\"));\n+\t\t\tboolean storeByHBase = \"true\".equals(ElementParameterParser.getValue(node, \"__STORE_BY_HBASE__\"));\n+\t\t    \n+\n+\t\t\tif(impalaDriver!=null && !\"\".equals(impalaDriver.trim()) && (this.isCustom || this.hiveDistrib.doSupportHive2())) {\n+\t\t\t    impalaDriver = impalaDriver.toLowerCase();\n+\t\t\t\tif (\"hive2\".equalsIgnoreCase(impalaDriver)) {\n+\t\t\t\t\tjavaDbDriver = \"org.apache.hive.jdbc.HiveDriver\";\n+\t\t\t\t\timpalaDbProtocol=\"hive2\";\n+\t\t\t\t}\n+\t\t\t\tif (\"impala40\".equalsIgnoreCase(impalaDriver)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg3OTg4Mw=="}, "originalCommit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "originalPosition": 60}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzNzI0NTEzOnYy", "diffSide": "RIGHT", "path": "main/plugins/org.talend.designer.components.bigdata/components/tImpalaConnection/tImpalaConnectionUtil.javajet", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQwODoyNTo0M1rOGxzqrA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQwNjowNjo0NVrOGybWFw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg3OTkxNg==", "bodyText": "can not be the case, you removed IMPALA40 and IMPALA41 to be IMPALA", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r454879916", "createdAt": "2020-07-15T08:25:43Z", "author": {"login": "AlixMetivier"}, "path": "main/plugins/org.talend.designer.components.bigdata/components/tImpalaConnection/tImpalaConnectionUtil.javajet", "diffHunk": "@@ -0,0 +1,309 @@\n+<%\n+\tclass ConnectionUtil extends DefaultConnectionUtil {\n+\t\tprivate String javaDbDriver = \"org.apache.hadoop.hive.jdbc.HiveDriver\";\n+\t\tprivate org.talend.hadoop.distribution.component.HiveComponent hiveDistrib;\n+\t\tprivate boolean isCustom;\n+\n+\t\tpublic ConnectionUtil(org.talend.hadoop.distribution.component.HiveComponent hiveDistrib) {\n+\t\t\tthis.hiveDistrib = hiveDistrib;\n+\t\t\tthis.isCustom = hiveDistrib instanceof org.talend.hadoop.distribution.custom.CustomDistribution;\n+\t\t}\n+\n+\t\tpublic void createConnection(INode node) {\n+\t\t\tString connectionMode = ElementParameterParser.getValue(node, \"__CONNECTION_MODE__\");\n+\t\t\tString hiveVersion = ElementParameterParser.getValue(node, \"__HIVE_VERSION__\");\n+\t\t\tboolean useKrb = \"true\".equals(ElementParameterParser.getValue(node, \"__USE_KRB__\"));\n+\t\t\tboolean securityIsEnabled = useKrb && (isCustom || this.hiveDistrib.doSupportKerberos());\n+%>\n+\t\t\tconn_<%=cid%> = java.sql.DriverManager.getConnection(url_<%=cid%>);\n+<%\n+\t\t}\n+\n+\t\tpublic void createURL(INode node) {\n+\t\t\tsuper.createURL(node);\n+\n+\t\t\tString additionalJdbcSettings = ElementParameterParser.getValue(node, \"__IMPALA_ADDITIONAL_JDBC__\");\n+\t\t\t\n+\t\t\tString hiveVersion = ElementParameterParser.getValue(node, \"__HIVE_VERSION__\");\n+\t\t\tString fsDefaultName = \"fs.default.name\";\n+\t\t\tString impalaDriver = ElementParameterParser.getValue(node, \"__IMPALA_DRIVER__\");\n+\t\t\tString impalaDbProtocol = \"hive2\";\n+\n+\t\t\tboolean setMapredJT = \"true\".equals(ElementParameterParser.getValue(node, \"__SET_MAPRED_JT__\"));\n+\t\t\tboolean setNamenode = \"true\".equals(ElementParameterParser.getValue(node, \"__SET_FS_DEFAULT_NAME__\"));\n+\t\t\tList<Map<String, String>> hadoopProps = (List<Map<String,String>>)ElementParameterParser.getObjectValue(node, \"__HADOOP_ADVANCED_PROPERTIES__\");\n+\n+\t\t\tboolean useYarn = \"true\".equals(ElementParameterParser.getValue(node, \"__USE_YARN__\"));\n+\n+\t\t\tboolean useKrb = \"true\".equals(ElementParameterParser.getValue(node, \"__USE_KRB__\"));\n+\t\t\tboolean securityIsEnabled = useKrb && ( this.isCustom || this.hiveDistrib.doSupportKerberos() );\n+\t\t\tString impalaPrincipal = ElementParameterParser.getValue(node, \"__IMPALA_PRINCIPAL__\");\n+\t\t\t\n+\t\t\tboolean useKeytab = \"true\".equals(ElementParameterParser.getValue(node, \"__USE_KEYTAB__\"));\n+\t\t\tString userPrincipal = ElementParameterParser.getValue(node, \"__PRINCIPAL__\");\n+\t\t\tString keytabPath = ElementParameterParser.getValue(node, \"__KEYTAB_PATH__\");\n+\t\t\t\n+\t\t\tboolean useSsl = \"true\".equals(ElementParameterParser.getValue(node, \"__USE_SSL__\"));\n+\t\t\tString sslTrustStore = ElementParameterParser.getValue(node, \"__SSL_TRUST_STORE__\");\n+\t\t\tString sslStorepasswordFieldName = \"__SSL_TRUST_STORE_PASSWORD__\";\n+\n+\t\t\tboolean configureFromClassPath = \"true\".equals(ElementParameterParser.getValue(node, \"__CONFIGURATIONS_FROM_CLASSPATH__\"));\n+\t\t\tboolean storeByHBase = \"true\".equals(ElementParameterParser.getValue(node, \"__STORE_BY_HBASE__\"));\n+\t\t    \n+\n+\t\t\tif(impalaDriver!=null && !\"\".equals(impalaDriver.trim()) && (this.isCustom || this.hiveDistrib.doSupportHive2())) {\n+\t\t\t    impalaDriver = impalaDriver.toLowerCase();\n+\t\t\t\tif (\"hive2\".equalsIgnoreCase(impalaDriver)) {\n+\t\t\t\t\tjavaDbDriver = \"org.apache.hive.jdbc.HiveDriver\";\n+\t\t\t\t\timpalaDbProtocol=\"hive2\";\n+\t\t\t\t}\n+\t\t\t\tif (\"impala40\".equalsIgnoreCase(impalaDriver)) {\n+\t\t\t\t\tjavaDbDriver = \"com.cloudera.impala.jdbc4.Driver\";\n+\t\t\t\t\timpalaDbProtocol=\"impala\";\n+\t\t\t\t}\t\n+\t\t\t\tif (\"impala41\".equalsIgnoreCase(impalaDriver)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ5OTc3Mw==", "bodyText": "yes old code copy/paste. I will fix it", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r455499773", "createdAt": "2020-07-16T04:15:33Z", "author": {"login": "Redwene"}, "path": "main/plugins/org.talend.designer.components.bigdata/components/tImpalaConnection/tImpalaConnectionUtil.javajet", "diffHunk": "@@ -0,0 +1,309 @@\n+<%\n+\tclass ConnectionUtil extends DefaultConnectionUtil {\n+\t\tprivate String javaDbDriver = \"org.apache.hadoop.hive.jdbc.HiveDriver\";\n+\t\tprivate org.talend.hadoop.distribution.component.HiveComponent hiveDistrib;\n+\t\tprivate boolean isCustom;\n+\n+\t\tpublic ConnectionUtil(org.talend.hadoop.distribution.component.HiveComponent hiveDistrib) {\n+\t\t\tthis.hiveDistrib = hiveDistrib;\n+\t\t\tthis.isCustom = hiveDistrib instanceof org.talend.hadoop.distribution.custom.CustomDistribution;\n+\t\t}\n+\n+\t\tpublic void createConnection(INode node) {\n+\t\t\tString connectionMode = ElementParameterParser.getValue(node, \"__CONNECTION_MODE__\");\n+\t\t\tString hiveVersion = ElementParameterParser.getValue(node, \"__HIVE_VERSION__\");\n+\t\t\tboolean useKrb = \"true\".equals(ElementParameterParser.getValue(node, \"__USE_KRB__\"));\n+\t\t\tboolean securityIsEnabled = useKrb && (isCustom || this.hiveDistrib.doSupportKerberos());\n+%>\n+\t\t\tconn_<%=cid%> = java.sql.DriverManager.getConnection(url_<%=cid%>);\n+<%\n+\t\t}\n+\n+\t\tpublic void createURL(INode node) {\n+\t\t\tsuper.createURL(node);\n+\n+\t\t\tString additionalJdbcSettings = ElementParameterParser.getValue(node, \"__IMPALA_ADDITIONAL_JDBC__\");\n+\t\t\t\n+\t\t\tString hiveVersion = ElementParameterParser.getValue(node, \"__HIVE_VERSION__\");\n+\t\t\tString fsDefaultName = \"fs.default.name\";\n+\t\t\tString impalaDriver = ElementParameterParser.getValue(node, \"__IMPALA_DRIVER__\");\n+\t\t\tString impalaDbProtocol = \"hive2\";\n+\n+\t\t\tboolean setMapredJT = \"true\".equals(ElementParameterParser.getValue(node, \"__SET_MAPRED_JT__\"));\n+\t\t\tboolean setNamenode = \"true\".equals(ElementParameterParser.getValue(node, \"__SET_FS_DEFAULT_NAME__\"));\n+\t\t\tList<Map<String, String>> hadoopProps = (List<Map<String,String>>)ElementParameterParser.getObjectValue(node, \"__HADOOP_ADVANCED_PROPERTIES__\");\n+\n+\t\t\tboolean useYarn = \"true\".equals(ElementParameterParser.getValue(node, \"__USE_YARN__\"));\n+\n+\t\t\tboolean useKrb = \"true\".equals(ElementParameterParser.getValue(node, \"__USE_KRB__\"));\n+\t\t\tboolean securityIsEnabled = useKrb && ( this.isCustom || this.hiveDistrib.doSupportKerberos() );\n+\t\t\tString impalaPrincipal = ElementParameterParser.getValue(node, \"__IMPALA_PRINCIPAL__\");\n+\t\t\t\n+\t\t\tboolean useKeytab = \"true\".equals(ElementParameterParser.getValue(node, \"__USE_KEYTAB__\"));\n+\t\t\tString userPrincipal = ElementParameterParser.getValue(node, \"__PRINCIPAL__\");\n+\t\t\tString keytabPath = ElementParameterParser.getValue(node, \"__KEYTAB_PATH__\");\n+\t\t\t\n+\t\t\tboolean useSsl = \"true\".equals(ElementParameterParser.getValue(node, \"__USE_SSL__\"));\n+\t\t\tString sslTrustStore = ElementParameterParser.getValue(node, \"__SSL_TRUST_STORE__\");\n+\t\t\tString sslStorepasswordFieldName = \"__SSL_TRUST_STORE_PASSWORD__\";\n+\n+\t\t\tboolean configureFromClassPath = \"true\".equals(ElementParameterParser.getValue(node, \"__CONFIGURATIONS_FROM_CLASSPATH__\"));\n+\t\t\tboolean storeByHBase = \"true\".equals(ElementParameterParser.getValue(node, \"__STORE_BY_HBASE__\"));\n+\t\t    \n+\n+\t\t\tif(impalaDriver!=null && !\"\".equals(impalaDriver.trim()) && (this.isCustom || this.hiveDistrib.doSupportHive2())) {\n+\t\t\t    impalaDriver = impalaDriver.toLowerCase();\n+\t\t\t\tif (\"hive2\".equalsIgnoreCase(impalaDriver)) {\n+\t\t\t\t\tjavaDbDriver = \"org.apache.hive.jdbc.HiveDriver\";\n+\t\t\t\t\timpalaDbProtocol=\"hive2\";\n+\t\t\t\t}\n+\t\t\t\tif (\"impala40\".equalsIgnoreCase(impalaDriver)) {\n+\t\t\t\t\tjavaDbDriver = \"com.cloudera.impala.jdbc4.Driver\";\n+\t\t\t\t\timpalaDbProtocol=\"impala\";\n+\t\t\t\t}\t\n+\t\t\t\tif (\"impala41\".equalsIgnoreCase(impalaDriver)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg3OTkxNg=="}, "originalCommit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTUzMDAwNw==", "bodyText": "done", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r455530007", "createdAt": "2020-07-16T06:06:45Z", "author": {"login": "Redwene"}, "path": "main/plugins/org.talend.designer.components.bigdata/components/tImpalaConnection/tImpalaConnectionUtil.javajet", "diffHunk": "@@ -0,0 +1,309 @@\n+<%\n+\tclass ConnectionUtil extends DefaultConnectionUtil {\n+\t\tprivate String javaDbDriver = \"org.apache.hadoop.hive.jdbc.HiveDriver\";\n+\t\tprivate org.talend.hadoop.distribution.component.HiveComponent hiveDistrib;\n+\t\tprivate boolean isCustom;\n+\n+\t\tpublic ConnectionUtil(org.talend.hadoop.distribution.component.HiveComponent hiveDistrib) {\n+\t\t\tthis.hiveDistrib = hiveDistrib;\n+\t\t\tthis.isCustom = hiveDistrib instanceof org.talend.hadoop.distribution.custom.CustomDistribution;\n+\t\t}\n+\n+\t\tpublic void createConnection(INode node) {\n+\t\t\tString connectionMode = ElementParameterParser.getValue(node, \"__CONNECTION_MODE__\");\n+\t\t\tString hiveVersion = ElementParameterParser.getValue(node, \"__HIVE_VERSION__\");\n+\t\t\tboolean useKrb = \"true\".equals(ElementParameterParser.getValue(node, \"__USE_KRB__\"));\n+\t\t\tboolean securityIsEnabled = useKrb && (isCustom || this.hiveDistrib.doSupportKerberos());\n+%>\n+\t\t\tconn_<%=cid%> = java.sql.DriverManager.getConnection(url_<%=cid%>);\n+<%\n+\t\t}\n+\n+\t\tpublic void createURL(INode node) {\n+\t\t\tsuper.createURL(node);\n+\n+\t\t\tString additionalJdbcSettings = ElementParameterParser.getValue(node, \"__IMPALA_ADDITIONAL_JDBC__\");\n+\t\t\t\n+\t\t\tString hiveVersion = ElementParameterParser.getValue(node, \"__HIVE_VERSION__\");\n+\t\t\tString fsDefaultName = \"fs.default.name\";\n+\t\t\tString impalaDriver = ElementParameterParser.getValue(node, \"__IMPALA_DRIVER__\");\n+\t\t\tString impalaDbProtocol = \"hive2\";\n+\n+\t\t\tboolean setMapredJT = \"true\".equals(ElementParameterParser.getValue(node, \"__SET_MAPRED_JT__\"));\n+\t\t\tboolean setNamenode = \"true\".equals(ElementParameterParser.getValue(node, \"__SET_FS_DEFAULT_NAME__\"));\n+\t\t\tList<Map<String, String>> hadoopProps = (List<Map<String,String>>)ElementParameterParser.getObjectValue(node, \"__HADOOP_ADVANCED_PROPERTIES__\");\n+\n+\t\t\tboolean useYarn = \"true\".equals(ElementParameterParser.getValue(node, \"__USE_YARN__\"));\n+\n+\t\t\tboolean useKrb = \"true\".equals(ElementParameterParser.getValue(node, \"__USE_KRB__\"));\n+\t\t\tboolean securityIsEnabled = useKrb && ( this.isCustom || this.hiveDistrib.doSupportKerberos() );\n+\t\t\tString impalaPrincipal = ElementParameterParser.getValue(node, \"__IMPALA_PRINCIPAL__\");\n+\t\t\t\n+\t\t\tboolean useKeytab = \"true\".equals(ElementParameterParser.getValue(node, \"__USE_KEYTAB__\"));\n+\t\t\tString userPrincipal = ElementParameterParser.getValue(node, \"__PRINCIPAL__\");\n+\t\t\tString keytabPath = ElementParameterParser.getValue(node, \"__KEYTAB_PATH__\");\n+\t\t\t\n+\t\t\tboolean useSsl = \"true\".equals(ElementParameterParser.getValue(node, \"__USE_SSL__\"));\n+\t\t\tString sslTrustStore = ElementParameterParser.getValue(node, \"__SSL_TRUST_STORE__\");\n+\t\t\tString sslStorepasswordFieldName = \"__SSL_TRUST_STORE_PASSWORD__\";\n+\n+\t\t\tboolean configureFromClassPath = \"true\".equals(ElementParameterParser.getValue(node, \"__CONFIGURATIONS_FROM_CLASSPATH__\"));\n+\t\t\tboolean storeByHBase = \"true\".equals(ElementParameterParser.getValue(node, \"__STORE_BY_HBASE__\"));\n+\t\t    \n+\n+\t\t\tif(impalaDriver!=null && !\"\".equals(impalaDriver.trim()) && (this.isCustom || this.hiveDistrib.doSupportHive2())) {\n+\t\t\t    impalaDriver = impalaDriver.toLowerCase();\n+\t\t\t\tif (\"hive2\".equalsIgnoreCase(impalaDriver)) {\n+\t\t\t\t\tjavaDbDriver = \"org.apache.hive.jdbc.HiveDriver\";\n+\t\t\t\t\timpalaDbProtocol=\"hive2\";\n+\t\t\t\t}\n+\t\t\t\tif (\"impala40\".equalsIgnoreCase(impalaDriver)) {\n+\t\t\t\t\tjavaDbDriver = \"com.cloudera.impala.jdbc4.Driver\";\n+\t\t\t\t\timpalaDbProtocol=\"impala\";\n+\t\t\t\t}\t\n+\t\t\t\tif (\"impala41\".equalsIgnoreCase(impalaDriver)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg3OTkxNg=="}, "originalCommit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "originalPosition": 64}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzNzI0ODUxOnYy", "diffSide": "RIGHT", "path": "main/plugins/org.talend.designer.components.bigdata/components/tImpalaInput/tImpalaInput_begin.javajet", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQwODoyNjo0MFrOGxzszg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQwNjowNzo0NFrOGybXaw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg4MDQ2Mg==", "bodyText": "can not be the case, you removed IMPALA40 and IMPALA41 to be IMPALA", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r454880462", "createdAt": "2020-07-15T08:26:40Z", "author": {"login": "AlixMetivier"}, "path": "main/plugins/org.talend.designer.components.bigdata/components/tImpalaInput/tImpalaInput_begin.javajet", "diffHunk": "@@ -72,7 +72,7 @@\n \t\t\t    impalaDriver = impalaDriver.toLowerCase();\n \t\t\t\tif (\"hive2\".equalsIgnoreCase(impalaDriver)) {\n \t\t\t\t\tjavaDbDriver = \"org.apache.hive.jdbc.HiveDriver\";\n-\t\t\t\t\timpalaDbProtocol=\"hive2\";\n+\t\t\t\t\timpalaDbProtocol=\"impala\";\n \t\t\t\t}\n \t\t\t\tif (\"impala40\".equalsIgnoreCase(impalaDriver)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQ5OTg2MQ==", "bodyText": "yes old code copy/paste. I will fix it", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r455499861", "createdAt": "2020-07-16T04:15:51Z", "author": {"login": "Redwene"}, "path": "main/plugins/org.talend.designer.components.bigdata/components/tImpalaInput/tImpalaInput_begin.javajet", "diffHunk": "@@ -72,7 +72,7 @@\n \t\t\t    impalaDriver = impalaDriver.toLowerCase();\n \t\t\t\tif (\"hive2\".equalsIgnoreCase(impalaDriver)) {\n \t\t\t\t\tjavaDbDriver = \"org.apache.hive.jdbc.HiveDriver\";\n-\t\t\t\t\timpalaDbProtocol=\"hive2\";\n+\t\t\t\t\timpalaDbProtocol=\"impala\";\n \t\t\t\t}\n \t\t\t\tif (\"impala40\".equalsIgnoreCase(impalaDriver)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg4MDQ2Mg=="}, "originalCommit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTUzMDM0Nw==", "bodyText": "done", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r455530347", "createdAt": "2020-07-16T06:07:44Z", "author": {"login": "Redwene"}, "path": "main/plugins/org.talend.designer.components.bigdata/components/tImpalaInput/tImpalaInput_begin.javajet", "diffHunk": "@@ -72,7 +72,7 @@\n \t\t\t    impalaDriver = impalaDriver.toLowerCase();\n \t\t\t\tif (\"hive2\".equalsIgnoreCase(impalaDriver)) {\n \t\t\t\t\tjavaDbDriver = \"org.apache.hive.jdbc.HiveDriver\";\n-\t\t\t\t\timpalaDbProtocol=\"hive2\";\n+\t\t\t\t\timpalaDbProtocol=\"impala\";\n \t\t\t\t}\n \t\t\t\tif (\"impala40\".equalsIgnoreCase(impalaDriver)) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg4MDQ2Mg=="}, "originalCommit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "originalPosition": 16}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzNzI1OTEzOnYy", "diffSide": "RIGHT", "path": "main/plugins/org.talend.designer.components.bigdata/components/tImpalaConnection/tImpalaConnection_java.xml", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQwODoyOToyNVrOGxzzdA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQwNjowNzo1OFrOGybXvQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg4MjE2NA==", "bodyText": "why this change, is it for URI creation ?", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r454882164", "createdAt": "2020-07-15T08:29:25Z", "author": {"login": "AlixMetivier"}, "path": "main/plugins/org.talend.designer.components.bigdata/components/tImpalaConnection/tImpalaConnection_java.xml", "diffHunk": "@@ -74,7 +72,7 @@\n \t\t\n \t\t<PARAMETER NAME=\"USER\" FIELD=\"TEXT\" NUM_ROW=\"30\"\n \t\t\tREPOSITORY_VALUE=\"USERNAME\" GROUP=\"CONNECTION\" SHOW=\"true\">\n-\t\t\t<DEFAULT>\"\"</DEFAULT>\n+\t\t\t<DEFAULT></DEFAULT>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTUwMDE1MA==", "bodyText": "I will fix it", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r455500150", "createdAt": "2020-07-16T04:17:04Z", "author": {"login": "Redwene"}, "path": "main/plugins/org.talend.designer.components.bigdata/components/tImpalaConnection/tImpalaConnection_java.xml", "diffHunk": "@@ -74,7 +72,7 @@\n \t\t\n \t\t<PARAMETER NAME=\"USER\" FIELD=\"TEXT\" NUM_ROW=\"30\"\n \t\t\tREPOSITORY_VALUE=\"USERNAME\" GROUP=\"CONNECTION\" SHOW=\"true\">\n-\t\t\t<DEFAULT>\"\"</DEFAULT>\n+\t\t\t<DEFAULT></DEFAULT>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg4MjE2NA=="}, "originalCommit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTUzMDQyOQ==", "bodyText": "done", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r455530429", "createdAt": "2020-07-16T06:07:58Z", "author": {"login": "Redwene"}, "path": "main/plugins/org.talend.designer.components.bigdata/components/tImpalaConnection/tImpalaConnection_java.xml", "diffHunk": "@@ -74,7 +72,7 @@\n \t\t\n \t\t<PARAMETER NAME=\"USER\" FIELD=\"TEXT\" NUM_ROW=\"30\"\n \t\t\tREPOSITORY_VALUE=\"USERNAME\" GROUP=\"CONNECTION\" SHOW=\"true\">\n-\t\t\t<DEFAULT>\"\"</DEFAULT>\n+\t\t\t<DEFAULT></DEFAULT>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg4MjE2NA=="}, "originalCommit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "originalPosition": 16}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzNzI4MjQxOnYy", "diffSide": "RIGHT", "path": "main/plugins/org.talend.designer.components.bigdata/components/tImpalaConnection/tImpalaConnectionUtilImpalaDriver.javajet", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQwODozNTo0NVrOGx0Bvw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQwNDoyMzoyOVrOGyZndw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg4NTgyMw==", "bodyText": "org.talend.hadoop.distribution.component.HadoopComponent can be changed to org.talend.hadoop.distribution.component.HiveComponent to avoid the cast", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r454885823", "createdAt": "2020-07-15T08:35:45Z", "author": {"login": "AlixMetivier"}, "path": "main/plugins/org.talend.designer.components.bigdata/components/tImpalaConnection/tImpalaConnectionUtilImpalaDriver.javajet", "diffHunk": "@@ -0,0 +1,298 @@\n+<%\n+\n+\tclass ConnectionUtilImpala extends DefaultConnectionUtil {\n+      // use HiveComponent type to get all necessary methods but there is something to fix about the design on the current typing \n+\t\tprivate org.talend.hadoop.distribution.component.HiveComponent distrib = null;\n+\t\tprivate boolean isCustom;\n+    \n+\t\tpublic ConnectionUtilImpala(org.talend.hadoop.distribution.component.HadoopComponent distrib) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTUwMTY4Nw==", "bodyText": "yes it could, but the constructor for impala using impala driver looks strange with HiveComponent. I did this choice to mask hiveComponent  (private) and for easier future changes", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r455501687", "createdAt": "2020-07-16T04:23:29Z", "author": {"login": "Redwene"}, "path": "main/plugins/org.talend.designer.components.bigdata/components/tImpalaConnection/tImpalaConnectionUtilImpalaDriver.javajet", "diffHunk": "@@ -0,0 +1,298 @@\n+<%\n+\n+\tclass ConnectionUtilImpala extends DefaultConnectionUtil {\n+      // use HiveComponent type to get all necessary methods but there is something to fix about the design on the current typing \n+\t\tprivate org.talend.hadoop.distribution.component.HiveComponent distrib = null;\n+\t\tprivate boolean isCustom;\n+    \n+\t\tpublic ConnectionUtilImpala(org.talend.hadoop.distribution.component.HadoopComponent distrib) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDg4NTgyMw=="}, "originalCommit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "originalPosition": 8}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzOTQwNTA2OnYy", "diffSide": "RIGHT", "path": "main/plugins/org.talend.designer.components.bigdata/components/tImpalaCreateTable/tImpalaCreateTable_java.xml", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQxNzozNToyMlrOGyIljQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQwNzozMToyMVrOGydrQw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTIyMjY2OQ==", "bodyText": "I think this change will require a migration task.", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r455222669", "createdAt": "2020-07-15T17:35:22Z", "author": {"login": "lbourgeois"}, "path": "main/plugins/org.talend.designer.components.bigdata/components/tImpalaCreateTable/tImpalaCreateTable_java.xml", "diffHunk": "@@ -65,9 +65,7 @@\n \t\t\t<ITEMS DEFAULT=\"HIVE2\">\n \t\t\t\t<ITEM NAME=\"HIVE2\" VALUE=\"HIVE2\"\n \t\t\t\t\t  SHOW_IF=\"(HIVE_SERVER == 'HIVE2')\" />\n-\t\t\t\t<ITEM NAME=\"IMPALA40\" VALUE=\"IMPALA40\"\n-\t\t\t\t\t  SHOW_IF=\"(DISTRIBUTION=='CLOUDERA' AND DISTRIB[DISTRIBUTION, IMPALA_VERSION].doSupportImpalaConnector[])\" />\n-\t\t\t\t<ITEM NAME=\"IMPALA41\" VALUE=\"IMPALA41\"\n+\t\t\t\t<ITEM NAME=\"IMPALA\" VALUE=\"IMPALA\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTUwMDM1OQ==", "bodyText": "distributions before CDP never use these items. what should I do ?", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r455500359", "createdAt": "2020-07-16T04:18:01Z", "author": {"login": "Redwene"}, "path": "main/plugins/org.talend.designer.components.bigdata/components/tImpalaCreateTable/tImpalaCreateTable_java.xml", "diffHunk": "@@ -65,9 +65,7 @@\n \t\t\t<ITEMS DEFAULT=\"HIVE2\">\n \t\t\t\t<ITEM NAME=\"HIVE2\" VALUE=\"HIVE2\"\n \t\t\t\t\t  SHOW_IF=\"(HIVE_SERVER == 'HIVE2')\" />\n-\t\t\t\t<ITEM NAME=\"IMPALA40\" VALUE=\"IMPALA40\"\n-\t\t\t\t\t  SHOW_IF=\"(DISTRIBUTION=='CLOUDERA' AND DISTRIB[DISTRIBUTION, IMPALA_VERSION].doSupportImpalaConnector[])\" />\n-\t\t\t\t<ITEM NAME=\"IMPALA41\" VALUE=\"IMPALA41\"\n+\t\t\t\t<ITEM NAME=\"IMPALA\" VALUE=\"IMPALA\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTIyMjY2OQ=="}, "originalCommit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTU2ODE5NQ==", "bodyText": "My understanding is that tImpalaCreateTable component is also available for other distros bit if that's not the case lgtm", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r455568195", "createdAt": "2020-07-16T07:31:21Z", "author": {"login": "lbourgeois"}, "path": "main/plugins/org.talend.designer.components.bigdata/components/tImpalaCreateTable/tImpalaCreateTable_java.xml", "diffHunk": "@@ -65,9 +65,7 @@\n \t\t\t<ITEMS DEFAULT=\"HIVE2\">\n \t\t\t\t<ITEM NAME=\"HIVE2\" VALUE=\"HIVE2\"\n \t\t\t\t\t  SHOW_IF=\"(HIVE_SERVER == 'HIVE2')\" />\n-\t\t\t\t<ITEM NAME=\"IMPALA40\" VALUE=\"IMPALA40\"\n-\t\t\t\t\t  SHOW_IF=\"(DISTRIBUTION=='CLOUDERA' AND DISTRIB[DISTRIBUTION, IMPALA_VERSION].doSupportImpalaConnector[])\" />\n-\t\t\t\t<ITEM NAME=\"IMPALA41\" VALUE=\"IMPALA41\"\n+\t\t\t\t<ITEM NAME=\"IMPALA\" VALUE=\"IMPALA\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTIyMjY2OQ=="}, "originalCommit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzOTQxODY5OnYy", "diffSide": "RIGHT", "path": "main/plugins/org.talend.designer.components.bigdata/components/tImpalaInput/tImpalaInput_begin.javajet", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQxNzozNzozNlrOGyIu_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQwNTo0MjoxNFrOGya38A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTIyNTA4Ng==", "bodyText": "looks strange to see\nif (\"hive2\".equalsIgnoreCase(impalaDriver)) {impalaDbProtocol=\"impala\";}", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r455225086", "createdAt": "2020-07-15T17:37:36Z", "author": {"login": "lbourgeois"}, "path": "main/plugins/org.talend.designer.components.bigdata/components/tImpalaInput/tImpalaInput_begin.javajet", "diffHunk": "@@ -72,7 +72,7 @@\n \t\t\t    impalaDriver = impalaDriver.toLowerCase();\n \t\t\t\tif (\"hive2\".equalsIgnoreCase(impalaDriver)) {\n \t\t\t\t\tjavaDbDriver = \"org.apache.hive.jdbc.HiveDriver\";\n-\t\t\t\t\timpalaDbProtocol=\"hive2\";\n+\t\t\t\t\timpalaDbProtocol=\"impala\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTUwMjQ5MA==", "bodyText": "it's what we discussed,old code with dirty changes to work with impala driver. that why I'm still on it  to change this", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r455502490", "createdAt": "2020-07-16T04:26:40Z", "author": {"login": "Redwene"}, "path": "main/plugins/org.talend.designer.components.bigdata/components/tImpalaInput/tImpalaInput_begin.javajet", "diffHunk": "@@ -72,7 +72,7 @@\n \t\t\t    impalaDriver = impalaDriver.toLowerCase();\n \t\t\t\tif (\"hive2\".equalsIgnoreCase(impalaDriver)) {\n \t\t\t\t\tjavaDbDriver = \"org.apache.hive.jdbc.HiveDriver\";\n-\t\t\t\t\timpalaDbProtocol=\"hive2\";\n+\t\t\t\t\timpalaDbProtocol=\"impala\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTIyNTA4Ng=="}, "originalCommit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTUyMjI4OA==", "bodyText": "done I quick fix for ssl, I will do the same for keberos.", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r455522288", "createdAt": "2020-07-16T05:42:14Z", "author": {"login": "Redwene"}, "path": "main/plugins/org.talend.designer.components.bigdata/components/tImpalaInput/tImpalaInput_begin.javajet", "diffHunk": "@@ -72,7 +72,7 @@\n \t\t\t    impalaDriver = impalaDriver.toLowerCase();\n \t\t\t\tif (\"hive2\".equalsIgnoreCase(impalaDriver)) {\n \t\t\t\t\tjavaDbDriver = \"org.apache.hive.jdbc.HiveDriver\";\n-\t\t\t\t\timpalaDbProtocol=\"hive2\";\n+\t\t\t\t\timpalaDbProtocol=\"impala\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTIyNTA4Ng=="}, "originalCommit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzOTQ4MDMzOnYy", "diffSide": "LEFT", "path": "main/plugins/org.talend.hadoop.distribution/src/main/java/org/talend/hadoop/distribution/component/ImpalaComponent.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQxNzo1NDowOFrOGyJWLg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQwNDozMzoxNlrOGyZwrA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTIzNTExOA==", "bodyText": "I don't get why this was moved to superinterface HaddopComponent.\nIt should stay in ImpalaComponent as it is related to Impala", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r455235118", "createdAt": "2020-07-15T17:54:08Z", "author": {"login": "lbourgeois"}, "path": "main/plugins/org.talend.hadoop.distribution/src/main/java/org/talend/hadoop/distribution/component/ImpalaComponent.java", "diffHunk": "@@ -18,17 +18,6 @@\n  */\n public interface ImpalaComponent extends HadoopComponent {\n \n-    /**\n-     * indicate if we support the impala native protocol.\n-     * connection with jdbc:impala://[Host]:[Port]/[Schema];[Property1]=[Value];[Property2]=[Value];\n-     * @return\n-     */\n-    default boolean doSupportImpalaConnector() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTUwNDA0NA==", "bodyText": "I moved it to Haddo Component to find out if its impala is supported before converting the distribution object to impala. We can thus refactor more easily the code between the choice of the driver hive and impala.", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r455504044", "createdAt": "2020-07-16T04:33:16Z", "author": {"login": "Redwene"}, "path": "main/plugins/org.talend.hadoop.distribution/src/main/java/org/talend/hadoop/distribution/component/ImpalaComponent.java", "diffHunk": "@@ -18,17 +18,6 @@\n  */\n public interface ImpalaComponent extends HadoopComponent {\n \n-    /**\n-     * indicate if we support the impala native protocol.\n-     * connection with jdbc:impala://[Host]:[Port]/[Schema];[Property1]=[Value];[Property2]=[Value];\n-     * @return\n-     */\n-    default boolean doSupportImpalaConnector() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTIzNTExOA=="}, "originalCommit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "originalPosition": 9}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzOTQ5MTY0OnYy", "diffSide": "RIGHT", "path": "main/plugins/org.talend.hadoop.distribution.cdp/src/main/java/org/talend/hadoop/distribution/cdp/CDP7xDistributionTemplate.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQxNzo1NjozNVrOGyJcvQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQwNDozNTowMlrOGyZySw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTIzNjc5Nw==", "bodyText": "Is it still CDH in path ?", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r455236797", "createdAt": "2020-07-15T17:56:35Z", "author": {"login": "lbourgeois"}, "path": "main/plugins/org.talend.hadoop.distribution.cdp/src/main/java/org/talend/hadoop/distribution/cdp/CDP7xDistributionTemplate.java", "diffHunk": "@@ -33,227 +34,253 @@\n import org.talend.hadoop.distribution.kudu.KuduVersion;\n \n @SuppressWarnings(\"nls\")\n-public class CDP7xDistributionTemplate extends AbstractDynamicCDPDistributionTemplate implements HDFSComponent, HBaseComponent,\n-        HCatalogComponent, MRComponent, HiveComponent, HiveOnSparkComponent, ImpalaComponent, SqoopComponent,\n- CDPSparkBatchComponent, SparkStreamingComponent, ICDP7xDistributionTemplate {\n-\n-    public final static String TEMPLATE_ID = \"CDP7xDistributionTemplate\";\n-  \n-    private final static String YARN_APPLICATION_CLASSPATH = \"/opt/cloudera/parcels/CDH/lib/spark/jars/*,\" + \n-    \t\t\"/opt/cloudera/parcels/CDH/lib/hive/lib/*,\" + \n-    \t\t\"/opt/cloudera/parcels/CDH/lib/impala/lib/*,\"+\n-    \t\t\"/opt/cloudera/parcels/CDH/lib/hbase/lib/*,\"+\n-    \t\t\"/opt/cloudera/parcels/CDH/lib/kudu/*\";\n-\n-    public CDP7xDistributionTemplate(DynamicPluginAdapter pluginAdapter) throws Exception {\n-        super(pluginAdapter);\n-    }\n-\n-    @Override\n-    public String getTemplateId() {\n-        return TEMPLATE_ID;\n-    }\n-\n-    @Override\n-    public String getYarnApplicationClasspath() {\n-    \treturn YARN_APPLICATION_CLASSPATH;\n-    }\n-    \n-    @Override\n-    public String generateSparkJarsPaths(List<String> commandLineJarsPaths) {\n-        return getYarnApplicationClasspath() ;\n-    }\n-    @Override\n-    public boolean doSupportSequenceFileShortType() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportNewHBaseAPI() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportCrossPlatformSubmission() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportImpersonation() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportEmbeddedMode() {\n-        return false;\n-    }\n-\n-    @Override\n-    public boolean doSupportStandaloneMode() {\n-        return super.doSupportStandaloneMode();\n-    }\n-   \n-    @Override\n-    public boolean doSupportHive1() {\n-        return false;\n-    }\n-\n-    @Override\n-    public boolean doSupportHive2() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportTezForHive() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportHBaseForHive() {\n-        return false;\n-    }\n-    @Override\n-    public boolean doSupportHBase2x() {\n-        return true;\n-    }\n-    @Override\n-    public boolean doSupportSSL() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportORCFormat() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportAvroFormat() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportParquetFormat() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportStoreAsParquet() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doJavaAPISupportStorePasswordInFile() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doJavaAPISqoopImportSupportDeleteTargetDir() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doJavaAPISqoopImportAllTablesSupportExcludeTable() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportClouderaNavigator() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportParquetOutput() {\n-        return true;\n-    }\n-\n-    @Override\n-    public Set<ESparkVersion> getSparkVersions() {\n-        Set<ESparkVersion> version = new HashSet<>();\n-        Set<ESparkVersion> sparkVersions = super.getSparkVersions();\n-        if (sparkVersions == null || sparkVersions.isEmpty()) {\n-            version.add(ESparkVersion.SPARK_2_2);\n-        } else {\n-            version.addAll(sparkVersions);\n-        }\n-        return version;\n-    }\n-\n-    @Override\n-    public boolean isExecutedThroughSparkJobServer() {\n-        return false;\n-    }\n-\n-    @Override\n-    public boolean doSupportSparkStandaloneMode() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportSparkYarnClientMode() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportDynamicMemoryAllocation() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportSSLwithKerberos() {\n-        return true;\n-    }\n-\n-    @Override\n-    public int getClouderaNavigatorAPIVersion() {\n-        return 9;\n-    }\n-\n-    @Override\n-    public boolean doSupportCheckpointing() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportBackpressure() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportAzureBlobStorage() {\n-        return true;\n-    }\n-\n-    @Override\n-    public short orderingWeight() {\n-        return 10;\n-    }\n-\n-    @Override\n-    public boolean doImportDynamoDBDependencies() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportAssumeRole() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportAvroDeflateProperties() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean useOldAWSAPI() {\n-        return false;\n-    }\n-\n-    @Override\n-    public String getSuffixParquetPackage() {\n-    \treturn \"org.apache.\";\n-    }\n-    @Override\n-    public KuduVersion getKuduVersion() {\n-        return KuduVersion.KUDU_1_12;\n-    }\n+public class CDP7xDistributionTemplate extends AbstractDynamicCDPDistributionTemplate\n+\t\timplements HDFSComponent, HBaseComponent, HCatalogComponent, MRComponent, HiveComponent, HiveOnSparkComponent,\n+\t\tImpalaComponent, SqoopComponent, CDPSparkBatchComponent, SparkStreamingComponent, ICDP7xDistributionTemplate {\n+\tprivate final static String SEPARATOR = \",\";\n+\tpublic final static String DEFAULT_LIB_ROOT = \"/opt/cloudera/parcels/CDH/lib\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "originalPosition": 239}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTUwNDQ1OQ==", "bodyText": "yes this is cloudera standard path", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r455504459", "createdAt": "2020-07-16T04:35:02Z", "author": {"login": "Redwene"}, "path": "main/plugins/org.talend.hadoop.distribution.cdp/src/main/java/org/talend/hadoop/distribution/cdp/CDP7xDistributionTemplate.java", "diffHunk": "@@ -33,227 +34,253 @@\n import org.talend.hadoop.distribution.kudu.KuduVersion;\n \n @SuppressWarnings(\"nls\")\n-public class CDP7xDistributionTemplate extends AbstractDynamicCDPDistributionTemplate implements HDFSComponent, HBaseComponent,\n-        HCatalogComponent, MRComponent, HiveComponent, HiveOnSparkComponent, ImpalaComponent, SqoopComponent,\n- CDPSparkBatchComponent, SparkStreamingComponent, ICDP7xDistributionTemplate {\n-\n-    public final static String TEMPLATE_ID = \"CDP7xDistributionTemplate\";\n-  \n-    private final static String YARN_APPLICATION_CLASSPATH = \"/opt/cloudera/parcels/CDH/lib/spark/jars/*,\" + \n-    \t\t\"/opt/cloudera/parcels/CDH/lib/hive/lib/*,\" + \n-    \t\t\"/opt/cloudera/parcels/CDH/lib/impala/lib/*,\"+\n-    \t\t\"/opt/cloudera/parcels/CDH/lib/hbase/lib/*,\"+\n-    \t\t\"/opt/cloudera/parcels/CDH/lib/kudu/*\";\n-\n-    public CDP7xDistributionTemplate(DynamicPluginAdapter pluginAdapter) throws Exception {\n-        super(pluginAdapter);\n-    }\n-\n-    @Override\n-    public String getTemplateId() {\n-        return TEMPLATE_ID;\n-    }\n-\n-    @Override\n-    public String getYarnApplicationClasspath() {\n-    \treturn YARN_APPLICATION_CLASSPATH;\n-    }\n-    \n-    @Override\n-    public String generateSparkJarsPaths(List<String> commandLineJarsPaths) {\n-        return getYarnApplicationClasspath() ;\n-    }\n-    @Override\n-    public boolean doSupportSequenceFileShortType() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportNewHBaseAPI() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportCrossPlatformSubmission() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportImpersonation() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportEmbeddedMode() {\n-        return false;\n-    }\n-\n-    @Override\n-    public boolean doSupportStandaloneMode() {\n-        return super.doSupportStandaloneMode();\n-    }\n-   \n-    @Override\n-    public boolean doSupportHive1() {\n-        return false;\n-    }\n-\n-    @Override\n-    public boolean doSupportHive2() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportTezForHive() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportHBaseForHive() {\n-        return false;\n-    }\n-    @Override\n-    public boolean doSupportHBase2x() {\n-        return true;\n-    }\n-    @Override\n-    public boolean doSupportSSL() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportORCFormat() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportAvroFormat() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportParquetFormat() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportStoreAsParquet() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doJavaAPISupportStorePasswordInFile() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doJavaAPISqoopImportSupportDeleteTargetDir() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doJavaAPISqoopImportAllTablesSupportExcludeTable() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportClouderaNavigator() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportParquetOutput() {\n-        return true;\n-    }\n-\n-    @Override\n-    public Set<ESparkVersion> getSparkVersions() {\n-        Set<ESparkVersion> version = new HashSet<>();\n-        Set<ESparkVersion> sparkVersions = super.getSparkVersions();\n-        if (sparkVersions == null || sparkVersions.isEmpty()) {\n-            version.add(ESparkVersion.SPARK_2_2);\n-        } else {\n-            version.addAll(sparkVersions);\n-        }\n-        return version;\n-    }\n-\n-    @Override\n-    public boolean isExecutedThroughSparkJobServer() {\n-        return false;\n-    }\n-\n-    @Override\n-    public boolean doSupportSparkStandaloneMode() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportSparkYarnClientMode() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportDynamicMemoryAllocation() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportSSLwithKerberos() {\n-        return true;\n-    }\n-\n-    @Override\n-    public int getClouderaNavigatorAPIVersion() {\n-        return 9;\n-    }\n-\n-    @Override\n-    public boolean doSupportCheckpointing() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportBackpressure() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportAzureBlobStorage() {\n-        return true;\n-    }\n-\n-    @Override\n-    public short orderingWeight() {\n-        return 10;\n-    }\n-\n-    @Override\n-    public boolean doImportDynamoDBDependencies() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportAssumeRole() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean doSupportAvroDeflateProperties() {\n-        return true;\n-    }\n-\n-    @Override\n-    public boolean useOldAWSAPI() {\n-        return false;\n-    }\n-\n-    @Override\n-    public String getSuffixParquetPackage() {\n-    \treturn \"org.apache.\";\n-    }\n-    @Override\n-    public KuduVersion getKuduVersion() {\n-        return KuduVersion.KUDU_1_12;\n-    }\n+public class CDP7xDistributionTemplate extends AbstractDynamicCDPDistributionTemplate\n+\t\timplements HDFSComponent, HBaseComponent, HCatalogComponent, MRComponent, HiveComponent, HiveOnSparkComponent,\n+\t\tImpalaComponent, SqoopComponent, CDPSparkBatchComponent, SparkStreamingComponent, ICDP7xDistributionTemplate {\n+\tprivate final static String SEPARATOR = \",\";\n+\tpublic final static String DEFAULT_LIB_ROOT = \"/opt/cloudera/parcels/CDH/lib\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTIzNjc5Nw=="}, "originalCommit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "originalPosition": 239}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgzOTUwNTQ2OnYy", "diffSide": "LEFT", "path": "main/plugins/org.talend.hadoop.distribution.cdp/resources/builtin/cdp/Cloudera_CDP_7_1_1.json", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQxODowMDowNlrOGyJlGQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNlQwNDo0ODo1MVrOGyZ_0Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTIzODkzNw==", "bodyText": "I wonder why those Spark libs are not needed anymore and how they can't miss at job compilation", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r455238937", "createdAt": "2020-07-15T18:00:06Z", "author": {"login": "lbourgeois"}, "path": "main/plugins/org.talend.hadoop.distribution.cdp/resources/builtin/cdp/Cloudera_CDP_7_1_1.json", "diffHunk": "@@ -4702,90 +4534,18 @@\n         \"childNodes\" : [ ],\n         \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_protobuf_java_2_5_0_jar\",\n         \"tagName\" : \"library\"\n-      }, {\n-        \"childNodes\" : [ ],\n-        \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_py4j_0_10_7_jar\",\n-        \"tagName\" : \"library\"\n-      }, {\n-        \"childNodes\" : [ ],\n-        \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_pyrolite_4_13_jar\",\n-        \"tagName\" : \"library\"\n       }, {\n         \"childNodes\" : [ ],\n         \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_re2j_1_2_jar\",\n         \"tagName\" : \"library\"\n-      }, {\n-        \"childNodes\" : [ ],\n-        \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_reflections_0_9_10_jar\",\n-        \"tagName\" : \"library\"\n-      }, {\n-        \"childNodes\" : [ ],\n-        \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_scala_compiler_2_11_0_jar\",\n-        \"tagName\" : \"library\"\n-      }, {\n-        \"childNodes\" : [ ],\n-        \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_scala_library_2_11_12_jar\",\n-        \"tagName\" : \"library\"\n-      }, {\n-        \"childNodes\" : [ ],\n-        \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_scala_parser_combinators_2_11_1_1_0_jar\",\n-        \"tagName\" : \"library\"\n-      }, {\n-        \"childNodes\" : [ ],\n-        \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_scala_reflect_2_11_12_jar\",\n-        \"tagName\" : \"library\"\n-      }, {\n-        \"childNodes\" : [ ],\n-        \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_scala_xml_2_11_1_0_6_jar\",\n-        \"tagName\" : \"library\"\n-      }, {\n-        \"childNodes\" : [ ],\n-        \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_scalap_2_11_0_jar\",\n-        \"tagName\" : \"library\"\n-      }, {\n-        \"childNodes\" : [ ],\n-        \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_sketches_core_0_9_0_jar\",\n-        \"tagName\" : \"library\"\n       }, {\n         \"childNodes\" : [ ],\n         \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_slf4j_api_1_7_30_jar\",\n         \"tagName\" : \"library\"\n-      }, {\n-        \"childNodes\" : [ ],\n-        \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_snakeyaml_1_24_jar\",\n-        \"tagName\" : \"library\"\n       }, {\n         \"childNodes\" : [ ],\n         \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_snappy_java_1_1_7_5_jar\",\n         \"tagName\" : \"library\"\n-      }, {\n-        \"childNodes\" : [ ],\n-        \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_spark_core_2_11_2_4_0_7_1_1_0_565_jar\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "originalPosition": 436}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTUwNzkyMQ==", "bodyText": "we are in the IMPALA-LIB-DYNAMIC section. this pot is loaded elsewhere.", "url": "https://github.com/Talend/tbd-studio-se/pull/1459#discussion_r455507921", "createdAt": "2020-07-16T04:48:51Z", "author": {"login": "Redwene"}, "path": "main/plugins/org.talend.hadoop.distribution.cdp/resources/builtin/cdp/Cloudera_CDP_7_1_1.json", "diffHunk": "@@ -4702,90 +4534,18 @@\n         \"childNodes\" : [ ],\n         \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_protobuf_java_2_5_0_jar\",\n         \"tagName\" : \"library\"\n-      }, {\n-        \"childNodes\" : [ ],\n-        \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_py4j_0_10_7_jar\",\n-        \"tagName\" : \"library\"\n-      }, {\n-        \"childNodes\" : [ ],\n-        \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_pyrolite_4_13_jar\",\n-        \"tagName\" : \"library\"\n       }, {\n         \"childNodes\" : [ ],\n         \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_re2j_1_2_jar\",\n         \"tagName\" : \"library\"\n-      }, {\n-        \"childNodes\" : [ ],\n-        \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_reflections_0_9_10_jar\",\n-        \"tagName\" : \"library\"\n-      }, {\n-        \"childNodes\" : [ ],\n-        \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_scala_compiler_2_11_0_jar\",\n-        \"tagName\" : \"library\"\n-      }, {\n-        \"childNodes\" : [ ],\n-        \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_scala_library_2_11_12_jar\",\n-        \"tagName\" : \"library\"\n-      }, {\n-        \"childNodes\" : [ ],\n-        \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_scala_parser_combinators_2_11_1_1_0_jar\",\n-        \"tagName\" : \"library\"\n-      }, {\n-        \"childNodes\" : [ ],\n-        \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_scala_reflect_2_11_12_jar\",\n-        \"tagName\" : \"library\"\n-      }, {\n-        \"childNodes\" : [ ],\n-        \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_scala_xml_2_11_1_0_6_jar\",\n-        \"tagName\" : \"library\"\n-      }, {\n-        \"childNodes\" : [ ],\n-        \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_scalap_2_11_0_jar\",\n-        \"tagName\" : \"library\"\n-      }, {\n-        \"childNodes\" : [ ],\n-        \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_sketches_core_0_9_0_jar\",\n-        \"tagName\" : \"library\"\n       }, {\n         \"childNodes\" : [ ],\n         \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_slf4j_api_1_7_30_jar\",\n         \"tagName\" : \"library\"\n-      }, {\n-        \"childNodes\" : [ ],\n-        \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_snakeyaml_1_24_jar\",\n-        \"tagName\" : \"library\"\n       }, {\n         \"childNodes\" : [ ],\n         \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_snappy_java_1_1_7_5_jar\",\n         \"tagName\" : \"library\"\n-      }, {\n-        \"childNodes\" : [ ],\n-        \"id\" : \"DYNAMIC_Cloudera_CDP7_1_1_0_565_spark_core_2_11_2_4_0_7_1_1_0_565_jar\",", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTIzODkzNw=="}, "originalCommit": {"oid": "248d815b93ed618f59984e9133f128fa0327ded4"}, "originalPosition": 436}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4851, "cost": 1, "resetAt": "2021-11-13T14:23:39Z"}}}