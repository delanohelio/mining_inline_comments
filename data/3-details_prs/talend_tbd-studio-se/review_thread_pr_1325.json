{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzkxNDM0NDQz", "number": 1325, "reviewThreads": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxMDoxOTozNFrODp0HUg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxNzoyMTozM1rODp9AQQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1MTcyMDUwOnYy", "diffSide": "RIGHT", "path": "main/plugins/org.talend.designer.components.bigdata/components/tSqoopImport/tSqoopImport_java.xml", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxMDoxOTozNVrOF5OIAQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxNDowNDo1NlrOF5VDlw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU0NDU3Nw==", "bodyText": "I haven't seen such modifications in TBD-9956 related PRs", "url": "https://github.com/Talend/tbd-studio-se/pull/1325#discussion_r395544577", "createdAt": "2020-03-20T10:19:35Z", "author": {"login": "lbourgeois"}, "path": "main/plugins/org.talend.designer.components.bigdata/components/tSqoopImport/tSqoopImport_java.xml", "diffHunk": "@@ -1777,10 +1777,14 @@\n \t\t\t\tUrlPath=\"platform:/plugin/org.talend.libraries.hadoop.cloudera.cdh5/lib/avro-1.7.5-cdh5.0.4.jar\"\n \t\t\t\tREQUIRED_IF=\"(USE_JAVAAPI=='true' AND DB_VERSION=='APACHE_2_4_0_EMR') AND (DISTRIBUTION!='CUSTOM')\" />\n \n-\t\t\t<IMPORT NAME=\"avro-mapred-1.5.4.jar\" MODULE=\"avro-mapred-1.5.4.jar\"\n-\t\t\t\tUrlPath=\"platform:/plugin/org.talend.libraries.apache/lib/avro-mapred-1.5.4.jar\"\n-\t\t\t\tMVN=\"mvn:org.talend.libraries/avro-mapred-1.5.4/6.0.0\"\n+\t\t\t<IMPORT NAME=\"avro-mapred-1.8.1.jar\" MODULE=\"avro-mapred-1.8.1.jar\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "631883aa4c7b0d837411dcc8ccbab278701c3fb3"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYxNjcxOQ==", "bodyText": "Those changes are from TBD-10095. However, without them it might be lib conflict between  older version of avro-mapred (1.5.4) on the component side and newer one on distribution.\nI would include them if you don't mind, @lbourgeois ?", "url": "https://github.com/Talend/tbd-studio-se/pull/1325#discussion_r395616719", "createdAt": "2020-03-20T12:55:11Z", "author": {"login": "sponomarova"}, "path": "main/plugins/org.talend.designer.components.bigdata/components/tSqoopImport/tSqoopImport_java.xml", "diffHunk": "@@ -1777,10 +1777,14 @@\n \t\t\t\tUrlPath=\"platform:/plugin/org.talend.libraries.hadoop.cloudera.cdh5/lib/avro-1.7.5-cdh5.0.4.jar\"\n \t\t\t\tREQUIRED_IF=\"(USE_JAVAAPI=='true' AND DB_VERSION=='APACHE_2_4_0_EMR') AND (DISTRIBUTION!='CUSTOM')\" />\n \n-\t\t\t<IMPORT NAME=\"avro-mapred-1.5.4.jar\" MODULE=\"avro-mapred-1.5.4.jar\"\n-\t\t\t\tUrlPath=\"platform:/plugin/org.talend.libraries.apache/lib/avro-mapred-1.5.4.jar\"\n-\t\t\t\tMVN=\"mvn:org.talend.libraries/avro-mapred-1.5.4/6.0.0\"\n+\t\t\t<IMPORT NAME=\"avro-mapred-1.8.1.jar\" MODULE=\"avro-mapred-1.8.1.jar\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU0NDU3Nw=="}, "originalCommit": {"oid": "631883aa4c7b0d837411dcc8ccbab278701c3fb3"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTY1ODEzNQ==", "bodyText": "Agree", "url": "https://github.com/Talend/tbd-studio-se/pull/1325#discussion_r395658135", "createdAt": "2020-03-20T14:04:56Z", "author": {"login": "lbourgeois"}, "path": "main/plugins/org.talend.designer.components.bigdata/components/tSqoopImport/tSqoopImport_java.xml", "diffHunk": "@@ -1777,10 +1777,14 @@\n \t\t\t\tUrlPath=\"platform:/plugin/org.talend.libraries.hadoop.cloudera.cdh5/lib/avro-1.7.5-cdh5.0.4.jar\"\n \t\t\t\tREQUIRED_IF=\"(USE_JAVAAPI=='true' AND DB_VERSION=='APACHE_2_4_0_EMR') AND (DISTRIBUTION!='CUSTOM')\" />\n \n-\t\t\t<IMPORT NAME=\"avro-mapred-1.5.4.jar\" MODULE=\"avro-mapred-1.5.4.jar\"\n-\t\t\t\tUrlPath=\"platform:/plugin/org.talend.libraries.apache/lib/avro-mapred-1.5.4.jar\"\n-\t\t\t\tMVN=\"mvn:org.talend.libraries/avro-mapred-1.5.4/6.0.0\"\n+\t\t\t<IMPORT NAME=\"avro-mapred-1.8.1.jar\" MODULE=\"avro-mapred-1.8.1.jar\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU0NDU3Nw=="}, "originalCommit": {"oid": "631883aa4c7b0d837411dcc8ccbab278701c3fb3"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1MTczMDk0OnYy", "diffSide": "RIGHT", "path": "main/plugins/org.talend.hadoop.distribution/src/main/java/org/talend/hadoop/distribution/dynamic/template/modulegroup/hdp/DynamicHDPSparkBatchModuleGroup.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxMDoyMjo1M1rOF5OOcA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxMjo1MTo0NFrOF5Sa9Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU0NjIyNA==", "bodyText": "Can you clarify why do we impact HBase in scope of this Sqoop fix. Havent seen such modifications in master PRs for TBD-9956", "url": "https://github.com/Talend/tbd-studio-se/pull/1325#discussion_r395546224", "createdAt": "2020-03-20T10:22:53Z", "author": {"login": "lbourgeois"}, "path": "main/plugins/org.talend.hadoop.distribution/src/main/java/org/talend/hadoop/distribution/dynamic/template/modulegroup/hdp/DynamicHDPSparkBatchModuleGroup.java", "diffHunk": "@@ -1,117 +1,138 @@\n-// ============================================================================\r\n-//\r\n-// Copyright (C) 2006-2019 Talend Inc. - www.talend.com\r\n-//\r\n-// This source code is available under agreement available at\r\n-// %InstallDIR%\\features\\org.talend.rcp.branding.%PRODUCTNAME%\\%PRODUCTNAME%license.txt\r\n-//\r\n-// You should have received a copy of the agreement\r\n-// along with this program; if not, write to Talend SA\r\n-// 9 rue Pages 92150 Suresnes, France\r\n-//\r\n-// ============================================================================\r\n-package org.talend.hadoop.distribution.dynamic.template.modulegroup.hdp;\r\n-\r\n-import java.util.HashSet;\r\n-import java.util.Set;\r\n-\r\n-import org.apache.commons.lang.StringUtils;\r\n-import org.talend.hadoop.distribution.DistributionModuleGroup;\r\n-import org.talend.hadoop.distribution.ESparkVersion;\r\n-import org.talend.hadoop.distribution.condition.BasicExpression;\r\n-import org.talend.hadoop.distribution.condition.BooleanOperator;\r\n-import org.talend.hadoop.distribution.condition.ComponentCondition;\r\n-import org.talend.hadoop.distribution.condition.EqualityOperator;\r\n-import org.talend.hadoop.distribution.condition.MultiComponentCondition;\r\n-import org.talend.hadoop.distribution.condition.SimpleComponentCondition;\r\n-import org.talend.hadoop.distribution.constants.MRConstant;\r\n-import org.talend.hadoop.distribution.dynamic.adapter.DynamicPluginAdapter;\r\n-import org.talend.hadoop.distribution.dynamic.template.modulegroup.DynamicModuleGroupConstant;\r\n-import org.talend.hadoop.distribution.dynamic.template.modulegroup.DynamicSparkBatchModuleGroup;\r\n-\r\n-\r\n-/**\r\n- * DOC cmeng  class global comment. Detailled comment\r\n- */\r\n-public class DynamicHDPSparkBatchModuleGroup extends DynamicSparkBatchModuleGroup {\r\n-\r\n-    protected ComponentCondition conditionNotSpark16;\r\n-\r\n-    public DynamicHDPSparkBatchModuleGroup(DynamicPluginAdapter pluginAdapter) {\r\n-        super(pluginAdapter);\r\n-    }\r\n-\r\n-    @Override\r\n-    protected void initConditions() {\r\n-        super.initConditions();\r\n-        conditionNotSpark16 = new SimpleComponentCondition(\r\n-                new BasicExpression(\"SUPPORTED_SPARK_VERSION\", EqualityOperator.NOT_EQ, ESparkVersion.SPARK_1_6.getSparkVersion())); //$NON-NLS-1$\r\n-    }\r\n-\r\n-    @Override\r\n-    public Set<DistributionModuleGroup> getModuleGroups() throws Exception {\r\n-        Set<DistributionModuleGroup> moduleGroups = new HashSet<>();\r\n-        Set<DistributionModuleGroup> moduleGroupsFromSuper = super.getModuleGroups();\r\n-        if (moduleGroupsFromSuper != null && !moduleGroupsFromSuper.isEmpty()) {\r\n-            moduleGroups.addAll(moduleGroupsFromSuper);\r\n-        }\r\n-        DynamicPluginAdapter pluginAdapter = getPluginAdapter();\r\n-\r\n-        String spark2RuntimeId = pluginAdapter\r\n-                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.SPARK2_MODULE_GROUP.getModuleName());\r\n-        String sparkMRRequiredRuntimeId = pluginAdapter\r\n-                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.SPARK_MRREQUIRED_MODULE_GROUP.getModuleName());\r\n-        String hdfsRuntimeId = pluginAdapter\r\n-                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.HDFS_MODULE_GROUP.getModuleName());\r\n-        String hdfsNotSpark16RuntimeId = pluginAdapter\r\n-                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.HDFS_NOT_SPARK_1_6_MODULE_GROUP.getModuleName());\r\n-        String tezNotSpark16RuntimeId = pluginAdapter\r\n-                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.TEZ_NOT_SPARK_1_6_MODULE_GROUP.getModuleName());\r\n-        String mapReduceRuntimeId = pluginAdapter\r\n-                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.MAPREDUCE_MODULE_GROUP.getModuleName());\r\n-        String atlasSpark1RuntimeId = pluginAdapter\r\n-                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.ATLAS_SPARK_1_MODULE_GROUP.getModuleName());\r\n-        String atlasSpark2RuntimeId = pluginAdapter\r\n-                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.ATLAS_SPARK_2_MODULE_GROUP.getModuleName());\r\n-\r\n-        checkRuntimeId(spark2RuntimeId);\r\n-        checkRuntimeId(sparkMRRequiredRuntimeId);\r\n-        checkRuntimeId(hdfsRuntimeId);\r\n-        checkRuntimeId(hdfsNotSpark16RuntimeId);\r\n-        checkRuntimeId(tezNotSpark16RuntimeId);\r\n-        checkRuntimeId(mapReduceRuntimeId);\r\n-        checkRuntimeId(atlasSpark1RuntimeId);\r\n-        checkRuntimeId(atlasSpark2RuntimeId);\r\n-\r\n-        ComponentCondition useAtlas = new SimpleComponentCondition(new BasicExpression(MRConstant.USE_ATLAS));\r\n-        ComponentCondition atlasSpark1x = new MultiComponentCondition(useAtlas, BooleanOperator.AND, conditionSpark1);\r\n-        ComponentCondition atlasSpark2x = new MultiComponentCondition(useAtlas, BooleanOperator.AND, conditionSpark2);\r\n-\r\n-        if (StringUtils.isNotBlank(sparkMRRequiredRuntimeId)) {\r\n-            moduleGroups.add(new DistributionModuleGroup(sparkMRRequiredRuntimeId, true, conditionSpark1));\r\n-            moduleGroups.add(new DistributionModuleGroup(sparkMRRequiredRuntimeId, true, conditionSpark2));\r\n-        }\r\n-        if (StringUtils.isNotBlank(hdfsRuntimeId)) {\r\n-            moduleGroups.add(new DistributionModuleGroup(hdfsRuntimeId, false, conditionSpark1));\r\n-            moduleGroups.add(new DistributionModuleGroup(hdfsRuntimeId, false, conditionSpark2));\r\n-        }\r\n-        if (StringUtils.isNotBlank(hdfsNotSpark16RuntimeId)) {\r\n-            moduleGroups.add(new DistributionModuleGroup(hdfsNotSpark16RuntimeId, false, conditionNotSpark16));\r\n-        }\r\n-        if (StringUtils.isNotBlank(tezNotSpark16RuntimeId)) {\r\n-            moduleGroups.add(new DistributionModuleGroup(tezNotSpark16RuntimeId, false, conditionNotSpark16));\r\n-        }\r\n-        if (StringUtils.isNotBlank(mapReduceRuntimeId)) {\r\n-            moduleGroups.add(new DistributionModuleGroup(mapReduceRuntimeId, false, conditionSpark1));\r\n-            moduleGroups.add(new DistributionModuleGroup(mapReduceRuntimeId, false, conditionSpark2));\r\n-        }\r\n-        if (StringUtils.isNotBlank(atlasSpark1RuntimeId)) {\r\n-            moduleGroups.add(new DistributionModuleGroup(atlasSpark1RuntimeId, true, atlasSpark1x));\r\n-        }\r\n-        if (StringUtils.isNotBlank(atlasSpark2RuntimeId)) {\r\n-            moduleGroups.add(new DistributionModuleGroup(atlasSpark2RuntimeId, true, atlasSpark2x));\r\n-        }\r\n-\r\n-        return moduleGroups;\r\n-    }\r\n-}\r\n+// ============================================================================\n+//\n+// Copyright (C) 2006-2019 Talend Inc. - www.talend.com\n+//\n+// This source code is available under agreement available at\n+// %InstallDIR%\\features\\org.talend.rcp.branding.%PRODUCTNAME%\\%PRODUCTNAME%license.txt\n+//\n+// You should have received a copy of the agreement\n+// along with this program; if not, write to Talend SA\n+// 9 rue Pages 92150 Suresnes, France\n+//\n+// ============================================================================\n+package org.talend.hadoop.distribution.dynamic.template.modulegroup.hdp;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+import org.apache.commons.lang.StringUtils;\n+import org.talend.hadoop.distribution.DistributionModuleGroup;\n+import org.talend.hadoop.distribution.ESparkVersion;\n+import org.talend.hadoop.distribution.condition.BasicExpression;\n+import org.talend.hadoop.distribution.condition.BooleanOperator;\n+import org.talend.hadoop.distribution.condition.ComponentCondition;\n+import org.talend.hadoop.distribution.condition.EqualityOperator;\n+import org.talend.hadoop.distribution.condition.MultiComponentCondition;\n+import org.talend.hadoop.distribution.condition.SimpleComponentCondition;\n+import org.talend.hadoop.distribution.constants.MRConstant;\n+import org.talend.hadoop.distribution.dynamic.adapter.DynamicPluginAdapter;\n+import org.talend.hadoop.distribution.dynamic.template.modulegroup.DynamicModuleGroupConstant;\n+import org.talend.hadoop.distribution.dynamic.template.modulegroup.DynamicSparkBatchModuleGroup;\n+\n+\n+/**\n+ * DOC cmeng  class global comment. Detailled comment\n+ */\n+public class DynamicHDPSparkBatchModuleGroup extends DynamicSparkBatchModuleGroup {\n+\n+    protected ComponentCondition conditionNotSpark16;\n+\n+    public DynamicHDPSparkBatchModuleGroup(DynamicPluginAdapter pluginAdapter) {\n+        super(pluginAdapter);\n+    }\n+\n+    @Override\n+    protected void initConditions() {\n+        super.initConditions();\n+        conditionNotSpark16 = new SimpleComponentCondition(\n+                new BasicExpression(\"SUPPORTED_SPARK_VERSION\", EqualityOperator.NOT_EQ, ESparkVersion.SPARK_1_6.getSparkVersion())); //$NON-NLS-1$\n+    }\n+\n+    @Override\n+    public Set<DistributionModuleGroup> getModuleGroups() throws Exception {\n+        Set<DistributionModuleGroup> moduleGroups = new HashSet<>();\n+        Set<DistributionModuleGroup> moduleGroupsFromSuper = super.getModuleGroups();\n+        if (moduleGroupsFromSuper != null && !moduleGroupsFromSuper.isEmpty()) {\n+            moduleGroups.addAll(moduleGroupsFromSuper);\n+        }\n+        DynamicPluginAdapter pluginAdapter = getPluginAdapter();\n+\n+        String spark2RuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.SPARK2_MODULE_GROUP.getModuleName());\n+        String sparkMRRequiredRuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.SPARK_MRREQUIRED_MODULE_GROUP.getModuleName());\n+        String hdfsRuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.HDFS_MODULE_GROUP.getModuleName());\n+        String hdfsNotSpark16RuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.HDFS_NOT_SPARK_1_6_MODULE_GROUP.getModuleName());\n+        String tezNotSpark16RuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.TEZ_NOT_SPARK_1_6_MODULE_GROUP.getModuleName());\n+        String mapReduceRuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.MAPREDUCE_MODULE_GROUP.getModuleName());\n+        String atlasSpark1RuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.ATLAS_SPARK_1_MODULE_GROUP.getModuleName());\n+        String atlasSpark2RuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.ATLAS_SPARK_2_MODULE_GROUP.getModuleName());\n+        String sqoopRuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.SQOOP_MODULE_GROUP.getModuleName());\n+        String sqoopParquetRuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.SQOOP_PARQUET_MODULE_GROUP.getModuleName());\n+        String hBaseRuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.HBASE_MODULE_GROUP.getModuleName());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "631883aa4c7b0d837411dcc8ccbab278701c3fb3"}, "originalPosition": 198}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYxNDk2NQ==", "bodyText": "hbase modifications shouldn't be here. Will revert that.", "url": "https://github.com/Talend/tbd-studio-se/pull/1325#discussion_r395614965", "createdAt": "2020-03-20T12:51:44Z", "author": {"login": "sponomarova"}, "path": "main/plugins/org.talend.hadoop.distribution/src/main/java/org/talend/hadoop/distribution/dynamic/template/modulegroup/hdp/DynamicHDPSparkBatchModuleGroup.java", "diffHunk": "@@ -1,117 +1,138 @@\n-// ============================================================================\r\n-//\r\n-// Copyright (C) 2006-2019 Talend Inc. - www.talend.com\r\n-//\r\n-// This source code is available under agreement available at\r\n-// %InstallDIR%\\features\\org.talend.rcp.branding.%PRODUCTNAME%\\%PRODUCTNAME%license.txt\r\n-//\r\n-// You should have received a copy of the agreement\r\n-// along with this program; if not, write to Talend SA\r\n-// 9 rue Pages 92150 Suresnes, France\r\n-//\r\n-// ============================================================================\r\n-package org.talend.hadoop.distribution.dynamic.template.modulegroup.hdp;\r\n-\r\n-import java.util.HashSet;\r\n-import java.util.Set;\r\n-\r\n-import org.apache.commons.lang.StringUtils;\r\n-import org.talend.hadoop.distribution.DistributionModuleGroup;\r\n-import org.talend.hadoop.distribution.ESparkVersion;\r\n-import org.talend.hadoop.distribution.condition.BasicExpression;\r\n-import org.talend.hadoop.distribution.condition.BooleanOperator;\r\n-import org.talend.hadoop.distribution.condition.ComponentCondition;\r\n-import org.talend.hadoop.distribution.condition.EqualityOperator;\r\n-import org.talend.hadoop.distribution.condition.MultiComponentCondition;\r\n-import org.talend.hadoop.distribution.condition.SimpleComponentCondition;\r\n-import org.talend.hadoop.distribution.constants.MRConstant;\r\n-import org.talend.hadoop.distribution.dynamic.adapter.DynamicPluginAdapter;\r\n-import org.talend.hadoop.distribution.dynamic.template.modulegroup.DynamicModuleGroupConstant;\r\n-import org.talend.hadoop.distribution.dynamic.template.modulegroup.DynamicSparkBatchModuleGroup;\r\n-\r\n-\r\n-/**\r\n- * DOC cmeng  class global comment. Detailled comment\r\n- */\r\n-public class DynamicHDPSparkBatchModuleGroup extends DynamicSparkBatchModuleGroup {\r\n-\r\n-    protected ComponentCondition conditionNotSpark16;\r\n-\r\n-    public DynamicHDPSparkBatchModuleGroup(DynamicPluginAdapter pluginAdapter) {\r\n-        super(pluginAdapter);\r\n-    }\r\n-\r\n-    @Override\r\n-    protected void initConditions() {\r\n-        super.initConditions();\r\n-        conditionNotSpark16 = new SimpleComponentCondition(\r\n-                new BasicExpression(\"SUPPORTED_SPARK_VERSION\", EqualityOperator.NOT_EQ, ESparkVersion.SPARK_1_6.getSparkVersion())); //$NON-NLS-1$\r\n-    }\r\n-\r\n-    @Override\r\n-    public Set<DistributionModuleGroup> getModuleGroups() throws Exception {\r\n-        Set<DistributionModuleGroup> moduleGroups = new HashSet<>();\r\n-        Set<DistributionModuleGroup> moduleGroupsFromSuper = super.getModuleGroups();\r\n-        if (moduleGroupsFromSuper != null && !moduleGroupsFromSuper.isEmpty()) {\r\n-            moduleGroups.addAll(moduleGroupsFromSuper);\r\n-        }\r\n-        DynamicPluginAdapter pluginAdapter = getPluginAdapter();\r\n-\r\n-        String spark2RuntimeId = pluginAdapter\r\n-                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.SPARK2_MODULE_GROUP.getModuleName());\r\n-        String sparkMRRequiredRuntimeId = pluginAdapter\r\n-                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.SPARK_MRREQUIRED_MODULE_GROUP.getModuleName());\r\n-        String hdfsRuntimeId = pluginAdapter\r\n-                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.HDFS_MODULE_GROUP.getModuleName());\r\n-        String hdfsNotSpark16RuntimeId = pluginAdapter\r\n-                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.HDFS_NOT_SPARK_1_6_MODULE_GROUP.getModuleName());\r\n-        String tezNotSpark16RuntimeId = pluginAdapter\r\n-                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.TEZ_NOT_SPARK_1_6_MODULE_GROUP.getModuleName());\r\n-        String mapReduceRuntimeId = pluginAdapter\r\n-                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.MAPREDUCE_MODULE_GROUP.getModuleName());\r\n-        String atlasSpark1RuntimeId = pluginAdapter\r\n-                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.ATLAS_SPARK_1_MODULE_GROUP.getModuleName());\r\n-        String atlasSpark2RuntimeId = pluginAdapter\r\n-                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.ATLAS_SPARK_2_MODULE_GROUP.getModuleName());\r\n-\r\n-        checkRuntimeId(spark2RuntimeId);\r\n-        checkRuntimeId(sparkMRRequiredRuntimeId);\r\n-        checkRuntimeId(hdfsRuntimeId);\r\n-        checkRuntimeId(hdfsNotSpark16RuntimeId);\r\n-        checkRuntimeId(tezNotSpark16RuntimeId);\r\n-        checkRuntimeId(mapReduceRuntimeId);\r\n-        checkRuntimeId(atlasSpark1RuntimeId);\r\n-        checkRuntimeId(atlasSpark2RuntimeId);\r\n-\r\n-        ComponentCondition useAtlas = new SimpleComponentCondition(new BasicExpression(MRConstant.USE_ATLAS));\r\n-        ComponentCondition atlasSpark1x = new MultiComponentCondition(useAtlas, BooleanOperator.AND, conditionSpark1);\r\n-        ComponentCondition atlasSpark2x = new MultiComponentCondition(useAtlas, BooleanOperator.AND, conditionSpark2);\r\n-\r\n-        if (StringUtils.isNotBlank(sparkMRRequiredRuntimeId)) {\r\n-            moduleGroups.add(new DistributionModuleGroup(sparkMRRequiredRuntimeId, true, conditionSpark1));\r\n-            moduleGroups.add(new DistributionModuleGroup(sparkMRRequiredRuntimeId, true, conditionSpark2));\r\n-        }\r\n-        if (StringUtils.isNotBlank(hdfsRuntimeId)) {\r\n-            moduleGroups.add(new DistributionModuleGroup(hdfsRuntimeId, false, conditionSpark1));\r\n-            moduleGroups.add(new DistributionModuleGroup(hdfsRuntimeId, false, conditionSpark2));\r\n-        }\r\n-        if (StringUtils.isNotBlank(hdfsNotSpark16RuntimeId)) {\r\n-            moduleGroups.add(new DistributionModuleGroup(hdfsNotSpark16RuntimeId, false, conditionNotSpark16));\r\n-        }\r\n-        if (StringUtils.isNotBlank(tezNotSpark16RuntimeId)) {\r\n-            moduleGroups.add(new DistributionModuleGroup(tezNotSpark16RuntimeId, false, conditionNotSpark16));\r\n-        }\r\n-        if (StringUtils.isNotBlank(mapReduceRuntimeId)) {\r\n-            moduleGroups.add(new DistributionModuleGroup(mapReduceRuntimeId, false, conditionSpark1));\r\n-            moduleGroups.add(new DistributionModuleGroup(mapReduceRuntimeId, false, conditionSpark2));\r\n-        }\r\n-        if (StringUtils.isNotBlank(atlasSpark1RuntimeId)) {\r\n-            moduleGroups.add(new DistributionModuleGroup(atlasSpark1RuntimeId, true, atlasSpark1x));\r\n-        }\r\n-        if (StringUtils.isNotBlank(atlasSpark2RuntimeId)) {\r\n-            moduleGroups.add(new DistributionModuleGroup(atlasSpark2RuntimeId, true, atlasSpark2x));\r\n-        }\r\n-\r\n-        return moduleGroups;\r\n-    }\r\n-}\r\n+// ============================================================================\n+//\n+// Copyright (C) 2006-2019 Talend Inc. - www.talend.com\n+//\n+// This source code is available under agreement available at\n+// %InstallDIR%\\features\\org.talend.rcp.branding.%PRODUCTNAME%\\%PRODUCTNAME%license.txt\n+//\n+// You should have received a copy of the agreement\n+// along with this program; if not, write to Talend SA\n+// 9 rue Pages 92150 Suresnes, France\n+//\n+// ============================================================================\n+package org.talend.hadoop.distribution.dynamic.template.modulegroup.hdp;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+import org.apache.commons.lang.StringUtils;\n+import org.talend.hadoop.distribution.DistributionModuleGroup;\n+import org.talend.hadoop.distribution.ESparkVersion;\n+import org.talend.hadoop.distribution.condition.BasicExpression;\n+import org.talend.hadoop.distribution.condition.BooleanOperator;\n+import org.talend.hadoop.distribution.condition.ComponentCondition;\n+import org.talend.hadoop.distribution.condition.EqualityOperator;\n+import org.talend.hadoop.distribution.condition.MultiComponentCondition;\n+import org.talend.hadoop.distribution.condition.SimpleComponentCondition;\n+import org.talend.hadoop.distribution.constants.MRConstant;\n+import org.talend.hadoop.distribution.dynamic.adapter.DynamicPluginAdapter;\n+import org.talend.hadoop.distribution.dynamic.template.modulegroup.DynamicModuleGroupConstant;\n+import org.talend.hadoop.distribution.dynamic.template.modulegroup.DynamicSparkBatchModuleGroup;\n+\n+\n+/**\n+ * DOC cmeng  class global comment. Detailled comment\n+ */\n+public class DynamicHDPSparkBatchModuleGroup extends DynamicSparkBatchModuleGroup {\n+\n+    protected ComponentCondition conditionNotSpark16;\n+\n+    public DynamicHDPSparkBatchModuleGroup(DynamicPluginAdapter pluginAdapter) {\n+        super(pluginAdapter);\n+    }\n+\n+    @Override\n+    protected void initConditions() {\n+        super.initConditions();\n+        conditionNotSpark16 = new SimpleComponentCondition(\n+                new BasicExpression(\"SUPPORTED_SPARK_VERSION\", EqualityOperator.NOT_EQ, ESparkVersion.SPARK_1_6.getSparkVersion())); //$NON-NLS-1$\n+    }\n+\n+    @Override\n+    public Set<DistributionModuleGroup> getModuleGroups() throws Exception {\n+        Set<DistributionModuleGroup> moduleGroups = new HashSet<>();\n+        Set<DistributionModuleGroup> moduleGroupsFromSuper = super.getModuleGroups();\n+        if (moduleGroupsFromSuper != null && !moduleGroupsFromSuper.isEmpty()) {\n+            moduleGroups.addAll(moduleGroupsFromSuper);\n+        }\n+        DynamicPluginAdapter pluginAdapter = getPluginAdapter();\n+\n+        String spark2RuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.SPARK2_MODULE_GROUP.getModuleName());\n+        String sparkMRRequiredRuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.SPARK_MRREQUIRED_MODULE_GROUP.getModuleName());\n+        String hdfsRuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.HDFS_MODULE_GROUP.getModuleName());\n+        String hdfsNotSpark16RuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.HDFS_NOT_SPARK_1_6_MODULE_GROUP.getModuleName());\n+        String tezNotSpark16RuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.TEZ_NOT_SPARK_1_6_MODULE_GROUP.getModuleName());\n+        String mapReduceRuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.MAPREDUCE_MODULE_GROUP.getModuleName());\n+        String atlasSpark1RuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.ATLAS_SPARK_1_MODULE_GROUP.getModuleName());\n+        String atlasSpark2RuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.ATLAS_SPARK_2_MODULE_GROUP.getModuleName());\n+        String sqoopRuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.SQOOP_MODULE_GROUP.getModuleName());\n+        String sqoopParquetRuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.SQOOP_PARQUET_MODULE_GROUP.getModuleName());\n+        String hBaseRuntimeId = pluginAdapter\n+                .getRuntimeModuleGroupIdByTemplateId(DynamicModuleGroupConstant.HBASE_MODULE_GROUP.getModuleName());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU0NjIyNA=="}, "originalCommit": {"oid": "631883aa4c7b0d837411dcc8ccbab278701c3fb3"}, "originalPosition": 198}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1MTczNzcxOnYy", "diffSide": "RIGHT", "path": "main/plugins/org.talend.hadoop.distribution.hdpx/resources/builtin/hdpx/Hortonworks_HDP_2_6_0_3_8.json", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxMDoyNToxN1rOF5OTCA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxNDoxNzowM1rOF5Vg2Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU0NzQwMA==", "bodyText": "Why does this file appear all modified ?", "url": "https://github.com/Talend/tbd-studio-se/pull/1325#discussion_r395547400", "createdAt": "2020-03-20T10:25:17Z", "author": {"login": "lbourgeois"}, "path": "main/plugins/org.talend.hadoop.distribution.hdpx/resources/builtin/hdpx/Hortonworks_HDP_2_6_0_3_8.json", "diffHunk": "@@ -0,0 +1,10537 @@\n+{", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "631883aa4c7b0d837411dcc8ccbab278701c3fb3"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTYxNTYyNg==", "bodyText": "No, only part of this file but it was re-written when I did \"cherry-pick\". Maybe will revert that and apply changes manually.", "url": "https://github.com/Talend/tbd-studio-se/pull/1325#discussion_r395615626", "createdAt": "2020-03-20T12:53:03Z", "author": {"login": "sponomarova"}, "path": "main/plugins/org.talend.hadoop.distribution.hdpx/resources/builtin/hdpx/Hortonworks_HDP_2_6_0_3_8.json", "diffHunk": "@@ -0,0 +1,10537 @@\n+{", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU0NzQwMA=="}, "originalCommit": {"oid": "631883aa4c7b0d837411dcc8ccbab278701c3fb3"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTY2NDA1MQ==", "bodyText": "Found the root cause : hdp2x folder in 7.2 was renamed hdpx in 7.3 (because it started to include hdp 3.1)", "url": "https://github.com/Talend/tbd-studio-se/pull/1325#discussion_r395664051", "createdAt": "2020-03-20T14:14:35Z", "author": {"login": "lbourgeois"}, "path": "main/plugins/org.talend.hadoop.distribution.hdpx/resources/builtin/hdpx/Hortonworks_HDP_2_6_0_3_8.json", "diffHunk": "@@ -0,0 +1,10537 @@\n+{", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU0NzQwMA=="}, "originalCommit": {"oid": "631883aa4c7b0d837411dcc8ccbab278701c3fb3"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTY2NTYyNQ==", "bodyText": "This file should be moved to hdp2xx folder or deleted if modifications on hdp2xx folder already reported", "url": "https://github.com/Talend/tbd-studio-se/pull/1325#discussion_r395665625", "createdAt": "2020-03-20T14:17:03Z", "author": {"login": "lbourgeois"}, "path": "main/plugins/org.talend.hadoop.distribution.hdpx/resources/builtin/hdpx/Hortonworks_HDP_2_6_0_3_8.json", "diffHunk": "@@ -0,0 +1,10537 @@\n+{", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTU0NzQwMA=="}, "originalCommit": {"oid": "631883aa4c7b0d837411dcc8ccbab278701c3fb3"}, "originalPosition": 1}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1MjQ3OTY1OnYy", "diffSide": "RIGHT", "path": "main/plugins/org.talend.hadoop.distribution.hdpx/resources/template/hdpx/hdp2xxTemplate.json", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxNDoyMToxMFrOF5Vq7w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxNDoyMToxMFrOF5Vq7w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTY2ODIwNw==", "bodyText": "this file should be moved to hdp2xx folder", "url": "https://github.com/Talend/tbd-studio-se/pull/1325#discussion_r395668207", "createdAt": "2020-03-20T14:21:10Z", "author": {"login": "lbourgeois"}, "path": "main/plugins/org.talend.hadoop.distribution.hdpx/resources/template/hdpx/hdp2xxTemplate.json", "diffHunk": "@@ -0,0 +1,1460 @@\n+{", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d1ddd4b76ab2a2a6a21ae74f30dff9dba8714fd0"}, "originalPosition": 1}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1Mjk4ODQ1OnYy", "diffSide": "RIGHT", "path": "main/plugins/org.talend.hadoop.distribution.hdpx/resources/template/hdp2xx/hdp2xxTemplate.json", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxNjoyNzo0M1rOF5ayGA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxNzoxMDo1OFrOF5cVHg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1MTk2MA==", "bodyText": "I am not confident with those changes as I see that in master we have Spark 1.6 and 2.1 : https://github.com/Talend/tbd-studio-se/blob/master/main/plugins/org.talend.hadoop.distribution.hdpx/resources/template/hdpx/hdp2xxTemplate.json#L14", "url": "https://github.com/Talend/tbd-studio-se/pull/1325#discussion_r395751960", "createdAt": "2020-03-20T16:27:43Z", "author": {"login": "lbourgeois"}, "path": "main/plugins/org.talend.hadoop.distribution.hdpx/resources/template/hdp2xx/hdp2xxTemplate.json", "diffHunk": "@@ -1,489 +1,491 @@\n {\n-  \"id\": \"HDP2.X.X\",\n-  \"name\": \"Hortonworks HDP2.X.X template\",\n-  \"distribution\": \"HORTONWORKS\",\n-  \"templateId\": \"HDP2xxDistributionTemplate\",\n-  \"baseVersion\": \"2.5.0\",\n-  \"topVersion\": \"3.0.0\",\n-  \"dynamicVersion\": \"will be filled during runtime\",\n-  \"properties\": {\n-    \"context\": \"plugin:org.talend.hadoop.distribution.hdpx\"\n-  },\n-  \"description\": \"\",\n-  \"supportedSparkVersions\": [\n-    \"SPARK_1_6\",\n-    \"SPARK_2_1\"\n-  ],\n-  \"modules\": [\n-    {\n-      \"id\": \"commons-lang3-3.5\",\n-      \"type\": \"STANDARD\",\n-      \"context\": \"{properties.context}\",\n-      \"jarName\": \"commons-lang3-3.5.jar\",\n-      \"mvnUri\": \"mvn:org.talend.libraries/commons-lang3-3.5/6.2.0\",\n-      \"useStudioRepository\": \"true\",\n-      \"supportedSparkVersions\": [\n+\t\"id\": \"HDP2.X.X\",\n+\t\"name\": \"Hortonworks HDP2.X.X template\",\n+\t\"distribution\": \"HORTONWORKS\",\n+\t\"templateId\": \"HDP2xxDistributionTemplate\",\n+\t\"baseVersion\": \"2.5.0\",\n+\t\"topVersion\": \"3.0.3\",\n+\t\"dynamicVersion\": \"will be filled during runtime\",\n+\t\"properties\": {\n+\t\t\"context\": \"plugin:org.talend.hadoop.distribution.hdpx\"\n+\t},\n+\t\"description\": \"\",\n+\t\"supportedSparkVersions\": [\n+        \"SPARK_2_0\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "26e324c23abd1643fb467caf188dfd54832b09da"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc2NDA0OQ==", "bodyText": "Agree. Not quite clear but that's how it is on patch/7.2.1 at the moment:\n\n  \n    \n      tbd-studio-se/main/plugins/org.talend.hadoop.distribution.hdpx/resources/template/hdp2xx/hdp2xxTemplate.json\n    \n    \n         Line 14\n      in\n      8524abb\n    \n    \n    \n    \n\n        \n          \n           \"SPARK_2_0\",", "url": "https://github.com/Talend/tbd-studio-se/pull/1325#discussion_r395764049", "createdAt": "2020-03-20T16:47:44Z", "author": {"login": "sponomarova"}, "path": "main/plugins/org.talend.hadoop.distribution.hdpx/resources/template/hdp2xx/hdp2xxTemplate.json", "diffHunk": "@@ -1,489 +1,491 @@\n {\n-  \"id\": \"HDP2.X.X\",\n-  \"name\": \"Hortonworks HDP2.X.X template\",\n-  \"distribution\": \"HORTONWORKS\",\n-  \"templateId\": \"HDP2xxDistributionTemplate\",\n-  \"baseVersion\": \"2.5.0\",\n-  \"topVersion\": \"3.0.0\",\n-  \"dynamicVersion\": \"will be filled during runtime\",\n-  \"properties\": {\n-    \"context\": \"plugin:org.talend.hadoop.distribution.hdpx\"\n-  },\n-  \"description\": \"\",\n-  \"supportedSparkVersions\": [\n-    \"SPARK_1_6\",\n-    \"SPARK_2_1\"\n-  ],\n-  \"modules\": [\n-    {\n-      \"id\": \"commons-lang3-3.5\",\n-      \"type\": \"STANDARD\",\n-      \"context\": \"{properties.context}\",\n-      \"jarName\": \"commons-lang3-3.5.jar\",\n-      \"mvnUri\": \"mvn:org.talend.libraries/commons-lang3-3.5/6.2.0\",\n-      \"useStudioRepository\": \"true\",\n-      \"supportedSparkVersions\": [\n+\t\"id\": \"HDP2.X.X\",\n+\t\"name\": \"Hortonworks HDP2.X.X template\",\n+\t\"distribution\": \"HORTONWORKS\",\n+\t\"templateId\": \"HDP2xxDistributionTemplate\",\n+\t\"baseVersion\": \"2.5.0\",\n+\t\"topVersion\": \"3.0.3\",\n+\t\"dynamicVersion\": \"will be filled during runtime\",\n+\t\"properties\": {\n+\t\t\"context\": \"plugin:org.talend.hadoop.distribution.hdpx\"\n+\t},\n+\t\"description\": \"\",\n+\t\"supportedSparkVersions\": [\n+        \"SPARK_2_0\",", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1MTk2MA=="}, "originalCommit": {"oid": "26e324c23abd1643fb467caf188dfd54832b09da"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc3NzMxMA==", "bodyText": "Indeed no reason to change that in scope of TBD-9956 but not clear why we have such diffs + official doc says 1.6 and 2.1 https://docs.cloudera.com/HDPDocuments/HDPforCloud/HDPforCloud-2.6.5/hdp-release-notes/content/hdp_comp_versions.html", "url": "https://github.com/Talend/tbd-studio-se/pull/1325#discussion_r395777310", "createdAt": "2020-03-20T17:10:58Z", "author": {"login": "lbourgeois"}, "path": "main/plugins/org.talend.hadoop.distribution.hdpx/resources/template/hdp2xx/hdp2xxTemplate.json", "diffHunk": "@@ -1,489 +1,491 @@\n {\n-  \"id\": \"HDP2.X.X\",\n-  \"name\": \"Hortonworks HDP2.X.X template\",\n-  \"distribution\": \"HORTONWORKS\",\n-  \"templateId\": \"HDP2xxDistributionTemplate\",\n-  \"baseVersion\": \"2.5.0\",\n-  \"topVersion\": \"3.0.0\",\n-  \"dynamicVersion\": \"will be filled during runtime\",\n-  \"properties\": {\n-    \"context\": \"plugin:org.talend.hadoop.distribution.hdpx\"\n-  },\n-  \"description\": \"\",\n-  \"supportedSparkVersions\": [\n-    \"SPARK_1_6\",\n-    \"SPARK_2_1\"\n-  ],\n-  \"modules\": [\n-    {\n-      \"id\": \"commons-lang3-3.5\",\n-      \"type\": \"STANDARD\",\n-      \"context\": \"{properties.context}\",\n-      \"jarName\": \"commons-lang3-3.5.jar\",\n-      \"mvnUri\": \"mvn:org.talend.libraries/commons-lang3-3.5/6.2.0\",\n-      \"useStudioRepository\": \"true\",\n-      \"supportedSparkVersions\": [\n+\t\"id\": \"HDP2.X.X\",\n+\t\"name\": \"Hortonworks HDP2.X.X template\",\n+\t\"distribution\": \"HORTONWORKS\",\n+\t\"templateId\": \"HDP2xxDistributionTemplate\",\n+\t\"baseVersion\": \"2.5.0\",\n+\t\"topVersion\": \"3.0.3\",\n+\t\"dynamicVersion\": \"will be filled during runtime\",\n+\t\"properties\": {\n+\t\t\"context\": \"plugin:org.talend.hadoop.distribution.hdpx\"\n+\t},\n+\t\"description\": \"\",\n+\t\"supportedSparkVersions\": [\n+        \"SPARK_2_0\",", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc1MTk2MA=="}, "originalCommit": {"oid": "26e324c23abd1643fb467caf188dfd54832b09da"}, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1MzE3Njk3OnYy", "diffSide": "RIGHT", "path": "main/plugins/org.talend.hadoop.distribution.hdpx/resources/builtin/hdp2xx/Hortonworks_HDP_2_6_0_3_8.json", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxNzoyMTozM1rOF5csrg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQxNzozNjowNFrOF5dMTg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc4MzM0Mg==", "bodyText": "Can't see addition of parquet-avro-1.4.1 added in https://github.com/Talend/tbd-studio-se/pull/1313/files", "url": "https://github.com/Talend/tbd-studio-se/pull/1325#discussion_r395783342", "createdAt": "2020-03-20T17:21:33Z", "author": {"login": "lbourgeois"}, "path": "main/plugins/org.talend.hadoop.distribution.hdpx/resources/builtin/hdp2xx/Hortonworks_HDP_2_6_0_3_8.json", "diffHunk": "@@ -6380,6 +6380,18 @@\n         \"childNodes\" : [ ],", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "26e324c23abd1643fb467caf188dfd54832b09da"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc5MTQzOA==", "bodyText": "Not included for some reason. Will re-generate build-in.", "url": "https://github.com/Talend/tbd-studio-se/pull/1325#discussion_r395791438", "createdAt": "2020-03-20T17:36:04Z", "author": {"login": "sponomarova"}, "path": "main/plugins/org.talend.hadoop.distribution.hdpx/resources/builtin/hdp2xx/Hortonworks_HDP_2_6_0_3_8.json", "diffHunk": "@@ -6380,6 +6380,18 @@\n         \"childNodes\" : [ ],", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTc4MzM0Mg=="}, "originalCommit": {"oid": "26e324c23abd1643fb467caf188dfd54832b09da"}, "originalPosition": 1}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4861, "cost": 1, "resetAt": "2021-11-13T14:23:39Z"}}}