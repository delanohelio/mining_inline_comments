{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzkyNjAwNDY1", "number": 980, "title": "HTTP Client Pipelining fullduplex", "bodyText": "Motivation:\nThe queue which orders and sequences HTTP pipelining on the client side\nhas been shown to lead to duplicate subscribe exceptions and also\ndoesn't support full duplex read/write.\nModifications:\n\nThe first was related to DefaultNettyPipelinedConnection\nwhich may have enqueued out of order which lead to a duplicate subscribe\nexception on NettyChannelPublisher. The DefaultNettyPipelinedConnection\nwas rewritten to avoid using the SequentialTaskQueue (which relies upon\nthread locals for single item execution and async completion) and also\ndoesn't allow for full duplex (write must finish before read starts),\nand those issues are both fixed.\nClientClosureRaceTest is intentionally closing the server connection\nabrubtley, which may result in writing a request that is not\nautomatically retryable. The retry strategy should always retry in this\ncase or else the test may hang/fail.\n\nResult:\nHTTP client now support full duplex pipelining.", "createdAt": "2020-03-23T19:39:08Z", "url": "https://github.com/apple/servicetalk/pull/980", "merged": true, "mergeCommit": {"oid": "29a8d451a03aa26d257a3d342e5bd727a8f50a84"}, "closed": true, "closedAt": "2020-04-29T19:36:15Z", "author": {"login": "Scottmitch"}, "timelineItems": {"totalCount": 37, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcQnn4qAFqTM3OTkxOTg2NQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABccdbw2AH2gAyMzkyNjAwNDY1OjA4ZGFjYTQ2YTQ3MWUxZGZlZWM4OGI5YTJhNjc0OGM2NmMxYzRhZDA=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc5OTE5ODY1", "url": "https://github.com/apple/servicetalk/pull/980#pullrequestreview-379919865", "createdAt": "2020-03-24T00:18:44Z", "commit": {"oid": "7469332830d536d9dc82b82bad56e4860a3caf7e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNFQwMDoxODo0NFrOF6c4hw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNFQwMDoxODo0NFrOF6c4hw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjgzNDk1MQ==", "bodyText": "we could consider moving this to concurrent.internal in the future, but for now I just left them internal here.", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r396834951", "createdAt": "2020-03-24T00:18:44Z", "author": {"login": "Scottmitch"}, "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.CompletableSource;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.CompletableOperator;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.PublisherOperator;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+\n+import io.netty.channel.Channel;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.Arrays;\n+import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(NettyPipelinedConnection.class);\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            writeQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"writeQueueTail\");\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            readQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"readQueueTail\");\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node writeQueueTail;\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node readQueueTail;\n+\n+    private final NettyConnection<Resp, Req> connection;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} producing the request(s) to write.\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        return Publisher.defer(() -> {\n+            // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+\n+            // Setup read side publisher and nodes\n+            DelayedSubscribePublisher<Resp> delayedResponsePublisher = new DelayedSubscribePublisher<>(\n+                    toSource(connection.read()));\n+            Node readNode = new Node(delayedResponsePublisher::processSubscribers);\n+            Publisher<Resp> composedResponsePublisher =\n+                    delayedResponsePublisher.liftSync(new ReadPopNextOperator(readNode));\n+\n+            // Setup write side publisher and nodes\n+            DelayedSubscribeCompletable delayedRequestCompletable = new DelayedSubscribeCompletable(toSource(\n+                            connection.write(requestPublisher, flushStrategySupplier, writeDemandEstimatorSupplier)));\n+            Node writeNode = new Node(() -> {\n+                try {\n+                    queueOffer(readQueueTailUpdater, readNode);\n+                } finally {\n+                    delayedRequestCompletable.processSubscribers();\n+                }\n+            });\n+\n+            queueOffer(writeQueueTailUpdater, writeNode);\n+\n+            return delayedRequestCompletable.liftSync(new WritePopNextOperator(writeNode))\n+                    // If there is an error on the read/write side we propagate the errors between the two via merge.\n+                    .merge(composedResponsePublisher);\n+        });\n+    }\n+\n+    @Override\n+    public SocketAddress localAddress() {\n+        return connection.localAddress();\n+    }\n+\n+    @Override\n+    public SocketAddress remoteAddress() {\n+        return connection.remoteAddress();\n+    }\n+\n+    @Override\n+    @Nullable\n+    public SSLSession sslSession() {\n+        return connection.sslSession();\n+    }\n+\n+    @Override\n+    public ExecutionContext executionContext() {\n+        return connection.executionContext();\n+    }\n+\n+    @Nullable\n+    @Override\n+    public <T> T socketOption(final SocketOption<T> option) {\n+        return connection.socketOption(option);\n+    }\n+\n+    @Override\n+    public Protocol protocol() {\n+        return connection.protocol();\n+    }\n+\n+    @Override\n+    public Single<Throwable> transportError() {\n+        return connection.transportError();\n+    }\n+\n+    @Override\n+    public Completable onClosing() {\n+        return connection.onClosing();\n+    }\n+\n+    @Override\n+    public Completable onClose() {\n+        return connection.onClose();\n+    }\n+\n+    @Override\n+    public Completable closeAsync() {\n+        return connection.closeAsync();\n+    }\n+\n+    @Override\n+    public Completable closeAsyncGracefully() {\n+        return connection.closeAsyncGracefully();\n+    }\n+\n+    @Override\n+    public Channel nettyChannel() {\n+        return connection.nettyChannel();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return getClass().getName() + '(' + connection + ')';\n+    }\n+\n+    @Override\n+    public Cancellable updateFlushStrategy(final NettyConnectionContext.FlushStrategyProvider strategyProvider) {\n+        return connection.updateFlushStrategy(strategyProvider);\n+    }\n+\n+    @Override\n+    public FlushStrategy defaultFlushStrategy() {\n+        return connection.defaultFlushStrategy();\n+    }\n+\n+    private void queueOffer(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node node) {\n+        for (;;) {\n+            Node tail = tailUpdater.get(this);\n+            if (tail == null) {\n+                if (tailUpdater.compareAndSet(this, null, node)) {\n+                    // node has been inserted and is the only node, we initiate processing.\n+                    safeProcessSubscribers(node.delayedSource);\n+                    break;\n+                }\n+                // Another thread won the race to offer a node, loop around and try again.\n+            } else if (tail.append(node)) {\n+                // Make the newly appended node visible as the tail. This is a best effort CAS and may fail because:\n+                // 1. Another thread is also inserting, has a stale tail, followed its existing tail links, and updated\n+                // the tail reference via queueOfferPatchTail.\n+                // 2. The consumer thread has seen the link from the old tail to the new node, processed node,\n+                // popped node from the list (updated node's next to point to EMPTY_NODE), another producer thread\n+                // appends a new node, sees the tail is popped, and updates the tail reference via CAS.\n+                tailUpdater.compareAndSet(this, tail, node);\n+                break;\n+            } else if (tail.isPopped()) {\n+                // A previously appended node was processed, and popped before updating the tail after append. In that\n+                // case the tail maybe pointing to an invalid node and we clear it out.\n+                if (tailUpdater.compareAndSet(this, tail, node)) {\n+                    safeProcessSubscribers(node.delayedSource);\n+                    break;\n+                }\n+                // Best effort to clear the tail, and failure is OK because:\n+                // 1. Another thread is in offer and already patched up the tail pointer and we will read the new tail\n+                // on the next loop iteration.\n+            } else if (queueOfferPatchTail(tailUpdater, node, tail)) {\n+                break;\n+            }\n+        }\n+    }\n+\n+    private boolean queueOfferPatchTail(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node node,\n+            final Node tail) {\n+        Node currentTail = tailUpdater.get(this);\n+        if (currentTail == tail) {\n+            // tail is stale so attempt to iterate through the linked list and update tail.\n+            currentTail = tail.iterateToTail();\n+            if (currentTail.isPopped()) {\n+                if (tailUpdater.compareAndSet(this, tail, node)) {\n+                    safeProcessSubscribers(node.delayedSource);\n+                    return true;\n+                }\n+            } else {\n+                tailUpdater.compareAndSet(this, tail, currentTail);\n+            }\n+            // Best effort to update/clear the tail, and failure is OK because:\n+            // 1. Another thread is in offer and already patched up the tail pointer and we will read the new\n+            // tail on the next loop iteration.\n+        }\n+        return false;\n+    }\n+\n+    private void queuePop(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node head) {\n+        // This method maybe called multiple times on the same node, in which case next will be EMPTY_NODE and the run\n+        // method will be a noop.\n+        Node next = head.pop();\n+        if (next != null) {\n+            safeProcessSubscribers(next.delayedSource);\n+        } else {\n+            tailUpdater.compareAndSet(this, head, null);\n+            // Best effort to clear the tail, and failure is OK because:\n+            // 1. Another thread appended this head, but has not yet updated the tail. In this case the tail will be\n+            // stale (e.g. pointing to head node that has already been processed) and corrected by future inserts.\n+        }\n+    }\n+\n+    private void safeProcessSubscribers(Runnable delayedSource) {\n+        try {\n+            delayedSource.run();\n+        } catch (Throwable cause) {\n+            connection.closeAsync().subscribe();\n+            LOGGER.warn(\"closing connection={} due to unexpected error on subscribe\", connection, cause);\n+        }\n+    }\n+\n+    /**\n+     * Logically equivalent to {@link Publisher#afterFinally(Runnable)} but relies upon internal queue CAS operations\n+     * to prevent multiple executions (e.g. reduces a CAS operation).\n+     */\n+    private final class ReadPopNextOperator implements PublisherOperator<Resp, Resp> {\n+        private final Node readNode;\n+\n+        private ReadPopNextOperator(final Node readNode) {\n+            this.readNode = readNode;\n+        }\n+\n+        @Override\n+        public PublisherSource.Subscriber<? super Resp> apply(PublisherSource.Subscriber<? super Resp> subscriber) {\n+            return new PublisherSource.Subscriber<Resp>() {\n+                @Override\n+                public void onSubscribe(final PublisherSource.Subscription subscription) {\n+                    subscriber.onSubscribe(new PublisherSource.Subscription() {\n+                        @Override\n+                        public void request(final long n) {\n+                            subscription.request(n);\n+                        }\n+\n+                        @Override\n+                        public void cancel() {\n+                            try {\n+                                subscription.cancel();\n+                            } finally {\n+                                pollNext();\n+                            }\n+                        }\n+                    });\n+                }\n+\n+                @Override\n+                public void onNext(@Nullable final Resp t) {\n+                    subscriber.onNext(t);\n+                }\n+\n+                @Override\n+                public void onError(final Throwable t) {\n+                    try {\n+                        subscriber.onError(t);\n+                    } finally {\n+                        pollNext();\n+                    }\n+                }\n+\n+                @Override\n+                public void onComplete() {\n+                    try {\n+                        subscriber.onComplete();\n+                    } finally {\n+                        pollNext();\n+                    }\n+                }\n+\n+                private void pollNext() {\n+                    queuePop(readQueueTailUpdater, readNode);\n+                }\n+            };\n+        }\n+    }\n+\n+    /**\n+     * Logically equivalent to {@link Completable#afterFinally(Runnable)} but relies upon internal queue CAS operations\n+     * to prevent multiple executions (e.g. reduces a CAS operation).\n+     */\n+    private final class WritePopNextOperator implements CompletableOperator {\n+        private final Node writeNode;\n+\n+        WritePopNextOperator(final Node writeNode) {\n+            this.writeNode = writeNode;\n+        }\n+\n+        @Override\n+        public CompletableSource.Subscriber apply(final CompletableSource.Subscriber subscriber) {\n+            return new CompletableSource.Subscriber() {\n+                @Override\n+                public void onSubscribe(final Cancellable cancellable) {\n+                    subscriber.onSubscribe(() -> {\n+                        try {\n+                            cancellable.cancel();\n+                        } finally {\n+                            pollNext();\n+                        }\n+                    });\n+                }\n+\n+                @Override\n+                public void onComplete() {\n+                    try {\n+                        subscriber.onComplete();\n+                    } finally {\n+                        pollNext();\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(final Throwable t) {\n+                    try {\n+                        subscriber.onError(t);\n+                    } finally {\n+                        pollNext();\n+                    }\n+                }\n+            };\n+        }\n+\n+        private void pollNext() {\n+            queuePop(writeQueueTailUpdater, writeNode);\n+        }\n+    }\n+\n+    private static final class Node {\n+        private static final Node EMPTY_NODE = new Node();\n+        private static final AtomicReferenceFieldUpdater<Node, Node> nextUpdater =\n+                newUpdater(Node.class, Node.class, \"next\");\n+        @Nullable\n+        private volatile Node next;\n+        final Runnable delayedSource;\n+\n+        Node(Runnable delayedSource) {\n+            this.delayedSource = requireNonNull(delayedSource);\n+        }\n+\n+        private Node() {\n+            this.next = this;\n+            this.delayedSource = () -> { };\n+        }\n+\n+        boolean append(Node next) {\n+            return nextUpdater.compareAndSet(this, null, next);\n+        }\n+\n+        @Nullable\n+        Node pop() {\n+            return nextUpdater.getAndSet(this, EMPTY_NODE);\n+        }\n+\n+        boolean isPopped() {\n+            return next == EMPTY_NODE;\n+        }\n+\n+        Node iterateToTail() {\n+            Node prev = this;\n+            Node next = prev.next;\n+            while (next != null) {\n+                prev = next;\n+                next = next.next;\n+            }\n+            return prev;\n+        }\n+    }\n+\n+    private static final class DelayedSubscribeCompletable extends Completable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7469332830d536d9dc82b82bad56e4860a3caf7e"}, "originalPosition": 438}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc5OTIwNDM1", "url": "https://github.com/apple/servicetalk/pull/980#pullrequestreview-379920435", "createdAt": "2020-03-24T00:20:28Z", "commit": {"oid": "7469332830d536d9dc82b82bad56e4860a3caf7e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNFQwMDoyMDoyOFrOF6c6Ig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNFQwMDoyMDoyOFrOF6c6Ig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjgzNTM2Mg==", "bodyText": "I wanted to keep the new API exposure for the NettyPipelinedConnection low for now, but I think this is worth revisiting as part of the larger \"how is state propagated on the server #981\" which may provide opportunities to clean this up.", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r396835362", "createdAt": "2020-03-24T00:20:28Z", "author": {"login": "Scottmitch"}, "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/PipelinedStreamingHttpConnection.java", "diffHunk": "@@ -19,38 +19,35 @@\n import io.servicetalk.concurrent.api.Publisher;\n import io.servicetalk.http.api.HttpExecutionContext;\n import io.servicetalk.http.api.StreamingHttpRequestResponseFactory;\n-import io.servicetalk.transport.netty.internal.DefaultNettyPipelinedConnection;\n import io.servicetalk.transport.netty.internal.FlushStrategy;\n import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimators;\n \n import javax.annotation.Nullable;\n \n final class PipelinedStreamingHttpConnection\n-        extends AbstractStreamingHttpConnection<DefaultNettyPipelinedConnection<Object, Object>> {\n-\n-    private final NettyConnection<Object, Object> nettyConnection;\n-\n+        extends AbstractStreamingHttpConnection<NettyPipelinedConnection<Object, Object>> {\n     PipelinedStreamingHttpConnection(final NettyConnection<Object, Object> connection,\n                                      final H1ProtocolConfig config,\n                                      final HttpExecutionContext executionContext,\n                                      final StreamingHttpRequestResponseFactory reqRespFactory) {\n-        super(new DefaultNettyPipelinedConnection<>(connection, config.maxPipelinedRequests()),\n+        super(new NettyPipelinedConnection<>(connection),\n                 config.maxPipelinedRequests(), executionContext, reqRespFactory, config.headersFactory());\n-        this.nettyConnection = connection;\n     }\n \n     @Override\n     protected Publisher<Object> writeAndRead(Publisher<Object> requestStream,\n                                              @Nullable final FlushStrategy flushStrategy) {\n         if (flushStrategy == null) {\n-            return connection.request(requestStream);\n+            return connection.write(requestStream, connection::defaultFlushStrategy,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7469332830d536d9dc82b82bad56e4860a3caf7e"}, "originalPosition": 32}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc5OTIwODAy", "url": "https://github.com/apple/servicetalk/pull/980#pullrequestreview-379920802", "createdAt": "2020-03-24T00:21:33Z", "commit": {"oid": "7469332830d536d9dc82b82bad56e4860a3caf7e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNFQwMDoyMTozM1rOF6c7Zw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNFQwMDoyMTozM1rOF6c7Zw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjgzNTY4Nw==", "bodyText": "this is also related to the larger \"state management on the server\" discussion too #981", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r396835687", "createdAt": "2020-03-24T00:21:33Z", "author": {"login": "Scottmitch"}, "path": "servicetalk-transport-netty-internal/src/main/java/io/servicetalk/transport/netty/internal/DefaultNettyConnection.java", "diffHunk": "@@ -537,6 +503,8 @@ public void channelWritabilityChanged(ChannelHandlerContext ctx) {\n             if (ctx.channel().isWritable()) {\n                 connection.channelOutboundListener.channelWritable();\n             } else if (connection.flushStrategyHolder.currentStrategy().shouldFlushOnUnwritable()) {\n+                // TODO(scott): if we have a flush per write operation, shouldFlushOnUnwritable is more challenging.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7469332830d536d9dc82b82bad56e4860a3caf7e"}, "originalPosition": 175}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgwNzc1NDgy", "url": "https://github.com/apple/servicetalk/pull/980#pullrequestreview-380775482", "createdAt": "2020-03-24T23:52:56Z", "commit": {"oid": "7469332830d536d9dc82b82bad56e4860a3caf7e"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 15, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNFQyMzo1Mjo1NlrOF7HXYQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQxODoyMjoxOFrOF7oixg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzUzMDk3Nw==", "bodyText": "shouldFlushOnUnwritable is to handle the case when we do not request more data to write because the channel buffer is full which in turn does not generate flush signals as there is no write activity. I think it still makes sense to consider that so that strategies like flush-on-end do not get deadlocked.", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r397530977", "createdAt": "2020-03-24T23:52:56Z", "author": {"login": "NiteshKant"}, "path": "servicetalk-transport-netty-internal/src/main/java/io/servicetalk/transport/netty/internal/DefaultNettyConnection.java", "diffHunk": "@@ -537,6 +503,8 @@ public void channelWritabilityChanged(ChannelHandlerContext ctx) {\n             if (ctx.channel().isWritable()) {\n                 connection.channelOutboundListener.channelWritable();\n             } else if (connection.flushStrategyHolder.currentStrategy().shouldFlushOnUnwritable()) {\n+                // TODO(scott): if we have a flush per write operation, shouldFlushOnUnwritable is more challenging.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjgzNTY4Nw=="}, "originalCommit": {"oid": "7469332830d536d9dc82b82bad56e4860a3caf7e"}, "originalPosition": 175}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzUzNjEzOQ==", "bodyText": "nit:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                public static WriteDemandEstimator newDefaultEstimator() {\n          \n          \n            \n                public static WriteDemandEstimator defaultEstimator() {", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r397536139", "createdAt": "2020-03-25T00:09:12Z", "author": {"login": "NiteshKant"}, "path": "servicetalk-transport-netty-internal/src/main/java/io/servicetalk/transport/netty/internal/WriteDemandEstimators.java", "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.transport.netty.internal;\n+\n+/**\n+ * Utility methods associated with {@link WriteDemandEstimator}.\n+ */\n+public final class WriteDemandEstimators {\n+    private WriteDemandEstimators() {\n+        // no instance\n+    }\n+\n+    /**\n+     * Returns a new instance of a default implementation of {@link WriteDemandEstimator}.\n+     *\n+     * @return A new instance of a default implementation of {@link WriteDemandEstimator}.\n+     */\n+    public static WriteDemandEstimator newDefaultEstimator() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7469332830d536d9dc82b82bad56e4860a3caf7e"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzUzNjc2NA==", "bodyText": "Is the intent here to add utility methods or just have this as a static factory for WriteDemandEstimator as elsewhere?\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n             * Utility methods associated with {@link WriteDemandEstimator}.\n          \n          \n            \n             * Factory to create instances of {@link WriteDemandEstimator}s", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r397536764", "createdAt": "2020-03-25T00:11:07Z", "author": {"login": "NiteshKant"}, "path": "servicetalk-transport-netty-internal/src/main/java/io/servicetalk/transport/netty/internal/WriteDemandEstimators.java", "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.transport.netty.internal;\n+\n+/**\n+ * Utility methods associated with {@link WriteDemandEstimator}.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7469332830d536d9dc82b82bad56e4860a3caf7e"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzU0MDAzMA==", "bodyText": "Specify a FlushStrategy (eg: flushOnEnd()) here to be comparable to writeAndFlush before?", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r397540030", "createdAt": "2020-03-25T00:21:50Z", "author": {"login": "NiteshKant"}, "path": "servicetalk-tcp-netty-internal/src/test/java/io/servicetalk/tcp/netty/internal/TcpServerBinderConnectionAcceptorTest.java", "diffHunk": "@@ -147,7 +148,7 @@ public void testAcceptConnection() {\n         try {\n             NettyConnection<Buffer, Buffer> connection = client.connectBlocking(CLIENT_CTX, serverAddress);\n             final Buffer buffer = connection.executionContext().bufferAllocator().fromAscii(\"Hello\");\n-            connection.writeAndFlush(buffer).toFuture().get();\n+            connection.write(Publisher.from(buffer)).toFuture().get();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7469332830d536d9dc82b82bad56e4860a3caf7e"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzU0MDI1NA==", "bodyText": "Specify a FlushStrategy (eg: flushOnEnd()) here to be comparable to writeAndFlush before?", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r397540254", "createdAt": "2020-03-25T00:22:37Z", "author": {"login": "NiteshKant"}, "path": "servicetalk-tcp-netty-internal/src/test/java/io/servicetalk/tcp/netty/internal/TcpConnectorTest.java", "diffHunk": "@@ -58,7 +59,8 @@ public void testWriteAndRead() throws Exception {\n \n     private static void testWriteAndRead(NettyConnection<Buffer, Buffer> connection)\n             throws ExecutionException, InterruptedException {\n-        connection.writeAndFlush(connection.executionContext().bufferAllocator().fromAscii(\"Hello\")).toFuture().get();\n+        connection.write(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7469332830d536d9dc82b82bad56e4860a3caf7e"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzU0Mjc2MQ==", "bodyText": "Do we know what changed here that made this more deterministic?", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r397542761", "createdAt": "2020-03-25T00:31:20Z", "author": {"login": "NiteshKant"}, "path": "servicetalk-http-netty/src/test/java/io/servicetalk/http/netty/ClientClosureRaceTest.java", "diffHunk": "@@ -122,76 +122,68 @@ public void stopServer() throws Exception {\n \n     @Test\n     public void testSequential() throws Exception {\n-        final HttpClient client = newClientBuilder().build();\n-        runIterations(() -> client.request(client.get(\"/foo\")).flatMap(\n-                response -> client.request(client.get(\"/bar\"))));\n+        try (HttpClient client = newClientBuilder().build()) {\n+            runIterations(() -> client.request(client.get(\"/foo\")).flatMap(\n+                    response -> client.request(client.get(\"/bar\"))));\n+        }\n     }\n \n     @Test\n     public void testSequentialPosts() throws Exception {\n-        final HttpClient client = newClientBuilder().build();\n-        runIterations(() -> client.request(client.post(\"/foo\").payloadBody(\"Some payload\", textSerializer())).flatMap(\n-                response -> client.request(client.post(\"/bar\").payloadBody(\"Another payload\", textSerializer()))));\n+        try (HttpClient client = newClientBuilder().build()) {\n+            runIterations(() ->\n+                    client.request(client.post(\"/foo\").payloadBody(\"Some payload\", textSerializer())).flatMap(\n+                    response -> client.request(client.post(\"/bar\").payloadBody(\"Another payload\", textSerializer()))));\n+        }\n     }\n \n     @Test\n     public void testPipelined() throws Exception {\n-        final HttpClient client = newClientBuilder()\n+        try (HttpClient client = newClientBuilder()\n                 .protocols(h1().maxPipelinedRequests(2).build())\n-                .build();\n-        runIterations(() -> collectUnordered(client.request(client.get(\"/foo\")),\n-                client.request(client.get(\"/bar\"))));\n+                .build()) {\n+            runIterations(() -> collectUnordered(client.request(client.get(\"/foo\")),\n+                    client.request(client.get(\"/bar\"))));\n+        }\n     }\n \n     @Test\n     public void testPipelinedPosts() throws Exception {\n-        final HttpClient client = newClientBuilder()\n+        try (HttpClient client = newClientBuilder()\n                 .protocols(h1().maxPipelinedRequests(2).build())\n-                .build();\n-        runIterations(() -> collectUnordered(\n-                client.request(client.get(\"/foo\").payloadBody(\"Some payload\", textSerializer())),\n-                client.request(client.get(\"/bar\").payloadBody(\"Another payload\", textSerializer()))));\n+                .build()) {\n+            runIterations(() -> collectUnordered(\n+                    client.request(client.get(\"/foo\").payloadBody(\"Some payload\", textSerializer())),\n+                    client.request(client.get(\"/bar\").payloadBody(\"Another payload\", textSerializer()))));\n+        }\n     }\n \n     private void runIterations(Callable<Single<?>> test) throws Exception {\n         int count = 0;\n         try {\n-            while (!receivedExpectedError && count < ITERATIONS) {\n-                try {\n-                    count++;\n-                    Object response = test.call().toFuture().get();\n-                    LOGGER.debug(\"Response {} = {}\", count, response);\n-                } catch (Exception e) {\n-                    if (isAllowableError(e)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7469332830d536d9dc82b82bad56e4860a3caf7e"}, "originalPosition": 123}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzU0OTQ4MA==", "bodyText": "Doesn't using connection::defaultFlushStrategy here means we will not use the strategy updated above using updateFlushStrategy()?", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r397549480", "createdAt": "2020-03-25T00:55:04Z", "author": {"login": "NiteshKant"}, "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/PipelinedStreamingHttpConnection.java", "diffHunk": "@@ -19,38 +19,35 @@\n import io.servicetalk.concurrent.api.Publisher;\n import io.servicetalk.http.api.HttpExecutionContext;\n import io.servicetalk.http.api.StreamingHttpRequestResponseFactory;\n-import io.servicetalk.transport.netty.internal.DefaultNettyPipelinedConnection;\n import io.servicetalk.transport.netty.internal.FlushStrategy;\n import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimators;\n \n import javax.annotation.Nullable;\n \n final class PipelinedStreamingHttpConnection\n-        extends AbstractStreamingHttpConnection<DefaultNettyPipelinedConnection<Object, Object>> {\n-\n-    private final NettyConnection<Object, Object> nettyConnection;\n-\n+        extends AbstractStreamingHttpConnection<NettyPipelinedConnection<Object, Object>> {\n     PipelinedStreamingHttpConnection(final NettyConnection<Object, Object> connection,\n                                      final H1ProtocolConfig config,\n                                      final HttpExecutionContext executionContext,\n                                      final StreamingHttpRequestResponseFactory reqRespFactory) {\n-        super(new DefaultNettyPipelinedConnection<>(connection, config.maxPipelinedRequests()),\n+        super(new NettyPipelinedConnection<>(connection),\n                 config.maxPipelinedRequests(), executionContext, reqRespFactory, config.headersFactory());\n-        this.nettyConnection = connection;\n     }\n \n     @Override\n     protected Publisher<Object> writeAndRead(Publisher<Object> requestStream,\n                                              @Nullable final FlushStrategy flushStrategy) {\n         if (flushStrategy == null) {\n-            return connection.request(requestStream);\n+            return connection.write(requestStream, connection::defaultFlushStrategy,\n+                    WriteDemandEstimators::newDefaultEstimator);\n         } else {\n-            // Using the Writer abstraction here defers updating the flush strategy until just before this request is\n-            // written.\n-            return connection.request(() -> {\n+            // TODO(scott): if we can remove the flush state on the connection we can simplify the control flow here.\n+            return Publisher.defer(() -> {\n                 final Cancellable resetFlushStrategy = connection.updateFlushStrategy(\n                         (prev, isOriginal) -> isOriginal ? flushStrategy : prev);\n-                return nettyConnection.write(requestStream).afterFinally(resetFlushStrategy::cancel);\n+                return connection.write(requestStream, connection::defaultFlushStrategy,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7469332830d536d9dc82b82bad56e4860a3caf7e"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzU1MDMzNg==", "bodyText": "Can we provide connection.write(requestStream) also on the pipelined connection so that the defaults are left to the actual NettyConnection implementation?", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r397550336", "createdAt": "2020-03-25T00:58:04Z", "author": {"login": "NiteshKant"}, "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/PipelinedStreamingHttpConnection.java", "diffHunk": "@@ -19,38 +19,35 @@\n import io.servicetalk.concurrent.api.Publisher;\n import io.servicetalk.http.api.HttpExecutionContext;\n import io.servicetalk.http.api.StreamingHttpRequestResponseFactory;\n-import io.servicetalk.transport.netty.internal.DefaultNettyPipelinedConnection;\n import io.servicetalk.transport.netty.internal.FlushStrategy;\n import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimators;\n \n import javax.annotation.Nullable;\n \n final class PipelinedStreamingHttpConnection\n-        extends AbstractStreamingHttpConnection<DefaultNettyPipelinedConnection<Object, Object>> {\n-\n-    private final NettyConnection<Object, Object> nettyConnection;\n-\n+        extends AbstractStreamingHttpConnection<NettyPipelinedConnection<Object, Object>> {\n     PipelinedStreamingHttpConnection(final NettyConnection<Object, Object> connection,\n                                      final H1ProtocolConfig config,\n                                      final HttpExecutionContext executionContext,\n                                      final StreamingHttpRequestResponseFactory reqRespFactory) {\n-        super(new DefaultNettyPipelinedConnection<>(connection, config.maxPipelinedRequests()),\n+        super(new NettyPipelinedConnection<>(connection),\n                 config.maxPipelinedRequests(), executionContext, reqRespFactory, config.headersFactory());\n-        this.nettyConnection = connection;\n     }\n \n     @Override\n     protected Publisher<Object> writeAndRead(Publisher<Object> requestStream,\n                                              @Nullable final FlushStrategy flushStrategy) {\n         if (flushStrategy == null) {\n-            return connection.request(requestStream);\n+            return connection.write(requestStream, connection::defaultFlushStrategy,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7469332830d536d9dc82b82bad56e4860a3caf7e"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzYxOTAzMA==", "bodyText": "Hmm ... can this handle multiple requests in the same Publisher?", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r397619030", "createdAt": "2020-03-25T05:38:12Z", "author": {"login": "NiteshKant"}, "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.CompletableSource;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.CompletableOperator;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.PublisherOperator;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+\n+import io.netty.channel.Channel;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.Arrays;\n+import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(NettyPipelinedConnection.class);\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            writeQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"writeQueueTail\");\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            readQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"readQueueTail\");\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node writeQueueTail;\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node readQueueTail;\n+\n+    private final NettyConnection<Resp, Req> connection;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} producing the request(s) to write.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7469332830d536d9dc82b82bad56e4860a3caf7e"}, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzYyNzEyMQ==", "bodyText": "Won't this cause overlapping subscribes to connection.read()?\nIt seems this path is not covered in tests too.", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r397627121", "createdAt": "2020-03-25T06:09:58Z", "author": {"login": "NiteshKant"}, "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.CompletableSource;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.CompletableOperator;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.PublisherOperator;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+\n+import io.netty.channel.Channel;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.Arrays;\n+import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(NettyPipelinedConnection.class);\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            writeQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"writeQueueTail\");\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            readQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"readQueueTail\");\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node writeQueueTail;\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node readQueueTail;\n+\n+    private final NettyConnection<Resp, Req> connection;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} producing the request(s) to write.\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        return Publisher.defer(() -> {\n+            // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+\n+            // Setup read side publisher and nodes\n+            DelayedSubscribePublisher<Resp> delayedResponsePublisher = new DelayedSubscribePublisher<>(\n+                    toSource(connection.read()));\n+            Node readNode = new Node(delayedResponsePublisher::processSubscribers);\n+            Publisher<Resp> composedResponsePublisher =\n+                    delayedResponsePublisher.liftSync(new ReadPopNextOperator(readNode));\n+\n+            // Setup write side publisher and nodes\n+            DelayedSubscribeCompletable delayedRequestCompletable = new DelayedSubscribeCompletable(toSource(\n+                            connection.write(requestPublisher, flushStrategySupplier, writeDemandEstimatorSupplier)));\n+            Node writeNode = new Node(() -> {\n+                try {\n+                    queueOffer(readQueueTailUpdater, readNode);\n+                } finally {\n+                    delayedRequestCompletable.processSubscribers();\n+                }\n+            });\n+\n+            queueOffer(writeQueueTailUpdater, writeNode);\n+\n+            return delayedRequestCompletable.liftSync(new WritePopNextOperator(writeNode))\n+                    // If there is an error on the read/write side we propagate the errors between the two via merge.\n+                    .merge(composedResponsePublisher);\n+        });\n+    }\n+\n+    @Override\n+    public SocketAddress localAddress() {\n+        return connection.localAddress();\n+    }\n+\n+    @Override\n+    public SocketAddress remoteAddress() {\n+        return connection.remoteAddress();\n+    }\n+\n+    @Override\n+    @Nullable\n+    public SSLSession sslSession() {\n+        return connection.sslSession();\n+    }\n+\n+    @Override\n+    public ExecutionContext executionContext() {\n+        return connection.executionContext();\n+    }\n+\n+    @Nullable\n+    @Override\n+    public <T> T socketOption(final SocketOption<T> option) {\n+        return connection.socketOption(option);\n+    }\n+\n+    @Override\n+    public Protocol protocol() {\n+        return connection.protocol();\n+    }\n+\n+    @Override\n+    public Single<Throwable> transportError() {\n+        return connection.transportError();\n+    }\n+\n+    @Override\n+    public Completable onClosing() {\n+        return connection.onClosing();\n+    }\n+\n+    @Override\n+    public Completable onClose() {\n+        return connection.onClose();\n+    }\n+\n+    @Override\n+    public Completable closeAsync() {\n+        return connection.closeAsync();\n+    }\n+\n+    @Override\n+    public Completable closeAsyncGracefully() {\n+        return connection.closeAsyncGracefully();\n+    }\n+\n+    @Override\n+    public Channel nettyChannel() {\n+        return connection.nettyChannel();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return getClass().getName() + '(' + connection + ')';\n+    }\n+\n+    @Override\n+    public Cancellable updateFlushStrategy(final NettyConnectionContext.FlushStrategyProvider strategyProvider) {\n+        return connection.updateFlushStrategy(strategyProvider);\n+    }\n+\n+    @Override\n+    public FlushStrategy defaultFlushStrategy() {\n+        return connection.defaultFlushStrategy();\n+    }\n+\n+    private void queueOffer(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node node) {\n+        for (;;) {\n+            Node tail = tailUpdater.get(this);\n+            if (tail == null) {\n+                if (tailUpdater.compareAndSet(this, null, node)) {\n+                    // node has been inserted and is the only node, we initiate processing.\n+                    safeProcessSubscribers(node.delayedSource);\n+                    break;\n+                }\n+                // Another thread won the race to offer a node, loop around and try again.\n+            } else if (tail.append(node)) {\n+                // Make the newly appended node visible as the tail. This is a best effort CAS and may fail because:\n+                // 1. Another thread is also inserting, has a stale tail, followed its existing tail links, and updated\n+                // the tail reference via queueOfferPatchTail.\n+                // 2. The consumer thread has seen the link from the old tail to the new node, processed node,\n+                // popped node from the list (updated node's next to point to EMPTY_NODE), another producer thread\n+                // appends a new node, sees the tail is popped, and updates the tail reference via CAS.\n+                tailUpdater.compareAndSet(this, tail, node);\n+                break;\n+            } else if (tail.isPopped()) {\n+                // A previously appended node was processed, and popped before updating the tail after append. In that\n+                // case the tail maybe pointing to an invalid node and we clear it out.\n+                if (tailUpdater.compareAndSet(this, tail, node)) {\n+                    safeProcessSubscribers(node.delayedSource);\n+                    break;\n+                }\n+                // Best effort to clear the tail, and failure is OK because:\n+                // 1. Another thread is in offer and already patched up the tail pointer and we will read the new tail\n+                // on the next loop iteration.\n+            } else if (queueOfferPatchTail(tailUpdater, node, tail)) {\n+                break;\n+            }\n+        }\n+    }\n+\n+    private boolean queueOfferPatchTail(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node node,\n+            final Node tail) {\n+        Node currentTail = tailUpdater.get(this);\n+        if (currentTail == tail) {\n+            // tail is stale so attempt to iterate through the linked list and update tail.\n+            currentTail = tail.iterateToTail();\n+            if (currentTail.isPopped()) {\n+                if (tailUpdater.compareAndSet(this, tail, node)) {\n+                    safeProcessSubscribers(node.delayedSource);\n+                    return true;\n+                }\n+            } else {\n+                tailUpdater.compareAndSet(this, tail, currentTail);\n+            }\n+            // Best effort to update/clear the tail, and failure is OK because:\n+            // 1. Another thread is in offer and already patched up the tail pointer and we will read the new\n+            // tail on the next loop iteration.\n+        }\n+        return false;\n+    }\n+\n+    private void queuePop(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node head) {\n+        // This method maybe called multiple times on the same node, in which case next will be EMPTY_NODE and the run\n+        // method will be a noop.\n+        Node next = head.pop();\n+        if (next != null) {\n+            safeProcessSubscribers(next.delayedSource);\n+        } else {\n+            tailUpdater.compareAndSet(this, head, null);\n+            // Best effort to clear the tail, and failure is OK because:\n+            // 1. Another thread appended this head, but has not yet updated the tail. In this case the tail will be\n+            // stale (e.g. pointing to head node that has already been processed) and corrected by future inserts.\n+        }\n+    }\n+\n+    private void safeProcessSubscribers(Runnable delayedSource) {\n+        try {\n+            delayedSource.run();\n+        } catch (Throwable cause) {\n+            connection.closeAsync().subscribe();\n+            LOGGER.warn(\"closing connection={} due to unexpected error on subscribe\", connection, cause);\n+        }\n+    }\n+\n+    /**\n+     * Logically equivalent to {@link Publisher#afterFinally(Runnable)} but relies upon internal queue CAS operations\n+     * to prevent multiple executions (e.g. reduces a CAS operation).\n+     */\n+    private final class ReadPopNextOperator implements PublisherOperator<Resp, Resp> {\n+        private final Node readNode;\n+\n+        private ReadPopNextOperator(final Node readNode) {\n+            this.readNode = readNode;\n+        }\n+\n+        @Override\n+        public PublisherSource.Subscriber<? super Resp> apply(PublisherSource.Subscriber<? super Resp> subscriber) {\n+            return new PublisherSource.Subscriber<Resp>() {\n+                @Override\n+                public void onSubscribe(final PublisherSource.Subscription subscription) {\n+                    subscriber.onSubscribe(new PublisherSource.Subscription() {\n+                        @Override\n+                        public void request(final long n) {\n+                            subscription.request(n);\n+                        }\n+\n+                        @Override\n+                        public void cancel() {\n+                            try {\n+                                subscription.cancel();\n+                            } finally {\n+                                pollNext();\n+                            }\n+                        }\n+                    });\n+                }\n+\n+                @Override\n+                public void onNext(@Nullable final Resp t) {\n+                    subscriber.onNext(t);\n+                }\n+\n+                @Override\n+                public void onError(final Throwable t) {\n+                    try {\n+                        subscriber.onError(t);\n+                    } finally {\n+                        pollNext();\n+                    }\n+                }\n+\n+                @Override\n+                public void onComplete() {\n+                    try {\n+                        subscriber.onComplete();\n+                    } finally {\n+                        pollNext();\n+                    }\n+                }\n+\n+                private void pollNext() {\n+                    queuePop(readQueueTailUpdater, readNode);\n+                }\n+            };\n+        }\n+    }\n+\n+    /**\n+     * Logically equivalent to {@link Completable#afterFinally(Runnable)} but relies upon internal queue CAS operations\n+     * to prevent multiple executions (e.g. reduces a CAS operation).\n+     */\n+    private final class WritePopNextOperator implements CompletableOperator {\n+        private final Node writeNode;\n+\n+        WritePopNextOperator(final Node writeNode) {\n+            this.writeNode = writeNode;\n+        }\n+\n+        @Override\n+        public CompletableSource.Subscriber apply(final CompletableSource.Subscriber subscriber) {\n+            return new CompletableSource.Subscriber() {\n+                @Override\n+                public void onSubscribe(final Cancellable cancellable) {\n+                    subscriber.onSubscribe(() -> {\n+                        try {\n+                            cancellable.cancel();\n+                        } finally {\n+                            pollNext();\n+                        }\n+                    });\n+                }\n+\n+                @Override\n+                public void onComplete() {\n+                    try {\n+                        subscriber.onComplete();\n+                    } finally {\n+                        pollNext();\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(final Throwable t) {\n+                    try {\n+                        subscriber.onError(t);\n+                    } finally {\n+                        pollNext();\n+                    }\n+                }\n+            };\n+        }\n+\n+        private void pollNext() {\n+            queuePop(writeQueueTailUpdater, writeNode);\n+        }\n+    }\n+\n+    private static final class Node {\n+        private static final Node EMPTY_NODE = new Node();\n+        private static final AtomicReferenceFieldUpdater<Node, Node> nextUpdater =\n+                newUpdater(Node.class, Node.class, \"next\");\n+        @Nullable\n+        private volatile Node next;\n+        final Runnable delayedSource;\n+\n+        Node(Runnable delayedSource) {\n+            this.delayedSource = requireNonNull(delayedSource);\n+        }\n+\n+        private Node() {\n+            this.next = this;\n+            this.delayedSource = () -> { };\n+        }\n+\n+        boolean append(Node next) {\n+            return nextUpdater.compareAndSet(this, null, next);\n+        }\n+\n+        @Nullable\n+        Node pop() {\n+            return nextUpdater.getAndSet(this, EMPTY_NODE);\n+        }\n+\n+        boolean isPopped() {\n+            return next == EMPTY_NODE;\n+        }\n+\n+        Node iterateToTail() {\n+            Node prev = this;\n+            Node next = prev.next;\n+            while (next != null) {\n+                prev = next;\n+                next = next.next;\n+            }\n+            return prev;\n+        }\n+    }\n+\n+    private static final class DelayedSubscribeCompletable extends Completable {\n+        private static final AtomicReferenceFieldUpdater<DelayedSubscribeCompletable, Object> stateUpdater =\n+                newUpdater(DelayedSubscribeCompletable.class, Object.class, \"state\");\n+        private static final Object ALLOW_SUBSCRIBE = new Object();\n+        private static final Object DRAINING_SUBSCRIBERS = new Object();\n+\n+        private final CompletableSource completable;\n+        /**\n+         * One of the following:\n+         * <li>\n+         *     <ul>{@code null} - initial state</ul>\n+         *     <ul>{@link #ALLOW_SUBSCRIBE} - {@link #handleSubscribe(CompletableSource.Subscriber)} methods will\n+         *     pass through to {@link #completable}</ul>\n+         *     <ul>{@link #DRAINING_SUBSCRIBERS} - set in {@link #processSubscribers()} while calling\n+         *     {@link CompletableSource#subscribe(CompletableSource.Subscriber)} on each {@link Completable}</ul>\n+         *     <ul>{@link CompletableSource.Subscriber} - if there is a single\n+         *     {@link #handleSubscribe(CompletableSource.Subscriber)} pending</ul>\n+         *     <ul>{@code Object[]} - if there are multiple {@link #handleSubscribe(CompletableSource.Subscriber)}\n+         *     calls pending</ul>\n+         * </li>\n+         */\n+        @Nullable\n+        private volatile Object state;\n+\n+        private DelayedSubscribeCompletable(final CompletableSource completable) {\n+            this.completable = requireNonNull(completable);\n+        }\n+\n+        void processSubscribers() {\n+            for (;;) {\n+                Object currentState = state;\n+                if (currentState == null) {\n+                    if (stateUpdater.compareAndSet(this, null, ALLOW_SUBSCRIBE)) {\n+                        break;\n+                    }\n+                } else if (currentState == ALLOW_SUBSCRIBE) {\n+                    break;\n+                } else if (currentState instanceof CompletableSource.Subscriber) {\n+                    CompletableSource.Subscriber currentSubscriber = (CompletableSource.Subscriber) currentState;\n+                    if (stateUpdater.compareAndSet(this, currentState, DRAINING_SUBSCRIBERS)) {\n+                        completable.subscribe(currentSubscriber);\n+                        if (stateUpdater.compareAndSet(this, DRAINING_SUBSCRIBERS, ALLOW_SUBSCRIBE)) {\n+                            break;\n+                        }\n+                    }\n+                } else if (stateUpdater.compareAndSet(this, currentState, DRAINING_SUBSCRIBERS)) {\n+                    assert currentState != DRAINING_SUBSCRIBERS;\n+                    CompletableSource.Subscriber[] queue = (CompletableSource.Subscriber[]) currentState;\n+                    for (CompletableSource.Subscriber next : queue) {\n+                        completable.subscribe(next);\n+                    }\n+                    if (stateUpdater.compareAndSet(this, DRAINING_SUBSCRIBERS, ALLOW_SUBSCRIBE)) {\n+                        break;\n+                    }\n+                }\n+            }\n+        }\n+\n+        @Override\n+        protected void handleSubscribe(final CompletableSource.Subscriber subscriber) {\n+            for (;;) {\n+                Object currentState = state;\n+                if (currentState == null || currentState == DRAINING_SUBSCRIBERS) {\n+                    if (stateUpdater.compareAndSet(this, currentState, subscriber)) {\n+                        break;\n+                    }\n+                } else if (currentState == ALLOW_SUBSCRIBE) {\n+                    completable.subscribe(subscriber);\n+                    break;\n+                } else if (currentState instanceof CompletableSource.Subscriber) {\n+                    // Ideally we can propagate the onSubscribe ASAP to allow for cancellation but this completable is\n+                    // designed to defer the subscribe until some other condition occurs, so no work will actually be\n+                    // done until that later time.\n+                    CompletableSource.Subscriber currentSubscriber = (CompletableSource.Subscriber) currentState;\n+                    if (stateUpdater.compareAndSet(this, currentState,\n+                            new Object[] {currentSubscriber, subscriber})) {\n+                        break;\n+                    }\n+                } else {\n+                    Object[] array = (Object[]) currentState;\n+                    // Unmodifiable collection to avoid issues with concurrent adding/draining with processSubscribers.\n+                    // The expected cardinality of the array will be low, so copy/resize is \"good enough\" for now.\n+                    Object[] newArray = Arrays.copyOf(array, array.length + 1);\n+                    newArray[array.length] = subscriber;\n+                    if (stateUpdater.compareAndSet(this, currentState, newArray)) {\n+                        break;\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    private static final class DelayedSubscribePublisher<T> extends Publisher<T> {\n+        @SuppressWarnings(\"rawtypes\")\n+        private static final AtomicReferenceFieldUpdater<DelayedSubscribePublisher, Object> stateUpdater =\n+                newUpdater(DelayedSubscribePublisher.class, Object.class, \"state\");\n+        private static final Object ALLOW_SUBSCRIBE = new Object();\n+        private static final Object DRAINING_SUBSCRIBERS = new Object();\n+\n+        private final PublisherSource<T> publisher;\n+        /**\n+         * One of the following:\n+         * <li>\n+         *     <ul>{@code null} - initial state</ul>\n+         *     <ul>{@link #ALLOW_SUBSCRIBE} - {@link #handleSubscribe(PublisherSource.Subscriber)} methods will\n+         *     pass through to {@link #publisher}</ul>\n+         *     <ul>{@link #DRAINING_SUBSCRIBERS} - set in {@link #processSubscribers()} while calling\n+         *     {@link PublisherSource#subscribe(PublisherSource.Subscriber)} on each {@link Publisher}</ul>\n+         *     <ul>{@link PublisherSource.Subscriber} - if there is a single\n+         *     {@link #handleSubscribe(PublisherSource.Subscriber)} pending</ul>\n+         *     <ul>{@code Object[]} - if there are multiple {@link #handleSubscribe(PublisherSource.Subscriber)}\n+         *     calls pending</ul>\n+         * </li>\n+         */\n+        @Nullable\n+        private volatile Object state;\n+\n+        DelayedSubscribePublisher(final PublisherSource<T> publisher) {\n+            this.publisher = requireNonNull(publisher);\n+        }\n+\n+        void processSubscribers() {\n+            for (;;) {\n+                Object currentState = state;\n+                if (currentState == null) {\n+                    if (stateUpdater.compareAndSet(this, null, ALLOW_SUBSCRIBE)) {\n+                        break;\n+                    }\n+                } else if (currentState == ALLOW_SUBSCRIBE) {\n+                    break;\n+                } else if (currentState instanceof PublisherSource.Subscriber) {\n+                    @SuppressWarnings(\"unchecked\")\n+                    PublisherSource.Subscriber<? super T> currentSubscriber =\n+                            (PublisherSource.Subscriber<? super T>) currentState;\n+                    if (stateUpdater.compareAndSet(this, currentState, DRAINING_SUBSCRIBERS)) {\n+                        publisher.subscribe(currentSubscriber);\n+                        if (stateUpdater.compareAndSet(this, DRAINING_SUBSCRIBERS, ALLOW_SUBSCRIBE)) {\n+                            break;\n+                        }\n+                    }\n+                } else if (stateUpdater.compareAndSet(this, currentState, DRAINING_SUBSCRIBERS)) {\n+                    assert currentState != DRAINING_SUBSCRIBERS;\n+                    @SuppressWarnings(\"unchecked\")\n+                    PublisherSource.Subscriber<? super T>[] queue =\n+                            (PublisherSource.Subscriber<? super T>[]) currentState;\n+                    for (PublisherSource.Subscriber<? super T> next : queue) {\n+                        publisher.subscribe(next);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7469332830d536d9dc82b82bad56e4860a3caf7e"}, "originalPosition": 584}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Nzk5OTUyMw==", "bodyText": "I think in this context it is OK because this is used with merge which will send the onSubscribe(). Also, even if we send the onSubscribe() eagerly we would not want to remove the subscriber from the queue as that may mess up the order: If response was cancelled after writes were done, removing the subscriber here would essentially give out of order responses. So, I think this is just a fine trade-off to reduce complexity of an eager onSubscribe()", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r397999523", "createdAt": "2020-03-25T16:36:15Z", "author": {"login": "NiteshKant"}, "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.CompletableSource;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.CompletableOperator;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.PublisherOperator;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+\n+import io.netty.channel.Channel;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.Arrays;\n+import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(NettyPipelinedConnection.class);\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            writeQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"writeQueueTail\");\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            readQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"readQueueTail\");\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node writeQueueTail;\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node readQueueTail;\n+\n+    private final NettyConnection<Resp, Req> connection;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} producing the request(s) to write.\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        return Publisher.defer(() -> {\n+            // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+\n+            // Setup read side publisher and nodes\n+            DelayedSubscribePublisher<Resp> delayedResponsePublisher = new DelayedSubscribePublisher<>(\n+                    toSource(connection.read()));\n+            Node readNode = new Node(delayedResponsePublisher::processSubscribers);\n+            Publisher<Resp> composedResponsePublisher =\n+                    delayedResponsePublisher.liftSync(new ReadPopNextOperator(readNode));\n+\n+            // Setup write side publisher and nodes\n+            DelayedSubscribeCompletable delayedRequestCompletable = new DelayedSubscribeCompletable(toSource(\n+                            connection.write(requestPublisher, flushStrategySupplier, writeDemandEstimatorSupplier)));\n+            Node writeNode = new Node(() -> {\n+                try {\n+                    queueOffer(readQueueTailUpdater, readNode);\n+                } finally {\n+                    delayedRequestCompletable.processSubscribers();\n+                }\n+            });\n+\n+            queueOffer(writeQueueTailUpdater, writeNode);\n+\n+            return delayedRequestCompletable.liftSync(new WritePopNextOperator(writeNode))\n+                    // If there is an error on the read/write side we propagate the errors between the two via merge.\n+                    .merge(composedResponsePublisher);\n+        });\n+    }\n+\n+    @Override\n+    public SocketAddress localAddress() {\n+        return connection.localAddress();\n+    }\n+\n+    @Override\n+    public SocketAddress remoteAddress() {\n+        return connection.remoteAddress();\n+    }\n+\n+    @Override\n+    @Nullable\n+    public SSLSession sslSession() {\n+        return connection.sslSession();\n+    }\n+\n+    @Override\n+    public ExecutionContext executionContext() {\n+        return connection.executionContext();\n+    }\n+\n+    @Nullable\n+    @Override\n+    public <T> T socketOption(final SocketOption<T> option) {\n+        return connection.socketOption(option);\n+    }\n+\n+    @Override\n+    public Protocol protocol() {\n+        return connection.protocol();\n+    }\n+\n+    @Override\n+    public Single<Throwable> transportError() {\n+        return connection.transportError();\n+    }\n+\n+    @Override\n+    public Completable onClosing() {\n+        return connection.onClosing();\n+    }\n+\n+    @Override\n+    public Completable onClose() {\n+        return connection.onClose();\n+    }\n+\n+    @Override\n+    public Completable closeAsync() {\n+        return connection.closeAsync();\n+    }\n+\n+    @Override\n+    public Completable closeAsyncGracefully() {\n+        return connection.closeAsyncGracefully();\n+    }\n+\n+    @Override\n+    public Channel nettyChannel() {\n+        return connection.nettyChannel();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return getClass().getName() + '(' + connection + ')';\n+    }\n+\n+    @Override\n+    public Cancellable updateFlushStrategy(final NettyConnectionContext.FlushStrategyProvider strategyProvider) {\n+        return connection.updateFlushStrategy(strategyProvider);\n+    }\n+\n+    @Override\n+    public FlushStrategy defaultFlushStrategy() {\n+        return connection.defaultFlushStrategy();\n+    }\n+\n+    private void queueOffer(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node node) {\n+        for (;;) {\n+            Node tail = tailUpdater.get(this);\n+            if (tail == null) {\n+                if (tailUpdater.compareAndSet(this, null, node)) {\n+                    // node has been inserted and is the only node, we initiate processing.\n+                    safeProcessSubscribers(node.delayedSource);\n+                    break;\n+                }\n+                // Another thread won the race to offer a node, loop around and try again.\n+            } else if (tail.append(node)) {\n+                // Make the newly appended node visible as the tail. This is a best effort CAS and may fail because:\n+                // 1. Another thread is also inserting, has a stale tail, followed its existing tail links, and updated\n+                // the tail reference via queueOfferPatchTail.\n+                // 2. The consumer thread has seen the link from the old tail to the new node, processed node,\n+                // popped node from the list (updated node's next to point to EMPTY_NODE), another producer thread\n+                // appends a new node, sees the tail is popped, and updates the tail reference via CAS.\n+                tailUpdater.compareAndSet(this, tail, node);\n+                break;\n+            } else if (tail.isPopped()) {\n+                // A previously appended node was processed, and popped before updating the tail after append. In that\n+                // case the tail maybe pointing to an invalid node and we clear it out.\n+                if (tailUpdater.compareAndSet(this, tail, node)) {\n+                    safeProcessSubscribers(node.delayedSource);\n+                    break;\n+                }\n+                // Best effort to clear the tail, and failure is OK because:\n+                // 1. Another thread is in offer and already patched up the tail pointer and we will read the new tail\n+                // on the next loop iteration.\n+            } else if (queueOfferPatchTail(tailUpdater, node, tail)) {\n+                break;\n+            }\n+        }\n+    }\n+\n+    private boolean queueOfferPatchTail(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node node,\n+            final Node tail) {\n+        Node currentTail = tailUpdater.get(this);\n+        if (currentTail == tail) {\n+            // tail is stale so attempt to iterate through the linked list and update tail.\n+            currentTail = tail.iterateToTail();\n+            if (currentTail.isPopped()) {\n+                if (tailUpdater.compareAndSet(this, tail, node)) {\n+                    safeProcessSubscribers(node.delayedSource);\n+                    return true;\n+                }\n+            } else {\n+                tailUpdater.compareAndSet(this, tail, currentTail);\n+            }\n+            // Best effort to update/clear the tail, and failure is OK because:\n+            // 1. Another thread is in offer and already patched up the tail pointer and we will read the new\n+            // tail on the next loop iteration.\n+        }\n+        return false;\n+    }\n+\n+    private void queuePop(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node head) {\n+        // This method maybe called multiple times on the same node, in which case next will be EMPTY_NODE and the run\n+        // method will be a noop.\n+        Node next = head.pop();\n+        if (next != null) {\n+            safeProcessSubscribers(next.delayedSource);\n+        } else {\n+            tailUpdater.compareAndSet(this, head, null);\n+            // Best effort to clear the tail, and failure is OK because:\n+            // 1. Another thread appended this head, but has not yet updated the tail. In this case the tail will be\n+            // stale (e.g. pointing to head node that has already been processed) and corrected by future inserts.\n+        }\n+    }\n+\n+    private void safeProcessSubscribers(Runnable delayedSource) {\n+        try {\n+            delayedSource.run();\n+        } catch (Throwable cause) {\n+            connection.closeAsync().subscribe();\n+            LOGGER.warn(\"closing connection={} due to unexpected error on subscribe\", connection, cause);\n+        }\n+    }\n+\n+    /**\n+     * Logically equivalent to {@link Publisher#afterFinally(Runnable)} but relies upon internal queue CAS operations\n+     * to prevent multiple executions (e.g. reduces a CAS operation).\n+     */\n+    private final class ReadPopNextOperator implements PublisherOperator<Resp, Resp> {\n+        private final Node readNode;\n+\n+        private ReadPopNextOperator(final Node readNode) {\n+            this.readNode = readNode;\n+        }\n+\n+        @Override\n+        public PublisherSource.Subscriber<? super Resp> apply(PublisherSource.Subscriber<? super Resp> subscriber) {\n+            return new PublisherSource.Subscriber<Resp>() {\n+                @Override\n+                public void onSubscribe(final PublisherSource.Subscription subscription) {\n+                    subscriber.onSubscribe(new PublisherSource.Subscription() {\n+                        @Override\n+                        public void request(final long n) {\n+                            subscription.request(n);\n+                        }\n+\n+                        @Override\n+                        public void cancel() {\n+                            try {\n+                                subscription.cancel();\n+                            } finally {\n+                                pollNext();\n+                            }\n+                        }\n+                    });\n+                }\n+\n+                @Override\n+                public void onNext(@Nullable final Resp t) {\n+                    subscriber.onNext(t);\n+                }\n+\n+                @Override\n+                public void onError(final Throwable t) {\n+                    try {\n+                        subscriber.onError(t);\n+                    } finally {\n+                        pollNext();\n+                    }\n+                }\n+\n+                @Override\n+                public void onComplete() {\n+                    try {\n+                        subscriber.onComplete();\n+                    } finally {\n+                        pollNext();\n+                    }\n+                }\n+\n+                private void pollNext() {\n+                    queuePop(readQueueTailUpdater, readNode);\n+                }\n+            };\n+        }\n+    }\n+\n+    /**\n+     * Logically equivalent to {@link Completable#afterFinally(Runnable)} but relies upon internal queue CAS operations\n+     * to prevent multiple executions (e.g. reduces a CAS operation).\n+     */\n+    private final class WritePopNextOperator implements CompletableOperator {\n+        private final Node writeNode;\n+\n+        WritePopNextOperator(final Node writeNode) {\n+            this.writeNode = writeNode;\n+        }\n+\n+        @Override\n+        public CompletableSource.Subscriber apply(final CompletableSource.Subscriber subscriber) {\n+            return new CompletableSource.Subscriber() {\n+                @Override\n+                public void onSubscribe(final Cancellable cancellable) {\n+                    subscriber.onSubscribe(() -> {\n+                        try {\n+                            cancellable.cancel();\n+                        } finally {\n+                            pollNext();\n+                        }\n+                    });\n+                }\n+\n+                @Override\n+                public void onComplete() {\n+                    try {\n+                        subscriber.onComplete();\n+                    } finally {\n+                        pollNext();\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(final Throwable t) {\n+                    try {\n+                        subscriber.onError(t);\n+                    } finally {\n+                        pollNext();\n+                    }\n+                }\n+            };\n+        }\n+\n+        private void pollNext() {\n+            queuePop(writeQueueTailUpdater, writeNode);\n+        }\n+    }\n+\n+    private static final class Node {\n+        private static final Node EMPTY_NODE = new Node();\n+        private static final AtomicReferenceFieldUpdater<Node, Node> nextUpdater =\n+                newUpdater(Node.class, Node.class, \"next\");\n+        @Nullable\n+        private volatile Node next;\n+        final Runnable delayedSource;\n+\n+        Node(Runnable delayedSource) {\n+            this.delayedSource = requireNonNull(delayedSource);\n+        }\n+\n+        private Node() {\n+            this.next = this;\n+            this.delayedSource = () -> { };\n+        }\n+\n+        boolean append(Node next) {\n+            return nextUpdater.compareAndSet(this, null, next);\n+        }\n+\n+        @Nullable\n+        Node pop() {\n+            return nextUpdater.getAndSet(this, EMPTY_NODE);\n+        }\n+\n+        boolean isPopped() {\n+            return next == EMPTY_NODE;\n+        }\n+\n+        Node iterateToTail() {\n+            Node prev = this;\n+            Node next = prev.next;\n+            while (next != null) {\n+                prev = next;\n+                next = next.next;\n+            }\n+            return prev;\n+        }\n+    }\n+\n+    private static final class DelayedSubscribeCompletable extends Completable {\n+        private static final AtomicReferenceFieldUpdater<DelayedSubscribeCompletable, Object> stateUpdater =\n+                newUpdater(DelayedSubscribeCompletable.class, Object.class, \"state\");\n+        private static final Object ALLOW_SUBSCRIBE = new Object();\n+        private static final Object DRAINING_SUBSCRIBERS = new Object();\n+\n+        private final CompletableSource completable;\n+        /**\n+         * One of the following:\n+         * <li>\n+         *     <ul>{@code null} - initial state</ul>\n+         *     <ul>{@link #ALLOW_SUBSCRIBE} - {@link #handleSubscribe(CompletableSource.Subscriber)} methods will\n+         *     pass through to {@link #completable}</ul>\n+         *     <ul>{@link #DRAINING_SUBSCRIBERS} - set in {@link #processSubscribers()} while calling\n+         *     {@link CompletableSource#subscribe(CompletableSource.Subscriber)} on each {@link Completable}</ul>\n+         *     <ul>{@link CompletableSource.Subscriber} - if there is a single\n+         *     {@link #handleSubscribe(CompletableSource.Subscriber)} pending</ul>\n+         *     <ul>{@code Object[]} - if there are multiple {@link #handleSubscribe(CompletableSource.Subscriber)}\n+         *     calls pending</ul>\n+         * </li>\n+         */\n+        @Nullable\n+        private volatile Object state;\n+\n+        private DelayedSubscribeCompletable(final CompletableSource completable) {\n+            this.completable = requireNonNull(completable);\n+        }\n+\n+        void processSubscribers() {\n+            for (;;) {\n+                Object currentState = state;\n+                if (currentState == null) {\n+                    if (stateUpdater.compareAndSet(this, null, ALLOW_SUBSCRIBE)) {\n+                        break;\n+                    }\n+                } else if (currentState == ALLOW_SUBSCRIBE) {\n+                    break;\n+                } else if (currentState instanceof CompletableSource.Subscriber) {\n+                    CompletableSource.Subscriber currentSubscriber = (CompletableSource.Subscriber) currentState;\n+                    if (stateUpdater.compareAndSet(this, currentState, DRAINING_SUBSCRIBERS)) {\n+                        completable.subscribe(currentSubscriber);\n+                        if (stateUpdater.compareAndSet(this, DRAINING_SUBSCRIBERS, ALLOW_SUBSCRIBE)) {\n+                            break;\n+                        }\n+                    }\n+                } else if (stateUpdater.compareAndSet(this, currentState, DRAINING_SUBSCRIBERS)) {\n+                    assert currentState != DRAINING_SUBSCRIBERS;\n+                    CompletableSource.Subscriber[] queue = (CompletableSource.Subscriber[]) currentState;\n+                    for (CompletableSource.Subscriber next : queue) {\n+                        completable.subscribe(next);\n+                    }\n+                    if (stateUpdater.compareAndSet(this, DRAINING_SUBSCRIBERS, ALLOW_SUBSCRIBE)) {\n+                        break;\n+                    }\n+                }\n+            }\n+        }\n+\n+        @Override\n+        protected void handleSubscribe(final CompletableSource.Subscriber subscriber) {\n+            for (;;) {\n+                Object currentState = state;\n+                if (currentState == null || currentState == DRAINING_SUBSCRIBERS) {\n+                    if (stateUpdater.compareAndSet(this, currentState, subscriber)) {\n+                        break;\n+                    }\n+                } else if (currentState == ALLOW_SUBSCRIBE) {\n+                    completable.subscribe(subscriber);\n+                    break;\n+                } else if (currentState instanceof CompletableSource.Subscriber) {\n+                    // Ideally we can propagate the onSubscribe ASAP to allow for cancellation but this completable is\n+                    // designed to defer the subscribe until some other condition occurs, so no work will actually be\n+                    // done until that later time.\n+                    CompletableSource.Subscriber currentSubscriber = (CompletableSource.Subscriber) currentState;\n+                    if (stateUpdater.compareAndSet(this, currentState,\n+                            new Object[] {currentSubscriber, subscriber})) {\n+                        break;\n+                    }\n+                } else {\n+                    Object[] array = (Object[]) currentState;\n+                    // Unmodifiable collection to avoid issues with concurrent adding/draining with processSubscribers.\n+                    // The expected cardinality of the array will be low, so copy/resize is \"good enough\" for now.\n+                    Object[] newArray = Arrays.copyOf(array, array.length + 1);\n+                    newArray[array.length] = subscriber;\n+                    if (stateUpdater.compareAndSet(this, currentState, newArray)) {\n+                        break;\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    private static final class DelayedSubscribePublisher<T> extends Publisher<T> {\n+        @SuppressWarnings(\"rawtypes\")\n+        private static final AtomicReferenceFieldUpdater<DelayedSubscribePublisher, Object> stateUpdater =\n+                newUpdater(DelayedSubscribePublisher.class, Object.class, \"state\");\n+        private static final Object ALLOW_SUBSCRIBE = new Object();\n+        private static final Object DRAINING_SUBSCRIBERS = new Object();\n+\n+        private final PublisherSource<T> publisher;\n+        /**\n+         * One of the following:\n+         * <li>\n+         *     <ul>{@code null} - initial state</ul>\n+         *     <ul>{@link #ALLOW_SUBSCRIBE} - {@link #handleSubscribe(PublisherSource.Subscriber)} methods will\n+         *     pass through to {@link #publisher}</ul>\n+         *     <ul>{@link #DRAINING_SUBSCRIBERS} - set in {@link #processSubscribers()} while calling\n+         *     {@link PublisherSource#subscribe(PublisherSource.Subscriber)} on each {@link Publisher}</ul>\n+         *     <ul>{@link PublisherSource.Subscriber} - if there is a single\n+         *     {@link #handleSubscribe(PublisherSource.Subscriber)} pending</ul>\n+         *     <ul>{@code Object[]} - if there are multiple {@link #handleSubscribe(PublisherSource.Subscriber)}\n+         *     calls pending</ul>\n+         * </li>\n+         */\n+        @Nullable\n+        private volatile Object state;\n+\n+        DelayedSubscribePublisher(final PublisherSource<T> publisher) {\n+            this.publisher = requireNonNull(publisher);\n+        }\n+\n+        void processSubscribers() {\n+            for (;;) {\n+                Object currentState = state;\n+                if (currentState == null) {\n+                    if (stateUpdater.compareAndSet(this, null, ALLOW_SUBSCRIBE)) {\n+                        break;\n+                    }\n+                } else if (currentState == ALLOW_SUBSCRIBE) {\n+                    break;\n+                } else if (currentState instanceof PublisherSource.Subscriber) {\n+                    @SuppressWarnings(\"unchecked\")\n+                    PublisherSource.Subscriber<? super T> currentSubscriber =\n+                            (PublisherSource.Subscriber<? super T>) currentState;\n+                    if (stateUpdater.compareAndSet(this, currentState, DRAINING_SUBSCRIBERS)) {\n+                        publisher.subscribe(currentSubscriber);\n+                        if (stateUpdater.compareAndSet(this, DRAINING_SUBSCRIBERS, ALLOW_SUBSCRIBE)) {\n+                            break;\n+                        }\n+                    }\n+                } else if (stateUpdater.compareAndSet(this, currentState, DRAINING_SUBSCRIBERS)) {\n+                    assert currentState != DRAINING_SUBSCRIBERS;\n+                    @SuppressWarnings(\"unchecked\")\n+                    PublisherSource.Subscriber<? super T>[] queue =\n+                            (PublisherSource.Subscriber<? super T>[]) currentState;\n+                    for (PublisherSource.Subscriber<? super T> next : queue) {\n+                        publisher.subscribe(next);\n+                    }\n+                    if (stateUpdater.compareAndSet(this, DRAINING_SUBSCRIBERS, ALLOW_SUBSCRIBE)) {\n+                        break;\n+                    }\n+                }\n+            }\n+        }\n+\n+        @Override\n+        protected void handleSubscribe(final PublisherSource.Subscriber<? super T> subscriber) {\n+            for (;;) {\n+                Object currentState = state;\n+                if (currentState == null || currentState == DRAINING_SUBSCRIBERS) {\n+                    if (stateUpdater.compareAndSet(this, currentState, subscriber)) {\n+                        break;\n+                    }\n+                } else if (currentState == ALLOW_SUBSCRIBE) {\n+                    publisher.subscribe(subscriber);\n+                    break;\n+                } else if (currentState instanceof PublisherSource.Subscriber) {\n+                    // Ideally we can propagate the onSubscribe ASAP to allow for cancellation but this publisher is", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7469332830d536d9dc82b82bad56e4860a3caf7e"}, "originalPosition": 605}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODA0NzM4OQ==", "bodyText": "If this delayedSource represents read subscriber which happened to throw then closing the connection will not make sure that we terminate the read side (as the queuing of read might have failed). For such cases, we should make sure that the control flow is completed by propagating the exception to the respective subscribers.", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r398047389", "createdAt": "2020-03-25T17:42:14Z", "author": {"login": "NiteshKant"}, "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.CompletableSource;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.CompletableOperator;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.PublisherOperator;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+\n+import io.netty.channel.Channel;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.Arrays;\n+import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(NettyPipelinedConnection.class);\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            writeQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"writeQueueTail\");\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            readQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"readQueueTail\");\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node writeQueueTail;\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node readQueueTail;\n+\n+    private final NettyConnection<Resp, Req> connection;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} producing the request(s) to write.\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        return Publisher.defer(() -> {\n+            // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+\n+            // Setup read side publisher and nodes\n+            DelayedSubscribePublisher<Resp> delayedResponsePublisher = new DelayedSubscribePublisher<>(\n+                    toSource(connection.read()));\n+            Node readNode = new Node(delayedResponsePublisher::processSubscribers);\n+            Publisher<Resp> composedResponsePublisher =\n+                    delayedResponsePublisher.liftSync(new ReadPopNextOperator(readNode));\n+\n+            // Setup write side publisher and nodes\n+            DelayedSubscribeCompletable delayedRequestCompletable = new DelayedSubscribeCompletable(toSource(\n+                            connection.write(requestPublisher, flushStrategySupplier, writeDemandEstimatorSupplier)));\n+            Node writeNode = new Node(() -> {\n+                try {\n+                    queueOffer(readQueueTailUpdater, readNode);\n+                } finally {\n+                    delayedRequestCompletable.processSubscribers();\n+                }\n+            });\n+\n+            queueOffer(writeQueueTailUpdater, writeNode);\n+\n+            return delayedRequestCompletable.liftSync(new WritePopNextOperator(writeNode))\n+                    // If there is an error on the read/write side we propagate the errors between the two via merge.\n+                    .merge(composedResponsePublisher);\n+        });\n+    }\n+\n+    @Override\n+    public SocketAddress localAddress() {\n+        return connection.localAddress();\n+    }\n+\n+    @Override\n+    public SocketAddress remoteAddress() {\n+        return connection.remoteAddress();\n+    }\n+\n+    @Override\n+    @Nullable\n+    public SSLSession sslSession() {\n+        return connection.sslSession();\n+    }\n+\n+    @Override\n+    public ExecutionContext executionContext() {\n+        return connection.executionContext();\n+    }\n+\n+    @Nullable\n+    @Override\n+    public <T> T socketOption(final SocketOption<T> option) {\n+        return connection.socketOption(option);\n+    }\n+\n+    @Override\n+    public Protocol protocol() {\n+        return connection.protocol();\n+    }\n+\n+    @Override\n+    public Single<Throwable> transportError() {\n+        return connection.transportError();\n+    }\n+\n+    @Override\n+    public Completable onClosing() {\n+        return connection.onClosing();\n+    }\n+\n+    @Override\n+    public Completable onClose() {\n+        return connection.onClose();\n+    }\n+\n+    @Override\n+    public Completable closeAsync() {\n+        return connection.closeAsync();\n+    }\n+\n+    @Override\n+    public Completable closeAsyncGracefully() {\n+        return connection.closeAsyncGracefully();\n+    }\n+\n+    @Override\n+    public Channel nettyChannel() {\n+        return connection.nettyChannel();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return getClass().getName() + '(' + connection + ')';\n+    }\n+\n+    @Override\n+    public Cancellable updateFlushStrategy(final NettyConnectionContext.FlushStrategyProvider strategyProvider) {\n+        return connection.updateFlushStrategy(strategyProvider);\n+    }\n+\n+    @Override\n+    public FlushStrategy defaultFlushStrategy() {\n+        return connection.defaultFlushStrategy();\n+    }\n+\n+    private void queueOffer(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node node) {\n+        for (;;) {\n+            Node tail = tailUpdater.get(this);\n+            if (tail == null) {\n+                if (tailUpdater.compareAndSet(this, null, node)) {\n+                    // node has been inserted and is the only node, we initiate processing.\n+                    safeProcessSubscribers(node.delayedSource);\n+                    break;\n+                }\n+                // Another thread won the race to offer a node, loop around and try again.\n+            } else if (tail.append(node)) {\n+                // Make the newly appended node visible as the tail. This is a best effort CAS and may fail because:\n+                // 1. Another thread is also inserting, has a stale tail, followed its existing tail links, and updated\n+                // the tail reference via queueOfferPatchTail.\n+                // 2. The consumer thread has seen the link from the old tail to the new node, processed node,\n+                // popped node from the list (updated node's next to point to EMPTY_NODE), another producer thread\n+                // appends a new node, sees the tail is popped, and updates the tail reference via CAS.\n+                tailUpdater.compareAndSet(this, tail, node);\n+                break;\n+            } else if (tail.isPopped()) {\n+                // A previously appended node was processed, and popped before updating the tail after append. In that\n+                // case the tail maybe pointing to an invalid node and we clear it out.\n+                if (tailUpdater.compareAndSet(this, tail, node)) {\n+                    safeProcessSubscribers(node.delayedSource);\n+                    break;\n+                }\n+                // Best effort to clear the tail, and failure is OK because:\n+                // 1. Another thread is in offer and already patched up the tail pointer and we will read the new tail\n+                // on the next loop iteration.\n+            } else if (queueOfferPatchTail(tailUpdater, node, tail)) {\n+                break;\n+            }\n+        }\n+    }\n+\n+    private boolean queueOfferPatchTail(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node node,\n+            final Node tail) {\n+        Node currentTail = tailUpdater.get(this);\n+        if (currentTail == tail) {\n+            // tail is stale so attempt to iterate through the linked list and update tail.\n+            currentTail = tail.iterateToTail();\n+            if (currentTail.isPopped()) {\n+                if (tailUpdater.compareAndSet(this, tail, node)) {\n+                    safeProcessSubscribers(node.delayedSource);\n+                    return true;\n+                }\n+            } else {\n+                tailUpdater.compareAndSet(this, tail, currentTail);\n+            }\n+            // Best effort to update/clear the tail, and failure is OK because:\n+            // 1. Another thread is in offer and already patched up the tail pointer and we will read the new\n+            // tail on the next loop iteration.\n+        }\n+        return false;\n+    }\n+\n+    private void queuePop(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node head) {\n+        // This method maybe called multiple times on the same node, in which case next will be EMPTY_NODE and the run\n+        // method will be a noop.\n+        Node next = head.pop();\n+        if (next != null) {\n+            safeProcessSubscribers(next.delayedSource);\n+        } else {\n+            tailUpdater.compareAndSet(this, head, null);\n+            // Best effort to clear the tail, and failure is OK because:\n+            // 1. Another thread appended this head, but has not yet updated the tail. In this case the tail will be\n+            // stale (e.g. pointing to head node that has already been processed) and corrected by future inserts.\n+        }\n+    }\n+\n+    private void safeProcessSubscribers(Runnable delayedSource) {\n+        try {\n+            delayedSource.run();\n+        } catch (Throwable cause) {\n+            connection.closeAsync().subscribe();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7469332830d536d9dc82b82bad56e4860a3caf7e"}, "originalPosition": 279}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODA1MzU0Ng==", "bodyText": "As queue and pop semantics implemented here are considerably complex, I am wondering about the motivation behind this special queue implementation as opposed to using one of the existing queues we use elsewhere? Consider adding the motivation in comments here.", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r398053546", "createdAt": "2020-03-25T17:51:07Z", "author": {"login": "NiteshKant"}, "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.CompletableSource;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.CompletableOperator;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.PublisherOperator;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+\n+import io.netty.channel.Channel;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.Arrays;\n+import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(NettyPipelinedConnection.class);\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7469332830d536d9dc82b82bad56e4860a3caf7e"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODA1OTQ1MA==", "bodyText": "Looks like .afterFinally(() -> queuePop(readQueueTailUpdater, readNode)) will have the same semantics as the ReadPopNextOperator\nSame for WritePopNextOperator", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r398059450", "createdAt": "2020-03-25T17:59:21Z", "author": {"login": "NiteshKant"}, "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.CompletableSource;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.CompletableOperator;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.PublisherOperator;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+\n+import io.netty.channel.Channel;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.Arrays;\n+import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(NettyPipelinedConnection.class);\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            writeQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"writeQueueTail\");\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            readQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"readQueueTail\");\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node writeQueueTail;\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node readQueueTail;\n+\n+    private final NettyConnection<Resp, Req> connection;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} producing the request(s) to write.\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        return Publisher.defer(() -> {\n+            // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+\n+            // Setup read side publisher and nodes\n+            DelayedSubscribePublisher<Resp> delayedResponsePublisher = new DelayedSubscribePublisher<>(\n+                    toSource(connection.read()));\n+            Node readNode = new Node(delayedResponsePublisher::processSubscribers);\n+            Publisher<Resp> composedResponsePublisher =\n+                    delayedResponsePublisher.liftSync(new ReadPopNextOperator(readNode));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7469332830d536d9dc82b82bad56e4860a3caf7e"}, "originalPosition": 101}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODA3NDU2Ng==", "bodyText": "I haven't mapped myself but have we made sure that all previous tests from the previous test(DefaultNettyPipelinedConnectionTest) are represented here?", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r398074566", "createdAt": "2020-03-25T18:22:18Z", "author": {"login": "NiteshKant"}, "path": "servicetalk-http-netty/src/test/java/io/servicetalk/http/netty/NettyPipelinedConnectionTest.java", "diffHunk": "@@ -0,0 +1,379 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.concurrent.api.TestCollectingPublisherSubscriber;\n+import io.servicetalk.concurrent.api.TestPublisher;\n+import io.servicetalk.concurrent.api.TestSubscription;\n+import io.servicetalk.concurrent.internal.ServiceTalkTestTimeout;\n+import io.servicetalk.transport.api.ConnectionContext.Protocol;\n+import io.servicetalk.transport.netty.internal.DefaultNettyConnection;\n+import io.servicetalk.transport.netty.internal.FlushStrategies;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimators;\n+\n+import io.netty.channel.embedded.EmbeddedChannel;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.Timeout;\n+import org.mockito.stubbing.Answer;\n+\n+import java.nio.channels.ClosedChannelException;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import java.util.concurrent.CyclicBarrier;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.SynchronousQueue;\n+import java.util.concurrent.ThreadPoolExecutor;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static io.servicetalk.buffer.netty.BufferAllocators.DEFAULT_ALLOCATOR;\n+import static io.servicetalk.concurrent.api.Executors.immediate;\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static io.servicetalk.concurrent.internal.DeliberateException.DELIBERATE_EXCEPTION;\n+import static io.servicetalk.http.api.HttpExecutionStrategies.defaultStrategy;\n+import static io.servicetalk.transport.netty.internal.CloseHandler.UNSUPPORTED_PROTOCOL_CLOSE_HANDLER;\n+import static io.servicetalk.transport.netty.internal.FlushStrategies.defaultFlushStrategy;\n+import static java.lang.Integer.MAX_VALUE;\n+import static java.util.concurrent.TimeUnit.SECONDS;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.hasSize;\n+import static org.hamcrest.Matchers.instanceOf;\n+import static org.hamcrest.Matchers.is;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertNotNull;\n+import static org.junit.Assert.assertTrue;\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.ArgumentMatchers.anyLong;\n+import static org.mockito.ArgumentMatchers.eq;\n+import static org.mockito.Mockito.doAnswer;\n+import static org.mockito.Mockito.mock;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+public class NettyPipelinedConnectionTest {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7469332830d536d9dc82b82bad56e4860a3caf7e"}, "originalPosition": 77}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzgxNTQ3Mjc0", "url": "https://github.com/apple/servicetalk/pull/980#pullrequestreview-381547274", "createdAt": "2020-03-25T21:23:35Z", "commit": {"oid": "7469332830d536d9dc82b82bad56e4860a3caf7e"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQyMToyMzozNVrOF7u5Gg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yNVQyMjowNDowMFrOF7wGcw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODE3ODU4Ng==", "bodyText": "nit: misordered modifierns, shoud be @SuppressWarnings(\"rawtypes\") final", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r398178586", "createdAt": "2020-03-25T21:23:35Z", "author": {"login": "idelpivnitskiy"}, "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.CompletableSource;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.CompletableOperator;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.PublisherOperator;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+\n+import io.netty.channel.Channel;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.Arrays;\n+import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(NettyPipelinedConnection.class);\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            writeQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"writeQueueTail\");\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            readQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"readQueueTail\");\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node writeQueueTail;\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node readQueueTail;\n+\n+    private final NettyConnection<Resp, Req> connection;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} producing the request(s) to write.\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        return Publisher.defer(() -> {\n+            // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+\n+            // Setup read side publisher and nodes\n+            DelayedSubscribePublisher<Resp> delayedResponsePublisher = new DelayedSubscribePublisher<>(\n+                    toSource(connection.read()));\n+            Node readNode = new Node(delayedResponsePublisher::processSubscribers);\n+            Publisher<Resp> composedResponsePublisher =\n+                    delayedResponsePublisher.liftSync(new ReadPopNextOperator(readNode));\n+\n+            // Setup write side publisher and nodes\n+            DelayedSubscribeCompletable delayedRequestCompletable = new DelayedSubscribeCompletable(toSource(\n+                            connection.write(requestPublisher, flushStrategySupplier, writeDemandEstimatorSupplier)));\n+            Node writeNode = new Node(() -> {\n+                try {\n+                    queueOffer(readQueueTailUpdater, readNode);\n+                } finally {\n+                    delayedRequestCompletable.processSubscribers();\n+                }\n+            });\n+\n+            queueOffer(writeQueueTailUpdater, writeNode);\n+\n+            return delayedRequestCompletable.liftSync(new WritePopNextOperator(writeNode))\n+                    // If there is an error on the read/write side we propagate the errors between the two via merge.\n+                    .merge(composedResponsePublisher);\n+        });\n+    }\n+\n+    @Override\n+    public SocketAddress localAddress() {\n+        return connection.localAddress();\n+    }\n+\n+    @Override\n+    public SocketAddress remoteAddress() {\n+        return connection.remoteAddress();\n+    }\n+\n+    @Override\n+    @Nullable\n+    public SSLSession sslSession() {\n+        return connection.sslSession();\n+    }\n+\n+    @Override\n+    public ExecutionContext executionContext() {\n+        return connection.executionContext();\n+    }\n+\n+    @Nullable\n+    @Override\n+    public <T> T socketOption(final SocketOption<T> option) {\n+        return connection.socketOption(option);\n+    }\n+\n+    @Override\n+    public Protocol protocol() {\n+        return connection.protocol();\n+    }\n+\n+    @Override\n+    public Single<Throwable> transportError() {\n+        return connection.transportError();\n+    }\n+\n+    @Override\n+    public Completable onClosing() {\n+        return connection.onClosing();\n+    }\n+\n+    @Override\n+    public Completable onClose() {\n+        return connection.onClose();\n+    }\n+\n+    @Override\n+    public Completable closeAsync() {\n+        return connection.closeAsync();\n+    }\n+\n+    @Override\n+    public Completable closeAsyncGracefully() {\n+        return connection.closeAsyncGracefully();\n+    }\n+\n+    @Override\n+    public Channel nettyChannel() {\n+        return connection.nettyChannel();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return getClass().getName() + '(' + connection + ')';\n+    }\n+\n+    @Override\n+    public Cancellable updateFlushStrategy(final NettyConnectionContext.FlushStrategyProvider strategyProvider) {\n+        return connection.updateFlushStrategy(strategyProvider);\n+    }\n+\n+    @Override\n+    public FlushStrategy defaultFlushStrategy() {\n+        return connection.defaultFlushStrategy();\n+    }\n+\n+    private void queueOffer(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7469332830d536d9dc82b82bad56e4860a3caf7e"}, "originalPosition": 200}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODE3ODcxOQ==", "bodyText": "nit: misordered modifierns, shoud be @SuppressWarnings(\"rawtypes\") final", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r398178719", "createdAt": "2020-03-25T21:23:52Z", "author": {"login": "idelpivnitskiy"}, "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.CompletableSource;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.CompletableOperator;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.PublisherOperator;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+\n+import io.netty.channel.Channel;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.Arrays;\n+import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(NettyPipelinedConnection.class);\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            writeQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"writeQueueTail\");\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            readQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"readQueueTail\");\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node writeQueueTail;\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node readQueueTail;\n+\n+    private final NettyConnection<Resp, Req> connection;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} producing the request(s) to write.\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        return Publisher.defer(() -> {\n+            // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+\n+            // Setup read side publisher and nodes\n+            DelayedSubscribePublisher<Resp> delayedResponsePublisher = new DelayedSubscribePublisher<>(\n+                    toSource(connection.read()));\n+            Node readNode = new Node(delayedResponsePublisher::processSubscribers);\n+            Publisher<Resp> composedResponsePublisher =\n+                    delayedResponsePublisher.liftSync(new ReadPopNextOperator(readNode));\n+\n+            // Setup write side publisher and nodes\n+            DelayedSubscribeCompletable delayedRequestCompletable = new DelayedSubscribeCompletable(toSource(\n+                            connection.write(requestPublisher, flushStrategySupplier, writeDemandEstimatorSupplier)));\n+            Node writeNode = new Node(() -> {\n+                try {\n+                    queueOffer(readQueueTailUpdater, readNode);\n+                } finally {\n+                    delayedRequestCompletable.processSubscribers();\n+                }\n+            });\n+\n+            queueOffer(writeQueueTailUpdater, writeNode);\n+\n+            return delayedRequestCompletable.liftSync(new WritePopNextOperator(writeNode))\n+                    // If there is an error on the read/write side we propagate the errors between the two via merge.\n+                    .merge(composedResponsePublisher);\n+        });\n+    }\n+\n+    @Override\n+    public SocketAddress localAddress() {\n+        return connection.localAddress();\n+    }\n+\n+    @Override\n+    public SocketAddress remoteAddress() {\n+        return connection.remoteAddress();\n+    }\n+\n+    @Override\n+    @Nullable\n+    public SSLSession sslSession() {\n+        return connection.sslSession();\n+    }\n+\n+    @Override\n+    public ExecutionContext executionContext() {\n+        return connection.executionContext();\n+    }\n+\n+    @Nullable\n+    @Override\n+    public <T> T socketOption(final SocketOption<T> option) {\n+        return connection.socketOption(option);\n+    }\n+\n+    @Override\n+    public Protocol protocol() {\n+        return connection.protocol();\n+    }\n+\n+    @Override\n+    public Single<Throwable> transportError() {\n+        return connection.transportError();\n+    }\n+\n+    @Override\n+    public Completable onClosing() {\n+        return connection.onClosing();\n+    }\n+\n+    @Override\n+    public Completable onClose() {\n+        return connection.onClose();\n+    }\n+\n+    @Override\n+    public Completable closeAsync() {\n+        return connection.closeAsync();\n+    }\n+\n+    @Override\n+    public Completable closeAsyncGracefully() {\n+        return connection.closeAsyncGracefully();\n+    }\n+\n+    @Override\n+    public Channel nettyChannel() {\n+        return connection.nettyChannel();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return getClass().getName() + '(' + connection + ')';\n+    }\n+\n+    @Override\n+    public Cancellable updateFlushStrategy(final NettyConnectionContext.FlushStrategyProvider strategyProvider) {\n+        return connection.updateFlushStrategy(strategyProvider);\n+    }\n+\n+    @Override\n+    public FlushStrategy defaultFlushStrategy() {\n+        return connection.defaultFlushStrategy();\n+    }\n+\n+    private void queueOffer(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node node) {\n+        for (;;) {\n+            Node tail = tailUpdater.get(this);\n+            if (tail == null) {\n+                if (tailUpdater.compareAndSet(this, null, node)) {\n+                    // node has been inserted and is the only node, we initiate processing.\n+                    safeProcessSubscribers(node.delayedSource);\n+                    break;\n+                }\n+                // Another thread won the race to offer a node, loop around and try again.\n+            } else if (tail.append(node)) {\n+                // Make the newly appended node visible as the tail. This is a best effort CAS and may fail because:\n+                // 1. Another thread is also inserting, has a stale tail, followed its existing tail links, and updated\n+                // the tail reference via queueOfferPatchTail.\n+                // 2. The consumer thread has seen the link from the old tail to the new node, processed node,\n+                // popped node from the list (updated node's next to point to EMPTY_NODE), another producer thread\n+                // appends a new node, sees the tail is popped, and updates the tail reference via CAS.\n+                tailUpdater.compareAndSet(this, tail, node);\n+                break;\n+            } else if (tail.isPopped()) {\n+                // A previously appended node was processed, and popped before updating the tail after append. In that\n+                // case the tail maybe pointing to an invalid node and we clear it out.\n+                if (tailUpdater.compareAndSet(this, tail, node)) {\n+                    safeProcessSubscribers(node.delayedSource);\n+                    break;\n+                }\n+                // Best effort to clear the tail, and failure is OK because:\n+                // 1. Another thread is in offer and already patched up the tail pointer and we will read the new tail\n+                // on the next loop iteration.\n+            } else if (queueOfferPatchTail(tailUpdater, node, tail)) {\n+                break;\n+            }\n+        }\n+    }\n+\n+    private boolean queueOfferPatchTail(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7469332830d536d9dc82b82bad56e4860a3caf7e"}, "originalPosition": 237}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODE3ODc5MA==", "bodyText": "nit: misordered modifierns, shoud be @SuppressWarnings(\"rawtypes\") final", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r398178790", "createdAt": "2020-03-25T21:23:59Z", "author": {"login": "idelpivnitskiy"}, "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.CompletableSource;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.CompletableOperator;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.PublisherOperator;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+\n+import io.netty.channel.Channel;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.Arrays;\n+import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(NettyPipelinedConnection.class);\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            writeQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"writeQueueTail\");\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            readQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"readQueueTail\");\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node writeQueueTail;\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node readQueueTail;\n+\n+    private final NettyConnection<Resp, Req> connection;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} producing the request(s) to write.\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        return Publisher.defer(() -> {\n+            // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+\n+            // Setup read side publisher and nodes\n+            DelayedSubscribePublisher<Resp> delayedResponsePublisher = new DelayedSubscribePublisher<>(\n+                    toSource(connection.read()));\n+            Node readNode = new Node(delayedResponsePublisher::processSubscribers);\n+            Publisher<Resp> composedResponsePublisher =\n+                    delayedResponsePublisher.liftSync(new ReadPopNextOperator(readNode));\n+\n+            // Setup write side publisher and nodes\n+            DelayedSubscribeCompletable delayedRequestCompletable = new DelayedSubscribeCompletable(toSource(\n+                            connection.write(requestPublisher, flushStrategySupplier, writeDemandEstimatorSupplier)));\n+            Node writeNode = new Node(() -> {\n+                try {\n+                    queueOffer(readQueueTailUpdater, readNode);\n+                } finally {\n+                    delayedRequestCompletable.processSubscribers();\n+                }\n+            });\n+\n+            queueOffer(writeQueueTailUpdater, writeNode);\n+\n+            return delayedRequestCompletable.liftSync(new WritePopNextOperator(writeNode))\n+                    // If there is an error on the read/write side we propagate the errors between the two via merge.\n+                    .merge(composedResponsePublisher);\n+        });\n+    }\n+\n+    @Override\n+    public SocketAddress localAddress() {\n+        return connection.localAddress();\n+    }\n+\n+    @Override\n+    public SocketAddress remoteAddress() {\n+        return connection.remoteAddress();\n+    }\n+\n+    @Override\n+    @Nullable\n+    public SSLSession sslSession() {\n+        return connection.sslSession();\n+    }\n+\n+    @Override\n+    public ExecutionContext executionContext() {\n+        return connection.executionContext();\n+    }\n+\n+    @Nullable\n+    @Override\n+    public <T> T socketOption(final SocketOption<T> option) {\n+        return connection.socketOption(option);\n+    }\n+\n+    @Override\n+    public Protocol protocol() {\n+        return connection.protocol();\n+    }\n+\n+    @Override\n+    public Single<Throwable> transportError() {\n+        return connection.transportError();\n+    }\n+\n+    @Override\n+    public Completable onClosing() {\n+        return connection.onClosing();\n+    }\n+\n+    @Override\n+    public Completable onClose() {\n+        return connection.onClose();\n+    }\n+\n+    @Override\n+    public Completable closeAsync() {\n+        return connection.closeAsync();\n+    }\n+\n+    @Override\n+    public Completable closeAsyncGracefully() {\n+        return connection.closeAsyncGracefully();\n+    }\n+\n+    @Override\n+    public Channel nettyChannel() {\n+        return connection.nettyChannel();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return getClass().getName() + '(' + connection + ')';\n+    }\n+\n+    @Override\n+    public Cancellable updateFlushStrategy(final NettyConnectionContext.FlushStrategyProvider strategyProvider) {\n+        return connection.updateFlushStrategy(strategyProvider);\n+    }\n+\n+    @Override\n+    public FlushStrategy defaultFlushStrategy() {\n+        return connection.defaultFlushStrategy();\n+    }\n+\n+    private void queueOffer(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node node) {\n+        for (;;) {\n+            Node tail = tailUpdater.get(this);\n+            if (tail == null) {\n+                if (tailUpdater.compareAndSet(this, null, node)) {\n+                    // node has been inserted and is the only node, we initiate processing.\n+                    safeProcessSubscribers(node.delayedSource);\n+                    break;\n+                }\n+                // Another thread won the race to offer a node, loop around and try again.\n+            } else if (tail.append(node)) {\n+                // Make the newly appended node visible as the tail. This is a best effort CAS and may fail because:\n+                // 1. Another thread is also inserting, has a stale tail, followed its existing tail links, and updated\n+                // the tail reference via queueOfferPatchTail.\n+                // 2. The consumer thread has seen the link from the old tail to the new node, processed node,\n+                // popped node from the list (updated node's next to point to EMPTY_NODE), another producer thread\n+                // appends a new node, sees the tail is popped, and updates the tail reference via CAS.\n+                tailUpdater.compareAndSet(this, tail, node);\n+                break;\n+            } else if (tail.isPopped()) {\n+                // A previously appended node was processed, and popped before updating the tail after append. In that\n+                // case the tail maybe pointing to an invalid node and we clear it out.\n+                if (tailUpdater.compareAndSet(this, tail, node)) {\n+                    safeProcessSubscribers(node.delayedSource);\n+                    break;\n+                }\n+                // Best effort to clear the tail, and failure is OK because:\n+                // 1. Another thread is in offer and already patched up the tail pointer and we will read the new tail\n+                // on the next loop iteration.\n+            } else if (queueOfferPatchTail(tailUpdater, node, tail)) {\n+                break;\n+            }\n+        }\n+    }\n+\n+    private boolean queueOfferPatchTail(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node node,\n+            final Node tail) {\n+        Node currentTail = tailUpdater.get(this);\n+        if (currentTail == tail) {\n+            // tail is stale so attempt to iterate through the linked list and update tail.\n+            currentTail = tail.iterateToTail();\n+            if (currentTail.isPopped()) {\n+                if (tailUpdater.compareAndSet(this, tail, node)) {\n+                    safeProcessSubscribers(node.delayedSource);\n+                    return true;\n+                }\n+            } else {\n+                tailUpdater.compareAndSet(this, tail, currentTail);\n+            }\n+            // Best effort to update/clear the tail, and failure is OK because:\n+            // 1. Another thread is in offer and already patched up the tail pointer and we will read the new\n+            // tail on the next loop iteration.\n+        }\n+        return false;\n+    }\n+\n+    private void queuePop(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7469332830d536d9dc82b82bad56e4860a3caf7e"}, "originalPosition": 260}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODE3OTI0OQ==", "bodyText": "The ordering of tags should be opposite:\n<ul>\n    <li>...</li>\n    ...\n</ul>", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r398179249", "createdAt": "2020-03-25T21:24:50Z", "author": {"login": "idelpivnitskiy"}, "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.CompletableSource;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.CompletableOperator;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.PublisherOperator;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+\n+import io.netty.channel.Channel;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.Arrays;\n+import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(NettyPipelinedConnection.class);\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            writeQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"writeQueueTail\");\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            readQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"readQueueTail\");\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node writeQueueTail;\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node readQueueTail;\n+\n+    private final NettyConnection<Resp, Req> connection;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} producing the request(s) to write.\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        return Publisher.defer(() -> {\n+            // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+\n+            // Setup read side publisher and nodes\n+            DelayedSubscribePublisher<Resp> delayedResponsePublisher = new DelayedSubscribePublisher<>(\n+                    toSource(connection.read()));\n+            Node readNode = new Node(delayedResponsePublisher::processSubscribers);\n+            Publisher<Resp> composedResponsePublisher =\n+                    delayedResponsePublisher.liftSync(new ReadPopNextOperator(readNode));\n+\n+            // Setup write side publisher and nodes\n+            DelayedSubscribeCompletable delayedRequestCompletable = new DelayedSubscribeCompletable(toSource(\n+                            connection.write(requestPublisher, flushStrategySupplier, writeDemandEstimatorSupplier)));\n+            Node writeNode = new Node(() -> {\n+                try {\n+                    queueOffer(readQueueTailUpdater, readNode);\n+                } finally {\n+                    delayedRequestCompletable.processSubscribers();\n+                }\n+            });\n+\n+            queueOffer(writeQueueTailUpdater, writeNode);\n+\n+            return delayedRequestCompletable.liftSync(new WritePopNextOperator(writeNode))\n+                    // If there is an error on the read/write side we propagate the errors between the two via merge.\n+                    .merge(composedResponsePublisher);\n+        });\n+    }\n+\n+    @Override\n+    public SocketAddress localAddress() {\n+        return connection.localAddress();\n+    }\n+\n+    @Override\n+    public SocketAddress remoteAddress() {\n+        return connection.remoteAddress();\n+    }\n+\n+    @Override\n+    @Nullable\n+    public SSLSession sslSession() {\n+        return connection.sslSession();\n+    }\n+\n+    @Override\n+    public ExecutionContext executionContext() {\n+        return connection.executionContext();\n+    }\n+\n+    @Nullable\n+    @Override\n+    public <T> T socketOption(final SocketOption<T> option) {\n+        return connection.socketOption(option);\n+    }\n+\n+    @Override\n+    public Protocol protocol() {\n+        return connection.protocol();\n+    }\n+\n+    @Override\n+    public Single<Throwable> transportError() {\n+        return connection.transportError();\n+    }\n+\n+    @Override\n+    public Completable onClosing() {\n+        return connection.onClosing();\n+    }\n+\n+    @Override\n+    public Completable onClose() {\n+        return connection.onClose();\n+    }\n+\n+    @Override\n+    public Completable closeAsync() {\n+        return connection.closeAsync();\n+    }\n+\n+    @Override\n+    public Completable closeAsyncGracefully() {\n+        return connection.closeAsyncGracefully();\n+    }\n+\n+    @Override\n+    public Channel nettyChannel() {\n+        return connection.nettyChannel();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return getClass().getName() + '(' + connection + ')';\n+    }\n+\n+    @Override\n+    public Cancellable updateFlushStrategy(final NettyConnectionContext.FlushStrategyProvider strategyProvider) {\n+        return connection.updateFlushStrategy(strategyProvider);\n+    }\n+\n+    @Override\n+    public FlushStrategy defaultFlushStrategy() {\n+        return connection.defaultFlushStrategy();\n+    }\n+\n+    private void queueOffer(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node node) {\n+        for (;;) {\n+            Node tail = tailUpdater.get(this);\n+            if (tail == null) {\n+                if (tailUpdater.compareAndSet(this, null, node)) {\n+                    // node has been inserted and is the only node, we initiate processing.\n+                    safeProcessSubscribers(node.delayedSource);\n+                    break;\n+                }\n+                // Another thread won the race to offer a node, loop around and try again.\n+            } else if (tail.append(node)) {\n+                // Make the newly appended node visible as the tail. This is a best effort CAS and may fail because:\n+                // 1. Another thread is also inserting, has a stale tail, followed its existing tail links, and updated\n+                // the tail reference via queueOfferPatchTail.\n+                // 2. The consumer thread has seen the link from the old tail to the new node, processed node,\n+                // popped node from the list (updated node's next to point to EMPTY_NODE), another producer thread\n+                // appends a new node, sees the tail is popped, and updates the tail reference via CAS.\n+                tailUpdater.compareAndSet(this, tail, node);\n+                break;\n+            } else if (tail.isPopped()) {\n+                // A previously appended node was processed, and popped before updating the tail after append. In that\n+                // case the tail maybe pointing to an invalid node and we clear it out.\n+                if (tailUpdater.compareAndSet(this, tail, node)) {\n+                    safeProcessSubscribers(node.delayedSource);\n+                    break;\n+                }\n+                // Best effort to clear the tail, and failure is OK because:\n+                // 1. Another thread is in offer and already patched up the tail pointer and we will read the new tail\n+                // on the next loop iteration.\n+            } else if (queueOfferPatchTail(tailUpdater, node, tail)) {\n+                break;\n+            }\n+        }\n+    }\n+\n+    private boolean queueOfferPatchTail(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node node,\n+            final Node tail) {\n+        Node currentTail = tailUpdater.get(this);\n+        if (currentTail == tail) {\n+            // tail is stale so attempt to iterate through the linked list and update tail.\n+            currentTail = tail.iterateToTail();\n+            if (currentTail.isPopped()) {\n+                if (tailUpdater.compareAndSet(this, tail, node)) {\n+                    safeProcessSubscribers(node.delayedSource);\n+                    return true;\n+                }\n+            } else {\n+                tailUpdater.compareAndSet(this, tail, currentTail);\n+            }\n+            // Best effort to update/clear the tail, and failure is OK because:\n+            // 1. Another thread is in offer and already patched up the tail pointer and we will read the new\n+            // tail on the next loop iteration.\n+        }\n+        return false;\n+    }\n+\n+    private void queuePop(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node head) {\n+        // This method maybe called multiple times on the same node, in which case next will be EMPTY_NODE and the run\n+        // method will be a noop.\n+        Node next = head.pop();\n+        if (next != null) {\n+            safeProcessSubscribers(next.delayedSource);\n+        } else {\n+            tailUpdater.compareAndSet(this, head, null);\n+            // Best effort to clear the tail, and failure is OK because:\n+            // 1. Another thread appended this head, but has not yet updated the tail. In this case the tail will be\n+            // stale (e.g. pointing to head node that has already been processed) and corrected by future inserts.\n+        }\n+    }\n+\n+    private void safeProcessSubscribers(Runnable delayedSource) {\n+        try {\n+            delayedSource.run();\n+        } catch (Throwable cause) {\n+            connection.closeAsync().subscribe();\n+            LOGGER.warn(\"closing connection={} due to unexpected error on subscribe\", connection, cause);\n+        }\n+    }\n+\n+    /**\n+     * Logically equivalent to {@link Publisher#afterFinally(Runnable)} but relies upon internal queue CAS operations\n+     * to prevent multiple executions (e.g. reduces a CAS operation).\n+     */\n+    private final class ReadPopNextOperator implements PublisherOperator<Resp, Resp> {\n+        private final Node readNode;\n+\n+        private ReadPopNextOperator(final Node readNode) {\n+            this.readNode = readNode;\n+        }\n+\n+        @Override\n+        public PublisherSource.Subscriber<? super Resp> apply(PublisherSource.Subscriber<? super Resp> subscriber) {\n+            return new PublisherSource.Subscriber<Resp>() {\n+                @Override\n+                public void onSubscribe(final PublisherSource.Subscription subscription) {\n+                    subscriber.onSubscribe(new PublisherSource.Subscription() {\n+                        @Override\n+                        public void request(final long n) {\n+                            subscription.request(n);\n+                        }\n+\n+                        @Override\n+                        public void cancel() {\n+                            try {\n+                                subscription.cancel();\n+                            } finally {\n+                                pollNext();\n+                            }\n+                        }\n+                    });\n+                }\n+\n+                @Override\n+                public void onNext(@Nullable final Resp t) {\n+                    subscriber.onNext(t);\n+                }\n+\n+                @Override\n+                public void onError(final Throwable t) {\n+                    try {\n+                        subscriber.onError(t);\n+                    } finally {\n+                        pollNext();\n+                    }\n+                }\n+\n+                @Override\n+                public void onComplete() {\n+                    try {\n+                        subscriber.onComplete();\n+                    } finally {\n+                        pollNext();\n+                    }\n+                }\n+\n+                private void pollNext() {\n+                    queuePop(readQueueTailUpdater, readNode);\n+                }\n+            };\n+        }\n+    }\n+\n+    /**\n+     * Logically equivalent to {@link Completable#afterFinally(Runnable)} but relies upon internal queue CAS operations\n+     * to prevent multiple executions (e.g. reduces a CAS operation).\n+     */\n+    private final class WritePopNextOperator implements CompletableOperator {\n+        private final Node writeNode;\n+\n+        WritePopNextOperator(final Node writeNode) {\n+            this.writeNode = writeNode;\n+        }\n+\n+        @Override\n+        public CompletableSource.Subscriber apply(final CompletableSource.Subscriber subscriber) {\n+            return new CompletableSource.Subscriber() {\n+                @Override\n+                public void onSubscribe(final Cancellable cancellable) {\n+                    subscriber.onSubscribe(() -> {\n+                        try {\n+                            cancellable.cancel();\n+                        } finally {\n+                            pollNext();\n+                        }\n+                    });\n+                }\n+\n+                @Override\n+                public void onComplete() {\n+                    try {\n+                        subscriber.onComplete();\n+                    } finally {\n+                        pollNext();\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(final Throwable t) {\n+                    try {\n+                        subscriber.onError(t);\n+                    } finally {\n+                        pollNext();\n+                    }\n+                }\n+            };\n+        }\n+\n+        private void pollNext() {\n+            queuePop(writeQueueTailUpdater, writeNode);\n+        }\n+    }\n+\n+    private static final class Node {\n+        private static final Node EMPTY_NODE = new Node();\n+        private static final AtomicReferenceFieldUpdater<Node, Node> nextUpdater =\n+                newUpdater(Node.class, Node.class, \"next\");\n+        @Nullable\n+        private volatile Node next;\n+        final Runnable delayedSource;\n+\n+        Node(Runnable delayedSource) {\n+            this.delayedSource = requireNonNull(delayedSource);\n+        }\n+\n+        private Node() {\n+            this.next = this;\n+            this.delayedSource = () -> { };\n+        }\n+\n+        boolean append(Node next) {\n+            return nextUpdater.compareAndSet(this, null, next);\n+        }\n+\n+        @Nullable\n+        Node pop() {\n+            return nextUpdater.getAndSet(this, EMPTY_NODE);\n+        }\n+\n+        boolean isPopped() {\n+            return next == EMPTY_NODE;\n+        }\n+\n+        Node iterateToTail() {\n+            Node prev = this;\n+            Node next = prev.next;\n+            while (next != null) {\n+                prev = next;\n+                next = next.next;\n+            }\n+            return prev;\n+        }\n+    }\n+\n+    private static final class DelayedSubscribeCompletable extends Completable {\n+        private static final AtomicReferenceFieldUpdater<DelayedSubscribeCompletable, Object> stateUpdater =\n+                newUpdater(DelayedSubscribeCompletable.class, Object.class, \"state\");\n+        private static final Object ALLOW_SUBSCRIBE = new Object();\n+        private static final Object DRAINING_SUBSCRIBERS = new Object();\n+\n+        private final CompletableSource completable;\n+        /**\n+         * One of the following:\n+         * <li>\n+         *     <ul>{@code null} - initial state</ul>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7469332830d536d9dc82b82bad56e4860a3caf7e"}, "originalPosition": 448}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODE3OTM1OQ==", "bodyText": "The ordering of tags should be opposite:\n<ul>\n    <li>...</li>\n    ...\n</ul>", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r398179359", "createdAt": "2020-03-25T21:25:05Z", "author": {"login": "idelpivnitskiy"}, "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,628 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.CompletableSource;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.CompletableOperator;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.PublisherOperator;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+\n+import io.netty.channel.Channel;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.Arrays;\n+import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(NettyPipelinedConnection.class);\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            writeQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"writeQueueTail\");\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node>\n+            readQueueTailUpdater = newUpdater(NettyPipelinedConnection.class, Node.class, \"readQueueTail\");\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node writeQueueTail;\n+    @SuppressWarnings(\"unused\")\n+    @Nullable\n+    private volatile Node readQueueTail;\n+\n+    private final NettyConnection<Resp, Req> connection;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} producing the request(s) to write.\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        return Publisher.defer(() -> {\n+            // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+\n+            // Setup read side publisher and nodes\n+            DelayedSubscribePublisher<Resp> delayedResponsePublisher = new DelayedSubscribePublisher<>(\n+                    toSource(connection.read()));\n+            Node readNode = new Node(delayedResponsePublisher::processSubscribers);\n+            Publisher<Resp> composedResponsePublisher =\n+                    delayedResponsePublisher.liftSync(new ReadPopNextOperator(readNode));\n+\n+            // Setup write side publisher and nodes\n+            DelayedSubscribeCompletable delayedRequestCompletable = new DelayedSubscribeCompletable(toSource(\n+                            connection.write(requestPublisher, flushStrategySupplier, writeDemandEstimatorSupplier)));\n+            Node writeNode = new Node(() -> {\n+                try {\n+                    queueOffer(readQueueTailUpdater, readNode);\n+                } finally {\n+                    delayedRequestCompletable.processSubscribers();\n+                }\n+            });\n+\n+            queueOffer(writeQueueTailUpdater, writeNode);\n+\n+            return delayedRequestCompletable.liftSync(new WritePopNextOperator(writeNode))\n+                    // If there is an error on the read/write side we propagate the errors between the two via merge.\n+                    .merge(composedResponsePublisher);\n+        });\n+    }\n+\n+    @Override\n+    public SocketAddress localAddress() {\n+        return connection.localAddress();\n+    }\n+\n+    @Override\n+    public SocketAddress remoteAddress() {\n+        return connection.remoteAddress();\n+    }\n+\n+    @Override\n+    @Nullable\n+    public SSLSession sslSession() {\n+        return connection.sslSession();\n+    }\n+\n+    @Override\n+    public ExecutionContext executionContext() {\n+        return connection.executionContext();\n+    }\n+\n+    @Nullable\n+    @Override\n+    public <T> T socketOption(final SocketOption<T> option) {\n+        return connection.socketOption(option);\n+    }\n+\n+    @Override\n+    public Protocol protocol() {\n+        return connection.protocol();\n+    }\n+\n+    @Override\n+    public Single<Throwable> transportError() {\n+        return connection.transportError();\n+    }\n+\n+    @Override\n+    public Completable onClosing() {\n+        return connection.onClosing();\n+    }\n+\n+    @Override\n+    public Completable onClose() {\n+        return connection.onClose();\n+    }\n+\n+    @Override\n+    public Completable closeAsync() {\n+        return connection.closeAsync();\n+    }\n+\n+    @Override\n+    public Completable closeAsyncGracefully() {\n+        return connection.closeAsyncGracefully();\n+    }\n+\n+    @Override\n+    public Channel nettyChannel() {\n+        return connection.nettyChannel();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return getClass().getName() + '(' + connection + ')';\n+    }\n+\n+    @Override\n+    public Cancellable updateFlushStrategy(final NettyConnectionContext.FlushStrategyProvider strategyProvider) {\n+        return connection.updateFlushStrategy(strategyProvider);\n+    }\n+\n+    @Override\n+    public FlushStrategy defaultFlushStrategy() {\n+        return connection.defaultFlushStrategy();\n+    }\n+\n+    private void queueOffer(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node node) {\n+        for (;;) {\n+            Node tail = tailUpdater.get(this);\n+            if (tail == null) {\n+                if (tailUpdater.compareAndSet(this, null, node)) {\n+                    // node has been inserted and is the only node, we initiate processing.\n+                    safeProcessSubscribers(node.delayedSource);\n+                    break;\n+                }\n+                // Another thread won the race to offer a node, loop around and try again.\n+            } else if (tail.append(node)) {\n+                // Make the newly appended node visible as the tail. This is a best effort CAS and may fail because:\n+                // 1. Another thread is also inserting, has a stale tail, followed its existing tail links, and updated\n+                // the tail reference via queueOfferPatchTail.\n+                // 2. The consumer thread has seen the link from the old tail to the new node, processed node,\n+                // popped node from the list (updated node's next to point to EMPTY_NODE), another producer thread\n+                // appends a new node, sees the tail is popped, and updates the tail reference via CAS.\n+                tailUpdater.compareAndSet(this, tail, node);\n+                break;\n+            } else if (tail.isPopped()) {\n+                // A previously appended node was processed, and popped before updating the tail after append. In that\n+                // case the tail maybe pointing to an invalid node and we clear it out.\n+                if (tailUpdater.compareAndSet(this, tail, node)) {\n+                    safeProcessSubscribers(node.delayedSource);\n+                    break;\n+                }\n+                // Best effort to clear the tail, and failure is OK because:\n+                // 1. Another thread is in offer and already patched up the tail pointer and we will read the new tail\n+                // on the next loop iteration.\n+            } else if (queueOfferPatchTail(tailUpdater, node, tail)) {\n+                break;\n+            }\n+        }\n+    }\n+\n+    private boolean queueOfferPatchTail(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node node,\n+            final Node tail) {\n+        Node currentTail = tailUpdater.get(this);\n+        if (currentTail == tail) {\n+            // tail is stale so attempt to iterate through the linked list and update tail.\n+            currentTail = tail.iterateToTail();\n+            if (currentTail.isPopped()) {\n+                if (tailUpdater.compareAndSet(this, tail, node)) {\n+                    safeProcessSubscribers(node.delayedSource);\n+                    return true;\n+                }\n+            } else {\n+                tailUpdater.compareAndSet(this, tail, currentTail);\n+            }\n+            // Best effort to update/clear the tail, and failure is OK because:\n+            // 1. Another thread is in offer and already patched up the tail pointer and we will read the new\n+            // tail on the next loop iteration.\n+        }\n+        return false;\n+    }\n+\n+    private void queuePop(\n+            final @SuppressWarnings(\"rawtypes\") AtomicReferenceFieldUpdater<NettyPipelinedConnection, Node> tailUpdater,\n+            final Node head) {\n+        // This method maybe called multiple times on the same node, in which case next will be EMPTY_NODE and the run\n+        // method will be a noop.\n+        Node next = head.pop();\n+        if (next != null) {\n+            safeProcessSubscribers(next.delayedSource);\n+        } else {\n+            tailUpdater.compareAndSet(this, head, null);\n+            // Best effort to clear the tail, and failure is OK because:\n+            // 1. Another thread appended this head, but has not yet updated the tail. In this case the tail will be\n+            // stale (e.g. pointing to head node that has already been processed) and corrected by future inserts.\n+        }\n+    }\n+\n+    private void safeProcessSubscribers(Runnable delayedSource) {\n+        try {\n+            delayedSource.run();\n+        } catch (Throwable cause) {\n+            connection.closeAsync().subscribe();\n+            LOGGER.warn(\"closing connection={} due to unexpected error on subscribe\", connection, cause);\n+        }\n+    }\n+\n+    /**\n+     * Logically equivalent to {@link Publisher#afterFinally(Runnable)} but relies upon internal queue CAS operations\n+     * to prevent multiple executions (e.g. reduces a CAS operation).\n+     */\n+    private final class ReadPopNextOperator implements PublisherOperator<Resp, Resp> {\n+        private final Node readNode;\n+\n+        private ReadPopNextOperator(final Node readNode) {\n+            this.readNode = readNode;\n+        }\n+\n+        @Override\n+        public PublisherSource.Subscriber<? super Resp> apply(PublisherSource.Subscriber<? super Resp> subscriber) {\n+            return new PublisherSource.Subscriber<Resp>() {\n+                @Override\n+                public void onSubscribe(final PublisherSource.Subscription subscription) {\n+                    subscriber.onSubscribe(new PublisherSource.Subscription() {\n+                        @Override\n+                        public void request(final long n) {\n+                            subscription.request(n);\n+                        }\n+\n+                        @Override\n+                        public void cancel() {\n+                            try {\n+                                subscription.cancel();\n+                            } finally {\n+                                pollNext();\n+                            }\n+                        }\n+                    });\n+                }\n+\n+                @Override\n+                public void onNext(@Nullable final Resp t) {\n+                    subscriber.onNext(t);\n+                }\n+\n+                @Override\n+                public void onError(final Throwable t) {\n+                    try {\n+                        subscriber.onError(t);\n+                    } finally {\n+                        pollNext();\n+                    }\n+                }\n+\n+                @Override\n+                public void onComplete() {\n+                    try {\n+                        subscriber.onComplete();\n+                    } finally {\n+                        pollNext();\n+                    }\n+                }\n+\n+                private void pollNext() {\n+                    queuePop(readQueueTailUpdater, readNode);\n+                }\n+            };\n+        }\n+    }\n+\n+    /**\n+     * Logically equivalent to {@link Completable#afterFinally(Runnable)} but relies upon internal queue CAS operations\n+     * to prevent multiple executions (e.g. reduces a CAS operation).\n+     */\n+    private final class WritePopNextOperator implements CompletableOperator {\n+        private final Node writeNode;\n+\n+        WritePopNextOperator(final Node writeNode) {\n+            this.writeNode = writeNode;\n+        }\n+\n+        @Override\n+        public CompletableSource.Subscriber apply(final CompletableSource.Subscriber subscriber) {\n+            return new CompletableSource.Subscriber() {\n+                @Override\n+                public void onSubscribe(final Cancellable cancellable) {\n+                    subscriber.onSubscribe(() -> {\n+                        try {\n+                            cancellable.cancel();\n+                        } finally {\n+                            pollNext();\n+                        }\n+                    });\n+                }\n+\n+                @Override\n+                public void onComplete() {\n+                    try {\n+                        subscriber.onComplete();\n+                    } finally {\n+                        pollNext();\n+                    }\n+                }\n+\n+                @Override\n+                public void onError(final Throwable t) {\n+                    try {\n+                        subscriber.onError(t);\n+                    } finally {\n+                        pollNext();\n+                    }\n+                }\n+            };\n+        }\n+\n+        private void pollNext() {\n+            queuePop(writeQueueTailUpdater, writeNode);\n+        }\n+    }\n+\n+    private static final class Node {\n+        private static final Node EMPTY_NODE = new Node();\n+        private static final AtomicReferenceFieldUpdater<Node, Node> nextUpdater =\n+                newUpdater(Node.class, Node.class, \"next\");\n+        @Nullable\n+        private volatile Node next;\n+        final Runnable delayedSource;\n+\n+        Node(Runnable delayedSource) {\n+            this.delayedSource = requireNonNull(delayedSource);\n+        }\n+\n+        private Node() {\n+            this.next = this;\n+            this.delayedSource = () -> { };\n+        }\n+\n+        boolean append(Node next) {\n+            return nextUpdater.compareAndSet(this, null, next);\n+        }\n+\n+        @Nullable\n+        Node pop() {\n+            return nextUpdater.getAndSet(this, EMPTY_NODE);\n+        }\n+\n+        boolean isPopped() {\n+            return next == EMPTY_NODE;\n+        }\n+\n+        Node iterateToTail() {\n+            Node prev = this;\n+            Node next = prev.next;\n+            while (next != null) {\n+                prev = next;\n+                next = next.next;\n+            }\n+            return prev;\n+        }\n+    }\n+\n+    private static final class DelayedSubscribeCompletable extends Completable {\n+        private static final AtomicReferenceFieldUpdater<DelayedSubscribeCompletable, Object> stateUpdater =\n+                newUpdater(DelayedSubscribeCompletable.class, Object.class, \"state\");\n+        private static final Object ALLOW_SUBSCRIBE = new Object();\n+        private static final Object DRAINING_SUBSCRIBERS = new Object();\n+\n+        private final CompletableSource completable;\n+        /**\n+         * One of the following:\n+         * <li>\n+         *     <ul>{@code null} - initial state</ul>\n+         *     <ul>{@link #ALLOW_SUBSCRIBE} - {@link #handleSubscribe(CompletableSource.Subscriber)} methods will\n+         *     pass through to {@link #completable}</ul>\n+         *     <ul>{@link #DRAINING_SUBSCRIBERS} - set in {@link #processSubscribers()} while calling\n+         *     {@link CompletableSource#subscribe(CompletableSource.Subscriber)} on each {@link Completable}</ul>\n+         *     <ul>{@link CompletableSource.Subscriber} - if there is a single\n+         *     {@link #handleSubscribe(CompletableSource.Subscriber)} pending</ul>\n+         *     <ul>{@code Object[]} - if there are multiple {@link #handleSubscribe(CompletableSource.Subscriber)}\n+         *     calls pending</ul>\n+         * </li>\n+         */\n+        @Nullable\n+        private volatile Object state;\n+\n+        private DelayedSubscribeCompletable(final CompletableSource completable) {\n+            this.completable = requireNonNull(completable);\n+        }\n+\n+        void processSubscribers() {\n+            for (;;) {\n+                Object currentState = state;\n+                if (currentState == null) {\n+                    if (stateUpdater.compareAndSet(this, null, ALLOW_SUBSCRIBE)) {\n+                        break;\n+                    }\n+                } else if (currentState == ALLOW_SUBSCRIBE) {\n+                    break;\n+                } else if (currentState instanceof CompletableSource.Subscriber) {\n+                    CompletableSource.Subscriber currentSubscriber = (CompletableSource.Subscriber) currentState;\n+                    if (stateUpdater.compareAndSet(this, currentState, DRAINING_SUBSCRIBERS)) {\n+                        completable.subscribe(currentSubscriber);\n+                        if (stateUpdater.compareAndSet(this, DRAINING_SUBSCRIBERS, ALLOW_SUBSCRIBE)) {\n+                            break;\n+                        }\n+                    }\n+                } else if (stateUpdater.compareAndSet(this, currentState, DRAINING_SUBSCRIBERS)) {\n+                    assert currentState != DRAINING_SUBSCRIBERS;\n+                    CompletableSource.Subscriber[] queue = (CompletableSource.Subscriber[]) currentState;\n+                    for (CompletableSource.Subscriber next : queue) {\n+                        completable.subscribe(next);\n+                    }\n+                    if (stateUpdater.compareAndSet(this, DRAINING_SUBSCRIBERS, ALLOW_SUBSCRIBE)) {\n+                        break;\n+                    }\n+                }\n+            }\n+        }\n+\n+        @Override\n+        protected void handleSubscribe(final CompletableSource.Subscriber subscriber) {\n+            for (;;) {\n+                Object currentState = state;\n+                if (currentState == null || currentState == DRAINING_SUBSCRIBERS) {\n+                    if (stateUpdater.compareAndSet(this, currentState, subscriber)) {\n+                        break;\n+                    }\n+                } else if (currentState == ALLOW_SUBSCRIBE) {\n+                    completable.subscribe(subscriber);\n+                    break;\n+                } else if (currentState instanceof CompletableSource.Subscriber) {\n+                    // Ideally we can propagate the onSubscribe ASAP to allow for cancellation but this completable is\n+                    // designed to defer the subscribe until some other condition occurs, so no work will actually be\n+                    // done until that later time.\n+                    CompletableSource.Subscriber currentSubscriber = (CompletableSource.Subscriber) currentState;\n+                    if (stateUpdater.compareAndSet(this, currentState,\n+                            new Object[] {currentSubscriber, subscriber})) {\n+                        break;\n+                    }\n+                } else {\n+                    Object[] array = (Object[]) currentState;\n+                    // Unmodifiable collection to avoid issues with concurrent adding/draining with processSubscribers.\n+                    // The expected cardinality of the array will be low, so copy/resize is \"good enough\" for now.\n+                    Object[] newArray = Arrays.copyOf(array, array.length + 1);\n+                    newArray[array.length] = subscriber;\n+                    if (stateUpdater.compareAndSet(this, currentState, newArray)) {\n+                        break;\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    private static final class DelayedSubscribePublisher<T> extends Publisher<T> {\n+        @SuppressWarnings(\"rawtypes\")\n+        private static final AtomicReferenceFieldUpdater<DelayedSubscribePublisher, Object> stateUpdater =\n+                newUpdater(DelayedSubscribePublisher.class, Object.class, \"state\");\n+        private static final Object ALLOW_SUBSCRIBE = new Object();\n+        private static final Object DRAINING_SUBSCRIBERS = new Object();\n+\n+        private final PublisherSource<T> publisher;\n+        /**\n+         * One of the following:\n+         * <li>\n+         *     <ul>{@code null} - initial state</ul>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7469332830d536d9dc82b82bad56e4860a3caf7e"}, "originalPosition": 541}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODE5ODM4Nw==", "bodyText": "Since we have only a single implementation of WriteDemandEstimator atm, and both classes (this and MaxSizeBasedWriteDemandEstimator) are in the same io.servicetalk.transport.netty.internal package, can we just make MaxSizeBasedWriteDemandEstimator public instead of introducing new factory? Because the code is internal, we can add it later if necessary.", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r398198387", "createdAt": "2020-03-25T22:04:00Z", "author": {"login": "idelpivnitskiy"}, "path": "servicetalk-transport-netty-internal/src/main/java/io/servicetalk/transport/netty/internal/WriteDemandEstimators.java", "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.transport.netty.internal;\n+\n+/**\n+ * Utility methods associated with {@link WriteDemandEstimator}.\n+ */\n+public final class WriteDemandEstimators {\n+    private WriteDemandEstimators() {\n+        // no instance\n+    }\n+\n+    /**\n+     * Returns a new instance of a default implementation of {@link WriteDemandEstimator}.\n+     *\n+     * @return A new instance of a default implementation of {@link WriteDemandEstimator}.\n+     */\n+    public static WriteDemandEstimator newDefaultEstimator() {\n+        return new MaxSizeBasedWriteDemandEstimator();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7469332830d536d9dc82b82bad56e4860a3caf7e"}, "originalPosition": 32}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "7469332830d536d9dc82b82bad56e4860a3caf7e", "author": {"user": {"login": "Scottmitch", "name": "Scott Mitchell"}}, "url": "https://github.com/apple/servicetalk/commit/7469332830d536d9dc82b82bad56e4860a3caf7e", "committedDate": "2020-03-23T19:30:37Z", "message": "HTTP Client Pipelining fullduplex\n\nMotivation:\nThe queue which orders and sequences HTTP pipelining on the client side\nhas been shown to lead to duplicate subscribe exceptions and also\ndoesn't support full duplex read/write.\n\nModifications:\n- The first was related to DefaultNettyPipelinedConnection\nwhich may have enqueued out of order which lead to a duplicate subscribe\nexception on NettyChannelPublisher. The DefaultNettyPipelinedConnection\nwas rewritten to avoid using the SequentialTaskQueue (which relies upon\nthread locals for single item execution and async completion) and also\ndoesn't allow for full duplex (write must finish before read starts),\nand those issues are both fixed.\n- ClientClosureRaceTest is intentionally closing the server connection\nabrubtley, which may result in writing a request that is not\nautomatically retryable. The retry strategy should always retry in this\ncase or else the test may hang/fail.\n\nResult:\nHTTP client now support full duplex pipelining."}, "afterCommit": {"oid": "fe35d0926b95b6d3e5a49967fceb0dcd4e934fdd", "author": {"user": {"login": "Scottmitch", "name": "Scott Mitchell"}}, "url": "https://github.com/apple/servicetalk/commit/fe35d0926b95b6d3e5a49967fceb0dcd4e934fdd", "committedDate": "2020-03-27T23:22:43Z", "message": "review comments\n\n- move the Delayed sources to their own files, and add tests\n- make error handling more explicit, and add tests\n- address various other review comments\n- move queue logic to independent file to make APIs more clear and allow\nfor easier documentation"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "fe35d0926b95b6d3e5a49967fceb0dcd4e934fdd", "author": {"user": {"login": "Scottmitch", "name": "Scott Mitchell"}}, "url": "https://github.com/apple/servicetalk/commit/fe35d0926b95b6d3e5a49967fceb0dcd4e934fdd", "committedDate": "2020-03-27T23:22:43Z", "message": "review comments\n\n- move the Delayed sources to their own files, and add tests\n- make error handling more explicit, and add tests\n- address various other review comments\n- move queue logic to independent file to make APIs more clear and allow\nfor easier documentation"}, "afterCommit": {"oid": "7656d2486bce249c2f4d7b2f0eeed800d4893089", "author": {"user": {"login": "Scottmitch", "name": "Scott Mitchell"}}, "url": "https://github.com/apple/servicetalk/commit/7656d2486bce249c2f4d7b2f0eeed800d4893089", "committedDate": "2020-03-27T23:32:46Z", "message": "review comments\n\n- move the Delayed sources to their own files, and add tests\n- make error handling more explicit, and add tests\n- address various other review comments\n- move queue logic to independent file to make APIs more clear and allow\nfor easier documentation"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg0MjYxMTE4", "url": "https://github.com/apple/servicetalk/pull/980#pullrequestreview-384261118", "createdAt": "2020-03-30T21:56:47Z", "commit": {"oid": "18a1efba918d766936fffbdb75604b0162f90e93"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQyMTo1Njo0OFrOF99uUg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQyMTo1Njo0OFrOF99uUg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDUxODczOA==", "bodyText": "@NiteshKant - this exception handling was added for demonstration purposes but is somewhat superfluous bcz the queue offer doesn't do any allocations (e.g. node allocation done outside the scope), and we don't always exhaustively protect against OOME type errors.\nalso the try/catch around the insertions are also somewhat much, because the Publisher  (or completable) will catch exceptions thrown during subscribe (in the internal handleSubscribe method). Let me know if you think it is worth keeping all of these cases.", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r400518738", "createdAt": "2020-03-30T21:56:48Z", "author": {"login": "Scottmitch"}, "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,353 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.CompletableSource;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.api.AsyncCloseable;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.CompletableOperator;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.PublisherOperator;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.http.netty.MpmcSequentialRunQueue.Node;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimators;\n+\n+import io.netty.channel.Channel;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    private static final Logger LOGGER = LoggerFactory.getLogger(NettyPipelinedConnection.class);\n+\n+    private final NettyConnection<Resp, Req> connection;\n+    private final MpmcSequentialRunQueue writeQueue;\n+    private final MpmcSequentialRunQueue readQueue;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+        writeQueue = new MpmcSequentialRunQueue();\n+        readQueue = new MpmcSequentialRunQueue();\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher) {\n+        return write(requestPublisher, connection::defaultFlushStrategy, WriteDemandEstimators::newDefaultEstimator);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        return Publisher.defer(() -> {\n+            // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+\n+            // Setup read side publisher and nodes\n+            DelayedSubscribePublisher<Resp> delayedReadPublisher = new DelayedSubscribePublisher<>(\n+                    toSource(connection.read()));\n+            Node readNode = new Node() {\n+                @Override\n+                public void run() {\n+                    try {\n+                        delayedReadPublisher.processSubscribers();\n+                    } catch (Throwable cause) {\n+                        closeOnError(connection, delayedReadPublisher, cause);\n+                    }\n+                }\n+            };\n+            Publisher<Resp> composedReadPublisher = delayedReadPublisher.liftSync(new ReadPopNextOperator(readNode));\n+\n+            // Setup write side publisher and nodes\n+            DelayedSubscribeCompletable delayedWriteCompletable = new DelayedSubscribeCompletable(toSource(\n+                            connection.write(requestPublisher, flushStrategySupplier, writeDemandEstimatorSupplier)));\n+            Node writeNode = new Node() {\n+                @Override\n+                public void run() {\n+                    try {\n+                        try {\n+                            readQueue.offer(readNode);\n+                        } catch (Throwable cause) {\n+                            delayedWriteCompletable.failSubscribers(cause);\n+                            // We have not started the write at this point, and the above operation will:\n+                            // - fail the write subscriber (pop the next write). We haven't subscribed to\n+                            // Completable returned from connection.write(..) and therefore the connection hasn't\n+                            // subscribed to the requestPublisher so there is nothing to cancel on the write side.\n+                            // - fail the merge operator (pop the next read, if still in progress), cancel the\n+                            // connection.read() (which may close the connection if the read is still active), and\n+                            // deliver an error to the downstream read Subscriber.\n+                            return;\n+                        }\n+\n+                        delayedWriteCompletable.processSubscribers();\n+                    } catch (Throwable cause) {\n+                        closeOnError(connection, delayedWriteCompletable, cause);\n+                    }\n+                }\n+            };\n+\n+            try {\n+                writeQueue.offer(writeNode);\n+            } catch (Throwable cause) {\n+                // The writeNode's run method handles exceptions as a result of Subscribe/external calls. An Exception", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "18a1efba918d766936fffbdb75604b0162f90e93"}, "originalPosition": 144}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "47b1de9c5beb12d8b09d8cf7f3742d6d7c187685", "author": {"user": {"login": "Scottmitch", "name": "Scott Mitchell"}}, "url": "https://github.com/apple/servicetalk/commit/47b1de9c5beb12d8b09d8cf7f3742d6d7c187685", "committedDate": "2020-03-30T22:43:05Z", "message": "increase scope of exception"}, "afterCommit": {"oid": "5572e4898545e9e1288da4b74223b157cee00cbb", "author": {"user": {"login": "Scottmitch", "name": "Scott Mitchell"}}, "url": "https://github.com/apple/servicetalk/commit/5572e4898545e9e1288da4b74223b157cee00cbb", "committedDate": "2020-03-30T23:47:57Z", "message": "adjust error handling and add comments"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "2106a0f1b5bdf9a12bd9f9395e6b708f0b6073c0", "author": {"user": {"login": "Scottmitch", "name": "Scott Mitchell"}}, "url": "https://github.com/apple/servicetalk/commit/2106a0f1b5bdf9a12bd9f9395e6b708f0b6073c0", "committedDate": "2020-03-31T22:25:01Z", "message": "more clarification of error flow, removal of unecessary code"}, "afterCommit": {"oid": "eda404ea0d6e3a6fcc88084a3cbc1aac10bbee12", "author": {"user": {"login": "Scottmitch", "name": "Scott Mitchell"}}, "url": "https://github.com/apple/servicetalk/commit/eda404ea0d6e3a6fcc88084a3cbc1aac10bbee12", "committedDate": "2020-04-01T03:26:38Z", "message": "remove delayed sources"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "67619123f8820c7bc4e2c886fa4ed53958932c25", "author": {"user": {"login": "Scottmitch", "name": "Scott Mitchell"}}, "url": "https://github.com/apple/servicetalk/commit/67619123f8820c7bc4e2c886fa4ed53958932c25", "committedDate": "2020-04-01T16:05:01Z", "message": "adjust methods and add comments for concurrent queue"}, "afterCommit": {"oid": "b18787edc146525dc2ecadf7ef8c0c6e887d46b2", "author": {"user": {"login": "Scottmitch", "name": "Scott Mitchell"}}, "url": "https://github.com/apple/servicetalk/commit/b18787edc146525dc2ecadf7ef8c0c6e887d46b2", "committedDate": "2020-04-02T03:05:28Z", "message": "add benchmark for NettyPipelinedConnection"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b18787edc146525dc2ecadf7ef8c0c6e887d46b2", "author": {"user": {"login": "Scottmitch", "name": "Scott Mitchell"}}, "url": "https://github.com/apple/servicetalk/commit/b18787edc146525dc2ecadf7ef8c0c6e887d46b2", "committedDate": "2020-04-02T03:05:28Z", "message": "add benchmark for NettyPipelinedConnection"}, "afterCommit": {"oid": "a0d21aaa1121c30ad55e674fe1e4ded9c53e18dc", "author": {"user": {"login": "Scottmitch", "name": "Scott Mitchell"}}, "url": "https://github.com/apple/servicetalk/commit/a0d21aaa1121c30ad55e674fe1e4ded9c53e18dc", "committedDate": "2020-04-07T19:07:42Z", "message": "add benchmark for NettyPipelinedConnection"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a0d21aaa1121c30ad55e674fe1e4ded9c53e18dc", "author": {"user": {"login": "Scottmitch", "name": "Scott Mitchell"}}, "url": "https://github.com/apple/servicetalk/commit/a0d21aaa1121c30ad55e674fe1e4ded9c53e18dc", "committedDate": "2020-04-07T19:07:42Z", "message": "add benchmark for NettyPipelinedConnection"}, "afterCommit": {"oid": "c53de34d09bf4dee72002aecfee5c160062ee1de", "author": {"user": {"login": "Scottmitch", "name": "Scott Mitchell"}}, "url": "https://github.com/apple/servicetalk/commit/c53de34d09bf4dee72002aecfee5c160062ee1de", "committedDate": "2020-04-08T00:00:40Z", "message": "add benchmark for NettyPipelinedConnection"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg5NzQyNzA3", "url": "https://github.com/apple/servicetalk/pull/980#pullrequestreview-389742707", "createdAt": "2020-04-08T08:07:47Z", "commit": {"oid": "c53de34d09bf4dee72002aecfee5c160062ee1de"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwODowNzo0N1rOGCjtYQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wOFQwODoxOToxNFrOGCkIIg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTMzNTM5Mw==", "bodyText": "nit: s/maybe/may be/", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r405335393", "createdAt": "2020-04-08T08:07:47Z", "author": {"login": "normanmaurer"}, "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/MpmcSequentialRunQueue.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n+import javax.annotation.Nullable;\n+\n+import static java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater;\n+\n+/**\n+ * This queue allows for Muli-Producer Multi-Consumer (Mpmc) threading semantics while also invoking the head\n+ * {@link Node}'s {@link Node#run()} in a serial fashion. The {@link Node#run()} will eventually trigger a\n+ * {@link #poll(Node)} (possibly asynchronously on another thread) which will invoke {@link Node#run()} on the next head\n+ * (assuming one exists).\n+ * <p>\n+ * Below is the expected interaction pattern and lifecycle of a Node:\n+ *     <pre>{@link #offer(Node)} -> {@link Node#run()} -> {@link #poll(Node)}</pre>\n+ * <p>\n+ * Although this queue supports Multi-Consumer threading semantics the {@link #poll(Node)} is typically only invoked\n+ * from a single thread (assuming successful runnable completion), it maybe invoked multiple times (potentially from", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c53de34d09bf4dee72002aecfee5c160062ee1de"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTMzNjY0OQ==", "bodyText": "nit: do we need to guard against null ? As otherwise we could end up updating the tail with null and then fail once we try to run node.run() (if node is null). I think at least we should add an assert.", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r405336649", "createdAt": "2020-04-08T08:09:44Z", "author": {"login": "normanmaurer"}, "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/MpmcSequentialRunQueue.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n+import javax.annotation.Nullable;\n+\n+import static java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater;\n+\n+/**\n+ * This queue allows for Muli-Producer Multi-Consumer (Mpmc) threading semantics while also invoking the head\n+ * {@link Node}'s {@link Node#run()} in a serial fashion. The {@link Node#run()} will eventually trigger a\n+ * {@link #poll(Node)} (possibly asynchronously on another thread) which will invoke {@link Node#run()} on the next head\n+ * (assuming one exists).\n+ * <p>\n+ * Below is the expected interaction pattern and lifecycle of a Node:\n+ *     <pre>{@link #offer(Node)} -> {@link Node#run()} -> {@link #poll(Node)}</pre>\n+ * <p>\n+ * Although this queue supports Multi-Consumer threading semantics the {@link #poll(Node)} is typically only invoked\n+ * from a single thread (assuming successful runnable completion), it maybe invoked multiple times (potentially from\n+ * different threads) with the same {@link Node} due to cancellation/failure.\n+ */\n+final class MpmcSequentialRunQueue {\n+    private static final AtomicReferenceFieldUpdater<MpmcSequentialRunQueue, Node>\n+            tailUpdater = newUpdater(MpmcSequentialRunQueue.class, Node.class, \"tail\");\n+\n+    @Nullable\n+    private volatile Node tail;\n+\n+    /**\n+     * Offer {@link Node} to this queue.\n+     * @param node The {@link Node} to append. Must only exclusively be offered to this queue instance.\n+     */\n+    void offer(final Node node) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c53de34d09bf4dee72002aecfee5c160062ee1de"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTMzODkwNQ==", "bodyText": "nit: I think offer is a bit of an odd name for what is happening in this method as it may queue or may run the node. So why not call it execute(...) just as Executor is doing (Which is very similar in terms of behaviour).", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r405338905", "createdAt": "2020-04-08T08:13:35Z", "author": {"login": "normanmaurer"}, "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/MpmcSequentialRunQueue.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n+import javax.annotation.Nullable;\n+\n+import static java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater;\n+\n+/**\n+ * This queue allows for Muli-Producer Multi-Consumer (Mpmc) threading semantics while also invoking the head\n+ * {@link Node}'s {@link Node#run()} in a serial fashion. The {@link Node#run()} will eventually trigger a\n+ * {@link #poll(Node)} (possibly asynchronously on another thread) which will invoke {@link Node#run()} on the next head\n+ * (assuming one exists).\n+ * <p>\n+ * Below is the expected interaction pattern and lifecycle of a Node:\n+ *     <pre>{@link #offer(Node)} -> {@link Node#run()} -> {@link #poll(Node)}</pre>\n+ * <p>\n+ * Although this queue supports Multi-Consumer threading semantics the {@link #poll(Node)} is typically only invoked\n+ * from a single thread (assuming successful runnable completion), it maybe invoked multiple times (potentially from\n+ * different threads) with the same {@link Node} due to cancellation/failure.\n+ */\n+final class MpmcSequentialRunQueue {\n+    private static final AtomicReferenceFieldUpdater<MpmcSequentialRunQueue, Node>\n+            tailUpdater = newUpdater(MpmcSequentialRunQueue.class, Node.class, \"tail\");\n+\n+    @Nullable\n+    private volatile Node tail;\n+\n+    /**\n+     * Offer {@link Node} to this queue.\n+     * @param node The {@link Node} to append. Must only exclusively be offered to this queue instance.\n+     */\n+    void offer(final Node node) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c53de34d09bf4dee72002aecfee5c160062ee1de"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTMzOTcwMQ==", "bodyText": "same as above... I think the method name is a bit odd as it may queue but also may run.", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r405339701", "createdAt": "2020-04-08T08:14:47Z", "author": {"login": "normanmaurer"}, "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/MpmcSequentialRunQueue.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n+import javax.annotation.Nullable;\n+\n+import static java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater;\n+\n+/**\n+ * This queue allows for Muli-Producer Multi-Consumer (Mpmc) threading semantics while also invoking the head\n+ * {@link Node}'s {@link Node#run()} in a serial fashion. The {@link Node#run()} will eventually trigger a\n+ * {@link #poll(Node)} (possibly asynchronously on another thread) which will invoke {@link Node#run()} on the next head\n+ * (assuming one exists).\n+ * <p>\n+ * Below is the expected interaction pattern and lifecycle of a Node:\n+ *     <pre>{@link #offer(Node)} -> {@link Node#run()} -> {@link #poll(Node)}</pre>\n+ * <p>\n+ * Although this queue supports Multi-Consumer threading semantics the {@link #poll(Node)} is typically only invoked\n+ * from a single thread (assuming successful runnable completion), it maybe invoked multiple times (potentially from\n+ * different threads) with the same {@link Node} due to cancellation/failure.\n+ */\n+final class MpmcSequentialRunQueue {\n+    private static final AtomicReferenceFieldUpdater<MpmcSequentialRunQueue, Node>\n+            tailUpdater = newUpdater(MpmcSequentialRunQueue.class, Node.class, \"tail\");\n+\n+    @Nullable\n+    private volatile Node tail;\n+\n+    /**\n+     * Offer {@link Node} to this queue.\n+     * @param node The {@link Node} to append. Must only exclusively be offered to this queue instance.\n+     */\n+    void offer(final Node node) {\n+        for (;;) {\n+            final Node currentTail = this.tail;\n+            if (currentTail == null) {\n+                if (tailUpdater.compareAndSet(this, null, node)) {\n+                    // node has been inserted and is the only node, we initiate processing.\n+                    node.run();\n+                    break;\n+                }\n+                // Another thread won the race to offer a node, loop around and try again.\n+            } else if (currentTail.append(node)) {\n+                // Make the newly appended node visible as the tail. This is a best effort CAS and may fail because:\n+                // 1. Another thread is also inserting, has a stale tail, followed its existing tail links, and updated\n+                // the tail reference via offerPatchTail.\n+                // 2. The consumer thread has seen the link from the old tail to the new node, processed node,\n+                // popped node from the list (updated node's next to point to EMPTY_NODE), another producer thread\n+                // appends a new node, sees the tail is popped, and updates the tail reference via CAS.\n+                tailUpdater.compareAndSet(this, currentTail, node);\n+                break;\n+            } else if (currentTail.isPopped()) {\n+                // A previously appended node was processed, and popped before updating the tail after append. In that\n+                // case the tail maybe pointing to an invalid node and we clear it out.\n+                if (tailUpdater.compareAndSet(this, currentTail, node)) {\n+                    node.run();\n+                    break;\n+                }\n+                // Best effort to clear the tail, and failure is OK because:\n+                // 1. Another thread is in offer and already patched up the tail pointer and we will read the new tail\n+                // on the next loop iteration.\n+            } else {\n+                // We failed to append to currentTail's next pointer, which means currentTail isn't the tail, and\n+                // currentTail hasn't been popped. This means the tail pointer is stale, so we re-read the reference\n+                // to see if it changed, and if not attempt to walk the list and update the tail pointer.\n+                final Node newTail = this.tail;\n+                if (newTail == currentTail && offerUpdateStaleTail(node, currentTail)) {\n+                    break;\n+                }\n+            }\n+        }\n+    }\n+\n+    private boolean offerUpdateStaleTail(final Node node, final Node oldTail) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c53de34d09bf4dee72002aecfee5c160062ee1de"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTMzOTg2MA==", "bodyText": "same comment with the method name.", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r405339860", "createdAt": "2020-04-08T08:15:04Z", "author": {"login": "normanmaurer"}, "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/MpmcSequentialRunQueue.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n+import javax.annotation.Nullable;\n+\n+import static java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater;\n+\n+/**\n+ * This queue allows for Muli-Producer Multi-Consumer (Mpmc) threading semantics while also invoking the head\n+ * {@link Node}'s {@link Node#run()} in a serial fashion. The {@link Node#run()} will eventually trigger a\n+ * {@link #poll(Node)} (possibly asynchronously on another thread) which will invoke {@link Node#run()} on the next head\n+ * (assuming one exists).\n+ * <p>\n+ * Below is the expected interaction pattern and lifecycle of a Node:\n+ *     <pre>{@link #offer(Node)} -> {@link Node#run()} -> {@link #poll(Node)}</pre>\n+ * <p>\n+ * Although this queue supports Multi-Consumer threading semantics the {@link #poll(Node)} is typically only invoked\n+ * from a single thread (assuming successful runnable completion), it maybe invoked multiple times (potentially from\n+ * different threads) with the same {@link Node} due to cancellation/failure.\n+ */\n+final class MpmcSequentialRunQueue {\n+    private static final AtomicReferenceFieldUpdater<MpmcSequentialRunQueue, Node>\n+            tailUpdater = newUpdater(MpmcSequentialRunQueue.class, Node.class, \"tail\");\n+\n+    @Nullable\n+    private volatile Node tail;\n+\n+    /**\n+     * Offer {@link Node} to this queue.\n+     * @param node The {@link Node} to append. Must only exclusively be offered to this queue instance.\n+     */\n+    void offer(final Node node) {\n+        for (;;) {\n+            final Node currentTail = this.tail;\n+            if (currentTail == null) {\n+                if (tailUpdater.compareAndSet(this, null, node)) {\n+                    // node has been inserted and is the only node, we initiate processing.\n+                    node.run();\n+                    break;\n+                }\n+                // Another thread won the race to offer a node, loop around and try again.\n+            } else if (currentTail.append(node)) {\n+                // Make the newly appended node visible as the tail. This is a best effort CAS and may fail because:\n+                // 1. Another thread is also inserting, has a stale tail, followed its existing tail links, and updated\n+                // the tail reference via offerPatchTail.\n+                // 2. The consumer thread has seen the link from the old tail to the new node, processed node,\n+                // popped node from the list (updated node's next to point to EMPTY_NODE), another producer thread\n+                // appends a new node, sees the tail is popped, and updates the tail reference via CAS.\n+                tailUpdater.compareAndSet(this, currentTail, node);\n+                break;\n+            } else if (currentTail.isPopped()) {\n+                // A previously appended node was processed, and popped before updating the tail after append. In that\n+                // case the tail maybe pointing to an invalid node and we clear it out.\n+                if (tailUpdater.compareAndSet(this, currentTail, node)) {\n+                    node.run();\n+                    break;\n+                }\n+                // Best effort to clear the tail, and failure is OK because:\n+                // 1. Another thread is in offer and already patched up the tail pointer and we will read the new tail\n+                // on the next loop iteration.\n+            } else {\n+                // We failed to append to currentTail's next pointer, which means currentTail isn't the tail, and\n+                // currentTail hasn't been popped. This means the tail pointer is stale, so we re-read the reference\n+                // to see if it changed, and if not attempt to walk the list and update the tail pointer.\n+                final Node newTail = this.tail;\n+                if (newTail == currentTail && offerUpdateStaleTail(node, currentTail)) {\n+                    break;\n+                }\n+            }\n+        }\n+    }\n+\n+    private boolean offerUpdateStaleTail(final Node node, final Node oldTail) {\n+        // tail is stale so attempt to iterate through the linked list and get the current tail reference.\n+        Node currentTail = oldTail.iterateToTail();\n+\n+        // Best effort check to see if the node is popped, then we attempt to directly insert node.\n+        if (currentTail.isPopped()) {\n+            if (tailUpdater.compareAndSet(this, oldTail, node)) {\n+                node.run();\n+                return true;\n+            }\n+        } else {\n+            // It is possible the currentTail has been popped after our best-effort check above. That is OK because\n+            // the offer method accounts for stale tail replacement.\n+            tailUpdater.compareAndSet(this, oldTail, currentTail);\n+        }\n+        // Best effort to update/clear the tail, and failure is OK because:\n+        // 1. Another thread is in offer and already patched up the tail pointer and we will read the new\n+        // tail on the next loop iteration.\n+        return false;\n+    }\n+\n+    /**\n+     * Pop {@code node} from this queue. This will invoke {@link Node#run()} on the next head of the queue\n+     * (if one exists).\n+     * <p>\n+     * Typically invoked by a single thread but maybe invoked by multiple threads, and maybe invoked multiple times.\n+     * Re-entry from {@link Node#run()} from another thread is permitted.\n+     * @param head A {@link Node} which has been passed to {@link #offer(Node)}, and whose {@link Node#run()} has been\n+     * invoked by this queue.\n+     */\n+    void poll(final Node head) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c53de34d09bf4dee72002aecfee5c160062ee1de"}, "originalPosition": 118}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTM0MDA3Mg==", "bodyText": "nit: {@code head}.", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r405340072", "createdAt": "2020-04-08T08:15:29Z", "author": {"login": "normanmaurer"}, "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/MpmcSequentialRunQueue.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n+import javax.annotation.Nullable;\n+\n+import static java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater;\n+\n+/**\n+ * This queue allows for Muli-Producer Multi-Consumer (Mpmc) threading semantics while also invoking the head\n+ * {@link Node}'s {@link Node#run()} in a serial fashion. The {@link Node#run()} will eventually trigger a\n+ * {@link #poll(Node)} (possibly asynchronously on another thread) which will invoke {@link Node#run()} on the next head\n+ * (assuming one exists).\n+ * <p>\n+ * Below is the expected interaction pattern and lifecycle of a Node:\n+ *     <pre>{@link #offer(Node)} -> {@link Node#run()} -> {@link #poll(Node)}</pre>\n+ * <p>\n+ * Although this queue supports Multi-Consumer threading semantics the {@link #poll(Node)} is typically only invoked\n+ * from a single thread (assuming successful runnable completion), it maybe invoked multiple times (potentially from\n+ * different threads) with the same {@link Node} due to cancellation/failure.\n+ */\n+final class MpmcSequentialRunQueue {\n+    private static final AtomicReferenceFieldUpdater<MpmcSequentialRunQueue, Node>\n+            tailUpdater = newUpdater(MpmcSequentialRunQueue.class, Node.class, \"tail\");\n+\n+    @Nullable\n+    private volatile Node tail;\n+\n+    /**\n+     * Offer {@link Node} to this queue.\n+     * @param node The {@link Node} to append. Must only exclusively be offered to this queue instance.\n+     */\n+    void offer(final Node node) {\n+        for (;;) {\n+            final Node currentTail = this.tail;\n+            if (currentTail == null) {\n+                if (tailUpdater.compareAndSet(this, null, node)) {\n+                    // node has been inserted and is the only node, we initiate processing.\n+                    node.run();\n+                    break;\n+                }\n+                // Another thread won the race to offer a node, loop around and try again.\n+            } else if (currentTail.append(node)) {\n+                // Make the newly appended node visible as the tail. This is a best effort CAS and may fail because:\n+                // 1. Another thread is also inserting, has a stale tail, followed its existing tail links, and updated\n+                // the tail reference via offerPatchTail.\n+                // 2. The consumer thread has seen the link from the old tail to the new node, processed node,\n+                // popped node from the list (updated node's next to point to EMPTY_NODE), another producer thread\n+                // appends a new node, sees the tail is popped, and updates the tail reference via CAS.\n+                tailUpdater.compareAndSet(this, currentTail, node);\n+                break;\n+            } else if (currentTail.isPopped()) {\n+                // A previously appended node was processed, and popped before updating the tail after append. In that\n+                // case the tail maybe pointing to an invalid node and we clear it out.\n+                if (tailUpdater.compareAndSet(this, currentTail, node)) {\n+                    node.run();\n+                    break;\n+                }\n+                // Best effort to clear the tail, and failure is OK because:\n+                // 1. Another thread is in offer and already patched up the tail pointer and we will read the new tail\n+                // on the next loop iteration.\n+            } else {\n+                // We failed to append to currentTail's next pointer, which means currentTail isn't the tail, and\n+                // currentTail hasn't been popped. This means the tail pointer is stale, so we re-read the reference\n+                // to see if it changed, and if not attempt to walk the list and update the tail pointer.\n+                final Node newTail = this.tail;\n+                if (newTail == currentTail && offerUpdateStaleTail(node, currentTail)) {\n+                    break;\n+                }\n+            }\n+        }\n+    }\n+\n+    private boolean offerUpdateStaleTail(final Node node, final Node oldTail) {\n+        // tail is stale so attempt to iterate through the linked list and get the current tail reference.\n+        Node currentTail = oldTail.iterateToTail();\n+\n+        // Best effort check to see if the node is popped, then we attempt to directly insert node.\n+        if (currentTail.isPopped()) {\n+            if (tailUpdater.compareAndSet(this, oldTail, node)) {\n+                node.run();\n+                return true;\n+            }\n+        } else {\n+            // It is possible the currentTail has been popped after our best-effort check above. That is OK because\n+            // the offer method accounts for stale tail replacement.\n+            tailUpdater.compareAndSet(this, oldTail, currentTail);\n+        }\n+        // Best effort to update/clear the tail, and failure is OK because:\n+        // 1. Another thread is in offer and already patched up the tail pointer and we will read the new\n+        // tail on the next loop iteration.\n+        return false;\n+    }\n+\n+    /**\n+     * Pop {@code node} from this queue. This will invoke {@link Node#run()} on the next head of the queue", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c53de34d09bf4dee72002aecfee5c160062ee1de"}, "originalPosition": 110}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTM0MDc3OA==", "bodyText": "nit: you could just have Node extend AtomicReference<Node> and remove the whole updater dance. This will also remove some overhead in terms of access checks.", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r405340778", "createdAt": "2020-04-08T08:16:44Z", "author": {"login": "normanmaurer"}, "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/MpmcSequentialRunQueue.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n+import javax.annotation.Nullable;\n+\n+import static java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater;\n+\n+/**\n+ * This queue allows for Muli-Producer Multi-Consumer (Mpmc) threading semantics while also invoking the head\n+ * {@link Node}'s {@link Node#run()} in a serial fashion. The {@link Node#run()} will eventually trigger a\n+ * {@link #poll(Node)} (possibly asynchronously on another thread) which will invoke {@link Node#run()} on the next head\n+ * (assuming one exists).\n+ * <p>\n+ * Below is the expected interaction pattern and lifecycle of a Node:\n+ *     <pre>{@link #offer(Node)} -> {@link Node#run()} -> {@link #poll(Node)}</pre>\n+ * <p>\n+ * Although this queue supports Multi-Consumer threading semantics the {@link #poll(Node)} is typically only invoked\n+ * from a single thread (assuming successful runnable completion), it maybe invoked multiple times (potentially from\n+ * different threads) with the same {@link Node} due to cancellation/failure.\n+ */\n+final class MpmcSequentialRunQueue {\n+    private static final AtomicReferenceFieldUpdater<MpmcSequentialRunQueue, Node>\n+            tailUpdater = newUpdater(MpmcSequentialRunQueue.class, Node.class, \"tail\");\n+\n+    @Nullable\n+    private volatile Node tail;\n+\n+    /**\n+     * Offer {@link Node} to this queue.\n+     * @param node The {@link Node} to append. Must only exclusively be offered to this queue instance.\n+     */\n+    void offer(final Node node) {\n+        for (;;) {\n+            final Node currentTail = this.tail;\n+            if (currentTail == null) {\n+                if (tailUpdater.compareAndSet(this, null, node)) {\n+                    // node has been inserted and is the only node, we initiate processing.\n+                    node.run();\n+                    break;\n+                }\n+                // Another thread won the race to offer a node, loop around and try again.\n+            } else if (currentTail.append(node)) {\n+                // Make the newly appended node visible as the tail. This is a best effort CAS and may fail because:\n+                // 1. Another thread is also inserting, has a stale tail, followed its existing tail links, and updated\n+                // the tail reference via offerPatchTail.\n+                // 2. The consumer thread has seen the link from the old tail to the new node, processed node,\n+                // popped node from the list (updated node's next to point to EMPTY_NODE), another producer thread\n+                // appends a new node, sees the tail is popped, and updates the tail reference via CAS.\n+                tailUpdater.compareAndSet(this, currentTail, node);\n+                break;\n+            } else if (currentTail.isPopped()) {\n+                // A previously appended node was processed, and popped before updating the tail after append. In that\n+                // case the tail maybe pointing to an invalid node and we clear it out.\n+                if (tailUpdater.compareAndSet(this, currentTail, node)) {\n+                    node.run();\n+                    break;\n+                }\n+                // Best effort to clear the tail, and failure is OK because:\n+                // 1. Another thread is in offer and already patched up the tail pointer and we will read the new tail\n+                // on the next loop iteration.\n+            } else {\n+                // We failed to append to currentTail's next pointer, which means currentTail isn't the tail, and\n+                // currentTail hasn't been popped. This means the tail pointer is stale, so we re-read the reference\n+                // to see if it changed, and if not attempt to walk the list and update the tail pointer.\n+                final Node newTail = this.tail;\n+                if (newTail == currentTail && offerUpdateStaleTail(node, currentTail)) {\n+                    break;\n+                }\n+            }\n+        }\n+    }\n+\n+    private boolean offerUpdateStaleTail(final Node node, final Node oldTail) {\n+        // tail is stale so attempt to iterate through the linked list and get the current tail reference.\n+        Node currentTail = oldTail.iterateToTail();\n+\n+        // Best effort check to see if the node is popped, then we attempt to directly insert node.\n+        if (currentTail.isPopped()) {\n+            if (tailUpdater.compareAndSet(this, oldTail, node)) {\n+                node.run();\n+                return true;\n+            }\n+        } else {\n+            // It is possible the currentTail has been popped after our best-effort check above. That is OK because\n+            // the offer method accounts for stale tail replacement.\n+            tailUpdater.compareAndSet(this, oldTail, currentTail);\n+        }\n+        // Best effort to update/clear the tail, and failure is OK because:\n+        // 1. Another thread is in offer and already patched up the tail pointer and we will read the new\n+        // tail on the next loop iteration.\n+        return false;\n+    }\n+\n+    /**\n+     * Pop {@code node} from this queue. This will invoke {@link Node#run()} on the next head of the queue\n+     * (if one exists).\n+     * <p>\n+     * Typically invoked by a single thread but maybe invoked by multiple threads, and maybe invoked multiple times.\n+     * Re-entry from {@link Node#run()} from another thread is permitted.\n+     * @param head A {@link Node} which has been passed to {@link #offer(Node)}, and whose {@link Node#run()} has been\n+     * invoked by this queue.\n+     */\n+    void poll(final Node head) {\n+        // This method maybe called multiple times on the same node, in which case next will be EMPTY_NODE and the run\n+        // method will be a noop.\n+        Node next = head.pop();\n+        if (next != null) {\n+            next.run();\n+        } else {\n+            tailUpdater.compareAndSet(this, head, null);\n+            // Best effort to clear the tail, and failure is OK because:\n+            // 1. Another thread appended this head, but has not yet updated the tail. In this case the tail will be\n+            // stale (e.g. pointing to head node that has already been processed) and corrected by future inserts.\n+        }\n+    }\n+\n+    /**\n+     * Single linked node in the queue.\n+     * <p>\n+     * Instances are single use only! No re-use or sharing between queue instances!\n+     */\n+    abstract static class Node {\n+        /**\n+         * the EMPTY_NODE's next must point to itself so that attempts to {@link #append(Node)} on it will fail,\n+         * and also be detected as {@link #isPopped()} and not prevent any new nodes from being\n+         * {@link #offer(Node) offered}.\n+         */\n+        private static final Node EMPTY_NODE = new Node(false) {\n+            @Override\n+            void run() {\n+            }\n+        };\n+        private static final AtomicReferenceFieldUpdater<Node, Node> nextUpdater =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c53de34d09bf4dee72002aecfee5c160062ee1de"}, "originalPosition": 148}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTM0MjI0Mg==", "bodyText": "nit: getClass.getSimpleName()", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r405342242", "createdAt": "2020-04-08T08:19:14Z", "author": {"login": "normanmaurer"}, "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,378 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.CompletableSource;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.PublisherSource.Subscriber;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.CompletableOperator;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.PublisherOperator;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.http.netty.MpmcSequentialRunQueue.Node;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimators;\n+\n+import io.netty.channel.Channel;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static io.servicetalk.concurrent.internal.SubscriberUtils.deliverTerminalFromSource;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    private final NettyConnection<Resp, Req> connection;\n+    private final MpmcSequentialRunQueue writeQueue;\n+    private final MpmcSequentialRunQueue readQueue;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+        writeQueue = new MpmcSequentialRunQueue();\n+        readQueue = new MpmcSequentialRunQueue();\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher) {\n+        return write(requestPublisher, connection::defaultFlushStrategy, WriteDemandEstimators::newDefaultEstimator);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+        return new Publisher<Resp>() {\n+            @Override\n+            protected void handleSubscribe(final Subscriber<? super Resp> subscriber) {\n+                final WriteNode node;\n+                try {\n+                    node = new WriteNode(subscriber, requestPublisher, flushStrategySupplier,\n+                            writeDemandEstimatorSupplier);\n+                } catch (Throwable cause) {\n+                    deliverTerminalFromSource(subscriber, cause);\n+                    return;\n+                }\n+\n+                try {\n+                    writeQueue.offer(node);\n+                } catch (Throwable cause) {\n+                    // The queue offer is not expected to throw, but if it does we cannot poll the WriteNode to recover.\n+                    // It is only safe to poll from the queue from Node#run() (or after it executes), so close.\n+                    closeConnection(subscriber, cause);\n+                }\n+            }\n+        };\n+    }\n+\n+    @Override\n+    public SocketAddress localAddress() {\n+        return connection.localAddress();\n+    }\n+\n+    @Override\n+    public SocketAddress remoteAddress() {\n+        return connection.remoteAddress();\n+    }\n+\n+    @Override\n+    @Nullable\n+    public SSLSession sslSession() {\n+        return connection.sslSession();\n+    }\n+\n+    @Override\n+    public ExecutionContext executionContext() {\n+        return connection.executionContext();\n+    }\n+\n+    @Nullable\n+    @Override\n+    public <T> T socketOption(final SocketOption<T> option) {\n+        return connection.socketOption(option);\n+    }\n+\n+    @Override\n+    public Protocol protocol() {\n+        return connection.protocol();\n+    }\n+\n+    @Override\n+    public Single<Throwable> transportError() {\n+        return connection.transportError();\n+    }\n+\n+    @Override\n+    public Completable onClosing() {\n+        return connection.onClosing();\n+    }\n+\n+    @Override\n+    public Completable onClose() {\n+        return connection.onClose();\n+    }\n+\n+    @Override\n+    public Completable closeAsync() {\n+        return connection.closeAsync();\n+    }\n+\n+    @Override\n+    public Completable closeAsyncGracefully() {\n+        return connection.closeAsyncGracefully();\n+    }\n+\n+    @Override\n+    public Channel nettyChannel() {\n+        return connection.nettyChannel();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return getClass().getName() + '(' + connection + ')';", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c53de34d09bf4dee72002aecfee5c160062ee1de"}, "originalPosition": 180}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg0NDAxNDc0", "url": "https://github.com/apple/servicetalk/pull/980#pullrequestreview-384401474", "createdAt": "2020-03-31T04:54:28Z", "commit": {"oid": "5572e4898545e9e1288da4b74223b157cee00cbb"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQwNjoxMzo0NFrOGBJDyA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMlQwNjo0NDo0MlrOGESxLA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzg1MDE4NA==", "bodyText": "ok connection::defaultFlushStrategy returns the last updated strategy, nevermind.", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r403850184", "createdAt": "2020-04-06T06:13:44Z", "author": {"login": "NiteshKant"}, "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/PipelinedStreamingHttpConnection.java", "diffHunk": "@@ -19,38 +19,35 @@\n import io.servicetalk.concurrent.api.Publisher;\n import io.servicetalk.http.api.HttpExecutionContext;\n import io.servicetalk.http.api.StreamingHttpRequestResponseFactory;\n-import io.servicetalk.transport.netty.internal.DefaultNettyPipelinedConnection;\n import io.servicetalk.transport.netty.internal.FlushStrategy;\n import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimators;\n \n import javax.annotation.Nullable;\n \n final class PipelinedStreamingHttpConnection\n-        extends AbstractStreamingHttpConnection<DefaultNettyPipelinedConnection<Object, Object>> {\n-\n-    private final NettyConnection<Object, Object> nettyConnection;\n-\n+        extends AbstractStreamingHttpConnection<NettyPipelinedConnection<Object, Object>> {\n     PipelinedStreamingHttpConnection(final NettyConnection<Object, Object> connection,\n                                      final H1ProtocolConfig config,\n                                      final HttpExecutionContext executionContext,\n                                      final StreamingHttpRequestResponseFactory reqRespFactory) {\n-        super(new DefaultNettyPipelinedConnection<>(connection, config.maxPipelinedRequests()),\n+        super(new NettyPipelinedConnection<>(connection),\n                 config.maxPipelinedRequests(), executionContext, reqRespFactory, config.headersFactory());\n-        this.nettyConnection = connection;\n     }\n \n     @Override\n     protected Publisher<Object> writeAndRead(Publisher<Object> requestStream,\n                                              @Nullable final FlushStrategy flushStrategy) {\n         if (flushStrategy == null) {\n-            return connection.request(requestStream);\n+            return connection.write(requestStream, connection::defaultFlushStrategy,\n+                    WriteDemandEstimators::newDefaultEstimator);\n         } else {\n-            // Using the Writer abstraction here defers updating the flush strategy until just before this request is\n-            // written.\n-            return connection.request(() -> {\n+            // TODO(scott): if we can remove the flush state on the connection we can simplify the control flow here.\n+            return Publisher.defer(() -> {\n                 final Cancellable resetFlushStrategy = connection.updateFlushStrategy(\n                         (prev, isOriginal) -> isOriginal ? flushStrategy : prev);\n-                return nettyConnection.write(requestStream).afterFinally(resetFlushStrategy::cancel);\n+                return connection.write(requestStream, connection::defaultFlushStrategy,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NzU0OTQ4MA=="}, "originalCommit": {"oid": "7469332830d536d9dc82b82bad56e4860a3caf7e"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzg1MDc4OQ==", "bodyText": "There is a code-path in this method which may make this method throw; if onSubcribe() throws and then a subsequent call to onError() also throws. In which case we will not call writeQueue.poll() below", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r403850789", "createdAt": "2020-04-06T06:15:30Z", "author": {"login": "NiteshKant"}, "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,378 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.CompletableSource;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.PublisherSource.Subscriber;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.CompletableOperator;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.PublisherOperator;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.http.netty.MpmcSequentialRunQueue.Node;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimators;\n+\n+import io.netty.channel.Channel;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static io.servicetalk.concurrent.internal.SubscriberUtils.deliverTerminalFromSource;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    private final NettyConnection<Resp, Req> connection;\n+    private final MpmcSequentialRunQueue writeQueue;\n+    private final MpmcSequentialRunQueue readQueue;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+        writeQueue = new MpmcSequentialRunQueue();\n+        readQueue = new MpmcSequentialRunQueue();\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher) {\n+        return write(requestPublisher, connection::defaultFlushStrategy, WriteDemandEstimators::newDefaultEstimator);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+        return new Publisher<Resp>() {\n+            @Override\n+            protected void handleSubscribe(final Subscriber<? super Resp> subscriber) {\n+                final WriteNode node;\n+                try {\n+                    node = new WriteNode(subscriber, requestPublisher, flushStrategySupplier,\n+                            writeDemandEstimatorSupplier);\n+                } catch (Throwable cause) {\n+                    deliverTerminalFromSource(subscriber, cause);\n+                    return;\n+                }\n+\n+                try {\n+                    writeQueue.offer(node);\n+                } catch (Throwable cause) {\n+                    // The queue offer is not expected to throw, but if it does we cannot poll the WriteNode to recover.\n+                    // It is only safe to poll from the queue from Node#run() (or after it executes), so close.\n+                    closeConnection(subscriber, cause);\n+                }\n+            }\n+        };\n+    }\n+\n+    @Override\n+    public SocketAddress localAddress() {\n+        return connection.localAddress();\n+    }\n+\n+    @Override\n+    public SocketAddress remoteAddress() {\n+        return connection.remoteAddress();\n+    }\n+\n+    @Override\n+    @Nullable\n+    public SSLSession sslSession() {\n+        return connection.sslSession();\n+    }\n+\n+    @Override\n+    public ExecutionContext executionContext() {\n+        return connection.executionContext();\n+    }\n+\n+    @Nullable\n+    @Override\n+    public <T> T socketOption(final SocketOption<T> option) {\n+        return connection.socketOption(option);\n+    }\n+\n+    @Override\n+    public Protocol protocol() {\n+        return connection.protocol();\n+    }\n+\n+    @Override\n+    public Single<Throwable> transportError() {\n+        return connection.transportError();\n+    }\n+\n+    @Override\n+    public Completable onClosing() {\n+        return connection.onClosing();\n+    }\n+\n+    @Override\n+    public Completable onClose() {\n+        return connection.onClose();\n+    }\n+\n+    @Override\n+    public Completable closeAsync() {\n+        return connection.closeAsync();\n+    }\n+\n+    @Override\n+    public Completable closeAsyncGracefully() {\n+        return connection.closeAsyncGracefully();\n+    }\n+\n+    @Override\n+    public Channel nettyChannel() {\n+        return connection.nettyChannel();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return getClass().getName() + '(' + connection + ')';\n+    }\n+\n+    @Override\n+    public Cancellable updateFlushStrategy(final NettyConnectionContext.FlushStrategyProvider strategyProvider) {\n+        return connection.updateFlushStrategy(strategyProvider);\n+    }\n+\n+    @Override\n+    public FlushStrategy defaultFlushStrategy() {\n+        return connection.defaultFlushStrategy();\n+    }\n+\n+    private void closeConnection(final Subscriber<? super Resp> subscriber, final Throwable cause) {\n+        toSource(connection.closeAsync().concat(Publisher.<Resp>failed(cause))).subscribe(subscriber);\n+    }\n+\n+    private final class WriteNode extends Node {\n+        private final Subscriber<? super Resp> subscriber;\n+        private final Publisher<Req> requestPublisher;\n+        private final Supplier<FlushStrategy> flushStrategySupplier;\n+        private final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier;\n+\n+        private WriteNode(final Subscriber<? super Resp> subscriber,\n+                          final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+            this.subscriber = subscriber;\n+            this.requestPublisher = requestPublisher;\n+            this.flushStrategySupplier = flushStrategySupplier;\n+            this.writeDemandEstimatorSupplier = writeDemandEstimatorSupplier;\n+        }\n+\n+        @Override\n+        void run() {\n+            final PublisherSource<Resp> src;\n+            try {\n+                src = toSource(connection.write(requestPublisher, flushStrategySupplier, writeDemandEstimatorSupplier)\n+                        .liftSync(new WritePopNextOperator(this))\n+                        .merge(new Publisher<Resp>() {\n+                            @Override\n+                            protected void handleSubscribe(final Subscriber<? super Resp> rSubscriber) {\n+                                try {\n+                                    readQueue.offer(new ReadNode(rSubscriber));\n+                                } catch (Throwable cause) {\n+                                    // We started the write, but failed to setup the read. This is considered fatal as\n+                                    // we will be out of sync for delivering future read responses.\n+                                    closeConnection(rSubscriber, cause);\n+                                }\n+                            }\n+                        }));\n+            } catch (Throwable cause) {\n+                // We failed to setup the write operation, which means we also failed to setup the read operation.\n+                // This failure maybe recoverable as our internal state isn't corrupted, so just propagate the error.\n+                deliverTerminalFromSource(subscriber, cause);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b18787edc146525dc2ecadf7ef8c0c6e887d46b2"}, "originalPosition": 234}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzg1Mjc1Ng==", "bodyText": "It is arguable whether the internal state is corrupter or not since connection.write() may have thrown. Avoiding to assume implementation of connection.write() and just closing connection may just be a safer option here.", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r403852756", "createdAt": "2020-04-06T06:21:24Z", "author": {"login": "NiteshKant"}, "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,378 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.CompletableSource;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.PublisherSource.Subscriber;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.CompletableOperator;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.PublisherOperator;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.http.netty.MpmcSequentialRunQueue.Node;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimators;\n+\n+import io.netty.channel.Channel;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static io.servicetalk.concurrent.internal.SubscriberUtils.deliverTerminalFromSource;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    private final NettyConnection<Resp, Req> connection;\n+    private final MpmcSequentialRunQueue writeQueue;\n+    private final MpmcSequentialRunQueue readQueue;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+        writeQueue = new MpmcSequentialRunQueue();\n+        readQueue = new MpmcSequentialRunQueue();\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher) {\n+        return write(requestPublisher, connection::defaultFlushStrategy, WriteDemandEstimators::newDefaultEstimator);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+        return new Publisher<Resp>() {\n+            @Override\n+            protected void handleSubscribe(final Subscriber<? super Resp> subscriber) {\n+                final WriteNode node;\n+                try {\n+                    node = new WriteNode(subscriber, requestPublisher, flushStrategySupplier,\n+                            writeDemandEstimatorSupplier);\n+                } catch (Throwable cause) {\n+                    deliverTerminalFromSource(subscriber, cause);\n+                    return;\n+                }\n+\n+                try {\n+                    writeQueue.offer(node);\n+                } catch (Throwable cause) {\n+                    // The queue offer is not expected to throw, but if it does we cannot poll the WriteNode to recover.\n+                    // It is only safe to poll from the queue from Node#run() (or after it executes), so close.\n+                    closeConnection(subscriber, cause);\n+                }\n+            }\n+        };\n+    }\n+\n+    @Override\n+    public SocketAddress localAddress() {\n+        return connection.localAddress();\n+    }\n+\n+    @Override\n+    public SocketAddress remoteAddress() {\n+        return connection.remoteAddress();\n+    }\n+\n+    @Override\n+    @Nullable\n+    public SSLSession sslSession() {\n+        return connection.sslSession();\n+    }\n+\n+    @Override\n+    public ExecutionContext executionContext() {\n+        return connection.executionContext();\n+    }\n+\n+    @Nullable\n+    @Override\n+    public <T> T socketOption(final SocketOption<T> option) {\n+        return connection.socketOption(option);\n+    }\n+\n+    @Override\n+    public Protocol protocol() {\n+        return connection.protocol();\n+    }\n+\n+    @Override\n+    public Single<Throwable> transportError() {\n+        return connection.transportError();\n+    }\n+\n+    @Override\n+    public Completable onClosing() {\n+        return connection.onClosing();\n+    }\n+\n+    @Override\n+    public Completable onClose() {\n+        return connection.onClose();\n+    }\n+\n+    @Override\n+    public Completable closeAsync() {\n+        return connection.closeAsync();\n+    }\n+\n+    @Override\n+    public Completable closeAsyncGracefully() {\n+        return connection.closeAsyncGracefully();\n+    }\n+\n+    @Override\n+    public Channel nettyChannel() {\n+        return connection.nettyChannel();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return getClass().getName() + '(' + connection + ')';\n+    }\n+\n+    @Override\n+    public Cancellable updateFlushStrategy(final NettyConnectionContext.FlushStrategyProvider strategyProvider) {\n+        return connection.updateFlushStrategy(strategyProvider);\n+    }\n+\n+    @Override\n+    public FlushStrategy defaultFlushStrategy() {\n+        return connection.defaultFlushStrategy();\n+    }\n+\n+    private void closeConnection(final Subscriber<? super Resp> subscriber, final Throwable cause) {\n+        toSource(connection.closeAsync().concat(Publisher.<Resp>failed(cause))).subscribe(subscriber);\n+    }\n+\n+    private final class WriteNode extends Node {\n+        private final Subscriber<? super Resp> subscriber;\n+        private final Publisher<Req> requestPublisher;\n+        private final Supplier<FlushStrategy> flushStrategySupplier;\n+        private final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier;\n+\n+        private WriteNode(final Subscriber<? super Resp> subscriber,\n+                          final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+            this.subscriber = subscriber;\n+            this.requestPublisher = requestPublisher;\n+            this.flushStrategySupplier = flushStrategySupplier;\n+            this.writeDemandEstimatorSupplier = writeDemandEstimatorSupplier;\n+        }\n+\n+        @Override\n+        void run() {\n+            final PublisherSource<Resp> src;\n+            try {\n+                src = toSource(connection.write(requestPublisher, flushStrategySupplier, writeDemandEstimatorSupplier)\n+                        .liftSync(new WritePopNextOperator(this))\n+                        .merge(new Publisher<Resp>() {\n+                            @Override\n+                            protected void handleSubscribe(final Subscriber<? super Resp> rSubscriber) {\n+                                try {\n+                                    readQueue.offer(new ReadNode(rSubscriber));\n+                                } catch (Throwable cause) {\n+                                    // We started the write, but failed to setup the read. This is considered fatal as\n+                                    // we will be out of sync for delivering future read responses.\n+                                    closeConnection(rSubscriber, cause);\n+                                }\n+                            }\n+                        }));\n+            } catch (Throwable cause) {\n+                // We failed to setup the write operation, which means we also failed to setup the read operation.\n+                // This failure maybe recoverable as our internal state isn't corrupted, so just propagate the error.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b18787edc146525dc2ecadf7ef8c0c6e887d46b2"}, "originalPosition": 233}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzg1NDgyNw==", "bodyText": "Hypothetically speaking if offer() threw after adding the node but without starting the write, this will basically mean that all subsequent writes will keep accumulating in the queue and will never be run as the Queue is technically having a node that has not completed write?", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r403854827", "createdAt": "2020-04-06T06:27:31Z", "author": {"login": "NiteshKant"}, "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,378 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.CompletableSource;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.PublisherSource.Subscriber;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.CompletableOperator;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.PublisherOperator;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.http.netty.MpmcSequentialRunQueue.Node;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimators;\n+\n+import io.netty.channel.Channel;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static io.servicetalk.concurrent.internal.SubscriberUtils.deliverTerminalFromSource;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    private final NettyConnection<Resp, Req> connection;\n+    private final MpmcSequentialRunQueue writeQueue;\n+    private final MpmcSequentialRunQueue readQueue;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+        writeQueue = new MpmcSequentialRunQueue();\n+        readQueue = new MpmcSequentialRunQueue();\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher) {\n+        return write(requestPublisher, connection::defaultFlushStrategy, WriteDemandEstimators::newDefaultEstimator);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+        return new Publisher<Resp>() {\n+            @Override\n+            protected void handleSubscribe(final Subscriber<? super Resp> subscriber) {\n+                final WriteNode node;\n+                try {\n+                    node = new WriteNode(subscriber, requestPublisher, flushStrategySupplier,\n+                            writeDemandEstimatorSupplier);\n+                } catch (Throwable cause) {\n+                    deliverTerminalFromSource(subscriber, cause);\n+                    return;\n+                }\n+\n+                try {\n+                    writeQueue.offer(node);\n+                } catch (Throwable cause) {\n+                    // The queue offer is not expected to throw, but if it does we cannot poll the WriteNode to recover.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b18787edc146525dc2ecadf7ef8c0c6e887d46b2"}, "originalPosition": 108}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzg1NzQ4OQ==", "bodyText": "Should we be popping the next node here too?", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r403857489", "createdAt": "2020-04-06T06:34:44Z", "author": {"login": "NiteshKant"}, "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,378 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.CompletableSource;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.PublisherSource.Subscriber;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.CompletableOperator;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.PublisherOperator;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.http.netty.MpmcSequentialRunQueue.Node;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimators;\n+\n+import io.netty.channel.Channel;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static io.servicetalk.concurrent.internal.SubscriberUtils.deliverTerminalFromSource;\n+import static java.util.Objects.requireNonNull;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    private final NettyConnection<Resp, Req> connection;\n+    private final MpmcSequentialRunQueue writeQueue;\n+    private final MpmcSequentialRunQueue readQueue;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+        writeQueue = new MpmcSequentialRunQueue();\n+        readQueue = new MpmcSequentialRunQueue();\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher) {\n+        return write(requestPublisher, connection::defaultFlushStrategy, WriteDemandEstimators::newDefaultEstimator);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+        return new Publisher<Resp>() {\n+            @Override\n+            protected void handleSubscribe(final Subscriber<? super Resp> subscriber) {\n+                final WriteNode node;\n+                try {\n+                    node = new WriteNode(subscriber, requestPublisher, flushStrategySupplier,\n+                            writeDemandEstimatorSupplier);\n+                } catch (Throwable cause) {\n+                    deliverTerminalFromSource(subscriber, cause);\n+                    return;\n+                }\n+\n+                try {\n+                    writeQueue.offer(node);\n+                } catch (Throwable cause) {\n+                    // The queue offer is not expected to throw, but if it does we cannot poll the WriteNode to recover.\n+                    // It is only safe to poll from the queue from Node#run() (or after it executes), so close.\n+                    closeConnection(subscriber, cause);\n+                }\n+            }\n+        };\n+    }\n+\n+    @Override\n+    public SocketAddress localAddress() {\n+        return connection.localAddress();\n+    }\n+\n+    @Override\n+    public SocketAddress remoteAddress() {\n+        return connection.remoteAddress();\n+    }\n+\n+    @Override\n+    @Nullable\n+    public SSLSession sslSession() {\n+        return connection.sslSession();\n+    }\n+\n+    @Override\n+    public ExecutionContext executionContext() {\n+        return connection.executionContext();\n+    }\n+\n+    @Nullable\n+    @Override\n+    public <T> T socketOption(final SocketOption<T> option) {\n+        return connection.socketOption(option);\n+    }\n+\n+    @Override\n+    public Protocol protocol() {\n+        return connection.protocol();\n+    }\n+\n+    @Override\n+    public Single<Throwable> transportError() {\n+        return connection.transportError();\n+    }\n+\n+    @Override\n+    public Completable onClosing() {\n+        return connection.onClosing();\n+    }\n+\n+    @Override\n+    public Completable onClose() {\n+        return connection.onClose();\n+    }\n+\n+    @Override\n+    public Completable closeAsync() {\n+        return connection.closeAsync();\n+    }\n+\n+    @Override\n+    public Completable closeAsyncGracefully() {\n+        return connection.closeAsyncGracefully();\n+    }\n+\n+    @Override\n+    public Channel nettyChannel() {\n+        return connection.nettyChannel();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return getClass().getName() + '(' + connection + ')';\n+    }\n+\n+    @Override\n+    public Cancellable updateFlushStrategy(final NettyConnectionContext.FlushStrategyProvider strategyProvider) {\n+        return connection.updateFlushStrategy(strategyProvider);\n+    }\n+\n+    @Override\n+    public FlushStrategy defaultFlushStrategy() {\n+        return connection.defaultFlushStrategy();\n+    }\n+\n+    private void closeConnection(final Subscriber<? super Resp> subscriber, final Throwable cause) {\n+        toSource(connection.closeAsync().concat(Publisher.<Resp>failed(cause))).subscribe(subscriber);\n+    }\n+\n+    private final class WriteNode extends Node {\n+        private final Subscriber<? super Resp> subscriber;\n+        private final Publisher<Req> requestPublisher;\n+        private final Supplier<FlushStrategy> flushStrategySupplier;\n+        private final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier;\n+\n+        private WriteNode(final Subscriber<? super Resp> subscriber,\n+                          final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+            this.subscriber = subscriber;\n+            this.requestPublisher = requestPublisher;\n+            this.flushStrategySupplier = flushStrategySupplier;\n+            this.writeDemandEstimatorSupplier = writeDemandEstimatorSupplier;\n+        }\n+\n+        @Override\n+        void run() {\n+            final PublisherSource<Resp> src;\n+            try {\n+                src = toSource(connection.write(requestPublisher, flushStrategySupplier, writeDemandEstimatorSupplier)\n+                        .liftSync(new WritePopNextOperator(this))\n+                        .merge(new Publisher<Resp>() {\n+                            @Override\n+                            protected void handleSubscribe(final Subscriber<? super Resp> rSubscriber) {\n+                                try {\n+                                    readQueue.offer(new ReadNode(rSubscriber));\n+                                } catch (Throwable cause) {\n+                                    // We started the write, but failed to setup the read. This is considered fatal as\n+                                    // we will be out of sync for delivering future read responses.\n+                                    closeConnection(rSubscriber, cause);\n+                                }\n+                            }\n+                        }));\n+            } catch (Throwable cause) {\n+                // We failed to setup the write operation, which means we also failed to setup the read operation.\n+                // This failure maybe recoverable as our internal state isn't corrupted, so just propagate the error.\n+                deliverTerminalFromSource(subscriber, cause);\n+                writeQueue.poll(this);\n+                return;\n+            }\n+            src.subscribe(subscriber);\n+        }\n+    }\n+\n+    private final class ReadNode extends Node {\n+        private final Subscriber<? super Resp> subscriber;\n+\n+        private ReadNode(final Subscriber<? super Resp> subscriber) {\n+            this.subscriber = subscriber;\n+        }\n+\n+        @Override\n+        void run() {\n+            final PublisherSource<Resp> src;\n+            try {\n+                src = toSource(connection.read().liftSync(new ReadPopNextOperator(this)));\n+            } catch (Throwable cause) {\n+                // We started the write, but failed to setup the read. This is considered fatal as we will be out of\n+                // sync for delivering future read responses.\n+                closeConnection(subscriber, cause);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b18787edc146525dc2ecadf7ef8c0c6e887d46b2"}, "originalPosition": 257}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzE1NDk4OA==", "bodyText": "Looks like this can race with poll() and run concurrent tasks.\ntail = node 1; (node1 currently running)\nThread 1:  \noffer (node 2)\n - node1.append(node2) <- success\n    - suspended\nThread 2 (concurrent with Thread 1):\n  offer(node3)\n  fails node1.append() as raced with Thread 1\n  suspended\n\nThread 3:\n  node 1 returns; node1.pop() returns node 2;\n     node 2.run();\n     returns;\n\nThread 2 resumes:\n    node1.isPopped() <- true\n    tailUpdater.cas(node1, node3) <- true\n      node3.run(); <-- we are running 2 nodes concurrently (Thread 2 => node 3, Thread 3 => node 2)", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r407154988", "createdAt": "2020-04-12T06:44:42Z", "author": {"login": "NiteshKant"}, "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/MpmcSequentialRunQueue.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import java.util.concurrent.atomic.AtomicReferenceFieldUpdater;\n+import javax.annotation.Nullable;\n+\n+import static java.util.concurrent.atomic.AtomicReferenceFieldUpdater.newUpdater;\n+\n+/**\n+ * This queue allows for Muli-Producer Multi-Consumer (Mpmc) threading semantics while also invoking the head\n+ * {@link Node}'s {@link Node#run()} in a serial fashion. The {@link Node#run()} will eventually trigger a\n+ * {@link #poll(Node)} (possibly asynchronously on another thread) which will invoke {@link Node#run()} on the next head\n+ * (assuming one exists).\n+ * <p>\n+ * Below is the expected interaction pattern and lifecycle of a Node:\n+ *     <pre>{@link #offer(Node)} -> {@link Node#run()} -> {@link #poll(Node)}</pre>\n+ * <p>\n+ * Although this queue supports Multi-Consumer threading semantics the {@link #poll(Node)} is typically only invoked\n+ * from a single thread (assuming successful runnable completion), it maybe invoked multiple times (potentially from\n+ * different threads) with the same {@link Node} due to cancellation/failure.\n+ */\n+final class MpmcSequentialRunQueue {\n+    private static final AtomicReferenceFieldUpdater<MpmcSequentialRunQueue, Node>\n+            tailUpdater = newUpdater(MpmcSequentialRunQueue.class, Node.class, \"tail\");\n+\n+    @Nullable\n+    private volatile Node tail;\n+\n+    /**\n+     * Offer {@link Node} to this queue.\n+     * @param node The {@link Node} to append. Must only exclusively be offered to this queue instance.\n+     */\n+    void offer(final Node node) {\n+        for (;;) {\n+            final Node currentTail = this.tail;\n+            if (currentTail == null) {\n+                if (tailUpdater.compareAndSet(this, null, node)) {\n+                    // node has been inserted and is the only node, we initiate processing.\n+                    node.run();\n+                    break;\n+                }\n+                // Another thread won the race to offer a node, loop around and try again.\n+            } else if (currentTail.append(node)) {\n+                // Make the newly appended node visible as the tail. This is a best effort CAS and may fail because:\n+                // 1. Another thread is also inserting, has a stale tail, followed its existing tail links, and updated\n+                // the tail reference via offerPatchTail.\n+                // 2. The consumer thread has seen the link from the old tail to the new node, processed node,\n+                // popped node from the list (updated node's next to point to EMPTY_NODE), another producer thread\n+                // appends a new node, sees the tail is popped, and updates the tail reference via CAS.\n+                tailUpdater.compareAndSet(this, currentTail, node);\n+                break;\n+            } else if (currentTail.isPopped()) {\n+                // A previously appended node was processed, and popped before updating the tail after append. In that\n+                // case the tail maybe pointing to an invalid node and we clear it out.\n+                if (tailUpdater.compareAndSet(this, currentTail, node)) {\n+                    node.run();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c53de34d09bf4dee72002aecfee5c160062ee1de"}, "originalPosition": 70}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c53de34d09bf4dee72002aecfee5c160062ee1de", "author": {"user": {"login": "Scottmitch", "name": "Scott Mitchell"}}, "url": "https://github.com/apple/servicetalk/commit/c53de34d09bf4dee72002aecfee5c160062ee1de", "committedDate": "2020-04-08T00:00:40Z", "message": "add benchmark for NettyPipelinedConnection"}, "afterCommit": {"oid": "19e2d3dd9e4345332ef958382148c87915d818f4", "author": {"user": {"login": "Scottmitch", "name": "Scott Mitchell"}}, "url": "https://github.com/apple/servicetalk/commit/19e2d3dd9e4345332ef958382148c87915d818f4", "committedDate": "2020-04-15T04:35:42Z", "message": "remove MpmcSequentialRunQueue, use MPSC compatible queues"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkzNDUwNTUy", "url": "https://github.com/apple/servicetalk/pull/980#pullrequestreview-393450552", "createdAt": "2020-04-15T04:37:55Z", "commit": {"oid": "19e2d3dd9e4345332ef958382148c87915d818f4"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNDozNzo1NVrOGFpgMw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNDozNzo1NVrOGFpgMw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODU3NjA1MQ==", "bodyText": "@NiteshKant - note these are utilities that are also shared with #1011 and #1014 ... which ever PR lands first will bring them in and I will rebase to avoid duplication.", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r408576051", "createdAt": "2020-04-15T04:37:55Z", "author": {"login": "Scottmitch"}, "path": "servicetalk-concurrent-internal/src/main/java/io/servicetalk/concurrent/internal/ConcurrentUtils.java", "diffHunk": "@@ -31,11 +31,46 @@\n \n     public static final int CONCURRENT_IDLE = 0;\n     public static final int CONCURRENT_EMITTING = 1;\n+    private static final int CONCURRENT_PENDING = 2;\n \n     private ConcurrentUtils() {\n         // No instances.\n     }\n \n+    /**\n+     * Acquire a lock that is exclusively held with no re-entry, but attempts to acquire the lock while it is\n+     * held can be detected by {@link #releasePendingLock(AtomicIntegerFieldUpdater, Object)}.\n+     * @param lockUpdater The {@link AtomicIntegerFieldUpdater} used to control the lock state.\n+     * @param owner The owner of the lock object.\n+     * @param <T> The type of object that owns the lock.\n+     * @return {@code true} if the lock was acquired, {@code false} otherwise.\n+     */\n+    public static <T> boolean acquirePendingLock(AtomicIntegerFieldUpdater<T> lockUpdater, T owner) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "19e2d3dd9e4345332ef958382148c87915d818f4"}, "originalPosition": 18}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzkzNDgyMjMw", "url": "https://github.com/apple/servicetalk/pull/980#pullrequestreview-393482230", "createdAt": "2020-04-15T06:17:00Z", "commit": {"oid": "19e2d3dd9e4345332ef958382148c87915d818f4"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjoxNzowMFrOGFrN1Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwNjoxODo0MVrOGFrQRQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYwNDExNw==", "bodyText": "nit: Should we enable it again after we are done with the benchmark ? IF so we may just do it in setup() and tearDown() methods", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r408604117", "createdAt": "2020-04-15T06:17:00Z", "author": {"login": "normanmaurer"}, "path": "servicetalk-benchmarks/src/jmh/java/io/servicetalk/http/netty/NettyPipelinedConnectionBenchmark.java", "diffHunk": "@@ -0,0 +1,268 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.CompletableSource;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.api.AsyncContext;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.http.api.HttpProtocolVersion;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategies;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.GlobalExecutionContext;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+\n+import io.netty.channel.Channel;\n+import org.openjdk.jmh.annotations.Benchmark;\n+import org.openjdk.jmh.annotations.BenchmarkMode;\n+import org.openjdk.jmh.annotations.Fork;\n+import org.openjdk.jmh.annotations.Level;\n+import org.openjdk.jmh.annotations.Measurement;\n+import org.openjdk.jmh.annotations.Mode;\n+import org.openjdk.jmh.annotations.Scope;\n+import org.openjdk.jmh.annotations.Setup;\n+import org.openjdk.jmh.annotations.State;\n+import org.openjdk.jmh.annotations.TearDown;\n+import org.openjdk.jmh.annotations.Warmup;\n+\n+import java.net.InetSocketAddress;\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.CyclicBarrier;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.atomic.AtomicInteger;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.Cancellable.IGNORE_CANCEL;\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+\n+@Fork(value = 1)\n+@State(Scope.Benchmark)\n+@Warmup(iterations = 5, time = 3)\n+@Measurement(iterations = 5, time = 3)\n+@BenchmarkMode(Mode.Throughput)\n+public class NettyPipelinedConnectionBenchmark {\n+    static {\n+        AsyncContext.disable(); // reduce noise in benchmarks.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "19e2d3dd9e4345332ef958382148c87915d818f4"}, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODYwNDc0MQ==", "bodyText": "nit: I wonder if unbounded may be risky here... But I guess it should be fine ?", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r408604741", "createdAt": "2020-04-15T06:18:41Z", "author": {"login": "normanmaurer"}, "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,344 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.PublisherSource.Subscriber;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.concurrent.internal.ConcurrentUtils;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimators;\n+\n+import io.netty.channel.Channel;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static io.servicetalk.concurrent.internal.ConcurrentUtils.acquirePendingLock;\n+import static io.servicetalk.concurrent.internal.ConcurrentUtils.releasePendingLock;\n+import static io.servicetalk.concurrent.internal.SubscriberUtils.deliverTerminalFromSource;\n+import static io.servicetalk.utils.internal.PlatformDependent.newUnboundedMpscQueue;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.atomic.AtomicIntegerFieldUpdater.newUpdater;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicIntegerFieldUpdater<NettyPipelinedConnection> writeQueueLockUpdater =\n+            newUpdater(NettyPipelinedConnection.class, \"writeQueueLock\");\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicIntegerFieldUpdater<NettyPipelinedConnection> readQueueLockUpdater =\n+            newUpdater(NettyPipelinedConnection.class, \"readQueueLock\");\n+    private final NettyConnection<Resp, Req> connection;\n+    private final Queue<WriteTask> writeQueue;\n+    private final Queue<Subscriber<? super Resp>> readQueue;\n+    @SuppressWarnings(\"unused\")\n+    private volatile int writeQueueLock;\n+    @SuppressWarnings(\"unused\")\n+    private volatile int readQueueLock;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+        writeQueue = newUnboundedMpscQueue();\n+        readQueue = newUnboundedMpscQueue();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "19e2d3dd9e4345332ef958382148c87915d818f4"}, "originalPosition": 81}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4e47b9196925fb08fdb54a2ef984428c546822c8", "author": {"user": {"login": "Scottmitch", "name": "Scott Mitchell"}}, "url": "https://github.com/apple/servicetalk/commit/4e47b9196925fb08fdb54a2ef984428c546822c8", "committedDate": "2020-04-28T04:04:31Z", "message": "HTTP Client Pipelining fullduplex\n\nMotivation:\nThe queue which orders and sequences HTTP pipelining on the client side\nhas been shown to lead to duplicate subscribe exceptions and also\ndoesn't support full duplex read/write.\n\nModifications:\n- The first was related to DefaultNettyPipelinedConnection\nwhich may have enqueued out of order which lead to a duplicate subscribe\nexception on NettyChannelPublisher. The DefaultNettyPipelinedConnection\nwas rewritten to avoid using the SequentialTaskQueue (which relies upon\nthread locals for single item execution and async completion) and also\ndoesn't allow for full duplex (write must finish before read starts),\nand those issues are both fixed.\n- ClientClosureRaceTest is intentionally closing the server connection\nabrubtley, which may result in writing a request that is not\nautomatically retryable. The retry strategy should always retry in this\ncase or else the test may hang/fail.\n\nResult:\nHTTP client now support full duplex pipelining."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "020649cfd6585f30136c3107120e0146ed988252", "author": {"user": {"login": "Scottmitch", "name": "Scott Mitchell"}}, "url": "https://github.com/apple/servicetalk/commit/020649cfd6585f30136c3107120e0146ed988252", "committedDate": "2020-04-28T04:04:31Z", "message": "review comments\n\n- move the Delayed sources to their own files, and add tests\n- make error handling more explicit, and add tests\n- address various other review comments\n- move queue logic to independent file to make APIs more clear and allow\nfor easier documentation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ac819cf1983284bad77319ae2a3680caf929f34d", "author": {"user": {"login": "Scottmitch", "name": "Scott Mitchell"}}, "url": "https://github.com/apple/servicetalk/commit/ac819cf1983284bad77319ae2a3680caf929f34d", "committedDate": "2020-04-28T04:04:31Z", "message": "adjust error handling and add comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "02e5f2a44e058a2da4a22c337f213abcfd3b3476", "author": {"user": {"login": "Scottmitch", "name": "Scott Mitchell"}}, "url": "https://github.com/apple/servicetalk/commit/02e5f2a44e058a2da4a22c337f213abcfd3b3476", "committedDate": "2020-04-28T04:04:31Z", "message": "more clarification of error flow, removal of unecessary code"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "18523787d5acbf15b1519c4d0c34a64c53117fc8", "author": {"user": {"login": "Scottmitch", "name": "Scott Mitchell"}}, "url": "https://github.com/apple/servicetalk/commit/18523787d5acbf15b1519c4d0c34a64c53117fc8", "committedDate": "2020-04-28T04:04:31Z", "message": "remove delayed sources"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "83a1f5f347c418cb82066e7ea13fb0aefd8080ca", "author": {"user": {"login": "Scottmitch", "name": "Scott Mitchell"}}, "url": "https://github.com/apple/servicetalk/commit/83a1f5f347c418cb82066e7ea13fb0aefd8080ca", "committedDate": "2020-04-28T04:04:31Z", "message": "update comment"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0218166d6a6caad6accdf9bc44e1413a675eb65a", "author": {"user": {"login": "Scottmitch", "name": "Scott Mitchell"}}, "url": "https://github.com/apple/servicetalk/commit/0218166d6a6caad6accdf9bc44e1413a675eb65a", "committedDate": "2020-04-28T04:04:31Z", "message": "more clarification comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e31b7674a0f19a7b746286ab792522121fc9e52b", "author": {"user": {"login": "Scottmitch", "name": "Scott Mitchell"}}, "url": "https://github.com/apple/servicetalk/commit/e31b7674a0f19a7b746286ab792522121fc9e52b", "committedDate": "2020-04-28T04:04:31Z", "message": "adjust methods and add comments for concurrent queue"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5e70d09f6e290f3f796351b6cd2a8f5ca612e22c", "author": {"user": {"login": "Scottmitch", "name": "Scott Mitchell"}}, "url": "https://github.com/apple/servicetalk/commit/5e70d09f6e290f3f796351b6cd2a8f5ca612e22c", "committedDate": "2020-04-28T04:04:31Z", "message": "add benchmark for NettyPipelinedConnection"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "48e60622d78c70c83cf4718473b609291e0c072e", "author": {"user": {"login": "Scottmitch", "name": "Scott Mitchell"}}, "url": "https://github.com/apple/servicetalk/commit/48e60622d78c70c83cf4718473b609291e0c072e", "committedDate": "2020-04-28T04:08:04Z", "message": "remove MpmcSequentialRunQueue, use MPSC compatible queues"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "912ff44a47c19d278a5c617a9e619542cee8453b", "author": {"user": {"login": "Scottmitch", "name": "Scott Mitchell"}}, "url": "https://github.com/apple/servicetalk/commit/912ff44a47c19d278a5c617a9e619542cee8453b", "committedDate": "2020-04-28T04:09:05Z", "message": "adjust exception handling"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "89e482ae0bd3e0828263149472c17bbe4b8a3daf", "author": {"user": {"login": "Scottmitch", "name": "Scott Mitchell"}}, "url": "https://github.com/apple/servicetalk/commit/89e482ae0bd3e0828263149472c17bbe4b8a3daf", "committedDate": "2020-04-28T04:09:56Z", "message": "re-acquire lock during queue drain after releasing lock"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e67ddd3040b7d00c14ad7c8da5750ac327447447", "author": {"user": {"login": "Scottmitch", "name": "Scott Mitchell"}}, "url": "https://github.com/apple/servicetalk/commit/e67ddd3040b7d00c14ad7c8da5750ac327447447", "committedDate": "2020-04-28T04:12:42Z", "message": "move try/catch in drain method"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "661009791935a6d551c55c61777011b4629b5fcc", "author": {"user": {"login": "Scottmitch", "name": "Scott Mitchell"}}, "url": "https://github.com/apple/servicetalk/commit/661009791935a6d551c55c61777011b4629b5fcc", "committedDate": "2020-04-15T17:13:21Z", "message": "re-acquire lock during queue drain after releasing lock"}, "afterCommit": {"oid": "e67ddd3040b7d00c14ad7c8da5750ac327447447", "author": {"user": {"login": "Scottmitch", "name": "Scott Mitchell"}}, "url": "https://github.com/apple/servicetalk/commit/e67ddd3040b7d00c14ad7c8da5750ac327447447", "committedDate": "2020-04-28T04:12:42Z", "message": "move try/catch in drain method"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAyMTU4OTU2", "url": "https://github.com/apple/servicetalk/pull/980#pullrequestreview-402158956", "createdAt": "2020-04-28T19:48:24Z", "commit": {"oid": "e67ddd3040b7d00c14ad7c8da5750ac327447447"}, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOFQxOTo0ODoyNFrOGNkP6Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOFQyMDoxNDo1M1rOGNlKCA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjg3ODU2OQ==", "bodyText": "nit: discrepancy b/w name and action here; either rename method to addTryAcquireLock or use queue.offer()", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r416878569", "createdAt": "2020-04-28T19:48:24Z", "author": {"login": "NiteshKant"}, "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,362 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.PublisherSource.Subscriber;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.concurrent.internal.ConcurrentUtils;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimators;\n+\n+import io.netty.channel.Channel;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static io.servicetalk.concurrent.internal.ConcurrentUtils.releaseLock;\n+import static io.servicetalk.concurrent.internal.ConcurrentUtils.tryAcquireLock;\n+import static io.servicetalk.concurrent.internal.SubscriberUtils.deliverTerminalFromSource;\n+import static io.servicetalk.utils.internal.PlatformDependent.newUnboundedMpscQueue;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.atomic.AtomicIntegerFieldUpdater.newUpdater;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicIntegerFieldUpdater<NettyPipelinedConnection> writeQueueLockUpdater =\n+            newUpdater(NettyPipelinedConnection.class, \"writeQueueLock\");\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicIntegerFieldUpdater<NettyPipelinedConnection> readQueueLockUpdater =\n+            newUpdater(NettyPipelinedConnection.class, \"readQueueLock\");\n+    private final NettyConnection<Resp, Req> connection;\n+    private final Queue<WriteTask> writeQueue;\n+    private final Queue<Subscriber<? super Resp>> readQueue;\n+    @SuppressWarnings(\"unused\")\n+    private volatile int writeQueueLock;\n+    @SuppressWarnings(\"unused\")\n+    private volatile int readQueueLock;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+        writeQueue = newUnboundedMpscQueue();\n+        readQueue = newUnboundedMpscQueue();\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher) {\n+        return write(requestPublisher, connection::defaultFlushStrategy, WriteDemandEstimators::newDefaultEstimator);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+        return new Publisher<Resp>() {\n+            @Override\n+            protected void handleSubscribe(final Subscriber<? super Resp> subscriber) {\n+                final WriteTask firstWriteTask;\n+                try {\n+                    firstWriteTask = offerTryAcquireLock(writeQueue, writeQueueLockUpdater,\n+                            new WriteTask(subscriber, requestPublisher, flushStrategySupplier,\n+                                    writeDemandEstimatorSupplier));\n+                } catch (Throwable cause) {\n+                    closeConnection(subscriber, cause);\n+                    return;\n+                }\n+\n+                if (firstWriteTask != null) {\n+                    firstWriteTask.run();\n+                }\n+            }\n+        };\n+    }\n+\n+    @Override\n+    public SocketAddress localAddress() {\n+        return connection.localAddress();\n+    }\n+\n+    @Override\n+    public SocketAddress remoteAddress() {\n+        return connection.remoteAddress();\n+    }\n+\n+    @Override\n+    @Nullable\n+    public SSLSession sslSession() {\n+        return connection.sslSession();\n+    }\n+\n+    @Override\n+    public ExecutionContext executionContext() {\n+        return connection.executionContext();\n+    }\n+\n+    @Nullable\n+    @Override\n+    public <T> T socketOption(final SocketOption<T> option) {\n+        return connection.socketOption(option);\n+    }\n+\n+    @Override\n+    public Protocol protocol() {\n+        return connection.protocol();\n+    }\n+\n+    @Override\n+    public Single<Throwable> transportError() {\n+        return connection.transportError();\n+    }\n+\n+    @Override\n+    public Completable onClosing() {\n+        return connection.onClosing();\n+    }\n+\n+    @Override\n+    public Completable onClose() {\n+        return connection.onClose();\n+    }\n+\n+    @Override\n+    public Completable closeAsync() {\n+        return connection.closeAsync();\n+    }\n+\n+    @Override\n+    public Completable closeAsyncGracefully() {\n+        return connection.closeAsyncGracefully();\n+    }\n+\n+    @Override\n+    public Channel nettyChannel() {\n+        return connection.nettyChannel();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return getClass().getSimpleName() + '(' + connection + ')';\n+    }\n+\n+    @Override\n+    public Cancellable updateFlushStrategy(final NettyConnectionContext.FlushStrategyProvider strategyProvider) {\n+        return connection.updateFlushStrategy(strategyProvider);\n+    }\n+\n+    @Override\n+    public FlushStrategy defaultFlushStrategy() {\n+        return connection.defaultFlushStrategy();\n+    }\n+\n+    private void closeConnection(final Subscriber<? super Resp> subscriber, final Throwable cause) {\n+        toSource(connection.closeAsync().concat(Publisher.<Resp>failed(cause))).subscribe(subscriber);\n+    }\n+\n+    private void tryStartRead(@Nullable Subscriber<? super Resp> subscriber) {\n+        if (subscriber == null) {\n+            return;\n+        }\n+        final PublisherSource<Resp> src;\n+        try {\n+            src = toSource(connection.read().afterFinally(() ->\n+                    tryStartRead(pollWithLockAcquired(readQueue, readQueueLockUpdater))));\n+        } catch (Throwable cause) {\n+            handleReadSetupError(subscriber, cause);\n+            return;\n+        }\n+        src.subscribe(subscriber);\n+    }\n+\n+    private final class WriteTask {\n+        private final Subscriber<? super Resp> subscriber;\n+        private final Publisher<Req> requestPublisher;\n+        private final Supplier<FlushStrategy> flushStrategySupplier;\n+        private final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier;\n+\n+        private WriteTask(final Subscriber<? super Resp> subscriber,\n+                          final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+            this.subscriber = subscriber;\n+            this.requestPublisher = requestPublisher;\n+            this.flushStrategySupplier = flushStrategySupplier;\n+            this.writeDemandEstimatorSupplier = writeDemandEstimatorSupplier;\n+        }\n+\n+        void run() {\n+            final PublisherSource<Resp> src;\n+            try {\n+                src = toSource(connection.write(requestPublisher, flushStrategySupplier,\n+                        writeDemandEstimatorSupplier)\n+                        .afterFinally(() -> {\n+                            WriteTask nextWriteTask = pollWithLockAcquired(writeQueue, writeQueueLockUpdater);\n+                            if (nextWriteTask != null) {\n+                                nextWriteTask.run();\n+                            }\n+                        }).merge(new Publisher<Resp>() {\n+                            @Override\n+                            protected void handleSubscribe(final Subscriber<? super Resp> rSubscriber) {\n+                                final Subscriber<? super Resp> firstReadSubscriber;\n+                                try {\n+                                    firstReadSubscriber =\n+                                            offerTryAcquireLock(readQueue, readQueueLockUpdater, rSubscriber);\n+                                } catch (Throwable cause) {\n+                                    closeConnection(rSubscriber, cause);\n+                                    return;\n+                                }\n+\n+                                tryStartRead(firstReadSubscriber);\n+                            }\n+                        }));\n+            } catch (Throwable cause) {\n+                handleWriteSetupError(subscriber, cause);\n+                return;\n+            }\n+            src.subscribe(subscriber);\n+        }\n+    }\n+\n+    private void handleWriteSetupError(Subscriber<? super Resp> subscriber, Throwable cause) {\n+        try {\n+            closeConnection(subscriber, cause);\n+        } finally {\n+            // the lock has been acquired!\n+            do {\n+                WriteTask nextWriteTask;\n+                while ((nextWriteTask = writeQueue.poll()) != null) {\n+                    deliverTerminalFromSource(nextWriteTask.subscriber, cause);\n+                }\n+            } while (!releaseLock(writeQueueLockUpdater, this) && tryAcquireLock(writeQueueLockUpdater, this));\n+        }\n+    }\n+\n+    private void handleReadSetupError(Subscriber<? super Resp> subscriber, Throwable cause) {\n+        try {\n+            closeConnection(subscriber, cause);\n+        } finally {\n+            // the lock has been acquired!\n+            do {\n+                Subscriber<? super Resp> nextSubscriber;\n+                while ((nextSubscriber = readQueue.poll()) != null) {\n+                    deliverTerminalFromSource(nextSubscriber, cause);\n+                }\n+            } while (!releaseLock(readQueueLockUpdater, this) && tryAcquireLock(readQueueLockUpdater, this));\n+        }\n+    }\n+\n+    /**\n+     * Offer {@code item} to the queue, try to acquire the processing lock, and if successful return an item for\n+     * single-consumer style processing. If non-{@code null} is returned the caller is responsible for releasing\n+     * the lock!\n+     * @param queue The {@link Queue#offer(Object)} and {@link Queue#poll()} (assuming lock was acquired).\n+     * @param lockUpdater Used to acquire the lock via\n+     * {@link ConcurrentUtils#tryAcquireLock(AtomicIntegerFieldUpdater, Object)}.\n+     * @param item The item to {@link Queue#offer(Object)}.\n+     * @param <T> The type of item in the {@link Queue}.\n+     * @return {@code null} if the queue was empty, or the lock couldn't be acquired. otherwise the lock has been\n+     * acquired and it is the caller's responsibility to release!\n+     */\n+    @Nullable\n+    private <T> T offerTryAcquireLock(final Queue<T> queue,\n+          @SuppressWarnings(\"rawtypes\") final AtomicIntegerFieldUpdater<NettyPipelinedConnection> lockUpdater, T item) {\n+        queue.add(item);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e67ddd3040b7d00c14ad7c8da5750ac327447447"}, "originalPosition": 314}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjg4MTExNA==", "bodyText": "This isn't necessarily the \"first write task\" rite? it can be the next write if the previous task completed concurrently.", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r416881114", "createdAt": "2020-04-28T19:52:52Z", "author": {"login": "NiteshKant"}, "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,362 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.PublisherSource.Subscriber;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.concurrent.internal.ConcurrentUtils;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimators;\n+\n+import io.netty.channel.Channel;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static io.servicetalk.concurrent.internal.ConcurrentUtils.releaseLock;\n+import static io.servicetalk.concurrent.internal.ConcurrentUtils.tryAcquireLock;\n+import static io.servicetalk.concurrent.internal.SubscriberUtils.deliverTerminalFromSource;\n+import static io.servicetalk.utils.internal.PlatformDependent.newUnboundedMpscQueue;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.atomic.AtomicIntegerFieldUpdater.newUpdater;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicIntegerFieldUpdater<NettyPipelinedConnection> writeQueueLockUpdater =\n+            newUpdater(NettyPipelinedConnection.class, \"writeQueueLock\");\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicIntegerFieldUpdater<NettyPipelinedConnection> readQueueLockUpdater =\n+            newUpdater(NettyPipelinedConnection.class, \"readQueueLock\");\n+    private final NettyConnection<Resp, Req> connection;\n+    private final Queue<WriteTask> writeQueue;\n+    private final Queue<Subscriber<? super Resp>> readQueue;\n+    @SuppressWarnings(\"unused\")\n+    private volatile int writeQueueLock;\n+    @SuppressWarnings(\"unused\")\n+    private volatile int readQueueLock;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+        writeQueue = newUnboundedMpscQueue();\n+        readQueue = newUnboundedMpscQueue();\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher) {\n+        return write(requestPublisher, connection::defaultFlushStrategy, WriteDemandEstimators::newDefaultEstimator);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+        return new Publisher<Resp>() {\n+            @Override\n+            protected void handleSubscribe(final Subscriber<? super Resp> subscriber) {\n+                final WriteTask firstWriteTask;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e67ddd3040b7d00c14ad7c8da5750ac327447447"}, "originalPosition": 109}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjg4MjIxNw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            return next; // lock must be released by caller!\n          \n          \n            \n                            return next; // lock must be released when the returned task completes!", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r416882217", "createdAt": "2020-04-28T19:54:42Z", "author": {"login": "NiteshKant"}, "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,362 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.PublisherSource.Subscriber;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.concurrent.internal.ConcurrentUtils;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimators;\n+\n+import io.netty.channel.Channel;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static io.servicetalk.concurrent.internal.ConcurrentUtils.releaseLock;\n+import static io.servicetalk.concurrent.internal.ConcurrentUtils.tryAcquireLock;\n+import static io.servicetalk.concurrent.internal.SubscriberUtils.deliverTerminalFromSource;\n+import static io.servicetalk.utils.internal.PlatformDependent.newUnboundedMpscQueue;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.atomic.AtomicIntegerFieldUpdater.newUpdater;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicIntegerFieldUpdater<NettyPipelinedConnection> writeQueueLockUpdater =\n+            newUpdater(NettyPipelinedConnection.class, \"writeQueueLock\");\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicIntegerFieldUpdater<NettyPipelinedConnection> readQueueLockUpdater =\n+            newUpdater(NettyPipelinedConnection.class, \"readQueueLock\");\n+    private final NettyConnection<Resp, Req> connection;\n+    private final Queue<WriteTask> writeQueue;\n+    private final Queue<Subscriber<? super Resp>> readQueue;\n+    @SuppressWarnings(\"unused\")\n+    private volatile int writeQueueLock;\n+    @SuppressWarnings(\"unused\")\n+    private volatile int readQueueLock;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+        writeQueue = newUnboundedMpscQueue();\n+        readQueue = newUnboundedMpscQueue();\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher) {\n+        return write(requestPublisher, connection::defaultFlushStrategy, WriteDemandEstimators::newDefaultEstimator);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+        return new Publisher<Resp>() {\n+            @Override\n+            protected void handleSubscribe(final Subscriber<? super Resp> subscriber) {\n+                final WriteTask firstWriteTask;\n+                try {\n+                    firstWriteTask = offerTryAcquireLock(writeQueue, writeQueueLockUpdater,\n+                            new WriteTask(subscriber, requestPublisher, flushStrategySupplier,\n+                                    writeDemandEstimatorSupplier));\n+                } catch (Throwable cause) {\n+                    closeConnection(subscriber, cause);\n+                    return;\n+                }\n+\n+                if (firstWriteTask != null) {\n+                    firstWriteTask.run();\n+                }\n+            }\n+        };\n+    }\n+\n+    @Override\n+    public SocketAddress localAddress() {\n+        return connection.localAddress();\n+    }\n+\n+    @Override\n+    public SocketAddress remoteAddress() {\n+        return connection.remoteAddress();\n+    }\n+\n+    @Override\n+    @Nullable\n+    public SSLSession sslSession() {\n+        return connection.sslSession();\n+    }\n+\n+    @Override\n+    public ExecutionContext executionContext() {\n+        return connection.executionContext();\n+    }\n+\n+    @Nullable\n+    @Override\n+    public <T> T socketOption(final SocketOption<T> option) {\n+        return connection.socketOption(option);\n+    }\n+\n+    @Override\n+    public Protocol protocol() {\n+        return connection.protocol();\n+    }\n+\n+    @Override\n+    public Single<Throwable> transportError() {\n+        return connection.transportError();\n+    }\n+\n+    @Override\n+    public Completable onClosing() {\n+        return connection.onClosing();\n+    }\n+\n+    @Override\n+    public Completable onClose() {\n+        return connection.onClose();\n+    }\n+\n+    @Override\n+    public Completable closeAsync() {\n+        return connection.closeAsync();\n+    }\n+\n+    @Override\n+    public Completable closeAsyncGracefully() {\n+        return connection.closeAsyncGracefully();\n+    }\n+\n+    @Override\n+    public Channel nettyChannel() {\n+        return connection.nettyChannel();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return getClass().getSimpleName() + '(' + connection + ')';\n+    }\n+\n+    @Override\n+    public Cancellable updateFlushStrategy(final NettyConnectionContext.FlushStrategyProvider strategyProvider) {\n+        return connection.updateFlushStrategy(strategyProvider);\n+    }\n+\n+    @Override\n+    public FlushStrategy defaultFlushStrategy() {\n+        return connection.defaultFlushStrategy();\n+    }\n+\n+    private void closeConnection(final Subscriber<? super Resp> subscriber, final Throwable cause) {\n+        toSource(connection.closeAsync().concat(Publisher.<Resp>failed(cause))).subscribe(subscriber);\n+    }\n+\n+    private void tryStartRead(@Nullable Subscriber<? super Resp> subscriber) {\n+        if (subscriber == null) {\n+            return;\n+        }\n+        final PublisherSource<Resp> src;\n+        try {\n+            src = toSource(connection.read().afterFinally(() ->\n+                    tryStartRead(pollWithLockAcquired(readQueue, readQueueLockUpdater))));\n+        } catch (Throwable cause) {\n+            handleReadSetupError(subscriber, cause);\n+            return;\n+        }\n+        src.subscribe(subscriber);\n+    }\n+\n+    private final class WriteTask {\n+        private final Subscriber<? super Resp> subscriber;\n+        private final Publisher<Req> requestPublisher;\n+        private final Supplier<FlushStrategy> flushStrategySupplier;\n+        private final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier;\n+\n+        private WriteTask(final Subscriber<? super Resp> subscriber,\n+                          final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+            this.subscriber = subscriber;\n+            this.requestPublisher = requestPublisher;\n+            this.flushStrategySupplier = flushStrategySupplier;\n+            this.writeDemandEstimatorSupplier = writeDemandEstimatorSupplier;\n+        }\n+\n+        void run() {\n+            final PublisherSource<Resp> src;\n+            try {\n+                src = toSource(connection.write(requestPublisher, flushStrategySupplier,\n+                        writeDemandEstimatorSupplier)\n+                        .afterFinally(() -> {\n+                            WriteTask nextWriteTask = pollWithLockAcquired(writeQueue, writeQueueLockUpdater);\n+                            if (nextWriteTask != null) {\n+                                nextWriteTask.run();\n+                            }\n+                        }).merge(new Publisher<Resp>() {\n+                            @Override\n+                            protected void handleSubscribe(final Subscriber<? super Resp> rSubscriber) {\n+                                final Subscriber<? super Resp> firstReadSubscriber;\n+                                try {\n+                                    firstReadSubscriber =\n+                                            offerTryAcquireLock(readQueue, readQueueLockUpdater, rSubscriber);\n+                                } catch (Throwable cause) {\n+                                    closeConnection(rSubscriber, cause);\n+                                    return;\n+                                }\n+\n+                                tryStartRead(firstReadSubscriber);\n+                            }\n+                        }));\n+            } catch (Throwable cause) {\n+                handleWriteSetupError(subscriber, cause);\n+                return;\n+            }\n+            src.subscribe(subscriber);\n+        }\n+    }\n+\n+    private void handleWriteSetupError(Subscriber<? super Resp> subscriber, Throwable cause) {\n+        try {\n+            closeConnection(subscriber, cause);\n+        } finally {\n+            // the lock has been acquired!\n+            do {\n+                WriteTask nextWriteTask;\n+                while ((nextWriteTask = writeQueue.poll()) != null) {\n+                    deliverTerminalFromSource(nextWriteTask.subscriber, cause);\n+                }\n+            } while (!releaseLock(writeQueueLockUpdater, this) && tryAcquireLock(writeQueueLockUpdater, this));\n+        }\n+    }\n+\n+    private void handleReadSetupError(Subscriber<? super Resp> subscriber, Throwable cause) {\n+        try {\n+            closeConnection(subscriber, cause);\n+        } finally {\n+            // the lock has been acquired!\n+            do {\n+                Subscriber<? super Resp> nextSubscriber;\n+                while ((nextSubscriber = readQueue.poll()) != null) {\n+                    deliverTerminalFromSource(nextSubscriber, cause);\n+                }\n+            } while (!releaseLock(readQueueLockUpdater, this) && tryAcquireLock(readQueueLockUpdater, this));\n+        }\n+    }\n+\n+    /**\n+     * Offer {@code item} to the queue, try to acquire the processing lock, and if successful return an item for\n+     * single-consumer style processing. If non-{@code null} is returned the caller is responsible for releasing\n+     * the lock!\n+     * @param queue The {@link Queue#offer(Object)} and {@link Queue#poll()} (assuming lock was acquired).\n+     * @param lockUpdater Used to acquire the lock via\n+     * {@link ConcurrentUtils#tryAcquireLock(AtomicIntegerFieldUpdater, Object)}.\n+     * @param item The item to {@link Queue#offer(Object)}.\n+     * @param <T> The type of item in the {@link Queue}.\n+     * @return {@code null} if the queue was empty, or the lock couldn't be acquired. otherwise the lock has been\n+     * acquired and it is the caller's responsibility to release!\n+     */\n+    @Nullable\n+    private <T> T offerTryAcquireLock(final Queue<T> queue,\n+          @SuppressWarnings(\"rawtypes\") final AtomicIntegerFieldUpdater<NettyPipelinedConnection> lockUpdater, T item) {\n+        queue.add(item);\n+        while (tryAcquireLock(lockUpdater, this)) {\n+            // exceptions are not expected from poll, and if they occur we can't reliably recover which would involve\n+            // draining the queue. just throw with the lock poisoned, callers will propagate the exception to related\n+            // subscriber and close the connection.\n+            final T next = queue.poll();\n+            if (next != null) {\n+                return next; // lock must be released by caller!", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e67ddd3040b7d00c14ad7c8da5750ac327447447"}, "originalPosition": 321}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjg4NTIxNg==", "bodyText": "Does it have to be afterFinally() or we can use beforeFinally()? A positive of using before*() here is that any exception will bubble up to the subscriber.", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r416885216", "createdAt": "2020-04-28T20:00:02Z", "author": {"login": "NiteshKant"}, "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,362 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.PublisherSource.Subscriber;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.concurrent.internal.ConcurrentUtils;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimators;\n+\n+import io.netty.channel.Channel;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static io.servicetalk.concurrent.internal.ConcurrentUtils.releaseLock;\n+import static io.servicetalk.concurrent.internal.ConcurrentUtils.tryAcquireLock;\n+import static io.servicetalk.concurrent.internal.SubscriberUtils.deliverTerminalFromSource;\n+import static io.servicetalk.utils.internal.PlatformDependent.newUnboundedMpscQueue;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.atomic.AtomicIntegerFieldUpdater.newUpdater;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicIntegerFieldUpdater<NettyPipelinedConnection> writeQueueLockUpdater =\n+            newUpdater(NettyPipelinedConnection.class, \"writeQueueLock\");\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicIntegerFieldUpdater<NettyPipelinedConnection> readQueueLockUpdater =\n+            newUpdater(NettyPipelinedConnection.class, \"readQueueLock\");\n+    private final NettyConnection<Resp, Req> connection;\n+    private final Queue<WriteTask> writeQueue;\n+    private final Queue<Subscriber<? super Resp>> readQueue;\n+    @SuppressWarnings(\"unused\")\n+    private volatile int writeQueueLock;\n+    @SuppressWarnings(\"unused\")\n+    private volatile int readQueueLock;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+        writeQueue = newUnboundedMpscQueue();\n+        readQueue = newUnboundedMpscQueue();\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher) {\n+        return write(requestPublisher, connection::defaultFlushStrategy, WriteDemandEstimators::newDefaultEstimator);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+        return new Publisher<Resp>() {\n+            @Override\n+            protected void handleSubscribe(final Subscriber<? super Resp> subscriber) {\n+                final WriteTask firstWriteTask;\n+                try {\n+                    firstWriteTask = offerTryAcquireLock(writeQueue, writeQueueLockUpdater,\n+                            new WriteTask(subscriber, requestPublisher, flushStrategySupplier,\n+                                    writeDemandEstimatorSupplier));\n+                } catch (Throwable cause) {\n+                    closeConnection(subscriber, cause);\n+                    return;\n+                }\n+\n+                if (firstWriteTask != null) {\n+                    firstWriteTask.run();\n+                }\n+            }\n+        };\n+    }\n+\n+    @Override\n+    public SocketAddress localAddress() {\n+        return connection.localAddress();\n+    }\n+\n+    @Override\n+    public SocketAddress remoteAddress() {\n+        return connection.remoteAddress();\n+    }\n+\n+    @Override\n+    @Nullable\n+    public SSLSession sslSession() {\n+        return connection.sslSession();\n+    }\n+\n+    @Override\n+    public ExecutionContext executionContext() {\n+        return connection.executionContext();\n+    }\n+\n+    @Nullable\n+    @Override\n+    public <T> T socketOption(final SocketOption<T> option) {\n+        return connection.socketOption(option);\n+    }\n+\n+    @Override\n+    public Protocol protocol() {\n+        return connection.protocol();\n+    }\n+\n+    @Override\n+    public Single<Throwable> transportError() {\n+        return connection.transportError();\n+    }\n+\n+    @Override\n+    public Completable onClosing() {\n+        return connection.onClosing();\n+    }\n+\n+    @Override\n+    public Completable onClose() {\n+        return connection.onClose();\n+    }\n+\n+    @Override\n+    public Completable closeAsync() {\n+        return connection.closeAsync();\n+    }\n+\n+    @Override\n+    public Completable closeAsyncGracefully() {\n+        return connection.closeAsyncGracefully();\n+    }\n+\n+    @Override\n+    public Channel nettyChannel() {\n+        return connection.nettyChannel();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return getClass().getSimpleName() + '(' + connection + ')';\n+    }\n+\n+    @Override\n+    public Cancellable updateFlushStrategy(final NettyConnectionContext.FlushStrategyProvider strategyProvider) {\n+        return connection.updateFlushStrategy(strategyProvider);\n+    }\n+\n+    @Override\n+    public FlushStrategy defaultFlushStrategy() {\n+        return connection.defaultFlushStrategy();\n+    }\n+\n+    private void closeConnection(final Subscriber<? super Resp> subscriber, final Throwable cause) {\n+        toSource(connection.closeAsync().concat(Publisher.<Resp>failed(cause))).subscribe(subscriber);\n+    }\n+\n+    private void tryStartRead(@Nullable Subscriber<? super Resp> subscriber) {\n+        if (subscriber == null) {\n+            return;\n+        }\n+        final PublisherSource<Resp> src;\n+        try {\n+            src = toSource(connection.read().afterFinally(() ->\n+                    tryStartRead(pollWithLockAcquired(readQueue, readQueueLockUpdater))));\n+        } catch (Throwable cause) {\n+            handleReadSetupError(subscriber, cause);\n+            return;\n+        }\n+        src.subscribe(subscriber);\n+    }\n+\n+    private final class WriteTask {\n+        private final Subscriber<? super Resp> subscriber;\n+        private final Publisher<Req> requestPublisher;\n+        private final Supplier<FlushStrategy> flushStrategySupplier;\n+        private final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier;\n+\n+        private WriteTask(final Subscriber<? super Resp> subscriber,\n+                          final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+            this.subscriber = subscriber;\n+            this.requestPublisher = requestPublisher;\n+            this.flushStrategySupplier = flushStrategySupplier;\n+            this.writeDemandEstimatorSupplier = writeDemandEstimatorSupplier;\n+        }\n+\n+        void run() {\n+            final PublisherSource<Resp> src;\n+            try {\n+                src = toSource(connection.write(requestPublisher, flushStrategySupplier,\n+                        writeDemandEstimatorSupplier)\n+                        .afterFinally(() -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e67ddd3040b7d00c14ad7c8da5750ac327447447"}, "originalPosition": 243}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjg4NjUzNA==", "bodyText": "firstReadSubscriber => nextReadSubscriber?", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r416886534", "createdAt": "2020-04-28T20:02:23Z", "author": {"login": "NiteshKant"}, "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,362 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.PublisherSource.Subscriber;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.concurrent.internal.ConcurrentUtils;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimators;\n+\n+import io.netty.channel.Channel;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static io.servicetalk.concurrent.internal.ConcurrentUtils.releaseLock;\n+import static io.servicetalk.concurrent.internal.ConcurrentUtils.tryAcquireLock;\n+import static io.servicetalk.concurrent.internal.SubscriberUtils.deliverTerminalFromSource;\n+import static io.servicetalk.utils.internal.PlatformDependent.newUnboundedMpscQueue;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.atomic.AtomicIntegerFieldUpdater.newUpdater;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicIntegerFieldUpdater<NettyPipelinedConnection> writeQueueLockUpdater =\n+            newUpdater(NettyPipelinedConnection.class, \"writeQueueLock\");\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicIntegerFieldUpdater<NettyPipelinedConnection> readQueueLockUpdater =\n+            newUpdater(NettyPipelinedConnection.class, \"readQueueLock\");\n+    private final NettyConnection<Resp, Req> connection;\n+    private final Queue<WriteTask> writeQueue;\n+    private final Queue<Subscriber<? super Resp>> readQueue;\n+    @SuppressWarnings(\"unused\")\n+    private volatile int writeQueueLock;\n+    @SuppressWarnings(\"unused\")\n+    private volatile int readQueueLock;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+        writeQueue = newUnboundedMpscQueue();\n+        readQueue = newUnboundedMpscQueue();\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher) {\n+        return write(requestPublisher, connection::defaultFlushStrategy, WriteDemandEstimators::newDefaultEstimator);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+        return new Publisher<Resp>() {\n+            @Override\n+            protected void handleSubscribe(final Subscriber<? super Resp> subscriber) {\n+                final WriteTask firstWriteTask;\n+                try {\n+                    firstWriteTask = offerTryAcquireLock(writeQueue, writeQueueLockUpdater,\n+                            new WriteTask(subscriber, requestPublisher, flushStrategySupplier,\n+                                    writeDemandEstimatorSupplier));\n+                } catch (Throwable cause) {\n+                    closeConnection(subscriber, cause);\n+                    return;\n+                }\n+\n+                if (firstWriteTask != null) {\n+                    firstWriteTask.run();\n+                }\n+            }\n+        };\n+    }\n+\n+    @Override\n+    public SocketAddress localAddress() {\n+        return connection.localAddress();\n+    }\n+\n+    @Override\n+    public SocketAddress remoteAddress() {\n+        return connection.remoteAddress();\n+    }\n+\n+    @Override\n+    @Nullable\n+    public SSLSession sslSession() {\n+        return connection.sslSession();\n+    }\n+\n+    @Override\n+    public ExecutionContext executionContext() {\n+        return connection.executionContext();\n+    }\n+\n+    @Nullable\n+    @Override\n+    public <T> T socketOption(final SocketOption<T> option) {\n+        return connection.socketOption(option);\n+    }\n+\n+    @Override\n+    public Protocol protocol() {\n+        return connection.protocol();\n+    }\n+\n+    @Override\n+    public Single<Throwable> transportError() {\n+        return connection.transportError();\n+    }\n+\n+    @Override\n+    public Completable onClosing() {\n+        return connection.onClosing();\n+    }\n+\n+    @Override\n+    public Completable onClose() {\n+        return connection.onClose();\n+    }\n+\n+    @Override\n+    public Completable closeAsync() {\n+        return connection.closeAsync();\n+    }\n+\n+    @Override\n+    public Completable closeAsyncGracefully() {\n+        return connection.closeAsyncGracefully();\n+    }\n+\n+    @Override\n+    public Channel nettyChannel() {\n+        return connection.nettyChannel();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return getClass().getSimpleName() + '(' + connection + ')';\n+    }\n+\n+    @Override\n+    public Cancellable updateFlushStrategy(final NettyConnectionContext.FlushStrategyProvider strategyProvider) {\n+        return connection.updateFlushStrategy(strategyProvider);\n+    }\n+\n+    @Override\n+    public FlushStrategy defaultFlushStrategy() {\n+        return connection.defaultFlushStrategy();\n+    }\n+\n+    private void closeConnection(final Subscriber<? super Resp> subscriber, final Throwable cause) {\n+        toSource(connection.closeAsync().concat(Publisher.<Resp>failed(cause))).subscribe(subscriber);\n+    }\n+\n+    private void tryStartRead(@Nullable Subscriber<? super Resp> subscriber) {\n+        if (subscriber == null) {\n+            return;\n+        }\n+        final PublisherSource<Resp> src;\n+        try {\n+            src = toSource(connection.read().afterFinally(() ->\n+                    tryStartRead(pollWithLockAcquired(readQueue, readQueueLockUpdater))));\n+        } catch (Throwable cause) {\n+            handleReadSetupError(subscriber, cause);\n+            return;\n+        }\n+        src.subscribe(subscriber);\n+    }\n+\n+    private final class WriteTask {\n+        private final Subscriber<? super Resp> subscriber;\n+        private final Publisher<Req> requestPublisher;\n+        private final Supplier<FlushStrategy> flushStrategySupplier;\n+        private final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier;\n+\n+        private WriteTask(final Subscriber<? super Resp> subscriber,\n+                          final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+            this.subscriber = subscriber;\n+            this.requestPublisher = requestPublisher;\n+            this.flushStrategySupplier = flushStrategySupplier;\n+            this.writeDemandEstimatorSupplier = writeDemandEstimatorSupplier;\n+        }\n+\n+        void run() {\n+            final PublisherSource<Resp> src;\n+            try {\n+                src = toSource(connection.write(requestPublisher, flushStrategySupplier,\n+                        writeDemandEstimatorSupplier)\n+                        .afterFinally(() -> {\n+                            WriteTask nextWriteTask = pollWithLockAcquired(writeQueue, writeQueueLockUpdater);\n+                            if (nextWriteTask != null) {\n+                                nextWriteTask.run();\n+                            }\n+                        }).merge(new Publisher<Resp>() {\n+                            @Override\n+                            protected void handleSubscribe(final Subscriber<? super Resp> rSubscriber) {\n+                                final Subscriber<? super Resp> firstReadSubscriber;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e67ddd3040b7d00c14ad7c8da5750ac327447447"}, "originalPosition": 251}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjg4Nzk4Mw==", "bodyText": "nit: move this method to the WriteTask as thats where it is used.", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r416887983", "createdAt": "2020-04-28T20:05:11Z", "author": {"login": "NiteshKant"}, "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,362 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.PublisherSource.Subscriber;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.concurrent.internal.ConcurrentUtils;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimators;\n+\n+import io.netty.channel.Channel;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static io.servicetalk.concurrent.internal.ConcurrentUtils.releaseLock;\n+import static io.servicetalk.concurrent.internal.ConcurrentUtils.tryAcquireLock;\n+import static io.servicetalk.concurrent.internal.SubscriberUtils.deliverTerminalFromSource;\n+import static io.servicetalk.utils.internal.PlatformDependent.newUnboundedMpscQueue;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.atomic.AtomicIntegerFieldUpdater.newUpdater;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicIntegerFieldUpdater<NettyPipelinedConnection> writeQueueLockUpdater =\n+            newUpdater(NettyPipelinedConnection.class, \"writeQueueLock\");\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicIntegerFieldUpdater<NettyPipelinedConnection> readQueueLockUpdater =\n+            newUpdater(NettyPipelinedConnection.class, \"readQueueLock\");\n+    private final NettyConnection<Resp, Req> connection;\n+    private final Queue<WriteTask> writeQueue;\n+    private final Queue<Subscriber<? super Resp>> readQueue;\n+    @SuppressWarnings(\"unused\")\n+    private volatile int writeQueueLock;\n+    @SuppressWarnings(\"unused\")\n+    private volatile int readQueueLock;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+        writeQueue = newUnboundedMpscQueue();\n+        readQueue = newUnboundedMpscQueue();\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher) {\n+        return write(requestPublisher, connection::defaultFlushStrategy, WriteDemandEstimators::newDefaultEstimator);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+        return new Publisher<Resp>() {\n+            @Override\n+            protected void handleSubscribe(final Subscriber<? super Resp> subscriber) {\n+                final WriteTask firstWriteTask;\n+                try {\n+                    firstWriteTask = offerTryAcquireLock(writeQueue, writeQueueLockUpdater,\n+                            new WriteTask(subscriber, requestPublisher, flushStrategySupplier,\n+                                    writeDemandEstimatorSupplier));\n+                } catch (Throwable cause) {\n+                    closeConnection(subscriber, cause);\n+                    return;\n+                }\n+\n+                if (firstWriteTask != null) {\n+                    firstWriteTask.run();\n+                }\n+            }\n+        };\n+    }\n+\n+    @Override\n+    public SocketAddress localAddress() {\n+        return connection.localAddress();\n+    }\n+\n+    @Override\n+    public SocketAddress remoteAddress() {\n+        return connection.remoteAddress();\n+    }\n+\n+    @Override\n+    @Nullable\n+    public SSLSession sslSession() {\n+        return connection.sslSession();\n+    }\n+\n+    @Override\n+    public ExecutionContext executionContext() {\n+        return connection.executionContext();\n+    }\n+\n+    @Nullable\n+    @Override\n+    public <T> T socketOption(final SocketOption<T> option) {\n+        return connection.socketOption(option);\n+    }\n+\n+    @Override\n+    public Protocol protocol() {\n+        return connection.protocol();\n+    }\n+\n+    @Override\n+    public Single<Throwable> transportError() {\n+        return connection.transportError();\n+    }\n+\n+    @Override\n+    public Completable onClosing() {\n+        return connection.onClosing();\n+    }\n+\n+    @Override\n+    public Completable onClose() {\n+        return connection.onClose();\n+    }\n+\n+    @Override\n+    public Completable closeAsync() {\n+        return connection.closeAsync();\n+    }\n+\n+    @Override\n+    public Completable closeAsyncGracefully() {\n+        return connection.closeAsyncGracefully();\n+    }\n+\n+    @Override\n+    public Channel nettyChannel() {\n+        return connection.nettyChannel();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return getClass().getSimpleName() + '(' + connection + ')';\n+    }\n+\n+    @Override\n+    public Cancellable updateFlushStrategy(final NettyConnectionContext.FlushStrategyProvider strategyProvider) {\n+        return connection.updateFlushStrategy(strategyProvider);\n+    }\n+\n+    @Override\n+    public FlushStrategy defaultFlushStrategy() {\n+        return connection.defaultFlushStrategy();\n+    }\n+\n+    private void closeConnection(final Subscriber<? super Resp> subscriber, final Throwable cause) {\n+        toSource(connection.closeAsync().concat(Publisher.<Resp>failed(cause))).subscribe(subscriber);\n+    }\n+\n+    private void tryStartRead(@Nullable Subscriber<? super Resp> subscriber) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e67ddd3040b7d00c14ad7c8da5750ac327447447"}, "originalPosition": 207}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNjg5MzQ0OA==", "bodyText": "Can we avoid calling external methods inside finally? eg: deliverTerminalFromSource can throw if both subscriber.onSubscribe()  and subscriber.onError() throw. Alternative:\nprivate void handleWriteSetupError(Subscriber<? super Resp> subscriber, Throwable cause) {\n    try {\n        closeConnection(subscriber, cause);\n    } catch (Throwable t) {\n        subscriber.onSubscribe(EMPTY_SUBSCRIPTION);\n        subscriber.onError(t);\n    }\n    // the lock has been acquired!\n    do {\n        WriteTask nextWriteTask;\n        while ((nextWriteTask = writeQueue.poll()) != null) {\n            deliverTerminalFromSource(nextWriteTask.subscriber, cause);\n        }\n    } while (!releaseLock(writeQueueLockUpdater, this) && tryAcquireLock(writeQueueLockUpdater, this));\n}\nOR just make sure closeConnection does not throw and remove the catch close above.", "url": "https://github.com/apple/servicetalk/pull/980#discussion_r416893448", "createdAt": "2020-04-28T20:14:53Z", "author": {"login": "NiteshKant"}, "path": "servicetalk-http-netty/src/main/java/io/servicetalk/http/netty/NettyPipelinedConnection.java", "diffHunk": "@@ -0,0 +1,362 @@\n+/*\n+ * Copyright \u00a9 2020 Apple Inc. and the ServiceTalk project authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package io.servicetalk.http.netty;\n+\n+import io.servicetalk.concurrent.Cancellable;\n+import io.servicetalk.concurrent.PublisherSource;\n+import io.servicetalk.concurrent.PublisherSource.Subscriber;\n+import io.servicetalk.concurrent.api.Completable;\n+import io.servicetalk.concurrent.api.Publisher;\n+import io.servicetalk.concurrent.api.Single;\n+import io.servicetalk.concurrent.internal.ConcurrentUtils;\n+import io.servicetalk.transport.api.ExecutionContext;\n+import io.servicetalk.transport.netty.internal.FlushStrategy;\n+import io.servicetalk.transport.netty.internal.NettyConnection;\n+import io.servicetalk.transport.netty.internal.NettyConnectionContext;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimator;\n+import io.servicetalk.transport.netty.internal.WriteDemandEstimators;\n+\n+import io.netty.channel.Channel;\n+\n+import java.net.SocketAddress;\n+import java.net.SocketOption;\n+import java.util.Queue;\n+import java.util.concurrent.atomic.AtomicIntegerFieldUpdater;\n+import java.util.function.Supplier;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLSession;\n+\n+import static io.servicetalk.concurrent.api.SourceAdapters.toSource;\n+import static io.servicetalk.concurrent.internal.ConcurrentUtils.releaseLock;\n+import static io.servicetalk.concurrent.internal.ConcurrentUtils.tryAcquireLock;\n+import static io.servicetalk.concurrent.internal.SubscriberUtils.deliverTerminalFromSource;\n+import static io.servicetalk.utils.internal.PlatformDependent.newUnboundedMpscQueue;\n+import static java.util.Objects.requireNonNull;\n+import static java.util.concurrent.atomic.AtomicIntegerFieldUpdater.newUpdater;\n+\n+/**\n+ * Contract for using a {@link NettyConnection} to make pipelined requests, typically for a client.\n+ * <p>\n+ * Pipelining allows to have concurrent requests processed on the server but still deliver responses in order.\n+ * This eliminates the need for request-response correlation, at the cost of head-of-line blocking.\n+ * @param <Req> Type of requests sent on this connection.\n+ * @param <Resp> Type of responses read from this connection.\n+ */\n+final class NettyPipelinedConnection<Req, Resp> implements NettyConnectionContext {\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicIntegerFieldUpdater<NettyPipelinedConnection> writeQueueLockUpdater =\n+            newUpdater(NettyPipelinedConnection.class, \"writeQueueLock\");\n+    @SuppressWarnings(\"rawtypes\")\n+    private static final AtomicIntegerFieldUpdater<NettyPipelinedConnection> readQueueLockUpdater =\n+            newUpdater(NettyPipelinedConnection.class, \"readQueueLock\");\n+    private final NettyConnection<Resp, Req> connection;\n+    private final Queue<WriteTask> writeQueue;\n+    private final Queue<Subscriber<? super Resp>> readQueue;\n+    @SuppressWarnings(\"unused\")\n+    private volatile int writeQueueLock;\n+    @SuppressWarnings(\"unused\")\n+    private volatile int readQueueLock;\n+\n+    /**\n+     * New instance.\n+     *\n+     * @param connection {@link NettyConnection} requests to which are to be pipelined.\n+     */\n+    NettyPipelinedConnection(NettyConnection<Resp, Req> connection) {\n+        this.connection = requireNonNull(connection);\n+        writeQueue = newUnboundedMpscQueue();\n+        readQueue = newUnboundedMpscQueue();\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher) {\n+        return write(requestPublisher, connection::defaultFlushStrategy, WriteDemandEstimators::newDefaultEstimator);\n+    }\n+\n+    /**\n+     * Do a write operation in a pipelined fashion.\n+     * @param requestPublisher {@link Publisher} representing the stream of data for a single \"request\".\n+     * @param flushStrategySupplier The {@link FlushStrategy} to use for this write operation.\n+     * @param writeDemandEstimatorSupplier A {@link Supplier} of {@link WriteDemandEstimator} for this request which\n+     * impacts how many elements are requested from the {@code requestPublisher} depending upon channel writability.\n+     * @return Response {@link Publisher} for this request.\n+     */\n+    Publisher<Resp> write(final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+        // Lazy modification of local state required (e.g. nodes, delayed subscriber, queue modifications)\n+        return new Publisher<Resp>() {\n+            @Override\n+            protected void handleSubscribe(final Subscriber<? super Resp> subscriber) {\n+                final WriteTask firstWriteTask;\n+                try {\n+                    firstWriteTask = offerTryAcquireLock(writeQueue, writeQueueLockUpdater,\n+                            new WriteTask(subscriber, requestPublisher, flushStrategySupplier,\n+                                    writeDemandEstimatorSupplier));\n+                } catch (Throwable cause) {\n+                    closeConnection(subscriber, cause);\n+                    return;\n+                }\n+\n+                if (firstWriteTask != null) {\n+                    firstWriteTask.run();\n+                }\n+            }\n+        };\n+    }\n+\n+    @Override\n+    public SocketAddress localAddress() {\n+        return connection.localAddress();\n+    }\n+\n+    @Override\n+    public SocketAddress remoteAddress() {\n+        return connection.remoteAddress();\n+    }\n+\n+    @Override\n+    @Nullable\n+    public SSLSession sslSession() {\n+        return connection.sslSession();\n+    }\n+\n+    @Override\n+    public ExecutionContext executionContext() {\n+        return connection.executionContext();\n+    }\n+\n+    @Nullable\n+    @Override\n+    public <T> T socketOption(final SocketOption<T> option) {\n+        return connection.socketOption(option);\n+    }\n+\n+    @Override\n+    public Protocol protocol() {\n+        return connection.protocol();\n+    }\n+\n+    @Override\n+    public Single<Throwable> transportError() {\n+        return connection.transportError();\n+    }\n+\n+    @Override\n+    public Completable onClosing() {\n+        return connection.onClosing();\n+    }\n+\n+    @Override\n+    public Completable onClose() {\n+        return connection.onClose();\n+    }\n+\n+    @Override\n+    public Completable closeAsync() {\n+        return connection.closeAsync();\n+    }\n+\n+    @Override\n+    public Completable closeAsyncGracefully() {\n+        return connection.closeAsyncGracefully();\n+    }\n+\n+    @Override\n+    public Channel nettyChannel() {\n+        return connection.nettyChannel();\n+    }\n+\n+    @Override\n+    public String toString() {\n+        return getClass().getSimpleName() + '(' + connection + ')';\n+    }\n+\n+    @Override\n+    public Cancellable updateFlushStrategy(final NettyConnectionContext.FlushStrategyProvider strategyProvider) {\n+        return connection.updateFlushStrategy(strategyProvider);\n+    }\n+\n+    @Override\n+    public FlushStrategy defaultFlushStrategy() {\n+        return connection.defaultFlushStrategy();\n+    }\n+\n+    private void closeConnection(final Subscriber<? super Resp> subscriber, final Throwable cause) {\n+        toSource(connection.closeAsync().concat(Publisher.<Resp>failed(cause))).subscribe(subscriber);\n+    }\n+\n+    private void tryStartRead(@Nullable Subscriber<? super Resp> subscriber) {\n+        if (subscriber == null) {\n+            return;\n+        }\n+        final PublisherSource<Resp> src;\n+        try {\n+            src = toSource(connection.read().afterFinally(() ->\n+                    tryStartRead(pollWithLockAcquired(readQueue, readQueueLockUpdater))));\n+        } catch (Throwable cause) {\n+            handleReadSetupError(subscriber, cause);\n+            return;\n+        }\n+        src.subscribe(subscriber);\n+    }\n+\n+    private final class WriteTask {\n+        private final Subscriber<? super Resp> subscriber;\n+        private final Publisher<Req> requestPublisher;\n+        private final Supplier<FlushStrategy> flushStrategySupplier;\n+        private final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier;\n+\n+        private WriteTask(final Subscriber<? super Resp> subscriber,\n+                          final Publisher<Req> requestPublisher,\n+                          final Supplier<FlushStrategy> flushStrategySupplier,\n+                          final Supplier<WriteDemandEstimator> writeDemandEstimatorSupplier) {\n+            this.subscriber = subscriber;\n+            this.requestPublisher = requestPublisher;\n+            this.flushStrategySupplier = flushStrategySupplier;\n+            this.writeDemandEstimatorSupplier = writeDemandEstimatorSupplier;\n+        }\n+\n+        void run() {\n+            final PublisherSource<Resp> src;\n+            try {\n+                src = toSource(connection.write(requestPublisher, flushStrategySupplier,\n+                        writeDemandEstimatorSupplier)\n+                        .afterFinally(() -> {\n+                            WriteTask nextWriteTask = pollWithLockAcquired(writeQueue, writeQueueLockUpdater);\n+                            if (nextWriteTask != null) {\n+                                nextWriteTask.run();\n+                            }\n+                        }).merge(new Publisher<Resp>() {\n+                            @Override\n+                            protected void handleSubscribe(final Subscriber<? super Resp> rSubscriber) {\n+                                final Subscriber<? super Resp> firstReadSubscriber;\n+                                try {\n+                                    firstReadSubscriber =\n+                                            offerTryAcquireLock(readQueue, readQueueLockUpdater, rSubscriber);\n+                                } catch (Throwable cause) {\n+                                    closeConnection(rSubscriber, cause);\n+                                    return;\n+                                }\n+\n+                                tryStartRead(firstReadSubscriber);\n+                            }\n+                        }));\n+            } catch (Throwable cause) {\n+                handleWriteSetupError(subscriber, cause);\n+                return;\n+            }\n+            src.subscribe(subscriber);\n+        }\n+    }\n+\n+    private void handleWriteSetupError(Subscriber<? super Resp> subscriber, Throwable cause) {\n+        try {\n+            closeConnection(subscriber, cause);\n+        } finally {\n+            // the lock has been acquired!\n+            do {\n+                WriteTask nextWriteTask;\n+                while ((nextWriteTask = writeQueue.poll()) != null) {\n+                    deliverTerminalFromSource(nextWriteTask.subscriber, cause);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e67ddd3040b7d00c14ad7c8da5750ac327447447"}, "originalPosition": 279}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1b990a298cc3d9f69425750b88df839f2f43e439", "author": {"user": {"login": "Scottmitch", "name": "Scott Mitchell"}}, "url": "https://github.com/apple/servicetalk/commit/1b990a298cc3d9f69425750b88df839f2f43e439", "committedDate": "2020-04-29T17:50:02Z", "message": "review comments, correct ordering of error notification when write error occurrs"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "217def034c7423a637126b2d5c1e94fd844e4925", "author": {"user": {"login": "Scottmitch", "name": "Scott Mitchell"}}, "url": "https://github.com/apple/servicetalk/commit/217def034c7423a637126b2d5c1e94fd844e4925", "committedDate": "2020-04-29T16:32:54Z", "message": "review comments, correct ordering of error notification when write error occurrs"}, "afterCommit": {"oid": "1b990a298cc3d9f69425750b88df839f2f43e439", "author": {"user": {"login": "Scottmitch", "name": "Scott Mitchell"}}, "url": "https://github.com/apple/servicetalk/commit/1b990a298cc3d9f69425750b88df839f2f43e439", "committedDate": "2020-04-29T17:50:02Z", "message": "review comments, correct ordering of error notification when write error occurrs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "889a52be8b2504bb8beb3d8714ae3962463c6795", "author": {"user": {"login": "Scottmitch", "name": "Scott Mitchell"}}, "url": "https://github.com/apple/servicetalk/commit/889a52be8b2504bb8beb3d8714ae3962463c6795", "committedDate": "2020-04-29T18:58:28Z", "message": "remove finally, release lock first"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "08daca46a471e1dfeec88b9a2a6748c66c1c4ad0", "author": {"user": {"login": "Scottmitch", "name": "Scott Mitchell"}}, "url": "https://github.com/apple/servicetalk/commit/08daca46a471e1dfeec88b9a2a6748c66c1c4ad0", "committedDate": "2020-04-29T19:13:32Z", "message": "move connection close up front"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3761, "cost": 1, "resetAt": "2021-11-01T11:59:11Z"}}}