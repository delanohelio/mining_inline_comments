{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDA4NTU3NzAz", "number": 7439, "title": "Update Deployment Docs", "bodyText": "Describe changes proposed in this pull request:\n\nDocument internal process for deploying importers during a release (e.g building importers)\n\nChecks\n\n Runs on heroku\n Has tests or has a separate issue that describes the types of test that should be created. If no test is included it should explicitly be mentioned in the PR why there is no test.\n The commit log is comprehensible. It follows 7 rules of great commit messages. For most PRs a single commit should suffice, in some cases multiple topical commits can be useful. During review it is ok to see tiny commits (e.g. Fix reviewer comments), but right before the code gets merged to master or rc branch, any such commits should be squashed since they are useless to the other developers. Definitely avoid merge commits, use rebase instead.\n Is this PR adding logic based on one or more clinical attributes? If yes, please make sure validation for this attribute is also present in the data validation / data loading layers (in backend repo) and documented in File-Formats Clinical data section!\n\nAny screenshots or GIFs?\nIf this is a new visual feature please add a before/after screenshot or gif\nhere with e.g. Giphy CAPTURE or Peek\nNotify reviewers\nRead our Pull request merging\npolicy. It can help to figure out who worked on the\nfile before you. Please use git blame <filename> to determine that\nand notify them either through slack or by assigning them as a reviewer on the PR", "createdAt": "2020-04-24T13:39:49Z", "url": "https://github.com/cBioPortal/cbioportal/pull/7439", "merged": true, "mergeCommit": {"oid": "c23e4203b468a26a9c31a66a533cc474ba7e3962"}, "closed": true, "closedAt": "2020-04-27T16:20:16Z", "author": {"login": "averyniceday"}, "timelineItems": {"totalCount": 16, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcYTU3TgH2gAyNDA4NTU3NzAzOmJiNGVhNDg0ODIzNTg3NmM1NTIxMDg0MWJiN2FlMmJjYmQyYWU5ZTI=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcbxRFngH2gAyNDA4NTU3NzAzOjYwNWZjZjUwZjVjYTJlNDQ4OGZhNmMyZTM4ZmJmYjIxODNiZjkxMjA=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "bb4ea4848235876c55210841bb7ae2bcbd2ae9e2", "author": {"user": {"login": "averyniceday", "name": null}}, "url": "https://github.com/cBioPortal/cbioportal/commit/bb4ea4848235876c55210841bb7ae2bcbd2ae9e2", "committedDate": "2020-04-16T21:11:15Z", "message": "Update Deployment-Procedure.md\n\nStart for Deployment stuff"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7ed9fe6cd0633b868ab8fb44edf1c6388ea3c79f", "author": {"user": {"login": "averyniceday", "name": null}}, "url": "https://github.com/cBioPortal/cbioportal/commit/7ed9fe6cd0633b868ab8fb44edf1c6388ea3c79f", "committedDate": "2020-04-17T14:03:19Z", "message": "Update Deployment-Procedure.md\n\nadd links and more info (crontab)"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5dc9aa8747b1747172da4c352604da9dda6f6129", "author": {"user": {"login": "averyniceday", "name": null}}, "url": "https://github.com/cBioPortal/cbioportal/commit/5dc9aa8747b1747172da4c352604da9dda6f6129", "committedDate": "2020-04-17T14:04:17Z", "message": "Update Deployment-Procedure.md"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e211c69e26e149b05d192ba7d674a6679a2f337e", "author": {"user": {"login": "averyniceday", "name": null}}, "url": "https://github.com/cBioPortal/cbioportal/commit/e211c69e26e149b05d192ba7d674a6679a2f337e", "committedDate": "2020-04-17T14:11:13Z", "message": "Update Deployment-Procedure.md"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c35de43a699dc817d89136335879557dc1a2dd28", "author": {"user": {"login": "averyniceday", "name": null}}, "url": "https://github.com/cBioPortal/cbioportal/commit/c35de43a699dc817d89136335879557dc1a2dd28", "committedDate": "2020-04-17T16:29:09Z", "message": "Update Deployment-Procedure.md"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9111357688bcd26a8b63cd63b87a199498a88597", "author": {"user": {"login": "averyniceday", "name": null}}, "url": "https://github.com/cBioPortal/cbioportal/commit/9111357688bcd26a8b63cd63b87a199498a88597", "committedDate": "2020-04-17T16:29:33Z", "message": "Update Deployment-Procedure.md"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "05abc8b0259053ac009205270ce30793a7f024a8", "author": {"user": {"login": "averyniceday", "name": null}}, "url": "https://github.com/cBioPortal/cbioportal/commit/05abc8b0259053ac009205270ce30793a7f024a8", "committedDate": "2020-04-20T14:49:30Z", "message": "Update Deployment-Procedure.md"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f4b3cfed4318c95903c768dd73bff0ff0970dc60", "author": {"user": {"login": "averyniceday", "name": null}}, "url": "https://github.com/cBioPortal/cbioportal/commit/f4b3cfed4318c95903c768dd73bff0ff0970dc60", "committedDate": "2020-04-20T15:18:31Z", "message": "Update Deployment-Procedure.md"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0e4979df9b6408bf3fd59acea3da523549b39ad7", "author": {"user": {"login": "averyniceday", "name": null}}, "url": "https://github.com/cBioPortal/cbioportal/commit/0e4979df9b6408bf3fd59acea3da523549b39ad7", "committedDate": "2020-04-24T13:41:34Z", "message": "Update Deployment-Procedure.md"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "16539972f8f3bf0ff82f82eb3351dc43d10c4e5f", "author": {"user": {"login": "averyniceday", "name": null}}, "url": "https://github.com/cBioPortal/cbioportal/commit/16539972f8f3bf0ff82f82eb3351dc43d10c4e5f", "committedDate": "2020-04-27T15:05:31Z", "message": "Update Deployment-Procedure.md"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e80ff07306b78f7dfe1299c3bd6c9d6003954cdd", "author": {"user": {"login": "averyniceday", "name": null}}, "url": "https://github.com/cBioPortal/cbioportal/commit/e80ff07306b78f7dfe1299c3bd6c9d6003954cdd", "committedDate": "2020-04-27T15:06:21Z", "message": "Update Deployment-Procedure.md"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAxMDYwMTAw", "url": "https://github.com/cBioPortal/cbioportal/pull/7439#pullrequestreview-401060100", "createdAt": "2020-04-27T15:21:41Z", "commit": {"oid": "e80ff07306b78f7dfe1299c3bd6c9d6003954cdd"}, "state": "APPROVED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yN1QxNToyMTo0MVrOGMo6jA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yN1QxNTozMjoxMlrOGMpdeA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTkwNjQ0NA==", "bodyText": "add space between pipelines,log", "url": "https://github.com/cBioPortal/cbioportal/pull/7439#discussion_r415906444", "createdAt": "2020-04-27T15:21:41Z", "author": {"login": "sheridancbio"}, "path": "docs/Deployment-Procedure.md", "diffHunk": "@@ -170,3 +170,64 @@ The last step is to modify the frontend url file for the triage portal. Log in t\n ```\n echo 'https://cbioportal-frontend.netlify.com' > /srv/www/triage-tomcat/frontend_url_version_2_1_0.txt\n ```\n+\n+## Upgrading Related Backend Components\n+Backend upgrades involving the database schema, DAO classes, etc. require updates to databases and importers. CBioPortal has multiple databases (located both internally on pipelines and in AWS) backing different portals. Similarly there are multiple importers responsible for loading portal-specific data. Every database must be manually migrated on an individual basis; all importers/data fetchers can be updated simultaenously through an existing deployment script.\n+\n+Before upgrading, make sure to turn off import jobs in the crontab and alert the backend pipelines team (Avery, Angelica, Rob, Manda). \n+\n+To access the crontab, log in to pipelines,log in as cbioportal_importer: `sudo su - cbioportal_importer`, and run `crontab -e`. Comment out any lines that run import jobs, save, and exit. Make sure to uncomment these lines once the upgrade (database and importers) is complete. Lines that need to be commented out will be under the `Import Jobs` section, shown [here](https://github.com/knowledgesystems/cmo-pipelines/blob/942de83c0f9a731e301151d10dad73744cd9c9a0/import-scripts/mycrontab#L4).", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e80ff07306b78f7dfe1299c3bd6c9d6003954cdd"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTkxMTc5MA==", "bodyText": "typo : cbiportal -> cbioportal (or cBioPortal)", "url": "https://github.com/cBioPortal/cbioportal/pull/7439#discussion_r415911790", "createdAt": "2020-04-27T15:28:04Z", "author": {"login": "sheridancbio"}, "path": "docs/Deployment-Procedure.md", "diffHunk": "@@ -170,3 +170,64 @@ The last step is to modify the frontend url file for the triage portal. Log in t\n ```\n echo 'https://cbioportal-frontend.netlify.com' > /srv/www/triage-tomcat/frontend_url_version_2_1_0.txt\n ```\n+\n+## Upgrading Related Backend Components\n+Backend upgrades involving the database schema, DAO classes, etc. require updates to databases and importers. CBioPortal has multiple databases (located both internally on pipelines and in AWS) backing different portals. Similarly there are multiple importers responsible for loading portal-specific data. Every database must be manually migrated on an individual basis; all importers/data fetchers can be updated simultaenously through an existing deployment script.\n+\n+Before upgrading, make sure to turn off import jobs in the crontab and alert the backend pipelines team (Avery, Angelica, Rob, Manda). \n+\n+To access the crontab, log in to pipelines,log in as cbioportal_importer: `sudo su - cbioportal_importer`, and run `crontab -e`. Comment out any lines that run import jobs, save, and exit. Make sure to uncomment these lines once the upgrade (database and importers) is complete. Lines that need to be commented out will be under the `Import Jobs` section, shown [here](https://github.com/knowledgesystems/cmo-pipelines/blob/942de83c0f9a731e301151d10dad73744cd9c9a0/import-scripts/mycrontab#L4).\n+\n+## Updating Databases\n+First, make sure there is a backup of the database being migrated. \n+If there is not a weekly dump, backup the database being migrated using mysqldump. This process may take awhile depending on the size of the database. \n+\n+```\n+mysqldump -u <user> -h <host> -p <database name> | gzip > <database_name>_`date +%Y%m%d_%H%M`.sql.gz \n+```\n+    \n+The second step is to migrate the database. Make sure that the migration script is the same version as the deployed cBioPortal website. It is recommended to first test the migration script manually line-by-line in a copy of the existing database. This will catch any data-related bugs that might not be captured by the python migration script. After testing is successful, migrate the production databases following these steps [here](Updating-your-cBioPortal-installation.md#Running-the-migration-script). \n+\n+These are all cBioPortal databases and their locations:\n+| Website  | Database | Location |\n+| ------------- | ------------- | ------------- |\n+| cbioportal.mskcc.org  | cgds_gdac  | pipelines |\n+| cbioportal.org  | cgds_public  | AWS |\n+| genie.cbioportal.org | cgds_genie | AWS | \n+| triage.cbioportal.org | cgds_triage | pipelines |\n+\n+To obtain information such as usernames, passwords, hostnames - ask Avery, Angelica, Rob, Manda, and Ino. \n+\n+## Updating Importers/Data Fetchers\n+Importers (code found [here](https://github.com/knowledgesystems/pipelines)) and data fetchers (code found [here](https://github.com/knowledgesystems/cmo-pipelines)) use code from the cBioPortal codebase. The cbioportal dependency is packaged with the genome-nexus-annotation-pipeline and specified in the pipelines importer pom.\n+\n+The following steps are used during releases/updates to build new importers with the **most-up-to-date** cBioPortal and genome-nexus-annotation-pipeline code. All steps should be performed on the pipelines machine. \n+\n+1. Set the jitpack hash [here](https://github.com/genome-nexus/genome-nexus-annotation-pipeline/blob/9510299395986653d9e9b672a38d472e52e7625b/pom.xml#L71) in the genome-nexus-annotation-pipeline codebase to the most recent cbioportal/cbioportal commit hash in master.\n+\n+2. Merge this change into genome-nexus-annotation-pipeline/master.\n+\n+3. Set the commit hash [here](https://github.com/knowledgesystems/pipelines/blob/f6c52bbda86b3929222d42c9bc84581fd6333fb4/pom.xml#L76) in the pipelines codebase to the most most recent genome-nexus/genome-nexus-annotation-pipeline commit hash **(after merge specfied in step 2)**. Also ensure the db version in the pom [here](https://github.com/knowledgesystems/pipelines/blob/f6c52bbda86b3929222d42c9bc84581fd6333fb4/pom.xml#L76) matches the db schema version in the cbiportal codebase. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e80ff07306b78f7dfe1299c3bd6c9d6003954cdd"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTkxNDMzNQ==", "bodyText": "add a reminder to run git pull in the pipelines-configuration repo in order to make sure you have the latest updates to the build script.  maybe git status is a good idea too .. to see whether anybody left the build script in an edited / modified state from the previous run.", "url": "https://github.com/cBioPortal/cbioportal/pull/7439#discussion_r415914335", "createdAt": "2020-04-27T15:31:01Z", "author": {"login": "sheridancbio"}, "path": "docs/Deployment-Procedure.md", "diffHunk": "@@ -170,3 +170,64 @@ The last step is to modify the frontend url file for the triage portal. Log in t\n ```\n echo 'https://cbioportal-frontend.netlify.com' > /srv/www/triage-tomcat/frontend_url_version_2_1_0.txt\n ```\n+\n+## Upgrading Related Backend Components\n+Backend upgrades involving the database schema, DAO classes, etc. require updates to databases and importers. CBioPortal has multiple databases (located both internally on pipelines and in AWS) backing different portals. Similarly there are multiple importers responsible for loading portal-specific data. Every database must be manually migrated on an individual basis; all importers/data fetchers can be updated simultaenously through an existing deployment script.\n+\n+Before upgrading, make sure to turn off import jobs in the crontab and alert the backend pipelines team (Avery, Angelica, Rob, Manda). \n+\n+To access the crontab, log in to pipelines,log in as cbioportal_importer: `sudo su - cbioportal_importer`, and run `crontab -e`. Comment out any lines that run import jobs, save, and exit. Make sure to uncomment these lines once the upgrade (database and importers) is complete. Lines that need to be commented out will be under the `Import Jobs` section, shown [here](https://github.com/knowledgesystems/cmo-pipelines/blob/942de83c0f9a731e301151d10dad73744cd9c9a0/import-scripts/mycrontab#L4).\n+\n+## Updating Databases\n+First, make sure there is a backup of the database being migrated. \n+If there is not a weekly dump, backup the database being migrated using mysqldump. This process may take awhile depending on the size of the database. \n+\n+```\n+mysqldump -u <user> -h <host> -p <database name> | gzip > <database_name>_`date +%Y%m%d_%H%M`.sql.gz \n+```\n+    \n+The second step is to migrate the database. Make sure that the migration script is the same version as the deployed cBioPortal website. It is recommended to first test the migration script manually line-by-line in a copy of the existing database. This will catch any data-related bugs that might not be captured by the python migration script. After testing is successful, migrate the production databases following these steps [here](Updating-your-cBioPortal-installation.md#Running-the-migration-script). \n+\n+These are all cBioPortal databases and their locations:\n+| Website  | Database | Location |\n+| ------------- | ------------- | ------------- |\n+| cbioportal.mskcc.org  | cgds_gdac  | pipelines |\n+| cbioportal.org  | cgds_public  | AWS |\n+| genie.cbioportal.org | cgds_genie | AWS | \n+| triage.cbioportal.org | cgds_triage | pipelines |\n+\n+To obtain information such as usernames, passwords, hostnames - ask Avery, Angelica, Rob, Manda, and Ino. \n+\n+## Updating Importers/Data Fetchers\n+Importers (code found [here](https://github.com/knowledgesystems/pipelines)) and data fetchers (code found [here](https://github.com/knowledgesystems/cmo-pipelines)) use code from the cBioPortal codebase. The cbioportal dependency is packaged with the genome-nexus-annotation-pipeline and specified in the pipelines importer pom.\n+\n+The following steps are used during releases/updates to build new importers with the **most-up-to-date** cBioPortal and genome-nexus-annotation-pipeline code. All steps should be performed on the pipelines machine. \n+\n+1. Set the jitpack hash [here](https://github.com/genome-nexus/genome-nexus-annotation-pipeline/blob/9510299395986653d9e9b672a38d472e52e7625b/pom.xml#L71) in the genome-nexus-annotation-pipeline codebase to the most recent cbioportal/cbioportal commit hash in master.\n+\n+2. Merge this change into genome-nexus-annotation-pipeline/master.\n+\n+3. Set the commit hash [here](https://github.com/knowledgesystems/pipelines/blob/f6c52bbda86b3929222d42c9bc84581fd6333fb4/pom.xml#L76) in the pipelines codebase to the most most recent genome-nexus/genome-nexus-annotation-pipeline commit hash **(after merge specfied in step 2)**. Also ensure the db version in the pom [here](https://github.com/knowledgesystems/pipelines/blob/f6c52bbda86b3929222d42c9bc84581fd6333fb4/pom.xml#L76) matches the db schema version in the cbiportal codebase. \n+\n+4. Merge this change into pipelines/master.\n+\n+5. Set the commit hash [here](https://github.com/knowledgesystems/cmo-pipelines/blob/e740c9fa3d409ab75988e7a157682733e261fca5/cvr/pom.xml#L70) in the cmo-pipelines codebase to the most recent genome-nexus/genome-nexus-annotation-pipeline commit hash **(after merge specified in step 2)**\n+\n+6. Merge this change into cmo-pipelines/master\n+\n+7. Run the deployment wrapper script. See details [here](Deployment-Procedure.md#Deployment-Script).  \n+\n+8. Verify new importers/data fetchers have been placed in `/data/portal-cron/lib` by checking timestamps.\n+```\n+ls -tlra /data/portal-cron/lib\n+```\n+\n+## Deployment Script\n+The wrapper script is found on pipelines here:\n+`/data/portal-cron/git-repos/pipelines-configuration/build-importer-jars/buildproductionjars.sh`.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e80ff07306b78f7dfe1299c3bd6c9d6003954cdd"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNTkxNTM4NA==", "bodyText": "I would boldface \"step 1\" .. to emphasize that the deployer should use the cbioportal codebase hash from the start of the procedure .. no the genome-nexus-annotation-pipeline hash (which they were working with most recently)", "url": "https://github.com/cBioPortal/cbioportal/pull/7439#discussion_r415915384", "createdAt": "2020-04-27T15:32:12Z", "author": {"login": "sheridancbio"}, "path": "docs/Deployment-Procedure.md", "diffHunk": "@@ -170,3 +170,64 @@ The last step is to modify the frontend url file for the triage portal. Log in t\n ```\n echo 'https://cbioportal-frontend.netlify.com' > /srv/www/triage-tomcat/frontend_url_version_2_1_0.txt\n ```\n+\n+## Upgrading Related Backend Components\n+Backend upgrades involving the database schema, DAO classes, etc. require updates to databases and importers. CBioPortal has multiple databases (located both internally on pipelines and in AWS) backing different portals. Similarly there are multiple importers responsible for loading portal-specific data. Every database must be manually migrated on an individual basis; all importers/data fetchers can be updated simultaenously through an existing deployment script.\n+\n+Before upgrading, make sure to turn off import jobs in the crontab and alert the backend pipelines team (Avery, Angelica, Rob, Manda). \n+\n+To access the crontab, log in to pipelines,log in as cbioportal_importer: `sudo su - cbioportal_importer`, and run `crontab -e`. Comment out any lines that run import jobs, save, and exit. Make sure to uncomment these lines once the upgrade (database and importers) is complete. Lines that need to be commented out will be under the `Import Jobs` section, shown [here](https://github.com/knowledgesystems/cmo-pipelines/blob/942de83c0f9a731e301151d10dad73744cd9c9a0/import-scripts/mycrontab#L4).\n+\n+## Updating Databases\n+First, make sure there is a backup of the database being migrated. \n+If there is not a weekly dump, backup the database being migrated using mysqldump. This process may take awhile depending on the size of the database. \n+\n+```\n+mysqldump -u <user> -h <host> -p <database name> | gzip > <database_name>_`date +%Y%m%d_%H%M`.sql.gz \n+```\n+    \n+The second step is to migrate the database. Make sure that the migration script is the same version as the deployed cBioPortal website. It is recommended to first test the migration script manually line-by-line in a copy of the existing database. This will catch any data-related bugs that might not be captured by the python migration script. After testing is successful, migrate the production databases following these steps [here](Updating-your-cBioPortal-installation.md#Running-the-migration-script). \n+\n+These are all cBioPortal databases and their locations:\n+| Website  | Database | Location |\n+| ------------- | ------------- | ------------- |\n+| cbioportal.mskcc.org  | cgds_gdac  | pipelines |\n+| cbioportal.org  | cgds_public  | AWS |\n+| genie.cbioportal.org | cgds_genie | AWS | \n+| triage.cbioportal.org | cgds_triage | pipelines |\n+\n+To obtain information such as usernames, passwords, hostnames - ask Avery, Angelica, Rob, Manda, and Ino. \n+\n+## Updating Importers/Data Fetchers\n+Importers (code found [here](https://github.com/knowledgesystems/pipelines)) and data fetchers (code found [here](https://github.com/knowledgesystems/cmo-pipelines)) use code from the cBioPortal codebase. The cbioportal dependency is packaged with the genome-nexus-annotation-pipeline and specified in the pipelines importer pom.\n+\n+The following steps are used during releases/updates to build new importers with the **most-up-to-date** cBioPortal and genome-nexus-annotation-pipeline code. All steps should be performed on the pipelines machine. \n+\n+1. Set the jitpack hash [here](https://github.com/genome-nexus/genome-nexus-annotation-pipeline/blob/9510299395986653d9e9b672a38d472e52e7625b/pom.xml#L71) in the genome-nexus-annotation-pipeline codebase to the most recent cbioportal/cbioportal commit hash in master.\n+\n+2. Merge this change into genome-nexus-annotation-pipeline/master.\n+\n+3. Set the commit hash [here](https://github.com/knowledgesystems/pipelines/blob/f6c52bbda86b3929222d42c9bc84581fd6333fb4/pom.xml#L76) in the pipelines codebase to the most most recent genome-nexus/genome-nexus-annotation-pipeline commit hash **(after merge specfied in step 2)**. Also ensure the db version in the pom [here](https://github.com/knowledgesystems/pipelines/blob/f6c52bbda86b3929222d42c9bc84581fd6333fb4/pom.xml#L76) matches the db schema version in the cbiportal codebase. \n+\n+4. Merge this change into pipelines/master.\n+\n+5. Set the commit hash [here](https://github.com/knowledgesystems/cmo-pipelines/blob/e740c9fa3d409ab75988e7a157682733e261fca5/cvr/pom.xml#L70) in the cmo-pipelines codebase to the most recent genome-nexus/genome-nexus-annotation-pipeline commit hash **(after merge specified in step 2)**\n+\n+6. Merge this change into cmo-pipelines/master\n+\n+7. Run the deployment wrapper script. See details [here](Deployment-Procedure.md#Deployment-Script).  \n+\n+8. Verify new importers/data fetchers have been placed in `/data/portal-cron/lib` by checking timestamps.\n+```\n+ls -tlra /data/portal-cron/lib\n+```\n+\n+## Deployment Script\n+The wrapper script is found on pipelines here:\n+`/data/portal-cron/git-repos/pipelines-configuration/build-importer-jars/buildproductionjars.sh`.\n+\n+The wrapper script takes two arguments:\n+1. --cbioportal-git-hash (required): Set to the cBioPortal commit hash being used in the pipelines build (hash specified in step 1 of [updating importers](#Updating-Importers). This must match because the build copies out resource files (e.g application-context-business.xml) from the cbioportal codebase. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e80ff07306b78f7dfe1299c3bd6c9d6003954cdd"}, "originalPosition": 61}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2169a18759f1b94543f9b94606745060930da3e4", "author": {"user": {"login": "averyniceday", "name": null}}, "url": "https://github.com/cBioPortal/cbioportal/commit/2169a18759f1b94543f9b94606745060930da3e4", "committedDate": "2020-04-27T15:36:26Z", "message": "Update Deployment-Procedure.md"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d36e3ff069f82bfae7a10cd550cd872cd8f1f07e", "author": {"user": {"login": "averyniceday", "name": null}}, "url": "https://github.com/cBioPortal/cbioportal/commit/d36e3ff069f82bfae7a10cd550cd872cd8f1f07e", "committedDate": "2020-04-27T15:39:35Z", "message": "Update Deployment-Procedure.md"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ccb872fb8d72d5705a69abcb56e9030e8ebdac22", "author": {"user": {"login": "averyniceday", "name": null}}, "url": "https://github.com/cBioPortal/cbioportal/commit/ccb872fb8d72d5705a69abcb56e9030e8ebdac22", "committedDate": "2020-04-27T15:43:33Z", "message": "Update Deployment-Procedure.md"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "605fcf50f5ca2e4488fa6c2e38fbfb2183bf9120", "author": {"user": {"login": "averyniceday", "name": null}}, "url": "https://github.com/cBioPortal/cbioportal/commit/605fcf50f5ca2e4488fa6c2e38fbfb2183bf9120", "committedDate": "2020-04-27T15:46:03Z", "message": "Update Deployment-Procedure.md"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1765, "cost": 1, "resetAt": "2021-11-01T13:07:16Z"}}}