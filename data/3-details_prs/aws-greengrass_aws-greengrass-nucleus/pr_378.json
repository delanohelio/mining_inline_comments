{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDcxODcwOTc3", "number": 378, "title": "Telemetry service to log kernel component state metrics", "bodyText": "Description of changes:\n\nCreated a telemetry service which starts with the kernel.\nThis service aggregates the metrics periodically based on the aggregation interval configured by reading the ~root/telemetry directory which has the log files for each namespace.\nAfter aggregation and accumulation of data points, the metrics are published to telemetry mqtt topic periodically based on the publish interval.\n\nBy submitting this pull request, I confirm that you can use, modify, copy, and redistribute this contribution, under the terms of your choice.", "createdAt": "2020-08-21T21:55:02Z", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378", "merged": true, "mergeCommit": {"oid": "f4e27cfc286b6e4468175ea5ed188749f54dac76"}, "closed": true, "closedAt": "2020-09-25T16:20:36Z", "author": {"login": "saranyailla"}, "timelineItems": {"totalCount": 148, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdLOQqCAH2gAyNDcxODcwOTc3OjE2YjJkMDRlMjM2NTM0YThiNjkwZjA1NWI4MzhmMzc0ZmNiMDBiMDI=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdMXx05AFqTQ5NjU0MDk0Ng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "16b2d04e236534a8b690f055b838f374fcb00b02", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/16b2d04e236534a8b690f055b838f374fcb00b02", "committedDate": "2020-09-22T02:07:16Z", "message": "update tests + test utils"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7f377ece01d65c38afeba3647580d88ecd9b750a", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/7f377ece01d65c38afeba3647580d88ecd9b750a", "committedDate": "2020-09-22T05:36:30Z", "message": "close context afterEach"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ad7266b7ccd2dd40abdf3bf031c9c5e6e93168e3", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/ad7266b7ccd2dd40abdf3bf031c9c5e6e93168e3", "committedDate": "2020-09-22T07:00:08Z", "message": "close context afterEach"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "663a72a747d0e3296eaef1b02e4bd1a1dd9aee42", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/663a72a747d0e3296eaef1b02e4bd1a1dd9aee42", "committedDate": "2020-09-22T07:01:47Z", "message": "Merge branch 'telemetry-logs' of github.com:/aws/aws-greengrass-kernel into telemetry-logs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5fbfd960435c0016a8b9d0f17f14a2211b9ef933", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/5fbfd960435c0016a8b9d0f17f14a2211b9ef933", "committedDate": "2020-09-22T19:04:04Z", "message": "update kernelComponents to GreengrassComponents"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e22abcb43550efb8e08c9b2e837eebd997a98f4a", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/e22abcb43550efb8e08c9b2e837eebd997a98f4a", "committedDate": "2020-09-22T19:04:34Z", "message": "Merge branch 'master' of github.com:/aws/aws-greengrass-kernel into telemetry-logs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a8dd452d086596145dbc618b6108a9adddb6c463", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/a8dd452d086596145dbc618b6108a9adddb6c463", "committedDate": "2020-09-22T20:45:18Z", "message": "update publish topic"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "73660164430ebf1cd0f54b13c61cc0e9a75a08ec", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/73660164430ebf1cd0f54b13c61cc0e9a75a08ec", "committedDate": "2020-09-22T20:58:22Z", "message": "update publish topic"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "46f3f153c4aae98e0f30103ed5a1e97c785b9cb5", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/46f3f153c4aae98e0f30103ed5a1e97c785b9cb5", "committedDate": "2020-09-22T20:59:13Z", "message": "Merge branch 'telemetry-logs' of github.com:/aws/aws-greengrass-kernel into telemetry-logs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f76a4fb43a83d166a6362bdf7d197ab8d3de5436", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/f76a4fb43a83d166a6362bdf7d197ab8d3de5436", "committedDate": "2020-09-23T00:49:21Z", "message": "Use single metric factory for all the tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "593c73f5f9ccfbaec204eda8bcece7582d6a2871", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/593c73f5f9ccfbaec204eda8bcece7582d6a2871", "committedDate": "2020-09-23T03:24:33Z", "message": "integ tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c194bdf0c6f5b4bc75e57efb91fe8a3d31044c0b", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/c194bdf0c6f5b4bc75e57efb91fe8a3d31044c0b", "committedDate": "2020-09-23T03:24:51Z", "message": "Merge branch 'master' of github.com:/aws/aws-greengrass-kernel into telemetry-logs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d977bc1a3ef114e4227fd40a741007294c886b19", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/d977bc1a3ef114e4227fd40a741007294c886b19", "committedDate": "2020-09-23T10:13:03Z", "message": "integ tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1f5ec3bc87d3be6d9bf072fffd46bd39219aedd5", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/1f5ec3bc87d3be6d9bf072fffd46bd39219aedd5", "committedDate": "2020-09-23T17:56:32Z", "message": "update tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/b2fcd1439f7efc3383cdbf81748de09d0311fc4e", "committedDate": "2020-09-23T17:57:05Z", "message": "Merge branch 'master' of github.com:/aws/aws-greengrass-kernel into telemetry-logs"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk0OTY1ODEy", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-494965812", "createdAt": "2020-09-23T19:05:11Z", "commit": {"oid": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e"}, "state": "COMMENTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QxOTowNToxMVrOHW9A-A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QxOToxOTozOVrOHW9e3w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzMDM5Mg==", "bodyText": "new AtomicReference(new ArrayList<>)", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493830392", "createdAt": "2020-09-23T19:05:11Z", "author": {"login": "MikeDombo"}, "path": "src/integrationtests/java/com/aws/greengrass/integrationtests/e2e/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,127 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.greengrass.integrationtests.e2e.telemetry;\n+\n+import com.aws.greengrass.config.Topics;\n+import com.aws.greengrass.dependency.State;\n+import com.aws.greengrass.integrationtests.e2e.BaseE2ETestCase;\n+import com.aws.greengrass.lifecyclemanager.exceptions.ServiceLoadException;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.SubscribeRequest;\n+import com.aws.greengrass.telemetry.MetricsPayload;\n+import com.aws.greengrass.telemetry.TelemetryAgent;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import software.amazon.awssdk.crt.mqtt.MqttMessage;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_METRICS_PUBLISH_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+\n+@SuppressWarnings(\"PMD.CloseResource\")\n+@ExtendWith(GGExtension.class)\n+@Tag(\"E2E\")\n+public class TelemetryAgentTest extends BaseE2ETestCase {\n+    private static final ObjectMapper DESERIALIZER = new ObjectMapper();\n+\n+    protected TelemetryAgentTest() throws Exception {\n+        super();\n+    }\n+\n+    @AfterEach\n+    void afterEach() {\n+        try {\n+            if (kernel != null) {\n+                kernel.shutdown();\n+            }\n+        } finally {\n+            // Cleanup all IoT thing resources we created\n+            cleanup();\n+        }\n+    }\n+\n+    @BeforeEach\n+    void launchKernel() throws Exception {\n+        initKernel();\n+        kernel.launch();\n+    }\n+\n+    @Test\n+    void GIVEN_kernel_running_WHEN_telemetry_agent_starts_THEN_metrics_are_published_to_Cloud() throws\n+            InterruptedException, ExecutionException, TimeoutException, ServiceLoadException {\n+        /*\n+         Metrics agent is an auto-start service. It publishes data to the cloud irrespective of the deployments.\n+         In this test, we just start the kernel and expect MA to publish time-based metrics such as system metrics and\n+         kernel component state metrics in the given interval.\n+        */\n+        MqttClient client = kernel.getContext().get(MqttClient.class);\n+        CountDownLatch cdl = new CountDownLatch(1);\n+        AtomicReference<List<MqttMessage>> mqttMessagesList = new AtomicReference<>();\n+        mqttMessagesList.set(new ArrayList<>());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e"}, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzMDcyMg==", "bodyText": "the client is mocked, so you don't really need to close it", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493830722", "createdAt": "2020-09-23T19:05:49Z", "author": {"login": "MikeDombo"}, "path": "src/integrationtests/java/com/aws/greengrass/integrationtests/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,127 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.greengrass.integrationtests.telemetry;\n+\n+import com.aws.greengrass.config.Topics;\n+import com.aws.greengrass.dependency.State;\n+import com.aws.greengrass.integrationtests.BaseITCase;\n+import com.aws.greengrass.lifecyclemanager.Kernel;\n+import com.aws.greengrass.lifecyclemanager.exceptions.ServiceLoadException;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.MetricsAggregator;\n+import com.aws.greengrass.telemetry.MetricsPayload;\n+import com.aws.greengrass.telemetry.TelemetryAgent;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.TestInfo;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.verify;\n+\n+@ExtendWith({GGExtension.class, MockitoExtension.class})\n+class TelemetryAgentTest extends BaseITCase {\n+    private Kernel kernel;\n+    @Mock\n+    private MqttClient mqttClient;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> captor;\n+\n+    @BeforeEach\n+    void before(TestInfo testInfo) {\n+        System.out.println(\"Running test: \" + testInfo.getDisplayName());\n+        kernel = new Kernel();\n+    }\n+\n+    @AfterEach\n+    void after() {\n+        if (kernel != null) {\n+            mqttClient.close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e"}, "originalPosition": 66}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzMTYxNw==", "bodyText": "instead of this, can you just check the topic that it is writing to? if it fails to deserialize, that ought to be a problem and fail the test.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493831617", "createdAt": "2020-09-23T19:07:32Z", "author": {"login": "MikeDombo"}, "path": "src/integrationtests/java/com/aws/greengrass/integrationtests/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,127 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.greengrass.integrationtests.telemetry;\n+\n+import com.aws.greengrass.config.Topics;\n+import com.aws.greengrass.dependency.State;\n+import com.aws.greengrass.integrationtests.BaseITCase;\n+import com.aws.greengrass.lifecyclemanager.Kernel;\n+import com.aws.greengrass.lifecyclemanager.exceptions.ServiceLoadException;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.MetricsAggregator;\n+import com.aws.greengrass.telemetry.MetricsPayload;\n+import com.aws.greengrass.telemetry.TelemetryAgent;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.TestInfo;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.verify;\n+\n+@ExtendWith({GGExtension.class, MockitoExtension.class})\n+class TelemetryAgentTest extends BaseITCase {\n+    private Kernel kernel;\n+    @Mock\n+    private MqttClient mqttClient;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> captor;\n+\n+    @BeforeEach\n+    void before(TestInfo testInfo) {\n+        System.out.println(\"Running test: \" + testInfo.getDisplayName());\n+        kernel = new Kernel();\n+    }\n+\n+    @AfterEach\n+    void after() {\n+        if (kernel != null) {\n+            mqttClient.close();\n+            kernel.shutdown();\n+        }\n+    }\n+\n+    @Test\n+    void GIVEN_kernel_running_with_telemetry_config_WHEN_launch_THEN_metrics_are_published() throws InterruptedException,\n+            ServiceLoadException {\n+        // GIVEN\n+        kernel.parseArgs(\"-i\", getClass().getResource(\"config.yaml\").toString());\n+        CountDownLatch mainRunning = new CountDownLatch(2);\n+        kernel.getContext().addGlobalStateChangeListener((service, oldState, newState) -> {\n+            if (service.getName().equals(\"main\") && newState.equals(State.RUNNING)) {\n+                mainRunning.countDown();\n+            }\n+        });\n+        kernel.getContext().put(MqttClient.class, mqttClient);\n+        //WHEN\n+        kernel.launch();\n+\n+        Topics parameterTopics = kernel.getConfig()\n+                .lookupTopics(SERVICES_NAMESPACE_TOPIC, TELEMETRY_AGENT_SERVICE_TOPICS, PARAMETERS_CONFIG_KEY);\n+        int aggregateInterval = Coerce.toInt(parameterTopics.find(TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC));\n+        int periodicInterval = Coerce.toInt(parameterTopics.find(TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC));\n+        //telemetry configurations are set correctly\n+        assertEquals(3, aggregateInterval);\n+        assertEquals(2, periodicInterval);\n+        Topics runtimeTopics = kernel.getConfig()\n+                .lookupTopics(SERVICES_NAMESPACE_TOPIC, TELEMETRY_AGENT_SERVICE_TOPICS, RUNTIME_STORE_NAMESPACE_TOPIC);\n+        long lastAgg = Coerce.toLong(runtimeTopics.find(TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC));\n+\n+        //wait for at least 4 seconds as the first aggregation occurs at 3rd second.\n+        Thread.sleep(4000);\n+        assertTrue(Coerce.toLong(runtimeTopics.find(TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC)) > lastAgg);\n+\n+        TelemetryAgent ma = (TelemetryAgent) kernel.locate(\"TelemetryAgent\");\n+        long delay = ma.getPeriodicPublishMetricsFuture().getDelay(TimeUnit.SECONDS);\n+        assertTrue(delay < periodicInterval);\n+        // telemetry logs are always written to ~root/telemetry\n+        assertEquals(kernel.getRootPath().resolve(\"telemetry\"), TelemetryConfig.getTelemetryDirectory());\n+        // THEN\n+        verify(mqttClient, timeout(1000).atLeastOnce()).publish(captor.capture());\n+        List<PublishRequest> prs = captor.getAllValues();\n+        for (PublishRequest pr : prs) {\n+            try {\n+                MetricsPayload mp = new ObjectMapper().readValue(pr.getPayload(), MetricsPayload.class);\n+                //There will be nothing to aggregate as publish happens at 1st second and aggregation at 2nd second.\n+                // So, there will only one accumulated data point for each namespace during the first publish\n+                assertEquals(kernel.getContext().get(MetricsAggregator.class)\n+                        .getNamespaceSet().getNamespaces().size(), mp.getAggregatedMetricList().size());\n+                assertEquals(QualityOfService.AT_LEAST_ONCE, pr.getQos());\n+                assertEquals(DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC.replace(\"{thingName}\", \"\"), pr.getTopic());\n+                assertEquals(\"2020-07-30\", mp.getSchema());\n+                // enough to verify the first message of type MetricsPayload\n+                break;\n+            } catch (IOException e) {\n+                System.out.println(\"Ignore if the publish message is not of MetricsPayload type\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e"}, "originalPosition": 122}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzMjQzMw==", "bodyText": "do this after everything has shutdown since otherwise you may be losing telemetry.\nMaybe put it right before the context close", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493832433", "createdAt": "2020-09-23T19:09:04Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/greengrass/lifecyclemanager/KernelLifecycle.java", "diffHunk": "@@ -255,6 +256,8 @@ public void shutdown(int timeoutSeconds) {\n             return;\n         }\n         close(tlog);\n+        //close the telemetry logger context\n+        TelemetryConfig.getInstance().closeContext();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzMzI3OA==", "bodyText": "if connection flips on and off very quickly, will this be doing the right thing?\nWhy do you re-schedule when the connection is resumed? Isn't the old schedule still going fine?", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493833278", "createdAt": "2020-09-23T19:10:38Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/greengrass/telemetry/TelemetryAgent.java", "diffHunk": "@@ -0,0 +1,271 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.greengrass.telemetry;\n+\n+import com.aws.greengrass.config.Topic;\n+import com.aws.greengrass.config.Topics;\n+import com.aws.greengrass.dependency.ImplementsService;\n+import com.aws.greengrass.deployment.DeviceConfiguration;\n+import com.aws.greengrass.lifecyclemanager.GreengrassService;\n+import com.aws.greengrass.lifecyclemanager.KernelMetricsEmitter;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.util.Coerce;\n+import com.aws.greengrass.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+\n+@ImplementsService(name = TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class TelemetryAgent extends GreengrassService {\n+    public static final String TELEMETRY_AGENT_SERVICE_TOPICS = \"TelemetryAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrassv2/health/json\";\n+    public static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    public static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    public static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 3_600;\n+    public static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    public static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 86_400;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final MetricsAggregator metricsAggregator;\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    @Getter(AccessLevel.PACKAGE)\n+    private final List<PeriodicMetricsEmitter> periodicMetricsEmitters = new ArrayList<>();\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter //used in e2e\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private final MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzNDY1Mw==", "bodyText": "must we sleep? We highly advise against randomly sleeping.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493834653", "createdAt": "2020-09-23T19:13:12Z", "author": {"login": "MikeDombo"}, "path": "src/test/java/com/aws/greengrass/telemetry/MetricsAggregatorTest.java", "diffHunk": "@@ -0,0 +1,259 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.greengrass.telemetry;\n+\n+import com.aws.greengrass.logging.impl.GreengrassLogMessage;\n+import com.aws.greengrass.telemetry.impl.Metric;\n+import com.aws.greengrass.telemetry.impl.MetricFactory;\n+import com.aws.greengrass.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.telemetry.models.TelemetryAggregation;\n+import com.aws.greengrass.telemetry.models.TelemetryUnit;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.junit.jupiter.api.extension.ExtensionContext;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.aws.greengrass.telemetry.MetricsAggregator.AGGREGATE_METRICS_FILE;\n+import static com.aws.greengrass.telemetry.MetricsAggregator.AggregatedMetric;\n+import static com.aws.greengrass.testcommons.testutilities.ExceptionLogProtector.ignoreExceptionOfType;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n+\n+@ExtendWith({MockitoExtension.class, GGExtension.class})\n+public class MetricsAggregatorTest {\n+    private static final ObjectMapper mapper = new ObjectMapper();\n+    private static final String sm = \"SystemMetrics\";\n+    private final NamespaceSet namespaceSet = new NamespaceSet();\n+    private final MetricFactory mf = new MetricFactory(sm);\n+    @TempDir\n+    protected Path tempRootDir;\n+    private MetricsAggregator ma;\n+    private final MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+\n+    @BeforeEach\n+    void setup() {\n+        namespaceSet.addNamespace(sm);\n+        ma = new MetricsAggregator(namespaceSet);\n+        TelemetryConfig.getInstance().setRoot(tempRootDir);\n+    }\n+\n+    @AfterEach\n+    void cleanup() {\n+        TelemetryConfig.getInstance().closeContext();\n+    }\n+\n+    @Test\n+    void GIVEN_system_metrics_WHEN_aggregate_THEN_aggregate_only_the_latest_values()\n+            throws InterruptedException, IOException {\n+        //Create a sample file with system metrics so we can test the freshness of the file and logs\n+        //with respect to the current timestamp\n+        long lastAgg = Instant.now().toEpochMilli();\n+        Metric m1 = new Metric(sm, \"CpuUsage\", TelemetryUnit.Percent, TelemetryAggregation.Sum);\n+        Metric m2 = new Metric(sm, \"SystemMemUsage\", TelemetryUnit.Megabytes, TelemetryAggregation.Average);\n+        Metric m3 = new Metric(sm, \"TotalNumberOfFDs\", TelemetryUnit.Count, TelemetryAggregation.Maximum);\n+        mf.putMetricData(m1, 10);\n+        mf.putMetricData(m2, 2000);\n+        mf.putMetricData(m3, 4000);\n+        mf.putMetricData(m1, 20);\n+        mf.putMetricData(m2, 3000);\n+        mf.putMetricData(m3, 5000);\n+        mf.putMetricData(m1, 30);\n+        mf.putMetricData(m2, 4000);\n+        mf.putMetricData(m3, 6000);\n+        Thread.sleep(100);\n+        long currTimestamp = Instant.now().toEpochMilli();\n+        ma.aggregateMetrics(lastAgg, currTimestamp);\n+        Path path = Paths.get(TelemetryConfig.getTelemetryDirectory().toString()).resolve(\n+                \"AggregateMetrics.log\");\n+        List<String> list = Files.readAllLines(path);\n+        assertEquals(ma.getNamespaceSet().getNamespaces().size(), list.size()); // Metrics are aggregated based on the namespace.\n+        for (String s : list) {\n+            AggregatedMetric am = mapper.readValue(mapper.readTree(s).get(\"message\").asText(),\n+                    AggregatedMetric.class);\n+            if (am.getNamespace().equals(sm)) {\n+                assertEquals(3, am.getMetrics().size()); // Three system metrics\n+                for (AggregatedMetric.Metric metrics : am.getMetrics()) {\n+                    if (metrics.getName().equals(\"CpuUsage\")) {\n+                        assertEquals((double) 60, metrics.getValue().get(\"Sum\"));\n+                    } else if (metrics.getName().equals(\"SystemMemUsage\")) {\n+                        assertEquals((double) 3000, metrics.getValue().get(\"Average\"));\n+                    } else if (metrics.getName().equals(\"TotalNumberOfFDs\")) {\n+                        assertEquals((double) 6000, metrics.getValue().get(\"Maximum\"));\n+                    }\n+                }\n+            }\n+        }\n+        lastAgg = currTimestamp;\n+        Thread.sleep(1000);\n+        currTimestamp = Instant.now().toEpochMilli();\n+        // Aggregate values within 1 second interval at this timestamp with 1\n+        ma.aggregateMetrics(lastAgg, currTimestamp);\n+        list = Files.readAllLines(path);\n+        assertEquals(2, list.size()); // AggregateMetrics.log is appended with the latest aggregations.\n+        for (String s : list) {\n+            GreengrassLogMessage egLog = mapper.readValue(s, GreengrassLogMessage.class);\n+            AggregatedMetric am = mapper.readValue(egLog.getMessage(),\n+                    AggregatedMetric.class);\n+            if (am.getTimestamp() == currTimestamp && am.getNamespace().equals(\"SystemMetrics\")) {\n+                assertEquals(0, am.getMetrics().size()); // There is no aggregation as there are no latest values\n+            }\n+        }\n+    }\n+\n+    @Test\n+    void GIVEN_invalid_metrics_WHEN_aggregate_THEN_parse_them_properly(ExtensionContext exContext) throws IOException,\n+            InterruptedException {\n+        //Create a sample file with aggregated metrics so we can test the freshness of the file and logs\n+        // with respect to the current timestamp\n+        ignoreExceptionOfType(exContext, MismatchedInputException.class);\n+        long lastAgg = Instant.now().toEpochMilli();\n+        Metric m1 = new Metric(sm, \"CpuUsage\", TelemetryUnit.Percent, TelemetryAggregation.Sum);\n+        Metric m2 = new Metric(sm, \"SystemMemUsage\", TelemetryUnit.Megabytes, TelemetryAggregation.Average);\n+        // Put null data\n+        mf.putMetricData(m1, null);\n+\n+        // Put invalid data for average aggregation\n+        mf.putMetricData(m2, \"banana\");\n+        mf.putMetricData(m2, 2000);\n+        //put invalid metric\n+        mf.logMetrics(new TelemetryLoggerMessage(\"alfredo\"));\n+        Thread.sleep(100);\n+        // Aggregate values within 1 second interval at this timestamp with 1\n+        ma.aggregateMetrics(lastAgg, Instant.now().toEpochMilli());\n+        Path path = Paths.get(TelemetryConfig.getTelemetryDirectory().toString()).resolve(\"AggregateMetrics.log\");\n+        List<String> list = Files.readAllLines(path);\n+        assertEquals(ma.getNamespaceSet().getNamespaces().size(), list.size()); // Metrics are aggregated based on the namespace.\n+        for (String s : list) {\n+            AggregatedMetric am = mapper.readValue(mapper.readTree(s).get(\"message\").asText(),\n+                    AggregatedMetric.class);\n+            if (am.getNamespace().equals(sm)) {\n+                assertEquals(2, am.getMetrics().size()); // Two system metrics, one of them is null\n+                for (AggregatedMetric.Metric metrics : am.getMetrics()) {\n+                    if (metrics.getName().equals(\"CpuUsage\")) {\n+                        assertEquals((double) 0, metrics.getValue().get(\"Sum\")); //No valid data point to aggregate\n+                    } else if (metrics.getName().equals(\"SystemMemUsage\")) {\n+                        assertEquals((double) 1000, metrics.getValue().get(\"Average\")); // ignore the invalid value\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    @Test\n+    void GIVEN_aggregated_metrics_WHEN_publish_THEN_collect_only_the_latest_values() throws InterruptedException {\n+        //Create a sample file with aggregated metrics so we can test the freshness of the file and logs\n+        // with respect to the current timestamp\n+        long lastPublish = Instant.now().toEpochMilli();\n+//        MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+        long currentTimestamp = Instant.now().toEpochMilli();\n+        List<AggregatedMetric.Metric> metricList = new ArrayList<>();\n+        Map<String, Object> map = new HashMap<>();\n+        map.put(\"Average\", 4000);\n+        metricList.add(new AggregatedMetric.Metric(\"TotalNumberOfFDs\", map, TelemetryUnit.Count));\n+        map.put(\"Average\", 15);\n+        metricList.add(new AggregatedMetric.Metric(\"CpuUsage\", map, TelemetryUnit.Percent));\n+        map.put(\"Average\", 9000);\n+        metricList.add(new AggregatedMetric.Metric(\"SystemMemUsage\", map, TelemetryUnit.Megabytes));\n+        AggregatedMetric aggregatedMetric = new AggregatedMetric(currentTimestamp, sm, metricList);\n+        metricFactory.logMetrics(new TelemetryLoggerMessage(aggregatedMetric));\n+        metricFactory.logMetrics(new TelemetryLoggerMessage(aggregatedMetric));\n+        metricFactory.logMetrics(new TelemetryLoggerMessage(aggregatedMetric));\n+        Thread.sleep(100);\n+        // Create an instance of the metrics uploader to get the aggregated metrics\n+        Map<Long, List<AggregatedMetric>> list = ma.getMetricsToPublish(lastPublish, currentTimestamp);\n+\n+        //We perform aggregation on the aggregated data points at the time of publish and get n additional metrics with\n+        // the current timestamp where n = no of namespaces. In this test, we have only 1 namespace i.e SystemMetrics\n+        assertEquals(1, list.get(currentTimestamp).size());\n+        currentTimestamp = Instant.now().toEpochMilli();\n+        list = ma.getMetricsToPublish(lastPublish, currentTimestamp);\n+        lastPublish = currentTimestamp;\n+        // we only have one list of the metrics collected\n+        assertEquals(1, list.size());\n+\n+        //we have 3 entries of the aggregated metrics before this latest TS + 1 entry which is the aggregation of those\n+        // 3 entries\n+        assertEquals(4, list.get(currentTimestamp).size());\n+\n+        Thread.sleep(1000);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e"}, "originalPosition": 198}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzNDg5OA==", "bodyText": "this shouldn't be needed. It is highly suspect.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493834898", "createdAt": "2020-09-23T19:13:41Z", "author": {"login": "MikeDombo"}, "path": "src/test/java/com/aws/greengrass/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.greengrass.telemetry;\n+\n+import com.aws.greengrass.config.Topic;\n+import com.aws.greengrass.dependency.Context;\n+import com.aws.greengrass.deployment.DeviceConfiguration;\n+import com.aws.greengrass.lifecyclemanager.KernelMetricsEmitter;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.testcommons.testutilities.GGServiceTestUtil;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.time.Instant;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.deployment.DeviceConfiguration.DEVICE_PARAM_THING_NAME;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_METRICS_PUBLISH_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.junit.jupiter.api.Assertions.assertNull;\n+import static org.mockito.Mockito.doNothing;\n+import static org.mockito.Mockito.lenient;\n+import static org.mockito.Mockito.reset;\n+import static org.mockito.Mockito.spy;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+@ExtendWith({MockitoExtension.class, GGExtension.class})\n+public class TelemetryAgentTest extends GGServiceTestUtil {\n+    @TempDir\n+    protected Path tempRootDir;\n+    @Mock\n+    private MqttClient mockMqttClient;\n+    @Mock\n+    private DeviceConfiguration mockDeviceConfiguration;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> publishRequestArgumentCaptor;\n+    @Captor\n+    private ArgumentCaptor<MqttClientConnectionEvents> mqttClientConnectionEventsArgumentCaptor;\n+    @Mock\n+    private ScheduledExecutorService ses;\n+    private TelemetryAgent telemetryAgent;\n+    private SystemMetricsEmitter sme;\n+    private KernelMetricsEmitter kme;\n+    private MetricsAggregator ma;\n+    @Mock\n+    private Context context;\n+\n+    @BeforeEach\n+    public void setup() {\n+        serviceFullName = \"MetricsAgentService\";\n+        initializeMockedConfig();\n+        TelemetryConfig.getInstance().setRoot(tempRootDir);\n+        ses = new ScheduledThreadPoolExecutor(3);\n+        context = new Context();\n+        sme = context.get(SystemMetricsEmitter.class);\n+        kme = context.get(KernelMetricsEmitter.class);\n+        ma = context.get(MetricsAggregator.class);\n+        Topic periodicAggregateMetricsIntervalSec = Topic.of(context, TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC, \"1\");\n+        lenient().when(config\n+                .lookup(PARAMETERS_CONFIG_KEY, TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC))\n+                .thenReturn(periodicAggregateMetricsIntervalSec);\n+        Topic periodicPublishMetricsIntervalSec = Topic.of(context, TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC, \"3\");\n+        lenient().when(config\n+                .lookup(PARAMETERS_CONFIG_KEY, TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC))\n+                .thenReturn(periodicPublishMetricsIntervalSec);\n+        Topic lastPeriodicAggregateTime = Topic.of(context, TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC,\n+                Instant.now().toEpochMilli());\n+        lenient().when(config.lookupTopics(RUNTIME_STORE_NAMESPACE_TOPIC)\n+                .lookup(TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC))\n+                .thenReturn(lastPeriodicAggregateTime);\n+        Topic lastPeriodicPublishTime = Topic.of(context, TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC,\n+                Instant.now().toEpochMilli());\n+        lenient().when(config.lookupTopics(RUNTIME_STORE_NAMESPACE_TOPIC)\n+                .lookup(TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC))\n+                .thenReturn(lastPeriodicPublishTime);\n+        Topic thingNameTopic = Topic.of(context, DEVICE_PARAM_THING_NAME, \"testThing\");\n+        when(config.lookup(DEVICE_PARAM_THING_NAME)).thenReturn(thingNameTopic);\n+        when(mockDeviceConfiguration.getThingName()).thenReturn(thingNameTopic);\n+        Topic telemetryMetricsPublishTopic = Topic.of(context, TELEMETRY_METRICS_PUBLISH_TOPICS,\n+                DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC);\n+        when(config.lookup(PARAMETERS_CONFIG_KEY, TELEMETRY_METRICS_PUBLISH_TOPICS))\n+                .thenReturn(telemetryMetricsPublishTopic);\n+        telemetryAgent = spy(new TelemetryAgent(config, mockMqttClient, mockDeviceConfiguration, ma, sme, kme, ses));\n+    }\n+\n+    @AfterEach\n+    public void cleanUp() throws IOException, InterruptedException {\n+        TelemetryConfig.getInstance().closeContext();\n+        telemetryAgent.shutdown();\n+        ses.shutdown();\n+        Thread.sleep(500);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e"}, "originalPosition": 121}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzNzczMw==", "bodyText": "use shutdownNow", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493837733", "createdAt": "2020-09-23T19:19:06Z", "author": {"login": "MikeDombo"}, "path": "src/test/java/com/aws/greengrass/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,186 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.greengrass.telemetry;\n+\n+import com.aws.greengrass.config.Topic;\n+import com.aws.greengrass.dependency.Context;\n+import com.aws.greengrass.deployment.DeviceConfiguration;\n+import com.aws.greengrass.lifecyclemanager.KernelMetricsEmitter;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.testcommons.testutilities.GGServiceTestUtil;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.time.Instant;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.deployment.DeviceConfiguration.DEVICE_PARAM_THING_NAME;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_METRICS_PUBLISH_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.junit.jupiter.api.Assertions.assertNull;\n+import static org.mockito.Mockito.doNothing;\n+import static org.mockito.Mockito.lenient;\n+import static org.mockito.Mockito.reset;\n+import static org.mockito.Mockito.spy;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+@ExtendWith({MockitoExtension.class, GGExtension.class})\n+public class TelemetryAgentTest extends GGServiceTestUtil {\n+    @TempDir\n+    protected Path tempRootDir;\n+    @Mock\n+    private MqttClient mockMqttClient;\n+    @Mock\n+    private DeviceConfiguration mockDeviceConfiguration;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> publishRequestArgumentCaptor;\n+    @Captor\n+    private ArgumentCaptor<MqttClientConnectionEvents> mqttClientConnectionEventsArgumentCaptor;\n+    @Mock\n+    private ScheduledExecutorService ses;\n+    private TelemetryAgent telemetryAgent;\n+    private SystemMetricsEmitter sme;\n+    private KernelMetricsEmitter kme;\n+    private MetricsAggregator ma;\n+    @Mock\n+    private Context context;\n+\n+    @BeforeEach\n+    public void setup() {\n+        serviceFullName = \"MetricsAgentService\";\n+        initializeMockedConfig();\n+        TelemetryConfig.getInstance().setRoot(tempRootDir);\n+        ses = new ScheduledThreadPoolExecutor(3);\n+        context = new Context();\n+        sme = context.get(SystemMetricsEmitter.class);\n+        kme = context.get(KernelMetricsEmitter.class);\n+        ma = context.get(MetricsAggregator.class);\n+        Topic periodicAggregateMetricsIntervalSec = Topic.of(context, TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC, \"1\");\n+        lenient().when(config\n+                .lookup(PARAMETERS_CONFIG_KEY, TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC))\n+                .thenReturn(periodicAggregateMetricsIntervalSec);\n+        Topic periodicPublishMetricsIntervalSec = Topic.of(context, TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC, \"3\");\n+        lenient().when(config\n+                .lookup(PARAMETERS_CONFIG_KEY, TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC))\n+                .thenReturn(periodicPublishMetricsIntervalSec);\n+        Topic lastPeriodicAggregateTime = Topic.of(context, TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC,\n+                Instant.now().toEpochMilli());\n+        lenient().when(config.lookupTopics(RUNTIME_STORE_NAMESPACE_TOPIC)\n+                .lookup(TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC))\n+                .thenReturn(lastPeriodicAggregateTime);\n+        Topic lastPeriodicPublishTime = Topic.of(context, TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC,\n+                Instant.now().toEpochMilli());\n+        lenient().when(config.lookupTopics(RUNTIME_STORE_NAMESPACE_TOPIC)\n+                .lookup(TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC))\n+                .thenReturn(lastPeriodicPublishTime);\n+        Topic thingNameTopic = Topic.of(context, DEVICE_PARAM_THING_NAME, \"testThing\");\n+        when(config.lookup(DEVICE_PARAM_THING_NAME)).thenReturn(thingNameTopic);\n+        when(mockDeviceConfiguration.getThingName()).thenReturn(thingNameTopic);\n+        Topic telemetryMetricsPublishTopic = Topic.of(context, TELEMETRY_METRICS_PUBLISH_TOPICS,\n+                DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC);\n+        when(config.lookup(PARAMETERS_CONFIG_KEY, TELEMETRY_METRICS_PUBLISH_TOPICS))\n+                .thenReturn(telemetryMetricsPublishTopic);\n+        telemetryAgent = spy(new TelemetryAgent(config, mockMqttClient, mockDeviceConfiguration, ma, sme, kme, ses));\n+    }\n+\n+    @AfterEach\n+    public void cleanUp() throws IOException, InterruptedException {\n+        TelemetryConfig.getInstance().closeContext();\n+        telemetryAgent.shutdown();\n+        ses.shutdown();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e"}, "originalPosition": 120}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzODA0Nw==", "bodyText": "remove this now that you close it in the kernel shutdown", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493838047", "createdAt": "2020-09-23T19:19:39Z", "author": {"login": "MikeDombo"}, "path": "src/test/java/com/aws/greengrass/testcommons/testutilities/ExceptionLogProtector.java", "diffHunk": "@@ -148,7 +149,9 @@ public void beforeEach(ExtensionContext context) throws Exception {\n     @SneakyThrows\n     public void afterEach(ExtensionContext context) throws Exception {\n         Slf4jLogAdapter.removeGlobalListener(getListener(context));\n-\n+        //Stop the telemetry logger context after each test so we can delete the telemetry log files that are created\n+        // during the test.\n+        TelemetryConfig.getInstance().closeContext();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e"}, "originalPosition": 15}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk0OTYxODY3", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-494961867", "createdAt": "2020-09-23T18:59:54Z", "commit": {"oid": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e"}, "state": "COMMENTED", "comments": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QxODo1OTo1NFrOHW8ziw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QxOToyMjowNFrOHW9kBg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgyNjk1NQ==", "bodyText": "You can remove this e2e test.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493826955", "createdAt": "2020-09-23T18:59:54Z", "author": {"login": "nikkhilmuthye"}, "path": "src/integrationtests/java/com/aws/greengrass/integrationtests/e2e/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,127 @@\n+/*", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgyNzY1Nw==", "bodyText": "Should wait for MetricAgent to start right?", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493827657", "createdAt": "2020-09-23T19:00:35Z", "author": {"login": "nikkhilmuthye"}, "path": "src/integrationtests/java/com/aws/greengrass/integrationtests/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,127 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.greengrass.integrationtests.telemetry;\n+\n+import com.aws.greengrass.config.Topics;\n+import com.aws.greengrass.dependency.State;\n+import com.aws.greengrass.integrationtests.BaseITCase;\n+import com.aws.greengrass.lifecyclemanager.Kernel;\n+import com.aws.greengrass.lifecyclemanager.exceptions.ServiceLoadException;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.MetricsAggregator;\n+import com.aws.greengrass.telemetry.MetricsPayload;\n+import com.aws.greengrass.telemetry.TelemetryAgent;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.TestInfo;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.verify;\n+\n+@ExtendWith({GGExtension.class, MockitoExtension.class})\n+class TelemetryAgentTest extends BaseITCase {\n+    private Kernel kernel;\n+    @Mock\n+    private MqttClient mqttClient;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> captor;\n+\n+    @BeforeEach\n+    void before(TestInfo testInfo) {\n+        System.out.println(\"Running test: \" + testInfo.getDisplayName());\n+        kernel = new Kernel();\n+    }\n+\n+    @AfterEach\n+    void after() {\n+        if (kernel != null) {\n+            mqttClient.close();\n+            kernel.shutdown();\n+        }\n+    }\n+\n+    @Test\n+    void GIVEN_kernel_running_with_telemetry_config_WHEN_launch_THEN_metrics_are_published() throws InterruptedException,\n+            ServiceLoadException {\n+        // GIVEN\n+        kernel.parseArgs(\"-i\", getClass().getResource(\"config.yaml\").toString());\n+        CountDownLatch mainRunning = new CountDownLatch(2);\n+        kernel.getContext().addGlobalStateChangeListener((service, oldState, newState) -> {\n+            if (service.getName().equals(\"main\") && newState.equals(State.RUNNING)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e"}, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgyODMxMw==", "bodyText": "use TimeUnit.SECONDS.sleep(4)", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493828313", "createdAt": "2020-09-23T19:01:31Z", "author": {"login": "nikkhilmuthye"}, "path": "src/integrationtests/java/com/aws/greengrass/integrationtests/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,127 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.greengrass.integrationtests.telemetry;\n+\n+import com.aws.greengrass.config.Topics;\n+import com.aws.greengrass.dependency.State;\n+import com.aws.greengrass.integrationtests.BaseITCase;\n+import com.aws.greengrass.lifecyclemanager.Kernel;\n+import com.aws.greengrass.lifecyclemanager.exceptions.ServiceLoadException;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.MetricsAggregator;\n+import com.aws.greengrass.telemetry.MetricsPayload;\n+import com.aws.greengrass.telemetry.TelemetryAgent;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.TestInfo;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.verify;\n+\n+@ExtendWith({GGExtension.class, MockitoExtension.class})\n+class TelemetryAgentTest extends BaseITCase {\n+    private Kernel kernel;\n+    @Mock\n+    private MqttClient mqttClient;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> captor;\n+\n+    @BeforeEach\n+    void before(TestInfo testInfo) {\n+        System.out.println(\"Running test: \" + testInfo.getDisplayName());\n+        kernel = new Kernel();\n+    }\n+\n+    @AfterEach\n+    void after() {\n+        if (kernel != null) {\n+            mqttClient.close();\n+            kernel.shutdown();\n+        }\n+    }\n+\n+    @Test\n+    void GIVEN_kernel_running_with_telemetry_config_WHEN_launch_THEN_metrics_are_published() throws InterruptedException,\n+            ServiceLoadException {\n+        // GIVEN\n+        kernel.parseArgs(\"-i\", getClass().getResource(\"config.yaml\").toString());\n+        CountDownLatch mainRunning = new CountDownLatch(2);\n+        kernel.getContext().addGlobalStateChangeListener((service, oldState, newState) -> {\n+            if (service.getName().equals(\"main\") && newState.equals(State.RUNNING)) {\n+                mainRunning.countDown();\n+            }\n+        });\n+        kernel.getContext().put(MqttClient.class, mqttClient);\n+        //WHEN\n+        kernel.launch();\n+\n+        Topics parameterTopics = kernel.getConfig()\n+                .lookupTopics(SERVICES_NAMESPACE_TOPIC, TELEMETRY_AGENT_SERVICE_TOPICS, PARAMETERS_CONFIG_KEY);\n+        int aggregateInterval = Coerce.toInt(parameterTopics.find(TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC));\n+        int periodicInterval = Coerce.toInt(parameterTopics.find(TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC));\n+        //telemetry configurations are set correctly\n+        assertEquals(3, aggregateInterval);\n+        assertEquals(2, periodicInterval);\n+        Topics runtimeTopics = kernel.getConfig()\n+                .lookupTopics(SERVICES_NAMESPACE_TOPIC, TELEMETRY_AGENT_SERVICE_TOPICS, RUNTIME_STORE_NAMESPACE_TOPIC);\n+        long lastAgg = Coerce.toLong(runtimeTopics.find(TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC));\n+\n+        //wait for at least 4 seconds as the first aggregation occurs at 3rd second.\n+        Thread.sleep(4000);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgyOTIxMg==", "bodyText": "You need to await this CDLatch to make sure that the service is actually running. Also, make that new CountDownLatch(1); since there is only one name you are waiting to be started.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493829212", "createdAt": "2020-09-23T19:03:06Z", "author": {"login": "nikkhilmuthye"}, "path": "src/integrationtests/java/com/aws/greengrass/integrationtests/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,127 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.greengrass.integrationtests.telemetry;\n+\n+import com.aws.greengrass.config.Topics;\n+import com.aws.greengrass.dependency.State;\n+import com.aws.greengrass.integrationtests.BaseITCase;\n+import com.aws.greengrass.lifecyclemanager.Kernel;\n+import com.aws.greengrass.lifecyclemanager.exceptions.ServiceLoadException;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.MetricsAggregator;\n+import com.aws.greengrass.telemetry.MetricsPayload;\n+import com.aws.greengrass.telemetry.TelemetryAgent;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.TestInfo;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.verify;\n+\n+@ExtendWith({GGExtension.class, MockitoExtension.class})\n+class TelemetryAgentTest extends BaseITCase {\n+    private Kernel kernel;\n+    @Mock\n+    private MqttClient mqttClient;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> captor;\n+\n+    @BeforeEach\n+    void before(TestInfo testInfo) {\n+        System.out.println(\"Running test: \" + testInfo.getDisplayName());\n+        kernel = new Kernel();\n+    }\n+\n+    @AfterEach\n+    void after() {\n+        if (kernel != null) {\n+            mqttClient.close();\n+            kernel.shutdown();\n+        }\n+    }\n+\n+    @Test\n+    void GIVEN_kernel_running_with_telemetry_config_WHEN_launch_THEN_metrics_are_published() throws InterruptedException,\n+            ServiceLoadException {\n+        // GIVEN\n+        kernel.parseArgs(\"-i\", getClass().getResource(\"config.yaml\").toString());\n+        CountDownLatch mainRunning = new CountDownLatch(2);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e"}, "originalPosition": 76}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzMDE5MQ==", "bodyText": "You need to verify the number of metrics as well. that should be (aggregation interval/publish interval) + 1", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493830191", "createdAt": "2020-09-23T19:04:51Z", "author": {"login": "nikkhilmuthye"}, "path": "src/integrationtests/java/com/aws/greengrass/integrationtests/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,127 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.greengrass.integrationtests.telemetry;\n+\n+import com.aws.greengrass.config.Topics;\n+import com.aws.greengrass.dependency.State;\n+import com.aws.greengrass.integrationtests.BaseITCase;\n+import com.aws.greengrass.lifecyclemanager.Kernel;\n+import com.aws.greengrass.lifecyclemanager.exceptions.ServiceLoadException;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.MetricsAggregator;\n+import com.aws.greengrass.telemetry.MetricsPayload;\n+import com.aws.greengrass.telemetry.TelemetryAgent;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.TestInfo;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.verify;\n+\n+@ExtendWith({GGExtension.class, MockitoExtension.class})\n+class TelemetryAgentTest extends BaseITCase {\n+    private Kernel kernel;\n+    @Mock\n+    private MqttClient mqttClient;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> captor;\n+\n+    @BeforeEach\n+    void before(TestInfo testInfo) {\n+        System.out.println(\"Running test: \" + testInfo.getDisplayName());\n+        kernel = new Kernel();\n+    }\n+\n+    @AfterEach\n+    void after() {\n+        if (kernel != null) {\n+            mqttClient.close();\n+            kernel.shutdown();\n+        }\n+    }\n+\n+    @Test\n+    void GIVEN_kernel_running_with_telemetry_config_WHEN_launch_THEN_metrics_are_published() throws InterruptedException,\n+            ServiceLoadException {\n+        // GIVEN\n+        kernel.parseArgs(\"-i\", getClass().getResource(\"config.yaml\").toString());\n+        CountDownLatch mainRunning = new CountDownLatch(2);\n+        kernel.getContext().addGlobalStateChangeListener((service, oldState, newState) -> {\n+            if (service.getName().equals(\"main\") && newState.equals(State.RUNNING)) {\n+                mainRunning.countDown();\n+            }\n+        });\n+        kernel.getContext().put(MqttClient.class, mqttClient);\n+        //WHEN\n+        kernel.launch();\n+\n+        Topics parameterTopics = kernel.getConfig()\n+                .lookupTopics(SERVICES_NAMESPACE_TOPIC, TELEMETRY_AGENT_SERVICE_TOPICS, PARAMETERS_CONFIG_KEY);\n+        int aggregateInterval = Coerce.toInt(parameterTopics.find(TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC));\n+        int periodicInterval = Coerce.toInt(parameterTopics.find(TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC));\n+        //telemetry configurations are set correctly\n+        assertEquals(3, aggregateInterval);\n+        assertEquals(2, periodicInterval);\n+        Topics runtimeTopics = kernel.getConfig()\n+                .lookupTopics(SERVICES_NAMESPACE_TOPIC, TELEMETRY_AGENT_SERVICE_TOPICS, RUNTIME_STORE_NAMESPACE_TOPIC);\n+        long lastAgg = Coerce.toLong(runtimeTopics.find(TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC));\n+\n+        //wait for at least 4 seconds as the first aggregation occurs at 3rd second.\n+        Thread.sleep(4000);\n+        assertTrue(Coerce.toLong(runtimeTopics.find(TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC)) > lastAgg);\n+\n+        TelemetryAgent ma = (TelemetryAgent) kernel.locate(\"TelemetryAgent\");\n+        long delay = ma.getPeriodicPublishMetricsFuture().getDelay(TimeUnit.SECONDS);\n+        assertTrue(delay < periodicInterval);\n+        // telemetry logs are always written to ~root/telemetry\n+        assertEquals(kernel.getRootPath().resolve(\"telemetry\"), TelemetryConfig.getTelemetryDirectory());\n+        // THEN\n+        verify(mqttClient, timeout(1000).atLeastOnce()).publish(captor.capture());\n+        List<PublishRequest> prs = captor.getAllValues();\n+        for (PublishRequest pr : prs) {\n+            try {\n+                MetricsPayload mp = new ObjectMapper().readValue(pr.getPayload(), MetricsPayload.class);\n+                //There will be nothing to aggregate as publish happens at 1st second and aggregation at 2nd second.\n+                // So, there will only one accumulated data point for each namespace during the first publish\n+                assertEquals(kernel.getContext().get(MetricsAggregator.class)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e"}, "originalPosition": 114}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzMDY3Mg==", "bodyText": "Is this correct? Publish interval should always be greater than aggregation interval.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493830672", "createdAt": "2020-09-23T19:05:44Z", "author": {"login": "nikkhilmuthye"}, "path": "src/integrationtests/resources/com/aws/greengrass/integrationtests/telemetry/config.yaml", "diffHunk": "@@ -0,0 +1,10 @@\n+---\n+services:\n+  main:\n+    lifecycle:\n+      install:\n+        all: echo All installed\n+  TelemetryAgent:\n+    parameters:\n+      periodicAggregateMetricsIntervalSec: 3\n+      periodicPublishMetricsIntervalSec: 2", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e"}, "originalPosition": 10}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzMTgzMg==", "bodyText": "any reason to inject the NamespaceSet and get use a getter on the NAMESPACE field?", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493831832", "createdAt": "2020-09-23T19:07:55Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/greengrass/lifecyclemanager/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,122 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.greengrass.lifecyclemanager;\n+\n+import com.aws.greengrass.dependency.State;\n+import com.aws.greengrass.logging.api.Logger;\n+import com.aws.greengrass.logging.impl.LogManager;\n+import com.aws.greengrass.telemetry.NamespaceSet;\n+import com.aws.greengrass.telemetry.PeriodicMetricsEmitter;\n+import com.aws.greengrass.telemetry.impl.Metric;\n+import com.aws.greengrass.telemetry.impl.MetricFactory;\n+import com.aws.greengrass.telemetry.models.TelemetryAggregation;\n+import com.aws.greengrass.telemetry.models.TelemetryUnit;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+import javax.inject.Inject;\n+\n+public class KernelMetricsEmitter extends PeriodicMetricsEmitter {\n+    public static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+    private static final String NAMESPACE = \"GreengrassComponents\";\n+    private final Kernel kernel;\n+    private final MetricFactory mf = new MetricFactory(NAMESPACE);\n+\n+    /**\n+     * Constructor for kernel metrics emitter.\n+     *\n+     * @param kernel {@link Kernel}\n+     * @param namespaceSet {@link NamespaceSet}\n+     */\n+    @Inject\n+    public KernelMetricsEmitter(Kernel kernel, NamespaceSet namespaceSet) {\n+        super();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzMjg5NQ==", "bodyText": "Same here, just use a @Getter on the field right? or make it package private?", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493832895", "createdAt": "2020-09-23T19:09:59Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/greengrass/telemetry/SystemMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,67 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.greengrass.telemetry;\n+\n+import com.aws.greengrass.logging.api.Logger;\n+import com.aws.greengrass.logging.impl.LogManager;\n+import com.aws.greengrass.telemetry.impl.Metric;\n+import com.aws.greengrass.telemetry.impl.MetricFactory;\n+import com.aws.greengrass.telemetry.models.TelemetryAggregation;\n+import com.aws.greengrass.telemetry.models.TelemetryUnit;\n+import oshi.SystemInfo;\n+import oshi.hardware.CentralProcessor;\n+\n+import javax.inject.Inject;\n+\n+public class SystemMetricsEmitter extends PeriodicMetricsEmitter {\n+    public static final Logger logger = LogManager.getLogger(SystemMetricsEmitter.class);\n+    private static final int MB_CONVERTER = 1024 * 1024;\n+    private static final int PERCENTAGE_CONVERTER = 100;\n+    private static final String NAMESPACE = \"SystemMetrics\";\n+    private static final CentralProcessor cpu = new SystemInfo().getHardware().getProcessor();\n+    private static final SystemInfo systemInfo = new SystemInfo();\n+    private final MetricFactory mf = new MetricFactory(NAMESPACE);\n+    private long[] previousTicks = new long[CentralProcessor.TickType.values().length];\n+\n+    /**\n+     * Constructor for the class.\n+     * @param namespaceSet {@link NamespaceSet}\n+     */\n+    @Inject\n+    public SystemMetricsEmitter(NamespaceSet namespaceSet) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzNTc4OA==", "bodyText": "they should by default be 0 right?", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493835788", "createdAt": "2020-09-23T19:15:16Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/greengrass/telemetry/TelemetryAgent.java", "diffHunk": "@@ -0,0 +1,271 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.greengrass.telemetry;\n+\n+import com.aws.greengrass.config.Topic;\n+import com.aws.greengrass.config.Topics;\n+import com.aws.greengrass.dependency.ImplementsService;\n+import com.aws.greengrass.deployment.DeviceConfiguration;\n+import com.aws.greengrass.lifecyclemanager.GreengrassService;\n+import com.aws.greengrass.lifecyclemanager.KernelMetricsEmitter;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.util.Coerce;\n+import com.aws.greengrass.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+\n+@ImplementsService(name = TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class TelemetryAgent extends GreengrassService {\n+    public static final String TELEMETRY_AGENT_SERVICE_TOPICS = \"TelemetryAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrassv2/health/json\";\n+    public static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    public static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    public static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 3_600;\n+    public static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    public static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 86_400;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzODQxMw==", "bodyText": "Change the topic to be $aws/things/{thingName}/greengrass/health/json", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493838413", "createdAt": "2020-09-23T19:20:21Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/greengrass/telemetry/TelemetryAgent.java", "diffHunk": "@@ -0,0 +1,271 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.greengrass.telemetry;\n+\n+import com.aws.greengrass.config.Topic;\n+import com.aws.greengrass.config.Topics;\n+import com.aws.greengrass.dependency.ImplementsService;\n+import com.aws.greengrass.deployment.DeviceConfiguration;\n+import com.aws.greengrass.lifecyclemanager.GreengrassService;\n+import com.aws.greengrass.lifecyclemanager.KernelMetricsEmitter;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.util.Coerce;\n+import com.aws.greengrass.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+\n+@ImplementsService(name = TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class TelemetryAgent extends GreengrassService {\n+    public static final String TELEMETRY_AGENT_SERVICE_TOPICS = \"TelemetryAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrassv2/health/json\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzOTM2Ng==", "bodyText": "I don't see why this has to be a class.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493839366", "createdAt": "2020-09-23T19:22:04Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/greengrass/telemetry/NamespaceSet.java", "diffHunk": "@@ -0,0 +1,15 @@\n+package com.aws.greengrass.telemetry;\n+\n+import lombok.Getter;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+\n+public class NamespaceSet {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e"}, "originalPosition": 8}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "62b187c5feb711507ee6a0ca1af15a2c39b8fb4d", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/62b187c5feb711507ee6a0ca1af15a2c39b8fb4d", "committedDate": "2020-09-23T23:13:04Z", "message": "remove namespace set + get namespaces using loggercontext + update integ tests, remove e2e tests + other changes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "363d5211c7b1c00b9398a7770ef1a2647e93621f", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/363d5211c7b1c00b9398a7770ef1a2647e93621f", "committedDate": "2020-09-24T00:48:56Z", "message": "update tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d9d2a79044108efb574ef45555b9d4c4c25a0151", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/d9d2a79044108efb574ef45555b9d4c4c25a0151", "committedDate": "2020-09-24T01:29:12Z", "message": "use shutdownNow()"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7da553e7b83954dec40d4e4a46956651e61bc6bc", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/7da553e7b83954dec40d4e4a46956651e61bc6bc", "committedDate": "2020-09-24T01:36:07Z", "message": "use shutdownNow()"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c27c902fe03b4e85c20ece0e798143c10e7af88e", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/c27c902fe03b4e85c20ece0e798143c10e7af88e", "committedDate": "2020-09-24T01:36:19Z", "message": "Merge branch 'telemetry-logs' of github.com:/aws/aws-greengrass-kernel into telemetry-logs"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk1MTY4MDUx", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-495168051", "createdAt": "2020-09-24T01:56:01Z", "commit": {"oid": "c27c902fe03b4e85c20ece0e798143c10e7af88e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQwMTo1NjowMVrOHXHAQg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQwMTo1NjowMVrOHXHAQg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk5NDA1MA==", "bodyText": "assert true whenever you await on a CDL", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493994050", "createdAt": "2020-09-24T01:56:01Z", "author": {"login": "MikeDombo"}, "path": "src/integrationtests/java/com/aws/greengrass/integrationtests/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,132 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.greengrass.integrationtests.telemetry;\n+\n+import com.aws.greengrass.config.Topics;\n+import com.aws.greengrass.dependency.State;\n+import com.aws.greengrass.integrationtests.BaseITCase;\n+import com.aws.greengrass.lifecyclemanager.Kernel;\n+import com.aws.greengrass.lifecyclemanager.exceptions.ServiceLoadException;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.MetricsAggregator;\n+import com.aws.greengrass.telemetry.MetricsPayload;\n+import com.aws.greengrass.telemetry.TelemetryAgent;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.TestInfo;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+import static org.mockito.Mockito.atLeastOnce;\n+import static org.mockito.Mockito.verify;\n+\n+@ExtendWith({GGExtension.class, MockitoExtension.class})\n+class TelemetryAgentTest extends BaseITCase {\n+    private Kernel kernel;\n+    @Mock\n+    private MqttClient mqttClient;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> captor;\n+\n+    @BeforeEach\n+    void before(TestInfo testInfo) {\n+        System.out.println(\"Running test: \" + testInfo.getDisplayName());\n+        kernel = new Kernel();\n+    }\n+\n+    @AfterEach\n+    void after() {\n+        if (kernel != null) {\n+            kernel.shutdown();\n+        }\n+    }\n+\n+    @Test\n+    void GIVEN_kernel_running_with_telemetry_config_WHEN_launch_THEN_metrics_are_published() throws InterruptedException,\n+            ServiceLoadException {\n+        // GIVEN\n+        kernel.parseArgs(\"-i\", getClass().getResource(\"config.yaml\").toString());\n+        CountDownLatch mainRunning = new CountDownLatch(1);\n+        kernel.getContext().addGlobalStateChangeListener((service, oldState, newState) -> {\n+            if (service.getName().equals(\"main\") && newState.equals(State.RUNNING)) {\n+                mainRunning.countDown();\n+            }\n+        });\n+        kernel.getContext().put(MqttClient.class, mqttClient);\n+        //WHEN\n+        kernel.launch();\n+        CountDownLatch telemetryRunning = new CountDownLatch(1);\n+        kernel.getContext().addGlobalStateChangeListener((service, oldState, newState) -> {\n+            if (service.getName().equals(\"TelemetryAgent\") && service.getState().equals(State.RUNNING)) {\n+                telemetryRunning.countDown();\n+            }\n+        });\n+        telemetryRunning.await(10, TimeUnit.SECONDS);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c27c902fe03b4e85c20ece0e798143c10e7af88e"}, "originalPosition": 90}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk1MTY4MTY4", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-495168168", "createdAt": "2020-09-24T01:56:28Z", "commit": {"oid": "c27c902fe03b4e85c20ece0e798143c10e7af88e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQwMTo1NjoyOFrOHXHAsg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQwMTo1NjoyOFrOHXHAsg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk5NDE2Mg==", "bodyText": "you never await this? So why have it at all?", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493994162", "createdAt": "2020-09-24T01:56:28Z", "author": {"login": "MikeDombo"}, "path": "src/integrationtests/java/com/aws/greengrass/integrationtests/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,132 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.greengrass.integrationtests.telemetry;\n+\n+import com.aws.greengrass.config.Topics;\n+import com.aws.greengrass.dependency.State;\n+import com.aws.greengrass.integrationtests.BaseITCase;\n+import com.aws.greengrass.lifecyclemanager.Kernel;\n+import com.aws.greengrass.lifecyclemanager.exceptions.ServiceLoadException;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.MetricsAggregator;\n+import com.aws.greengrass.telemetry.MetricsPayload;\n+import com.aws.greengrass.telemetry.TelemetryAgent;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.TestInfo;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+import static org.mockito.Mockito.atLeastOnce;\n+import static org.mockito.Mockito.verify;\n+\n+@ExtendWith({GGExtension.class, MockitoExtension.class})\n+class TelemetryAgentTest extends BaseITCase {\n+    private Kernel kernel;\n+    @Mock\n+    private MqttClient mqttClient;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> captor;\n+\n+    @BeforeEach\n+    void before(TestInfo testInfo) {\n+        System.out.println(\"Running test: \" + testInfo.getDisplayName());\n+        kernel = new Kernel();\n+    }\n+\n+    @AfterEach\n+    void after() {\n+        if (kernel != null) {\n+            kernel.shutdown();\n+        }\n+    }\n+\n+    @Test\n+    void GIVEN_kernel_running_with_telemetry_config_WHEN_launch_THEN_metrics_are_published() throws InterruptedException,\n+            ServiceLoadException {\n+        // GIVEN\n+        kernel.parseArgs(\"-i\", getClass().getResource(\"config.yaml\").toString());\n+        CountDownLatch mainRunning = new CountDownLatch(1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c27c902fe03b4e85c20ece0e798143c10e7af88e"}, "originalPosition": 75}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk1MTY4OTkw", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-495168990", "createdAt": "2020-09-24T01:59:13Z", "commit": {"oid": "c27c902fe03b4e85c20ece0e798143c10e7af88e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQwMTo1OToxM1rOHXHDSg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQwMTo1OToxM1rOHXHDSg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk5NDgyNg==", "bodyText": "this is a hack. don't do this", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493994826", "createdAt": "2020-09-24T01:59:13Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/greengrass/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,368 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.greengrass.telemetry;\n+\n+import com.aws.greengrass.logging.api.Logger;\n+import com.aws.greengrass.logging.impl.GreengrassLogMessage;\n+import com.aws.greengrass.logging.impl.LogManager;\n+import com.aws.greengrass.telemetry.impl.Metric;\n+import com.aws.greengrass.telemetry.impl.MetricFactory;\n+import com.aws.greengrass.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.telemetry.models.TelemetryUnit;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.annotation.JsonAnyGetter;\n+import com.fasterxml.jackson.annotation.JsonAnySetter;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Stream;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private final ObjectMapper objectMapper = new ObjectMapper();\n+    private final MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+\n+    /**\n+     * Get the set of all the namespaces created using MetricsFactory. This method assumes that MetricFactory will be\n+     * used only to emit and aggregate metrics.\n+     *\n+     * @return namespace set\n+     */\n+    public static Set<String> getNamespaceSet() {\n+        Set<String> namespaces = new HashSet<>();\n+        for (ch.qos.logback.classic.Logger logger : TelemetryConfig.getInstance().getContext().getLoggerList()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c27c902fe03b4e85c20ece0e798143c10e7af88e"}, "originalPosition": 52}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk1MTY5ODc1", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-495169875", "createdAt": "2020-09-24T02:02:11Z", "commit": {"oid": "c27c902fe03b4e85c20ece0e798143c10e7af88e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQwMjowMjoxMVrOHXHGWg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQwMjowMjoxMVrOHXHGWg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk5NTYxMA==", "bodyText": "don't mock the context if you're just going to use a real context anyway", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493995610", "createdAt": "2020-09-24T02:02:11Z", "author": {"login": "MikeDombo"}, "path": "src/test/java/com/aws/greengrass/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.greengrass.telemetry;\n+\n+import com.aws.greengrass.config.Topic;\n+import com.aws.greengrass.dependency.Context;\n+import com.aws.greengrass.deployment.DeviceConfiguration;\n+import com.aws.greengrass.lifecyclemanager.KernelMetricsEmitter;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.testcommons.testutilities.GGServiceTestUtil;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.time.Instant;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledThreadPoolExecutor;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.deployment.DeviceConfiguration.DEVICE_PARAM_THING_NAME;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_METRICS_PUBLISH_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.junit.jupiter.api.Assertions.assertNull;\n+import static org.mockito.Mockito.doNothing;\n+import static org.mockito.Mockito.lenient;\n+import static org.mockito.Mockito.reset;\n+import static org.mockito.Mockito.spy;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+@ExtendWith({MockitoExtension.class, GGExtension.class})\n+public class TelemetryAgentTest extends GGServiceTestUtil {\n+    @TempDir\n+    protected Path tempRootDir;\n+    @Mock\n+    private MqttClient mockMqttClient;\n+    @Mock\n+    private DeviceConfiguration mockDeviceConfiguration;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> publishRequestArgumentCaptor;\n+    @Captor\n+    private ArgumentCaptor<MqttClientConnectionEvents> mqttClientConnectionEventsArgumentCaptor;\n+    @Mock\n+    private ScheduledExecutorService ses;\n+    private TelemetryAgent telemetryAgent;\n+    private SystemMetricsEmitter sme;\n+    private KernelMetricsEmitter kme;\n+    private MetricsAggregator ma;\n+    @Mock\n+    private Context context;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c27c902fe03b4e85c20ece0e798143c10e7af88e"}, "originalPosition": 75}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk1MTY5OTIz", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-495169923", "createdAt": "2020-09-24T02:02:19Z", "commit": {"oid": "c27c902fe03b4e85c20ece0e798143c10e7af88e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQwMjowMjoxOVrOHXHGgQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQwMjowMjoxOVrOHXHGgQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk5NTY0OQ==", "bodyText": "same", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493995649", "createdAt": "2020-09-24T02:02:19Z", "author": {"login": "MikeDombo"}, "path": "src/test/java/com/aws/greengrass/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.greengrass.telemetry;\n+\n+import com.aws.greengrass.config.Topic;\n+import com.aws.greengrass.dependency.Context;\n+import com.aws.greengrass.deployment.DeviceConfiguration;\n+import com.aws.greengrass.lifecyclemanager.KernelMetricsEmitter;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.testcommons.testutilities.GGServiceTestUtil;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.time.Instant;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledThreadPoolExecutor;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.deployment.DeviceConfiguration.DEVICE_PARAM_THING_NAME;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_METRICS_PUBLISH_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.junit.jupiter.api.Assertions.assertNull;\n+import static org.mockito.Mockito.doNothing;\n+import static org.mockito.Mockito.lenient;\n+import static org.mockito.Mockito.reset;\n+import static org.mockito.Mockito.spy;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+@ExtendWith({MockitoExtension.class, GGExtension.class})\n+public class TelemetryAgentTest extends GGServiceTestUtil {\n+    @TempDir\n+    protected Path tempRootDir;\n+    @Mock\n+    private MqttClient mockMqttClient;\n+    @Mock\n+    private DeviceConfiguration mockDeviceConfiguration;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> publishRequestArgumentCaptor;\n+    @Captor\n+    private ArgumentCaptor<MqttClientConnectionEvents> mqttClientConnectionEventsArgumentCaptor;\n+    @Mock", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c27c902fe03b4e85c20ece0e798143c10e7af88e"}, "originalPosition": 68}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk1MTcwMTg4", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-495170188", "createdAt": "2020-09-24T02:03:12Z", "commit": {"oid": "c27c902fe03b4e85c20ece0e798143c10e7af88e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQwMjowMzoxM1rOHXHHWg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQwMjowMzoxM1rOHXHHWg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzk5NTg2Ng==", "bodyText": "this is going to cause a kernel to be created. This is not a proper unit test", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r493995866", "createdAt": "2020-09-24T02:03:13Z", "author": {"login": "MikeDombo"}, "path": "src/test/java/com/aws/greengrass/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.greengrass.telemetry;\n+\n+import com.aws.greengrass.config.Topic;\n+import com.aws.greengrass.dependency.Context;\n+import com.aws.greengrass.deployment.DeviceConfiguration;\n+import com.aws.greengrass.lifecyclemanager.KernelMetricsEmitter;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.testcommons.testutilities.GGServiceTestUtil;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.time.Instant;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledThreadPoolExecutor;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.deployment.DeviceConfiguration.DEVICE_PARAM_THING_NAME;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_METRICS_PUBLISH_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.junit.jupiter.api.Assertions.assertNull;\n+import static org.mockito.Mockito.doNothing;\n+import static org.mockito.Mockito.lenient;\n+import static org.mockito.Mockito.reset;\n+import static org.mockito.Mockito.spy;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+@ExtendWith({MockitoExtension.class, GGExtension.class})\n+public class TelemetryAgentTest extends GGServiceTestUtil {\n+    @TempDir\n+    protected Path tempRootDir;\n+    @Mock\n+    private MqttClient mockMqttClient;\n+    @Mock\n+    private DeviceConfiguration mockDeviceConfiguration;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> publishRequestArgumentCaptor;\n+    @Captor\n+    private ArgumentCaptor<MqttClientConnectionEvents> mqttClientConnectionEventsArgumentCaptor;\n+    @Mock\n+    private ScheduledExecutorService ses;\n+    private TelemetryAgent telemetryAgent;\n+    private SystemMetricsEmitter sme;\n+    private KernelMetricsEmitter kme;\n+    private MetricsAggregator ma;\n+    @Mock\n+    private Context context;\n+\n+    @BeforeEach\n+    public void setup() {\n+        serviceFullName = \"MetricsAgentService\";\n+        initializeMockedConfig();\n+        TelemetryConfig.getInstance().setRoot(tempRootDir);\n+        ses = new ScheduledThreadPoolExecutor(3);\n+        context = new Context();\n+        sme = context.get(SystemMetricsEmitter.class);\n+        kme = context.get(KernelMetricsEmitter.class);\n+        ma = context.get(MetricsAggregator.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c27c902fe03b4e85c20ece0e798143c10e7af88e"}, "originalPosition": 86}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "138aeda5a7370b5922081cfbe5c1849c93b0ef13", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/138aeda5a7370b5922081cfbe5c1849c93b0ef13", "committedDate": "2020-09-24T02:15:01Z", "message": "mock the classes properly in tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d83ed45c0b896d9ff2f87497030a11bf8911d95c", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/d83ed45c0b896d9ff2f87497030a11bf8911d95c", "committedDate": "2020-09-24T02:37:29Z", "message": "mock the classes properly in tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "171b5ff54f9622544b78f65617c32ff3197070da", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/171b5ff54f9622544b78f65617c32ff3197070da", "committedDate": "2020-09-24T02:41:51Z", "message": "Merge branch 'telemetry-logs' of github.com:/aws/aws-greengrass-kernel into telemetry-logs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "275101e8d3963e7f4404a2ad54e48a1323ed9681", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/275101e8d3963e7f4404a2ad54e48a1323ed9681", "committedDate": "2020-09-24T02:52:34Z", "message": "close context"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "09b401ca39ef258db27a316519ee7ccffc2f747f", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/09b401ca39ef258db27a316519ee7ccffc2f747f", "committedDate": "2020-09-24T04:10:04Z", "message": "get namespaces from telemetry files directory + tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "efe8ff15000f359f3911610ea4d7470958f05db6", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/efe8ff15000f359f3911610ea4d7470958f05db6", "committedDate": "2020-09-24T04:10:17Z", "message": "Merge branch 'master' of github.com:/aws/aws-greengrass-kernel into telemetry-logs"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk1MjIwNzY2", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-495220766", "createdAt": "2020-09-24T05:01:35Z", "commit": {"oid": "efe8ff15000f359f3911610ea4d7470958f05db6"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQwNTowMTozNVrOHXJzJQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQwNTowMTozNVrOHXJzJQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDAzOTg0NQ==", "bodyText": "static", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r494039845", "createdAt": "2020-09-24T05:01:35Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/greengrass/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,375 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.greengrass.telemetry;\n+\n+import com.aws.greengrass.logging.api.Logger;\n+import com.aws.greengrass.logging.impl.GreengrassLogMessage;\n+import com.aws.greengrass.logging.impl.LogManager;\n+import com.aws.greengrass.telemetry.impl.Metric;\n+import com.aws.greengrass.telemetry.impl.MetricFactory;\n+import com.aws.greengrass.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.telemetry.models.TelemetryUnit;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.annotation.JsonAnyGetter;\n+import com.fasterxml.jackson.annotation.JsonAnySetter;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Stream;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private final ObjectMapper objectMapper = new ObjectMapper();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "efe8ff15000f359f3911610ea4d7470958f05db6"}, "originalPosition": 41}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "43b1327d170c18c423610454c698484505b791a5", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/43b1327d170c18c423610454c698484505b791a5", "committedDate": "2020-09-24T07:48:55Z", "message": "await termination"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk1ODA2NzAy", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-495806702", "createdAt": "2020-09-24T17:43:24Z", "commit": {"oid": "43b1327d170c18c423610454c698484505b791a5"}, "state": "DISMISSED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk1MDkwNDk4", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-495090498", "createdAt": "2020-09-23T22:24:43Z", "commit": {"oid": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQyMDo0NTo0NlrOHXsAeg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQyMTowNjo0MlrOHXso-w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDYwMDMxNA==", "bodyText": "remove", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r494600314", "createdAt": "2020-09-24T20:45:46Z", "author": {"login": "nikkhilmuthye"}, "path": "src/integrationtests/java/com/aws/greengrass/integrationtests/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.greengrass.integrationtests.telemetry;\n+\n+import com.aws.greengrass.config.Topics;\n+import com.aws.greengrass.dependency.State;\n+import com.aws.greengrass.integrationtests.BaseITCase;\n+import com.aws.greengrass.lifecyclemanager.Kernel;\n+import com.aws.greengrass.lifecyclemanager.exceptions.ServiceLoadException;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.MetricsAggregator;\n+import com.aws.greengrass.telemetry.MetricsPayload;\n+import com.aws.greengrass.telemetry.TelemetryAgent;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.TestInfo;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+import static org.mockito.Mockito.atLeastOnce;\n+import static org.mockito.Mockito.verify;\n+\n+@ExtendWith({GGExtension.class, MockitoExtension.class})\n+class TelemetryAgentTest extends BaseITCase {\n+    private Kernel kernel;\n+    @Mock\n+    private MqttClient mqttClient;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> captor;\n+\n+    @BeforeEach\n+    void before(TestInfo testInfo) {\n+        System.out.println(\"Running test: \" + testInfo.getDisplayName());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "43b1327d170c18c423610454c698484505b791a5"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDYwMDY0MA==", "bodyText": "The message should convey why it failed.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r494600640", "createdAt": "2020-09-24T20:46:28Z", "author": {"login": "nikkhilmuthye"}, "path": "src/integrationtests/java/com/aws/greengrass/integrationtests/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.greengrass.integrationtests.telemetry;\n+\n+import com.aws.greengrass.config.Topics;\n+import com.aws.greengrass.dependency.State;\n+import com.aws.greengrass.integrationtests.BaseITCase;\n+import com.aws.greengrass.lifecyclemanager.Kernel;\n+import com.aws.greengrass.lifecyclemanager.exceptions.ServiceLoadException;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.MetricsAggregator;\n+import com.aws.greengrass.telemetry.MetricsPayload;\n+import com.aws.greengrass.telemetry.TelemetryAgent;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.TestInfo;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+import static org.mockito.Mockito.atLeastOnce;\n+import static org.mockito.Mockito.verify;\n+\n+@ExtendWith({GGExtension.class, MockitoExtension.class})\n+class TelemetryAgentTest extends BaseITCase {\n+    private Kernel kernel;\n+    @Mock\n+    private MqttClient mqttClient;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> captor;\n+\n+    @BeforeEach\n+    void before(TestInfo testInfo) {\n+        System.out.println(\"Running test: \" + testInfo.getDisplayName());\n+        kernel = new Kernel();\n+    }\n+\n+    @AfterEach\n+    void after() {\n+        if (kernel != null) {\n+            kernel.shutdown();\n+        }\n+    }\n+\n+    @Test\n+    void GIVEN_kernel_running_with_telemetry_config_WHEN_launch_THEN_metrics_are_published() throws InterruptedException,\n+            ServiceLoadException {\n+        // GIVEN\n+        kernel.parseArgs(\"-i\", getClass().getResource(\"config.yaml\").toString());\n+        kernel.getContext().put(MqttClient.class, mqttClient);\n+        //WHEN\n+        kernel.launch();\n+        CountDownLatch telemetryRunning = new CountDownLatch(1);\n+        kernel.getContext().addGlobalStateChangeListener((service, oldState, newState) -> {\n+            if (service.getName().equals(\"TelemetryAgent\") && service.getState().equals(State.RUNNING)) {\n+                telemetryRunning.countDown();\n+            }\n+        });\n+        assertTrue(telemetryRunning.await(1, TimeUnit.MINUTES), \"TelemetryAgent is in RUNNING state.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "43b1327d170c18c423610454c698484505b791a5"}, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDYwMTIzMA==", "bodyText": "FSS and telemetry log to different topics. If you are unable to deserialize the payload, then fail.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r494601230", "createdAt": "2020-09-24T20:47:38Z", "author": {"login": "nikkhilmuthye"}, "path": "src/integrationtests/java/com/aws/greengrass/integrationtests/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,127 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.greengrass.integrationtests.telemetry;\n+\n+import com.aws.greengrass.config.Topics;\n+import com.aws.greengrass.dependency.State;\n+import com.aws.greengrass.integrationtests.BaseITCase;\n+import com.aws.greengrass.lifecyclemanager.Kernel;\n+import com.aws.greengrass.lifecyclemanager.exceptions.ServiceLoadException;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.MetricsAggregator;\n+import com.aws.greengrass.telemetry.MetricsPayload;\n+import com.aws.greengrass.telemetry.TelemetryAgent;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.TestInfo;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+import static org.mockito.Mockito.timeout;\n+import static org.mockito.Mockito.verify;\n+\n+@ExtendWith({GGExtension.class, MockitoExtension.class})\n+class TelemetryAgentTest extends BaseITCase {\n+    private Kernel kernel;\n+    @Mock\n+    private MqttClient mqttClient;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> captor;\n+\n+    @BeforeEach\n+    void before(TestInfo testInfo) {\n+        System.out.println(\"Running test: \" + testInfo.getDisplayName());\n+        kernel = new Kernel();\n+    }\n+\n+    @AfterEach\n+    void after() {\n+        if (kernel != null) {\n+            mqttClient.close();\n+            kernel.shutdown();\n+        }\n+    }\n+\n+    @Test\n+    void GIVEN_kernel_running_with_telemetry_config_WHEN_launch_THEN_metrics_are_published() throws InterruptedException,\n+            ServiceLoadException {\n+        // GIVEN\n+        kernel.parseArgs(\"-i\", getClass().getResource(\"config.yaml\").toString());\n+        CountDownLatch mainRunning = new CountDownLatch(2);\n+        kernel.getContext().addGlobalStateChangeListener((service, oldState, newState) -> {\n+            if (service.getName().equals(\"main\") && newState.equals(State.RUNNING)) {\n+                mainRunning.countDown();\n+            }\n+        });\n+        kernel.getContext().put(MqttClient.class, mqttClient);\n+        //WHEN\n+        kernel.launch();\n+\n+        Topics parameterTopics = kernel.getConfig()\n+                .lookupTopics(SERVICES_NAMESPACE_TOPIC, TELEMETRY_AGENT_SERVICE_TOPICS, PARAMETERS_CONFIG_KEY);\n+        int aggregateInterval = Coerce.toInt(parameterTopics.find(TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC));\n+        int periodicInterval = Coerce.toInt(parameterTopics.find(TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC));\n+        //telemetry configurations are set correctly\n+        assertEquals(3, aggregateInterval);\n+        assertEquals(2, periodicInterval);\n+        Topics runtimeTopics = kernel.getConfig()\n+                .lookupTopics(SERVICES_NAMESPACE_TOPIC, TELEMETRY_AGENT_SERVICE_TOPICS, RUNTIME_STORE_NAMESPACE_TOPIC);\n+        long lastAgg = Coerce.toLong(runtimeTopics.find(TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC));\n+\n+        //wait for at least 4 seconds as the first aggregation occurs at 3rd second.\n+        Thread.sleep(4000);\n+        assertTrue(Coerce.toLong(runtimeTopics.find(TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC)) > lastAgg);\n+\n+        TelemetryAgent ma = (TelemetryAgent) kernel.locate(\"TelemetryAgent\");\n+        long delay = ma.getPeriodicPublishMetricsFuture().getDelay(TimeUnit.SECONDS);\n+        assertTrue(delay < periodicInterval);\n+        // telemetry logs are always written to ~root/telemetry\n+        assertEquals(kernel.getRootPath().resolve(\"telemetry\"), TelemetryConfig.getTelemetryDirectory());\n+        // THEN\n+        verify(mqttClient, timeout(1000).atLeastOnce()).publish(captor.capture());\n+        List<PublishRequest> prs = captor.getAllValues();\n+        for (PublishRequest pr : prs) {\n+            try {\n+                MetricsPayload mp = new ObjectMapper().readValue(pr.getPayload(), MetricsPayload.class);\n+                //There will be nothing to aggregate as publish happens at 1st second and aggregation at 2nd second.\n+                // So, there will only one accumulated data point for each namespace during the first publish\n+                assertEquals(kernel.getContext().get(MetricsAggregator.class)\n+                        .getNamespaceSet().getNamespaces().size(), mp.getAggregatedMetricList().size());\n+                assertEquals(QualityOfService.AT_LEAST_ONCE, pr.getQos());\n+                assertEquals(DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC.replace(\"{thingName}\", \"\"), pr.getTopic());\n+                assertEquals(\"2020-07-30\", mp.getSchema());\n+                // enough to verify the first message of type MetricsPayload\n+                break;\n+            } catch (IOException e) {\n+                System.out.println(\"Ignore if the publish message is not of MetricsPayload type\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzgzMTYxNw=="}, "originalCommit": {"oid": "b2fcd1439f7efc3383cdbf81748de09d0311fc4e"}, "originalPosition": 122}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDYxMDIzNA==", "bodyText": "nit: Make this TODO say, Get accumulated data points during aggregation and cache it to the disk.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r494610234", "createdAt": "2020-09-24T21:05:43Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/greengrass/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,375 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.greengrass.telemetry;\n+\n+import com.aws.greengrass.logging.api.Logger;\n+import com.aws.greengrass.logging.impl.GreengrassLogMessage;\n+import com.aws.greengrass.logging.impl.LogManager;\n+import com.aws.greengrass.telemetry.impl.Metric;\n+import com.aws.greengrass.telemetry.impl.MetricFactory;\n+import com.aws.greengrass.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.telemetry.models.TelemetryUnit;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.annotation.JsonAnyGetter;\n+import com.fasterxml.jackson.annotation.JsonAnySetter;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Stream;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private static final ObjectMapper objectMapper = new ObjectMapper();\n+    private final MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+\n+    /**\n+     * Read namespaces from files.\n+     * Telemetry log files format : fileName + \"_%d{yyyy_MM_dd_HH}_%i\" + \".\" + prefix\n+     *\n+     * @return namespace set\n+     */\n+    public static Set<String> getNamespaceSet() {\n+        Set<String> namespaces = new HashSet<>();\n+        try (Stream<Path> paths = Files\n+                .walk(TelemetryConfig.getTelemetryDirectory())\n+                .filter(Files::isRegularFile)) {\n+            paths.forEach((p) -> {\n+                String fileName = Coerce.toString(p.getFileName()).split(\".log\")[0];\n+                if (fileName.contains(\"_\")) {\n+                    fileName = fileName.split(\"_\")[0];\n+                }\n+                if (!fileName.equalsIgnoreCase(AGGREGATE_METRICS_FILE)) {\n+                    namespaces.add(fileName);\n+                }\n+            });\n+        } catch (IOException e) {\n+            logger.atError().cause(e).log(\"Unable to read files from the telemetry directory\");\n+        }\n+        return namespaces;\n+    }\n+\n+    /**\n+     * This method performs aggregation on the metrics emitted over the aggregation interval and writes them to a file.\n+     *\n+     * @param lastAgg       timestamp at which the last aggregation was done.\n+     * @param currTimestamp timestamp at which the current aggregation is initiated.\n+     */\n+    protected void aggregateMetrics(long lastAgg, long currTimestamp) {\n+        for (String namespace : getNamespaceSet()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<String, List<Metric>> metrics = new HashMap<>();\n+            // Read from the Telemetry/namespace*.log file.\n+            // TODO : Read only those files that are modified after the last aggregation.\n+            // file.lastModified() behavior is platform dependent.\n+            try (Stream<Path> paths = Files\n+                    .walk(TelemetryConfig.getTelemetryDirectory())\n+                    .filter(Files::isRegularFile)\n+                    .filter((path) -> Coerce.toString(path.getFileName()).startsWith(namespace))\n+            ) {\n+                paths.forEach(path -> {\n+                    try (Stream<String> logs = Files.lines(path)) {\n+                        logs.forEach((log) -> {\n+                            try {\n+                                /* {\"thread\":\"pool-3-thread-4\",\"level\":\"TRACE\",\"eventType\":null,\"message\":\"{\\\"NS\\\":\n+\n+                                \\\"SystemMetrics\\\",\\\"N\\\":\\\"TotalNumberOfFDs\\\",\\\"U\\\":\\\"Count\\\",\\\"A\\\":\\\"Average\\\",\\\"V\\\"\n+\n+                                :4583,\\\"TS\\\":1600127641506}\",\"contexts\":{},\"loggerName\":\"Metrics-SystemMetrics\",\n+\n+                                \"timestamp\":1600127641506,\"cause\":null} */\n+                                GreengrassLogMessage egLog = objectMapper.readValue(log,\n+                                        GreengrassLogMessage.class);\n+                                Metric mdp = objectMapper.readValue(egLog.getMessage(), Metric.class);\n+                                // Avoid the metrics that are emitted at/after the currTimestamp and before the\n+                                // aggregation interval\n+                                if (mdp != null && currTimestamp > mdp.getTimestamp() && mdp.getTimestamp()\n+                                        >= lastAgg) {\n+                                    metrics.computeIfAbsent(mdp.getName(), k -> new ArrayList<>()).add(mdp);\n+                                }\n+                            } catch (IOException e) {\n+                                logger.atError().cause(e).log(\"Unable to parse the metric log.\");\n+                            }\n+                        });\n+                    } catch (IOException e) {\n+                        logger.atError().cause(e).log(\"Unable to parse the emitted metric log file.\");\n+                    }\n+                });\n+            } catch (IOException e) {\n+                logger.atError().cause(e).log(\"Unable to read metric files from the directory\");\n+            }\n+            aggMetrics.setNamespace(namespace);\n+            aggMetrics.setTimestamp(currTimestamp);\n+            aggMetrics.setMetrics(doAggregation(metrics));\n+            metricFactory.logMetrics(new TelemetryLoggerMessage(aggMetrics));\n+        }\n+    }\n+\n+    /**\n+     * This function takes in the map of metrics with metric name as key and returns a list of metrics with aggregation.\n+     * Example:\n+     * Input:\n+     * NumOfComponentsInstalled\n+     * |___GreengrassComponents,NumOfComponentsInstalled,Count,Average,10,1234567890\n+     * |___GreengrassComponents,NumOfComponentsInstalled,Count,Average,15,1234567891\n+     * NumOfComponentsBroken\n+     * |___GreengrassComponents,NumOfComponentsBroken,Count,Average,10,1234567890\n+     * |___GreengrassComponents,NumOfComponentsBroken,Count,Average,20,1234567891\n+     * Output:\n+     * |___N -  NumOfComponentsInstalled,Average - 12.5,U - Count\n+     * |___N -  NumOfComponentsBroken,Average - 15,U - Count\n+     *\n+     * @param map metric name -> metric\n+     * @return a list of {@link AggregatedMetric.Metric}\n+     */\n+    private List<AggregatedMetric.Metric> doAggregation(Map<String, List<Metric>> map) {\n+        List<AggregatedMetric.Metric> aggMetrics = new ArrayList<>();\n+        for (Map.Entry<String, List<Metric>> metric : map.entrySet()) {\n+            String metricName = metric.getKey();\n+            List<Metric> metrics = metric.getValue();\n+            String aggregationType = Coerce.toString(metrics.get(0).getAggregation());\n+            List<Double> values = new ArrayList<>();\n+            for (Metric m : metrics) {\n+                values.add(Coerce.toDouble(m.getValue()));\n+            }\n+            double aggregation = values.isEmpty() ? 0 : getAggregatedValue(values, aggregationType);\n+            Map<String, Object> value = new HashMap<>();\n+            value.put(aggregationType, aggregation);\n+            AggregatedMetric.Metric m = AggregatedMetric.Metric.builder()\n+                    .name(metricName)\n+                    .unit(metrics.get(0).getUnit())\n+                    .value(value)\n+                    .build();\n+            aggMetrics.add(m);\n+        }\n+        return aggMetrics;\n+    }\n+\n+    /**\n+     * This function returns the set of all the aggregated metric data points that are to be published to the cloud\n+     * since the last upload. This also includes one extra aggregated point for each namespace which is the aggregation\n+     * of aggregated points in that publish interval.\n+     *\n+     * @param lastPublish   timestamp at which the last publish was done.\n+     * @param currTimestamp timestamp at which the current publish is initiated.\n+     */\n+    protected Map<Long, List<AggregatedMetric>> getMetricsToPublish(long lastPublish, long currTimestamp) {\n+        Map<Long, List<AggregatedMetric>> aggUploadMetrics = new HashMap<>();\n+        // Read from the Telemetry/AggregatedMetrics.log file.\n+        // TODO : Read only those files that are modified after the last publish.\n+        try (Stream<Path> paths = Files\n+                .walk(TelemetryConfig.getTelemetryDirectory())\n+                .filter(Files::isRegularFile)\n+                .filter((path) -> Coerce.toString(path.getFileName()).startsWith(AGGREGATE_METRICS_FILE))) {\n+            paths.forEach(path -> {\n+                try (Stream<String> logs = Files.lines(path)) {\n+                    logs.forEach(log -> {\n+                        try {\n+                            /* {\"thread\":\"main\",\"level\":\"TRACE\",\"eventType\":null,\n+\n+                            \"message\":\"{\\\"TS\\\":1599617227533,\\\"NS\\\":\\\"SystemMetrics\\\",\\\"M\\\":[{\\\"N\\\":\\\"CpuUsage\\\",\n+\n+                            \\\"V\\\":60.0,\\\"U\\\":\\\"Percent\\\"},{\\\"N\\\":\\\"TotalNumberOfFDs\\\",\\\"V\\\":6000.0,\\\"U\\\":\\\"Count\\\"},\n+\n+                            {\\\"N\\\":\\\"SystemMemUsage\\\",\\\"V\\\":3000.0,\\\"U\\\":\\\"Megabytes\\\"}]}\",\"contexts\":{},\"loggerName\":\n+\n+                            \"Metrics-AggregateMetrics\",\"timestamp\":1599617227595,\"cause\":null} */\n+                            GreengrassLogMessage egLog = objectMapper.readValue(log,\n+                                    GreengrassLogMessage.class);\n+                            AggregatedMetric am = objectMapper.readValue(egLog.getMessage(),\n+                                    AggregatedMetric.class);\n+                            // Avoid the metrics that are aggregated at/after the currTimestamp and before the\n+                            // upload interval\n+                            if (am != null && currTimestamp > am.getTimestamp() && am.getTimestamp() >= lastPublish) {\n+                                aggUploadMetrics.computeIfAbsent(currTimestamp, k -> new ArrayList<>()).add(am);\n+                            }\n+                        } catch (JsonProcessingException e) {\n+                            logger.atError().cause(e).log(\"Unable to parse the aggregated metric log.\");\n+                        }\n+                    });\n+                } catch (IOException e) {\n+                    logger.atError().cause(e).log(\"Unable to parse the aggregated metric log file.\");\n+                }\n+            });\n+        } catch (IOException e) {\n+            logger.atError().cause(e).log(\"Unable to read the aggregated metric files from the directory\");\n+        }\n+        aggUploadMetrics.putIfAbsent(currTimestamp, new ArrayList<>());\n+        //Along with the aggregated data points, we need to collect an additional data point for each metric which is\n+        // like the aggregation of aggregated data points.\n+        // TODO : Do cumulative average rather than performing average on average", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "43b1327d170c18c423610454c698484505b791a5"}, "originalPosition": 218}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDYxMDU5Nw==", "bodyText": "Does this need to be public? If so, put it in its own class.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r494610597", "createdAt": "2020-09-24T21:06:29Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/greengrass/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,375 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.greengrass.telemetry;\n+\n+import com.aws.greengrass.logging.api.Logger;\n+import com.aws.greengrass.logging.impl.GreengrassLogMessage;\n+import com.aws.greengrass.logging.impl.LogManager;\n+import com.aws.greengrass.telemetry.impl.Metric;\n+import com.aws.greengrass.telemetry.impl.MetricFactory;\n+import com.aws.greengrass.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.telemetry.models.TelemetryUnit;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.annotation.JsonAnyGetter;\n+import com.fasterxml.jackson.annotation.JsonAnySetter;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Stream;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private static final ObjectMapper objectMapper = new ObjectMapper();\n+    private final MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+\n+    /**\n+     * Read namespaces from files.\n+     * Telemetry log files format : fileName + \"_%d{yyyy_MM_dd_HH}_%i\" + \".\" + prefix\n+     *\n+     * @return namespace set\n+     */\n+    public static Set<String> getNamespaceSet() {\n+        Set<String> namespaces = new HashSet<>();\n+        try (Stream<Path> paths = Files\n+                .walk(TelemetryConfig.getTelemetryDirectory())\n+                .filter(Files::isRegularFile)) {\n+            paths.forEach((p) -> {\n+                String fileName = Coerce.toString(p.getFileName()).split(\".log\")[0];\n+                if (fileName.contains(\"_\")) {\n+                    fileName = fileName.split(\"_\")[0];\n+                }\n+                if (!fileName.equalsIgnoreCase(AGGREGATE_METRICS_FILE)) {\n+                    namespaces.add(fileName);\n+                }\n+            });\n+        } catch (IOException e) {\n+            logger.atError().cause(e).log(\"Unable to read files from the telemetry directory\");\n+        }\n+        return namespaces;\n+    }\n+\n+    /**\n+     * This method performs aggregation on the metrics emitted over the aggregation interval and writes them to a file.\n+     *\n+     * @param lastAgg       timestamp at which the last aggregation was done.\n+     * @param currTimestamp timestamp at which the current aggregation is initiated.\n+     */\n+    protected void aggregateMetrics(long lastAgg, long currTimestamp) {\n+        for (String namespace : getNamespaceSet()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<String, List<Metric>> metrics = new HashMap<>();\n+            // Read from the Telemetry/namespace*.log file.\n+            // TODO : Read only those files that are modified after the last aggregation.\n+            // file.lastModified() behavior is platform dependent.\n+            try (Stream<Path> paths = Files\n+                    .walk(TelemetryConfig.getTelemetryDirectory())\n+                    .filter(Files::isRegularFile)\n+                    .filter((path) -> Coerce.toString(path.getFileName()).startsWith(namespace))\n+            ) {\n+                paths.forEach(path -> {\n+                    try (Stream<String> logs = Files.lines(path)) {\n+                        logs.forEach((log) -> {\n+                            try {\n+                                /* {\"thread\":\"pool-3-thread-4\",\"level\":\"TRACE\",\"eventType\":null,\"message\":\"{\\\"NS\\\":\n+\n+                                \\\"SystemMetrics\\\",\\\"N\\\":\\\"TotalNumberOfFDs\\\",\\\"U\\\":\\\"Count\\\",\\\"A\\\":\\\"Average\\\",\\\"V\\\"\n+\n+                                :4583,\\\"TS\\\":1600127641506}\",\"contexts\":{},\"loggerName\":\"Metrics-SystemMetrics\",\n+\n+                                \"timestamp\":1600127641506,\"cause\":null} */\n+                                GreengrassLogMessage egLog = objectMapper.readValue(log,\n+                                        GreengrassLogMessage.class);\n+                                Metric mdp = objectMapper.readValue(egLog.getMessage(), Metric.class);\n+                                // Avoid the metrics that are emitted at/after the currTimestamp and before the\n+                                // aggregation interval\n+                                if (mdp != null && currTimestamp > mdp.getTimestamp() && mdp.getTimestamp()\n+                                        >= lastAgg) {\n+                                    metrics.computeIfAbsent(mdp.getName(), k -> new ArrayList<>()).add(mdp);\n+                                }\n+                            } catch (IOException e) {\n+                                logger.atError().cause(e).log(\"Unable to parse the metric log.\");\n+                            }\n+                        });\n+                    } catch (IOException e) {\n+                        logger.atError().cause(e).log(\"Unable to parse the emitted metric log file.\");\n+                    }\n+                });\n+            } catch (IOException e) {\n+                logger.atError().cause(e).log(\"Unable to read metric files from the directory\");\n+            }\n+            aggMetrics.setNamespace(namespace);\n+            aggMetrics.setTimestamp(currTimestamp);\n+            aggMetrics.setMetrics(doAggregation(metrics));\n+            metricFactory.logMetrics(new TelemetryLoggerMessage(aggMetrics));\n+        }\n+    }\n+\n+    /**\n+     * This function takes in the map of metrics with metric name as key and returns a list of metrics with aggregation.\n+     * Example:\n+     * Input:\n+     * NumOfComponentsInstalled\n+     * |___GreengrassComponents,NumOfComponentsInstalled,Count,Average,10,1234567890\n+     * |___GreengrassComponents,NumOfComponentsInstalled,Count,Average,15,1234567891\n+     * NumOfComponentsBroken\n+     * |___GreengrassComponents,NumOfComponentsBroken,Count,Average,10,1234567890\n+     * |___GreengrassComponents,NumOfComponentsBroken,Count,Average,20,1234567891\n+     * Output:\n+     * |___N -  NumOfComponentsInstalled,Average - 12.5,U - Count\n+     * |___N -  NumOfComponentsBroken,Average - 15,U - Count\n+     *\n+     * @param map metric name -> metric\n+     * @return a list of {@link AggregatedMetric.Metric}\n+     */\n+    private List<AggregatedMetric.Metric> doAggregation(Map<String, List<Metric>> map) {\n+        List<AggregatedMetric.Metric> aggMetrics = new ArrayList<>();\n+        for (Map.Entry<String, List<Metric>> metric : map.entrySet()) {\n+            String metricName = metric.getKey();\n+            List<Metric> metrics = metric.getValue();\n+            String aggregationType = Coerce.toString(metrics.get(0).getAggregation());\n+            List<Double> values = new ArrayList<>();\n+            for (Metric m : metrics) {\n+                values.add(Coerce.toDouble(m.getValue()));\n+            }\n+            double aggregation = values.isEmpty() ? 0 : getAggregatedValue(values, aggregationType);\n+            Map<String, Object> value = new HashMap<>();\n+            value.put(aggregationType, aggregation);\n+            AggregatedMetric.Metric m = AggregatedMetric.Metric.builder()\n+                    .name(metricName)\n+                    .unit(metrics.get(0).getUnit())\n+                    .value(value)\n+                    .build();\n+            aggMetrics.add(m);\n+        }\n+        return aggMetrics;\n+    }\n+\n+    /**\n+     * This function returns the set of all the aggregated metric data points that are to be published to the cloud\n+     * since the last upload. This also includes one extra aggregated point for each namespace which is the aggregation\n+     * of aggregated points in that publish interval.\n+     *\n+     * @param lastPublish   timestamp at which the last publish was done.\n+     * @param currTimestamp timestamp at which the current publish is initiated.\n+     */\n+    protected Map<Long, List<AggregatedMetric>> getMetricsToPublish(long lastPublish, long currTimestamp) {\n+        Map<Long, List<AggregatedMetric>> aggUploadMetrics = new HashMap<>();\n+        // Read from the Telemetry/AggregatedMetrics.log file.\n+        // TODO : Read only those files that are modified after the last publish.\n+        try (Stream<Path> paths = Files\n+                .walk(TelemetryConfig.getTelemetryDirectory())\n+                .filter(Files::isRegularFile)\n+                .filter((path) -> Coerce.toString(path.getFileName()).startsWith(AGGREGATE_METRICS_FILE))) {\n+            paths.forEach(path -> {\n+                try (Stream<String> logs = Files.lines(path)) {\n+                    logs.forEach(log -> {\n+                        try {\n+                            /* {\"thread\":\"main\",\"level\":\"TRACE\",\"eventType\":null,\n+\n+                            \"message\":\"{\\\"TS\\\":1599617227533,\\\"NS\\\":\\\"SystemMetrics\\\",\\\"M\\\":[{\\\"N\\\":\\\"CpuUsage\\\",\n+\n+                            \\\"V\\\":60.0,\\\"U\\\":\\\"Percent\\\"},{\\\"N\\\":\\\"TotalNumberOfFDs\\\",\\\"V\\\":6000.0,\\\"U\\\":\\\"Count\\\"},\n+\n+                            {\\\"N\\\":\\\"SystemMemUsage\\\",\\\"V\\\":3000.0,\\\"U\\\":\\\"Megabytes\\\"}]}\",\"contexts\":{},\"loggerName\":\n+\n+                            \"Metrics-AggregateMetrics\",\"timestamp\":1599617227595,\"cause\":null} */\n+                            GreengrassLogMessage egLog = objectMapper.readValue(log,\n+                                    GreengrassLogMessage.class);\n+                            AggregatedMetric am = objectMapper.readValue(egLog.getMessage(),\n+                                    AggregatedMetric.class);\n+                            // Avoid the metrics that are aggregated at/after the currTimestamp and before the\n+                            // upload interval\n+                            if (am != null && currTimestamp > am.getTimestamp() && am.getTimestamp() >= lastPublish) {\n+                                aggUploadMetrics.computeIfAbsent(currTimestamp, k -> new ArrayList<>()).add(am);\n+                            }\n+                        } catch (JsonProcessingException e) {\n+                            logger.atError().cause(e).log(\"Unable to parse the aggregated metric log.\");\n+                        }\n+                    });\n+                } catch (IOException e) {\n+                    logger.atError().cause(e).log(\"Unable to parse the aggregated metric log file.\");\n+                }\n+            });\n+        } catch (IOException e) {\n+            logger.atError().cause(e).log(\"Unable to read the aggregated metric files from the directory\");\n+        }\n+        aggUploadMetrics.putIfAbsent(currTimestamp, new ArrayList<>());\n+        //Along with the aggregated data points, we need to collect an additional data point for each metric which is\n+        // like the aggregation of aggregated data points.\n+        // TODO : Do cumulative average rather than performing average on average\n+        aggUploadMetrics.compute(currTimestamp, (k, v) -> {\n+            v.addAll(getAggForThePublishInterval(aggUploadMetrics.get(currTimestamp), currTimestamp));\n+            return v;\n+        });\n+        return aggUploadMetrics;\n+    }\n+\n+    /**\n+     * This function takes a list of aggregated metrics and returns their aggregation in a list(Aggregation of\n+     * aggregated metrics). This is published to the cloud along with the aggregated metric points\n+     * Example:\n+     * Input:\n+     * TS:123456\n+     * NS:GreengrassComponents\n+     * |___N -  NumOfComponentsInstalled,Average - 20,U - Count\n+     * |___N -  NumOfComponentsBroken,Average - 5,U - Count\n+     * TS:123457\n+     * NS:GreengrassComponents\n+     * |___N -  NumOfComponentsInstalled,Average - 10,U - Count\n+     * |___N -  NumOfComponentsBroken,Average - 15,U - Count\n+     * Output:\n+     * TS:123457\n+     * NS:GreengrassComponents\n+     * |___N -  NumOfComponentsInstalled,Average - 15,U - Count\n+     * |___N -  NumOfComponentsBroken,Average - 10,U - Count\n+     *\n+     * @param aggList list of {@link AggregatedMetric}\n+     * @return a list of {@link AggregatedMetric}\n+     */\n+    private List<AggregatedMetric> getAggForThePublishInterval(List<AggregatedMetric> aggList, long currTimestamp) {\n+        List<AggregatedMetric> list = new ArrayList<>();\n+        for (String namespace : getNamespaceSet()) {\n+            HashMap<String, List<AggregatedMetric.Metric>> metrics = new HashMap<>();\n+            AggregatedMetric newAgg = new AggregatedMetric();\n+            for (AggregatedMetric am : aggList) {\n+                if (am.getNamespace().equals(namespace)) {\n+                    for (AggregatedMetric.Metric m : am.getMetrics()) {\n+                        metrics.computeIfAbsent(m.getName(), k -> new ArrayList<>()).add(m);\n+                    }\n+                }\n+            }\n+            newAgg.setNamespace(namespace);\n+            newAgg.setTimestamp(currTimestamp);\n+            newAgg.setMetrics(doAggregationForPublish(metrics));\n+            list.add(newAgg);\n+        }\n+        return list;\n+    }\n+\n+    /**\n+     * This function takes in the map of aggregated metrics with metric name as key and returns a list of metrics with\n+     * aggregation.\n+     * Input:\n+     * NumOfComponentsInstalled\n+     * |___N - NumOfComponentsInstalled,Average - 10,U - Count\n+     * |___N - NumOfComponentsInstalled,Average - 15,U - Count\n+     * NumOfComponentsBroken\n+     * |___N - NumOfComponentsBroken,Average - 10,U - Count\n+     * |___N - NumOfComponentsBroken,Average - 20,U - Count\n+     * Output:\n+     * |___N - NumOfComponentsInstalled,Average - 12.5,U - Count\n+     * |___N - NumOfComponentsBroken,Average - 15,U - Count\n+     *\n+     * @param map metric name -> aggregated metric\n+     * @return list of {@link AggregatedMetric.Metric }\n+     */\n+    private List<AggregatedMetric.Metric> doAggregationForPublish(Map<String, List<AggregatedMetric.Metric>> map) {\n+        List<AggregatedMetric.Metric> aggMetrics = new ArrayList<>();\n+        for (Map.Entry<String, List<AggregatedMetric.Metric>> metric : map.entrySet()) {\n+            List<AggregatedMetric.Metric> metrics = metric.getValue();\n+            List<Double> values = new ArrayList<>();\n+            metrics.get(0).getValue().forEach((aggType, aggValue) -> {\n+                metrics.forEach((v) -> values.add(Coerce.toDouble(v.getValue().get(aggType))));\n+                Map<String, Object> value = new HashMap<>();\n+                value.put(aggType, values.isEmpty() ? 0 : getAggregatedValue(values, aggType));\n+                AggregatedMetric.Metric m = AggregatedMetric.Metric.builder()\n+                        .name(metric.getKey())\n+                        .unit(metrics.get(0).getUnit())\n+                        .value(value)\n+                        .build();\n+                aggMetrics.add(m);\n+            });\n+        }\n+        return aggMetrics;\n+    }\n+\n+    /**\n+     * This method performs aggregation on the list of values of the metrics.\n+     *\n+     * @param values          list of the values extracted from the metrics\n+     * @param aggregationType string value of {@link com.aws.greengrass.telemetry.models.TelemetryAggregation}\n+     * @return returns an aggregated value for the entire list.\n+     */\n+    private double getAggregatedValue(List<Double> values, String aggregationType) {\n+        double aggregation = 0;\n+        switch (aggregationType) {\n+            case \"Average\":\n+                aggregation = values.stream().mapToDouble(Coerce::toDouble).sum();\n+                if (!values.isEmpty()) {\n+                    aggregation = aggregation / values.size();\n+                }\n+                break;\n+            case \"Sum\":\n+                aggregation = values.stream().mapToDouble(Coerce::toDouble).sum();\n+                break;\n+            case \"Maximum\":\n+                aggregation = values.stream().mapToDouble(Coerce::toDouble).max().getAsDouble();\n+                break;\n+            case \"Minimum\":\n+                aggregation = values.stream().mapToDouble(Coerce::toDouble).min().getAsDouble();\n+                break;\n+            default:\n+                logger.atError().log(\"Unknown aggregation type: {}\", aggregationType);\n+                break;\n+        }\n+        return aggregation;\n+    }\n+\n+    @Data\n+    @Builder\n+    @NoArgsConstructor\n+    @AllArgsConstructor\n+    public static class AggregatedMetric {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "43b1327d170c18c423610454c698484505b791a5"}, "originalPosition": 341}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDYxMDY4Mw==", "bodyText": "same here", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r494610683", "createdAt": "2020-09-24T21:06:42Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/greengrass/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,375 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.greengrass.telemetry;\n+\n+import com.aws.greengrass.logging.api.Logger;\n+import com.aws.greengrass.logging.impl.GreengrassLogMessage;\n+import com.aws.greengrass.logging.impl.LogManager;\n+import com.aws.greengrass.telemetry.impl.Metric;\n+import com.aws.greengrass.telemetry.impl.MetricFactory;\n+import com.aws.greengrass.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.telemetry.models.TelemetryUnit;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.annotation.JsonAnyGetter;\n+import com.fasterxml.jackson.annotation.JsonAnySetter;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Stream;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private static final ObjectMapper objectMapper = new ObjectMapper();\n+    private final MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+\n+    /**\n+     * Read namespaces from files.\n+     * Telemetry log files format : fileName + \"_%d{yyyy_MM_dd_HH}_%i\" + \".\" + prefix\n+     *\n+     * @return namespace set\n+     */\n+    public static Set<String> getNamespaceSet() {\n+        Set<String> namespaces = new HashSet<>();\n+        try (Stream<Path> paths = Files\n+                .walk(TelemetryConfig.getTelemetryDirectory())\n+                .filter(Files::isRegularFile)) {\n+            paths.forEach((p) -> {\n+                String fileName = Coerce.toString(p.getFileName()).split(\".log\")[0];\n+                if (fileName.contains(\"_\")) {\n+                    fileName = fileName.split(\"_\")[0];\n+                }\n+                if (!fileName.equalsIgnoreCase(AGGREGATE_METRICS_FILE)) {\n+                    namespaces.add(fileName);\n+                }\n+            });\n+        } catch (IOException e) {\n+            logger.atError().cause(e).log(\"Unable to read files from the telemetry directory\");\n+        }\n+        return namespaces;\n+    }\n+\n+    /**\n+     * This method performs aggregation on the metrics emitted over the aggregation interval and writes them to a file.\n+     *\n+     * @param lastAgg       timestamp at which the last aggregation was done.\n+     * @param currTimestamp timestamp at which the current aggregation is initiated.\n+     */\n+    protected void aggregateMetrics(long lastAgg, long currTimestamp) {\n+        for (String namespace : getNamespaceSet()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<String, List<Metric>> metrics = new HashMap<>();\n+            // Read from the Telemetry/namespace*.log file.\n+            // TODO : Read only those files that are modified after the last aggregation.\n+            // file.lastModified() behavior is platform dependent.\n+            try (Stream<Path> paths = Files\n+                    .walk(TelemetryConfig.getTelemetryDirectory())\n+                    .filter(Files::isRegularFile)\n+                    .filter((path) -> Coerce.toString(path.getFileName()).startsWith(namespace))\n+            ) {\n+                paths.forEach(path -> {\n+                    try (Stream<String> logs = Files.lines(path)) {\n+                        logs.forEach((log) -> {\n+                            try {\n+                                /* {\"thread\":\"pool-3-thread-4\",\"level\":\"TRACE\",\"eventType\":null,\"message\":\"{\\\"NS\\\":\n+\n+                                \\\"SystemMetrics\\\",\\\"N\\\":\\\"TotalNumberOfFDs\\\",\\\"U\\\":\\\"Count\\\",\\\"A\\\":\\\"Average\\\",\\\"V\\\"\n+\n+                                :4583,\\\"TS\\\":1600127641506}\",\"contexts\":{},\"loggerName\":\"Metrics-SystemMetrics\",\n+\n+                                \"timestamp\":1600127641506,\"cause\":null} */\n+                                GreengrassLogMessage egLog = objectMapper.readValue(log,\n+                                        GreengrassLogMessage.class);\n+                                Metric mdp = objectMapper.readValue(egLog.getMessage(), Metric.class);\n+                                // Avoid the metrics that are emitted at/after the currTimestamp and before the\n+                                // aggregation interval\n+                                if (mdp != null && currTimestamp > mdp.getTimestamp() && mdp.getTimestamp()\n+                                        >= lastAgg) {\n+                                    metrics.computeIfAbsent(mdp.getName(), k -> new ArrayList<>()).add(mdp);\n+                                }\n+                            } catch (IOException e) {\n+                                logger.atError().cause(e).log(\"Unable to parse the metric log.\");\n+                            }\n+                        });\n+                    } catch (IOException e) {\n+                        logger.atError().cause(e).log(\"Unable to parse the emitted metric log file.\");\n+                    }\n+                });\n+            } catch (IOException e) {\n+                logger.atError().cause(e).log(\"Unable to read metric files from the directory\");\n+            }\n+            aggMetrics.setNamespace(namespace);\n+            aggMetrics.setTimestamp(currTimestamp);\n+            aggMetrics.setMetrics(doAggregation(metrics));\n+            metricFactory.logMetrics(new TelemetryLoggerMessage(aggMetrics));\n+        }\n+    }\n+\n+    /**\n+     * This function takes in the map of metrics with metric name as key and returns a list of metrics with aggregation.\n+     * Example:\n+     * Input:\n+     * NumOfComponentsInstalled\n+     * |___GreengrassComponents,NumOfComponentsInstalled,Count,Average,10,1234567890\n+     * |___GreengrassComponents,NumOfComponentsInstalled,Count,Average,15,1234567891\n+     * NumOfComponentsBroken\n+     * |___GreengrassComponents,NumOfComponentsBroken,Count,Average,10,1234567890\n+     * |___GreengrassComponents,NumOfComponentsBroken,Count,Average,20,1234567891\n+     * Output:\n+     * |___N -  NumOfComponentsInstalled,Average - 12.5,U - Count\n+     * |___N -  NumOfComponentsBroken,Average - 15,U - Count\n+     *\n+     * @param map metric name -> metric\n+     * @return a list of {@link AggregatedMetric.Metric}\n+     */\n+    private List<AggregatedMetric.Metric> doAggregation(Map<String, List<Metric>> map) {\n+        List<AggregatedMetric.Metric> aggMetrics = new ArrayList<>();\n+        for (Map.Entry<String, List<Metric>> metric : map.entrySet()) {\n+            String metricName = metric.getKey();\n+            List<Metric> metrics = metric.getValue();\n+            String aggregationType = Coerce.toString(metrics.get(0).getAggregation());\n+            List<Double> values = new ArrayList<>();\n+            for (Metric m : metrics) {\n+                values.add(Coerce.toDouble(m.getValue()));\n+            }\n+            double aggregation = values.isEmpty() ? 0 : getAggregatedValue(values, aggregationType);\n+            Map<String, Object> value = new HashMap<>();\n+            value.put(aggregationType, aggregation);\n+            AggregatedMetric.Metric m = AggregatedMetric.Metric.builder()\n+                    .name(metricName)\n+                    .unit(metrics.get(0).getUnit())\n+                    .value(value)\n+                    .build();\n+            aggMetrics.add(m);\n+        }\n+        return aggMetrics;\n+    }\n+\n+    /**\n+     * This function returns the set of all the aggregated metric data points that are to be published to the cloud\n+     * since the last upload. This also includes one extra aggregated point for each namespace which is the aggregation\n+     * of aggregated points in that publish interval.\n+     *\n+     * @param lastPublish   timestamp at which the last publish was done.\n+     * @param currTimestamp timestamp at which the current publish is initiated.\n+     */\n+    protected Map<Long, List<AggregatedMetric>> getMetricsToPublish(long lastPublish, long currTimestamp) {\n+        Map<Long, List<AggregatedMetric>> aggUploadMetrics = new HashMap<>();\n+        // Read from the Telemetry/AggregatedMetrics.log file.\n+        // TODO : Read only those files that are modified after the last publish.\n+        try (Stream<Path> paths = Files\n+                .walk(TelemetryConfig.getTelemetryDirectory())\n+                .filter(Files::isRegularFile)\n+                .filter((path) -> Coerce.toString(path.getFileName()).startsWith(AGGREGATE_METRICS_FILE))) {\n+            paths.forEach(path -> {\n+                try (Stream<String> logs = Files.lines(path)) {\n+                    logs.forEach(log -> {\n+                        try {\n+                            /* {\"thread\":\"main\",\"level\":\"TRACE\",\"eventType\":null,\n+\n+                            \"message\":\"{\\\"TS\\\":1599617227533,\\\"NS\\\":\\\"SystemMetrics\\\",\\\"M\\\":[{\\\"N\\\":\\\"CpuUsage\\\",\n+\n+                            \\\"V\\\":60.0,\\\"U\\\":\\\"Percent\\\"},{\\\"N\\\":\\\"TotalNumberOfFDs\\\",\\\"V\\\":6000.0,\\\"U\\\":\\\"Count\\\"},\n+\n+                            {\\\"N\\\":\\\"SystemMemUsage\\\",\\\"V\\\":3000.0,\\\"U\\\":\\\"Megabytes\\\"}]}\",\"contexts\":{},\"loggerName\":\n+\n+                            \"Metrics-AggregateMetrics\",\"timestamp\":1599617227595,\"cause\":null} */\n+                            GreengrassLogMessage egLog = objectMapper.readValue(log,\n+                                    GreengrassLogMessage.class);\n+                            AggregatedMetric am = objectMapper.readValue(egLog.getMessage(),\n+                                    AggregatedMetric.class);\n+                            // Avoid the metrics that are aggregated at/after the currTimestamp and before the\n+                            // upload interval\n+                            if (am != null && currTimestamp > am.getTimestamp() && am.getTimestamp() >= lastPublish) {\n+                                aggUploadMetrics.computeIfAbsent(currTimestamp, k -> new ArrayList<>()).add(am);\n+                            }\n+                        } catch (JsonProcessingException e) {\n+                            logger.atError().cause(e).log(\"Unable to parse the aggregated metric log.\");\n+                        }\n+                    });\n+                } catch (IOException e) {\n+                    logger.atError().cause(e).log(\"Unable to parse the aggregated metric log file.\");\n+                }\n+            });\n+        } catch (IOException e) {\n+            logger.atError().cause(e).log(\"Unable to read the aggregated metric files from the directory\");\n+        }\n+        aggUploadMetrics.putIfAbsent(currTimestamp, new ArrayList<>());\n+        //Along with the aggregated data points, we need to collect an additional data point for each metric which is\n+        // like the aggregation of aggregated data points.\n+        // TODO : Do cumulative average rather than performing average on average\n+        aggUploadMetrics.compute(currTimestamp, (k, v) -> {\n+            v.addAll(getAggForThePublishInterval(aggUploadMetrics.get(currTimestamp), currTimestamp));\n+            return v;\n+        });\n+        return aggUploadMetrics;\n+    }\n+\n+    /**\n+     * This function takes a list of aggregated metrics and returns their aggregation in a list(Aggregation of\n+     * aggregated metrics). This is published to the cloud along with the aggregated metric points\n+     * Example:\n+     * Input:\n+     * TS:123456\n+     * NS:GreengrassComponents\n+     * |___N -  NumOfComponentsInstalled,Average - 20,U - Count\n+     * |___N -  NumOfComponentsBroken,Average - 5,U - Count\n+     * TS:123457\n+     * NS:GreengrassComponents\n+     * |___N -  NumOfComponentsInstalled,Average - 10,U - Count\n+     * |___N -  NumOfComponentsBroken,Average - 15,U - Count\n+     * Output:\n+     * TS:123457\n+     * NS:GreengrassComponents\n+     * |___N -  NumOfComponentsInstalled,Average - 15,U - Count\n+     * |___N -  NumOfComponentsBroken,Average - 10,U - Count\n+     *\n+     * @param aggList list of {@link AggregatedMetric}\n+     * @return a list of {@link AggregatedMetric}\n+     */\n+    private List<AggregatedMetric> getAggForThePublishInterval(List<AggregatedMetric> aggList, long currTimestamp) {\n+        List<AggregatedMetric> list = new ArrayList<>();\n+        for (String namespace : getNamespaceSet()) {\n+            HashMap<String, List<AggregatedMetric.Metric>> metrics = new HashMap<>();\n+            AggregatedMetric newAgg = new AggregatedMetric();\n+            for (AggregatedMetric am : aggList) {\n+                if (am.getNamespace().equals(namespace)) {\n+                    for (AggregatedMetric.Metric m : am.getMetrics()) {\n+                        metrics.computeIfAbsent(m.getName(), k -> new ArrayList<>()).add(m);\n+                    }\n+                }\n+            }\n+            newAgg.setNamespace(namespace);\n+            newAgg.setTimestamp(currTimestamp);\n+            newAgg.setMetrics(doAggregationForPublish(metrics));\n+            list.add(newAgg);\n+        }\n+        return list;\n+    }\n+\n+    /**\n+     * This function takes in the map of aggregated metrics with metric name as key and returns a list of metrics with\n+     * aggregation.\n+     * Input:\n+     * NumOfComponentsInstalled\n+     * |___N - NumOfComponentsInstalled,Average - 10,U - Count\n+     * |___N - NumOfComponentsInstalled,Average - 15,U - Count\n+     * NumOfComponentsBroken\n+     * |___N - NumOfComponentsBroken,Average - 10,U - Count\n+     * |___N - NumOfComponentsBroken,Average - 20,U - Count\n+     * Output:\n+     * |___N - NumOfComponentsInstalled,Average - 12.5,U - Count\n+     * |___N - NumOfComponentsBroken,Average - 15,U - Count\n+     *\n+     * @param map metric name -> aggregated metric\n+     * @return list of {@link AggregatedMetric.Metric }\n+     */\n+    private List<AggregatedMetric.Metric> doAggregationForPublish(Map<String, List<AggregatedMetric.Metric>> map) {\n+        List<AggregatedMetric.Metric> aggMetrics = new ArrayList<>();\n+        for (Map.Entry<String, List<AggregatedMetric.Metric>> metric : map.entrySet()) {\n+            List<AggregatedMetric.Metric> metrics = metric.getValue();\n+            List<Double> values = new ArrayList<>();\n+            metrics.get(0).getValue().forEach((aggType, aggValue) -> {\n+                metrics.forEach((v) -> values.add(Coerce.toDouble(v.getValue().get(aggType))));\n+                Map<String, Object> value = new HashMap<>();\n+                value.put(aggType, values.isEmpty() ? 0 : getAggregatedValue(values, aggType));\n+                AggregatedMetric.Metric m = AggregatedMetric.Metric.builder()\n+                        .name(metric.getKey())\n+                        .unit(metrics.get(0).getUnit())\n+                        .value(value)\n+                        .build();\n+                aggMetrics.add(m);\n+            });\n+        }\n+        return aggMetrics;\n+    }\n+\n+    /**\n+     * This method performs aggregation on the list of values of the metrics.\n+     *\n+     * @param values          list of the values extracted from the metrics\n+     * @param aggregationType string value of {@link com.aws.greengrass.telemetry.models.TelemetryAggregation}\n+     * @return returns an aggregated value for the entire list.\n+     */\n+    private double getAggregatedValue(List<Double> values, String aggregationType) {\n+        double aggregation = 0;\n+        switch (aggregationType) {\n+            case \"Average\":\n+                aggregation = values.stream().mapToDouble(Coerce::toDouble).sum();\n+                if (!values.isEmpty()) {\n+                    aggregation = aggregation / values.size();\n+                }\n+                break;\n+            case \"Sum\":\n+                aggregation = values.stream().mapToDouble(Coerce::toDouble).sum();\n+                break;\n+            case \"Maximum\":\n+                aggregation = values.stream().mapToDouble(Coerce::toDouble).max().getAsDouble();\n+                break;\n+            case \"Minimum\":\n+                aggregation = values.stream().mapToDouble(Coerce::toDouble).min().getAsDouble();\n+                break;\n+            default:\n+                logger.atError().log(\"Unknown aggregation type: {}\", aggregationType);\n+                break;\n+        }\n+        return aggregation;\n+    }\n+\n+    @Data\n+    @Builder\n+    @NoArgsConstructor\n+    @AllArgsConstructor\n+    public static class AggregatedMetric {\n+        @JsonProperty(\"TS\")\n+        private Long timestamp;\n+        @JsonProperty(\"NS\")\n+        private String namespace;\n+        @JsonProperty(\"M\")\n+        private List<Metric> metrics;\n+\n+        @Data\n+        @NoArgsConstructor\n+        @AllArgsConstructor\n+        @Builder\n+        public static class Metric {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "43b1327d170c18c423610454c698484505b791a5"}, "originalPosition": 353}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bc9918a2588074440917278a5acb0aa112d950d0", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/bc9918a2588074440917278a5acb0aa112d950d0", "committedDate": "2020-09-24T22:19:56Z", "message": "separate classes for aggreagte metrics + update tests"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk2MDEwODA3", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-496010807", "createdAt": "2020-09-24T23:15:04Z", "commit": {"oid": "bc9918a2588074440917278a5acb0aa112d950d0"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQyMzoxNTowNFrOHXvrgg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQyMzoxNTowNFrOHXvrgg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDY2MDQ4Mg==", "bodyText": "[nit]\nRemove testinfo, unused.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r494660482", "createdAt": "2020-09-24T23:15:04Z", "author": {"login": "MikeDombo"}, "path": "src/integrationtests/java/com/aws/greengrass/integrationtests/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.greengrass.integrationtests.telemetry;\n+\n+import com.aws.greengrass.config.Topics;\n+import com.aws.greengrass.dependency.State;\n+import com.aws.greengrass.integrationtests.BaseITCase;\n+import com.aws.greengrass.lifecyclemanager.Kernel;\n+import com.aws.greengrass.lifecyclemanager.exceptions.ServiceLoadException;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.MetricsAggregator;\n+import com.aws.greengrass.telemetry.MetricsPayload;\n+import com.aws.greengrass.telemetry.TelemetryAgent;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.TestInfo;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+import static org.junit.jupiter.api.Assertions.fail;\n+import static org.mockito.Mockito.atLeastOnce;\n+import static org.mockito.Mockito.verify;\n+\n+@ExtendWith({GGExtension.class, MockitoExtension.class})\n+class TelemetryAgentTest extends BaseITCase {\n+    private Kernel kernel;\n+    @Mock\n+    private MqttClient mqttClient;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> captor;\n+\n+    @BeforeEach\n+    void before(TestInfo testInfo) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc9918a2588074440917278a5acb0aa112d950d0"}, "originalPosition": 59}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk2MDMwMTYw", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-496030160", "createdAt": "2020-09-25T00:14:43Z", "commit": {"oid": "bc9918a2588074440917278a5acb0aa112d950d0"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQwMDoxNDo0M1rOHXwvfw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQwMDoxNzo1MlrOHXwylQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDY3Nzg4Nw==", "bodyText": "nit: Add copywrite", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r494677887", "createdAt": "2020-09-25T00:14:43Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/greengrass/telemetry/AggregatedMetric.java", "diffHunk": "@@ -0,0 +1,39 @@\n+package com.aws.greengrass.telemetry;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc9918a2588074440917278a5acb0aa112d950d0"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDY3NzkwNA==", "bodyText": "nit: Add copywrite", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r494677904", "createdAt": "2020-09-25T00:14:48Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/greengrass/telemetry/AggregatedMetricList.java", "diffHunk": "@@ -0,0 +1,22 @@\n+package com.aws.greengrass.telemetry;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc9918a2588074440917278a5acb0aa112d950d0"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDY3ODY3Nw==", "bodyText": "Can you rename this to something not ending in List since it contains more than a list? Maybe just AggregatedNamespaceData since it is for a namespace? unless you can come up with a better name", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r494678677", "createdAt": "2020-09-25T00:17:52Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/greengrass/telemetry/AggregatedMetricList.java", "diffHunk": "@@ -0,0 +1,22 @@\n+package com.aws.greengrass.telemetry;\n+\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.util.List;\n+\n+@Data\n+@Builder\n+@NoArgsConstructor\n+@AllArgsConstructor\n+public class AggregatedMetricList {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc9918a2588074440917278a5acb0aa112d950d0"}, "originalPosition": 15}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f95bf07008d53fd815b549751d069f46c1f1109e", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/f95bf07008d53fd815b549751d069f46c1f1109e", "committedDate": "2020-09-25T01:01:02Z", "message": "Rename to AggregateNamespaceData + copyright"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk2MDk4NDM4", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-496098438", "createdAt": "2020-09-25T04:12:37Z", "commit": {"oid": "f95bf07008d53fd815b549751d069f46c1f1109e"}, "state": "DISMISSED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk2MDk4NTg5", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-496098589", "createdAt": "2020-09-25T04:13:10Z", "commit": {"oid": "f95bf07008d53fd815b549751d069f46c1f1109e"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQwNDoxMzoxMVrOHX0WIQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQwNDoxNDoyMFrOHX0XRg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDczNjkyOQ==", "bodyText": "1 minute is way too long. Try more like 10 seconds at most. We'd like tests to fail fast.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r494736929", "createdAt": "2020-09-25T04:13:11Z", "author": {"login": "MikeDombo"}, "path": "src/integrationtests/java/com/aws/greengrass/integrationtests/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,125 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.greengrass.integrationtests.telemetry;\n+\n+import com.aws.greengrass.config.Topics;\n+import com.aws.greengrass.dependency.State;\n+import com.aws.greengrass.integrationtests.BaseITCase;\n+import com.aws.greengrass.lifecyclemanager.Kernel;\n+import com.aws.greengrass.lifecyclemanager.exceptions.ServiceLoadException;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.MetricsAggregator;\n+import com.aws.greengrass.telemetry.MetricsPayload;\n+import com.aws.greengrass.telemetry.TelemetryAgent;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+import static org.junit.jupiter.api.Assertions.fail;\n+import static org.mockito.Mockito.atLeastOnce;\n+import static org.mockito.Mockito.verify;\n+\n+@ExtendWith({GGExtension.class, MockitoExtension.class})\n+class TelemetryAgentTest extends BaseITCase {\n+    private Kernel kernel;\n+    @Mock\n+    private MqttClient mqttClient;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> captor;\n+\n+    @BeforeEach\n+    void before() {\n+        kernel = new Kernel();\n+    }\n+\n+    @AfterEach\n+    void after() {\n+        if (kernel != null) {\n+            kernel.shutdown();\n+        }\n+    }\n+\n+    @Test\n+    void GIVEN_kernel_running_with_telemetry_config_WHEN_launch_THEN_metrics_are_published() throws InterruptedException,\n+            ServiceLoadException {\n+        // GIVEN\n+        kernel.parseArgs(\"-i\", getClass().getResource(\"config.yaml\").toString());\n+        kernel.getContext().put(MqttClient.class, mqttClient);\n+        //WHEN\n+        kernel.launch();\n+        CountDownLatch telemetryRunning = new CountDownLatch(1);\n+        kernel.getContext().addGlobalStateChangeListener((service, oldState, newState) -> {\n+            if (service.getName().equals(\"TelemetryAgent\") && service.getState().equals(State.RUNNING)) {\n+                telemetryRunning.countDown();\n+            }\n+        });\n+        assertTrue(telemetryRunning.await(1, TimeUnit.MINUTES), \"TelemetryAgent is not in RUNNING state.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f95bf07008d53fd815b549751d069f46c1f1109e"}, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDczNzAwNw==", "bodyText": "use kernel.findServiceTopics(<servicename>)", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r494737007", "createdAt": "2020-09-25T04:13:32Z", "author": {"login": "MikeDombo"}, "path": "src/integrationtests/java/com/aws/greengrass/integrationtests/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,125 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.greengrass.integrationtests.telemetry;\n+\n+import com.aws.greengrass.config.Topics;\n+import com.aws.greengrass.dependency.State;\n+import com.aws.greengrass.integrationtests.BaseITCase;\n+import com.aws.greengrass.lifecyclemanager.Kernel;\n+import com.aws.greengrass.lifecyclemanager.exceptions.ServiceLoadException;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.MetricsAggregator;\n+import com.aws.greengrass.telemetry.MetricsPayload;\n+import com.aws.greengrass.telemetry.TelemetryAgent;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+import static org.junit.jupiter.api.Assertions.fail;\n+import static org.mockito.Mockito.atLeastOnce;\n+import static org.mockito.Mockito.verify;\n+\n+@ExtendWith({GGExtension.class, MockitoExtension.class})\n+class TelemetryAgentTest extends BaseITCase {\n+    private Kernel kernel;\n+    @Mock\n+    private MqttClient mqttClient;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> captor;\n+\n+    @BeforeEach\n+    void before() {\n+        kernel = new Kernel();\n+    }\n+\n+    @AfterEach\n+    void after() {\n+        if (kernel != null) {\n+            kernel.shutdown();\n+        }\n+    }\n+\n+    @Test\n+    void GIVEN_kernel_running_with_telemetry_config_WHEN_launch_THEN_metrics_are_published() throws InterruptedException,\n+            ServiceLoadException {\n+        // GIVEN\n+        kernel.parseArgs(\"-i\", getClass().getResource(\"config.yaml\").toString());\n+        kernel.getContext().put(MqttClient.class, mqttClient);\n+        //WHEN\n+        kernel.launch();\n+        CountDownLatch telemetryRunning = new CountDownLatch(1);\n+        kernel.getContext().addGlobalStateChangeListener((service, oldState, newState) -> {\n+            if (service.getName().equals(\"TelemetryAgent\") && service.getState().equals(State.RUNNING)) {\n+                telemetryRunning.countDown();\n+            }\n+        });\n+        assertTrue(telemetryRunning.await(1, TimeUnit.MINUTES), \"TelemetryAgent is not in RUNNING state.\");\n+        Topics parameterTopics = kernel.getConfig()\n+                .lookupTopics(SERVICES_NAMESPACE_TOPIC, TELEMETRY_AGENT_SERVICE_TOPICS, PARAMETERS_CONFIG_KEY);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f95bf07008d53fd815b549751d069f46c1f1109e"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDczNzExOA==", "bodyText": "use or create a constant for \"TelemetryAgent\" and use it in the @ImplementsService declaration", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r494737118", "createdAt": "2020-09-25T04:14:01Z", "author": {"login": "MikeDombo"}, "path": "src/integrationtests/java/com/aws/greengrass/integrationtests/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,125 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.greengrass.integrationtests.telemetry;\n+\n+import com.aws.greengrass.config.Topics;\n+import com.aws.greengrass.dependency.State;\n+import com.aws.greengrass.integrationtests.BaseITCase;\n+import com.aws.greengrass.lifecyclemanager.Kernel;\n+import com.aws.greengrass.lifecyclemanager.exceptions.ServiceLoadException;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.MetricsAggregator;\n+import com.aws.greengrass.telemetry.MetricsPayload;\n+import com.aws.greengrass.telemetry.TelemetryAgent;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+import static org.junit.jupiter.api.Assertions.fail;\n+import static org.mockito.Mockito.atLeastOnce;\n+import static org.mockito.Mockito.verify;\n+\n+@ExtendWith({GGExtension.class, MockitoExtension.class})\n+class TelemetryAgentTest extends BaseITCase {\n+    private Kernel kernel;\n+    @Mock\n+    private MqttClient mqttClient;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> captor;\n+\n+    @BeforeEach\n+    void before() {\n+        kernel = new Kernel();\n+    }\n+\n+    @AfterEach\n+    void after() {\n+        if (kernel != null) {\n+            kernel.shutdown();\n+        }\n+    }\n+\n+    @Test\n+    void GIVEN_kernel_running_with_telemetry_config_WHEN_launch_THEN_metrics_are_published() throws InterruptedException,\n+            ServiceLoadException {\n+        // GIVEN\n+        kernel.parseArgs(\"-i\", getClass().getResource(\"config.yaml\").toString());\n+        kernel.getContext().put(MqttClient.class, mqttClient);\n+        //WHEN\n+        kernel.launch();\n+        CountDownLatch telemetryRunning = new CountDownLatch(1);\n+        kernel.getContext().addGlobalStateChangeListener((service, oldState, newState) -> {\n+            if (service.getName().equals(\"TelemetryAgent\") && service.getState().equals(State.RUNNING)) {\n+                telemetryRunning.countDown();\n+            }\n+        });\n+        assertTrue(telemetryRunning.await(1, TimeUnit.MINUTES), \"TelemetryAgent is not in RUNNING state.\");\n+        Topics parameterTopics = kernel.getConfig()\n+                .lookupTopics(SERVICES_NAMESPACE_TOPIC, TELEMETRY_AGENT_SERVICE_TOPICS, PARAMETERS_CONFIG_KEY);\n+        int aggregateInterval = Coerce.toInt(parameterTopics.find(TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC));\n+        int periodicInterval = Coerce.toInt(parameterTopics.find(TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC));\n+        TelemetryAgent ma = (TelemetryAgent) kernel.locate(\"TelemetryAgent\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f95bf07008d53fd815b549751d069f46c1f1109e"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDczNzIyMg==", "bodyText": "same", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r494737222", "createdAt": "2020-09-25T04:14:20Z", "author": {"login": "MikeDombo"}, "path": "src/integrationtests/java/com/aws/greengrass/integrationtests/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,125 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.greengrass.integrationtests.telemetry;\n+\n+import com.aws.greengrass.config.Topics;\n+import com.aws.greengrass.dependency.State;\n+import com.aws.greengrass.integrationtests.BaseITCase;\n+import com.aws.greengrass.lifecyclemanager.Kernel;\n+import com.aws.greengrass.lifecyclemanager.exceptions.ServiceLoadException;\n+import com.aws.greengrass.mqttclient.MqttClient;\n+import com.aws.greengrass.mqttclient.PublishRequest;\n+import com.aws.greengrass.telemetry.MetricsAggregator;\n+import com.aws.greengrass.telemetry.MetricsPayload;\n+import com.aws.greengrass.telemetry.TelemetryAgent;\n+import com.aws.greengrass.telemetry.impl.config.TelemetryConfig;\n+import com.aws.greengrass.testcommons.testutilities.GGExtension;\n+import com.aws.greengrass.util.Coerce;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Captor;\n+import org.mockito.Mock;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+import software.amazon.awssdk.crt.mqtt.QualityOfService;\n+\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.greengrass.componentmanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.lifecyclemanager.GreengrassService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.greengrass.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+import static org.junit.jupiter.api.Assertions.fail;\n+import static org.mockito.Mockito.atLeastOnce;\n+import static org.mockito.Mockito.verify;\n+\n+@ExtendWith({GGExtension.class, MockitoExtension.class})\n+class TelemetryAgentTest extends BaseITCase {\n+    private Kernel kernel;\n+    @Mock\n+    private MqttClient mqttClient;\n+    @Captor\n+    private ArgumentCaptor<PublishRequest> captor;\n+\n+    @BeforeEach\n+    void before() {\n+        kernel = new Kernel();\n+    }\n+\n+    @AfterEach\n+    void after() {\n+        if (kernel != null) {\n+            kernel.shutdown();\n+        }\n+    }\n+\n+    @Test\n+    void GIVEN_kernel_running_with_telemetry_config_WHEN_launch_THEN_metrics_are_published() throws InterruptedException,\n+            ServiceLoadException {\n+        // GIVEN\n+        kernel.parseArgs(\"-i\", getClass().getResource(\"config.yaml\").toString());\n+        kernel.getContext().put(MqttClient.class, mqttClient);\n+        //WHEN\n+        kernel.launch();\n+        CountDownLatch telemetryRunning = new CountDownLatch(1);\n+        kernel.getContext().addGlobalStateChangeListener((service, oldState, newState) -> {\n+            if (service.getName().equals(\"TelemetryAgent\") && service.getState().equals(State.RUNNING)) {\n+                telemetryRunning.countDown();\n+            }\n+        });\n+        assertTrue(telemetryRunning.await(1, TimeUnit.MINUTES), \"TelemetryAgent is not in RUNNING state.\");\n+        Topics parameterTopics = kernel.getConfig()\n+                .lookupTopics(SERVICES_NAMESPACE_TOPIC, TELEMETRY_AGENT_SERVICE_TOPICS, PARAMETERS_CONFIG_KEY);\n+        int aggregateInterval = Coerce.toInt(parameterTopics.find(TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC));\n+        int periodicInterval = Coerce.toInt(parameterTopics.find(TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC));\n+        TelemetryAgent ma = (TelemetryAgent) kernel.locate(\"TelemetryAgent\");\n+        long delay = ma.getPeriodicPublishMetricsFuture().getDelay(TimeUnit.SECONDS);\n+        assertTrue(delay <= periodicInterval);\n+        //telemetry configurations are set correctly\n+        assertEquals(2, aggregateInterval);\n+        assertEquals(4, periodicInterval);\n+        Topics runtimeTopics = kernel.getConfig()\n+                .lookupTopics(SERVICES_NAMESPACE_TOPIC, TELEMETRY_AGENT_SERVICE_TOPICS, RUNTIME_STORE_NAMESPACE_TOPIC);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f95bf07008d53fd815b549751d069f46c1f1109e"}, "originalPosition": 95}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1e5623f5e409f2efa7d19db09362166efaa4ad05", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/1e5623f5e409f2efa7d19db09362166efaa4ad05", "committedDate": "2020-09-25T04:43:34Z", "message": "modify tests with timeout and findservicetopics"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "684e1829317055c283470b43d54a859668af59e3", "author": {"user": {"login": "MikeDombo", "name": "Michael Dombrowski"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/684e1829317055c283470b43d54a859668af59e3", "committedDate": "2020-09-25T07:06:31Z", "message": "Merge branch 'master' into telemetry-logs"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk2MTYxMTIx", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-496161121", "createdAt": "2020-09-25T07:07:01Z", "commit": {"oid": "684e1829317055c283470b43d54a859668af59e3"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk2NTQwOTQ2", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-496540946", "createdAt": "2020-09-25T15:46:34Z", "commit": {"oid": "684e1829317055c283470b43d54a859668af59e3"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3b5fcf28288381e8c3dce1f31f868dc32d02016f", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/3b5fcf28288381e8c3dce1f31f868dc32d02016f", "committedDate": "2020-08-21T21:46:53Z", "message": "Telemetry service to log kernel component state metrics"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcyODQxMzIy", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-472841322", "createdAt": "2020-08-21T22:01:23Z", "commit": {"oid": "3b5fcf28288381e8c3dce1f31f868dc32d02016f"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQyMjowMToyM1rOHE-_ig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQyMjowNToxM1rOHE_D4Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk4ODQyNg==", "bodyText": "remove this. You shouldn't have both field and constructor injection", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r474988426", "createdAt": "2020-08-21T22:01:23Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,41 @@\n+\n+\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.dependency.State;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    private final MetricsAgentFactory metricsAgentFactory = new MetricsAgentFactory();\n+    @Inject", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3b5fcf28288381e8c3dce1f31f868dc32d02016f"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk4ODQ5NQ==", "bodyText": "remove this. It isn't helpful at all as we already log lifecycle events.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r474988495", "createdAt": "2020-08-21T22:01:40Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,41 @@\n+\n+\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.dependency.State;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    private final MetricsAgentFactory metricsAgentFactory = new MetricsAgentFactory();\n+    @Inject\n+    private final Kernel kernel;\n+\n+    @Inject\n+    public MetricsAgent(Topics topics, Kernel kernel) {\n+        super(topics);\n+        this.kernel = kernel;\n+    }\n+\n+    @Override\n+    protected void startup() {\n+        logger.atInfo().log(\"Starting MetricsAgent.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3b5fcf28288381e8c3dce1f31f868dc32d02016f"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk4ODU3OQ==", "bodyText": "remove this if you're not doing anything", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r474988579", "createdAt": "2020-08-21T22:02:00Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,41 @@\n+\n+\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.dependency.State;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    private final MetricsAgentFactory metricsAgentFactory = new MetricsAgentFactory();\n+    @Inject\n+    private final Kernel kernel;\n+\n+    @Inject\n+    public MetricsAgent(Topics topics, Kernel kernel) {\n+        super(topics);\n+        this.kernel = kernel;\n+    }\n+\n+    @Override\n+    protected void startup() {\n+        logger.atInfo().log(\"Starting MetricsAgent.\");\n+        reportState(State.RUNNING);\n+        metricsAgentFactory.collectTimeBasedMetrics(this.kernel);\n+    }\n+\n+    @Override\n+    protected void shutdown() {\n+        logger.atInfo().log(\"MetricsAgent is shutting down!\");\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3b5fcf28288381e8c3dce1f31f868dc32d02016f"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk4ODc5Ng==", "bodyText": "pull this out into a method in this class", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r474988796", "createdAt": "2020-08-21T22:02:51Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgentFactory.java", "diffHunk": "@@ -0,0 +1,66 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.constants.DefaultMetricPeriod;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryType;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+\n+public class MetricsAgentFactory {\n+\n+    public void collectTimeBasedMetrics(Kernel kernel) {\n+        this.collectKernelComponentState(kernel, DefaultMetricPeriod.DEFAULT_NUM_COMPONENT_STATE_PERIOD);\n+    }\n+\n+    private void collectKernelComponentState(Kernel kernel, int period) {\n+        Map<TelemetryMetricName, MetricDataBuilder> metricsMap = new HashMap<>();\n+        for (TelemetryMetricName telemetryMetricName : TelemetryMetricName.KernelComponents.values()) {\n+            Metric metric = Metric.builder()\n+                    .metricNamespace(TelemetryNamespace.KERNEL)\n+                    .metricName(telemetryMetricName)\n+                    .metricUnit(TelemetryUnit.COUNT)\n+                    .metricType(TelemetryType.TIME_BASED)\n+                    .build();\n+            MetricDataBuilder metricDataBuilder = new MetricFactory().addMetric(metric);\n+            metricsMap.put(telemetryMetricName, metricDataBuilder);\n+        }\n+\n+        Map<TelemetryMetricName, Integer> numComponentState = new HashMap<>();\n+        for (TelemetryMetricName telemetryMetricName : TelemetryMetricName.KernelComponents.values()) {\n+                numComponentState.put(telemetryMetricName,0);\n+        }\n+\n+        Runnable emitMetrics = new Runnable() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3b5fcf28288381e8c3dce1f31f868dc32d02016f"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk4ODk1OA==", "bodyText": "didn't you have a const for that NUM_COMPONENTS?", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r474988958", "createdAt": "2020-08-21T22:03:26Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgentFactory.java", "diffHunk": "@@ -0,0 +1,66 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.constants.DefaultMetricPeriod;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryType;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+\n+public class MetricsAgentFactory {\n+\n+    public void collectTimeBasedMetrics(Kernel kernel) {\n+        this.collectKernelComponentState(kernel, DefaultMetricPeriod.DEFAULT_NUM_COMPONENT_STATE_PERIOD);\n+    }\n+\n+    private void collectKernelComponentState(Kernel kernel, int period) {\n+        Map<TelemetryMetricName, MetricDataBuilder> metricsMap = new HashMap<>();\n+        for (TelemetryMetricName telemetryMetricName : TelemetryMetricName.KernelComponents.values()) {\n+            Metric metric = Metric.builder()\n+                    .metricNamespace(TelemetryNamespace.KERNEL)\n+                    .metricName(telemetryMetricName)\n+                    .metricUnit(TelemetryUnit.COUNT)\n+                    .metricType(TelemetryType.TIME_BASED)\n+                    .build();\n+            MetricDataBuilder metricDataBuilder = new MetricFactory().addMetric(metric);\n+            metricsMap.put(telemetryMetricName, metricDataBuilder);\n+        }\n+\n+        Map<TelemetryMetricName, Integer> numComponentState = new HashMap<>();\n+        for (TelemetryMetricName telemetryMetricName : TelemetryMetricName.KernelComponents.values()) {\n+                numComponentState.put(telemetryMetricName,0);\n+        }\n+\n+        Runnable emitMetrics = new Runnable() {\n+            @Override\n+            public void run() {\n+                Collection<EvergreenService> evergreenServices = kernel.orderedDependencies();\n+                for (EvergreenService evergreenService : evergreenServices) {\n+                    TelemetryMetricName telemetryMetricName = TelemetryMetricName.KernelComponents\n+                            .valueOf(\"NUM_COMPONENTS_\" + evergreenService.getState().toString());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3b5fcf28288381e8c3dce1f31f868dc32d02016f"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk4OTA0MA==", "bodyText": "reformat this file, there should be spaces around the :", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r474989040", "createdAt": "2020-08-21T22:03:43Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgentFactory.java", "diffHunk": "@@ -0,0 +1,66 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.constants.DefaultMetricPeriod;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryType;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+\n+public class MetricsAgentFactory {\n+\n+    public void collectTimeBasedMetrics(Kernel kernel) {\n+        this.collectKernelComponentState(kernel, DefaultMetricPeriod.DEFAULT_NUM_COMPONENT_STATE_PERIOD);\n+    }\n+\n+    private void collectKernelComponentState(Kernel kernel, int period) {\n+        Map<TelemetryMetricName, MetricDataBuilder> metricsMap = new HashMap<>();\n+        for (TelemetryMetricName telemetryMetricName : TelemetryMetricName.KernelComponents.values()) {\n+            Metric metric = Metric.builder()\n+                    .metricNamespace(TelemetryNamespace.KERNEL)\n+                    .metricName(telemetryMetricName)\n+                    .metricUnit(TelemetryUnit.COUNT)\n+                    .metricType(TelemetryType.TIME_BASED)\n+                    .build();\n+            MetricDataBuilder metricDataBuilder = new MetricFactory().addMetric(metric);\n+            metricsMap.put(telemetryMetricName, metricDataBuilder);\n+        }\n+\n+        Map<TelemetryMetricName, Integer> numComponentState = new HashMap<>();\n+        for (TelemetryMetricName telemetryMetricName : TelemetryMetricName.KernelComponents.values()) {\n+                numComponentState.put(telemetryMetricName,0);\n+        }\n+\n+        Runnable emitMetrics = new Runnable() {\n+            @Override\n+            public void run() {\n+                Collection<EvergreenService> evergreenServices = kernel.orderedDependencies();\n+                for (EvergreenService evergreenService : evergreenServices) {\n+                    TelemetryMetricName telemetryMetricName = TelemetryMetricName.KernelComponents\n+                            .valueOf(\"NUM_COMPONENTS_\" + evergreenService.getState().toString());\n+                    numComponentState.put(telemetryMetricName, numComponentState.get(telemetryMetricName) + 1);\n+                }\n+\n+                for (HashMap.Entry<TelemetryMetricName, MetricDataBuilder> metricMap:metricsMap.entrySet()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3b5fcf28288381e8c3dce1f31f868dc32d02016f"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk4OTI2Ng==", "bodyText": "Do not create a new threadpool. Use injection to get the threadpool from the context.\nKeep a reference to the output of the schedule so that you can cancel it when requested to stop.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r474989266", "createdAt": "2020-08-21T22:04:27Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgentFactory.java", "diffHunk": "@@ -0,0 +1,66 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.constants.DefaultMetricPeriod;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryType;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+\n+public class MetricsAgentFactory {\n+\n+    public void collectTimeBasedMetrics(Kernel kernel) {\n+        this.collectKernelComponentState(kernel, DefaultMetricPeriod.DEFAULT_NUM_COMPONENT_STATE_PERIOD);\n+    }\n+\n+    private void collectKernelComponentState(Kernel kernel, int period) {\n+        Map<TelemetryMetricName, MetricDataBuilder> metricsMap = new HashMap<>();\n+        for (TelemetryMetricName telemetryMetricName : TelemetryMetricName.KernelComponents.values()) {\n+            Metric metric = Metric.builder()\n+                    .metricNamespace(TelemetryNamespace.KERNEL)\n+                    .metricName(telemetryMetricName)\n+                    .metricUnit(TelemetryUnit.COUNT)\n+                    .metricType(TelemetryType.TIME_BASED)\n+                    .build();\n+            MetricDataBuilder metricDataBuilder = new MetricFactory().addMetric(metric);\n+            metricsMap.put(telemetryMetricName, metricDataBuilder);\n+        }\n+\n+        Map<TelemetryMetricName, Integer> numComponentState = new HashMap<>();\n+        for (TelemetryMetricName telemetryMetricName : TelemetryMetricName.KernelComponents.values()) {\n+                numComponentState.put(telemetryMetricName,0);\n+        }\n+\n+        Runnable emitMetrics = new Runnable() {\n+            @Override\n+            public void run() {\n+                Collection<EvergreenService> evergreenServices = kernel.orderedDependencies();\n+                for (EvergreenService evergreenService : evergreenServices) {\n+                    TelemetryMetricName telemetryMetricName = TelemetryMetricName.KernelComponents\n+                            .valueOf(\"NUM_COMPONENTS_\" + evergreenService.getState().toString());\n+                    numComponentState.put(telemetryMetricName, numComponentState.get(telemetryMetricName) + 1);\n+                }\n+\n+                for (HashMap.Entry<TelemetryMetricName, MetricDataBuilder> metricMap:metricsMap.entrySet()) {\n+                    MetricDataBuilder metricDataBuilder = metricMap.getValue();\n+                    metricDataBuilder.putMetricData(numComponentState.get(metricMap.getKey())).emit();\n+                    numComponentState.put(metricMap.getKey(),0);\n+                }\n+            }\n+        };\n+\n+        ScheduledExecutorService executor = Executors.newScheduledThreadPool(metricsMap.size());\n+        executor.scheduleAtFixedRate(emitMetrics, 0, period, TimeUnit.SECONDS);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3b5fcf28288381e8c3dce1f31f868dc32d02016f"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk4OTQwMQ==", "bodyText": "normally we don't break these out into separate classes, you can just keep it where it is used.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r474989401", "createdAt": "2020-08-21T22:04:54Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/constants/DefaultMetricPeriod.java", "diffHunk": "@@ -0,0 +1,5 @@\n+package com.aws.iot.evergreen.telemetry.constants;\n+\n+public class DefaultMetricPeriod {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3b5fcf28288381e8c3dce1f31f868dc32d02016f"}, "originalPosition": 3}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk4OTQ4Nw==", "bodyText": "Missing tests.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r474989487", "createdAt": "2020-08-21T22:05:02Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgentFactory.java", "diffHunk": "@@ -0,0 +1,66 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.constants.DefaultMetricPeriod;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryType;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+\n+public class MetricsAgentFactory {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3b5fcf28288381e8c3dce1f31f868dc32d02016f"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDk4OTUzNw==", "bodyText": "remove spaces.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r474989537", "createdAt": "2020-08-21T22:05:13Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,41 @@\n+\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3b5fcf28288381e8c3dce1f31f868dc32d02016f"}, "originalPosition": 2}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDczMDM4MDg5", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-473038089", "createdAt": "2020-08-23T20:02:00Z", "commit": {"oid": "3b5fcf28288381e8c3dce1f31f868dc32d02016f"}, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fd1e7ff14d913726778524300382d9419da84485", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/fd1e7ff14d913726778524300382d9419da84485", "committedDate": "2020-08-24T21:48:37Z", "message": "Use context for Executor, Move runnable code to another method, update emit metrics to match with sdk changes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2009213d5abceae5a7670ecc38df60ec82e15f63", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/2009213d5abceae5a7670ecc38df60ec82e15f63", "committedDate": "2020-08-25T21:16:46Z", "message": "Move component metrics code to kernel from MA Factory"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a3070f8e0be114a435e7a8da76eef7efe44a755f", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/a3070f8e0be114a435e7a8da76eef7efe44a755f", "committedDate": "2020-08-25T21:20:26Z", "message": "Add system metrics"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9115edf1a99a1565ed052699274e90eb4fa7d909", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/9115edf1a99a1565ed052699274e90eb4fa7d909", "committedDate": "2020-08-25T21:17:33Z", "message": "Add system metric components"}, "afterCommit": {"oid": "a3070f8e0be114a435e7a8da76eef7efe44a755f", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/a3070f8e0be114a435e7a8da76eef7efe44a755f", "committedDate": "2020-08-25T21:20:26Z", "message": "Add system metrics"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDc0OTM3Mjk1", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-474937295", "createdAt": "2020-08-25T21:48:59Z", "commit": {"oid": "a3070f8e0be114a435e7a8da76eef7efe44a755f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNVQyMTo0ODo1OVrOHGrt2A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNVQyMTo0ODo1OVrOHGrt2A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njc2OTc1Mg==", "bodyText": "Move everything you put in kernel into your new service", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r476769752", "createdAt": "2020-08-25T21:48:59Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/kernel/Kernel.java", "diffHunk": "@@ -540,4 +549,46 @@ public Kernel parseArgs(String... args) {\n     public String deTilde(String filename) {\n         return kernelCommandLine.deTilde(filename);\n     }\n+\n+    private void collectKernelComponentState() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3070f8e0be114a435e7a8da76eef7efe44a755f"}, "originalPosition": 44}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDc0OTM3ODA3", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-474937807", "createdAt": "2020-08-25T21:50:01Z", "commit": {"oid": "a3070f8e0be114a435e7a8da76eef7efe44a755f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNVQyMTo1MDowMVrOHGrxYQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNVQyMTo1MDowMVrOHGrxYQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njc3MDY1Nw==", "bodyText": "you need to add this library as a dependency", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r476770657", "createdAt": "2020-08-25T21:50:01Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgentFactory.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/*\n+ * Copyright Amazon.com Inc. or its affiliates.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.dependency.Context;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import oshi.SystemInfo;\n+import oshi.hardware.CentralProcessor;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3070f8e0be114a435e7a8da76eef7efe44a755f"}, "originalPosition": 17}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDc0OTM4NzE3", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-474938717", "createdAt": "2020-08-25T21:51:50Z", "commit": {"oid": "a3070f8e0be114a435e7a8da76eef7efe44a755f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNVQyMTo1MTo1MFrOHGr3Xg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNVQyMTo1MTo1MFrOHGr3Xg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njc3MjE5MA==", "bodyText": "?", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r476772190", "createdAt": "2020-08-25T21:51:50Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgentFactory.java", "diffHunk": "@@ -0,0 +1,93 @@\n+/*\n+ * Copyright Amazon.com Inc. or its affiliates.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.dependency.Context;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import oshi.SystemInfo;\n+import oshi.hardware.CentralProcessor;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+\n+public  class MetricsAgentFactory {\n+    private static final int DEFAULT_SYSTEM_METRICS_PERIOD = 300;\n+    private static int MB_CONVERTER = 1024 * 1024;\n+    private static int PERCENTAGE_CONVERTER = 100;\n+    private static CentralProcessor cpu = new SystemInfo().getHardware().getProcessor();\n+    private static SystemInfo systemInfo = new SystemInfo();\n+    private static long[] previousTicks = new long[CentralProcessor.TickType.values().length];\n+\n+\n+    /**\n+     * Kuch bhi.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3070f8e0be114a435e7a8da76eef7efe44a755f"}, "originalPosition": 34}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d5e9abb0328e179dc0e161069923e8ed71ed4e66", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/d5e9abb0328e179dc0e161069923e8ed71ed4e66", "committedDate": "2020-08-27T18:26:32Z", "message": "Add custom file location for metrics"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "939dd8a1df5e3abb0439153187f1c9991249ea91", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/939dd8a1df5e3abb0439153187f1c9991249ea91", "committedDate": "2020-08-29T09:15:57Z", "message": "Add metrics aggregator and config"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5fcbab00f75e4ef38b421e1cc3fd7b00cb10c7c4", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/5fcbab00f75e4ef38b421e1cc3fd7b00cb10c7c4", "committedDate": "2020-08-29T21:18:48Z", "message": "add oshi dependency"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e7ee3231e416c1f16d7bd01e24a3fbc5b5616501", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/e7ee3231e416c1f16d7bd01e24a3fbc5b5616501", "committedDate": "2020-08-29T21:23:05Z", "message": "Merge branch 'master' of github.com:/aws/aws-greengrass-kernel into telemetry-logs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "044114b548f4eb239cb00d856aedbde52f3984bb", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/044114b548f4eb239cb00d856aedbde52f3984bb", "committedDate": "2020-08-31T19:39:24Z", "message": "metrics uploader + metrics aggregator"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDc4OTE1MDcz", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-478915073", "createdAt": "2020-08-31T20:03:35Z", "commit": {"oid": "044114b548f4eb239cb00d856aedbde52f3984bb"}, "state": "COMMENTED", "comments": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQyMDowMzozNVrOHKHXbg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQyMDoxNTowN1rOHKHttw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM2ODQ5NA==", "bodyText": "fix indentation", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r480368494", "createdAt": "2020-08-31T20:03:35Z", "author": {"login": "MikeDombo"}, "path": "pom.xml", "diffHunk": "@@ -172,6 +172,11 @@\n         with recent Windows/VC redist. The behavior is changed in recent jna release. By declaring direct dependency of\n         jna, we avoid the problem of loading msvcr100.dll.\n         -->\n+\t\t<dependency>\n+\t\t\t<groupId>com.github.oshi</groupId>\n+\t\t\t<artifactId>oshi-core</artifactId>\n+\t\t\t<version>5.2.3</version>\n+\t\t</dependency>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "044114b548f4eb239cb00d856aedbde52f3984bb"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM2ODgwMw==", "bodyText": "remove all of this from kernel. This class is huge. Move it to a separate class to handle kernel metrics which you may call from here.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r480368803", "createdAt": "2020-08-31T20:04:16Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/kernel/Kernel.java", "diffHunk": "@@ -84,6 +93,13 @@\n     public static final String SERVICE_TYPE_TO_CLASS_MAP_KEY = \"componentTypeToClassMap\";\n     private static final String PLUGIN_SERVICE_TYPE_NAME = \"plugin\";\n \n+    // Kernel metrics\n+    private static final long KERNEL_COMPONENTS_STATE_PERIOD =\n+            telemetryDataConfigMap.get(TelemetryNamespace.KernelComponents.toString()).getEmitFrequency();\n+    private static final String KERNEL_COMPONENT_METRIC_STORE = TelemetryNamespace.KernelComponents.toString();\n+    private static Map<TelemetryMetricName, MetricDataBuilder> kernelMetrics = new HashMap<>();\n+    private static Map<TelemetryMetricName, Integer> kernelMetricsData = new HashMap<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "044114b548f4eb239cb00d856aedbde52f3984bb"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM2OTc1Mg==", "bodyText": "why are you doing this? Just take the name as-is, or use toUpperCase() or toLowerCase to regularize it.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r480369752", "createdAt": "2020-08-31T20:06:12Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/kernel/Kernel.java", "diffHunk": "@@ -551,4 +567,45 @@ public Kernel parseArgs(String... args) {\n     public String deTilde(String filename) {\n         return kernelCommandLine.deTilde(filename);\n     }\n+\n+    /**\n+     * Collect kernel metrics - Number of components running in each state.\n+     */\n+    private void collectKernelComponentState() {\n+        List<TelemetryMetricName> telemetryMetricNames =\n+                TelemetryMetricName.getMetricNamesOf(TelemetryNamespace.KernelComponents);\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            Metric metric = Metric.builder()\n+                    .metricNamespace(TelemetryNamespace.KernelComponents)\n+                    .metricName(telemetryMetricName)\n+                    .metricUnit(TelemetryUnit.Count)\n+                    .build();\n+            MetricDataBuilder metricDataBuilder = new MetricFactory(KERNEL_COMPONENT_METRIC_STORE).addMetric(metric);\n+            kernelMetrics.put(telemetryMetricName, metricDataBuilder);\n+        }\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            kernelMetricsData.put(telemetryMetricName, 0);\n+        }\n+\n+        ScheduledExecutorService executor = context.get(ScheduledExecutorService.class);\n+        executor.scheduleAtFixedRate(emitMetrics(), 0, KERNEL_COMPONENTS_STATE_PERIOD, TimeUnit.MILLISECONDS);\n+    }\n+\n+    private Runnable emitMetrics() {\n+        return () -> {\n+            Collection<EvergreenService> evergreenServices = orderedDependencies();\n+            for (EvergreenService evergreenService : evergreenServices) {\n+                String serviceState = evergreenService.getState().toString();\n+                serviceState = serviceState.charAt(0) + serviceState.substring(1).toLowerCase();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "044114b548f4eb239cb00d856aedbde52f3984bb"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM3MDM5Nw==", "bodyText": "Catch the exception for if valueOf fails", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r480370397", "createdAt": "2020-08-31T20:07:27Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/kernel/Kernel.java", "diffHunk": "@@ -551,4 +567,45 @@ public Kernel parseArgs(String... args) {\n     public String deTilde(String filename) {\n         return kernelCommandLine.deTilde(filename);\n     }\n+\n+    /**\n+     * Collect kernel metrics - Number of components running in each state.\n+     */\n+    private void collectKernelComponentState() {\n+        List<TelemetryMetricName> telemetryMetricNames =\n+                TelemetryMetricName.getMetricNamesOf(TelemetryNamespace.KernelComponents);\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            Metric metric = Metric.builder()\n+                    .metricNamespace(TelemetryNamespace.KernelComponents)\n+                    .metricName(telemetryMetricName)\n+                    .metricUnit(TelemetryUnit.Count)\n+                    .build();\n+            MetricDataBuilder metricDataBuilder = new MetricFactory(KERNEL_COMPONENT_METRIC_STORE).addMetric(metric);\n+            kernelMetrics.put(telemetryMetricName, metricDataBuilder);\n+        }\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            kernelMetricsData.put(telemetryMetricName, 0);\n+        }\n+\n+        ScheduledExecutorService executor = context.get(ScheduledExecutorService.class);\n+        executor.scheduleAtFixedRate(emitMetrics(), 0, KERNEL_COMPONENTS_STATE_PERIOD, TimeUnit.MILLISECONDS);\n+    }\n+\n+    private Runnable emitMetrics() {\n+        return () -> {\n+            Collection<EvergreenService> evergreenServices = orderedDependencies();\n+            for (EvergreenService evergreenService : evergreenServices) {\n+                String serviceState = evergreenService.getState().toString();\n+                serviceState = serviceState.charAt(0) + serviceState.substring(1).toLowerCase();\n+                TelemetryMetricName telemetryMetricName =\n+                        TelemetryMetricName.valueOf(\"NumberOfComponents\" + serviceState);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "044114b548f4eb239cb00d856aedbde52f3984bb"}, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM3MTQ5MQ==", "bodyText": "this map doesn't need to be a field of the class", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r480371491", "createdAt": "2020-08-31T20:09:37Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/kernel/Kernel.java", "diffHunk": "@@ -551,4 +567,45 @@ public Kernel parseArgs(String... args) {\n     public String deTilde(String filename) {\n         return kernelCommandLine.deTilde(filename);\n     }\n+\n+    /**\n+     * Collect kernel metrics - Number of components running in each state.\n+     */\n+    private void collectKernelComponentState() {\n+        List<TelemetryMetricName> telemetryMetricNames =\n+                TelemetryMetricName.getMetricNamesOf(TelemetryNamespace.KernelComponents);\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            Metric metric = Metric.builder()\n+                    .metricNamespace(TelemetryNamespace.KernelComponents)\n+                    .metricName(telemetryMetricName)\n+                    .metricUnit(TelemetryUnit.Count)\n+                    .build();\n+            MetricDataBuilder metricDataBuilder = new MetricFactory(KERNEL_COMPONENT_METRIC_STORE).addMetric(metric);\n+            kernelMetrics.put(telemetryMetricName, metricDataBuilder);\n+        }\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            kernelMetricsData.put(telemetryMetricName, 0);\n+        }\n+\n+        ScheduledExecutorService executor = context.get(ScheduledExecutorService.class);\n+        executor.scheduleAtFixedRate(emitMetrics(), 0, KERNEL_COMPONENTS_STATE_PERIOD, TimeUnit.MILLISECONDS);\n+    }\n+\n+    private Runnable emitMetrics() {\n+        return () -> {\n+            Collection<EvergreenService> evergreenServices = orderedDependencies();\n+            for (EvergreenService evergreenService : evergreenServices) {\n+                String serviceState = evergreenService.getState().toString();\n+                serviceState = serviceState.charAt(0) + serviceState.substring(1).toLowerCase();\n+                TelemetryMetricName telemetryMetricName =\n+                        TelemetryMetricName.valueOf(\"NumberOfComponents\" + serviceState);\n+                kernelMetricsData.put(telemetryMetricName, kernelMetricsData.get(telemetryMetricName) + 1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "044114b548f4eb239cb00d856aedbde52f3984bb"}, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM3MjUxMw==", "bodyText": "Never do this.\nKernel manages your lifecycle correctly", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r480372513", "createdAt": "2020-08-31T20:11:38Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,56 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.dependency.State;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.telemetry.config.TelemetryDataConfig;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    public static final Map<String, TelemetryDataConfig> telemetryDataConfigMap = createSampleConfiguration();\n+\n+    public MetricsAgent(Topics topics) {\n+        super(topics);\n+    }\n+\n+    @Override\n+    public void startup() {\n+        // Is it always going to be true that STARTING precedes RUNNING?\n+        if (this.getState().equals(State.STARTING)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "044114b548f4eb239cb00d856aedbde52f3984bb"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM3MjU5NA==", "bodyText": "never do this", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r480372594", "createdAt": "2020-08-31T20:11:47Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,56 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.dependency.State;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.telemetry.config.TelemetryDataConfig;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    public static final Map<String, TelemetryDataConfig> telemetryDataConfigMap = createSampleConfiguration();\n+\n+    public MetricsAgent(Topics topics) {\n+        super(topics);\n+    }\n+\n+    @Override\n+    public void startup() {\n+        // Is it always going to be true that STARTING precedes RUNNING?\n+        if (this.getState().equals(State.STARTING)) {\n+            reportState(State.RUNNING);\n+            this.systemMetricsEmitter.collectSystemMetrics(getContext());\n+            this.metricsAggregator.aggregateMetrics(getContext());\n+            this.metricsUploader.uploadMetrics(getContext());\n+        } else {\n+            reportState(this.getState());\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "044114b548f4eb239cb00d856aedbde52f3984bb"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM3MzAxNQ==", "bodyText": "this is wrong. Get the path properly", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r480373015", "createdAt": "2020-08-31T20:12:43Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,152 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.dependency.Context;\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.aggregation.AggregatedMetric;\n+import com.aws.iot.evergreen.telemetry.config.TelemetryDataConfig;\n+import com.aws.iot.evergreen.telemetry.impl.MetricDataPoint;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.telemetryDataConfigMap;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+\n+    /**\n+     * Aggregate metrics based on the telemetry config.\n+     * @param context use this to schedule thread pool.\n+     */\n+    public void aggregateMetrics(Context context) {\n+        // TODO read from a telemetry config file.\n+        for (Map.Entry<String, TelemetryDataConfig> config: telemetryDataConfigMap.entrySet()) {\n+            TelemetryDataConfig metricConfig = config.getValue();\n+            ScheduledExecutorService executor = context.get(ScheduledExecutorService.class);\n+            executor.scheduleAtFixedRate(readLogsAndAggregate(metricConfig), 0, metricConfig.getAggregateFrequency(),\n+                    TimeUnit.MILLISECONDS);\n+        }\n+    }\n+\n+    private Runnable readLogsAndAggregate(TelemetryDataConfig config) {\n+        return () -> {\n+            long currentTimestamp = Instant.now().toEpochMilli();\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<MetricDataPoint>> metrics = new HashMap<>();\n+\n+            try {\n+                Stream<Path> paths = Files\n+                        .walk(Paths.get(System.getProperty(\"user.dir\") + \"/Telemetry/\"))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "044114b548f4eb239cb00d856aedbde52f3984bb"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM3MzcxNw==", "bodyText": "This won't be clear at all .log(\"Failed reading metric logs\", e)", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r480373717", "createdAt": "2020-08-31T20:14:10Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,152 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.dependency.Context;\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.aggregation.AggregatedMetric;\n+import com.aws.iot.evergreen.telemetry.config.TelemetryDataConfig;\n+import com.aws.iot.evergreen.telemetry.impl.MetricDataPoint;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.telemetryDataConfigMap;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+\n+    /**\n+     * Aggregate metrics based on the telemetry config.\n+     * @param context use this to schedule thread pool.\n+     */\n+    public void aggregateMetrics(Context context) {\n+        // TODO read from a telemetry config file.\n+        for (Map.Entry<String, TelemetryDataConfig> config: telemetryDataConfigMap.entrySet()) {\n+            TelemetryDataConfig metricConfig = config.getValue();\n+            ScheduledExecutorService executor = context.get(ScheduledExecutorService.class);\n+            executor.scheduleAtFixedRate(readLogsAndAggregate(metricConfig), 0, metricConfig.getAggregateFrequency(),\n+                    TimeUnit.MILLISECONDS);\n+        }\n+    }\n+\n+    private Runnable readLogsAndAggregate(TelemetryDataConfig config) {\n+        return () -> {\n+            long currentTimestamp = Instant.now().toEpochMilli();\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<MetricDataPoint>> metrics = new HashMap<>();\n+\n+            try {\n+                Stream<Path> paths = Files\n+                        .walk(Paths.get(System.getProperty(\"user.dir\") + \"/Telemetry/\"))\n+                        .filter(Files::isRegularFile);\n+                paths.forEach((path) -> {\n+                    /*\n+                     Read from the file at Telemetry/namespace*.log\n+                     Read only modified files and aggregate only new values based on the last aggregated time.\n+                     */\n+                    Object fileName = null;\n+                    if (path != null) {\n+                        fileName = path.getFileName();\n+                    }\n+                    if (fileName == null) {\n+                        fileName = \"\";\n+                    }\n+                    if (path != null\n+                            && path.getFileName() != null\n+                            && path.getFileName().toString().matches(config.getMetricNamespace() + \"(.*)\")\n+                            && currentTimestamp - new File(path.toString()).lastModified()\n+                            <= config.getAggregateFrequency()) {\n+                        try {\n+                            for (String log :\n+                                    Files.lines(Paths.get(path.toString())).collect(Collectors.toList())) {\n+                                /*\n+                                [0]  [1] [2]        [3]          [4]         [5]             [6]\n+                                2020 Aug 28 12:08:21,520-0700 [TRACE] (pool-3-thread-4) Metrics-KernelComponents:\n+\n+                                [7]\n+                                {\"M\":{\"NS\": \"KernelComponents\",\"N\":\"NumberOfComponentsStopping\",\"U\":\"Count\"},\n+                                \"V\":0,\"TS\":1598598501520}. {}\n+                                 */\n+                                MetricDataPoint mdp = new ObjectMapper()\n+                                        .readValue(log.split(\" \")[7], MetricDataPoint.class);\n+                                if (currentTimestamp - mdp.getTimestamp() <= config.getAggregateFrequency()) {\n+                                    metrics.computeIfAbsent(mdp.getMetric().getMetricName(),\n+                                            k -> new ArrayList<>()).add(mdp);\n+                                }\n+                            }\n+                        } catch (IOException e) {\n+                            logger.atError().log(e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "044114b548f4eb239cb00d856aedbde52f3984bb"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM3Mzc2MQ==", "bodyText": "same", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r480373761", "createdAt": "2020-08-31T20:14:16Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,152 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.dependency.Context;\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.aggregation.AggregatedMetric;\n+import com.aws.iot.evergreen.telemetry.config.TelemetryDataConfig;\n+import com.aws.iot.evergreen.telemetry.impl.MetricDataPoint;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.telemetryDataConfigMap;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+\n+    /**\n+     * Aggregate metrics based on the telemetry config.\n+     * @param context use this to schedule thread pool.\n+     */\n+    public void aggregateMetrics(Context context) {\n+        // TODO read from a telemetry config file.\n+        for (Map.Entry<String, TelemetryDataConfig> config: telemetryDataConfigMap.entrySet()) {\n+            TelemetryDataConfig metricConfig = config.getValue();\n+            ScheduledExecutorService executor = context.get(ScheduledExecutorService.class);\n+            executor.scheduleAtFixedRate(readLogsAndAggregate(metricConfig), 0, metricConfig.getAggregateFrequency(),\n+                    TimeUnit.MILLISECONDS);\n+        }\n+    }\n+\n+    private Runnable readLogsAndAggregate(TelemetryDataConfig config) {\n+        return () -> {\n+            long currentTimestamp = Instant.now().toEpochMilli();\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<MetricDataPoint>> metrics = new HashMap<>();\n+\n+            try {\n+                Stream<Path> paths = Files\n+                        .walk(Paths.get(System.getProperty(\"user.dir\") + \"/Telemetry/\"))\n+                        .filter(Files::isRegularFile);\n+                paths.forEach((path) -> {\n+                    /*\n+                     Read from the file at Telemetry/namespace*.log\n+                     Read only modified files and aggregate only new values based on the last aggregated time.\n+                     */\n+                    Object fileName = null;\n+                    if (path != null) {\n+                        fileName = path.getFileName();\n+                    }\n+                    if (fileName == null) {\n+                        fileName = \"\";\n+                    }\n+                    if (path != null\n+                            && path.getFileName() != null\n+                            && path.getFileName().toString().matches(config.getMetricNamespace() + \"(.*)\")\n+                            && currentTimestamp - new File(path.toString()).lastModified()\n+                            <= config.getAggregateFrequency()) {\n+                        try {\n+                            for (String log :\n+                                    Files.lines(Paths.get(path.toString())).collect(Collectors.toList())) {\n+                                /*\n+                                [0]  [1] [2]        [3]          [4]         [5]             [6]\n+                                2020 Aug 28 12:08:21,520-0700 [TRACE] (pool-3-thread-4) Metrics-KernelComponents:\n+\n+                                [7]\n+                                {\"M\":{\"NS\": \"KernelComponents\",\"N\":\"NumberOfComponentsStopping\",\"U\":\"Count\"},\n+                                \"V\":0,\"TS\":1598598501520}. {}\n+                                 */\n+                                MetricDataPoint mdp = new ObjectMapper()\n+                                        .readValue(log.split(\" \")[7], MetricDataPoint.class);\n+                                if (currentTimestamp - mdp.getTimestamp() <= config.getAggregateFrequency()) {\n+                                    metrics.computeIfAbsent(mdp.getMetric().getMetricName(),\n+                                            k -> new ArrayList<>()).add(mdp);\n+                                }\n+                            }\n+                        } catch (IOException e) {\n+                            logger.atError().log(e);\n+                        }\n+                    }\n+\n+                });\n+                aggMetrics.setMetricNamespace(TelemetryNamespace.valueOf(config.getMetricNamespace()));\n+                aggMetrics.setTimestamp(currentTimestamp);\n+                aggMetrics.setMetric(doAggregation(metrics, TelemetryAggregation.valueOf(config.getAggregationType())));\n+                /*\n+                    Writing to memory for now. But write to a file?\n+                 */\n+                logger.atInfo().log(new ObjectMapper().writeValueAsString(aggMetrics));\n+            } catch (IOException e) {\n+                logger.atError().log(e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "044114b548f4eb239cb00d856aedbde52f3984bb"}, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM3Mzg0MA==", "bodyText": "use a switch", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r480373840", "createdAt": "2020-08-31T20:14:26Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,152 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.dependency.Context;\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.aggregation.AggregatedMetric;\n+import com.aws.iot.evergreen.telemetry.config.TelemetryDataConfig;\n+import com.aws.iot.evergreen.telemetry.impl.MetricDataPoint;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.telemetryDataConfigMap;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+\n+    /**\n+     * Aggregate metrics based on the telemetry config.\n+     * @param context use this to schedule thread pool.\n+     */\n+    public void aggregateMetrics(Context context) {\n+        // TODO read from a telemetry config file.\n+        for (Map.Entry<String, TelemetryDataConfig> config: telemetryDataConfigMap.entrySet()) {\n+            TelemetryDataConfig metricConfig = config.getValue();\n+            ScheduledExecutorService executor = context.get(ScheduledExecutorService.class);\n+            executor.scheduleAtFixedRate(readLogsAndAggregate(metricConfig), 0, metricConfig.getAggregateFrequency(),\n+                    TimeUnit.MILLISECONDS);\n+        }\n+    }\n+\n+    private Runnable readLogsAndAggregate(TelemetryDataConfig config) {\n+        return () -> {\n+            long currentTimestamp = Instant.now().toEpochMilli();\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<MetricDataPoint>> metrics = new HashMap<>();\n+\n+            try {\n+                Stream<Path> paths = Files\n+                        .walk(Paths.get(System.getProperty(\"user.dir\") + \"/Telemetry/\"))\n+                        .filter(Files::isRegularFile);\n+                paths.forEach((path) -> {\n+                    /*\n+                     Read from the file at Telemetry/namespace*.log\n+                     Read only modified files and aggregate only new values based on the last aggregated time.\n+                     */\n+                    Object fileName = null;\n+                    if (path != null) {\n+                        fileName = path.getFileName();\n+                    }\n+                    if (fileName == null) {\n+                        fileName = \"\";\n+                    }\n+                    if (path != null\n+                            && path.getFileName() != null\n+                            && path.getFileName().toString().matches(config.getMetricNamespace() + \"(.*)\")\n+                            && currentTimestamp - new File(path.toString()).lastModified()\n+                            <= config.getAggregateFrequency()) {\n+                        try {\n+                            for (String log :\n+                                    Files.lines(Paths.get(path.toString())).collect(Collectors.toList())) {\n+                                /*\n+                                [0]  [1] [2]        [3]          [4]         [5]             [6]\n+                                2020 Aug 28 12:08:21,520-0700 [TRACE] (pool-3-thread-4) Metrics-KernelComponents:\n+\n+                                [7]\n+                                {\"M\":{\"NS\": \"KernelComponents\",\"N\":\"NumberOfComponentsStopping\",\"U\":\"Count\"},\n+                                \"V\":0,\"TS\":1598598501520}. {}\n+                                 */\n+                                MetricDataPoint mdp = new ObjectMapper()\n+                                        .readValue(log.split(\" \")[7], MetricDataPoint.class);\n+                                if (currentTimestamp - mdp.getTimestamp() <= config.getAggregateFrequency()) {\n+                                    metrics.computeIfAbsent(mdp.getMetric().getMetricName(),\n+                                            k -> new ArrayList<>()).add(mdp);\n+                                }\n+                            }\n+                        } catch (IOException e) {\n+                            logger.atError().log(e);\n+                        }\n+                    }\n+\n+                });\n+                aggMetrics.setMetricNamespace(TelemetryNamespace.valueOf(config.getMetricNamespace()));\n+                aggMetrics.setTimestamp(currentTimestamp);\n+                aggMetrics.setMetric(doAggregation(metrics, TelemetryAggregation.valueOf(config.getAggregationType())));\n+                /*\n+                    Writing to memory for now. But write to a file?\n+                 */\n+                logger.atInfo().log(new ObjectMapper().writeValueAsString(aggMetrics));\n+            } catch (IOException e) {\n+                logger.atError().log(e);\n+            }\n+        };\n+    }\n+\n+    private List<AggregatedMetric.Metric> doAggregation(Map<TelemetryMetricName, List<MetricDataPoint>> metrics,\n+                                                        TelemetryAggregation telemetryAggregation) {\n+        List<AggregatedMetric.Metric> aggMetrics = new ArrayList<>();\n+        for (Map.Entry<TelemetryMetricName, List<MetricDataPoint>> metric : metrics.entrySet()) {\n+            TelemetryMetricName metricName = metric.getKey();\n+            List<MetricDataPoint> mdp = metric.getValue();\n+            Object aggregation = null;\n+            if (telemetryAggregation.equals(TelemetryAggregation.Average)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .mapToDouble(a -> Double.parseDouble(a.getValue().toString()))\n+                        .sum();\n+                if (!mdp.isEmpty()) {\n+                    aggregation = (double) aggregation / mdp.size();\n+                }\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Sum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .mapToDouble(a -> Double.parseDouble(a.getValue().toString()))\n+                        .sum();\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Maximum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .mapToDouble(a -> Double.parseDouble(a.getValue().toString()))\n+                        .max();\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Minimum)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "044114b548f4eb239cb00d856aedbde52f3984bb"}, "originalPosition": 137}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM3NDE5OQ==", "bodyText": "we need a way to cancel this. Also to de-duplicate calls, otherwise we can have multiple aggregations going.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r480374199", "createdAt": "2020-08-31T20:15:07Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,152 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.dependency.Context;\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.aggregation.AggregatedMetric;\n+import com.aws.iot.evergreen.telemetry.config.TelemetryDataConfig;\n+import com.aws.iot.evergreen.telemetry.impl.MetricDataPoint;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.telemetryDataConfigMap;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+\n+    /**\n+     * Aggregate metrics based on the telemetry config.\n+     * @param context use this to schedule thread pool.\n+     */\n+    public void aggregateMetrics(Context context) {\n+        // TODO read from a telemetry config file.\n+        for (Map.Entry<String, TelemetryDataConfig> config: telemetryDataConfigMap.entrySet()) {\n+            TelemetryDataConfig metricConfig = config.getValue();\n+            ScheduledExecutorService executor = context.get(ScheduledExecutorService.class);\n+            executor.scheduleAtFixedRate(readLogsAndAggregate(metricConfig), 0, metricConfig.getAggregateFrequency(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "044114b548f4eb239cb00d856aedbde52f3984bb"}, "originalPosition": 43}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9b38867eeb049739046da321a88644c60faeacd5", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/9b38867eeb049739046da321a88644c60faeacd5", "committedDate": "2020-09-01T02:53:05Z", "message": "Moved kernel metrics to separate class + Update log messages"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDc5MzY2MDMx", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-479366031", "createdAt": "2020-09-01T02:54:15Z", "commit": {"oid": "9b38867eeb049739046da321a88644c60faeacd5"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 13, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMVQwMjo1NDoxNVrOHKYyaw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMVQxNTozMDo1MFrOHK8I3g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDY1MzkzMQ==", "bodyText": "revert this.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r480653931", "createdAt": "2020-09-01T02:54:15Z", "author": {"login": "nikkhilmuthye"}, "path": "pom.xml", "diffHunk": "@@ -90,7 +90,7 @@\n         <dependency>\n             <groupId>com.aws.iot</groupId>\n             <artifactId>evergreen-java-sdk</artifactId>\n-            <version>0.0.0-SNAPSHOT</version>\n+            <version>0.0.0-telemetry-SNAPSHOT</version>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9b38867eeb049739046da321a88644c60faeacd5"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTIyMzUwMg==", "bodyText": "does it have to be static?", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r481223502", "createdAt": "2020-09-01T15:17:23Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/kernel/Kernel.java", "diffHunk": "@@ -83,7 +83,7 @@\n     public static final String SERVICE_TYPE_TOPIC_KEY = \"componentType\";\n     public static final String SERVICE_TYPE_TO_CLASS_MAP_KEY = \"componentTypeToClassMap\";\n     private static final String PLUGIN_SERVICE_TYPE_NAME = \"plugin\";\n-\n+    private static final KernelMetricsEmitter kernelMetricsEmitter = new KernelMetricsEmitter();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9b38867eeb049739046da321a88644c60faeacd5"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTIyMzczNw==", "bodyText": "nit: add copywrite in all new files.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r481223737", "createdAt": "2020-09-01T15:17:44Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,75 @@\n+package com.aws.iot.evergreen.kernel;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9b38867eeb049739046da321a88644c60faeacd5"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTIyNTgwMg==", "bodyText": "Why are you returning a runnable here? You can just save the kernel reference and metrics data map in the class. and just have a normal void function.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r481225802", "createdAt": "2020-09-01T15:20:44Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,75 @@\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.dependency.Context;\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.MetricsAgent;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+\n+public class KernelMetricsEmitter {\n+    private static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+\n+    private static final long KERNEL_COMPONENTS_STATE_PERIOD = MetricsAgent.createSampleConfiguration()\n+            .get(TelemetryNamespace.KernelComponents.toString()).getEmitFrequency();\n+    private static final String KERNEL_COMPONENT_METRIC_STORE = TelemetryNamespace.KernelComponents.toString();\n+    private static Map<TelemetryMetricName, MetricDataBuilder> kernelMetrics = new HashMap<>();\n+\n+    /**\n+     * Collect kernel metrics - Number of components running in each state.\n+     */\n+    protected void collectKernelComponentState(Context context, Kernel kernel) {\n+        List<TelemetryMetricName> telemetryMetricNames =\n+                TelemetryMetricName.getMetricNamesOf(TelemetryNamespace.KernelComponents);\n+        Map<TelemetryMetricName, Integer> kernelMetricsData = new HashMap<>();\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            Metric metric = Metric.builder()\n+                    .metricNamespace(TelemetryNamespace.KernelComponents)\n+                    .metricName(telemetryMetricName)\n+                    .metricUnit(TelemetryUnit.Count)\n+                    .build();\n+            MetricDataBuilder metricDataBuilder = new MetricFactory(KERNEL_COMPONENT_METRIC_STORE).addMetric(metric);\n+            kernelMetrics.put(telemetryMetricName, metricDataBuilder);\n+        }\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            kernelMetricsData.put(telemetryMetricName, 0);\n+        }\n+        ScheduledExecutorService executor = context.get(ScheduledExecutorService.class);\n+        executor.scheduleAtFixedRate(emitMetrics(kernel, kernelMetricsData),\n+                0, KERNEL_COMPONENTS_STATE_PERIOD, TimeUnit.MILLISECONDS);\n+    }\n+\n+    private Runnable emitMetrics(Kernel kernel, Map<TelemetryMetricName, Integer> kernelMetricsData) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9b38867eeb049739046da321a88644c60faeacd5"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTIyNjU3MA==", "bodyText": "I am not a big fan of this logic. Can you just subscribe to a topic and then start/stop the scheduled task based on that?", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r481226570", "createdAt": "2020-09-01T15:21:47Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,75 @@\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.dependency.Context;\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.MetricsAgent;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+\n+public class KernelMetricsEmitter {\n+    private static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+\n+    private static final long KERNEL_COMPONENTS_STATE_PERIOD = MetricsAgent.createSampleConfiguration()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9b38867eeb049739046da321a88644c60faeacd5"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTIyNzUxNQ==", "bodyText": "nit: rename to startPeriodicTelemetryMetricsUpdate", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r481227515", "createdAt": "2020-09-01T15:23:06Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,75 @@\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.dependency.Context;\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.MetricsAgent;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+\n+public class KernelMetricsEmitter {\n+    private static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+\n+    private static final long KERNEL_COMPONENTS_STATE_PERIOD = MetricsAgent.createSampleConfiguration()\n+            .get(TelemetryNamespace.KernelComponents.toString()).getEmitFrequency();\n+    private static final String KERNEL_COMPONENT_METRIC_STORE = TelemetryNamespace.KernelComponents.toString();\n+    private static Map<TelemetryMetricName, MetricDataBuilder> kernelMetrics = new HashMap<>();\n+\n+    /**\n+     * Collect kernel metrics - Number of components running in each state.\n+     */\n+    protected void collectKernelComponentState(Context context, Kernel kernel) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9b38867eeb049739046da321a88644c60faeacd5"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTIyNzc5Mw==", "bodyText": "nit: format", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r481227793", "createdAt": "2020-09-01T15:23:33Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,75 @@\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.dependency.Context;\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.MetricsAgent;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+\n+public class KernelMetricsEmitter {\n+    private static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+\n+    private static final long KERNEL_COMPONENTS_STATE_PERIOD = MetricsAgent.createSampleConfiguration()\n+            .get(TelemetryNamespace.KernelComponents.toString()).getEmitFrequency();\n+    private static final String KERNEL_COMPONENT_METRIC_STORE = TelemetryNamespace.KernelComponents.toString();\n+    private static Map<TelemetryMetricName, MetricDataBuilder> kernelMetrics = new HashMap<>();\n+\n+    /**\n+     * Collect kernel metrics - Number of components running in each state.\n+     */\n+    protected void collectKernelComponentState(Context context, Kernel kernel) {\n+        List<TelemetryMetricName> telemetryMetricNames =\n+                TelemetryMetricName.getMetricNamesOf(TelemetryNamespace.KernelComponents);\n+        Map<TelemetryMetricName, Integer> kernelMetricsData = new HashMap<>();\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            Metric metric = Metric.builder()\n+                    .metricNamespace(TelemetryNamespace.KernelComponents)\n+                    .metricName(telemetryMetricName)\n+                    .metricUnit(TelemetryUnit.Count)\n+                    .build();\n+            MetricDataBuilder metricDataBuilder = new MetricFactory(KERNEL_COMPONENT_METRIC_STORE).addMetric(metric);\n+            kernelMetrics.put(telemetryMetricName, metricDataBuilder);\n+        }\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            kernelMetricsData.put(telemetryMetricName, 0);\n+        }\n+        ScheduledExecutorService executor = context.get(ScheduledExecutorService.class);\n+        executor.scheduleAtFixedRate(emitMetrics(kernel, kernelMetricsData),\n+                0, KERNEL_COMPONENTS_STATE_PERIOD, TimeUnit.MILLISECONDS);\n+    }\n+\n+    private Runnable emitMetrics(Kernel kernel, Map<TelemetryMetricName, Integer> kernelMetricsData) {\n+        return () -> {\n+            Collection<EvergreenService> evergreenServices = kernel.orderedDependencies();\n+            for (EvergreenService evergreenService : evergreenServices) {\n+                String serviceState = evergreenService.getState().toString();\n+                serviceState = serviceState.charAt(0) + serviceState.substring(1).toLowerCase();\n+                try{\n+                    TelemetryMetricName telemetryMetricName =\n+                            TelemetryMetricName.valueOf(\"NumberOfComponents\" + serviceState);\n+                    kernelMetricsData.put(telemetryMetricName, kernelMetricsData.get(telemetryMetricName) + 1);\n+                } catch (IllegalArgumentException e) {\n+                    logger.atError().log(\"Unable to find the metric name.\" + e);\n+                }\n+            }\n+            for (HashMap.Entry<TelemetryMetricName, MetricDataBuilder> kernelMetric : kernelMetrics.entrySet()) {\n+                MetricDataBuilder metricDataBuilder = kernelMetric.getValue();\n+                metricDataBuilder.putMetricData(kernelMetricsData.get(kernelMetric.getKey())).emit();\n+                kernelMetricsData.put(kernelMetric.getKey(),0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9b38867eeb049739046da321a88644c60faeacd5"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTIyOTA5Mw==", "bodyText": "Instead of this just call super.startup()", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r481229093", "createdAt": "2020-09-01T15:25:28Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,50 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.dependency.State;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.telemetry.config.TelemetryDataConfig;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+\n+    public MetricsAgent(Topics topics) {\n+        super(topics);\n+    }\n+\n+    @Override\n+    public void startup() {\n+        reportState(State.RUNNING);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9b38867eeb049739046da321a88644c60faeacd5"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTIzMDExNg==", "bodyText": "Same comment here. Why use Runnable?", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r481230116", "createdAt": "2020-09-01T15:26:47Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsUploader.java", "diffHunk": "@@ -0,0 +1,36 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.dependency.Context;\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.config.TelemetryDataConfig;\n+\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+\n+\n+public class MetricsUploader {\n+    public static final Logger logger = LogManager.getLogger(MetricsUploader.class);\n+\n+    /**\n+     * Upload metrics on based on upload frequency.\n+     * @param context use this to schedule thread pool.\n+     */\n+    public void uploadMetrics(Context context) {\n+        // TODO read from a telemetry config file.\n+        for (Map.Entry<String, TelemetryDataConfig> config : MetricsAgent.createSampleConfiguration().entrySet()) {\n+            TelemetryDataConfig metricConfig = config.getValue();\n+            ScheduledExecutorService executor = context.get(ScheduledExecutorService.class);\n+            executor.scheduleAtFixedRate(readLogsAndUpload(metricConfig),0, metricConfig.getUploadFrequency(),\n+                    TimeUnit.MILLISECONDS);\n+        }\n+    }\n+\n+    private Runnable readLogsAndUpload(TelemetryDataConfig config) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9b38867eeb049739046da321a88644c60faeacd5"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTIzMDU3Ng==", "bodyText": "nit: rename to startSystemTelemetryMetricsPeriodicUpdate", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r481230576", "createdAt": "2020-09-01T15:27:22Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/SystemMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,88 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.dependency.Context;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import oshi.SystemInfo;\n+import oshi.hardware.CentralProcessor;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.createSampleConfiguration;\n+\n+public class SystemMetricsEmitter {\n+    private static final int MB_CONVERTER = 1024 * 1024;\n+    private static final int PERCENTAGE_CONVERTER = 100;\n+    private static long SYSTEM_METRICS_PERIOD = createSampleConfiguration()\n+            .get(TelemetryNamespace.SystemMetrics.toString()).getEmitFrequency();\n+    private static String SYSTEM_METRICS_STORE = TelemetryNamespace.SystemMetrics.toString();\n+    private static CentralProcessor cpu = new SystemInfo().getHardware().getProcessor();\n+    private static SystemInfo systemInfo = new SystemInfo();\n+    private static long[] previousTicks = new long[CentralProcessor.TickType.values().length];\n+    private static Map<TelemetryMetricName, Object> systemMetricsData = new HashMap<>();\n+    private static Map<TelemetryMetricName, MetricDataBuilder> systemMetrics = new HashMap<>();\n+\n+    /**\n+     * Create system metrics, collect and emit periodically.\n+     *\n+     */\n+    protected void collectSystemMetrics(Context context) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9b38867eeb049739046da321a88644c60faeacd5"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTIzMTA2MQ==", "bodyText": "Put this in its own class", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r481231061", "createdAt": "2020-09-01T15:28:03Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/aggregation/AggregatedMetric.java", "diffHunk": "@@ -0,0 +1,32 @@\n+package com.aws.iot.evergreen.telemetry.aggregation;\n+\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import lombok.Builder;\n+import lombok.Data;\n+\n+import java.util.List;\n+\n+@Data\n+public class AggregatedMetric {\n+    @JsonProperty(\"TS\")\n+    private Long timestamp;\n+    @JsonProperty(\"NS\")\n+    private TelemetryNamespace metricNamespace;\n+    @JsonProperty(\"M\")\n+    private List<Metric> metric;\n+\n+    @Data\n+    @Builder\n+    public static class Metric {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9b38867eeb049739046da321a88644c60faeacd5"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTIzMjYxNQ==", "bodyText": "Need to get this from the logger. Look at how I have done it for the logs uploader. https://github.com/aws/aws-greengrass-sdk-java/pull/56/files#diff-bf04d24956d8f5f6cb2dc5a970349455R71\nMight want to do something similar for metrics.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r481232615", "createdAt": "2020-09-01T15:30:05Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,159 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.dependency.Context;\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.aggregation.AggregatedMetric;\n+import com.aws.iot.evergreen.telemetry.config.TelemetryDataConfig;\n+import com.aws.iot.evergreen.telemetry.impl.MetricDataPoint;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.createSampleConfiguration;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    public static final String LOG_FILES_PATH = System.getProperty(\"user.dir\") + \"/Telemetry/\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9b38867eeb049739046da321a88644c60faeacd5"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTIzMzExOA==", "bodyText": "nit: Right. Instead add a TODO:", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r481233118", "createdAt": "2020-09-01T15:30:50Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,159 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.dependency.Context;\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.aggregation.AggregatedMetric;\n+import com.aws.iot.evergreen.telemetry.config.TelemetryDataConfig;\n+import com.aws.iot.evergreen.telemetry.impl.MetricDataPoint;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.createSampleConfiguration;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    public static final String LOG_FILES_PATH = System.getProperty(\"user.dir\") + \"/Telemetry/\";\n+\n+    /**\n+     * Aggregate metrics based on the telemetry config.\n+     * @param context use this to schedule thread pool.\n+     */\n+    public void aggregateMetrics(Context context) {\n+        // TODO read from a telemetry config file.\n+        for (Map.Entry<String, TelemetryDataConfig> config: createSampleConfiguration().entrySet()) {\n+            TelemetryDataConfig metricConfig = config.getValue();\n+            ScheduledExecutorService executor = context.get(ScheduledExecutorService.class);\n+            executor.scheduleAtFixedRate(readLogsAndAggregate(metricConfig), 0, metricConfig.getAggregateFrequency(),\n+                    TimeUnit.MILLISECONDS);\n+        }\n+    }\n+\n+    private Runnable readLogsAndAggregate(TelemetryDataConfig config) {\n+        return () -> {\n+            long currentTimestamp = Instant.now().toEpochMilli();\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<MetricDataPoint>> metrics = new HashMap<>();\n+            try {\n+                Stream<Path> paths = Files\n+                        .walk(Paths.get(LOG_FILES_PATH))\n+                        .filter(Files::isRegularFile);\n+                paths.forEach((path) -> {\n+                    /*\n+                     Read from the file at Telemetry/namespace*.log\n+                     Read only modified files and aggregate only new values based on the last aggregated time.\n+                     */\n+                    Object fileName = null;\n+                    if (path != null) {\n+                        fileName = path.getFileName();\n+                    }\n+                    if (fileName == null) {\n+                        fileName = \"\";\n+                    }\n+                    if (fileName.toString().matches(config.getMetricNamespace() + \"(.*)\")\n+                            && currentTimestamp - new File(path.toString()).lastModified()\n+                            <= config.getAggregateFrequency()) {\n+                        try {\n+                            for (String log :\n+                                    Files.lines(Paths.get(path.toString())).collect(Collectors.toList())) {\n+                                /*\n+                                [0]  [1] [2]        [3]          [4]         [5]             [6]\n+                                2020 Aug 28 12:08:21,520-0700 [TRACE] (pool-3-thread-4) Metrics-KernelComponents:\n+\n+                                [7]\n+                                {\"M\":{\"NS\": \"KernelComponents\",\"N\":\"NumberOfComponentsStopping\",\"U\":\"Count\"},\n+                                \"V\":0,\"TS\":1598598501520}. {}\n+                                 */\n+                                MetricDataPoint mdp = new ObjectMapper()\n+                                        .readValue(log.split(\" \")[7], MetricDataPoint.class);\n+                                if (currentTimestamp - mdp.getTimestamp() <= config.getAggregateFrequency()) {\n+                                    metrics.computeIfAbsent(mdp.getMetric().getMetricName(),\n+                                            k -> new ArrayList<>()).add(mdp);\n+                                }\n+                            }\n+                        } catch (IOException e) {\n+                            logger.atError().log(\"Failed to read the telemetry logs for aggregation.\" + e);\n+                        }\n+                    }\n+\n+                });\n+                aggMetrics.setMetricNamespace(TelemetryNamespace.valueOf(config.getMetricNamespace()));\n+                aggMetrics.setTimestamp(currentTimestamp);\n+                aggMetrics.setMetric(doAggregation(metrics, TelemetryAggregation.valueOf(config.getAggregationType())));\n+                /*\n+                    Writing to memory for now. But write to a file?", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9b38867eeb049739046da321a88644c60faeacd5"}, "originalPosition": 101}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0782fa17b596f951f873e4a402fa0a2bca4e585c", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/0782fa17b596f951f873e4a402fa0a2bca4e585c", "committedDate": "2020-09-08T07:33:23Z", "message": "Merge branch 'master' of github.com:/aws/aws-greengrass-kernel into telemetry-logs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c1900ef340a313e29eec3027061f349b38bd093a", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/c1900ef340a313e29eec3027061f349b38bd093a", "committedDate": "2020-09-08T07:37:04Z", "message": "Telemetry metrics + tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bf31cb5a50235c3b20a391be6058c839680f9e39", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/bf31cb5a50235c3b20a391be6058c839680f9e39", "committedDate": "2020-09-08T07:41:14Z", "message": "Telemetry metrics + tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f", "committedDate": "2020-09-08T07:41:45Z", "message": "Merge branch 'telemetry-logs' of github.com:/aws/aws-greengrass-kernel into telemetry-logs"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg0MjkwMTY0", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-484290164", "createdAt": "2020-09-08T16:06:10Z", "commit": {"oid": "044114b548f4eb239cb00d856aedbde52f3984bb"}, "state": "COMMENTED", "comments": {"totalCount": 25, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxNjowNjoxMFrOHOkNww==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxNjozMDo0NlrOHOlJgA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTAzNTQ1OQ==", "bodyText": "Fix indentation. out-dent it", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485035459", "createdAt": "2020-09-08T16:06:10Z", "author": {"login": "MikeDombo"}, "path": "pom.xml", "diffHunk": "@@ -172,6 +172,11 @@\n         with recent Windows/VC redist. The behavior is changed in recent jna release. By declaring direct dependency of\n         jna, we avoid the problem of loading msvcr100.dll.\n         -->\n+\t\t<dependency>\n+\t\t\t<groupId>com.github.oshi</groupId>\n+\t\t\t<artifactId>oshi-core</artifactId>\n+\t\t\t<version>5.2.3</version>\n+\t\t</dependency>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM2ODQ5NA=="}, "originalCommit": {"oid": "044114b548f4eb239cb00d856aedbde52f3984bb"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTAzNjY1NA==", "bodyText": "Inject in the constructor instead of getting it from context.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485036654", "createdAt": "2020-09-08T16:08:07Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,125 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.MetricsAgent;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.util.Coerce;\n+import lombok.NonNull;\n+\n+import java.time.Instant;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+\n+public class KernelMetricsEmitter {\n+    // Kernel metrics\n+    public static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+    private static final String KERNEL_COMPONENT_METRIC_STORE = TelemetryNamespace.KernelComponents.toString();\n+    private static Map<TelemetryMetricName, MetricDataBuilder> kernelMetrics = new HashMap<>();\n+    private static Map<TelemetryMetricName, Integer> kernelMetricsData = new HashMap<>();\n+    private ScheduledFuture<?> periodicKernelMetricsFuture = null;\n+    private final Object periodicKernelMetricsInProgressLock = new Object();\n+    private int periodicKernelMetricsIntervalSec = 0;\n+\n+    @NonNull\n+    private final Kernel kernel;\n+\n+    /**\n+     *  Constructor for kernel metrics emitter.\n+     * @param kernel  {@link Kernel}\n+     */\n+    public KernelMetricsEmitter(Kernel kernel) {\n+        this.kernel = kernel;\n+    }\n+\n+    /**\n+     * Schedules the periodic kernel metrics based on the configured aggregation interval.\n+     * @param isReconfigured true if the interval is reconfigured\n+     */\n+    public void schedulePeriodicKernelMetrics(boolean isReconfigured) {\n+        // If the kernel/aggregation interval is reconfigured, cancel the previously scheduled job.\n+        if (this.periodicKernelMetricsFuture != null) {\n+            this.periodicKernelMetricsFuture.cancel(false);\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicKernelMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant\n+                        .ofEpochMilli(MetricsAgent.getLastPeriodicAggregationMetricsTime());\n+                if (lastPeriodicAggTime.plusSeconds(periodicKernelMetricsIntervalSec).isBefore(Instant.now())) {\n+                    this.emitKernelMetrics();\n+                }\n+            }\n+        }\n+        ScheduledExecutorService ses = this.kernel.getContext().get(ScheduledExecutorService.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTAzODg1MA==", "bodyText": "this is not correct. You're accessing \"parameters\" directly under the root, which it won't be. It will most likely be under \"system\", so you can look at the DeviceConfiguration class which is used to read that section", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485038850", "createdAt": "2020-09-08T16:11:36Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,125 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.MetricsAgent;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.util.Coerce;\n+import lombok.NonNull;\n+\n+import java.time.Instant;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+\n+public class KernelMetricsEmitter {\n+    // Kernel metrics\n+    public static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+    private static final String KERNEL_COMPONENT_METRIC_STORE = TelemetryNamespace.KernelComponents.toString();\n+    private static Map<TelemetryMetricName, MetricDataBuilder> kernelMetrics = new HashMap<>();\n+    private static Map<TelemetryMetricName, Integer> kernelMetricsData = new HashMap<>();\n+    private ScheduledFuture<?> periodicKernelMetricsFuture = null;\n+    private final Object periodicKernelMetricsInProgressLock = new Object();\n+    private int periodicKernelMetricsIntervalSec = 0;\n+\n+    @NonNull\n+    private final Kernel kernel;\n+\n+    /**\n+     *  Constructor for kernel metrics emitter.\n+     * @param kernel  {@link Kernel}\n+     */\n+    public KernelMetricsEmitter(Kernel kernel) {\n+        this.kernel = kernel;\n+    }\n+\n+    /**\n+     * Schedules the periodic kernel metrics based on the configured aggregation interval.\n+     * @param isReconfigured true if the interval is reconfigured\n+     */\n+    public void schedulePeriodicKernelMetrics(boolean isReconfigured) {\n+        // If the kernel/aggregation interval is reconfigured, cancel the previously scheduled job.\n+        if (this.periodicKernelMetricsFuture != null) {\n+            this.periodicKernelMetricsFuture.cancel(false);\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicKernelMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant\n+                        .ofEpochMilli(MetricsAgent.getLastPeriodicAggregationMetricsTime());\n+                if (lastPeriodicAggTime.plusSeconds(periodicKernelMetricsIntervalSec).isBefore(Instant.now())) {\n+                    this.emitKernelMetrics();\n+                }\n+            }\n+        }\n+        ScheduledExecutorService ses = this.kernel.getContext().get(ScheduledExecutorService.class);\n+        periodicKernelMetricsFuture = ses.scheduleWithFixedDelay(\n+                this::emitKernelMetrics, 0, periodicKernelMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Collect kernel metrics - Number of components running in each state.\n+     */\n+    protected void collectKernelComponentState() {\n+        List<TelemetryMetricName> telemetryMetricNames =\n+                TelemetryMetricName.getMetricNamesOf(TelemetryNamespace.KernelComponents);\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            Metric metric = Metric.builder()\n+                    .metricNamespace(TelemetryNamespace.KernelComponents)\n+                    .metricName(telemetryMetricName)\n+                    .metricUnit(TelemetryUnit.Count)\n+                    .metricAggregation(TelemetryAggregation.Average)\n+                    .build();\n+            MetricDataBuilder metricDataBuilder = new MetricFactory(KERNEL_COMPONENT_METRIC_STORE).addMetric(metric);\n+            kernelMetrics.put(telemetryMetricName, metricDataBuilder);\n+        }\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            kernelMetricsData.put(telemetryMetricName, 0);\n+        }\n+        kernel.getConfig().lookup(PARAMETERS_CONFIG_KEY, TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f"}, "originalPosition": 95}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTAzOTUxMw==", "bodyText": "log the exception not using concatentation. .log(\"...\", e)", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485039513", "createdAt": "2020-09-08T16:12:40Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,125 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.MetricsAgent;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.util.Coerce;\n+import lombok.NonNull;\n+\n+import java.time.Instant;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+\n+public class KernelMetricsEmitter {\n+    // Kernel metrics\n+    public static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+    private static final String KERNEL_COMPONENT_METRIC_STORE = TelemetryNamespace.KernelComponents.toString();\n+    private static Map<TelemetryMetricName, MetricDataBuilder> kernelMetrics = new HashMap<>();\n+    private static Map<TelemetryMetricName, Integer> kernelMetricsData = new HashMap<>();\n+    private ScheduledFuture<?> periodicKernelMetricsFuture = null;\n+    private final Object periodicKernelMetricsInProgressLock = new Object();\n+    private int periodicKernelMetricsIntervalSec = 0;\n+\n+    @NonNull\n+    private final Kernel kernel;\n+\n+    /**\n+     *  Constructor for kernel metrics emitter.\n+     * @param kernel  {@link Kernel}\n+     */\n+    public KernelMetricsEmitter(Kernel kernel) {\n+        this.kernel = kernel;\n+    }\n+\n+    /**\n+     * Schedules the periodic kernel metrics based on the configured aggregation interval.\n+     * @param isReconfigured true if the interval is reconfigured\n+     */\n+    public void schedulePeriodicKernelMetrics(boolean isReconfigured) {\n+        // If the kernel/aggregation interval is reconfigured, cancel the previously scheduled job.\n+        if (this.periodicKernelMetricsFuture != null) {\n+            this.periodicKernelMetricsFuture.cancel(false);\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicKernelMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant\n+                        .ofEpochMilli(MetricsAgent.getLastPeriodicAggregationMetricsTime());\n+                if (lastPeriodicAggTime.plusSeconds(periodicKernelMetricsIntervalSec).isBefore(Instant.now())) {\n+                    this.emitKernelMetrics();\n+                }\n+            }\n+        }\n+        ScheduledExecutorService ses = this.kernel.getContext().get(ScheduledExecutorService.class);\n+        periodicKernelMetricsFuture = ses.scheduleWithFixedDelay(\n+                this::emitKernelMetrics, 0, periodicKernelMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Collect kernel metrics - Number of components running in each state.\n+     */\n+    protected void collectKernelComponentState() {\n+        List<TelemetryMetricName> telemetryMetricNames =\n+                TelemetryMetricName.getMetricNamesOf(TelemetryNamespace.KernelComponents);\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            Metric metric = Metric.builder()\n+                    .metricNamespace(TelemetryNamespace.KernelComponents)\n+                    .metricName(telemetryMetricName)\n+                    .metricUnit(TelemetryUnit.Count)\n+                    .metricAggregation(TelemetryAggregation.Average)\n+                    .build();\n+            MetricDataBuilder metricDataBuilder = new MetricFactory(KERNEL_COMPONENT_METRIC_STORE).addMetric(metric);\n+            kernelMetrics.put(telemetryMetricName, metricDataBuilder);\n+        }\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            kernelMetricsData.put(telemetryMetricName, 0);\n+        }\n+        kernel.getConfig().lookup(PARAMETERS_CONFIG_KEY, TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC)\n+                .dflt(DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC)\n+                .subscribe((why, newv) -> {\n+                    periodicKernelMetricsIntervalSec = Coerce.toInt(newv);\n+                    if (periodicKernelMetricsFuture != null) {\n+                        this.schedulePeriodicKernelMetrics(true);\n+                    }\n+                });\n+        this.schedulePeriodicKernelMetrics(false);\n+    }\n+\n+    private void emitKernelMetrics() {\n+        Collection<EvergreenService> evergreenServices = kernel.orderedDependencies();\n+        for (EvergreenService evergreenService : evergreenServices) {\n+            String serviceState = evergreenService.getState().toString();\n+            serviceState = serviceState.charAt(0) + serviceState.substring(1).toLowerCase();\n+            try {\n+                TelemetryMetricName telemetryMetricName =\n+                        TelemetryMetricName.valueOf(\"NumberOfComponents\" + serviceState);\n+                kernelMetricsData.put(telemetryMetricName, kernelMetricsData.get(telemetryMetricName) + 1);\n+            } catch (IllegalArgumentException e) {\n+                logger.atError().log(\"Unable to find the metric name.\" + e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0MDA4OQ==", "bodyText": "cancel(true)? With true it will attempt to cancel the running instance.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485040089", "createdAt": "2020-09-08T16:13:39Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,125 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.MetricsAgent;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.util.Coerce;\n+import lombok.NonNull;\n+\n+import java.time.Instant;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+\n+public class KernelMetricsEmitter {\n+    // Kernel metrics\n+    public static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+    private static final String KERNEL_COMPONENT_METRIC_STORE = TelemetryNamespace.KernelComponents.toString();\n+    private static Map<TelemetryMetricName, MetricDataBuilder> kernelMetrics = new HashMap<>();\n+    private static Map<TelemetryMetricName, Integer> kernelMetricsData = new HashMap<>();\n+    private ScheduledFuture<?> periodicKernelMetricsFuture = null;\n+    private final Object periodicKernelMetricsInProgressLock = new Object();\n+    private int periodicKernelMetricsIntervalSec = 0;\n+\n+    @NonNull\n+    private final Kernel kernel;\n+\n+    /**\n+     *  Constructor for kernel metrics emitter.\n+     * @param kernel  {@link Kernel}\n+     */\n+    public KernelMetricsEmitter(Kernel kernel) {\n+        this.kernel = kernel;\n+    }\n+\n+    /**\n+     * Schedules the periodic kernel metrics based on the configured aggregation interval.\n+     * @param isReconfigured true if the interval is reconfigured\n+     */\n+    public void schedulePeriodicKernelMetrics(boolean isReconfigured) {\n+        // If the kernel/aggregation interval is reconfigured, cancel the previously scheduled job.\n+        if (this.periodicKernelMetricsFuture != null) {\n+            this.periodicKernelMetricsFuture.cancel(false);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0MjczMg==", "bodyText": "these should all be injected in the constructor so that you can actually test this code.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485042732", "createdAt": "2020-09-08T16:17:37Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.Getter;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    public static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 180;\n+    public static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 60;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    ScheduledFuture<?> periodicSystemMetricsFuture = null;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private String updateTopic;\n+    private String thingName;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0MzExMg==", "bodyText": "Use dependency injection to get this, don't read directly from the context", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485043112", "createdAt": "2020-09-08T16:18:15Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.Getter;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    public static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 180;\n+    public static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 60;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    ScheduledFuture<?> periodicSystemMetricsFuture = null;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private String updateTopic;\n+    private String thingName;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses = getContext().get(ScheduledExecutorService.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0MzQ4OA==", "bodyText": "why does this need a getter? At least don't make it public", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485043488", "createdAt": "2020-09-08T16:18:56Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.Getter;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    public static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 180;\n+    public static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 60;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    ScheduledFuture<?> periodicSystemMetricsFuture = null;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private String updateTopic;\n+    private String thingName;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses = getContext().get(ScheduledExecutorService.class);\n+    @Getter\n+    private static long lastPeriodicAggregationMetricsTime = Instant.now().toEpochMilli();\n+\n+\n+    @Getter", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0MzYyNg==", "bodyText": "should not be public", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485043626", "createdAt": "2020-09-08T16:19:10Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.Getter;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    public static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 180;\n+    public static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 60;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    ScheduledFuture<?> periodicSystemMetricsFuture = null;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private String updateTopic;\n+    private String thingName;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses = getContext().get(ScheduledExecutorService.class);\n+    @Getter\n+    private static long lastPeriodicAggregationMetricsTime = Instant.now().toEpochMilli();\n+\n+\n+    @Getter\n+    public MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0MzkwMg==", "bodyText": "again, should you cancel(true)?", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485043902", "createdAt": "2020-09-08T16:19:35Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.Getter;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    public static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 180;\n+    public static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 60;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    ScheduledFuture<?> periodicSystemMetricsFuture = null;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private String updateTopic;\n+    private String thingName;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses = getContext().get(ScheduledExecutorService.class);\n+    @Getter\n+    private static long lastPeriodicAggregationMetricsTime = Instant.now().toEpochMilli();\n+\n+\n+    @Getter\n+    public MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+\n+    /**\n+     *  Constructor for metrics agent.\n+     * @param topics root configuration topic for this service\n+     * @param mqttClient {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        // If the aggregation interval is reconfigured, cancel the previously scheduled job.\n+        if (periodicAggregateMetricsFuture != null) {\n+            periodicAggregateMetricsFuture.cancel(false);\n+        }\n+        // System metrics are emitted based on the aggregation interval.\n+        if (periodicSystemMetricsFuture != null) {\n+            periodicSystemMetricsFuture.cancel(false);\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f"}, "originalPosition": 104}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0NDUxNQ==", "bodyText": "should not be public. Make it package-private if you need to call it in tests", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485044515", "createdAt": "2020-09-08T16:20:33Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.Getter;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    public static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 180;\n+    public static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 60;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    ScheduledFuture<?> periodicSystemMetricsFuture = null;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private String updateTopic;\n+    private String thingName;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses = getContext().get(ScheduledExecutorService.class);\n+    @Getter\n+    private static long lastPeriodicAggregationMetricsTime = Instant.now().toEpochMilli();\n+\n+\n+    @Getter\n+    public MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+\n+    /**\n+     *  Constructor for metrics agent.\n+     * @param topics root configuration topic for this service\n+     * @param mqttClient {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        // If the aggregation interval is reconfigured, cancel the previously scheduled job.\n+        if (periodicAggregateMetricsFuture != null) {\n+            periodicAggregateMetricsFuture.cancel(false);\n+        }\n+        // System metrics are emitted based on the aggregation interval.\n+        if (periodicSystemMetricsFuture != null) {\n+            periodicSystemMetricsFuture.cancel(false);\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    emitPeriodicSystemMetrics();\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        periodicSystemMetricsFuture = ses.scheduleWithFixedDelay(\n+                this::emitPeriodicSystemMetrics, 0, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        periodicAggregateMetricsFuture = ses.scheduleWithFixedDelay(\n+                this::aggregatePeriodicMetrics, 0, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     *  Schedules the publishing of metrics based on the configured publish interval or the mqtt connection status.\n+     */\n+    private void schedulePeriodicPublishMetrics(boolean isReconfiguredOrConnectionResumed) {\n+        // If we missed to publish the metrics due to connection lost or if the publish interval is reconfigured,\n+        // cancel the previously scheduled job.\n+        if (periodicPublishMetricsFuture != null) {\n+            periodicPublishMetricsFuture.cancel(false);\n+        }\n+        if (isReconfiguredOrConnectionResumed) {\n+            synchronized (periodicPublishMetricsInProgressLock) {\n+                Instant lastPeriodicPublishTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicPublishTimeTopic()));\n+                if (lastPeriodicPublishTime.plusSeconds(periodicPublishMetricsIntervalSec)\n+                        .isBefore(Instant.now())) {\n+                    publishPeriodicMetrics();\n+                }\n+            }\n+        }\n+        periodicPublishMetricsFuture = ses.scheduleWithFixedDelay(\n+                this::publishPeriodicMetrics, 0, periodicPublishMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Helper for metrics aggregator. Also used in tests.\n+     */\n+    public void aggregatePeriodicMetrics() {\n+        long timeStamp = Instant.now().toEpochMilli();\n+        this.metricsAggregator.aggregateMetrics(periodicAggregateMetricsIntervalSec,timeStamp);\n+        getPeriodicAggregateTimeTopic().withValue(timeStamp);\n+    }\n+\n+    /**\n+     * Helper for metrics uploader. Also used in tests.\n+     */\n+    public void publishPeriodicMetrics() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f"}, "originalPosition": 154}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0NDU4NQ==", "bodyText": "same", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485044585", "createdAt": "2020-09-08T16:20:42Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.Getter;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    public static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 180;\n+    public static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 60;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    ScheduledFuture<?> periodicSystemMetricsFuture = null;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private String updateTopic;\n+    private String thingName;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses = getContext().get(ScheduledExecutorService.class);\n+    @Getter\n+    private static long lastPeriodicAggregationMetricsTime = Instant.now().toEpochMilli();\n+\n+\n+    @Getter\n+    public MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+\n+    /**\n+     *  Constructor for metrics agent.\n+     * @param topics root configuration topic for this service\n+     * @param mqttClient {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        // If the aggregation interval is reconfigured, cancel the previously scheduled job.\n+        if (periodicAggregateMetricsFuture != null) {\n+            periodicAggregateMetricsFuture.cancel(false);\n+        }\n+        // System metrics are emitted based on the aggregation interval.\n+        if (periodicSystemMetricsFuture != null) {\n+            periodicSystemMetricsFuture.cancel(false);\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    emitPeriodicSystemMetrics();\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        periodicSystemMetricsFuture = ses.scheduleWithFixedDelay(\n+                this::emitPeriodicSystemMetrics, 0, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        periodicAggregateMetricsFuture = ses.scheduleWithFixedDelay(\n+                this::aggregatePeriodicMetrics, 0, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     *  Schedules the publishing of metrics based on the configured publish interval or the mqtt connection status.\n+     */\n+    private void schedulePeriodicPublishMetrics(boolean isReconfiguredOrConnectionResumed) {\n+        // If we missed to publish the metrics due to connection lost or if the publish interval is reconfigured,\n+        // cancel the previously scheduled job.\n+        if (periodicPublishMetricsFuture != null) {\n+            periodicPublishMetricsFuture.cancel(false);\n+        }\n+        if (isReconfiguredOrConnectionResumed) {\n+            synchronized (periodicPublishMetricsInProgressLock) {\n+                Instant lastPeriodicPublishTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicPublishTimeTopic()));\n+                if (lastPeriodicPublishTime.plusSeconds(periodicPublishMetricsIntervalSec)\n+                        .isBefore(Instant.now())) {\n+                    publishPeriodicMetrics();\n+                }\n+            }\n+        }\n+        periodicPublishMetricsFuture = ses.scheduleWithFixedDelay(\n+                this::publishPeriodicMetrics, 0, periodicPublishMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Helper for metrics aggregator. Also used in tests.\n+     */\n+    public void aggregatePeriodicMetrics() {\n+        long timeStamp = Instant.now().toEpochMilli();\n+        this.metricsAggregator.aggregateMetrics(periodicAggregateMetricsIntervalSec,timeStamp);\n+        getPeriodicAggregateTimeTopic().withValue(timeStamp);\n+    }\n+\n+    /**\n+     * Helper for metrics uploader. Also used in tests.\n+     */\n+    public void publishPeriodicMetrics() {\n+        if (!isConnected.get()) {\n+            logger.atInfo().log(\"Cannot publish the metrics: MQTT Connection interrupted.\");\n+            return;\n+        }\n+        long timeStamp = Instant.now().toEpochMilli();\n+        Map<Long, List<MetricsAggregator.AggregatedMetric>> metricsToPublishMap =\n+                this.metricsUploader.getAggregatedMetrics(periodicPublishMetricsIntervalSec, timeStamp);\n+        getPeriodicPublishTimeTopic().withValue(timeStamp);\n+        MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder()\n+                .schema(\"schema\")\n+                .build();\n+        this.publisher.publish(aggregatedMetricsChunk, metricsToPublishMap.get(timeStamp));\n+    }\n+\n+    /**\n+     * Helper for system metrics emitter. Also used in tests.\n+     */\n+    public void emitPeriodicSystemMetrics() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f"}, "originalPosition": 172}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0NDk4MA==", "bodyText": "these configurations will be deleted on the next deployment. Consider using the runtime config space", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485044980", "createdAt": "2020-09-08T16:21:21Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.Getter;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    public static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 180;\n+    public static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 60;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    ScheduledFuture<?> periodicSystemMetricsFuture = null;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private String updateTopic;\n+    private String thingName;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses = getContext().get(ScheduledExecutorService.class);\n+    @Getter\n+    private static long lastPeriodicAggregationMetricsTime = Instant.now().toEpochMilli();\n+\n+\n+    @Getter\n+    public MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+\n+    /**\n+     *  Constructor for metrics agent.\n+     * @param topics root configuration topic for this service\n+     * @param mqttClient {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        // If the aggregation interval is reconfigured, cancel the previously scheduled job.\n+        if (periodicAggregateMetricsFuture != null) {\n+            periodicAggregateMetricsFuture.cancel(false);\n+        }\n+        // System metrics are emitted based on the aggregation interval.\n+        if (periodicSystemMetricsFuture != null) {\n+            periodicSystemMetricsFuture.cancel(false);\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    emitPeriodicSystemMetrics();\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        periodicSystemMetricsFuture = ses.scheduleWithFixedDelay(\n+                this::emitPeriodicSystemMetrics, 0, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        periodicAggregateMetricsFuture = ses.scheduleWithFixedDelay(\n+                this::aggregatePeriodicMetrics, 0, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     *  Schedules the publishing of metrics based on the configured publish interval or the mqtt connection status.\n+     */\n+    private void schedulePeriodicPublishMetrics(boolean isReconfiguredOrConnectionResumed) {\n+        // If we missed to publish the metrics due to connection lost or if the publish interval is reconfigured,\n+        // cancel the previously scheduled job.\n+        if (periodicPublishMetricsFuture != null) {\n+            periodicPublishMetricsFuture.cancel(false);\n+        }\n+        if (isReconfiguredOrConnectionResumed) {\n+            synchronized (periodicPublishMetricsInProgressLock) {\n+                Instant lastPeriodicPublishTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicPublishTimeTopic()));\n+                if (lastPeriodicPublishTime.plusSeconds(periodicPublishMetricsIntervalSec)\n+                        .isBefore(Instant.now())) {\n+                    publishPeriodicMetrics();\n+                }\n+            }\n+        }\n+        periodicPublishMetricsFuture = ses.scheduleWithFixedDelay(\n+                this::publishPeriodicMetrics, 0, periodicPublishMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Helper for metrics aggregator. Also used in tests.\n+     */\n+    public void aggregatePeriodicMetrics() {\n+        long timeStamp = Instant.now().toEpochMilli();\n+        this.metricsAggregator.aggregateMetrics(periodicAggregateMetricsIntervalSec,timeStamp);\n+        getPeriodicAggregateTimeTopic().withValue(timeStamp);\n+    }\n+\n+    /**\n+     * Helper for metrics uploader. Also used in tests.\n+     */\n+    public void publishPeriodicMetrics() {\n+        if (!isConnected.get()) {\n+            logger.atInfo().log(\"Cannot publish the metrics: MQTT Connection interrupted.\");\n+            return;\n+        }\n+        long timeStamp = Instant.now().toEpochMilli();\n+        Map<Long, List<MetricsAggregator.AggregatedMetric>> metricsToPublishMap =\n+                this.metricsUploader.getAggregatedMetrics(periodicPublishMetricsIntervalSec, timeStamp);\n+        getPeriodicPublishTimeTopic().withValue(timeStamp);\n+        MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder()\n+                .schema(\"schema\")\n+                .build();\n+        this.publisher.publish(aggregatedMetricsChunk, metricsToPublishMap.get(timeStamp));\n+    }\n+\n+    /**\n+     * Helper for system metrics emitter. Also used in tests.\n+     */\n+    public void emitPeriodicSystemMetrics() {\n+        this.systemMetricsEmitter.emitMetrics();\n+    }\n+\n+    private Topic getPeriodicPublishTimeTopic() {\n+        return config.lookup(TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC).dflt(Instant.now().toEpochMilli())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f"}, "originalPosition": 177}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0NTQ4Mg==", "bodyText": "call super later because that will set your state as running. Instead, try to get through all this code before declaring that you're running", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485045482", "createdAt": "2020-09-08T16:22:10Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.Getter;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    public static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 180;\n+    public static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 60;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    ScheduledFuture<?> periodicSystemMetricsFuture = null;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private String updateTopic;\n+    private String thingName;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses = getContext().get(ScheduledExecutorService.class);\n+    @Getter\n+    private static long lastPeriodicAggregationMetricsTime = Instant.now().toEpochMilli();\n+\n+\n+    @Getter\n+    public MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+\n+    /**\n+     *  Constructor for metrics agent.\n+     * @param topics root configuration topic for this service\n+     * @param mqttClient {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        // If the aggregation interval is reconfigured, cancel the previously scheduled job.\n+        if (periodicAggregateMetricsFuture != null) {\n+            periodicAggregateMetricsFuture.cancel(false);\n+        }\n+        // System metrics are emitted based on the aggregation interval.\n+        if (periodicSystemMetricsFuture != null) {\n+            periodicSystemMetricsFuture.cancel(false);\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    emitPeriodicSystemMetrics();\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        periodicSystemMetricsFuture = ses.scheduleWithFixedDelay(\n+                this::emitPeriodicSystemMetrics, 0, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        periodicAggregateMetricsFuture = ses.scheduleWithFixedDelay(\n+                this::aggregatePeriodicMetrics, 0, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     *  Schedules the publishing of metrics based on the configured publish interval or the mqtt connection status.\n+     */\n+    private void schedulePeriodicPublishMetrics(boolean isReconfiguredOrConnectionResumed) {\n+        // If we missed to publish the metrics due to connection lost or if the publish interval is reconfigured,\n+        // cancel the previously scheduled job.\n+        if (periodicPublishMetricsFuture != null) {\n+            periodicPublishMetricsFuture.cancel(false);\n+        }\n+        if (isReconfiguredOrConnectionResumed) {\n+            synchronized (periodicPublishMetricsInProgressLock) {\n+                Instant lastPeriodicPublishTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicPublishTimeTopic()));\n+                if (lastPeriodicPublishTime.plusSeconds(periodicPublishMetricsIntervalSec)\n+                        .isBefore(Instant.now())) {\n+                    publishPeriodicMetrics();\n+                }\n+            }\n+        }\n+        periodicPublishMetricsFuture = ses.scheduleWithFixedDelay(\n+                this::publishPeriodicMetrics, 0, periodicPublishMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Helper for metrics aggregator. Also used in tests.\n+     */\n+    public void aggregatePeriodicMetrics() {\n+        long timeStamp = Instant.now().toEpochMilli();\n+        this.metricsAggregator.aggregateMetrics(periodicAggregateMetricsIntervalSec,timeStamp);\n+        getPeriodicAggregateTimeTopic().withValue(timeStamp);\n+    }\n+\n+    /**\n+     * Helper for metrics uploader. Also used in tests.\n+     */\n+    public void publishPeriodicMetrics() {\n+        if (!isConnected.get()) {\n+            logger.atInfo().log(\"Cannot publish the metrics: MQTT Connection interrupted.\");\n+            return;\n+        }\n+        long timeStamp = Instant.now().toEpochMilli();\n+        Map<Long, List<MetricsAggregator.AggregatedMetric>> metricsToPublishMap =\n+                this.metricsUploader.getAggregatedMetrics(periodicPublishMetricsIntervalSec, timeStamp);\n+        getPeriodicPublishTimeTopic().withValue(timeStamp);\n+        MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder()\n+                .schema(\"schema\")\n+                .build();\n+        this.publisher.publish(aggregatedMetricsChunk, metricsToPublishMap.get(timeStamp));\n+    }\n+\n+    /**\n+     * Helper for system metrics emitter. Also used in tests.\n+     */\n+    public void emitPeriodicSystemMetrics() {\n+        this.systemMetricsEmitter.emitMetrics();\n+    }\n+\n+    private Topic getPeriodicPublishTimeTopic() {\n+        return config.lookup(TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC).dflt(Instant.now().toEpochMilli())\n+                .subscribe((why, newv) -> lastPeriodicAggregationMetricsTime = Coerce.toLong(newv));\n+    }\n+\n+    private Topic getPeriodicAggregateTimeTopic() {\n+        return config.lookup(TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC).dflt(Instant.now().toEpochMilli());\n+    }\n+\n+    private void updateThingNameAndPublishTopic(String newThingName) {\n+        if (newThingName != null) {\n+            thingName = newThingName;\n+            updateTopic = telemetryMetricsPublishTopic.replace(\"{thingName}\", thingName);\n+            this.publisher.setUpdateTopic(updateTopic);\n+        }\n+    }\n+\n+    @Override\n+    public void startup() throws InterruptedException {\n+        super.startup();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f"}, "originalPosition": 195}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0NjE2OQ==", "bodyText": "this is correct. Change the earlier problematic one in the kernel to use kernel.findServiceTopics(MeticsAgent).lookup(parameters, ...)", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485046169", "createdAt": "2020-09-08T16:23:18Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,235 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.Getter;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    public static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 180;\n+    public static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 60;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    ScheduledFuture<?> periodicSystemMetricsFuture = null;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private String updateTopic;\n+    private String thingName;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses = getContext().get(ScheduledExecutorService.class);\n+    @Getter\n+    private static long lastPeriodicAggregationMetricsTime = Instant.now().toEpochMilli();\n+\n+\n+    @Getter\n+    public MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+\n+    /**\n+     *  Constructor for metrics agent.\n+     * @param topics root configuration topic for this service\n+     * @param mqttClient {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        // If the aggregation interval is reconfigured, cancel the previously scheduled job.\n+        if (periodicAggregateMetricsFuture != null) {\n+            periodicAggregateMetricsFuture.cancel(false);\n+        }\n+        // System metrics are emitted based on the aggregation interval.\n+        if (periodicSystemMetricsFuture != null) {\n+            periodicSystemMetricsFuture.cancel(false);\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    emitPeriodicSystemMetrics();\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        periodicSystemMetricsFuture = ses.scheduleWithFixedDelay(\n+                this::emitPeriodicSystemMetrics, 0, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        periodicAggregateMetricsFuture = ses.scheduleWithFixedDelay(\n+                this::aggregatePeriodicMetrics, 0, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     *  Schedules the publishing of metrics based on the configured publish interval or the mqtt connection status.\n+     */\n+    private void schedulePeriodicPublishMetrics(boolean isReconfiguredOrConnectionResumed) {\n+        // If we missed to publish the metrics due to connection lost or if the publish interval is reconfigured,\n+        // cancel the previously scheduled job.\n+        if (periodicPublishMetricsFuture != null) {\n+            periodicPublishMetricsFuture.cancel(false);\n+        }\n+        if (isReconfiguredOrConnectionResumed) {\n+            synchronized (periodicPublishMetricsInProgressLock) {\n+                Instant lastPeriodicPublishTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicPublishTimeTopic()));\n+                if (lastPeriodicPublishTime.plusSeconds(periodicPublishMetricsIntervalSec)\n+                        .isBefore(Instant.now())) {\n+                    publishPeriodicMetrics();\n+                }\n+            }\n+        }\n+        periodicPublishMetricsFuture = ses.scheduleWithFixedDelay(\n+                this::publishPeriodicMetrics, 0, periodicPublishMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Helper for metrics aggregator. Also used in tests.\n+     */\n+    public void aggregatePeriodicMetrics() {\n+        long timeStamp = Instant.now().toEpochMilli();\n+        this.metricsAggregator.aggregateMetrics(periodicAggregateMetricsIntervalSec,timeStamp);\n+        getPeriodicAggregateTimeTopic().withValue(timeStamp);\n+    }\n+\n+    /**\n+     * Helper for metrics uploader. Also used in tests.\n+     */\n+    public void publishPeriodicMetrics() {\n+        if (!isConnected.get()) {\n+            logger.atInfo().log(\"Cannot publish the metrics: MQTT Connection interrupted.\");\n+            return;\n+        }\n+        long timeStamp = Instant.now().toEpochMilli();\n+        Map<Long, List<MetricsAggregator.AggregatedMetric>> metricsToPublishMap =\n+                this.metricsUploader.getAggregatedMetrics(periodicPublishMetricsIntervalSec, timeStamp);\n+        getPeriodicPublishTimeTopic().withValue(timeStamp);\n+        MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder()\n+                .schema(\"schema\")\n+                .build();\n+        this.publisher.publish(aggregatedMetricsChunk, metricsToPublishMap.get(timeStamp));\n+    }\n+\n+    /**\n+     * Helper for system metrics emitter. Also used in tests.\n+     */\n+    public void emitPeriodicSystemMetrics() {\n+        this.systemMetricsEmitter.emitMetrics();\n+    }\n+\n+    private Topic getPeriodicPublishTimeTopic() {\n+        return config.lookup(TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC).dflt(Instant.now().toEpochMilli())\n+                .subscribe((why, newv) -> lastPeriodicAggregationMetricsTime = Coerce.toLong(newv));\n+    }\n+\n+    private Topic getPeriodicAggregateTimeTopic() {\n+        return config.lookup(TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC).dflt(Instant.now().toEpochMilli());\n+    }\n+\n+    private void updateThingNameAndPublishTopic(String newThingName) {\n+        if (newThingName != null) {\n+            thingName = newThingName;\n+            updateTopic = telemetryMetricsPublishTopic.replace(\"{thingName}\", thingName);\n+            this.publisher.setUpdateTopic(updateTopic);\n+        }\n+    }\n+\n+    @Override\n+    public void startup() throws InterruptedException {\n+        super.startup();\n+        topics.lookup(PARAMETERS_CONFIG_KEY, TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC)\n+                .dflt(DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC)\n+                .subscribe((why, newv) -> {\n+                    periodicAggregateMetricsIntervalSec = Coerce.toInt(newv);\n+                    if (periodicAggregateMetricsFuture != null) {\n+                        schedulePeriodicAggregateMetrics(true);\n+                    }\n+                });\n+        topics.lookup(PARAMETERS_CONFIG_KEY, TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC)\n+                .dflt(DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC)\n+                .subscribe((why, newv) -> {\n+                    periodicPublishMetricsIntervalSec = Coerce.toInt(newv);\n+                    if (periodicPublishMetricsFuture != null) {\n+                        schedulePeriodicPublishMetrics(true);\n+                    }\n+                });\n+        topics.lookup(PARAMETERS_CONFIG_KEY, TELEMETRY_METRICS_PUBLISH_TOPICS)\n+                .dflt(DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f"}, "originalPosition": 213}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0NjY5Mg==", "bodyText": "Same issue", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485046692", "createdAt": "2020-09-08T16:24:14Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,152 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.dependency.Context;\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.aggregation.AggregatedMetric;\n+import com.aws.iot.evergreen.telemetry.config.TelemetryDataConfig;\n+import com.aws.iot.evergreen.telemetry.impl.MetricDataPoint;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.telemetryDataConfigMap;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+\n+    /**\n+     * Aggregate metrics based on the telemetry config.\n+     * @param context use this to schedule thread pool.\n+     */\n+    public void aggregateMetrics(Context context) {\n+        // TODO read from a telemetry config file.\n+        for (Map.Entry<String, TelemetryDataConfig> config: telemetryDataConfigMap.entrySet()) {\n+            TelemetryDataConfig metricConfig = config.getValue();\n+            ScheduledExecutorService executor = context.get(ScheduledExecutorService.class);\n+            executor.scheduleAtFixedRate(readLogsAndAggregate(metricConfig), 0, metricConfig.getAggregateFrequency(),\n+                    TimeUnit.MILLISECONDS);\n+        }\n+    }\n+\n+    private Runnable readLogsAndAggregate(TelemetryDataConfig config) {\n+        return () -> {\n+            long currentTimestamp = Instant.now().toEpochMilli();\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<MetricDataPoint>> metrics = new HashMap<>();\n+\n+            try {\n+                Stream<Path> paths = Files\n+                        .walk(Paths.get(System.getProperty(\"user.dir\") + \"/Telemetry/\"))\n+                        .filter(Files::isRegularFile);\n+                paths.forEach((path) -> {\n+                    /*\n+                     Read from the file at Telemetry/namespace*.log\n+                     Read only modified files and aggregate only new values based on the last aggregated time.\n+                     */\n+                    Object fileName = null;\n+                    if (path != null) {\n+                        fileName = path.getFileName();\n+                    }\n+                    if (fileName == null) {\n+                        fileName = \"\";\n+                    }\n+                    if (path != null\n+                            && path.getFileName() != null\n+                            && path.getFileName().toString().matches(config.getMetricNamespace() + \"(.*)\")\n+                            && currentTimestamp - new File(path.toString()).lastModified()\n+                            <= config.getAggregateFrequency()) {\n+                        try {\n+                            for (String log :\n+                                    Files.lines(Paths.get(path.toString())).collect(Collectors.toList())) {\n+                                /*\n+                                [0]  [1] [2]        [3]          [4]         [5]             [6]\n+                                2020 Aug 28 12:08:21,520-0700 [TRACE] (pool-3-thread-4) Metrics-KernelComponents:\n+\n+                                [7]\n+                                {\"M\":{\"NS\": \"KernelComponents\",\"N\":\"NumberOfComponentsStopping\",\"U\":\"Count\"},\n+                                \"V\":0,\"TS\":1598598501520}. {}\n+                                 */\n+                                MetricDataPoint mdp = new ObjectMapper()\n+                                        .readValue(log.split(\" \")[7], MetricDataPoint.class);\n+                                if (currentTimestamp - mdp.getTimestamp() <= config.getAggregateFrequency()) {\n+                                    metrics.computeIfAbsent(mdp.getMetric().getMetricName(),\n+                                            k -> new ArrayList<>()).add(mdp);\n+                                }\n+                            }\n+                        } catch (IOException e) {\n+                            logger.atError().log(e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM3MzcxNw=="}, "originalCommit": {"oid": "044114b548f4eb239cb00d856aedbde52f3984bb"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0Njc4Mw==", "bodyText": "Still here", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485046783", "createdAt": "2020-09-08T16:24:23Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,152 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.dependency.Context;\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.aggregation.AggregatedMetric;\n+import com.aws.iot.evergreen.telemetry.config.TelemetryDataConfig;\n+import com.aws.iot.evergreen.telemetry.impl.MetricDataPoint;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.TimeUnit;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.telemetryDataConfigMap;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+\n+    /**\n+     * Aggregate metrics based on the telemetry config.\n+     * @param context use this to schedule thread pool.\n+     */\n+    public void aggregateMetrics(Context context) {\n+        // TODO read from a telemetry config file.\n+        for (Map.Entry<String, TelemetryDataConfig> config: telemetryDataConfigMap.entrySet()) {\n+            TelemetryDataConfig metricConfig = config.getValue();\n+            ScheduledExecutorService executor = context.get(ScheduledExecutorService.class);\n+            executor.scheduleAtFixedRate(readLogsAndAggregate(metricConfig), 0, metricConfig.getAggregateFrequency(),\n+                    TimeUnit.MILLISECONDS);\n+        }\n+    }\n+\n+    private Runnable readLogsAndAggregate(TelemetryDataConfig config) {\n+        return () -> {\n+            long currentTimestamp = Instant.now().toEpochMilli();\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<MetricDataPoint>> metrics = new HashMap<>();\n+\n+            try {\n+                Stream<Path> paths = Files\n+                        .walk(Paths.get(System.getProperty(\"user.dir\") + \"/Telemetry/\"))\n+                        .filter(Files::isRegularFile);\n+                paths.forEach((path) -> {\n+                    /*\n+                     Read from the file at Telemetry/namespace*.log\n+                     Read only modified files and aggregate only new values based on the last aggregated time.\n+                     */\n+                    Object fileName = null;\n+                    if (path != null) {\n+                        fileName = path.getFileName();\n+                    }\n+                    if (fileName == null) {\n+                        fileName = \"\";\n+                    }\n+                    if (path != null\n+                            && path.getFileName() != null\n+                            && path.getFileName().toString().matches(config.getMetricNamespace() + \"(.*)\")\n+                            && currentTimestamp - new File(path.toString()).lastModified()\n+                            <= config.getAggregateFrequency()) {\n+                        try {\n+                            for (String log :\n+                                    Files.lines(Paths.get(path.toString())).collect(Collectors.toList())) {\n+                                /*\n+                                [0]  [1] [2]        [3]          [4]         [5]             [6]\n+                                2020 Aug 28 12:08:21,520-0700 [TRACE] (pool-3-thread-4) Metrics-KernelComponents:\n+\n+                                [7]\n+                                {\"M\":{\"NS\": \"KernelComponents\",\"N\":\"NumberOfComponentsStopping\",\"U\":\"Count\"},\n+                                \"V\":0,\"TS\":1598598501520}. {}\n+                                 */\n+                                MetricDataPoint mdp = new ObjectMapper()\n+                                        .readValue(log.split(\" \")[7], MetricDataPoint.class);\n+                                if (currentTimestamp - mdp.getTimestamp() <= config.getAggregateFrequency()) {\n+                                    metrics.computeIfAbsent(mdp.getMetric().getMetricName(),\n+                                            k -> new ArrayList<>()).add(mdp);\n+                                }\n+                            }\n+                        } catch (IOException e) {\n+                            logger.atError().log(e);\n+                        }\n+                    }\n+\n+                });\n+                aggMetrics.setMetricNamespace(TelemetryNamespace.valueOf(config.getMetricNamespace()));\n+                aggMetrics.setTimestamp(currentTimestamp);\n+                aggMetrics.setMetric(doAggregation(metrics, TelemetryAggregation.valueOf(config.getAggregationType())));\n+                /*\n+                    Writing to memory for now. But write to a file?\n+                 */\n+                logger.atInfo().log(new ObjectMapper().writeValueAsString(aggMetrics));\n+            } catch (IOException e) {\n+                logger.atError().log(e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDM3Mzc2MQ=="}, "originalCommit": {"oid": "044114b548f4eb239cb00d856aedbde52f3984bb"}, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0NzU0Mw==", "bodyText": "why Object? It looks like it always ends up as a double", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485047543", "createdAt": "2020-09-08T16:25:34Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,196 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.MetricDataPoint;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.text.NumberFormat;\n+import java.text.ParseException;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+public class MetricsAggregator {\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private static final int MILLI_SECONDS = 1000;\n+    MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+\n+    /**\n+     * This method stores the aggregated data points of the metrics emitted over the interval.\n+     *\n+     * @param aggregationIntervalSec periodic interval in seconds for the aggregating the metrics\n+     * @param currentTimestamp timestamp at which the aggregate is initiated\n+     */\n+    public void aggregateMetrics(int aggregationIntervalSec, long currentTimestamp) {\n+        int aggregationIntervalMilliSec = aggregationIntervalSec * MILLI_SECONDS;\n+        for (TelemetryNamespace namespace : TelemetryNamespace.values()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<MetricDataPoint>> metrics = new HashMap<>();\n+            try {\n+                Stream<Path> paths = Files\n+                        .walk(MetricFactory.getTelemetryDirectory())\n+                        .filter(Files::isRegularFile)\n+                        .filter(path -> {\n+                            Object fileName = null;\n+                            if (path != null) {\n+                                fileName = path.getFileName();\n+                            }\n+                            if (fileName == null) {\n+                                fileName = \"\";\n+                            }\n+                            return fileName.toString().startsWith(namespace.toString());\n+                        });\n+                paths.forEach((path) -> {\n+                    /*\n+                     Read from the file at Telemetry/namespace*.log\n+                     Read only modified files and aggregate only new values based on the last aggregated time.\n+                     */\n+                    if (currentTimestamp - new File(path.toString()).lastModified() <= aggregationIntervalMilliSec) {\n+                        try {\n+                            for (String log :\n+                                    Files.lines(Paths.get(path.toString())).collect(Collectors.toList())) {\n+                                /*\n+                                [0]  [1] [2]        [3]          [4]         [5]             [6]\n+                                2020 Aug 28 12:08:21,520-0700 [TRACE] (pool-3-thread-4) Metrics-KernelComponents:\n+\n+                                [7]\n+                                {\"M\":{\"NS\": \"KernelComponents\",\"N\":\"NumberOfComponentsStopping\",\"U\":\"Count\"},\n+                                \"V\":0,\"TS\":1598598501520}. {}\n+                                 */\n+                                MetricDataPoint mdp = new ObjectMapper()\n+                                        .readValue(log.split(\" \")[7], MetricDataPoint.class);\n+                                if (mdp.getMetric() != null\n+                                        && currentTimestamp - mdp.getTimestamp() <= aggregationIntervalMilliSec) {\n+                                        metrics.computeIfAbsent(mdp.getMetric().getMetricName(),\n+                                                k -> new ArrayList<>()).add(mdp);\n+                                }\n+                            }\n+                        } catch (IOException e) {\n+                            logger.atError().log(e);\n+                        }\n+                    }\n+                });\n+                aggMetrics.setMetricNamespace(namespace);\n+                aggMetrics.setTimestamp(currentTimestamp);\n+                aggMetrics.setMetrics(doAggregation(metrics));\n+                metricFactory.logMetrics(new TelemetryLoggerMessage(aggMetrics));\n+            } catch (IOException e) {\n+                logger.atError().log(e);\n+            }\n+        }\n+    }\n+\n+    private List<Metric> doAggregation(Map<TelemetryMetricName, List<MetricDataPoint>> metrics) {\n+        List<Metric> aggMetrics = new ArrayList<>();\n+        for (Map.Entry<TelemetryMetricName, List<MetricDataPoint>> metric : metrics.entrySet()) {\n+            TelemetryMetricName metricName = metric.getKey();\n+            List<MetricDataPoint> mdp = metric.getValue();\n+            TelemetryAggregation telemetryAggregation = mdp.get(0).getMetric().getMetricAggregation();\n+            Object aggregation = 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f"}, "originalPosition": 111}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0NzkzNg==", "bodyText": "why are these classes necessary? Why not use the classes in the logger SDK?", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485047936", "createdAt": "2020-09-08T16:26:10Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,196 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.MetricDataPoint;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.text.NumberFormat;\n+import java.text.ParseException;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+public class MetricsAggregator {\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private static final int MILLI_SECONDS = 1000;\n+    MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+\n+    /**\n+     * This method stores the aggregated data points of the metrics emitted over the interval.\n+     *\n+     * @param aggregationIntervalSec periodic interval in seconds for the aggregating the metrics\n+     * @param currentTimestamp timestamp at which the aggregate is initiated\n+     */\n+    public void aggregateMetrics(int aggregationIntervalSec, long currentTimestamp) {\n+        int aggregationIntervalMilliSec = aggregationIntervalSec * MILLI_SECONDS;\n+        for (TelemetryNamespace namespace : TelemetryNamespace.values()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<MetricDataPoint>> metrics = new HashMap<>();\n+            try {\n+                Stream<Path> paths = Files\n+                        .walk(MetricFactory.getTelemetryDirectory())\n+                        .filter(Files::isRegularFile)\n+                        .filter(path -> {\n+                            Object fileName = null;\n+                            if (path != null) {\n+                                fileName = path.getFileName();\n+                            }\n+                            if (fileName == null) {\n+                                fileName = \"\";\n+                            }\n+                            return fileName.toString().startsWith(namespace.toString());\n+                        });\n+                paths.forEach((path) -> {\n+                    /*\n+                     Read from the file at Telemetry/namespace*.log\n+                     Read only modified files and aggregate only new values based on the last aggregated time.\n+                     */\n+                    if (currentTimestamp - new File(path.toString()).lastModified() <= aggregationIntervalMilliSec) {\n+                        try {\n+                            for (String log :\n+                                    Files.lines(Paths.get(path.toString())).collect(Collectors.toList())) {\n+                                /*\n+                                [0]  [1] [2]        [3]          [4]         [5]             [6]\n+                                2020 Aug 28 12:08:21,520-0700 [TRACE] (pool-3-thread-4) Metrics-KernelComponents:\n+\n+                                [7]\n+                                {\"M\":{\"NS\": \"KernelComponents\",\"N\":\"NumberOfComponentsStopping\",\"U\":\"Count\"},\n+                                \"V\":0,\"TS\":1598598501520}. {}\n+                                 */\n+                                MetricDataPoint mdp = new ObjectMapper()\n+                                        .readValue(log.split(\" \")[7], MetricDataPoint.class);\n+                                if (mdp.getMetric() != null\n+                                        && currentTimestamp - mdp.getTimestamp() <= aggregationIntervalMilliSec) {\n+                                        metrics.computeIfAbsent(mdp.getMetric().getMetricName(),\n+                                                k -> new ArrayList<>()).add(mdp);\n+                                }\n+                            }\n+                        } catch (IOException e) {\n+                            logger.atError().log(e);\n+                        }\n+                    }\n+                });\n+                aggMetrics.setMetricNamespace(namespace);\n+                aggMetrics.setTimestamp(currentTimestamp);\n+                aggMetrics.setMetrics(doAggregation(metrics));\n+                metricFactory.logMetrics(new TelemetryLoggerMessage(aggMetrics));\n+            } catch (IOException e) {\n+                logger.atError().log(e);\n+            }\n+        }\n+    }\n+\n+    private List<Metric> doAggregation(Map<TelemetryMetricName, List<MetricDataPoint>> metrics) {\n+        List<Metric> aggMetrics = new ArrayList<>();\n+        for (Map.Entry<TelemetryMetricName, List<MetricDataPoint>> metric : metrics.entrySet()) {\n+            TelemetryMetricName metricName = metric.getKey();\n+            List<MetricDataPoint> mdp = metric.getValue();\n+            TelemetryAggregation telemetryAggregation = mdp.get(0).getMetric().getMetricAggregation();\n+            Object aggregation = 0;\n+            if (telemetryAggregation.equals(TelemetryAggregation.Average)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> format(a.getValue()))\n+                        .sum();\n+                if (!mdp.isEmpty()) {\n+                    aggregation = (double) aggregation / mdp.size();\n+                }\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Sum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> format(a.getValue()))\n+                        .sum();\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Maximum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> format(a.getValue()))\n+                        .max()\n+                        .getAsDouble();\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Minimum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> format(a.getValue()))\n+                        .min()\n+                        .getAsDouble();\n+            }\n+\n+            Metric m = Metric.builder()\n+                    .metricName(metricName)\n+                    .metricUnit(mdp.get(0).getMetric().getMetricUnit())\n+                    .value(aggregation)\n+                    .build();\n+            aggMetrics.add(m);\n+        }\n+        return aggMetrics;\n+    }\n+\n+    @Data\n+    @Builder\n+    @NoArgsConstructor\n+    @AllArgsConstructor\n+    public static class AggregatedMetric {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f"}, "originalPosition": 157}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0ODMxMA==", "bodyText": "Do not use concatenation. .log(\"...\", e)", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485048310", "createdAt": "2020-09-08T16:26:45Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,196 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.MetricDataPoint;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.text.NumberFormat;\n+import java.text.ParseException;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+public class MetricsAggregator {\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private static final int MILLI_SECONDS = 1000;\n+    MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+\n+    /**\n+     * This method stores the aggregated data points of the metrics emitted over the interval.\n+     *\n+     * @param aggregationIntervalSec periodic interval in seconds for the aggregating the metrics\n+     * @param currentTimestamp timestamp at which the aggregate is initiated\n+     */\n+    public void aggregateMetrics(int aggregationIntervalSec, long currentTimestamp) {\n+        int aggregationIntervalMilliSec = aggregationIntervalSec * MILLI_SECONDS;\n+        for (TelemetryNamespace namespace : TelemetryNamespace.values()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<MetricDataPoint>> metrics = new HashMap<>();\n+            try {\n+                Stream<Path> paths = Files\n+                        .walk(MetricFactory.getTelemetryDirectory())\n+                        .filter(Files::isRegularFile)\n+                        .filter(path -> {\n+                            Object fileName = null;\n+                            if (path != null) {\n+                                fileName = path.getFileName();\n+                            }\n+                            if (fileName == null) {\n+                                fileName = \"\";\n+                            }\n+                            return fileName.toString().startsWith(namespace.toString());\n+                        });\n+                paths.forEach((path) -> {\n+                    /*\n+                     Read from the file at Telemetry/namespace*.log\n+                     Read only modified files and aggregate only new values based on the last aggregated time.\n+                     */\n+                    if (currentTimestamp - new File(path.toString()).lastModified() <= aggregationIntervalMilliSec) {\n+                        try {\n+                            for (String log :\n+                                    Files.lines(Paths.get(path.toString())).collect(Collectors.toList())) {\n+                                /*\n+                                [0]  [1] [2]        [3]          [4]         [5]             [6]\n+                                2020 Aug 28 12:08:21,520-0700 [TRACE] (pool-3-thread-4) Metrics-KernelComponents:\n+\n+                                [7]\n+                                {\"M\":{\"NS\": \"KernelComponents\",\"N\":\"NumberOfComponentsStopping\",\"U\":\"Count\"},\n+                                \"V\":0,\"TS\":1598598501520}. {}\n+                                 */\n+                                MetricDataPoint mdp = new ObjectMapper()\n+                                        .readValue(log.split(\" \")[7], MetricDataPoint.class);\n+                                if (mdp.getMetric() != null\n+                                        && currentTimestamp - mdp.getTimestamp() <= aggregationIntervalMilliSec) {\n+                                        metrics.computeIfAbsent(mdp.getMetric().getMetricName(),\n+                                                k -> new ArrayList<>()).add(mdp);\n+                                }\n+                            }\n+                        } catch (IOException e) {\n+                            logger.atError().log(e);\n+                        }\n+                    }\n+                });\n+                aggMetrics.setMetricNamespace(namespace);\n+                aggMetrics.setTimestamp(currentTimestamp);\n+                aggMetrics.setMetrics(doAggregation(metrics));\n+                metricFactory.logMetrics(new TelemetryLoggerMessage(aggMetrics));\n+            } catch (IOException e) {\n+                logger.atError().log(e);\n+            }\n+        }\n+    }\n+\n+    private List<Metric> doAggregation(Map<TelemetryMetricName, List<MetricDataPoint>> metrics) {\n+        List<Metric> aggMetrics = new ArrayList<>();\n+        for (Map.Entry<TelemetryMetricName, List<MetricDataPoint>> metric : metrics.entrySet()) {\n+            TelemetryMetricName metricName = metric.getKey();\n+            List<MetricDataPoint> mdp = metric.getValue();\n+            TelemetryAggregation telemetryAggregation = mdp.get(0).getMetric().getMetricAggregation();\n+            Object aggregation = 0;\n+            if (telemetryAggregation.equals(TelemetryAggregation.Average)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> format(a.getValue()))\n+                        .sum();\n+                if (!mdp.isEmpty()) {\n+                    aggregation = (double) aggregation / mdp.size();\n+                }\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Sum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> format(a.getValue()))\n+                        .sum();\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Maximum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> format(a.getValue()))\n+                        .max()\n+                        .getAsDouble();\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Minimum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> format(a.getValue()))\n+                        .min()\n+                        .getAsDouble();\n+            }\n+\n+            Metric m = Metric.builder()\n+                    .metricName(metricName)\n+                    .metricUnit(mdp.get(0).getMetric().getMetricUnit())\n+                    .value(aggregation)\n+                    .build();\n+            aggMetrics.add(m);\n+        }\n+        return aggMetrics;\n+    }\n+\n+    @Data\n+    @Builder\n+    @NoArgsConstructor\n+    @AllArgsConstructor\n+    public static class AggregatedMetric {\n+        @JsonProperty(\"TS\")\n+        private Long timestamp;\n+        @JsonProperty(\"NS\")\n+        private TelemetryNamespace metricNamespace;\n+        @JsonProperty(\"M\")\n+        private List<Metric> metrics;\n+    }\n+\n+    @Data\n+    @NoArgsConstructor\n+    @AllArgsConstructor\n+    @Builder\n+    public static class Metric {\n+        @JsonProperty(\"N\")\n+        private TelemetryMetricName metricName;\n+        @JsonProperty(\"V\")\n+        private Object value;\n+        @JsonProperty(\"U\")\n+        private TelemetryUnit metricUnit;\n+    }\n+\n+    /**\n+     * Helper function to process the value of the metric object during aggregation.\n+     * @param value metric data point value.\n+     * @return converted value of the object to double. Returns 0 if invalid.\n+     */\n+    public double format(Object value) {\n+        double val = 0;\n+        if (value != null) {\n+            try {\n+                 val = NumberFormat.getInstance().parse(value.toString()).doubleValue();\n+                return val;\n+            } catch (ParseException e) {\n+                logger.atError().log(\"Error parsing the metric value: \" + e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f"}, "originalPosition": 191}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0OTM5Nw==", "bodyText": "we should not be handling text-mode logs here at all. Metrics should always be JSON, and I have no problem forcing that.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485049397", "createdAt": "2020-09-08T16:28:33Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsUploader.java", "diffHunk": "@@ -0,0 +1,90 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static com.aws.iot.evergreen.telemetry.MetricsAggregator.AGGREGATE_METRICS_FILE;\n+\n+public class MetricsUploader {\n+    public static final Logger logger = LogManager.getLogger(MetricsUploader.class);\n+    private static final int MILLI_SECONDS = 1000;\n+\n+    /**\n+     * This function returns the set of all the aggregated metric data points that are to be published to the cloud\n+     * since the last upload.\n+     *\n+     * @param uploadIntervalSec periodic interval in seconds for the publishing the metrics\n+     * @param currentTimestamp timestamp at which the publish is initiated\n+     */\n+    public Map<Long,List<MetricsAggregator.AggregatedMetric>>\n+    getAggregatedMetrics(int uploadIntervalSec, long currentTimestamp) {\n+        int uploadIntervalMilliSec = uploadIntervalSec * MILLI_SECONDS;\n+        Map<Long,List<MetricsAggregator.AggregatedMetric>> aggUploadMetrics = new HashMap<>();\n+        MetricsAggregator.AggregatedMetric am;\n+        try {\n+            List<Path> paths = Files\n+                    .walk(MetricFactory.getTelemetryDirectory())\n+                    .filter(Files::isRegularFile)\n+                    .filter((path) -> {\n+                        Object fileName = null;\n+                        if (path != null) {\n+                            fileName = path.getFileName();\n+                        }\n+                        if (fileName == null) {\n+                            fileName = \"\";\n+                        }\n+                        return fileName.toString().startsWith(AGGREGATE_METRICS_FILE);\n+                    }).collect(Collectors.toList());\n+            for (Path path :paths) {\n+                /*\n+                 Read AggregatedMetrics file from the file at Telemetry.\n+                 Read only modified files and publish only new values based on the timestamp.\n+                 */\n+                if (currentTimestamp - new File(path.toString()).lastModified() <= uploadIntervalMilliSec) {\n+                    List<String> logs = Files.lines(Paths.get(path.toString())).collect(Collectors.toList());\n+                    for (String log : logs) {\n+                        try {\n+                            /*\n+                            [0]  [1] [2]        [3]          [4]         [5]             [6]\n+                            2020 Aug 28 12:08:21,520-0700 [TRACE] (pool-3-thread-4) Metrics-KernelComponents:\n+\n+                            [7]\n+                            {\"TS\":1599256194930,\"NS\":\"SystemMetrics\",\"M\":[{\n+                            \"N\":\"TotalNumberOfFDs\",\"V\":5000.0,\"U\":\"Count\"},\n+                            {\"N\":\"CpuUsage\",\"V\":20.0,\"U\":\"Percent\"},\n+                            {\"N\":\"SystemMemUsage\",\"V\":3000.0,\"U\":\"Megabytes\"}]}. {}\n+\n+                             */\n+                            am = new ObjectMapper()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f"}, "originalPosition": 73}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0OTU5OQ==", "bodyText": "No concatentation. Use the logger properly to log out exceptions", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485049599", "createdAt": "2020-09-08T16:28:55Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsUploader.java", "diffHunk": "@@ -0,0 +1,90 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static com.aws.iot.evergreen.telemetry.MetricsAggregator.AGGREGATE_METRICS_FILE;\n+\n+public class MetricsUploader {\n+    public static final Logger logger = LogManager.getLogger(MetricsUploader.class);\n+    private static final int MILLI_SECONDS = 1000;\n+\n+    /**\n+     * This function returns the set of all the aggregated metric data points that are to be published to the cloud\n+     * since the last upload.\n+     *\n+     * @param uploadIntervalSec periodic interval in seconds for the publishing the metrics\n+     * @param currentTimestamp timestamp at which the publish is initiated\n+     */\n+    public Map<Long,List<MetricsAggregator.AggregatedMetric>>\n+    getAggregatedMetrics(int uploadIntervalSec, long currentTimestamp) {\n+        int uploadIntervalMilliSec = uploadIntervalSec * MILLI_SECONDS;\n+        Map<Long,List<MetricsAggregator.AggregatedMetric>> aggUploadMetrics = new HashMap<>();\n+        MetricsAggregator.AggregatedMetric am;\n+        try {\n+            List<Path> paths = Files\n+                    .walk(MetricFactory.getTelemetryDirectory())\n+                    .filter(Files::isRegularFile)\n+                    .filter((path) -> {\n+                        Object fileName = null;\n+                        if (path != null) {\n+                            fileName = path.getFileName();\n+                        }\n+                        if (fileName == null) {\n+                            fileName = \"\";\n+                        }\n+                        return fileName.toString().startsWith(AGGREGATE_METRICS_FILE);\n+                    }).collect(Collectors.toList());\n+            for (Path path :paths) {\n+                /*\n+                 Read AggregatedMetrics file from the file at Telemetry.\n+                 Read only modified files and publish only new values based on the timestamp.\n+                 */\n+                if (currentTimestamp - new File(path.toString()).lastModified() <= uploadIntervalMilliSec) {\n+                    List<String> logs = Files.lines(Paths.get(path.toString())).collect(Collectors.toList());\n+                    for (String log : logs) {\n+                        try {\n+                            /*\n+                            [0]  [1] [2]        [3]          [4]         [5]             [6]\n+                            2020 Aug 28 12:08:21,520-0700 [TRACE] (pool-3-thread-4) Metrics-KernelComponents:\n+\n+                            [7]\n+                            {\"TS\":1599256194930,\"NS\":\"SystemMetrics\",\"M\":[{\n+                            \"N\":\"TotalNumberOfFDs\",\"V\":5000.0,\"U\":\"Count\"},\n+                            {\"N\":\"CpuUsage\",\"V\":20.0,\"U\":\"Percent\"},\n+                            {\"N\":\"SystemMemUsage\",\"V\":3000.0,\"U\":\"Megabytes\"}]}. {}\n+\n+                             */\n+                            am = new ObjectMapper()\n+                                    .readValue(log.split(\" \")[7], MetricsAggregator.AggregatedMetric.class);\n+                            if (am != null && currentTimestamp - am.getTimestamp() <= uploadIntervalMilliSec) {\n+                                aggUploadMetrics.computeIfAbsent(currentTimestamp, k -> new ArrayList<>()).add(am);\n+                            }\n+                        } catch (MismatchedInputException mis) {\n+                            logger.atError().log(\"Unable to parse the aggregated metric log: \" + mis);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0OTY2NQ==", "bodyText": "add context to the message", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485049665", "createdAt": "2020-09-08T16:29:02Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsUploader.java", "diffHunk": "@@ -0,0 +1,90 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static com.aws.iot.evergreen.telemetry.MetricsAggregator.AGGREGATE_METRICS_FILE;\n+\n+public class MetricsUploader {\n+    public static final Logger logger = LogManager.getLogger(MetricsUploader.class);\n+    private static final int MILLI_SECONDS = 1000;\n+\n+    /**\n+     * This function returns the set of all the aggregated metric data points that are to be published to the cloud\n+     * since the last upload.\n+     *\n+     * @param uploadIntervalSec periodic interval in seconds for the publishing the metrics\n+     * @param currentTimestamp timestamp at which the publish is initiated\n+     */\n+    public Map<Long,List<MetricsAggregator.AggregatedMetric>>\n+    getAggregatedMetrics(int uploadIntervalSec, long currentTimestamp) {\n+        int uploadIntervalMilliSec = uploadIntervalSec * MILLI_SECONDS;\n+        Map<Long,List<MetricsAggregator.AggregatedMetric>> aggUploadMetrics = new HashMap<>();\n+        MetricsAggregator.AggregatedMetric am;\n+        try {\n+            List<Path> paths = Files\n+                    .walk(MetricFactory.getTelemetryDirectory())\n+                    .filter(Files::isRegularFile)\n+                    .filter((path) -> {\n+                        Object fileName = null;\n+                        if (path != null) {\n+                            fileName = path.getFileName();\n+                        }\n+                        if (fileName == null) {\n+                            fileName = \"\";\n+                        }\n+                        return fileName.toString().startsWith(AGGREGATE_METRICS_FILE);\n+                    }).collect(Collectors.toList());\n+            for (Path path :paths) {\n+                /*\n+                 Read AggregatedMetrics file from the file at Telemetry.\n+                 Read only modified files and publish only new values based on the timestamp.\n+                 */\n+                if (currentTimestamp - new File(path.toString()).lastModified() <= uploadIntervalMilliSec) {\n+                    List<String> logs = Files.lines(Paths.get(path.toString())).collect(Collectors.toList());\n+                    for (String log : logs) {\n+                        try {\n+                            /*\n+                            [0]  [1] [2]        [3]          [4]         [5]             [6]\n+                            2020 Aug 28 12:08:21,520-0700 [TRACE] (pool-3-thread-4) Metrics-KernelComponents:\n+\n+                            [7]\n+                            {\"TS\":1599256194930,\"NS\":\"SystemMetrics\",\"M\":[{\n+                            \"N\":\"TotalNumberOfFDs\",\"V\":5000.0,\"U\":\"Count\"},\n+                            {\"N\":\"CpuUsage\",\"V\":20.0,\"U\":\"Percent\"},\n+                            {\"N\":\"SystemMemUsage\",\"V\":3000.0,\"U\":\"Megabytes\"}]}. {}\n+\n+                             */\n+                            am = new ObjectMapper()\n+                                    .readValue(log.split(\" \")[7], MetricsAggregator.AggregatedMetric.class);\n+                            if (am != null && currentTimestamp - am.getTimestamp() <= uploadIntervalMilliSec) {\n+                                aggUploadMetrics.computeIfAbsent(currentTimestamp, k -> new ArrayList<>()).add(am);\n+                            }\n+                        } catch (MismatchedInputException mis) {\n+                            logger.atError().log(\"Unable to parse the aggregated metric log: \" + mis);\n+                        }\n+                    }\n+                }\n+            }\n+        } catch (IOException e) {\n+            logger.atError().log(e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA1MDA3NQ==", "bodyText": "do you need a new factory for all of these? Couldn't it be saved and reused?", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485050075", "createdAt": "2020-09-08T16:29:44Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/SystemMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,81 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import oshi.SystemInfo;\n+import oshi.hardware.CentralProcessor;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+public class SystemMetricsEmitter {\n+    private static final int MB_CONVERTER = 1024 * 1024;\n+    private static final int PERCENTAGE_CONVERTER = 100;\n+    private static String SYSTEM_METRICS_STORE = TelemetryNamespace.SystemMetrics.toString();\n+    private static CentralProcessor cpu = new SystemInfo().getHardware().getProcessor();\n+    private static SystemInfo systemInfo = new SystemInfo();\n+    private static long[] previousTicks = new long[CentralProcessor.TickType.values().length];\n+    private static Map<TelemetryMetricName, Object> systemMetricsData = new HashMap<>();\n+    private static Map<TelemetryMetricName, MetricDataBuilder> systemMetrics = new HashMap<>();\n+\n+    /**\n+     * Create system metrics.\n+     */\n+    protected void collectSystemMetrics() {\n+        Metric systemMetric = Metric.builder()\n+                .metricNamespace(TelemetryNamespace.SystemMetrics)\n+                .metricName(TelemetryMetricName.CpuUsage)\n+                .metricUnit(TelemetryUnit.Percent)\n+                .metricAggregation(TelemetryAggregation.Average)\n+                .build();\n+        MetricDataBuilder mdb = new MetricFactory(SYSTEM_METRICS_STORE).addMetric(systemMetric);\n+        systemMetrics.put(TelemetryMetricName.CpuUsage, mdb);\n+\n+        systemMetric = Metric.builder()\n+                .metricNamespace(TelemetryNamespace.SystemMetrics)\n+                .metricName(TelemetryMetricName.TotalNumberOfFDs)\n+                .metricUnit(TelemetryUnit.Count)\n+                .metricAggregation(TelemetryAggregation.Average)\n+                .build();\n+        mdb = new MetricFactory(SYSTEM_METRICS_STORE).addMetric(systemMetric);\n+        systemMetrics.put(TelemetryMetricName.TotalNumberOfFDs, mdb);\n+\n+        systemMetric = Metric.builder()\n+                .metricNamespace(TelemetryNamespace.SystemMetrics)\n+                .metricName(TelemetryMetricName.SystemMemUsage)\n+                .metricUnit(TelemetryUnit.Megabytes)\n+                .metricAggregation(TelemetryAggregation.Average)\n+                .build();\n+        mdb = new MetricFactory(SYSTEM_METRICS_STORE).addMetric(systemMetric);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA1MDc1Mg==", "bodyText": "No concatenation (especially without a space). Use KV to add a key-value pair .kv(\"topic\", updateTopic)", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485050752", "createdAt": "2020-09-08T16:30:46Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/util/MqttChunkedPayloadPublisher.java", "diffHunk": "@@ -52,11 +52,11 @@ public void publish(Chunkable<T> chunkablePayload, List<T> variablePayloads) {\n                         start + chunkingInformation.getNumberOfComponentsPerPublish()));\n                 this.mqttClient.publish(PublishRequest.builder()\n                         .qos(QualityOfService.AT_LEAST_ONCE)\n-                        .topic(this.updateFssDataTopic)\n+                        .topic(this.updateTopic)\n                         .payload(SERIALIZER.writeValueAsBytes(chunkablePayload)).build());\n             }\n         } catch (JsonProcessingException e) {\n-            logger.atError().cause(e).log(\"Unable to publish fleet status service.\");\n+            logger.atError().cause(e).log(\"Unable to publish data via topic.\" + updateTopic);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f"}, "originalPosition": 19}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "04a2944bd0e65671d4a0b2db9f470ddf68d69acd", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/04a2944bd0e65671d4a0b2db9f470ddf68d69acd", "committedDate": "2020-09-09T20:27:50Z", "message": "Add telemetry metrics + tests + modify log statements"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg1MzgwNDM1", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-485380435", "createdAt": "2020-09-09T20:30:31Z", "commit": {"oid": "04a2944bd0e65671d4a0b2db9f470ddf68d69acd"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQyMDozMDozMVrOHPZNSQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQyMDozMDozMVrOHPZNSQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTkwMzY4OQ==", "bodyText": "use kernel.findServiceTopics", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485903689", "createdAt": "2020-09-09T20:30:31Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,135 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.MetricsAgent;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.util.Coerce;\n+import lombok.NonNull;\n+\n+import java.time.Instant;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.iot.evergreen.kernel.EvergreenService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.METRICS_AGENT_SERVICE_TOPICS;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+\n+public class KernelMetricsEmitter {\n+    // Kernel metrics\n+    public static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+    private static final String KERNEL_COMPONENT_METRIC_STORE = TelemetryNamespace.KernelComponents.toString();\n+    private static Map<TelemetryMetricName, MetricDataBuilder> kernelMetrics = new HashMap<>();\n+    private static Map<TelemetryMetricName, Integer> kernelMetricsData = new HashMap<>();\n+    private final Object periodicKernelMetricsInProgressLock = new Object();\n+    private final ScheduledExecutorService ses;\n+    @NonNull\n+    private final Kernel kernel;\n+    private ScheduledFuture<?> periodicKernelMetricsFuture = null;\n+    private int periodicKernelMetricsIntervalSec = 0;\n+\n+    /**\n+     * Constructor for kernel metrics emitter.\n+     *\n+     * @param kernel {@link Kernel}\n+     */\n+    public KernelMetricsEmitter(Kernel kernel) {\n+        this.kernel = kernel;\n+        this.ses = this.kernel.getContext().get(ScheduledExecutorService.class);\n+    }\n+\n+    /**\n+     * Schedules the periodic kernel metrics based on the configured aggregation interval.\n+     *\n+     * @param isReconfigured true if the interval is reconfigured\n+     */\n+    public void schedulePeriodicKernelMetrics(boolean isReconfigured) {\n+        // If the kernel/aggregation interval is reconfigured, cancel the previously scheduled job.\n+        if (this.periodicKernelMetricsFuture != null) {\n+            this.periodicKernelMetricsFuture.cancel(false);\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicKernelMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant\n+                        .ofEpochMilli(MetricsAgent.getLastPeriodicAggregationMetricsTime());\n+                if (lastPeriodicAggTime.plusSeconds(periodicKernelMetricsIntervalSec).isBefore(Instant.now())) {\n+                    this.emitKernelMetrics();\n+                }\n+            }\n+        }\n+        periodicKernelMetricsFuture = ses.scheduleWithFixedDelay(\n+                this::emitKernelMetrics, 0, periodicKernelMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Collect kernel metrics - Number of components running in each state.\n+     */\n+    protected void collectKernelComponentState() {\n+        List<TelemetryMetricName> telemetryMetricNames =\n+                TelemetryMetricName.getMetricNamesOf(TelemetryNamespace.KernelComponents);\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            Metric metric = Metric.builder()\n+                    .metricNamespace(TelemetryNamespace.KernelComponents)\n+                    .metricName(telemetryMetricName)\n+                    .metricUnit(TelemetryUnit.Count)\n+                    .metricAggregation(TelemetryAggregation.Average)\n+                    .build();\n+            MetricDataBuilder metricDataBuilder = new MetricFactory(KERNEL_COMPONENT_METRIC_STORE).addMetric(metric);\n+            kernelMetrics.put(telemetryMetricName, metricDataBuilder);\n+        }\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            kernelMetricsData.put(telemetryMetricName, 0);\n+        }\n+        /*\n+            Using lookup to create the MetricAgent service topics as this is called during the kernel launch\n+            before the service is created.\n+         */\n+        Topics metricTopics = kernel.getConfig().lookupTopics(SERVICES_NAMESPACE_TOPIC, METRICS_AGENT_SERVICE_TOPICS);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "04a2944bd0e65671d4a0b2db9f470ddf68d69acd"}, "originalPosition": 104}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg1MzgxMTU2", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-485381156", "createdAt": "2020-09-09T20:31:36Z", "commit": {"oid": "04a2944bd0e65671d4a0b2db9f470ddf68d69acd"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQyMDozMTozNlrOHPZPfQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQyMDozMTozNlrOHPZPfQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTkwNDI1Mw==", "bodyText": "These calls are a bit redundant because subscribe is immediately called with the initial value.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485904253", "createdAt": "2020-09-09T20:31:36Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,135 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.MetricsAgent;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.util.Coerce;\n+import lombok.NonNull;\n+\n+import java.time.Instant;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.iot.evergreen.kernel.EvergreenService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.METRICS_AGENT_SERVICE_TOPICS;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+\n+public class KernelMetricsEmitter {\n+    // Kernel metrics\n+    public static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+    private static final String KERNEL_COMPONENT_METRIC_STORE = TelemetryNamespace.KernelComponents.toString();\n+    private static Map<TelemetryMetricName, MetricDataBuilder> kernelMetrics = new HashMap<>();\n+    private static Map<TelemetryMetricName, Integer> kernelMetricsData = new HashMap<>();\n+    private final Object periodicKernelMetricsInProgressLock = new Object();\n+    private final ScheduledExecutorService ses;\n+    @NonNull\n+    private final Kernel kernel;\n+    private ScheduledFuture<?> periodicKernelMetricsFuture = null;\n+    private int periodicKernelMetricsIntervalSec = 0;\n+\n+    /**\n+     * Constructor for kernel metrics emitter.\n+     *\n+     * @param kernel {@link Kernel}\n+     */\n+    public KernelMetricsEmitter(Kernel kernel) {\n+        this.kernel = kernel;\n+        this.ses = this.kernel.getContext().get(ScheduledExecutorService.class);\n+    }\n+\n+    /**\n+     * Schedules the periodic kernel metrics based on the configured aggregation interval.\n+     *\n+     * @param isReconfigured true if the interval is reconfigured\n+     */\n+    public void schedulePeriodicKernelMetrics(boolean isReconfigured) {\n+        // If the kernel/aggregation interval is reconfigured, cancel the previously scheduled job.\n+        if (this.periodicKernelMetricsFuture != null) {\n+            this.periodicKernelMetricsFuture.cancel(false);\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicKernelMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant\n+                        .ofEpochMilli(MetricsAgent.getLastPeriodicAggregationMetricsTime());\n+                if (lastPeriodicAggTime.plusSeconds(periodicKernelMetricsIntervalSec).isBefore(Instant.now())) {\n+                    this.emitKernelMetrics();\n+                }\n+            }\n+        }\n+        periodicKernelMetricsFuture = ses.scheduleWithFixedDelay(\n+                this::emitKernelMetrics, 0, periodicKernelMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Collect kernel metrics - Number of components running in each state.\n+     */\n+    protected void collectKernelComponentState() {\n+        List<TelemetryMetricName> telemetryMetricNames =\n+                TelemetryMetricName.getMetricNamesOf(TelemetryNamespace.KernelComponents);\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            Metric metric = Metric.builder()\n+                    .metricNamespace(TelemetryNamespace.KernelComponents)\n+                    .metricName(telemetryMetricName)\n+                    .metricUnit(TelemetryUnit.Count)\n+                    .metricAggregation(TelemetryAggregation.Average)\n+                    .build();\n+            MetricDataBuilder metricDataBuilder = new MetricFactory(KERNEL_COMPONENT_METRIC_STORE).addMetric(metric);\n+            kernelMetrics.put(telemetryMetricName, metricDataBuilder);\n+        }\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            kernelMetricsData.put(telemetryMetricName, 0);\n+        }\n+        /*\n+            Using lookup to create the MetricAgent service topics as this is called during the kernel launch\n+            before the service is created.\n+         */\n+        Topics metricTopics = kernel.getConfig().lookupTopics(SERVICES_NAMESPACE_TOPIC, METRICS_AGENT_SERVICE_TOPICS);\n+        metricTopics.lookup(PARAMETERS_CONFIG_KEY, TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC)\n+                .dflt(DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC)\n+                .subscribe((why, newv) -> {\n+                    periodicKernelMetricsIntervalSec = Coerce.toInt(newv);\n+                    if (periodicKernelMetricsFuture != null) {\n+                        this.schedulePeriodicKernelMetrics(true);\n+                    }\n+                });\n+        this.schedulePeriodicKernelMetrics(false);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "04a2944bd0e65671d4a0b2db9f470ddf68d69acd"}, "originalPosition": 113}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg1MzgxMzU1", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-485381355", "createdAt": "2020-09-09T20:31:54Z", "commit": {"oid": "04a2944bd0e65671d4a0b2db9f470ddf68d69acd"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQyMDozMTo1NFrOHPZQJQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQyMDozMTo1NFrOHPZQJQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTkwNDQyMQ==", "bodyText": "remove the :", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485904421", "createdAt": "2020-09-09T20:31:54Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,135 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.MetricsAgent;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.util.Coerce;\n+import lombok.NonNull;\n+\n+import java.time.Instant;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.iot.evergreen.kernel.EvergreenService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.METRICS_AGENT_SERVICE_TOPICS;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+\n+public class KernelMetricsEmitter {\n+    // Kernel metrics\n+    public static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+    private static final String KERNEL_COMPONENT_METRIC_STORE = TelemetryNamespace.KernelComponents.toString();\n+    private static Map<TelemetryMetricName, MetricDataBuilder> kernelMetrics = new HashMap<>();\n+    private static Map<TelemetryMetricName, Integer> kernelMetricsData = new HashMap<>();\n+    private final Object periodicKernelMetricsInProgressLock = new Object();\n+    private final ScheduledExecutorService ses;\n+    @NonNull\n+    private final Kernel kernel;\n+    private ScheduledFuture<?> periodicKernelMetricsFuture = null;\n+    private int periodicKernelMetricsIntervalSec = 0;\n+\n+    /**\n+     * Constructor for kernel metrics emitter.\n+     *\n+     * @param kernel {@link Kernel}\n+     */\n+    public KernelMetricsEmitter(Kernel kernel) {\n+        this.kernel = kernel;\n+        this.ses = this.kernel.getContext().get(ScheduledExecutorService.class);\n+    }\n+\n+    /**\n+     * Schedules the periodic kernel metrics based on the configured aggregation interval.\n+     *\n+     * @param isReconfigured true if the interval is reconfigured\n+     */\n+    public void schedulePeriodicKernelMetrics(boolean isReconfigured) {\n+        // If the kernel/aggregation interval is reconfigured, cancel the previously scheduled job.\n+        if (this.periodicKernelMetricsFuture != null) {\n+            this.periodicKernelMetricsFuture.cancel(false);\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicKernelMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant\n+                        .ofEpochMilli(MetricsAgent.getLastPeriodicAggregationMetricsTime());\n+                if (lastPeriodicAggTime.plusSeconds(periodicKernelMetricsIntervalSec).isBefore(Instant.now())) {\n+                    this.emitKernelMetrics();\n+                }\n+            }\n+        }\n+        periodicKernelMetricsFuture = ses.scheduleWithFixedDelay(\n+                this::emitKernelMetrics, 0, periodicKernelMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Collect kernel metrics - Number of components running in each state.\n+     */\n+    protected void collectKernelComponentState() {\n+        List<TelemetryMetricName> telemetryMetricNames =\n+                TelemetryMetricName.getMetricNamesOf(TelemetryNamespace.KernelComponents);\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            Metric metric = Metric.builder()\n+                    .metricNamespace(TelemetryNamespace.KernelComponents)\n+                    .metricName(telemetryMetricName)\n+                    .metricUnit(TelemetryUnit.Count)\n+                    .metricAggregation(TelemetryAggregation.Average)\n+                    .build();\n+            MetricDataBuilder metricDataBuilder = new MetricFactory(KERNEL_COMPONENT_METRIC_STORE).addMetric(metric);\n+            kernelMetrics.put(telemetryMetricName, metricDataBuilder);\n+        }\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            kernelMetricsData.put(telemetryMetricName, 0);\n+        }\n+        /*\n+            Using lookup to create the MetricAgent service topics as this is called during the kernel launch\n+            before the service is created.\n+         */\n+        Topics metricTopics = kernel.getConfig().lookupTopics(SERVICES_NAMESPACE_TOPIC, METRICS_AGENT_SERVICE_TOPICS);\n+        metricTopics.lookup(PARAMETERS_CONFIG_KEY, TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC)\n+                .dflt(DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC)\n+                .subscribe((why, newv) -> {\n+                    periodicKernelMetricsIntervalSec = Coerce.toInt(newv);\n+                    if (periodicKernelMetricsFuture != null) {\n+                        this.schedulePeriodicKernelMetrics(true);\n+                    }\n+                });\n+        this.schedulePeriodicKernelMetrics(false);\n+    }\n+\n+    private void emitKernelMetrics() {\n+        Collection<EvergreenService> evergreenServices = kernel.orderedDependencies();\n+        for (EvergreenService evergreenService : evergreenServices) {\n+            String serviceState = evergreenService.getState().toString();\n+            serviceState = serviceState.charAt(0) + serviceState.substring(1).toLowerCase();\n+            try {\n+                TelemetryMetricName telemetryMetricName =\n+                        TelemetryMetricName.valueOf(\"NumberOfComponents\" + serviceState);\n+                kernelMetricsData.put(telemetryMetricName, kernelMetricsData.get(telemetryMetricName) + 1);\n+            } catch (IllegalArgumentException e) {\n+                logger.atError().log(\"Unable to find the metric name:\", e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "04a2944bd0e65671d4a0b2db9f470ddf68d69acd"}, "originalPosition": 126}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg1MzgxNjIx", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-485381621", "createdAt": "2020-09-09T20:32:17Z", "commit": {"oid": "04a2944bd0e65671d4a0b2db9f470ddf68d69acd"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQyMDozMjoxN1rOHPZQ9g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQyMDozMjoxN1rOHPZQ9g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTkwNDYzMA==", "bodyText": "synchronize this", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485904630", "createdAt": "2020-09-09T20:32:17Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,135 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.MetricsAgent;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.util.Coerce;\n+import lombok.NonNull;\n+\n+import java.time.Instant;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.iot.evergreen.kernel.EvergreenService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.METRICS_AGENT_SERVICE_TOPICS;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+\n+public class KernelMetricsEmitter {\n+    // Kernel metrics\n+    public static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+    private static final String KERNEL_COMPONENT_METRIC_STORE = TelemetryNamespace.KernelComponents.toString();\n+    private static Map<TelemetryMetricName, MetricDataBuilder> kernelMetrics = new HashMap<>();\n+    private static Map<TelemetryMetricName, Integer> kernelMetricsData = new HashMap<>();\n+    private final Object periodicKernelMetricsInProgressLock = new Object();\n+    private final ScheduledExecutorService ses;\n+    @NonNull\n+    private final Kernel kernel;\n+    private ScheduledFuture<?> periodicKernelMetricsFuture = null;\n+    private int periodicKernelMetricsIntervalSec = 0;\n+\n+    /**\n+     * Constructor for kernel metrics emitter.\n+     *\n+     * @param kernel {@link Kernel}\n+     */\n+    public KernelMetricsEmitter(Kernel kernel) {\n+        this.kernel = kernel;\n+        this.ses = this.kernel.getContext().get(ScheduledExecutorService.class);\n+    }\n+\n+    /**\n+     * Schedules the periodic kernel metrics based on the configured aggregation interval.\n+     *\n+     * @param isReconfigured true if the interval is reconfigured\n+     */\n+    public void schedulePeriodicKernelMetrics(boolean isReconfigured) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "04a2944bd0e65671d4a0b2db9f470ddf68d69acd"}, "originalPosition": 63}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg1MzgxODI5", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-485381829", "createdAt": "2020-09-09T20:32:33Z", "commit": {"oid": "04a2944bd0e65671d4a0b2db9f470ddf68d69acd"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQyMDozMjozM1rOHPZRjw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQyMDozMjozM1rOHPZRjw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTkwNDc4Mw==", "bodyText": "use dependency injection instead of reading from context", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485904783", "createdAt": "2020-09-09T20:32:33Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,135 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.MetricsAgent;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.util.Coerce;\n+import lombok.NonNull;\n+\n+import java.time.Instant;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+\n+import static com.aws.iot.evergreen.kernel.EvergreenService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.METRICS_AGENT_SERVICE_TOPICS;\n+import static com.aws.iot.evergreen.telemetry.MetricsAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+\n+public class KernelMetricsEmitter {\n+    // Kernel metrics\n+    public static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+    private static final String KERNEL_COMPONENT_METRIC_STORE = TelemetryNamespace.KernelComponents.toString();\n+    private static Map<TelemetryMetricName, MetricDataBuilder> kernelMetrics = new HashMap<>();\n+    private static Map<TelemetryMetricName, Integer> kernelMetricsData = new HashMap<>();\n+    private final Object periodicKernelMetricsInProgressLock = new Object();\n+    private final ScheduledExecutorService ses;\n+    @NonNull\n+    private final Kernel kernel;\n+    private ScheduledFuture<?> periodicKernelMetricsFuture = null;\n+    private int periodicKernelMetricsIntervalSec = 0;\n+\n+    /**\n+     * Constructor for kernel metrics emitter.\n+     *\n+     * @param kernel {@link Kernel}\n+     */\n+    public KernelMetricsEmitter(Kernel kernel) {\n+        this.kernel = kernel;\n+        this.ses = this.kernel.getContext().get(ScheduledExecutorService.class);\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "04a2944bd0e65671d4a0b2db9f470ddf68d69acd"}, "originalPosition": 56}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg1MzgyNjEx", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-485382611", "createdAt": "2020-09-09T20:33:41Z", "commit": {"oid": "04a2944bd0e65671d4a0b2db9f470ddf68d69acd"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQyMDozMzo0MVrOHPZUPg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQyMDozMzo0MVrOHPZUPg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTkwNTQ3MA==", "bodyText": "why are these package-private and not just private?", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485905470", "createdAt": "2020-09-09T20:33:41Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,241 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.Getter;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    public static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    public static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 60;\n+    static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 180;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    @Getter\n+    private static long lastPeriodicAggregationMetricsTime = Instant.now().toEpochMilli();\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses = getContext().get(ScheduledExecutorService.class);\n+    ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    @Getter\n+    public MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    ScheduledFuture<?> periodicSystemMetricsFuture = null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "04a2944bd0e65671d4a0b2db9f470ddf68d69acd"}, "originalPosition": 72}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg1MzgzMTEx", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-485383111", "createdAt": "2020-09-09T20:34:24Z", "commit": {"oid": "04a2944bd0e65671d4a0b2db9f470ddf68d69acd"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQyMDozNDoyNFrOHPZV5Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQyMDozNDoyNFrOHPZV5Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTkwNTg5Mw==", "bodyText": "remove :", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r485905893", "createdAt": "2020-09-09T20:34:24Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,201 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.MetricDataPoint;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.text.NumberFormat;\n+import java.text.ParseException;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+public class MetricsAggregator {\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private static final int MILLI_SECONDS = 1000;\n+    MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    private final ObjectMapper objectMapper = new ObjectMapper();\n+\n+    /**\n+     * This method stores the aggregated data points of the metrics emitted over the interval.\n+     *\n+     * @param aggregationIntervalSec periodic interval in seconds for the aggregating the metrics\n+     * @param currTimestamp timestamp at which the aggregate is initiated\n+     */\n+    public void aggregateMetrics(int aggregationIntervalSec, long currTimestamp) {\n+        int aggIntervalMilliSec = aggregationIntervalSec * MILLI_SECONDS;\n+        for (TelemetryNamespace namespace : TelemetryNamespace.values()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<MetricDataPoint>> metrics = new HashMap<>();\n+            MetricDataPoint mdp;\n+            try {\n+                List<Path> paths = Files\n+                        .walk(TelemetryConfig.getTelemetryDirectory())\n+                        .filter(Files::isRegularFile)\n+                        .filter(path -> {\n+                            Object fileName = null;\n+                            if (path != null) {\n+                                fileName = path.getFileName();\n+                            }\n+                            if (fileName == null) {\n+                                fileName = \"\";\n+                            }\n+                            return fileName.toString().startsWith(namespace.toString());\n+                        }).collect(Collectors.toList());\n+                for (Path path :paths) {\n+                    /*\n+                     Read from the file at Telemetry/namespace*.log\n+                     Read only modified files and aggregate only new values based on the last aggregated time.\n+                     */\n+                    if (currTimestamp - new File(path.toString()).lastModified() <= aggIntervalMilliSec) {\n+                        List<String> logs = Files.lines(Paths.get(path.toString())).collect(Collectors.toList());\n+                        for (String log : logs) {\n+                            try {\n+                            /*\n+\n+                            {\"thread\":\"main\",\"level\":\"TRACE\",\"eventType\":null,\n+\n+                            \"message\":\"{\\\"M\\\":{\\\"NS\\\":\\\"SystemMetrics\\\",\\\"N\\\":\\\"CpuUsage\\\",\\\"U\\\":\\\"Percent\\\",\n+\n+                            \\\"A\\\":\\\"Average\\\"},\\\"V\\\":123,\\\"TS\\\":1599613654270}\",\"contexts\":{},\n+\n+                            \"loggerName\":\"Metrics-french fries\",\"timestamp\":1599613654270,\"cause\":null}\n+\n+                             */\n+\n+                            mdp = objectMapper.readValue(objectMapper.readTree(log).get(\"message\").asText(),\n+                                    MetricDataPoint.class);\n+                            if (mdp.getMetric() != null && currTimestamp - mdp.getTimestamp() <= aggIntervalMilliSec) {\n+                                metrics.computeIfAbsent(mdp.getMetric().getMetricName(),\n+                                        k -> new ArrayList<>()).add(mdp);\n+                            }\n+                        } catch (IOException e) {\n+                                logger.atError().log(\"Unable to parse the metric log: \", e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "04a2944bd0e65671d4a0b2db9f470ddf68d69acd"}, "originalPosition": 95}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "eb8f6729a4c0e179ff3f13f4ce10ce608827b7b0", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/eb8f6729a4c0e179ff3f13f4ce10ce608827b7b0", "committedDate": "2020-09-09T20:37:04Z", "message": "Add telemetry metrics + tests + modify log statements"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "62a10c319a5a406b376edf792aa91618478a74ca", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/62a10c319a5a406b376edf792aa91618478a74ca", "committedDate": "2020-09-09T20:37:55Z", "message": "Merge branch 'telemetry-logs' of github.com:aws/aws-greengrass-kernel into telemetry-logs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "abdc9e5e716f92cf14668bf42de356d989c56b5b", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/abdc9e5e716f92cf14668bf42de356d989c56b5b", "committedDate": "2020-09-11T01:05:50Z", "message": "Moved kernel metrics to MA + update tests + add initial e2e test + modify aggregation and publish logic"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "067e8400fd290b8575977b2bc59f500d4e68dcae", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/067e8400fd290b8575977b2bc59f500d4e68dcae", "committedDate": "2020-09-11T01:25:57Z", "message": "Moved kernel metrics to MA + update tests + add initial e2e test + modify aggregation and publish logic"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a79ccf3350bed1c6dbdd04a7fc26f451d184a7bc", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/a79ccf3350bed1c6dbdd04a7fc26f451d184a7bc", "committedDate": "2020-09-11T01:27:51Z", "message": "Merge branch 'telemetry-logs' of github.com:aws/aws-greengrass-kernel into telemetry-logs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a4bf94ffcb92a1b498e471c7532d17798c0840d4", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/a4bf94ffcb92a1b498e471c7532d17798c0840d4", "committedDate": "2020-09-11T01:43:06Z", "message": "Merge branch 'telemetry-logs' of github.com:aws/aws-greengrass-kernel into telemetry-logs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1bcbcff49657ecb14873822edf541b84dace0cc4", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/1bcbcff49657ecb14873822edf541b84dace0cc4", "committedDate": "2020-09-11T01:43:36Z", "message": "Merge branch 'telemetry-logs' of github.com:aws/aws-greengrass-kernel into telemetry-logs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1f6f8fa609fd963745b7444ac83769f270db472d", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/1f6f8fa609fd963745b7444ac83769f270db472d", "committedDate": "2020-09-11T02:11:19Z", "message": "Changed parameter to runtime config space."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg2NDQ4MTc0", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-486448174", "createdAt": "2020-09-11T03:25:37Z", "commit": {"oid": "1f6f8fa609fd963745b7444ac83769f270db472d"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 31, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQwMzoyNTozN1rOHQM8Uw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQwMzo0NzoyOVrOHQNQ8Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1MTMxNQ==", "bodyText": "don't bother with this", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486751315", "createdAt": "2020-09-11T03:25:37Z", "author": {"login": "MikeDombo"}, "path": "src/integrationtests/java/com/aws/iot/evergreen/integrationtests/e2e/telemetry/MetricsAgentTest.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ *  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *   SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.integrationtests.e2e.telemetry;\n+\n+import com.amazonaws.services.evergreen.model.PackageMetaData;\n+import com.amazonaws.services.evergreen.model.PublishConfigurationResult;\n+import com.amazonaws.services.evergreen.model.SetConfigurationRequest;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.State;\n+import com.aws.iot.evergreen.integrationtests.e2e.BaseE2ETestCase;\n+import com.aws.iot.evergreen.integrationtests.e2e.util.IotJobsUtils;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.mqtt.SubscribeRequest;\n+import com.aws.iot.evergreen.telemetry.MetricsAgent;\n+import com.aws.iot.evergreen.telemetry.MetricsAggregator;\n+import com.aws.iot.evergreen.telemetry.MetricsPayload;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.Timeout;\n+import software.amazon.awssdk.crt.mqtt.MqttMessage;\n+import software.amazon.awssdk.services.iot.model.JobExecutionStatus;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static com.aws.iot.evergreen.kernel.EvergreenService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.github.grantwest.eventually.EventuallyLambdaMatcher.eventuallyEval;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+\n+// TODO : Complete the tests\n+@SuppressWarnings(\"PMD.CloseResource\")\n+@Tag(\"E2E\")\n+public class MetricsAgentTest extends BaseE2ETestCase {\n+    private static final ObjectMapper DESERIALIZER = new ObjectMapper();\n+\n+    @AfterEach\n+    void afterEach() {\n+        try {\n+            if (kernel != null) {\n+                kernel.shutdown();\n+            }\n+        } finally {\n+            // Cleanup all IoT thing resources we created\n+            cleanup();\n+        }\n+    }\n+\n+    @BeforeEach\n+    void launchKernel() throws Exception {\n+        initKernel();\n+        kernel.launch();\n+\n+        // TODO: Without this sleep, DeploymentService sometimes is not able to pick up new IoT job created here,\n+        // causing these tests to fail. There may be a race condition between DeploymentService startup logic and\n+        // creating new IoT job here.\n+        TimeUnit.SECONDS.sleep(10);\n+    }\n+\n+    @Timeout(value = 10, unit = TimeUnit.MINUTES)\n+    @Test\n+    void GIVEN_kernel_running_with_deployed_services_WHEN_deployment_finishes_THEN_fss_data_is_uploaded() throws Exception {\n+        MqttClient client = kernel.getContext().get(MqttClient.class);\n+\n+        CountDownLatch cdl = new CountDownLatch(2);\n+        AtomicReference<List<MqttMessage>> mqttMessagesList = new AtomicReference<>();\n+        mqttMessagesList.set(new ArrayList<>());\n+        // TODO: Make the publish topic configurable?\n+        client.subscribe(SubscribeRequest.builder()\n+                .topic(MetricsAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC.replace(\"{thingName}\", thingInfo.getThingName()))\n+                .callback((m) -> {\n+                    cdl.countDown();\n+                    mqttMessagesList.get().add(m);\n+                }).build());\n+        Topics maTopics = kernel.getConfig().lookupTopics(SERVICES_NAMESPACE_TOPIC,\n+                MetricsAgent.METRICS_AGENT_SERVICE_TOPICS);\n+        maTopics.lookup(PARAMETERS_CONFIG_KEY, MetricsAgent.getTELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC())\n+                .withValue(5);\n+        maTopics.lookup(PARAMETERS_CONFIG_KEY, MetricsAgent.getTELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC())\n+                .withValue(3);\n+        //Deployment to have some services running in Kernel\n+        SetConfigurationRequest setRequest1 = new SetConfigurationRequest()\n+                .withTargetName(thingGroupName)\n+                .withTargetType(THING_GROUP_TARGET_TYPE)\n+                .addPackagesEntry(\"CustomerApp\", new PackageMetaData().withRootComponent(true).withVersion(\"1.0.0\")\n+                        .withConfiguration(\"{\\\"sampleText\\\":\\\"FCS integ test\\\"}\"))\n+                .addPackagesEntry(\"SomeService\", new PackageMetaData().withRootComponent(true).withVersion(\"1.0.0\"));\n+        PublishConfigurationResult publishResult1 = setAndPublishFleetConfiguration(setRequest1);\n+\n+        IotJobsUtils.waitForJobExecutionStatusToSatisfy(iotClient, publishResult1.getJobId(), thingInfo.getThingName(),\n+                Duration.ofMinutes(5), s -> s.equals(JobExecutionStatus.SUCCEEDED));\n+\n+\n+        // Ensure that main is finished, which is its terminal state, so this means that all updates ought to be done\n+        assertThat(kernel.getMain()::getState, eventuallyEval(is(State.FINISHED)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f6f8fa609fd963745b7444ac83769f270db472d"}, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1MTQxNw==", "bodyText": "missing any sort of assertions about the data", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486751417", "createdAt": "2020-09-11T03:26:04Z", "author": {"login": "MikeDombo"}, "path": "src/integrationtests/java/com/aws/iot/evergreen/integrationtests/e2e/telemetry/MetricsAgentTest.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ *  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *   SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.integrationtests.e2e.telemetry;\n+\n+import com.amazonaws.services.evergreen.model.PackageMetaData;\n+import com.amazonaws.services.evergreen.model.PublishConfigurationResult;\n+import com.amazonaws.services.evergreen.model.SetConfigurationRequest;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.State;\n+import com.aws.iot.evergreen.integrationtests.e2e.BaseE2ETestCase;\n+import com.aws.iot.evergreen.integrationtests.e2e.util.IotJobsUtils;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.mqtt.SubscribeRequest;\n+import com.aws.iot.evergreen.telemetry.MetricsAgent;\n+import com.aws.iot.evergreen.telemetry.MetricsAggregator;\n+import com.aws.iot.evergreen.telemetry.MetricsPayload;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.Timeout;\n+import software.amazon.awssdk.crt.mqtt.MqttMessage;\n+import software.amazon.awssdk.services.iot.model.JobExecutionStatus;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static com.aws.iot.evergreen.kernel.EvergreenService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.github.grantwest.eventually.EventuallyLambdaMatcher.eventuallyEval;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+\n+// TODO : Complete the tests\n+@SuppressWarnings(\"PMD.CloseResource\")\n+@Tag(\"E2E\")\n+public class MetricsAgentTest extends BaseE2ETestCase {\n+    private static final ObjectMapper DESERIALIZER = new ObjectMapper();\n+\n+    @AfterEach\n+    void afterEach() {\n+        try {\n+            if (kernel != null) {\n+                kernel.shutdown();\n+            }\n+        } finally {\n+            // Cleanup all IoT thing resources we created\n+            cleanup();\n+        }\n+    }\n+\n+    @BeforeEach\n+    void launchKernel() throws Exception {\n+        initKernel();\n+        kernel.launch();\n+\n+        // TODO: Without this sleep, DeploymentService sometimes is not able to pick up new IoT job created here,\n+        // causing these tests to fail. There may be a race condition between DeploymentService startup logic and\n+        // creating new IoT job here.\n+        TimeUnit.SECONDS.sleep(10);\n+    }\n+\n+    @Timeout(value = 10, unit = TimeUnit.MINUTES)\n+    @Test\n+    void GIVEN_kernel_running_with_deployed_services_WHEN_deployment_finishes_THEN_fss_data_is_uploaded() throws Exception {\n+        MqttClient client = kernel.getContext().get(MqttClient.class);\n+\n+        CountDownLatch cdl = new CountDownLatch(2);\n+        AtomicReference<List<MqttMessage>> mqttMessagesList = new AtomicReference<>();\n+        mqttMessagesList.set(new ArrayList<>());\n+        // TODO: Make the publish topic configurable?\n+        client.subscribe(SubscribeRequest.builder()\n+                .topic(MetricsAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC.replace(\"{thingName}\", thingInfo.getThingName()))\n+                .callback((m) -> {\n+                    cdl.countDown();\n+                    mqttMessagesList.get().add(m);\n+                }).build());\n+        Topics maTopics = kernel.getConfig().lookupTopics(SERVICES_NAMESPACE_TOPIC,\n+                MetricsAgent.METRICS_AGENT_SERVICE_TOPICS);\n+        maTopics.lookup(PARAMETERS_CONFIG_KEY, MetricsAgent.getTELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC())\n+                .withValue(5);\n+        maTopics.lookup(PARAMETERS_CONFIG_KEY, MetricsAgent.getTELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC())\n+                .withValue(3);\n+        //Deployment to have some services running in Kernel\n+        SetConfigurationRequest setRequest1 = new SetConfigurationRequest()\n+                .withTargetName(thingGroupName)\n+                .withTargetType(THING_GROUP_TARGET_TYPE)\n+                .addPackagesEntry(\"CustomerApp\", new PackageMetaData().withRootComponent(true).withVersion(\"1.0.0\")\n+                        .withConfiguration(\"{\\\"sampleText\\\":\\\"FCS integ test\\\"}\"))\n+                .addPackagesEntry(\"SomeService\", new PackageMetaData().withRootComponent(true).withVersion(\"1.0.0\"));\n+        PublishConfigurationResult publishResult1 = setAndPublishFleetConfiguration(setRequest1);\n+\n+        IotJobsUtils.waitForJobExecutionStatusToSatisfy(iotClient, publishResult1.getJobId(), thingInfo.getThingName(),\n+                Duration.ofMinutes(5), s -> s.equals(JobExecutionStatus.SUCCEEDED));\n+\n+\n+        // Ensure that main is finished, which is its terminal state, so this means that all updates ought to be done\n+        assertThat(kernel.getMain()::getState, eventuallyEval(is(State.FINISHED)));\n+        List<List<MetricsAggregator.AggregatedMetric>> metrics = new ArrayList<>();\n+        for (MqttMessage mt : mqttMessagesList.get()) {\n+            try {\n+                // In this test, we filter only the metrics payload.\n+                MetricsPayload mp = DESERIALIZER.readValue(mt.getPayload(), MetricsPayload.class);\n+                metrics.add(mp.getAggregatedMetricList());\n+            } catch (MismatchedInputException  e) {\n+                // do nothing if the payload is something else", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f6f8fa609fd963745b7444ac83769f270db472d"}, "originalPosition": 115}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1MTgxOA==", "bodyText": "What is in each of these maps? can it be consolidated? Do they need to exist at all?", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486751818", "createdAt": "2020-09-11T03:27:39Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,82 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import javax.inject.Inject;\n+\n+public class KernelMetricsEmitter {\n+    public static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+    private static final String KERNEL_COMPONENT_METRIC_STORE = TelemetryNamespace.KernelComponents.toString();\n+    private static Map<TelemetryMetricName, MetricDataBuilder> kernelMetrics = new HashMap<>();\n+    private static Map<TelemetryMetricName, Integer> kernelMetricsData = new HashMap<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f6f8fa609fd963745b7444ac83769f270db472d"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1MTk3MQ==", "bodyText": "remove evergreen from the topic. I think Nikkhil just made a change to make it greengrassv2", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486751971", "createdAt": "2020-09-11T03:28:19Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,293 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f6f8fa609fd963745b7444ac83769f270db472d"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1MjEwNA==", "bodyText": "all these getters should be package-private so that they're only used in the tests", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486752104", "createdAt": "2020-09-11T03:28:56Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,293 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    @Getter\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 30;\n+    @Getter\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter\n+    private  static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 120;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    @Getter\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicEmitSystemMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicEmitKernelMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f6f8fa609fd963745b7444ac83769f270db472d"}, "originalPosition": 81}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1MjE4OQ==", "bodyText": "formatting", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486752189", "createdAt": "2020-09-11T03:29:22Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,293 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    @Getter\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 30;\n+    @Getter\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter\n+    private  static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 120;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    @Getter\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicEmitSystemMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicEmitKernelMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+    private final KernelMetricsEmitter kernelMetricsEmitter;\n+    private final MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder().schema(\"2020-07-30\").build();\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics              root configuration topic for this service\n+     * @param mqttClient          {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     * @param ses {@link ScheduledExecutorService}\n+     * @param kernelMetricsEmitter {@link KernelMetricsEmitter}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration,\n+                        ScheduledExecutorService ses, KernelMetricsEmitter kernelMetricsEmitter) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        this.kernelMetricsEmitter = kernelMetricsEmitter;\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            // If the aggregation interval is reconfigured, cancel the previously scheduled job.\n+            if (periodicAggregateMetricsFuture != null) {\n+            periodicAggregateMetricsFuture.cancel(false);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f6f8fa609fd963745b7444ac83769f270db472d"}, "originalPosition": 120}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1MjMzMQ==", "bodyText": "this needs to be synchronized too", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486752331", "createdAt": "2020-09-11T03:29:51Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,293 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    @Getter\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 30;\n+    @Getter\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter\n+    private  static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 120;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    @Getter\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicEmitSystemMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicEmitKernelMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+    private final KernelMetricsEmitter kernelMetricsEmitter;\n+    private final MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder().schema(\"2020-07-30\").build();\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics              root configuration topic for this service\n+     * @param mqttClient          {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     * @param ses {@link ScheduledExecutorService}\n+     * @param kernelMetricsEmitter {@link KernelMetricsEmitter}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration,\n+                        ScheduledExecutorService ses, KernelMetricsEmitter kernelMetricsEmitter) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        this.kernelMetricsEmitter = kernelMetricsEmitter;\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            // If the aggregation interval is reconfigured, cancel the previously scheduled job.\n+            if (periodicAggregateMetricsFuture != null) {\n+            periodicAggregateMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitSystemMetricsFuture != null) {\n+                periodicEmitSystemMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitKernelMetricsFuture != null) {\n+                periodicEmitKernelMetricsFuture.cancel(false);\n+            }\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    emitPeriodicSystemMetrics();\n+                    emitPeriodicKernelMetrics();\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Start emitting metrics with no delay. This is device specific where metrics are stored in files.\n+        periodicEmitSystemMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicSystemMetrics, 0,\n+                    periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        periodicEmitKernelMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicKernelMetrics, 0,\n+                periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        // As the time based metrics (eg. System metrics) are emitted with the same interval as aggregation, start\n+        // aggregating the metrics after at least one data point is emitted. So, the initial delay to aggregate the\n+        // metrics can be made equal to the interval. This is device specific where the metrics are stored in files.\n+        periodicAggregateMetricsFuture = ses.scheduleWithFixedDelay(this::aggregatePeriodicMetrics,\n+                periodicAggregateMetricsIntervalSec, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f6f8fa609fd963745b7444ac83769f270db472d"}, "originalPosition": 150}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1MjU3NA==", "bodyText": "Throughput isn't really much of a concern, so just add synchronized to all these methods, otherwise you have threading problems with reading and writing these fields with all the futures.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486752574", "createdAt": "2020-09-11T03:30:56Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,293 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    @Getter\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 30;\n+    @Getter\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter\n+    private  static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 120;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    @Getter\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicEmitSystemMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicEmitKernelMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+    private final KernelMetricsEmitter kernelMetricsEmitter;\n+    private final MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder().schema(\"2020-07-30\").build();\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics              root configuration topic for this service\n+     * @param mqttClient          {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     * @param ses {@link ScheduledExecutorService}\n+     * @param kernelMetricsEmitter {@link KernelMetricsEmitter}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration,\n+                        ScheduledExecutorService ses, KernelMetricsEmitter kernelMetricsEmitter) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        this.kernelMetricsEmitter = kernelMetricsEmitter;\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            // If the aggregation interval is reconfigured, cancel the previously scheduled job.\n+            if (periodicAggregateMetricsFuture != null) {\n+            periodicAggregateMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitSystemMetricsFuture != null) {\n+                periodicEmitSystemMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitKernelMetricsFuture != null) {\n+                periodicEmitKernelMetricsFuture.cancel(false);\n+            }\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    emitPeriodicSystemMetrics();\n+                    emitPeriodicKernelMetrics();\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Start emitting metrics with no delay. This is device specific where metrics are stored in files.\n+        periodicEmitSystemMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicSystemMetrics, 0,\n+                    periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        periodicEmitKernelMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicKernelMetrics, 0,\n+                periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        // As the time based metrics (eg. System metrics) are emitted with the same interval as aggregation, start\n+        // aggregating the metrics after at least one data point is emitted. So, the initial delay to aggregate the\n+        // metrics can be made equal to the interval. This is device specific where the metrics are stored in files.\n+        periodicAggregateMetricsFuture = ses.scheduleWithFixedDelay(this::aggregatePeriodicMetrics,\n+                periodicAggregateMetricsIntervalSec, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1MjMzMQ=="}, "originalCommit": {"oid": "1f6f8fa609fd963745b7444ac83769f270db472d"}, "originalPosition": 150}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1MjYxOA==", "bodyText": "remove space", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486752618", "createdAt": "2020-09-11T03:31:07Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,293 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    @Getter\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 30;\n+    @Getter\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter\n+    private  static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 120;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    @Getter\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicEmitSystemMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicEmitKernelMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+    private final KernelMetricsEmitter kernelMetricsEmitter;\n+    private final MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder().schema(\"2020-07-30\").build();\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics              root configuration topic for this service\n+     * @param mqttClient          {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     * @param ses {@link ScheduledExecutorService}\n+     * @param kernelMetricsEmitter {@link KernelMetricsEmitter}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration,\n+                        ScheduledExecutorService ses, KernelMetricsEmitter kernelMetricsEmitter) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        this.kernelMetricsEmitter = kernelMetricsEmitter;\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            // If the aggregation interval is reconfigured, cancel the previously scheduled job.\n+            if (periodicAggregateMetricsFuture != null) {\n+            periodicAggregateMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitSystemMetricsFuture != null) {\n+                periodicEmitSystemMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitKernelMetricsFuture != null) {\n+                periodicEmitKernelMetricsFuture.cancel(false);\n+            }\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    emitPeriodicSystemMetrics();\n+                    emitPeriodicKernelMetrics();\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Start emitting metrics with no delay. This is device specific where metrics are stored in files.\n+        periodicEmitSystemMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicSystemMetrics, 0,\n+                    periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        periodicEmitKernelMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicKernelMetrics, 0,\n+                periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        // As the time based metrics (eg. System metrics) are emitted with the same interval as aggregation, start\n+        // aggregating the metrics after at least one data point is emitted. So, the initial delay to aggregate the\n+        // metrics can be made equal to the interval. This is device specific where the metrics are stored in files.\n+        periodicAggregateMetricsFuture = ses.scheduleWithFixedDelay(this::aggregatePeriodicMetrics,\n+                periodicAggregateMetricsIntervalSec, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Schedules the publishing of metrics based on the configured publish interval or the mqtt connection status.\n+     */\n+    private void schedulePeriodicPublishMetrics(boolean isReconfiguredOrConnectionResumed) {\n+        // If we missed to publish the metrics due to connection loss or if the publish interval is reconfigured,\n+        // cancel the previously scheduled job.\n+        synchronized (periodicPublishMetricsInProgressLock) {\n+            if (periodicPublishMetricsFuture != null) {\n+                periodicPublishMetricsFuture.cancel(false);\n+            }\n+        }\n+        if (isReconfiguredOrConnectionResumed) {\n+            synchronized (periodicPublishMetricsInProgressLock) {\n+                Instant lastPeriodicPubTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicPublishTimeTopic()));\n+                if (lastPeriodicPubTime.plusSeconds(periodicPublishMetricsIntervalSec)\n+                        .isBefore(Instant.now())) {\n+                    publishPeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Add some jitter as an initial delay. If the fleet has a lot of devices associated to it, we don't want\n+        // all the devices to send the periodic publish of metrics at the same time.\n+        long initialDelay = RandomUtils.nextLong(0, periodicPublishMetricsIntervalSec);\n+        periodicPublishMetricsFuture = ses.scheduleWithFixedDelay(this::publishPeriodicMetrics, initialDelay,\n+                periodicPublishMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Helper for metrics aggregator. Also used in tests.\n+     */\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f6f8fa609fd963745b7444ac83769f270db472d"}, "originalPosition": 183}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1MjY4MQ==", "bodyText": "not info level. drop to debug", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486752681", "createdAt": "2020-09-11T03:31:24Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,293 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    @Getter\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 30;\n+    @Getter\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter\n+    private  static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 120;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    @Getter\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicEmitSystemMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicEmitKernelMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+    private final KernelMetricsEmitter kernelMetricsEmitter;\n+    private final MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder().schema(\"2020-07-30\").build();\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics              root configuration topic for this service\n+     * @param mqttClient          {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     * @param ses {@link ScheduledExecutorService}\n+     * @param kernelMetricsEmitter {@link KernelMetricsEmitter}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration,\n+                        ScheduledExecutorService ses, KernelMetricsEmitter kernelMetricsEmitter) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        this.kernelMetricsEmitter = kernelMetricsEmitter;\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            // If the aggregation interval is reconfigured, cancel the previously scheduled job.\n+            if (periodicAggregateMetricsFuture != null) {\n+            periodicAggregateMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitSystemMetricsFuture != null) {\n+                periodicEmitSystemMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitKernelMetricsFuture != null) {\n+                periodicEmitKernelMetricsFuture.cancel(false);\n+            }\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    emitPeriodicSystemMetrics();\n+                    emitPeriodicKernelMetrics();\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Start emitting metrics with no delay. This is device specific where metrics are stored in files.\n+        periodicEmitSystemMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicSystemMetrics, 0,\n+                    periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        periodicEmitKernelMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicKernelMetrics, 0,\n+                periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        // As the time based metrics (eg. System metrics) are emitted with the same interval as aggregation, start\n+        // aggregating the metrics after at least one data point is emitted. So, the initial delay to aggregate the\n+        // metrics can be made equal to the interval. This is device specific where the metrics are stored in files.\n+        periodicAggregateMetricsFuture = ses.scheduleWithFixedDelay(this::aggregatePeriodicMetrics,\n+                periodicAggregateMetricsIntervalSec, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Schedules the publishing of metrics based on the configured publish interval or the mqtt connection status.\n+     */\n+    private void schedulePeriodicPublishMetrics(boolean isReconfiguredOrConnectionResumed) {\n+        // If we missed to publish the metrics due to connection loss or if the publish interval is reconfigured,\n+        // cancel the previously scheduled job.\n+        synchronized (periodicPublishMetricsInProgressLock) {\n+            if (periodicPublishMetricsFuture != null) {\n+                periodicPublishMetricsFuture.cancel(false);\n+            }\n+        }\n+        if (isReconfiguredOrConnectionResumed) {\n+            synchronized (periodicPublishMetricsInProgressLock) {\n+                Instant lastPeriodicPubTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicPublishTimeTopic()));\n+                if (lastPeriodicPubTime.plusSeconds(periodicPublishMetricsIntervalSec)\n+                        .isBefore(Instant.now())) {\n+                    publishPeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Add some jitter as an initial delay. If the fleet has a lot of devices associated to it, we don't want\n+        // all the devices to send the periodic publish of metrics at the same time.\n+        long initialDelay = RandomUtils.nextLong(0, periodicPublishMetricsIntervalSec);\n+        periodicPublishMetricsFuture = ses.scheduleWithFixedDelay(this::publishPeriodicMetrics, initialDelay,\n+                periodicPublishMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Helper for metrics aggregator. Also used in tests.\n+     */\n+\n+     void aggregatePeriodicMetrics() {\n+        long timeStamp = Instant.now().toEpochMilli();\n+        long lastAgg = Coerce.toLong(getPeriodicAggregateTimeTopic());\n+        this.metricsAggregator.aggregateMetrics(lastAgg, timeStamp);\n+        getPeriodicAggregateTimeTopic().withValue(timeStamp);\n+    }\n+\n+    /**\n+     * Helper for metrics uploader. Also used in tests.\n+     */\n+     void publishPeriodicMetrics() {\n+        if (!isConnected.get()) {\n+            logger.atInfo().log(\"Cannot publish the metrics: MQTT Connection interrupted.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f6f8fa609fd963745b7444ac83769f270db472d"}, "originalPosition": 196}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1MjgzMA==", "bodyText": "what? Do not log all this data", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486752830", "createdAt": "2020-09-11T03:31:53Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,293 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    @Getter\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 30;\n+    @Getter\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter\n+    private  static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 120;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    @Getter\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicEmitSystemMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicEmitKernelMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+    private final KernelMetricsEmitter kernelMetricsEmitter;\n+    private final MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder().schema(\"2020-07-30\").build();\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics              root configuration topic for this service\n+     * @param mqttClient          {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     * @param ses {@link ScheduledExecutorService}\n+     * @param kernelMetricsEmitter {@link KernelMetricsEmitter}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration,\n+                        ScheduledExecutorService ses, KernelMetricsEmitter kernelMetricsEmitter) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        this.kernelMetricsEmitter = kernelMetricsEmitter;\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            // If the aggregation interval is reconfigured, cancel the previously scheduled job.\n+            if (periodicAggregateMetricsFuture != null) {\n+            periodicAggregateMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitSystemMetricsFuture != null) {\n+                periodicEmitSystemMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitKernelMetricsFuture != null) {\n+                periodicEmitKernelMetricsFuture.cancel(false);\n+            }\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    emitPeriodicSystemMetrics();\n+                    emitPeriodicKernelMetrics();\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Start emitting metrics with no delay. This is device specific where metrics are stored in files.\n+        periodicEmitSystemMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicSystemMetrics, 0,\n+                    periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        periodicEmitKernelMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicKernelMetrics, 0,\n+                periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        // As the time based metrics (eg. System metrics) are emitted with the same interval as aggregation, start\n+        // aggregating the metrics after at least one data point is emitted. So, the initial delay to aggregate the\n+        // metrics can be made equal to the interval. This is device specific where the metrics are stored in files.\n+        periodicAggregateMetricsFuture = ses.scheduleWithFixedDelay(this::aggregatePeriodicMetrics,\n+                periodicAggregateMetricsIntervalSec, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Schedules the publishing of metrics based on the configured publish interval or the mqtt connection status.\n+     */\n+    private void schedulePeriodicPublishMetrics(boolean isReconfiguredOrConnectionResumed) {\n+        // If we missed to publish the metrics due to connection loss or if the publish interval is reconfigured,\n+        // cancel the previously scheduled job.\n+        synchronized (periodicPublishMetricsInProgressLock) {\n+            if (periodicPublishMetricsFuture != null) {\n+                periodicPublishMetricsFuture.cancel(false);\n+            }\n+        }\n+        if (isReconfiguredOrConnectionResumed) {\n+            synchronized (periodicPublishMetricsInProgressLock) {\n+                Instant lastPeriodicPubTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicPublishTimeTopic()));\n+                if (lastPeriodicPubTime.plusSeconds(periodicPublishMetricsIntervalSec)\n+                        .isBefore(Instant.now())) {\n+                    publishPeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Add some jitter as an initial delay. If the fleet has a lot of devices associated to it, we don't want\n+        // all the devices to send the periodic publish of metrics at the same time.\n+        long initialDelay = RandomUtils.nextLong(0, periodicPublishMetricsIntervalSec);\n+        periodicPublishMetricsFuture = ses.scheduleWithFixedDelay(this::publishPeriodicMetrics, initialDelay,\n+                periodicPublishMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Helper for metrics aggregator. Also used in tests.\n+     */\n+\n+     void aggregatePeriodicMetrics() {\n+        long timeStamp = Instant.now().toEpochMilli();\n+        long lastAgg = Coerce.toLong(getPeriodicAggregateTimeTopic());\n+        this.metricsAggregator.aggregateMetrics(lastAgg, timeStamp);\n+        getPeriodicAggregateTimeTopic().withValue(timeStamp);\n+    }\n+\n+    /**\n+     * Helper for metrics uploader. Also used in tests.\n+     */\n+     void publishPeriodicMetrics() {\n+        if (!isConnected.get()) {\n+            logger.atInfo().log(\"Cannot publish the metrics: MQTT Connection interrupted.\");\n+            return;\n+        }\n+        long timeStamp = Instant.now().toEpochMilli();\n+        long lastPublish = Coerce.toLong(getPeriodicPublishTimeTopic());\n+        Map<Long, List<MetricsAggregator.AggregatedMetric>> metricsToPublishMap =\n+                this.metricsUploader.getAggregatedMetrics(lastPublish, timeStamp);\n+        getPeriodicPublishTimeTopic().withValue(timeStamp);\n+        try {\n+            logger.atInfo().log(new ObjectMapper().writeValueAsString(metricsToPublishMap.get(timeStamp)));\n+        } catch (JsonProcessingException e) {\n+            logger.atTrace().log(\"Invalid message format\", e);\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f6f8fa609fd963745b7444ac83769f270db472d"}, "originalPosition": 208}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1MjkwMQ==", "bodyText": "timestamp", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486752901", "createdAt": "2020-09-11T03:32:12Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,293 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    @Getter\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 30;\n+    @Getter\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter\n+    private  static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 120;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    @Getter\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicEmitSystemMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicEmitKernelMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+    private final KernelMetricsEmitter kernelMetricsEmitter;\n+    private final MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder().schema(\"2020-07-30\").build();\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics              root configuration topic for this service\n+     * @param mqttClient          {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     * @param ses {@link ScheduledExecutorService}\n+     * @param kernelMetricsEmitter {@link KernelMetricsEmitter}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration,\n+                        ScheduledExecutorService ses, KernelMetricsEmitter kernelMetricsEmitter) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        this.kernelMetricsEmitter = kernelMetricsEmitter;\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            // If the aggregation interval is reconfigured, cancel the previously scheduled job.\n+            if (periodicAggregateMetricsFuture != null) {\n+            periodicAggregateMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitSystemMetricsFuture != null) {\n+                periodicEmitSystemMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitKernelMetricsFuture != null) {\n+                periodicEmitKernelMetricsFuture.cancel(false);\n+            }\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    emitPeriodicSystemMetrics();\n+                    emitPeriodicKernelMetrics();\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Start emitting metrics with no delay. This is device specific where metrics are stored in files.\n+        periodicEmitSystemMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicSystemMetrics, 0,\n+                    periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        periodicEmitKernelMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicKernelMetrics, 0,\n+                periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        // As the time based metrics (eg. System metrics) are emitted with the same interval as aggregation, start\n+        // aggregating the metrics after at least one data point is emitted. So, the initial delay to aggregate the\n+        // metrics can be made equal to the interval. This is device specific where the metrics are stored in files.\n+        periodicAggregateMetricsFuture = ses.scheduleWithFixedDelay(this::aggregatePeriodicMetrics,\n+                periodicAggregateMetricsIntervalSec, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Schedules the publishing of metrics based on the configured publish interval or the mqtt connection status.\n+     */\n+    private void schedulePeriodicPublishMetrics(boolean isReconfiguredOrConnectionResumed) {\n+        // If we missed to publish the metrics due to connection loss or if the publish interval is reconfigured,\n+        // cancel the previously scheduled job.\n+        synchronized (periodicPublishMetricsInProgressLock) {\n+            if (periodicPublishMetricsFuture != null) {\n+                periodicPublishMetricsFuture.cancel(false);\n+            }\n+        }\n+        if (isReconfiguredOrConnectionResumed) {\n+            synchronized (periodicPublishMetricsInProgressLock) {\n+                Instant lastPeriodicPubTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicPublishTimeTopic()));\n+                if (lastPeriodicPubTime.plusSeconds(periodicPublishMetricsIntervalSec)\n+                        .isBefore(Instant.now())) {\n+                    publishPeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Add some jitter as an initial delay. If the fleet has a lot of devices associated to it, we don't want\n+        // all the devices to send the periodic publish of metrics at the same time.\n+        long initialDelay = RandomUtils.nextLong(0, periodicPublishMetricsIntervalSec);\n+        periodicPublishMetricsFuture = ses.scheduleWithFixedDelay(this::publishPeriodicMetrics, initialDelay,\n+                periodicPublishMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Helper for metrics aggregator. Also used in tests.\n+     */\n+\n+     void aggregatePeriodicMetrics() {\n+        long timeStamp = Instant.now().toEpochMilli();\n+        long lastAgg = Coerce.toLong(getPeriodicAggregateTimeTopic());\n+        this.metricsAggregator.aggregateMetrics(lastAgg, timeStamp);\n+        getPeriodicAggregateTimeTopic().withValue(timeStamp);\n+    }\n+\n+    /**\n+     * Helper for metrics uploader. Also used in tests.\n+     */\n+     void publishPeriodicMetrics() {\n+        if (!isConnected.get()) {\n+            logger.atInfo().log(\"Cannot publish the metrics: MQTT Connection interrupted.\");\n+            return;\n+        }\n+        long timeStamp = Instant.now().toEpochMilli();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f6f8fa609fd963745b7444ac83769f270db472d"}, "originalPosition": 199}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1Mjk4Nw==", "bodyText": "needs synchronization", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486752987", "createdAt": "2020-09-11T03:32:43Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,293 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    @Getter\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 30;\n+    @Getter\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter\n+    private  static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 120;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    @Getter\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicEmitSystemMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicEmitKernelMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+    private final KernelMetricsEmitter kernelMetricsEmitter;\n+    private final MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder().schema(\"2020-07-30\").build();\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics              root configuration topic for this service\n+     * @param mqttClient          {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     * @param ses {@link ScheduledExecutorService}\n+     * @param kernelMetricsEmitter {@link KernelMetricsEmitter}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration,\n+                        ScheduledExecutorService ses, KernelMetricsEmitter kernelMetricsEmitter) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        this.kernelMetricsEmitter = kernelMetricsEmitter;\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            // If the aggregation interval is reconfigured, cancel the previously scheduled job.\n+            if (periodicAggregateMetricsFuture != null) {\n+            periodicAggregateMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitSystemMetricsFuture != null) {\n+                periodicEmitSystemMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitKernelMetricsFuture != null) {\n+                periodicEmitKernelMetricsFuture.cancel(false);\n+            }\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    emitPeriodicSystemMetrics();\n+                    emitPeriodicKernelMetrics();\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Start emitting metrics with no delay. This is device specific where metrics are stored in files.\n+        periodicEmitSystemMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicSystemMetrics, 0,\n+                    periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        periodicEmitKernelMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicKernelMetrics, 0,\n+                periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        // As the time based metrics (eg. System metrics) are emitted with the same interval as aggregation, start\n+        // aggregating the metrics after at least one data point is emitted. So, the initial delay to aggregate the\n+        // metrics can be made equal to the interval. This is device specific where the metrics are stored in files.\n+        periodicAggregateMetricsFuture = ses.scheduleWithFixedDelay(this::aggregatePeriodicMetrics,\n+                periodicAggregateMetricsIntervalSec, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Schedules the publishing of metrics based on the configured publish interval or the mqtt connection status.\n+     */\n+    private void schedulePeriodicPublishMetrics(boolean isReconfiguredOrConnectionResumed) {\n+        // If we missed to publish the metrics due to connection loss or if the publish interval is reconfigured,\n+        // cancel the previously scheduled job.\n+        synchronized (periodicPublishMetricsInProgressLock) {\n+            if (periodicPublishMetricsFuture != null) {\n+                periodicPublishMetricsFuture.cancel(false);\n+            }\n+        }\n+        if (isReconfiguredOrConnectionResumed) {\n+            synchronized (periodicPublishMetricsInProgressLock) {\n+                Instant lastPeriodicPubTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicPublishTimeTopic()));\n+                if (lastPeriodicPubTime.plusSeconds(periodicPublishMetricsIntervalSec)\n+                        .isBefore(Instant.now())) {\n+                    publishPeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Add some jitter as an initial delay. If the fleet has a lot of devices associated to it, we don't want\n+        // all the devices to send the periodic publish of metrics at the same time.\n+        long initialDelay = RandomUtils.nextLong(0, periodicPublishMetricsIntervalSec);\n+        periodicPublishMetricsFuture = ses.scheduleWithFixedDelay(this::publishPeriodicMetrics, initialDelay,\n+                periodicPublishMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Helper for metrics aggregator. Also used in tests.\n+     */\n+\n+     void aggregatePeriodicMetrics() {\n+        long timeStamp = Instant.now().toEpochMilli();\n+        long lastAgg = Coerce.toLong(getPeriodicAggregateTimeTopic());\n+        this.metricsAggregator.aggregateMetrics(lastAgg, timeStamp);\n+        getPeriodicAggregateTimeTopic().withValue(timeStamp);\n+    }\n+\n+    /**\n+     * Helper for metrics uploader. Also used in tests.\n+     */\n+     void publishPeriodicMetrics() {\n+        if (!isConnected.get()) {\n+            logger.atInfo().log(\"Cannot publish the metrics: MQTT Connection interrupted.\");\n+            return;\n+        }\n+        long timeStamp = Instant.now().toEpochMilli();\n+        long lastPublish = Coerce.toLong(getPeriodicPublishTimeTopic());\n+        Map<Long, List<MetricsAggregator.AggregatedMetric>> metricsToPublishMap =\n+                this.metricsUploader.getAggregatedMetrics(lastPublish, timeStamp);\n+        getPeriodicPublishTimeTopic().withValue(timeStamp);\n+        try {\n+            logger.atInfo().log(new ObjectMapper().writeValueAsString(metricsToPublishMap.get(timeStamp)));\n+        } catch (JsonProcessingException e) {\n+            logger.atTrace().log(\"Invalid message format\", e);\n+        }\n+        // Publish only if the collected metrics are not empty.\n+        if (!metricsToPublishMap.get(timeStamp).isEmpty()) {\n+            this.publisher.publish(aggregatedMetricsChunk, metricsToPublishMap.get(timeStamp));\n+        }\n+    }\n+\n+    /**\n+     * Helper for system metrics emitter. Also used in tests.\n+     */\n+     void emitPeriodicSystemMetrics() {\n+        this.systemMetricsEmitter.emitMetrics();\n+    }\n+\n+    /**\n+     * Helper for kernel metrics emitter. Also used in tests.\n+     */\n+     void emitPeriodicKernelMetrics() {\n+        this.kernelMetricsEmitter.emitMetrics();\n+    }\n+\n+    private Topic getPeriodicPublishTimeTopic() {\n+        return config.lookup(RUNTIME_STORE_NAMESPACE_TOPIC, TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC)\n+                .dflt(Instant.now().toEpochMilli());\n+    }\n+\n+    private Topic getPeriodicAggregateTimeTopic() {\n+        return config.lookup(RUNTIME_STORE_NAMESPACE_TOPIC, TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC)\n+                .dflt(Instant.now().toEpochMilli());\n+    }\n+\n+    private void updateThingNameAndPublishTopic(String newThingName) {\n+        if (newThingName != null) {\n+            thingName = newThingName;\n+            updateTopic = telemetryMetricsPublishTopic.replace(\"{thingName}\", thingName);\n+            this.publisher.setUpdateTopic(updateTopic);\n+        }\n+    }\n+\n+    @Override\n+    public void startup() throws InterruptedException {\n+        this.systemMetricsEmitter.collectSystemMetrics();\n+        this.kernelMetricsEmitter.collectKernelComponentState();\n+        topics.lookup(RUNTIME_STORE_NAMESPACE_TOPIC, TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC)\n+                .dflt(DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC)\n+                .subscribe((why, newv) -> {\n+                    periodicAggregateMetricsIntervalSec = Coerce.toInt(newv);\n+                    if (periodicAggregateMetricsFuture != null) {\n+                        schedulePeriodicAggregateMetrics(true);\n+                    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f6f8fa609fd963745b7444ac83769f270db472d"}, "originalPosition": 257}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1MzAzNQ==", "bodyText": "sync", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486753035", "createdAt": "2020-09-11T03:32:50Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,293 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    @Getter\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 30;\n+    @Getter\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter\n+    private  static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 120;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    @Getter\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicEmitSystemMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicEmitKernelMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+    private final KernelMetricsEmitter kernelMetricsEmitter;\n+    private final MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder().schema(\"2020-07-30\").build();\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics              root configuration topic for this service\n+     * @param mqttClient          {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     * @param ses {@link ScheduledExecutorService}\n+     * @param kernelMetricsEmitter {@link KernelMetricsEmitter}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration,\n+                        ScheduledExecutorService ses, KernelMetricsEmitter kernelMetricsEmitter) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        this.kernelMetricsEmitter = kernelMetricsEmitter;\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            // If the aggregation interval is reconfigured, cancel the previously scheduled job.\n+            if (periodicAggregateMetricsFuture != null) {\n+            periodicAggregateMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitSystemMetricsFuture != null) {\n+                periodicEmitSystemMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitKernelMetricsFuture != null) {\n+                periodicEmitKernelMetricsFuture.cancel(false);\n+            }\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    emitPeriodicSystemMetrics();\n+                    emitPeriodicKernelMetrics();\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Start emitting metrics with no delay. This is device specific where metrics are stored in files.\n+        periodicEmitSystemMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicSystemMetrics, 0,\n+                    periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        periodicEmitKernelMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicKernelMetrics, 0,\n+                periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        // As the time based metrics (eg. System metrics) are emitted with the same interval as aggregation, start\n+        // aggregating the metrics after at least one data point is emitted. So, the initial delay to aggregate the\n+        // metrics can be made equal to the interval. This is device specific where the metrics are stored in files.\n+        periodicAggregateMetricsFuture = ses.scheduleWithFixedDelay(this::aggregatePeriodicMetrics,\n+                periodicAggregateMetricsIntervalSec, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Schedules the publishing of metrics based on the configured publish interval or the mqtt connection status.\n+     */\n+    private void schedulePeriodicPublishMetrics(boolean isReconfiguredOrConnectionResumed) {\n+        // If we missed to publish the metrics due to connection loss or if the publish interval is reconfigured,\n+        // cancel the previously scheduled job.\n+        synchronized (periodicPublishMetricsInProgressLock) {\n+            if (periodicPublishMetricsFuture != null) {\n+                periodicPublishMetricsFuture.cancel(false);\n+            }\n+        }\n+        if (isReconfiguredOrConnectionResumed) {\n+            synchronized (periodicPublishMetricsInProgressLock) {\n+                Instant lastPeriodicPubTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicPublishTimeTopic()));\n+                if (lastPeriodicPubTime.plusSeconds(periodicPublishMetricsIntervalSec)\n+                        .isBefore(Instant.now())) {\n+                    publishPeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Add some jitter as an initial delay. If the fleet has a lot of devices associated to it, we don't want\n+        // all the devices to send the periodic publish of metrics at the same time.\n+        long initialDelay = RandomUtils.nextLong(0, periodicPublishMetricsIntervalSec);\n+        periodicPublishMetricsFuture = ses.scheduleWithFixedDelay(this::publishPeriodicMetrics, initialDelay,\n+                periodicPublishMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Helper for metrics aggregator. Also used in tests.\n+     */\n+\n+     void aggregatePeriodicMetrics() {\n+        long timeStamp = Instant.now().toEpochMilli();\n+        long lastAgg = Coerce.toLong(getPeriodicAggregateTimeTopic());\n+        this.metricsAggregator.aggregateMetrics(lastAgg, timeStamp);\n+        getPeriodicAggregateTimeTopic().withValue(timeStamp);\n+    }\n+\n+    /**\n+     * Helper for metrics uploader. Also used in tests.\n+     */\n+     void publishPeriodicMetrics() {\n+        if (!isConnected.get()) {\n+            logger.atInfo().log(\"Cannot publish the metrics: MQTT Connection interrupted.\");\n+            return;\n+        }\n+        long timeStamp = Instant.now().toEpochMilli();\n+        long lastPublish = Coerce.toLong(getPeriodicPublishTimeTopic());\n+        Map<Long, List<MetricsAggregator.AggregatedMetric>> metricsToPublishMap =\n+                this.metricsUploader.getAggregatedMetrics(lastPublish, timeStamp);\n+        getPeriodicPublishTimeTopic().withValue(timeStamp);\n+        try {\n+            logger.atInfo().log(new ObjectMapper().writeValueAsString(metricsToPublishMap.get(timeStamp)));\n+        } catch (JsonProcessingException e) {\n+            logger.atTrace().log(\"Invalid message format\", e);\n+        }\n+        // Publish only if the collected metrics are not empty.\n+        if (!metricsToPublishMap.get(timeStamp).isEmpty()) {\n+            this.publisher.publish(aggregatedMetricsChunk, metricsToPublishMap.get(timeStamp));\n+        }\n+    }\n+\n+    /**\n+     * Helper for system metrics emitter. Also used in tests.\n+     */\n+     void emitPeriodicSystemMetrics() {\n+        this.systemMetricsEmitter.emitMetrics();\n+    }\n+\n+    /**\n+     * Helper for kernel metrics emitter. Also used in tests.\n+     */\n+     void emitPeriodicKernelMetrics() {\n+        this.kernelMetricsEmitter.emitMetrics();\n+    }\n+\n+    private Topic getPeriodicPublishTimeTopic() {\n+        return config.lookup(RUNTIME_STORE_NAMESPACE_TOPIC, TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC)\n+                .dflt(Instant.now().toEpochMilli());\n+    }\n+\n+    private Topic getPeriodicAggregateTimeTopic() {\n+        return config.lookup(RUNTIME_STORE_NAMESPACE_TOPIC, TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC)\n+                .dflt(Instant.now().toEpochMilli());\n+    }\n+\n+    private void updateThingNameAndPublishTopic(String newThingName) {\n+        if (newThingName != null) {\n+            thingName = newThingName;\n+            updateTopic = telemetryMetricsPublishTopic.replace(\"{thingName}\", thingName);\n+            this.publisher.setUpdateTopic(updateTopic);\n+        }\n+    }\n+\n+    @Override\n+    public void startup() throws InterruptedException {\n+        this.systemMetricsEmitter.collectSystemMetrics();\n+        this.kernelMetricsEmitter.collectKernelComponentState();\n+        topics.lookup(RUNTIME_STORE_NAMESPACE_TOPIC, TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC)\n+                .dflt(DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC)\n+                .subscribe((why, newv) -> {\n+                    periodicAggregateMetricsIntervalSec = Coerce.toInt(newv);\n+                    if (periodicAggregateMetricsFuture != null) {\n+                        schedulePeriodicAggregateMetrics(true);\n+                    }\n+                });\n+        topics.lookup(RUNTIME_STORE_NAMESPACE_TOPIC, TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC)\n+                .dflt(DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC)\n+                .subscribe((why, newv) -> {\n+                    periodicPublishMetricsIntervalSec = Coerce.toInt(newv);\n+                    if (periodicPublishMetricsFuture != null) {\n+                        schedulePeriodicPublishMetrics(true);\n+                    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f6f8fa609fd963745b7444ac83769f270db472d"}, "originalPosition": 265}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1MzE0NA==", "bodyText": "formatting", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486753144", "createdAt": "2020-09-11T03:33:21Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,194 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.MetricDataPoint;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.text.NumberFormat;\n+import java.text.ParseException;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+public class MetricsAggregator {\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    private final ObjectMapper objectMapper = new ObjectMapper();\n+\n+    /**\n+     * This method stores the aggregated data points of the metrics emitted over the interval.\n+     *\n+     * @param lastAgg timestamp at which the last aggregation was done.\n+     * @param currTimestamp timestamp at which the current aggregation is initiated.\n+     */\n+    public void aggregateMetrics(long lastAgg, long currTimestamp) {\n+        for (TelemetryNamespace namespace : TelemetryNamespace.values()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<MetricDataPoint>> metrics = new HashMap<>();\n+            MetricDataPoint mdp;\n+            try {\n+                List<Path> paths = Files\n+                        .walk(TelemetryConfig.getTelemetryDirectory())\n+                        .filter(Files::isRegularFile)\n+                        .filter(path -> {\n+                            Object fileName = null;\n+                            if (path != null) {\n+                                fileName = path.getFileName();\n+                            }\n+                            if (fileName == null) {\n+                                fileName = \"\";\n+                            }\n+                            return fileName.toString().startsWith(namespace.toString());\n+                        }).collect(Collectors.toList());\n+                for (Path path :paths) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f6f8fa609fd963745b7444ac83769f270db472d"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1MzUxNg==", "bodyText": "Deserialize into EvergreenStructuredLogMessage then EvergreenMetricsMessage", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486753516", "createdAt": "2020-09-11T03:34:58Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,194 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.MetricDataPoint;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.text.NumberFormat;\n+import java.text.ParseException;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+public class MetricsAggregator {\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    private final ObjectMapper objectMapper = new ObjectMapper();\n+\n+    /**\n+     * This method stores the aggregated data points of the metrics emitted over the interval.\n+     *\n+     * @param lastAgg timestamp at which the last aggregation was done.\n+     * @param currTimestamp timestamp at which the current aggregation is initiated.\n+     */\n+    public void aggregateMetrics(long lastAgg, long currTimestamp) {\n+        for (TelemetryNamespace namespace : TelemetryNamespace.values()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<MetricDataPoint>> metrics = new HashMap<>();\n+            MetricDataPoint mdp;\n+            try {\n+                List<Path> paths = Files\n+                        .walk(TelemetryConfig.getTelemetryDirectory())\n+                        .filter(Files::isRegularFile)\n+                        .filter(path -> {\n+                            Object fileName = null;\n+                            if (path != null) {\n+                                fileName = path.getFileName();\n+                            }\n+                            if (fileName == null) {\n+                                fileName = \"\";\n+                            }\n+                            return fileName.toString().startsWith(namespace.toString());\n+                        }).collect(Collectors.toList());\n+                for (Path path :paths) {\n+                    // Read from the Telemetry/namespace*.log file.\n+                    // TODO : Read only those files that are modified after the last aggregation.\n+                    // file.lastModified() behavior is platform dependent.\n+                    List<String> logs = Files.lines(Paths.get(path.toString())).collect(Collectors.toList());\n+                    for (String log : logs) {\n+                        try {\n+                        /*\n+\n+                        {\"thread\":\"main\",\"level\":\"TRACE\",\"eventType\":null,\n+\n+                        \"message\":\"{\\\"M\\\":{\\\"NS\\\":\\\"SystemMetrics\\\",\\\"N\\\":\\\"CpuUsage\\\",\\\"U\\\":\\\"Percent\\\",\n+\n+                        \\\"A\\\":\\\"Average\\\"},\\\"V\\\":123,\\\"TS\\\":1599613654270}\",\"contexts\":{},\n+\n+                        \"loggerName\":\"Metrics-french fries\",\"timestamp\":1599613654270,\"cause\":null}\n+\n+                         */\n+                        mdp = objectMapper.readValue(objectMapper.readTree(log).get(\"message\").asText(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f6f8fa609fd963745b7444ac83769f270db472d"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1NDA5OA==", "bodyText": "Why not use the classes that already exist in the logger?", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486754098", "createdAt": "2020-09-11T03:37:13Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,194 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.MetricDataPoint;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.text.NumberFormat;\n+import java.text.ParseException;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+public class MetricsAggregator {\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    private final ObjectMapper objectMapper = new ObjectMapper();\n+\n+    /**\n+     * This method stores the aggregated data points of the metrics emitted over the interval.\n+     *\n+     * @param lastAgg timestamp at which the last aggregation was done.\n+     * @param currTimestamp timestamp at which the current aggregation is initiated.\n+     */\n+    public void aggregateMetrics(long lastAgg, long currTimestamp) {\n+        for (TelemetryNamespace namespace : TelemetryNamespace.values()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<MetricDataPoint>> metrics = new HashMap<>();\n+            MetricDataPoint mdp;\n+            try {\n+                List<Path> paths = Files\n+                        .walk(TelemetryConfig.getTelemetryDirectory())\n+                        .filter(Files::isRegularFile)\n+                        .filter(path -> {\n+                            Object fileName = null;\n+                            if (path != null) {\n+                                fileName = path.getFileName();\n+                            }\n+                            if (fileName == null) {\n+                                fileName = \"\";\n+                            }\n+                            return fileName.toString().startsWith(namespace.toString());\n+                        }).collect(Collectors.toList());\n+                for (Path path :paths) {\n+                    // Read from the Telemetry/namespace*.log file.\n+                    // TODO : Read only those files that are modified after the last aggregation.\n+                    // file.lastModified() behavior is platform dependent.\n+                    List<String> logs = Files.lines(Paths.get(path.toString())).collect(Collectors.toList());\n+                    for (String log : logs) {\n+                        try {\n+                        /*\n+\n+                        {\"thread\":\"main\",\"level\":\"TRACE\",\"eventType\":null,\n+\n+                        \"message\":\"{\\\"M\\\":{\\\"NS\\\":\\\"SystemMetrics\\\",\\\"N\\\":\\\"CpuUsage\\\",\\\"U\\\":\\\"Percent\\\",\n+\n+                        \\\"A\\\":\\\"Average\\\"},\\\"V\\\":123,\\\"TS\\\":1599613654270}\",\"contexts\":{},\n+\n+                        \"loggerName\":\"Metrics-french fries\",\"timestamp\":1599613654270,\"cause\":null}\n+\n+                         */\n+                        mdp = objectMapper.readValue(objectMapper.readTree(log).get(\"message\").asText(),\n+                                MetricDataPoint.class);\n+                        // Avoid the metrics that are emitted at/after the currTimestamp and before the\n+                        // aggregation interval\n+                        if (mdp != null && currTimestamp > mdp.getTimestamp() && mdp.getTimestamp() >= lastAgg) {\n+                            metrics.computeIfAbsent(mdp.getMetric().getName(), k -> new ArrayList<>()).add(mdp);\n+                        }\n+                    } catch (IOException e) {\n+                            logger.atError().log(\"Unable to parse the metric log.\", e);\n+                        }\n+                    }\n+                }\n+                aggMetrics.setMetricNamespace(namespace);\n+                aggMetrics.setTimestamp(currTimestamp);\n+                aggMetrics.setMetrics(doAggregation(metrics));\n+                metricFactory.logMetrics(new TelemetryLoggerMessage(aggMetrics));\n+            } catch (IOException e) {\n+                logger.atError().log(\"Unable to parse the emitted metric log file.\", e);\n+            }\n+        }\n+    }\n+\n+    private List<Metric> doAggregation(Map<TelemetryMetricName, List<MetricDataPoint>> metrics) {\n+        List<Metric> aggMetrics = new ArrayList<>();\n+        for (Map.Entry<TelemetryMetricName, List<MetricDataPoint>> metric : metrics.entrySet()) {\n+            TelemetryMetricName metricName = metric.getKey();\n+            List<MetricDataPoint> mdp = metric.getValue();\n+            TelemetryAggregation telemetryAggregation = mdp.get(0).getMetric().getAggregation();\n+            double aggregation = 0;\n+            if (telemetryAggregation.equals(TelemetryAggregation.Average)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> format(a.getValue()))\n+                        .sum();\n+                if (!mdp.isEmpty()) {\n+                    aggregation = (double) aggregation / mdp.size();\n+                }\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Sum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> format(a.getValue()))\n+                        .sum();\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Maximum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> format(a.getValue()))\n+                        .max()\n+                        .getAsDouble();\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Minimum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> format(a.getValue()))\n+                        .min()\n+                        .getAsDouble();\n+            }\n+            Metric m = Metric.builder()\n+                    .metricName(metricName)\n+                    .metricUnit(mdp.get(0).getMetric().getUnit())\n+                    .value(aggregation)\n+                    .build();\n+            aggMetrics.add(m);\n+        }\n+        return aggMetrics;\n+    }\n+\n+    @Data\n+    @Builder\n+    @NoArgsConstructor\n+    @AllArgsConstructor\n+    public static class AggregatedMetric {\n+        @JsonProperty(\"TS\")\n+        private Long timestamp;\n+        @JsonProperty(\"NS\")\n+        private TelemetryNamespace metricNamespace;\n+        @JsonProperty(\"M\")\n+        private List<Metric> metrics;\n+    }\n+\n+    @Data\n+    @NoArgsConstructor\n+    @AllArgsConstructor\n+    @Builder\n+    public static class Metric {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f6f8fa609fd963745b7444ac83769f270db472d"}, "originalPosition": 168}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1NDEzNg==", "bodyText": "This is not resolved", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486754136", "createdAt": "2020-09-11T03:37:26Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,196 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.MetricDataPoint;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.text.NumberFormat;\n+import java.text.ParseException;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+public class MetricsAggregator {\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private static final int MILLI_SECONDS = 1000;\n+    MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+\n+    /**\n+     * This method stores the aggregated data points of the metrics emitted over the interval.\n+     *\n+     * @param aggregationIntervalSec periodic interval in seconds for the aggregating the metrics\n+     * @param currentTimestamp timestamp at which the aggregate is initiated\n+     */\n+    public void aggregateMetrics(int aggregationIntervalSec, long currentTimestamp) {\n+        int aggregationIntervalMilliSec = aggregationIntervalSec * MILLI_SECONDS;\n+        for (TelemetryNamespace namespace : TelemetryNamespace.values()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<MetricDataPoint>> metrics = new HashMap<>();\n+            try {\n+                Stream<Path> paths = Files\n+                        .walk(MetricFactory.getTelemetryDirectory())\n+                        .filter(Files::isRegularFile)\n+                        .filter(path -> {\n+                            Object fileName = null;\n+                            if (path != null) {\n+                                fileName = path.getFileName();\n+                            }\n+                            if (fileName == null) {\n+                                fileName = \"\";\n+                            }\n+                            return fileName.toString().startsWith(namespace.toString());\n+                        });\n+                paths.forEach((path) -> {\n+                    /*\n+                     Read from the file at Telemetry/namespace*.log\n+                     Read only modified files and aggregate only new values based on the last aggregated time.\n+                     */\n+                    if (currentTimestamp - new File(path.toString()).lastModified() <= aggregationIntervalMilliSec) {\n+                        try {\n+                            for (String log :\n+                                    Files.lines(Paths.get(path.toString())).collect(Collectors.toList())) {\n+                                /*\n+                                [0]  [1] [2]        [3]          [4]         [5]             [6]\n+                                2020 Aug 28 12:08:21,520-0700 [TRACE] (pool-3-thread-4) Metrics-KernelComponents:\n+\n+                                [7]\n+                                {\"M\":{\"NS\": \"KernelComponents\",\"N\":\"NumberOfComponentsStopping\",\"U\":\"Count\"},\n+                                \"V\":0,\"TS\":1598598501520}. {}\n+                                 */\n+                                MetricDataPoint mdp = new ObjectMapper()\n+                                        .readValue(log.split(\" \")[7], MetricDataPoint.class);\n+                                if (mdp.getMetric() != null\n+                                        && currentTimestamp - mdp.getTimestamp() <= aggregationIntervalMilliSec) {\n+                                        metrics.computeIfAbsent(mdp.getMetric().getMetricName(),\n+                                                k -> new ArrayList<>()).add(mdp);\n+                                }\n+                            }\n+                        } catch (IOException e) {\n+                            logger.atError().log(e);\n+                        }\n+                    }\n+                });\n+                aggMetrics.setMetricNamespace(namespace);\n+                aggMetrics.setTimestamp(currentTimestamp);\n+                aggMetrics.setMetrics(doAggregation(metrics));\n+                metricFactory.logMetrics(new TelemetryLoggerMessage(aggMetrics));\n+            } catch (IOException e) {\n+                logger.atError().log(e);\n+            }\n+        }\n+    }\n+\n+    private List<Metric> doAggregation(Map<TelemetryMetricName, List<MetricDataPoint>> metrics) {\n+        List<Metric> aggMetrics = new ArrayList<>();\n+        for (Map.Entry<TelemetryMetricName, List<MetricDataPoint>> metric : metrics.entrySet()) {\n+            TelemetryMetricName metricName = metric.getKey();\n+            List<MetricDataPoint> mdp = metric.getValue();\n+            TelemetryAggregation telemetryAggregation = mdp.get(0).getMetric().getMetricAggregation();\n+            Object aggregation = 0;\n+            if (telemetryAggregation.equals(TelemetryAggregation.Average)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> format(a.getValue()))\n+                        .sum();\n+                if (!mdp.isEmpty()) {\n+                    aggregation = (double) aggregation / mdp.size();\n+                }\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Sum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> format(a.getValue()))\n+                        .sum();\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Maximum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> format(a.getValue()))\n+                        .max()\n+                        .getAsDouble();\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Minimum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> format(a.getValue()))\n+                        .min()\n+                        .getAsDouble();\n+            }\n+\n+            Metric m = Metric.builder()\n+                    .metricName(metricName)\n+                    .metricUnit(mdp.get(0).getMetric().getMetricUnit())\n+                    .value(aggregation)\n+                    .build();\n+            aggMetrics.add(m);\n+        }\n+        return aggMetrics;\n+    }\n+\n+    @Data\n+    @Builder\n+    @NoArgsConstructor\n+    @AllArgsConstructor\n+    public static class AggregatedMetric {\n+        @JsonProperty(\"TS\")\n+        private Long timestamp;\n+        @JsonProperty(\"NS\")\n+        private TelemetryNamespace metricNamespace;\n+        @JsonProperty(\"M\")\n+        private List<Metric> metrics;\n+    }\n+\n+    @Data\n+    @NoArgsConstructor\n+    @AllArgsConstructor\n+    @Builder\n+    public static class Metric {\n+        @JsonProperty(\"N\")\n+        private TelemetryMetricName metricName;\n+        @JsonProperty(\"V\")\n+        private Object value;\n+        @JsonProperty(\"U\")\n+        private TelemetryUnit metricUnit;\n+    }\n+\n+    /**\n+     * Helper function to process the value of the metric object during aggregation.\n+     * @param value metric data point value.\n+     * @return converted value of the object to double. Returns 0 if invalid.\n+     */\n+    public double format(Object value) {\n+        double val = 0;\n+        if (value != null) {\n+            try {\n+                 val = NumberFormat.getInstance().parse(value.toString()).doubleValue();\n+                return val;\n+            } catch (ParseException e) {\n+                logger.atError().log(\"Error parsing the metric value: \" + e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0ODMxMA=="}, "originalCommit": {"oid": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f"}, "originalPosition": 191}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1NDI3Mg==", "bodyText": "use Coerce.toDouble", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486754272", "createdAt": "2020-09-11T03:37:59Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,194 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.MetricDataPoint;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.text.NumberFormat;\n+import java.text.ParseException;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+public class MetricsAggregator {\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    private final ObjectMapper objectMapper = new ObjectMapper();\n+\n+    /**\n+     * This method stores the aggregated data points of the metrics emitted over the interval.\n+     *\n+     * @param lastAgg timestamp at which the last aggregation was done.\n+     * @param currTimestamp timestamp at which the current aggregation is initiated.\n+     */\n+    public void aggregateMetrics(long lastAgg, long currTimestamp) {\n+        for (TelemetryNamespace namespace : TelemetryNamespace.values()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<MetricDataPoint>> metrics = new HashMap<>();\n+            MetricDataPoint mdp;\n+            try {\n+                List<Path> paths = Files\n+                        .walk(TelemetryConfig.getTelemetryDirectory())\n+                        .filter(Files::isRegularFile)\n+                        .filter(path -> {\n+                            Object fileName = null;\n+                            if (path != null) {\n+                                fileName = path.getFileName();\n+                            }\n+                            if (fileName == null) {\n+                                fileName = \"\";\n+                            }\n+                            return fileName.toString().startsWith(namespace.toString());\n+                        }).collect(Collectors.toList());\n+                for (Path path :paths) {\n+                    // Read from the Telemetry/namespace*.log file.\n+                    // TODO : Read only those files that are modified after the last aggregation.\n+                    // file.lastModified() behavior is platform dependent.\n+                    List<String> logs = Files.lines(Paths.get(path.toString())).collect(Collectors.toList());\n+                    for (String log : logs) {\n+                        try {\n+                        /*\n+\n+                        {\"thread\":\"main\",\"level\":\"TRACE\",\"eventType\":null,\n+\n+                        \"message\":\"{\\\"M\\\":{\\\"NS\\\":\\\"SystemMetrics\\\",\\\"N\\\":\\\"CpuUsage\\\",\\\"U\\\":\\\"Percent\\\",\n+\n+                        \\\"A\\\":\\\"Average\\\"},\\\"V\\\":123,\\\"TS\\\":1599613654270}\",\"contexts\":{},\n+\n+                        \"loggerName\":\"Metrics-french fries\",\"timestamp\":1599613654270,\"cause\":null}\n+\n+                         */\n+                        mdp = objectMapper.readValue(objectMapper.readTree(log).get(\"message\").asText(),\n+                                MetricDataPoint.class);\n+                        // Avoid the metrics that are emitted at/after the currTimestamp and before the\n+                        // aggregation interval\n+                        if (mdp != null && currTimestamp > mdp.getTimestamp() && mdp.getTimestamp() >= lastAgg) {\n+                            metrics.computeIfAbsent(mdp.getMetric().getName(), k -> new ArrayList<>()).add(mdp);\n+                        }\n+                    } catch (IOException e) {\n+                            logger.atError().log(\"Unable to parse the metric log.\", e);\n+                        }\n+                    }\n+                }\n+                aggMetrics.setMetricNamespace(namespace);\n+                aggMetrics.setTimestamp(currTimestamp);\n+                aggMetrics.setMetrics(doAggregation(metrics));\n+                metricFactory.logMetrics(new TelemetryLoggerMessage(aggMetrics));\n+            } catch (IOException e) {\n+                logger.atError().log(\"Unable to parse the emitted metric log file.\", e);\n+            }\n+        }\n+    }\n+\n+    private List<Metric> doAggregation(Map<TelemetryMetricName, List<MetricDataPoint>> metrics) {\n+        List<Metric> aggMetrics = new ArrayList<>();\n+        for (Map.Entry<TelemetryMetricName, List<MetricDataPoint>> metric : metrics.entrySet()) {\n+            TelemetryMetricName metricName = metric.getKey();\n+            List<MetricDataPoint> mdp = metric.getValue();\n+            TelemetryAggregation telemetryAggregation = mdp.get(0).getMetric().getAggregation();\n+            double aggregation = 0;\n+            if (telemetryAggregation.equals(TelemetryAggregation.Average)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> format(a.getValue()))\n+                        .sum();\n+                if (!mdp.isEmpty()) {\n+                    aggregation = (double) aggregation / mdp.size();\n+                }\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Sum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> format(a.getValue()))\n+                        .sum();\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Maximum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> format(a.getValue()))\n+                        .max()\n+                        .getAsDouble();\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Minimum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> format(a.getValue()))\n+                        .min()\n+                        .getAsDouble();\n+            }\n+            Metric m = Metric.builder()\n+                    .metricName(metricName)\n+                    .metricUnit(mdp.get(0).getMetric().getUnit())\n+                    .value(aggregation)\n+                    .build();\n+            aggMetrics.add(m);\n+        }\n+        return aggMetrics;\n+    }\n+\n+    @Data\n+    @Builder\n+    @NoArgsConstructor\n+    @AllArgsConstructor\n+    public static class AggregatedMetric {\n+        @JsonProperty(\"TS\")\n+        private Long timestamp;\n+        @JsonProperty(\"NS\")\n+        private TelemetryNamespace metricNamespace;\n+        @JsonProperty(\"M\")\n+        private List<Metric> metrics;\n+    }\n+\n+    @Data\n+    @NoArgsConstructor\n+    @AllArgsConstructor\n+    @Builder\n+    public static class Metric {\n+        @JsonProperty(\"N\")\n+        private TelemetryMetricName metricName;\n+        @JsonProperty(\"V\")\n+        private Object value;\n+        @JsonProperty(\"U\")\n+        private TelemetryUnit metricUnit;\n+    }\n+\n+    /**\n+     * Helper function to process the value of the metric object during aggregation.\n+     * @param value metric data point value.\n+     * @return converted value of the object to double. Returns 0 if invalid.\n+     */\n+    public double format(Object value) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f6f8fa609fd963745b7444ac83769f270db472d"}, "originalPosition": 182}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1NDY3MQ==", "bodyText": "Please add a README.md file under telemetry to explain what all this is doing. I'm quite confused why we have 2 classes that are reading files from the FS. The aggregator and uploader. Why can't we keep more of this in memory?", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486754671", "createdAt": "2020-09-11T03:39:47Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsUploader.java", "diffHunk": "@@ -0,0 +1,89 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static com.aws.iot.evergreen.telemetry.MetricsAggregator.AGGREGATE_METRICS_FILE;\n+\n+public class MetricsUploader {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f6f8fa609fd963745b7444ac83769f270db472d"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1NDc5Mg==", "bodyText": "Why are aggregates written to a file?", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486754792", "createdAt": "2020-09-11T03:40:15Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsUploader.java", "diffHunk": "@@ -0,0 +1,89 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static com.aws.iot.evergreen.telemetry.MetricsAggregator.AGGREGATE_METRICS_FILE;\n+\n+public class MetricsUploader {\n+    public static final Logger logger = LogManager.getLogger(MetricsUploader.class);\n+    private final ObjectMapper objectMapper = new ObjectMapper();\n+\n+    /**\n+     * This function returns the set of all the aggregated metric data points that are to be published to the cloud\n+     * since the last upload.\n+     *\n+     * @param lastPublish timestamp at which the last publish was done.\n+     * @param currTimestamp timestamp at which the current publish is initiated.\n+     */\n+    public Map<Long,List<MetricsAggregator.AggregatedMetric>> getAggregatedMetrics(long lastPublish,\n+                                                                                   long currTimestamp) {\n+        Map<Long,List<MetricsAggregator.AggregatedMetric>> aggUploadMetrics = new HashMap<>();\n+        MetricsAggregator.AggregatedMetric am;\n+        try {\n+            List<Path> paths = Files\n+                    .walk(TelemetryConfig.getTelemetryDirectory())\n+                    .filter(Files::isRegularFile)\n+                    .filter((path) -> {\n+                        Object fileName = null;\n+                        if (path != null) {\n+                            fileName = path.getFileName();\n+                        }\n+                        if (fileName == null) {\n+                            fileName = \"\";\n+                        }\n+                        return fileName.toString().startsWith(AGGREGATE_METRICS_FILE);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f6f8fa609fd963745b7444ac83769f270db472d"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1NDgxOQ==", "bodyText": "formatting", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486754819", "createdAt": "2020-09-11T03:40:19Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsUploader.java", "diffHunk": "@@ -0,0 +1,89 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static com.aws.iot.evergreen.telemetry.MetricsAggregator.AGGREGATE_METRICS_FILE;\n+\n+public class MetricsUploader {\n+    public static final Logger logger = LogManager.getLogger(MetricsUploader.class);\n+    private final ObjectMapper objectMapper = new ObjectMapper();\n+\n+    /**\n+     * This function returns the set of all the aggregated metric data points that are to be published to the cloud\n+     * since the last upload.\n+     *\n+     * @param lastPublish timestamp at which the last publish was done.\n+     * @param currTimestamp timestamp at which the current publish is initiated.\n+     */\n+    public Map<Long,List<MetricsAggregator.AggregatedMetric>> getAggregatedMetrics(long lastPublish,\n+                                                                                   long currTimestamp) {\n+        Map<Long,List<MetricsAggregator.AggregatedMetric>> aggUploadMetrics = new HashMap<>();\n+        MetricsAggregator.AggregatedMetric am;\n+        try {\n+            List<Path> paths = Files\n+                    .walk(TelemetryConfig.getTelemetryDirectory())\n+                    .filter(Files::isRegularFile)\n+                    .filter((path) -> {\n+                        Object fileName = null;\n+                        if (path != null) {\n+                            fileName = path.getFileName();\n+                        }\n+                        if (fileName == null) {\n+                            fileName = \"\";\n+                        }\n+                        return fileName.toString().startsWith(AGGREGATE_METRICS_FILE);\n+                    }).collect(Collectors.toList());\n+            for (Path path :paths) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f6f8fa609fd963745b7444ac83769f270db472d"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1NTAwNg==", "bodyText": "This is not resolved. The previous iteration of our metrics library handled this case.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486755006", "createdAt": "2020-09-11T03:41:07Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/SystemMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,81 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import oshi.SystemInfo;\n+import oshi.hardware.CentralProcessor;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+public class SystemMetricsEmitter {\n+    private static final int MB_CONVERTER = 1024 * 1024;\n+    private static final int PERCENTAGE_CONVERTER = 100;\n+    private static String SYSTEM_METRICS_STORE = TelemetryNamespace.SystemMetrics.toString();\n+    private static CentralProcessor cpu = new SystemInfo().getHardware().getProcessor();\n+    private static SystemInfo systemInfo = new SystemInfo();\n+    private static long[] previousTicks = new long[CentralProcessor.TickType.values().length];\n+    private static Map<TelemetryMetricName, Object> systemMetricsData = new HashMap<>();\n+    private static Map<TelemetryMetricName, MetricDataBuilder> systemMetrics = new HashMap<>();\n+\n+    /**\n+     * Create system metrics.\n+     */\n+    protected void collectSystemMetrics() {\n+        Metric systemMetric = Metric.builder()\n+                .metricNamespace(TelemetryNamespace.SystemMetrics)\n+                .metricName(TelemetryMetricName.CpuUsage)\n+                .metricUnit(TelemetryUnit.Percent)\n+                .metricAggregation(TelemetryAggregation.Average)\n+                .build();\n+        MetricDataBuilder mdb = new MetricFactory(SYSTEM_METRICS_STORE).addMetric(systemMetric);\n+        systemMetrics.put(TelemetryMetricName.CpuUsage, mdb);\n+\n+        systemMetric = Metric.builder()\n+                .metricNamespace(TelemetryNamespace.SystemMetrics)\n+                .metricName(TelemetryMetricName.TotalNumberOfFDs)\n+                .metricUnit(TelemetryUnit.Count)\n+                .metricAggregation(TelemetryAggregation.Average)\n+                .build();\n+        mdb = new MetricFactory(SYSTEM_METRICS_STORE).addMetric(systemMetric);\n+        systemMetrics.put(TelemetryMetricName.TotalNumberOfFDs, mdb);\n+\n+        systemMetric = Metric.builder()\n+                .metricNamespace(TelemetryNamespace.SystemMetrics)\n+                .metricName(TelemetryMetricName.SystemMemUsage)\n+                .metricUnit(TelemetryUnit.Megabytes)\n+                .metricAggregation(TelemetryAggregation.Average)\n+                .build();\n+        mdb = new MetricFactory(SYSTEM_METRICS_STORE).addMetric(systemMetric);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA1MDA3NQ=="}, "originalCommit": {"oid": "1d0e4d73b348dfcd8edc3d9af58d5c3135f3421f"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1NTIzOA==", "bodyText": "what is the Object which is the value?", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486755238", "createdAt": "2020-09-11T03:42:11Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/SystemMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,79 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import oshi.SystemInfo;\n+import oshi.hardware.CentralProcessor;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+public class SystemMetricsEmitter {\n+    private static final int MB_CONVERTER = 1024 * 1024;\n+    private static final int PERCENTAGE_CONVERTER = 100;\n+    private static final String SYSTEM_METRICS_STORE = TelemetryNamespace.SystemMetrics.toString();\n+    private static final CentralProcessor cpu = new SystemInfo().getHardware().getProcessor();\n+    private static final SystemInfo systemInfo = new SystemInfo();\n+    private final Map<TelemetryMetricName, Object> systemMetricsData = new HashMap<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f6f8fa609fd963745b7444ac83769f270db472d"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1NTg2OA==", "bodyText": "Neither of these maps needs to exist. You can just do all of this in an easier to read, plainly procedural way.\nmake metric with value\nmake MDB\nadd metric to MDB\nemit metric\n\nThis should be way way easier than what you've implemented", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486755868", "createdAt": "2020-09-11T03:45:00Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/SystemMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,79 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import oshi.SystemInfo;\n+import oshi.hardware.CentralProcessor;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+public class SystemMetricsEmitter {\n+    private static final int MB_CONVERTER = 1024 * 1024;\n+    private static final int PERCENTAGE_CONVERTER = 100;\n+    private static final String SYSTEM_METRICS_STORE = TelemetryNamespace.SystemMetrics.toString();\n+    private static final CentralProcessor cpu = new SystemInfo().getHardware().getProcessor();\n+    private static final SystemInfo systemInfo = new SystemInfo();\n+    private final Map<TelemetryMetricName, Object> systemMetricsData = new HashMap<>();\n+    private final Map<TelemetryMetricName, MetricDataBuilder> systemMetrics = new HashMap<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f6f8fa609fd963745b7444ac83769f270db472d"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1NjE2Mw==", "bodyText": "add EGExtension", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486756163", "createdAt": "2020-09-11T03:46:00Z", "author": {"login": "MikeDombo"}, "path": "src/test/java/com/aws/iot/evergreen/telemetry/MetricsAggregatorTest.java", "diffHunk": "@@ -0,0 +1,146 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+\n+@ExtendWith(MockitoExtension.class)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f6f8fa609fd963745b7444ac83769f270db472d"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1NjIzNg==", "bodyText": "Don't initialize here. Just do it in the field and make it static and final", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486756236", "createdAt": "2020-09-11T03:46:20Z", "author": {"login": "MikeDombo"}, "path": "src/test/java/com/aws/iot/evergreen/telemetry/MetricsAggregatorTest.java", "diffHunk": "@@ -0,0 +1,146 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+\n+@ExtendWith(MockitoExtension.class)\n+public class MetricsAggregatorTest {\n+    @TempDir\n+    protected Path tempRootDir;\n+    private ObjectMapper mapper;\n+\n+    @BeforeEach\n+    public void setup() {\n+        System.setProperty(\"root\", tempRootDir.toAbsolutePath().toString());\n+        mapper = new ObjectMapper();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f6f8fa609fd963745b7444ac83769f270db472d"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1NjQ0OQ==", "bodyText": "all of these are backwards. It is expected, then actual value in assertions", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486756449", "createdAt": "2020-09-11T03:46:55Z", "author": {"login": "MikeDombo"}, "path": "src/test/java/com/aws/iot/evergreen/telemetry/MetricsAggregatorTest.java", "diffHunk": "@@ -0,0 +1,146 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+\n+@ExtendWith(MockitoExtension.class)\n+public class MetricsAggregatorTest {\n+    @TempDir\n+    protected Path tempRootDir;\n+    private ObjectMapper mapper;\n+\n+    @BeforeEach\n+    public void setup() {\n+        System.setProperty(\"root\", tempRootDir.toAbsolutePath().toString());\n+        mapper = new ObjectMapper();\n+    }\n+\n+    @Test\n+    public void GIVEN_system_metrics_WHEN_aggregate_THEN_aggregate_only_the_latest_values()\n+            throws InterruptedException, IOException {\n+        //Create a sample file with system metrics so we can test the freshness of the file and logs\n+        //with respect to the current timestamp\n+        long lastAgg = Instant.now().toEpochMilli();\n+        Metric m = new Metric(TelemetryNamespace.SystemMetrics, TelemetryMetricName.CpuUsage,\n+                TelemetryUnit.Percent, TelemetryAggregation.Sum);\n+        MetricDataBuilder mdb1 = new MetricFactory(TelemetryNamespace.SystemMetrics.toString()).addMetric(m);\n+        m = new Metric(TelemetryNamespace.SystemMetrics, TelemetryMetricName.SystemMemUsage,\n+                TelemetryUnit.Megabytes, TelemetryAggregation.Average);\n+        MetricDataBuilder mdb2 = new MetricFactory(TelemetryNamespace.SystemMetrics.toString()).addMetric(m);\n+        m = new Metric(TelemetryNamespace.SystemMetrics, TelemetryMetricName.TotalNumberOfFDs,\n+                TelemetryUnit.Count, TelemetryAggregation.Maximum);\n+        MetricDataBuilder mdb3 = new MetricFactory(TelemetryNamespace.SystemMetrics.toString()).addMetric(m);\n+        mdb1.putMetricData(10).emit();\n+        mdb2.putMetricData(2000).emit();\n+        mdb3.putMetricData(4000).emit();\n+        mdb1.putMetricData(20).emit();\n+        mdb2.putMetricData(3000).emit();\n+        mdb3.putMetricData(5000).emit();\n+        mdb1.putMetricData(30).emit();\n+        mdb2.putMetricData(4000).emit();\n+        mdb3.putMetricData(6000).emit();\n+        MetricsAggregator ma = new MetricsAggregator();\n+        long currTimestamp = Instant.now().toEpochMilli();\n+        ma.aggregateMetrics(lastAgg, currTimestamp);\n+        String path = TelemetryConfig.getTelemetryDirectory().toString() + \"/AggregateMetrics.log\";\n+        List<String> list = Files.lines(Paths.get(path)).collect(Collectors.toList());\n+        assertEquals(list.size(), TelemetryNamespace.values().length); // Metrics are aggregated based on the namespace.\n+        for (String s : list) {\n+            MetricsAggregator.AggregatedMetric am = mapper.readValue(mapper.readTree(s).get(\"message\").asText(),\n+                    MetricsAggregator.AggregatedMetric.class);\n+            if (am.getMetricNamespace().equals(TelemetryNamespace.SystemMetrics)) {\n+                assertEquals(am.getMetrics().size(), 3); // Three system metrics\n+                for (MetricsAggregator.Metric metrics : am.getMetrics()) {\n+                    if (metrics.getMetricName().equals(TelemetryMetricName.CpuUsage)) {\n+                        assertEquals(metrics.getValue(), (double) 60);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f6f8fa609fd963745b7444ac83769f270db472d"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1NjUwMQ==", "bodyText": "backwards", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486756501", "createdAt": "2020-09-11T03:47:08Z", "author": {"login": "MikeDombo"}, "path": "src/test/java/com/aws/iot/evergreen/telemetry/MetricsAggregatorTest.java", "diffHunk": "@@ -0,0 +1,146 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+\n+@ExtendWith(MockitoExtension.class)\n+public class MetricsAggregatorTest {\n+    @TempDir\n+    protected Path tempRootDir;\n+    private ObjectMapper mapper;\n+\n+    @BeforeEach\n+    public void setup() {\n+        System.setProperty(\"root\", tempRootDir.toAbsolutePath().toString());\n+        mapper = new ObjectMapper();\n+    }\n+\n+    @Test\n+    public void GIVEN_system_metrics_WHEN_aggregate_THEN_aggregate_only_the_latest_values()\n+            throws InterruptedException, IOException {\n+        //Create a sample file with system metrics so we can test the freshness of the file and logs\n+        //with respect to the current timestamp\n+        long lastAgg = Instant.now().toEpochMilli();\n+        Metric m = new Metric(TelemetryNamespace.SystemMetrics, TelemetryMetricName.CpuUsage,\n+                TelemetryUnit.Percent, TelemetryAggregation.Sum);\n+        MetricDataBuilder mdb1 = new MetricFactory(TelemetryNamespace.SystemMetrics.toString()).addMetric(m);\n+        m = new Metric(TelemetryNamespace.SystemMetrics, TelemetryMetricName.SystemMemUsage,\n+                TelemetryUnit.Megabytes, TelemetryAggregation.Average);\n+        MetricDataBuilder mdb2 = new MetricFactory(TelemetryNamespace.SystemMetrics.toString()).addMetric(m);\n+        m = new Metric(TelemetryNamespace.SystemMetrics, TelemetryMetricName.TotalNumberOfFDs,\n+                TelemetryUnit.Count, TelemetryAggregation.Maximum);\n+        MetricDataBuilder mdb3 = new MetricFactory(TelemetryNamespace.SystemMetrics.toString()).addMetric(m);\n+        mdb1.putMetricData(10).emit();\n+        mdb2.putMetricData(2000).emit();\n+        mdb3.putMetricData(4000).emit();\n+        mdb1.putMetricData(20).emit();\n+        mdb2.putMetricData(3000).emit();\n+        mdb3.putMetricData(5000).emit();\n+        mdb1.putMetricData(30).emit();\n+        mdb2.putMetricData(4000).emit();\n+        mdb3.putMetricData(6000).emit();\n+        MetricsAggregator ma = new MetricsAggregator();\n+        long currTimestamp = Instant.now().toEpochMilli();\n+        ma.aggregateMetrics(lastAgg, currTimestamp);\n+        String path = TelemetryConfig.getTelemetryDirectory().toString() + \"/AggregateMetrics.log\";\n+        List<String> list = Files.lines(Paths.get(path)).collect(Collectors.toList());\n+        assertEquals(list.size(), TelemetryNamespace.values().length); // Metrics are aggregated based on the namespace.\n+        for (String s : list) {\n+            MetricsAggregator.AggregatedMetric am = mapper.readValue(mapper.readTree(s).get(\"message\").asText(),\n+                    MetricsAggregator.AggregatedMetric.class);\n+            if (am.getMetricNamespace().equals(TelemetryNamespace.SystemMetrics)) {\n+                assertEquals(am.getMetrics().size(), 3); // Three system metrics\n+                for (MetricsAggregator.Metric metrics : am.getMetrics()) {\n+                    if (metrics.getMetricName().equals(TelemetryMetricName.CpuUsage)) {\n+                        assertEquals(metrics.getValue(), (double) 60);\n+                    } else if (metrics.getMetricName().equals(TelemetryMetricName.SystemMemUsage)) {\n+                        assertEquals(metrics.getValue(), (double) 3000);\n+                    } else if (metrics.getMetricName().equals(TelemetryMetricName.TotalNumberOfFDs)) {\n+                        assertEquals((double) metrics.getValue(), (double) 6000);\n+                    }\n+                }\n+            }\n+        }\n+        lastAgg = currTimestamp;\n+        Thread.sleep(1000);\n+        long currentTimestamp = Instant.now().toEpochMilli();\n+        // Aggregate values within 1 second interval at this timestamp with 1\n+        ma.aggregateMetrics(lastAgg, currentTimestamp);\n+        list = Files.lines(Paths.get(path)).collect(Collectors.toList());\n+        assertEquals(list.size(), 8); // AggregateMetrics.log is appended with the latest aggregations.\n+        for (String s : list) {\n+            MetricsAggregator.AggregatedMetric am = mapper.readValue(mapper.readTree(s).get(\"message\").asText(),\n+                    MetricsAggregator.AggregatedMetric.class);\n+            if (am.getTimestamp() == currentTimestamp && am.getMetricNamespace().equals(TelemetryNamespace.SystemMetrics)) {\n+                assertEquals(am.getMetrics().size(), 0); // There is no aggregation as there are no latest values", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f6f8fa609fd963745b7444ac83769f270db472d"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1NjUyNg==", "bodyText": "backwards", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486756526", "createdAt": "2020-09-11T03:47:13Z", "author": {"login": "MikeDombo"}, "path": "src/test/java/com/aws/iot/evergreen/telemetry/MetricsAggregatorTest.java", "diffHunk": "@@ -0,0 +1,146 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+\n+@ExtendWith(MockitoExtension.class)\n+public class MetricsAggregatorTest {\n+    @TempDir\n+    protected Path tempRootDir;\n+    private ObjectMapper mapper;\n+\n+    @BeforeEach\n+    public void setup() {\n+        System.setProperty(\"root\", tempRootDir.toAbsolutePath().toString());\n+        mapper = new ObjectMapper();\n+    }\n+\n+    @Test\n+    public void GIVEN_system_metrics_WHEN_aggregate_THEN_aggregate_only_the_latest_values()\n+            throws InterruptedException, IOException {\n+        //Create a sample file with system metrics so we can test the freshness of the file and logs\n+        //with respect to the current timestamp\n+        long lastAgg = Instant.now().toEpochMilli();\n+        Metric m = new Metric(TelemetryNamespace.SystemMetrics, TelemetryMetricName.CpuUsage,\n+                TelemetryUnit.Percent, TelemetryAggregation.Sum);\n+        MetricDataBuilder mdb1 = new MetricFactory(TelemetryNamespace.SystemMetrics.toString()).addMetric(m);\n+        m = new Metric(TelemetryNamespace.SystemMetrics, TelemetryMetricName.SystemMemUsage,\n+                TelemetryUnit.Megabytes, TelemetryAggregation.Average);\n+        MetricDataBuilder mdb2 = new MetricFactory(TelemetryNamespace.SystemMetrics.toString()).addMetric(m);\n+        m = new Metric(TelemetryNamespace.SystemMetrics, TelemetryMetricName.TotalNumberOfFDs,\n+                TelemetryUnit.Count, TelemetryAggregation.Maximum);\n+        MetricDataBuilder mdb3 = new MetricFactory(TelemetryNamespace.SystemMetrics.toString()).addMetric(m);\n+        mdb1.putMetricData(10).emit();\n+        mdb2.putMetricData(2000).emit();\n+        mdb3.putMetricData(4000).emit();\n+        mdb1.putMetricData(20).emit();\n+        mdb2.putMetricData(3000).emit();\n+        mdb3.putMetricData(5000).emit();\n+        mdb1.putMetricData(30).emit();\n+        mdb2.putMetricData(4000).emit();\n+        mdb3.putMetricData(6000).emit();\n+        MetricsAggregator ma = new MetricsAggregator();\n+        long currTimestamp = Instant.now().toEpochMilli();\n+        ma.aggregateMetrics(lastAgg, currTimestamp);\n+        String path = TelemetryConfig.getTelemetryDirectory().toString() + \"/AggregateMetrics.log\";\n+        List<String> list = Files.lines(Paths.get(path)).collect(Collectors.toList());\n+        assertEquals(list.size(), TelemetryNamespace.values().length); // Metrics are aggregated based on the namespace.\n+        for (String s : list) {\n+            MetricsAggregator.AggregatedMetric am = mapper.readValue(mapper.readTree(s).get(\"message\").asText(),\n+                    MetricsAggregator.AggregatedMetric.class);\n+            if (am.getMetricNamespace().equals(TelemetryNamespace.SystemMetrics)) {\n+                assertEquals(am.getMetrics().size(), 3); // Three system metrics\n+                for (MetricsAggregator.Metric metrics : am.getMetrics()) {\n+                    if (metrics.getMetricName().equals(TelemetryMetricName.CpuUsage)) {\n+                        assertEquals(metrics.getValue(), (double) 60);\n+                    } else if (metrics.getMetricName().equals(TelemetryMetricName.SystemMemUsage)) {\n+                        assertEquals(metrics.getValue(), (double) 3000);\n+                    } else if (metrics.getMetricName().equals(TelemetryMetricName.TotalNumberOfFDs)) {\n+                        assertEquals((double) metrics.getValue(), (double) 6000);\n+                    }\n+                }\n+            }\n+        }\n+        lastAgg = currTimestamp;\n+        Thread.sleep(1000);\n+        long currentTimestamp = Instant.now().toEpochMilli();\n+        // Aggregate values within 1 second interval at this timestamp with 1\n+        ma.aggregateMetrics(lastAgg, currentTimestamp);\n+        list = Files.lines(Paths.get(path)).collect(Collectors.toList());\n+        assertEquals(list.size(), 8); // AggregateMetrics.log is appended with the latest aggregations.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f6f8fa609fd963745b7444ac83769f270db472d"}, "originalPosition": 92}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1NjU5Mw==", "bodyText": "add EGExtension", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486756593", "createdAt": "2020-09-11T03:47:29Z", "author": {"login": "MikeDombo"}, "path": "src/test/java/com/aws/iot/evergreen/telemetry/MetricsUploaderTest.java", "diffHunk": "@@ -0,0 +1,112 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.nio.file.Path;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+\n+import static com.aws.iot.evergreen.telemetry.MetricsAggregator.AGGREGATE_METRICS_FILE;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n+\n+@ExtendWith(MockitoExtension.class)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f6f8fa609fd963745b7444ac83769f270db472d"}, "originalPosition": 24}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg2NDU2MTY2", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-486456166", "createdAt": "2020-09-11T03:54:32Z", "commit": {"oid": "1f6f8fa609fd963745b7444ac83769f270db472d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQwMzo1NDozM1rOHQNX0w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQwMzo1NDozM1rOHQNX0w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1ODM1NQ==", "bodyText": "cloud deployment is very slow. If you don't absolutely need it; don't use it. Just setup the kernel with some config. You may need to stop extending the base class to make this test run faster without stuff that it doesn't need", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r486758355", "createdAt": "2020-09-11T03:54:33Z", "author": {"login": "MikeDombo"}, "path": "src/integrationtests/java/com/aws/iot/evergreen/integrationtests/e2e/telemetry/MetricsAgentTest.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ *  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *   SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.integrationtests.e2e.telemetry;\n+\n+import com.amazonaws.services.evergreen.model.PackageMetaData;\n+import com.amazonaws.services.evergreen.model.PublishConfigurationResult;\n+import com.amazonaws.services.evergreen.model.SetConfigurationRequest;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.State;\n+import com.aws.iot.evergreen.integrationtests.e2e.BaseE2ETestCase;\n+import com.aws.iot.evergreen.integrationtests.e2e.util.IotJobsUtils;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.mqtt.SubscribeRequest;\n+import com.aws.iot.evergreen.telemetry.MetricsAgent;\n+import com.aws.iot.evergreen.telemetry.MetricsAggregator;\n+import com.aws.iot.evergreen.telemetry.MetricsPayload;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.Timeout;\n+import software.amazon.awssdk.crt.mqtt.MqttMessage;\n+import software.amazon.awssdk.services.iot.model.JobExecutionStatus;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static com.aws.iot.evergreen.kernel.EvergreenService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.github.grantwest.eventually.EventuallyLambdaMatcher.eventuallyEval;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+\n+// TODO : Complete the tests\n+@SuppressWarnings(\"PMD.CloseResource\")\n+@Tag(\"E2E\")\n+public class MetricsAgentTest extends BaseE2ETestCase {\n+    private static final ObjectMapper DESERIALIZER = new ObjectMapper();\n+\n+    @AfterEach\n+    void afterEach() {\n+        try {\n+            if (kernel != null) {\n+                kernel.shutdown();\n+            }\n+        } finally {\n+            // Cleanup all IoT thing resources we created\n+            cleanup();\n+        }\n+    }\n+\n+    @BeforeEach\n+    void launchKernel() throws Exception {\n+        initKernel();\n+        kernel.launch();\n+\n+        // TODO: Without this sleep, DeploymentService sometimes is not able to pick up new IoT job created here,\n+        // causing these tests to fail. There may be a race condition between DeploymentService startup logic and\n+        // creating new IoT job here.\n+        TimeUnit.SECONDS.sleep(10);\n+    }\n+\n+    @Timeout(value = 10, unit = TimeUnit.MINUTES)\n+    @Test\n+    void GIVEN_kernel_running_with_deployed_services_WHEN_deployment_finishes_THEN_fss_data_is_uploaded() throws Exception {\n+        MqttClient client = kernel.getContext().get(MqttClient.class);\n+\n+        CountDownLatch cdl = new CountDownLatch(2);\n+        AtomicReference<List<MqttMessage>> mqttMessagesList = new AtomicReference<>();\n+        mqttMessagesList.set(new ArrayList<>());\n+        // TODO: Make the publish topic configurable?\n+        client.subscribe(SubscribeRequest.builder()\n+                .topic(MetricsAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC.replace(\"{thingName}\", thingInfo.getThingName()))\n+                .callback((m) -> {\n+                    cdl.countDown();\n+                    mqttMessagesList.get().add(m);\n+                }).build());\n+        Topics maTopics = kernel.getConfig().lookupTopics(SERVICES_NAMESPACE_TOPIC,\n+                MetricsAgent.METRICS_AGENT_SERVICE_TOPICS);\n+        maTopics.lookup(PARAMETERS_CONFIG_KEY, MetricsAgent.getTELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC())\n+                .withValue(5);\n+        maTopics.lookup(PARAMETERS_CONFIG_KEY, MetricsAgent.getTELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC())\n+                .withValue(3);\n+        //Deployment to have some services running in Kernel\n+        SetConfigurationRequest setRequest1 = new SetConfigurationRequest()\n+                .withTargetName(thingGroupName)\n+                .withTargetType(THING_GROUP_TARGET_TYPE)\n+                .addPackagesEntry(\"CustomerApp\", new PackageMetaData().withRootComponent(true).withVersion(\"1.0.0\")\n+                        .withConfiguration(\"{\\\"sampleText\\\":\\\"FCS integ test\\\"}\"))\n+                .addPackagesEntry(\"SomeService\", new PackageMetaData().withRootComponent(true).withVersion(\"1.0.0\"));\n+        PublishConfigurationResult publishResult1 = setAndPublishFleetConfiguration(setRequest1);\n+\n+        IotJobsUtils.waitForJobExecutionStatusToSatisfy(iotClient, publishResult1.getJobId(), thingInfo.getThingName(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f6f8fa609fd963745b7444ac83769f270db472d"}, "originalPosition": 102}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a0fd2089874ae7ca1570e35caa8bbdf42fed1545", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/a0fd2089874ae7ca1570e35caa8bbdf42fed1545", "committedDate": "2020-09-11T11:10:30Z", "message": "Removed MetricsUploader class + add readme + update tests + sync + format code"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg2OTExNjk0", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-486911694", "createdAt": "2020-09-11T15:32:56Z", "commit": {"oid": "a0fd2089874ae7ca1570e35caa8bbdf42fed1545"}, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQxNTozMjo1NlrOHQjufg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQxNTozODoyNFrOHQj7pQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzEyNDYwNg==", "bodyText": "just keep the lock for L139", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r487124606", "createdAt": "2020-09-11T15:32:56Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,300 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrassv2/health/json\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 30;\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 120;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private final KernelMetricsEmitter kernelMetricsEmitter;\n+    private final MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder().schema(\"2020-07-30\").build();\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicEmitSystemMetricsFuture = null;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicEmitKernelMetricsFuture = null;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private final MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics               root configuration topic for this service\n+     * @param mqttClient           {@link MqttClient}\n+     * @param deviceConfiguration  {@link DeviceConfiguration}\n+     * @param ses                  {@link ScheduledExecutorService}\n+     * @param kernelMetricsEmitter {@link KernelMetricsEmitter}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration,\n+                        ScheduledExecutorService ses, KernelMetricsEmitter kernelMetricsEmitter) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        this.kernelMetricsEmitter = kernelMetricsEmitter;\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            // If the aggregation interval is reconfigured, cancel the previously scheduled job.\n+            if (periodicAggregateMetricsFuture != null) {\n+                periodicAggregateMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitSystemMetricsFuture != null) {\n+                periodicEmitSystemMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitKernelMetricsFuture != null) {\n+                periodicEmitKernelMetricsFuture.cancel(false);\n+            }\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    emitPeriodicSystemMetrics();\n+                    emitPeriodicKernelMetrics();\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Start emitting metrics with no delay. This is device specific where metrics are stored in files.\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            periodicEmitSystemMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicSystemMetrics, 0,\n+                    periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        }\n+        synchronized (periodicAggregateMetricsInProgressLock) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0fd2089874ae7ca1570e35caa8bbdf42fed1545"}, "originalPosition": 143}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzEyNDcyNQ==", "bodyText": "same, just keep the lock you already are holding", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r487124725", "createdAt": "2020-09-11T15:33:07Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,300 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrassv2/health/json\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 30;\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 120;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private final KernelMetricsEmitter kernelMetricsEmitter;\n+    private final MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder().schema(\"2020-07-30\").build();\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicEmitSystemMetricsFuture = null;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicEmitKernelMetricsFuture = null;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private final MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics               root configuration topic for this service\n+     * @param mqttClient           {@link MqttClient}\n+     * @param deviceConfiguration  {@link DeviceConfiguration}\n+     * @param ses                  {@link ScheduledExecutorService}\n+     * @param kernelMetricsEmitter {@link KernelMetricsEmitter}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration,\n+                        ScheduledExecutorService ses, KernelMetricsEmitter kernelMetricsEmitter) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        this.kernelMetricsEmitter = kernelMetricsEmitter;\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            // If the aggregation interval is reconfigured, cancel the previously scheduled job.\n+            if (periodicAggregateMetricsFuture != null) {\n+                periodicAggregateMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitSystemMetricsFuture != null) {\n+                periodicEmitSystemMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitKernelMetricsFuture != null) {\n+                periodicEmitKernelMetricsFuture.cancel(false);\n+            }\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    emitPeriodicSystemMetrics();\n+                    emitPeriodicKernelMetrics();\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Start emitting metrics with no delay. This is device specific where metrics are stored in files.\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            periodicEmitSystemMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicSystemMetrics, 0,\n+                    periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        }\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            periodicEmitKernelMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicKernelMetrics, 0,\n+                    periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        }\n+        // As the time based metrics (eg. System metrics) are emitted with the same interval as aggregation, start\n+        // aggregating the metrics after at least one data point is emitted. So, the initial delay to aggregate the\n+        // metrics can be made equal to the interval. This is device specific where the metrics are stored in files.\n+        synchronized (periodicAggregateMetricsInProgressLock) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0fd2089874ae7ca1570e35caa8bbdf42fed1545"}, "originalPosition": 150}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzEyNTExOQ==", "bodyText": "since this happens a lot, maybe extract it to a method?", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r487125119", "createdAt": "2020-09-11T15:33:47Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,300 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrassv2/health/json\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 30;\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 120;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private final KernelMetricsEmitter kernelMetricsEmitter;\n+    private final MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder().schema(\"2020-07-30\").build();\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicEmitSystemMetricsFuture = null;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicEmitKernelMetricsFuture = null;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private final MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics               root configuration topic for this service\n+     * @param mqttClient           {@link MqttClient}\n+     * @param deviceConfiguration  {@link DeviceConfiguration}\n+     * @param ses                  {@link ScheduledExecutorService}\n+     * @param kernelMetricsEmitter {@link KernelMetricsEmitter}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration,\n+                        ScheduledExecutorService ses, KernelMetricsEmitter kernelMetricsEmitter) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        this.kernelMetricsEmitter = kernelMetricsEmitter;\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            // If the aggregation interval is reconfigured, cancel the previously scheduled job.\n+            if (periodicAggregateMetricsFuture != null) {\n+                periodicAggregateMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitSystemMetricsFuture != null) {\n+                periodicEmitSystemMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitKernelMetricsFuture != null) {\n+                periodicEmitKernelMetricsFuture.cancel(false);\n+            }\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    emitPeriodicSystemMetrics();\n+                    emitPeriodicKernelMetrics();\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Start emitting metrics with no delay. This is device specific where metrics are stored in files.\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            periodicEmitSystemMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicSystemMetrics, 0,\n+                    periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        }\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            periodicEmitKernelMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicKernelMetrics, 0,\n+                    periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        }\n+        // As the time based metrics (eg. System metrics) are emitted with the same interval as aggregation, start\n+        // aggregating the metrics after at least one data point is emitted. So, the initial delay to aggregate the\n+        // metrics can be made equal to the interval. This is device specific where the metrics are stored in files.\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            periodicAggregateMetricsFuture = ses.scheduleWithFixedDelay(this::aggregatePeriodicMetrics,\n+                    periodicAggregateMetricsIntervalSec, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        }\n+    }\n+\n+    /**\n+     * Schedules the publishing of metrics based on the configured publish interval or the mqtt connection status.\n+     */\n+    private void schedulePeriodicPublishMetrics(boolean isReconfiguredOrConnectionResumed) {\n+        // If we missed to publish the metrics due to connection loss or if the publish interval is reconfigured,\n+        // cancel the previously scheduled job.\n+        synchronized (periodicPublishMetricsInProgressLock) {\n+            if (periodicPublishMetricsFuture != null) {\n+                periodicPublishMetricsFuture.cancel(false);\n+            }\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0fd2089874ae7ca1570e35caa8bbdf42fed1545"}, "originalPosition": 166}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzEyNTU2Nw==", "bodyText": "drop this to debug", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r487125567", "createdAt": "2020-09-11T15:34:30Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,300 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrassv2/health/json\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 30;\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 120;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private final KernelMetricsEmitter kernelMetricsEmitter;\n+    private final MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder().schema(\"2020-07-30\").build();\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicEmitSystemMetricsFuture = null;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicEmitKernelMetricsFuture = null;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private final MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics               root configuration topic for this service\n+     * @param mqttClient           {@link MqttClient}\n+     * @param deviceConfiguration  {@link DeviceConfiguration}\n+     * @param ses                  {@link ScheduledExecutorService}\n+     * @param kernelMetricsEmitter {@link KernelMetricsEmitter}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration,\n+                        ScheduledExecutorService ses, KernelMetricsEmitter kernelMetricsEmitter) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        this.kernelMetricsEmitter = kernelMetricsEmitter;\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            // If the aggregation interval is reconfigured, cancel the previously scheduled job.\n+            if (periodicAggregateMetricsFuture != null) {\n+                periodicAggregateMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitSystemMetricsFuture != null) {\n+                periodicEmitSystemMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitKernelMetricsFuture != null) {\n+                periodicEmitKernelMetricsFuture.cancel(false);\n+            }\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    emitPeriodicSystemMetrics();\n+                    emitPeriodicKernelMetrics();\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Start emitting metrics with no delay. This is device specific where metrics are stored in files.\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            periodicEmitSystemMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicSystemMetrics, 0,\n+                    periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        }\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            periodicEmitKernelMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicKernelMetrics, 0,\n+                    periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        }\n+        // As the time based metrics (eg. System metrics) are emitted with the same interval as aggregation, start\n+        // aggregating the metrics after at least one data point is emitted. So, the initial delay to aggregate the\n+        // metrics can be made equal to the interval. This is device specific where the metrics are stored in files.\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            periodicAggregateMetricsFuture = ses.scheduleWithFixedDelay(this::aggregatePeriodicMetrics,\n+                    periodicAggregateMetricsIntervalSec, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        }\n+    }\n+\n+    /**\n+     * Schedules the publishing of metrics based on the configured publish interval or the mqtt connection status.\n+     */\n+    private void schedulePeriodicPublishMetrics(boolean isReconfiguredOrConnectionResumed) {\n+        // If we missed to publish the metrics due to connection loss or if the publish interval is reconfigured,\n+        // cancel the previously scheduled job.\n+        synchronized (periodicPublishMetricsInProgressLock) {\n+            if (periodicPublishMetricsFuture != null) {\n+                periodicPublishMetricsFuture.cancel(false);\n+            }\n+        }\n+        if (isReconfiguredOrConnectionResumed) {\n+            synchronized (periodicPublishMetricsInProgressLock) {\n+                Instant lastPeriodicPubTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicPublishTimeTopic()));\n+                if (lastPeriodicPubTime.plusSeconds(periodicPublishMetricsIntervalSec)\n+                        .isBefore(Instant.now())) {\n+                    publishPeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Add some jitter as an initial delay. If the fleet has a lot of devices associated to it, we don't want\n+        // all the devices to send the periodic publish of metrics at the same time.\n+        long initialDelay = RandomUtils.nextLong(0, periodicPublishMetricsIntervalSec);\n+        synchronized (periodicPublishMetricsInProgressLock) {\n+            periodicPublishMetricsFuture = ses.scheduleWithFixedDelay(this::publishPeriodicMetrics, initialDelay,\n+                    periodicPublishMetricsIntervalSec, TimeUnit.SECONDS);\n+        }\n+    }\n+\n+    /**\n+     * Helper for metrics aggregator. Also used in tests.\n+     */\n+    void aggregatePeriodicMetrics() {\n+        long timestamp = Instant.now().toEpochMilli();\n+        long lastAgg = Coerce.toLong(getPeriodicAggregateTimeTopic());\n+        metricsAggregator.aggregateMetrics(lastAgg, timestamp);\n+        getPeriodicAggregateTimeTopic().withValue(timestamp);\n+    }\n+\n+    /**\n+     * Helper for metrics uploader. Also used in tests.\n+     */\n+    void publishPeriodicMetrics() {\n+        if (!isConnected.get()) {\n+            logger.atInfo().log(\"Cannot publish the metrics. MQTT connection interrupted.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0fd2089874ae7ca1570e35caa8bbdf42fed1545"}, "originalPosition": 200}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzEyNTg3MQ==", "bodyText": "unresolved", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r487125871", "createdAt": "2020-09-11T15:35:01Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,293 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/evergreen/health/json\";\n+    @Getter\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 30;\n+    @Getter\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter\n+    private  static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 120;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final MetricsUploader metricsUploader = new MetricsUploader();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    @Getter\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicEmitSystemMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicEmitKernelMetricsFuture = null;\n+    @Getter\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+    private final KernelMetricsEmitter kernelMetricsEmitter;\n+    private final MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder().schema(\"2020-07-30\").build();\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics              root configuration topic for this service\n+     * @param mqttClient          {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     * @param ses {@link ScheduledExecutorService}\n+     * @param kernelMetricsEmitter {@link KernelMetricsEmitter}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration,\n+                        ScheduledExecutorService ses, KernelMetricsEmitter kernelMetricsEmitter) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        this.kernelMetricsEmitter = kernelMetricsEmitter;\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            // If the aggregation interval is reconfigured, cancel the previously scheduled job.\n+            if (periodicAggregateMetricsFuture != null) {\n+            periodicAggregateMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitSystemMetricsFuture != null) {\n+                periodicEmitSystemMetricsFuture.cancel(false);\n+            }\n+            // These are emitted based on the aggregation interval.\n+            if (periodicEmitKernelMetricsFuture != null) {\n+                periodicEmitKernelMetricsFuture.cancel(false);\n+            }\n+        }\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    emitPeriodicSystemMetrics();\n+                    emitPeriodicKernelMetrics();\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Start emitting metrics with no delay. This is device specific where metrics are stored in files.\n+        periodicEmitSystemMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicSystemMetrics, 0,\n+                    periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        periodicEmitKernelMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicKernelMetrics, 0,\n+                periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        // As the time based metrics (eg. System metrics) are emitted with the same interval as aggregation, start\n+        // aggregating the metrics after at least one data point is emitted. So, the initial delay to aggregate the\n+        // metrics can be made equal to the interval. This is device specific where the metrics are stored in files.\n+        periodicAggregateMetricsFuture = ses.scheduleWithFixedDelay(this::aggregatePeriodicMetrics,\n+                periodicAggregateMetricsIntervalSec, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Schedules the publishing of metrics based on the configured publish interval or the mqtt connection status.\n+     */\n+    private void schedulePeriodicPublishMetrics(boolean isReconfiguredOrConnectionResumed) {\n+        // If we missed to publish the metrics due to connection loss or if the publish interval is reconfigured,\n+        // cancel the previously scheduled job.\n+        synchronized (periodicPublishMetricsInProgressLock) {\n+            if (periodicPublishMetricsFuture != null) {\n+                periodicPublishMetricsFuture.cancel(false);\n+            }\n+        }\n+        if (isReconfiguredOrConnectionResumed) {\n+            synchronized (periodicPublishMetricsInProgressLock) {\n+                Instant lastPeriodicPubTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicPublishTimeTopic()));\n+                if (lastPeriodicPubTime.plusSeconds(periodicPublishMetricsIntervalSec)\n+                        .isBefore(Instant.now())) {\n+                    publishPeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Add some jitter as an initial delay. If the fleet has a lot of devices associated to it, we don't want\n+        // all the devices to send the periodic publish of metrics at the same time.\n+        long initialDelay = RandomUtils.nextLong(0, periodicPublishMetricsIntervalSec);\n+        periodicPublishMetricsFuture = ses.scheduleWithFixedDelay(this::publishPeriodicMetrics, initialDelay,\n+                periodicPublishMetricsIntervalSec, TimeUnit.SECONDS);\n+    }\n+\n+    /**\n+     * Helper for metrics aggregator. Also used in tests.\n+     */\n+\n+     void aggregatePeriodicMetrics() {\n+        long timeStamp = Instant.now().toEpochMilli();\n+        long lastAgg = Coerce.toLong(getPeriodicAggregateTimeTopic());\n+        this.metricsAggregator.aggregateMetrics(lastAgg, timeStamp);\n+        getPeriodicAggregateTimeTopic().withValue(timeStamp);\n+    }\n+\n+    /**\n+     * Helper for metrics uploader. Also used in tests.\n+     */\n+     void publishPeriodicMetrics() {\n+        if (!isConnected.get()) {\n+            logger.atInfo().log(\"Cannot publish the metrics: MQTT Connection interrupted.\");\n+            return;\n+        }\n+        long timeStamp = Instant.now().toEpochMilli();\n+        long lastPublish = Coerce.toLong(getPeriodicPublishTimeTopic());\n+        Map<Long, List<MetricsAggregator.AggregatedMetric>> metricsToPublishMap =\n+                this.metricsUploader.getAggregatedMetrics(lastPublish, timeStamp);\n+        getPeriodicPublishTimeTopic().withValue(timeStamp);\n+        try {\n+            logger.atInfo().log(new ObjectMapper().writeValueAsString(metricsToPublishMap.get(timeStamp)));\n+        } catch (JsonProcessingException e) {\n+            logger.atTrace().log(\"Invalid message format\", e);\n+        }\n+        // Publish only if the collected metrics are not empty.\n+        if (!metricsToPublishMap.get(timeStamp).isEmpty()) {\n+            this.publisher.publish(aggregatedMetricsChunk, metricsToPublishMap.get(timeStamp));\n+        }\n+    }\n+\n+    /**\n+     * Helper for system metrics emitter. Also used in tests.\n+     */\n+     void emitPeriodicSystemMetrics() {\n+        this.systemMetricsEmitter.emitMetrics();\n+    }\n+\n+    /**\n+     * Helper for kernel metrics emitter. Also used in tests.\n+     */\n+     void emitPeriodicKernelMetrics() {\n+        this.kernelMetricsEmitter.emitMetrics();\n+    }\n+\n+    private Topic getPeriodicPublishTimeTopic() {\n+        return config.lookup(RUNTIME_STORE_NAMESPACE_TOPIC, TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC)\n+                .dflt(Instant.now().toEpochMilli());\n+    }\n+\n+    private Topic getPeriodicAggregateTimeTopic() {\n+        return config.lookup(RUNTIME_STORE_NAMESPACE_TOPIC, TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC)\n+                .dflt(Instant.now().toEpochMilli());\n+    }\n+\n+    private void updateThingNameAndPublishTopic(String newThingName) {\n+        if (newThingName != null) {\n+            thingName = newThingName;\n+            updateTopic = telemetryMetricsPublishTopic.replace(\"{thingName}\", thingName);\n+            this.publisher.setUpdateTopic(updateTopic);\n+        }\n+    }\n+\n+    @Override\n+    public void startup() throws InterruptedException {\n+        this.systemMetricsEmitter.collectSystemMetrics();\n+        this.kernelMetricsEmitter.collectKernelComponentState();\n+        topics.lookup(RUNTIME_STORE_NAMESPACE_TOPIC, TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC)\n+                .dflt(DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC)\n+                .subscribe((why, newv) -> {\n+                    periodicAggregateMetricsIntervalSec = Coerce.toInt(newv);\n+                    if (periodicAggregateMetricsFuture != null) {\n+                        schedulePeriodicAggregateMetrics(true);\n+                    }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1Mjk4Nw=="}, "originalCommit": {"oid": "1f6f8fa609fd963745b7444ac83769f270db472d"}, "originalPosition": 257}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzEyNzIxNQ==", "bodyText": "this doesn't make sense. What is the point in having 2 different objects which are only usable once?\nEither this is a bug in the SDK which should be addressed or it should be simplified to a single object.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r487127215", "createdAt": "2020-09-11T15:37:07Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/README.md", "diffHunk": "@@ -0,0 +1,110 @@\n+# Telemetry\n+\n+Metrics agent(MA) is a service that is responsible for publishing telemetry data from the device to the IoT cloud via an MQTT topic. MA periodically aggregates and publishes various types of metrics related to kernel, system, mqtt and so on based on the telemetric configuration set by the customer.\n+\n+## Workflow\n+There are three major steps involved in order for the MA to publish the telemetry data.\n+  - Creating a metric and emitting the data points\n+  - Aggregating the emitted metrics\n+  - Publishing the aggregated metrics\n+\n+### Creating a metric and emitting the data points\n+Typically, metric creation and emission are component/service specific(excluding system metrcis. MA takes care of System metrics).\n+##### Create a metric\n+Each metric has to be specified with its name, namespace it belongs to, aggregation type that we want to perform on it and unit of the metric. It is enough to create a metric just once.\n+```\n+    Metric metric = Metric.builder()\n+            .namespace(TelemetryNamespace.KernelComponents)\n+            .name(TelemetryMetricName.NumberOfComponentsInstalled)\n+            .unit(TelemetryUnit.Count)\n+            .aggregation(TelemetryAggregation.Average)\n+            .build();\n+```\n+##### Emit a metric\n+Emitting a metric data point is nothing but assiging a value to the metric and writing it to the file.\n+- The name of the file is always going to be the namespace of the metric and it always resides inside the `Telemetry/` directory.\n+    > Telemetry\n+    > ___ generic.log\n+    > ___ KernelComponents.log\n+    > ___ SystemMetrics.log\n+    > ___ ...\n+\n+- The file to which the metric has to be written is specified using the `MetricFactory`. If nothing is specified, then the metrics are written to \"generic.log\" file.\n+    ```\n+    MetricFactory metricFactory = new MetricFactory(\"KernelComponents\");\n+    MetricDataBuilder mdb = metricFactory.add(metric);\n+    ```\n+    You cannot reuse this metricFactory with another metric data object as it is bound to this metric data object(mdb). It is enough to do it just once.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0fd2089874ae7ca1570e35caa8bbdf42fed1545"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzEyNzk3Mw==", "bodyText": "since there's only a single metric per datapoint, why not flatten this structure and remove the nesting?", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r487127973", "createdAt": "2020-09-11T15:38:24Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/README.md", "diffHunk": "@@ -0,0 +1,110 @@\n+# Telemetry\n+\n+Metrics agent(MA) is a service that is responsible for publishing telemetry data from the device to the IoT cloud via an MQTT topic. MA periodically aggregates and publishes various types of metrics related to kernel, system, mqtt and so on based on the telemetric configuration set by the customer.\n+\n+## Workflow\n+There are three major steps involved in order for the MA to publish the telemetry data.\n+  - Creating a metric and emitting the data points\n+  - Aggregating the emitted metrics\n+  - Publishing the aggregated metrics\n+\n+### Creating a metric and emitting the data points\n+Typically, metric creation and emission are component/service specific(excluding system metrcis. MA takes care of System metrics).\n+##### Create a metric\n+Each metric has to be specified with its name, namespace it belongs to, aggregation type that we want to perform on it and unit of the metric. It is enough to create a metric just once.\n+```\n+    Metric metric = Metric.builder()\n+            .namespace(TelemetryNamespace.KernelComponents)\n+            .name(TelemetryMetricName.NumberOfComponentsInstalled)\n+            .unit(TelemetryUnit.Count)\n+            .aggregation(TelemetryAggregation.Average)\n+            .build();\n+```\n+##### Emit a metric\n+Emitting a metric data point is nothing but assiging a value to the metric and writing it to the file.\n+- The name of the file is always going to be the namespace of the metric and it always resides inside the `Telemetry/` directory.\n+    > Telemetry\n+    > ___ generic.log\n+    > ___ KernelComponents.log\n+    > ___ SystemMetrics.log\n+    > ___ ...\n+\n+- The file to which the metric has to be written is specified using the `MetricFactory`. If nothing is specified, then the metrics are written to \"generic.log\" file.\n+    ```\n+    MetricFactory metricFactory = new MetricFactory(\"KernelComponents\");\n+    MetricDataBuilder mdb = metricFactory.add(metric);\n+    ```\n+    You cannot reuse this metricFactory with another metric data object as it is bound to this metric data object(mdb). It is enough to do it just once.\n+- Assigning a value to the metric and writing it to the file(emit) is done using `MetricDataBuilder`. You can now reuse this `MetricDataBuilder` as many times as you want to emit the data point.\n+    ```\n+    mdb.putMetricData(100).emit();\n+    mdb.putMetricData(200).emit();\n+    ```\n+Sample contents of the file `Telemetry/KernelComponents.log`\n+```\n+{\n+    \"thread\": \"pool-1-thread-1\",\n+    \"level\": \"TRACE\",\n+    \"eventType\": null,\n+    \"message\": \"{\\\"M\\\":{\\\"NS\\\":\\\"KernelComponents\\\",\\\"N\\\":\\\"NumberOfComponentsInstalled\\\",\\\"U\\\":\\\"Count\\\",\\\"A\\\":\\\"Average\\\"},\\\"V\\\":100,\\\"TS\\\":1599814408615}\",\n+    \"contexts\": {},\n+    \"loggerName\": \"Metrics-KernelComponents\",\n+    \"timestamp\": 1599814408616,\n+    \"cause\": null\n+}\n+```\n+Message part of the log corresponds to the following structure\n+```\n+Metric data point\n+|__ Metric", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a0fd2089874ae7ca1570e35caa8bbdf42fed1545"}, "originalPosition": 59}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "723efea7f1ab287252721edd3ecc80504781a724", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/723efea7f1ab287252721edd3ecc80504781a724", "committedDate": "2020-09-11T21:45:19Z", "message": "Removed MetricsUploader class + add readme + update tests + sync + format code"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2a905d731be3d86cd2c82373cb78e9953da3a675", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/2a905d731be3d86cd2c82373cb78e9953da3a675", "committedDate": "2020-09-11T21:45:49Z", "message": "Merge branch 'master' of github.com:aws/aws-greengrass-kernel into telemetry-logs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "77407ad2ac6b0145c882dd6c63db5bc65ba38f96", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/77407ad2ac6b0145c882dd6c63db5bc65ba38f96", "committedDate": "2020-09-11T21:46:32Z", "message": "Merge branch 'telemetry-logs' of github.com:aws/aws-greengrass-kernel into telemetry-logs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0885143b7846ce5bc38053c39dc261ff10a10b70", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/0885143b7846ce5bc38053c39dc261ff10a10b70", "committedDate": "2020-09-12T01:43:03Z", "message": "Reuse metric factory + clean up extra objects+ add func for sync"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg3ODcxOTkw", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-487871990", "createdAt": "2020-09-14T15:09:06Z", "commit": {"oid": "0885143b7846ce5bc38053c39dc261ff10a10b70"}, "state": "COMMENTED", "comments": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxNTowOTowN1rOHRZrKA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNFQxNTozMjowOVrOHRa0sA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAwODQ4OA==", "bodyText": "nit: renanme", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488008488", "createdAt": "2020-09-14T15:09:07Z", "author": {"login": "nikkhilmuthye"}, "path": "src/integrationtests/java/com/aws/iot/evergreen/integrationtests/e2e/telemetry/MetricsAgentTest.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ *  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *   SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.integrationtests.e2e.telemetry;\n+\n+import com.amazonaws.services.evergreen.model.PackageMetaData;\n+import com.amazonaws.services.evergreen.model.PublishConfigurationResult;\n+import com.amazonaws.services.evergreen.model.SetConfigurationRequest;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.State;\n+import com.aws.iot.evergreen.integrationtests.e2e.BaseE2ETestCase;\n+import com.aws.iot.evergreen.integrationtests.e2e.util.IotJobsUtils;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.mqtt.SubscribeRequest;\n+import com.aws.iot.evergreen.telemetry.MetricsAgent;\n+import com.aws.iot.evergreen.telemetry.MetricsAggregator;\n+import com.aws.iot.evergreen.telemetry.MetricsPayload;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.Timeout;\n+import software.amazon.awssdk.crt.mqtt.MqttMessage;\n+import software.amazon.awssdk.services.iot.model.JobExecutionStatus;\n+\n+import java.time.Duration;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static com.aws.iot.evergreen.kernel.EvergreenService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.iot.evergreen.packagemanager.KernelConfigResolver.PARAMETERS_CONFIG_KEY;\n+import static com.github.grantwest.eventually.EventuallyLambdaMatcher.eventuallyEval;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+\n+// TODO : Complete the tests\n+@SuppressWarnings(\"PMD.CloseResource\")\n+@Tag(\"E2E\")\n+public class MetricsAgentTest extends BaseE2ETestCase {\n+    private static final ObjectMapper DESERIALIZER = new ObjectMapper();\n+\n+    @AfterEach\n+    void afterEach() {\n+        try {\n+            if (kernel != null) {\n+                kernel.shutdown();\n+            }\n+        } finally {\n+            // Cleanup all IoT thing resources we created\n+            cleanup();\n+        }\n+    }\n+\n+    @BeforeEach\n+    void launchKernel() throws Exception {\n+        initKernel();\n+        kernel.launch();\n+\n+        // TODO: Without this sleep, DeploymentService sometimes is not able to pick up new IoT job created here,\n+        // causing these tests to fail. There may be a race condition between DeploymentService startup logic and\n+        // creating new IoT job here.\n+        TimeUnit.SECONDS.sleep(10);\n+    }\n+\n+    @Timeout(value = 10, unit = TimeUnit.MINUTES)\n+    @Test\n+    void GIVEN_kernel_running_with_deployed_services_WHEN_deployment_finishes_THEN_fss_data_is_uploaded() throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0885143b7846ce5bc38053c39dc261ff10a10b70"}, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAwOTk4OA==", "bodyText": "+1", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488009988", "createdAt": "2020-09-14T15:11:09Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,82 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import javax.inject.Inject;\n+\n+public class KernelMetricsEmitter {\n+    public static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+    private static final String KERNEL_COMPONENT_METRIC_STORE = TelemetryNamespace.KernelComponents.toString();\n+    private static Map<TelemetryMetricName, MetricDataBuilder> kernelMetrics = new HashMap<>();\n+    private static Map<TelemetryMetricName, Integer> kernelMetricsData = new HashMap<>();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Njc1MTgxOA=="}, "originalCommit": {"oid": "1f6f8fa609fd963745b7444ac83769f270db472d"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAxMTk5NQ==", "bodyText": "I don't believe this will is the correct way since the kernel might be emitting periodic as well as event based metrics.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488011995", "createdAt": "2020-09-14T15:13:58Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,83 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import javax.inject.Inject;\n+\n+public class KernelMetricsEmitter {\n+    public static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+    private static final String KERNEL_COMPONENT_METRIC_STORE = TelemetryNamespace.KernelComponents.toString();\n+    private static Map<TelemetryMetricName, MetricDataBuilder> kernelMetrics = new HashMap<>();\n+    private static Map<TelemetryMetricName, Integer> kernelMetricsData = new HashMap<>();\n+    private final Kernel kernel;\n+    private final MetricFactory metricFactory = new MetricFactory(KERNEL_COMPONENT_METRIC_STORE);\n+\n+    /**\n+     * Constructor for kernel metrics emitter.\n+     *\n+     * @param kernel {@link Kernel}\n+     */\n+    @Inject\n+    public KernelMetricsEmitter(Kernel kernel) {\n+        this.kernel = kernel;\n+    }\n+\n+    /**\n+     * Collect kernel metrics - Number of components running in each state.\n+     */\n+    public void collectKernelComponentState() {\n+        List<TelemetryMetricName> telemetryMetricNames =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0885143b7846ce5bc38053c39dc261ff10a10b70"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAxNTQ5NA==", "bodyText": "Create an interface for PeriodicMetricsEmitter and then implement that here and in the system metrics. Then in the Metrics Agent, you can have a list of PeriodicMetricsEmitters instead of having individual objects.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488015494", "createdAt": "2020-09-14T15:18:41Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,83 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import javax.inject.Inject;\n+\n+public class KernelMetricsEmitter {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0885143b7846ce5bc38053c39dc261ff10a10b70"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAxNjE1OQ==", "bodyText": "explain why you do this.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488016159", "createdAt": "2020-09-14T15:19:34Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,83 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import javax.inject.Inject;\n+\n+public class KernelMetricsEmitter {\n+    public static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+    private static final String KERNEL_COMPONENT_METRIC_STORE = TelemetryNamespace.KernelComponents.toString();\n+    private static Map<TelemetryMetricName, MetricDataBuilder> kernelMetrics = new HashMap<>();\n+    private static Map<TelemetryMetricName, Integer> kernelMetricsData = new HashMap<>();\n+    private final Kernel kernel;\n+    private final MetricFactory metricFactory = new MetricFactory(KERNEL_COMPONENT_METRIC_STORE);\n+\n+    /**\n+     * Constructor for kernel metrics emitter.\n+     *\n+     * @param kernel {@link Kernel}\n+     */\n+    @Inject\n+    public KernelMetricsEmitter(Kernel kernel) {\n+        this.kernel = kernel;\n+    }\n+\n+    /**\n+     * Collect kernel metrics - Number of components running in each state.\n+     */\n+    public void collectKernelComponentState() {\n+        List<TelemetryMetricName> telemetryMetricNames =\n+                TelemetryMetricName.getMetricNamesOf(TelemetryNamespace.KernelComponents);\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            Metric metric = Metric.builder()\n+                    .namespace(TelemetryNamespace.KernelComponents)\n+                    .name(telemetryMetricName)\n+                    .unit(TelemetryUnit.Count)\n+                    .aggregation(TelemetryAggregation.Average)\n+                    .build();\n+            MetricDataBuilder metricDataBuilder = metricFactory.addMetric(metric);\n+            kernelMetrics.put(telemetryMetricName, metricDataBuilder);\n+        }\n+        for (TelemetryMetricName telemetryMetricName : telemetryMetricNames) {\n+            kernelMetricsData.put(telemetryMetricName, 0);\n+        }\n+    }\n+\n+    /**\n+     * Emit kernel component state metrics.\n+     */\n+    public void emitMetrics() {\n+        Collection<EvergreenService> evergreenServices = kernel.orderedDependencies();\n+        for (EvergreenService evergreenService : evergreenServices) {\n+            String serviceState = evergreenService.getState().toString();\n+            serviceState = serviceState.charAt(0) + serviceState.substring(1).toLowerCase();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0885143b7846ce5bc38053c39dc261ff10a10b70"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAxNzIyOQ==", "bodyText": "why do you need this? Can't you use config?", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488017229", "createdAt": "2020-09-14T15:20:55Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrassv2/health/json\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 3_600;\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 86_400;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0885143b7846ce5bc38053c39dc261ff10a10b70"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAxOTA0Mg==", "bodyText": "Does not have to be separate future objects right since they are all running with the same interval? maybe a list is fine?", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488019042", "createdAt": "2020-09-14T15:23:30Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrassv2/health/json\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 3_600;\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 86_400;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private final KernelMetricsEmitter kernelMetricsEmitter;\n+    private final MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder().schema(\"2020-07-30\").build();\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicEmitSystemMetricsFuture = null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0885143b7846ce5bc38053c39dc261ff10a10b70"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAyMDkxNw==", "bodyText": "Add jitter", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488020917", "createdAt": "2020-09-14T15:26:03Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrassv2/health/json\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 3_600;\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 86_400;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private final KernelMetricsEmitter kernelMetricsEmitter;\n+    private final MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder().schema(\"2020-07-30\").build();\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicEmitSystemMetricsFuture = null;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicEmitKernelMetricsFuture = null;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private final MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics               root configuration topic for this service\n+     * @param mqttClient           {@link MqttClient}\n+     * @param deviceConfiguration  {@link DeviceConfiguration}\n+     * @param ses                  {@link ScheduledExecutorService}\n+     * @param kernelMetricsEmitter {@link KernelMetricsEmitter}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration,\n+                        ScheduledExecutorService ses, KernelMetricsEmitter kernelMetricsEmitter) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        this.kernelMetricsEmitter = kernelMetricsEmitter;\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        cancel(periodicEmitSystemMetricsFuture, periodicAggregateMetricsInProgressLock, false);\n+        cancel(periodicEmitKernelMetricsFuture, periodicAggregateMetricsInProgressLock, false);\n+        cancel(periodicAggregateMetricsFuture, periodicAggregateMetricsInProgressLock, false);\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    emitPeriodicSystemMetrics();\n+                    emitPeriodicKernelMetrics();\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            // Start emitting metrics with no delay. This is device specific where metrics are stored in files.\n+            periodicEmitSystemMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicSystemMetrics, 0,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0885143b7846ce5bc38053c39dc261ff10a10b70"}, "originalPosition": 129}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAyNjEwOQ==", "bodyText": "why are you synchronizing the cancel?", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488026109", "createdAt": "2020-09-14T15:30:32Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrassv2/health/json\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 3_600;\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 86_400;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private final KernelMetricsEmitter kernelMetricsEmitter;\n+    private final MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder().schema(\"2020-07-30\").build();\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicEmitSystemMetricsFuture = null;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicEmitKernelMetricsFuture = null;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private final MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics               root configuration topic for this service\n+     * @param mqttClient           {@link MqttClient}\n+     * @param deviceConfiguration  {@link DeviceConfiguration}\n+     * @param ses                  {@link ScheduledExecutorService}\n+     * @param kernelMetricsEmitter {@link KernelMetricsEmitter}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration,\n+                        ScheduledExecutorService ses, KernelMetricsEmitter kernelMetricsEmitter) {\n+        super(topics);\n+        this.topics = topics;\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        this.kernelMetricsEmitter = kernelMetricsEmitter;\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        cancel(periodicEmitSystemMetricsFuture, periodicAggregateMetricsInProgressLock, false);\n+        cancel(periodicEmitKernelMetricsFuture, periodicAggregateMetricsInProgressLock, false);\n+        cancel(periodicAggregateMetricsFuture, periodicAggregateMetricsInProgressLock, false);\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    emitPeriodicSystemMetrics();\n+                    emitPeriodicKernelMetrics();\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            // Start emitting metrics with no delay. This is device specific where metrics are stored in files.\n+            periodicEmitSystemMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicSystemMetrics, 0,\n+                    periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+\n+            periodicEmitKernelMetricsFuture = ses.scheduleWithFixedDelay(this::emitPeriodicKernelMetrics, 0,\n+                    periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+\n+            // As the time based metrics (eg. System metrics) are emitted with the same interval as aggregation, start\n+            // aggregating the metrics after at least one data point is emitted. So, the initial delay to aggregate the\n+            // metrics can be made equal to the interval. This is device specific where the metrics are stored in files.\n+\n+            periodicAggregateMetricsFuture = ses.scheduleWithFixedDelay(this::aggregatePeriodicMetrics,\n+                    periodicAggregateMetricsIntervalSec, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        }\n+    }\n+\n+    /**\n+     * Schedules the publishing of metrics based on the configured publish interval or the mqtt connection status.\n+     */\n+    private void schedulePeriodicPublishMetrics(boolean isReconfiguredOrConnectionResumed) {\n+        // If we missed to publish the metrics due to connection loss or if the publish interval is reconfigured,\n+        // cancel the previously scheduled job.\n+        cancel(periodicPublishMetricsFuture, periodicPublishMetricsInProgressLock, false);\n+        if (isReconfiguredOrConnectionResumed) {\n+            synchronized (periodicPublishMetricsInProgressLock) {\n+                Instant lastPeriodicPubTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicPublishTimeTopic()));\n+                if (lastPeriodicPubTime.plusSeconds(periodicPublishMetricsIntervalSec)\n+                        .isBefore(Instant.now())) {\n+                    publishPeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Add some jitter as an initial delay. If the fleet has a lot of devices associated to it, we don't want\n+        // all the devices to send the periodic publish of metrics at the same time.\n+        long initialDelay = RandomUtils.nextLong(0, periodicPublishMetricsIntervalSec);\n+        synchronized (periodicPublishMetricsInProgressLock) {\n+            periodicPublishMetricsFuture = ses.scheduleWithFixedDelay(this::publishPeriodicMetrics, initialDelay,\n+                    periodicPublishMetricsIntervalSec, TimeUnit.SECONDS);\n+        }\n+    }\n+\n+    /**\n+     * Helper for metrics aggregator. Also used in tests.\n+     */\n+    void aggregatePeriodicMetrics() {\n+        long timestamp = Instant.now().toEpochMilli();\n+        long lastAgg = Coerce.toLong(getPeriodicAggregateTimeTopic());\n+        metricsAggregator.aggregateMetrics(lastAgg, timestamp);\n+        getPeriodicAggregateTimeTopic().withValue(timestamp);\n+    }\n+\n+    /**\n+     * Helper for metrics uploader. Also used in tests.\n+     */\n+    void publishPeriodicMetrics() {\n+        if (!isConnected.get()) {\n+            logger.atDebug().log(\"Cannot publish the metrics. MQTT connection interrupted.\");\n+            return;\n+        }\n+        long timestamp = Instant.now().toEpochMilli();\n+        long lastPublish = Coerce.toLong(getPeriodicPublishTimeTopic());\n+        Map<Long, List<MetricsAggregator.AggregatedMetric>> metricsToPublishMap =\n+                metricsAggregator.getMetricsToPublish(lastPublish, timestamp);\n+        getPeriodicPublishTimeTopic().withValue(timestamp);\n+        // Publish only if the collected metrics are not empty.\n+        if (!metricsToPublishMap.get(timestamp).isEmpty()) {\n+            publisher.publish(aggregatedMetricsChunk, metricsToPublishMap.get(timestamp));\n+        }\n+    }\n+\n+    /**\n+     * Helper for system metrics emitter. Also used in tests.\n+     */\n+    void emitPeriodicSystemMetrics() {\n+        systemMetricsEmitter.emitMetrics();\n+    }\n+\n+    /**\n+     * Helper for kernel metrics emitter. Also used in tests.\n+     */\n+    void emitPeriodicKernelMetrics() {\n+        kernelMetricsEmitter.emitMetrics();\n+    }\n+\n+    private Topic getPeriodicPublishTimeTopic() {\n+        return config.lookup(RUNTIME_STORE_NAMESPACE_TOPIC, TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC)\n+                .dflt(Instant.now().toEpochMilli());\n+    }\n+\n+    private Topic getPeriodicAggregateTimeTopic() {\n+        return config.lookup(RUNTIME_STORE_NAMESPACE_TOPIC, TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC)\n+                .dflt(Instant.now().toEpochMilli());\n+    }\n+\n+    private void updateThingNameAndPublishTopic(String newThingName) {\n+        if (newThingName != null) {\n+            thingName = newThingName;\n+            updateTopic = telemetryMetricsPublishTopic.replace(\"{thingName}\", thingName);\n+            publisher.setUpdateTopic(updateTopic);\n+        }\n+    }\n+\n+    private void cancel(ScheduledFuture<?> future, Object lock, boolean immediately) {\n+        synchronized (lock) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0885143b7846ce5bc38053c39dc261ff10a10b70"}, "originalPosition": 231}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAyNjM4MQ==", "bodyText": "nit: copywrite", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488026381", "createdAt": "2020-09-14T15:30:54Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,243 @@\n+package com.aws.iot.evergreen.telemetry;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0885143b7846ce5bc38053c39dc261ff10a10b70"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAyNzMxMg==", "bodyText": "Instead of doing this, use @Builder.Default in the class.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488027312", "createdAt": "2020-09-14T15:32:09Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,280 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrassv2/health/json\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 3_600;\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 86_400;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final Topics topics;\n+    private final SystemMetricsEmitter systemMetricsEmitter = new SystemMetricsEmitter();\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private final KernelMetricsEmitter kernelMetricsEmitter;\n+    private final MetricsPayload aggregatedMetricsChunk = MetricsPayload.builder().schema(\"2020-07-30\").build();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0885143b7846ce5bc38053c39dc261ff10a10b70"}, "originalPosition": 60}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7415ab215d360b905f921bf544ab9e0d0ea85173", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/7415ab215d360b905f921bf544ab9e0d0ea85173", "committedDate": "2020-09-14T20:11:41Z", "message": "Updated code with latest sdk"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "03b0b8c9daac2ec2c7160d6ea19867fdfdab4c97", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/03b0b8c9daac2ec2c7160d6ea19867fdfdab4c97", "committedDate": "2020-09-14T20:12:00Z", "message": "Merge branch 'master' of github.com:aws/aws-greengrass-kernel into telemetry-logs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2229b1c0e1626e974c6b3f91fe299b59cc92ca8d", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/2229b1c0e1626e974c6b3f91fe299b59cc92ca8d", "committedDate": "2020-09-15T00:03:24Z", "message": "add abstraction for metrics emitter + copyrights + update tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "31fa4eef1e6347406b493f1be90ab0a45a7290fe", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/31fa4eef1e6347406b493f1be90ab0a45a7290fe", "committedDate": "2020-09-15T01:26:04Z", "message": "update readme"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7ed5f105eb4f34ee7ea49794cfd9da068a501675", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/7ed5f105eb4f34ee7ea49794cfd9da068a501675", "committedDate": "2020-09-15T01:45:47Z", "message": "add default schema value + remove topics to use config + update test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4d731cde8f9438c921195073cde509085bd39cda", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/4d731cde8f9438c921195073cde509085bd39cda", "committedDate": "2020-09-15T02:05:12Z", "message": "clean up"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a1b5c55fdac26c9652cbf13f768ac07401cf27f0", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/a1b5c55fdac26c9652cbf13f768ac07401cf27f0", "committedDate": "2020-09-15T02:53:27Z", "message": "Merge branch 'master' of github.com:aws/aws-greengrass-kernel into telemetry-logs"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg4Mjg3Nzc0", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-488287774", "createdAt": "2020-09-15T02:56:43Z", "commit": {"oid": "4d731cde8f9438c921195073cde509085bd39cda"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQwMjo1Njo0M1rOHRuq7Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQwMzowNjoyMFrOHRu0uA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM1MjQ5Mw==", "bodyText": "assert true around this.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488352493", "createdAt": "2020-09-15T02:56:43Z", "author": {"login": "MikeDombo"}, "path": "src/integrationtests/java/com/aws/iot/evergreen/integrationtests/e2e/telemetry/MetricsAgentTest.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/*\n+ *  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *   SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.integrationtests.e2e.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.State;\n+import com.aws.iot.evergreen.integrationtests.e2e.BaseE2ETestCase;\n+import com.aws.iot.evergreen.kernel.exceptions.ServiceLoadException;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.mqtt.SubscribeRequest;\n+import com.aws.iot.evergreen.telemetry.MetricsAgent;\n+import com.aws.iot.evergreen.telemetry.MetricsPayload;\n+import com.aws.iot.evergreen.testcommons.testutilities.EGExtension;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.Timeout;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import software.amazon.awssdk.crt.mqtt.MqttMessage;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static com.aws.iot.evergreen.kernel.EvergreenService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.iot.evergreen.kernel.EvergreenService.SERVICES_NAMESPACE_TOPIC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+\n+@SuppressWarnings(\"PMD.CloseResource\")\n+@ExtendWith(EGExtension.class)\n+@Tag(\"E2E\")\n+public class MetricsAgentTest extends BaseE2ETestCase {\n+    private static final ObjectMapper DESERIALIZER = new ObjectMapper();\n+\n+    @AfterEach\n+    void afterEach() {\n+        try {\n+            if (kernel != null) {\n+                kernel.shutdown();\n+            }\n+        } finally {\n+            // Cleanup all IoT thing resources we created\n+            cleanup();\n+        }\n+    }\n+\n+    @BeforeEach\n+    void launchKernel() throws Exception {\n+        initKernel();\n+        kernel.launch();\n+    }\n+\n+    @Timeout(value = 3, unit = TimeUnit.MINUTES)\n+    @Test\n+    void GIVEN_kernel_running_WHEN_metrics_agent_starts_THEN_metrics_are_published_to_Cloud() throws\n+            InterruptedException, ExecutionException, TimeoutException, ServiceLoadException {\n+        /*\n+         Metrics agent is an auto-start service. It publishes data to the cloud irrespective of the deployments.\n+         In this test, we just start the kernel and expect MA to publish time-based metrics such as system metrics and\n+         kernel component state metrics in the given interval.\n+        */\n+        MqttClient client = kernel.getContext().get(MqttClient.class);\n+        CountDownLatch cdl = new CountDownLatch(1);\n+        AtomicReference<List<MqttMessage>> mqttMessagesList = new AtomicReference<>();\n+        mqttMessagesList.set(new ArrayList<>());\n+        long aggInterval = 1;\n+        long pubInterval = 5;\n+        MetricsPayload mp = null;\n+        Topics maTopics = kernel.getConfig().lookupTopics(SERVICES_NAMESPACE_TOPIC,\n+                MetricsAgent.METRICS_AGENT_SERVICE_TOPICS);\n+        maTopics.lookup(RUNTIME_STORE_NAMESPACE_TOPIC, MetricsAgent.getTELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC())\n+                .withValue(aggInterval);\n+        maTopics.lookup(RUNTIME_STORE_NAMESPACE_TOPIC, MetricsAgent.getTELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC())\n+                .withValue(pubInterval);\n+        String telemetryTopic = MetricsAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC\n+                .replace(\"{thingName}\", thingInfo.getThingName());\n+        client.subscribe(SubscribeRequest.builder()\n+                .topic(telemetryTopic)\n+                .callback((m) -> {\n+                    cdl.countDown();\n+                    mqttMessagesList.get().add(m);\n+                })\n+                .build());\n+        cdl.await(30, TimeUnit.SECONDS);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4d731cde8f9438c921195073cde509085bd39cda"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM1MzEwNg==", "bodyText": "don't use RUNTIME_STORE_NAMESPACE_TOPIC. Use getRuntimeConfig(). Here and everywhere", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488353106", "createdAt": "2020-09-15T02:58:59Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,261 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrassv2/health/json\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 3_600;\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 86_400;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter //used in e2e\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private final MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    private final List<PeriodicMetricsEmitter> periodicMetricsEmitters = new ArrayList<>();\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics              root configuration topic for this service\n+     * @param mqttClient          {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     * @param kernel              {@link Kernel}\n+     * @param ses                 {@link ScheduledExecutorService}\n+     */\n+    @Inject\n+    public MetricsAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration, Kernel kernel,\n+                        ScheduledExecutorService ses) {\n+        super(topics);\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        periodicMetricsEmitters.add(new SystemMetricsEmitter());\n+        periodicMetricsEmitters.add(new KernelMetricsEmitter(kernel));\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        for (PeriodicMetricsEmitter emitter : periodicMetricsEmitters) {\n+            cancelJob(emitter.future, periodicAggregateMetricsInProgressLock, false);\n+        }\n+        cancelJob(periodicAggregateMetricsFuture, periodicAggregateMetricsInProgressLock, false);\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    for (PeriodicMetricsEmitter periodicMetricsEmitter : periodicMetricsEmitters) {\n+                        periodicMetricsEmitter.emitMetrics();\n+                    }\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            for (PeriodicMetricsEmitter emitter : periodicMetricsEmitters) {\n+                // Start emitting metrics with no delay. This is device specific where metrics are stored in files.\n+                emitter.future = ses.scheduleWithFixedDelay(emitter::emitMetrics, 0,\n+                        periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+            }\n+\n+            // As the time based metrics (eg. System metrics) are emitted with the same interval as aggregation, start\n+            // aggregating the metrics after at least one data point is emitted. So, the initial delay to aggregate the\n+            // metrics can be made equal to the interval. This is device specific where the metrics are stored in files.\n+            periodicAggregateMetricsFuture = ses.scheduleWithFixedDelay(this::aggregatePeriodicMetrics,\n+                    periodicAggregateMetricsIntervalSec, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        }\n+    }\n+\n+    /**\n+     * Schedules the publishing of metrics based on the configured publish interval or the mqtt connection status.\n+     */\n+    private void schedulePeriodicPublishMetrics(boolean isReconfiguredOrConnectionResumed) {\n+        // If we missed to publish the metrics due to connection loss or if the publish interval is reconfigured,\n+        // cancel the previously scheduled job.\n+        cancelJob(periodicPublishMetricsFuture, periodicPublishMetricsInProgressLock, false);\n+        if (isReconfiguredOrConnectionResumed) {\n+            synchronized (periodicPublishMetricsInProgressLock) {\n+                Instant lastPeriodicPubTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicPublishTimeTopic()));\n+                if (lastPeriodicPubTime.plusSeconds(periodicPublishMetricsIntervalSec).isBefore(Instant.now())) {\n+                    publishPeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Add some jitter as an initial delay. If the fleet has a lot of devices associated to it, we don't want\n+        // all the devices to send the periodic publish of metrics at the same time.\n+        long initialDelay = RandomUtils.nextLong(1, periodicPublishMetricsIntervalSec + 1);\n+        synchronized (periodicPublishMetricsInProgressLock) {\n+            periodicPublishMetricsFuture = ses.scheduleWithFixedDelay(this::publishPeriodicMetrics, initialDelay,\n+                    periodicPublishMetricsIntervalSec, TimeUnit.SECONDS);\n+        }\n+    }\n+\n+    /**\n+     * Helper for metrics aggregator. Also used in tests.\n+     */\n+    void aggregatePeriodicMetrics() {\n+        long timestamp = Instant.now().toEpochMilli();\n+        long lastAgg = Coerce.toLong(getPeriodicAggregateTimeTopic());\n+        metricsAggregator.aggregateMetrics(lastAgg, timestamp);\n+        getPeriodicAggregateTimeTopic().withValue(timestamp);\n+    }\n+\n+    /**\n+     * Helper for metrics uploader. Also used in tests.\n+     */\n+    void publishPeriodicMetrics() {\n+        if (!isConnected.get()) {\n+            logger.atDebug().log(\"Cannot publish the metrics. MQTT connection interrupted.\");\n+            return;\n+        }\n+        long timestamp = Instant.now().toEpochMilli();\n+        long lastPublish = Coerce.toLong(getPeriodicPublishTimeTopic());\n+        Map<Long, List<MetricsAggregator.AggregatedMetric>> metricsToPublishMap =\n+                metricsAggregator.getMetricsToPublish(lastPublish, timestamp);\n+        getPeriodicPublishTimeTopic().withValue(timestamp);\n+        // Publish only if the collected metrics are not empty.\n+        if (!metricsToPublishMap.get(timestamp).isEmpty()) {\n+            publisher.publish(MetricsPayload.builder().build(), metricsToPublishMap.get(timestamp));\n+        }\n+    }\n+\n+    private Topic getPeriodicPublishTimeTopic() {\n+        return config.lookup(RUNTIME_STORE_NAMESPACE_TOPIC, TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC)\n+                .dflt(Instant.now().toEpochMilli());\n+    }\n+\n+    private Topic getPeriodicAggregateTimeTopic() {\n+        return config.lookup(RUNTIME_STORE_NAMESPACE_TOPIC, TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC)\n+                .dflt(Instant.now().toEpochMilli());\n+    }\n+\n+    private void updateThingNameAndPublishTopic(String newThingName) {\n+        if (newThingName != null) {\n+            thingName = newThingName;\n+            updateTopic = telemetryMetricsPublishTopic.replace(\"{thingName}\", thingName);\n+            publisher.setUpdateTopic(updateTopic);\n+        }\n+    }\n+\n+    private void cancelJob(ScheduledFuture<?> future, Object lock, boolean immediately) {\n+        if (future != null) {\n+            synchronized (lock) {\n+                future.cancel(immediately);\n+            }\n+        }\n+    }\n+\n+    @Override\n+    public void startup() throws InterruptedException {\n+        for (PeriodicMetricsEmitter emitter : periodicMetricsEmitters) {\n+            emitter.buildMetrics();\n+        }\n+        config.lookup(RUNTIME_STORE_NAMESPACE_TOPIC, TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4d731cde8f9438c921195073cde509085bd39cda"}, "originalPosition": 222}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM1MzM0Mg==", "bodyText": "why Object? This is a string", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488353342", "createdAt": "2020-09-15T02:59:43Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,246 @@\n+/*\n+ * Copyright Amazon.com Inc. or its affiliates.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.EvergreenStructuredLogMessage;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private final ObjectMapper objectMapper = new ObjectMapper();\n+    MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+\n+    /**\n+     * This method stores the aggregated data points of the metrics emitted over the interval.\n+     *\n+     * @param lastAgg       timestamp at which the last aggregation was done.\n+     * @param currTimestamp timestamp at which the current aggregation is initiated.\n+     */\n+    protected void aggregateMetrics(long lastAgg, long currTimestamp) {\n+        for (TelemetryNamespace namespace : TelemetryNamespace.values()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<Metric>> metrics = new HashMap<>();\n+            Metric mdp;\n+            try {\n+                List<Path> paths = Files\n+                        .walk(TelemetryConfig.getTelemetryDirectory())\n+                        .filter(Files::isRegularFile)\n+                        .filter(path -> {\n+                            Object fileName = null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4d731cde8f9438c921195073cde509085bd39cda"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM1MzU2MA==", "bodyText": "you already have a Path. Why are you converting it to a string and then a Path again?", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488353560", "createdAt": "2020-09-15T03:00:36Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,246 @@\n+/*\n+ * Copyright Amazon.com Inc. or its affiliates.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.EvergreenStructuredLogMessage;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private final ObjectMapper objectMapper = new ObjectMapper();\n+    MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+\n+    /**\n+     * This method stores the aggregated data points of the metrics emitted over the interval.\n+     *\n+     * @param lastAgg       timestamp at which the last aggregation was done.\n+     * @param currTimestamp timestamp at which the current aggregation is initiated.\n+     */\n+    protected void aggregateMetrics(long lastAgg, long currTimestamp) {\n+        for (TelemetryNamespace namespace : TelemetryNamespace.values()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<Metric>> metrics = new HashMap<>();\n+            Metric mdp;\n+            try {\n+                List<Path> paths = Files\n+                        .walk(TelemetryConfig.getTelemetryDirectory())\n+                        .filter(Files::isRegularFile)\n+                        .filter(path -> {\n+                            Object fileName = null;\n+                            if (path != null) {\n+                                fileName = path.getFileName();\n+                            }\n+                            if (fileName == null) {\n+                                fileName = \"\";\n+                            }\n+                            return fileName.toString().startsWith(namespace.toString());\n+                        }).collect(Collectors.toList());\n+                for (Path path : paths) {\n+                    // Read from the Telemetry/namespace*.log file.\n+                    // TODO : Read only those files that are modified after the last aggregation.\n+                    // file.lastModified() behavior is platform dependent.\n+                    List<String> logs = Files.lines(Paths.get(path.toString())).collect(Collectors.toList());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4d731cde8f9438c921195073cde509085bd39cda"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM1MzcxMQ==", "bodyText": "Do not use collect this will cause massive memory usage as you will be reading in the entire file all at once. Do this as a stream.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488353711", "createdAt": "2020-09-15T03:01:13Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,246 @@\n+/*\n+ * Copyright Amazon.com Inc. or its affiliates.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.EvergreenStructuredLogMessage;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private final ObjectMapper objectMapper = new ObjectMapper();\n+    MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+\n+    /**\n+     * This method stores the aggregated data points of the metrics emitted over the interval.\n+     *\n+     * @param lastAgg       timestamp at which the last aggregation was done.\n+     * @param currTimestamp timestamp at which the current aggregation is initiated.\n+     */\n+    protected void aggregateMetrics(long lastAgg, long currTimestamp) {\n+        for (TelemetryNamespace namespace : TelemetryNamespace.values()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<Metric>> metrics = new HashMap<>();\n+            Metric mdp;\n+            try {\n+                List<Path> paths = Files\n+                        .walk(TelemetryConfig.getTelemetryDirectory())\n+                        .filter(Files::isRegularFile)\n+                        .filter(path -> {\n+                            Object fileName = null;\n+                            if (path != null) {\n+                                fileName = path.getFileName();\n+                            }\n+                            if (fileName == null) {\n+                                fileName = \"\";\n+                            }\n+                            return fileName.toString().startsWith(namespace.toString());\n+                        }).collect(Collectors.toList());\n+                for (Path path : paths) {\n+                    // Read from the Telemetry/namespace*.log file.\n+                    // TODO : Read only those files that are modified after the last aggregation.\n+                    // file.lastModified() behavior is platform dependent.\n+                    List<String> logs = Files.lines(Paths.get(path.toString())).collect(Collectors.toList());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM1MzU2MA=="}, "originalCommit": {"oid": "4d731cde8f9438c921195073cde509085bd39cda"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM1MzkyNQ==", "bodyText": "again. This is a string", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488353925", "createdAt": "2020-09-15T03:02:02Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,246 @@\n+/*\n+ * Copyright Amazon.com Inc. or its affiliates.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.EvergreenStructuredLogMessage;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private final ObjectMapper objectMapper = new ObjectMapper();\n+    MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+\n+    /**\n+     * This method stores the aggregated data points of the metrics emitted over the interval.\n+     *\n+     * @param lastAgg       timestamp at which the last aggregation was done.\n+     * @param currTimestamp timestamp at which the current aggregation is initiated.\n+     */\n+    protected void aggregateMetrics(long lastAgg, long currTimestamp) {\n+        for (TelemetryNamespace namespace : TelemetryNamespace.values()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<Metric>> metrics = new HashMap<>();\n+            Metric mdp;\n+            try {\n+                List<Path> paths = Files\n+                        .walk(TelemetryConfig.getTelemetryDirectory())\n+                        .filter(Files::isRegularFile)\n+                        .filter(path -> {\n+                            Object fileName = null;\n+                            if (path != null) {\n+                                fileName = path.getFileName();\n+                            }\n+                            if (fileName == null) {\n+                                fileName = \"\";\n+                            }\n+                            return fileName.toString().startsWith(namespace.toString());\n+                        }).collect(Collectors.toList());\n+                for (Path path : paths) {\n+                    // Read from the Telemetry/namespace*.log file.\n+                    // TODO : Read only those files that are modified after the last aggregation.\n+                    // file.lastModified() behavior is platform dependent.\n+                    List<String> logs = Files.lines(Paths.get(path.toString())).collect(Collectors.toList());\n+                    for (String log : logs) {\n+                        try {\n+                            /*\n+                              {\"thread\":\"pool-3-thread-4\",\"level\":\"TRACE\",\"eventType\":null,\n+\n+                              \"message\":\"{\\\"NS\\\":\\\"SystemMetrics\\\",\\\"N\\\":\\\"TotalNumberOfFDs\\\",\\\"U\\\":\\\"Count\\\",\n+\n+                              \\\"A\\\":\\\"Average\\\",\\\"V\\\":4583,\\\"TS\\\":1600127641506}\",\"contexts\":{},\n+\n+                              \"loggerName\":\"Metrics-SystemMetrics\",\"timestamp\":1600127641506,\"cause\":null}\n+                             */\n+                            EvergreenStructuredLogMessage egLog = objectMapper.readValue(log,\n+                                    EvergreenStructuredLogMessage.class);\n+                            mdp = objectMapper.readValue(egLog.getMessage(), Metric.class);\n+                            // Avoid the metrics that are emitted at/after the currTimestamp and before the\n+                            // aggregation interval\n+                            if (mdp != null && currTimestamp > mdp.getTimestamp() && mdp.getTimestamp() >= lastAgg) {\n+                                metrics.computeIfAbsent(mdp.getName(), k -> new ArrayList<>()).add(mdp);\n+                            }\n+                        } catch (IOException e) {\n+                            logger.atError().log(\"Unable to parse the metric log.\", e);\n+                        }\n+                    }\n+                }\n+                aggMetrics.setMetricNamespace(namespace);\n+                aggMetrics.setTimestamp(currTimestamp);\n+                aggMetrics.setMetrics(doAggregation(metrics));\n+                metricFactory.logMetrics(new TelemetryLoggerMessage(aggMetrics));\n+            } catch (IOException e) {\n+                logger.atError().log(\"Unable to parse the emitted metric log file.\", e);\n+            }\n+        }\n+    }\n+\n+    private List<AggregatedMetric.Metric> doAggregation(Map<TelemetryMetricName, List<Metric>> metrics) {\n+        List<AggregatedMetric.Metric> aggMetrics = new ArrayList<>();\n+        for (Map.Entry<TelemetryMetricName, List<Metric>> metric : metrics.entrySet()) {\n+            TelemetryMetricName metricName = metric.getKey();\n+            List<Metric> mdp = metric.getValue();\n+            TelemetryAggregation telemetryAggregation = mdp.get(0).getAggregation();\n+            double aggregation = 0;\n+            if (telemetryAggregation.equals(TelemetryAggregation.Average)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> Coerce.toDouble(a.getValue()))\n+                        .sum();\n+                if (!mdp.isEmpty()) {\n+                    aggregation = aggregation / mdp.size();\n+                }\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Sum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> Coerce.toDouble(a.getValue()))\n+                        .sum();\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Maximum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> Coerce.toDouble(a.getValue()))\n+                        .max()\n+                        .getAsDouble();\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Minimum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> Coerce.toDouble(a.getValue()))\n+                        .min()\n+                        .getAsDouble();\n+            }\n+            AggregatedMetric.Metric m = AggregatedMetric.Metric.builder()\n+                    .metricName(metricName)\n+                    .metricUnit(mdp.get(0).getUnit())\n+                    .value(aggregation)\n+                    .build();\n+            aggMetrics.add(m);\n+        }\n+        return aggMetrics;\n+    }\n+\n+    /**\n+     * This function returns the set of all the aggregated metric data points that are to be published to the cloud\n+     * since the last upload.\n+     *\n+     * @param lastPublish   timestamp at which the last publish was done.\n+     * @param currTimestamp timestamp at which the current publish is initiated.\n+     */\n+    protected Map<Long, List<MetricsAggregator.AggregatedMetric>> getMetricsToPublish(long lastPublish,\n+                                                                                      long currTimestamp) {\n+        Map<Long, List<MetricsAggregator.AggregatedMetric>> aggUploadMetrics = new HashMap<>();\n+        MetricsAggregator.AggregatedMetric am;\n+        try {\n+            List<Path> paths = Files\n+                    .walk(TelemetryConfig.getTelemetryDirectory())\n+                    .filter(Files::isRegularFile)\n+                    .filter((path) -> {\n+                        Object fileName = null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4d731cde8f9438c921195073cde509085bd39cda"}, "originalPosition": 173}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM1Mzk1Mw==", "bodyText": "Same as above", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488353953", "createdAt": "2020-09-15T03:02:09Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,246 @@\n+/*\n+ * Copyright Amazon.com Inc. or its affiliates.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.EvergreenStructuredLogMessage;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private final ObjectMapper objectMapper = new ObjectMapper();\n+    MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+\n+    /**\n+     * This method stores the aggregated data points of the metrics emitted over the interval.\n+     *\n+     * @param lastAgg       timestamp at which the last aggregation was done.\n+     * @param currTimestamp timestamp at which the current aggregation is initiated.\n+     */\n+    protected void aggregateMetrics(long lastAgg, long currTimestamp) {\n+        for (TelemetryNamespace namespace : TelemetryNamespace.values()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<Metric>> metrics = new HashMap<>();\n+            Metric mdp;\n+            try {\n+                List<Path> paths = Files\n+                        .walk(TelemetryConfig.getTelemetryDirectory())\n+                        .filter(Files::isRegularFile)\n+                        .filter(path -> {\n+                            Object fileName = null;\n+                            if (path != null) {\n+                                fileName = path.getFileName();\n+                            }\n+                            if (fileName == null) {\n+                                fileName = \"\";\n+                            }\n+                            return fileName.toString().startsWith(namespace.toString());\n+                        }).collect(Collectors.toList());\n+                for (Path path : paths) {\n+                    // Read from the Telemetry/namespace*.log file.\n+                    // TODO : Read only those files that are modified after the last aggregation.\n+                    // file.lastModified() behavior is platform dependent.\n+                    List<String> logs = Files.lines(Paths.get(path.toString())).collect(Collectors.toList());\n+                    for (String log : logs) {\n+                        try {\n+                            /*\n+                              {\"thread\":\"pool-3-thread-4\",\"level\":\"TRACE\",\"eventType\":null,\n+\n+                              \"message\":\"{\\\"NS\\\":\\\"SystemMetrics\\\",\\\"N\\\":\\\"TotalNumberOfFDs\\\",\\\"U\\\":\\\"Count\\\",\n+\n+                              \\\"A\\\":\\\"Average\\\",\\\"V\\\":4583,\\\"TS\\\":1600127641506}\",\"contexts\":{},\n+\n+                              \"loggerName\":\"Metrics-SystemMetrics\",\"timestamp\":1600127641506,\"cause\":null}\n+                             */\n+                            EvergreenStructuredLogMessage egLog = objectMapper.readValue(log,\n+                                    EvergreenStructuredLogMessage.class);\n+                            mdp = objectMapper.readValue(egLog.getMessage(), Metric.class);\n+                            // Avoid the metrics that are emitted at/after the currTimestamp and before the\n+                            // aggregation interval\n+                            if (mdp != null && currTimestamp > mdp.getTimestamp() && mdp.getTimestamp() >= lastAgg) {\n+                                metrics.computeIfAbsent(mdp.getName(), k -> new ArrayList<>()).add(mdp);\n+                            }\n+                        } catch (IOException e) {\n+                            logger.atError().log(\"Unable to parse the metric log.\", e);\n+                        }\n+                    }\n+                }\n+                aggMetrics.setMetricNamespace(namespace);\n+                aggMetrics.setTimestamp(currTimestamp);\n+                aggMetrics.setMetrics(doAggregation(metrics));\n+                metricFactory.logMetrics(new TelemetryLoggerMessage(aggMetrics));\n+            } catch (IOException e) {\n+                logger.atError().log(\"Unable to parse the emitted metric log file.\", e);\n+            }\n+        }\n+    }\n+\n+    private List<AggregatedMetric.Metric> doAggregation(Map<TelemetryMetricName, List<Metric>> metrics) {\n+        List<AggregatedMetric.Metric> aggMetrics = new ArrayList<>();\n+        for (Map.Entry<TelemetryMetricName, List<Metric>> metric : metrics.entrySet()) {\n+            TelemetryMetricName metricName = metric.getKey();\n+            List<Metric> mdp = metric.getValue();\n+            TelemetryAggregation telemetryAggregation = mdp.get(0).getAggregation();\n+            double aggregation = 0;\n+            if (telemetryAggregation.equals(TelemetryAggregation.Average)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> Coerce.toDouble(a.getValue()))\n+                        .sum();\n+                if (!mdp.isEmpty()) {\n+                    aggregation = aggregation / mdp.size();\n+                }\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Sum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> Coerce.toDouble(a.getValue()))\n+                        .sum();\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Maximum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> Coerce.toDouble(a.getValue()))\n+                        .max()\n+                        .getAsDouble();\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Minimum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> Coerce.toDouble(a.getValue()))\n+                        .min()\n+                        .getAsDouble();\n+            }\n+            AggregatedMetric.Metric m = AggregatedMetric.Metric.builder()\n+                    .metricName(metricName)\n+                    .metricUnit(mdp.get(0).getUnit())\n+                    .value(aggregation)\n+                    .build();\n+            aggMetrics.add(m);\n+        }\n+        return aggMetrics;\n+    }\n+\n+    /**\n+     * This function returns the set of all the aggregated metric data points that are to be published to the cloud\n+     * since the last upload.\n+     *\n+     * @param lastPublish   timestamp at which the last publish was done.\n+     * @param currTimestamp timestamp at which the current publish is initiated.\n+     */\n+    protected Map<Long, List<MetricsAggregator.AggregatedMetric>> getMetricsToPublish(long lastPublish,\n+                                                                                      long currTimestamp) {\n+        Map<Long, List<MetricsAggregator.AggregatedMetric>> aggUploadMetrics = new HashMap<>();\n+        MetricsAggregator.AggregatedMetric am;\n+        try {\n+            List<Path> paths = Files\n+                    .walk(TelemetryConfig.getTelemetryDirectory())\n+                    .filter(Files::isRegularFile)\n+                    .filter((path) -> {\n+                        Object fileName = null;\n+                        if (path != null) {\n+                            fileName = path.getFileName();\n+                        }\n+                        if (fileName == null) {\n+                            fileName = \"\";\n+                        }\n+                        return fileName.toString().startsWith(AGGREGATE_METRICS_FILE);\n+                    }).collect(Collectors.toList());\n+            for (Path path : paths) {\n+                // Read from the Telemetry/AggregatedMetrics.log file.\n+                // TODO : Read only those files that are modified after the last publish.\n+                List<String> logs = Files.lines(Paths.get(path.toString())).collect(Collectors.toList());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4d731cde8f9438c921195073cde509085bd39cda"}, "originalPosition": 185}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM1NDA4Ng==", "bodyText": "should not be public", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488354086", "createdAt": "2020-09-15T03:02:40Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/PeriodicMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,18 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import java.util.concurrent.ScheduledFuture;\n+\n+public abstract class PeriodicMetricsEmitter {\n+    public ScheduledFuture future;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4d731cde8f9438c921195073cde509085bd39cda"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM1NDUzNA==", "bodyText": "I highly disagree with saving these prebuilt metrics. This costs us memory and will be moved into the old generation, if not the perm gen. If you just build the metric when needed which is only once an hour or so, then we can save quite a bit or memory and mental complexity.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488354534", "createdAt": "2020-09-15T03:04:30Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/SystemMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,74 @@\n+/*\n+ * Copyright Amazon.com Inc. or its affiliates.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import oshi.SystemInfo;\n+import oshi.hardware.CentralProcessor;\n+\n+import java.util.HashMap;\n+import java.util.Map;\n+\n+public class SystemMetricsEmitter extends PeriodicMetricsEmitter {\n+    private static final int MB_CONVERTER = 1024 * 1024;\n+    private static final int PERCENTAGE_CONVERTER = 100;\n+    private static final String SYSTEM_METRICS_STORE = TelemetryNamespace.SystemMetrics.toString();\n+    private static final CentralProcessor cpu = new SystemInfo().getHardware().getProcessor();\n+    private static final SystemInfo systemInfo = new SystemInfo();\n+    private final Map<TelemetryMetricName, Metric> map = new HashMap<>();\n+    private final MetricFactory mf = new MetricFactory(SYSTEM_METRICS_STORE);\n+    private long[] previousTicks = new long[CentralProcessor.TickType.values().length];\n+\n+    /**\n+     * Build system metrics.\n+     */\n+    @Override\n+    public void buildMetrics() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4d731cde8f9438c921195073cde509085bd39cda"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM1NTAwMA==", "bodyText": "just keep this as a Path and use resolve to get the file", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488355000", "createdAt": "2020-09-15T03:06:20Z", "author": {"login": "MikeDombo"}, "path": "src/test/java/com/aws/iot/evergreen/telemetry/MetricsAggregatorTest.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Copyright Amazon.com Inc. or its affiliates.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.impl.EvergreenStructuredLogMessage;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.testcommons.testutilities.EGExtension;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.junit.jupiter.api.extension.ExtensionContext;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+\n+import static com.aws.iot.evergreen.telemetry.MetricsAggregator.AGGREGATE_METRICS_FILE;\n+import static com.aws.iot.evergreen.testcommons.testutilities.ExceptionLogProtector.ignoreExceptionOfType;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n+\n+@ExtendWith({MockitoExtension.class, EGExtension.class})\n+public class MetricsAggregatorTest {\n+    private static final ObjectMapper mapper = new ObjectMapper();\n+    @TempDir\n+    protected Path tempRootDir;\n+\n+    @BeforeEach\n+    public void setup() {\n+        System.setProperty(\"root\", tempRootDir.toAbsolutePath().toString());\n+    }\n+\n+    @Test\n+    public void GIVEN_system_metrics_WHEN_aggregate_THEN_aggregate_only_the_latest_values()\n+            throws InterruptedException, IOException {\n+        //Create a sample file with system metrics so we can test the freshness of the file and logs\n+        //with respect to the current timestamp\n+        long lastAgg = Instant.now().toEpochMilli();\n+        Metric m1 = new Metric(TelemetryNamespace.SystemMetrics, TelemetryMetricName.CpuUsage,\n+                TelemetryUnit.Percent, TelemetryAggregation.Sum);\n+        MetricFactory mf = new MetricFactory(TelemetryNamespace.SystemMetrics.toString());\n+        Metric m2 = new Metric(TelemetryNamespace.SystemMetrics, TelemetryMetricName.SystemMemUsage,\n+                TelemetryUnit.Megabytes, TelemetryAggregation.Average);\n+        Metric m3 = new Metric(TelemetryNamespace.SystemMetrics, TelemetryMetricName.TotalNumberOfFDs,\n+                TelemetryUnit.Count, TelemetryAggregation.Maximum);\n+        mf.putMetricData(m1,10);\n+        mf.putMetricData(m2,2000);\n+        mf.putMetricData(m3,4000);\n+        mf.putMetricData(m1,20);\n+        mf.putMetricData(m2,3000);\n+        mf.putMetricData(m3,5000);\n+        mf.putMetricData(m1,30);\n+        mf.putMetricData(m2,4000);\n+        mf.putMetricData(m3,6000);\n+        MetricsAggregator ma = new MetricsAggregator();\n+        long currTimestamp = Instant.now().toEpochMilli();\n+        ma.aggregateMetrics(lastAgg, currTimestamp);\n+        String path = TelemetryConfig.getTelemetryDirectory().toString() + \"/AggregateMetrics.log\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4d731cde8f9438c921195073cde509085bd39cda"}, "originalPosition": 78}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg4MzAxNDQ1", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-488301445", "createdAt": "2020-09-15T03:44:48Z", "commit": {"oid": "4d731cde8f9438c921195073cde509085bd39cda"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQwMzo0NDo0OFrOHRvbGA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQwNDoxMjoyNlrOHRv2Gg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM2NDgyNA==", "bodyText": "You can just hard code the list for now.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488364824", "createdAt": "2020-09-15T03:44:48Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,83 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.api.MetricDataBuilder;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import javax.inject.Inject;\n+\n+public class KernelMetricsEmitter {\n+    public static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+    private static final String KERNEL_COMPONENT_METRIC_STORE = TelemetryNamespace.KernelComponents.toString();\n+    private static Map<TelemetryMetricName, MetricDataBuilder> kernelMetrics = new HashMap<>();\n+    private static Map<TelemetryMetricName, Integer> kernelMetricsData = new HashMap<>();\n+    private final Kernel kernel;\n+    private final MetricFactory metricFactory = new MetricFactory(KERNEL_COMPONENT_METRIC_STORE);\n+\n+    /**\n+     * Constructor for kernel metrics emitter.\n+     *\n+     * @param kernel {@link Kernel}\n+     */\n+    @Inject\n+    public KernelMetricsEmitter(Kernel kernel) {\n+        this.kernel = kernel;\n+    }\n+\n+    /**\n+     * Collect kernel metrics - Number of components running in each state.\n+     */\n+    public void collectKernelComponentState() {\n+        List<TelemetryMetricName> telemetryMetricNames =", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODAxMTk5NQ=="}, "originalCommit": {"oid": "0885143b7846ce5bc38053c39dc261ff10a10b70"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM3MDEzMQ==", "bodyText": "update service name to aws.greengrass.telemetry", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488370131", "createdAt": "2020-09-15T04:06:00Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,261 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {\n+    public static final String METRICS_AGENT_SERVICE_TOPICS = \"MetricsAgent\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4d731cde8f9438c921195073cde509085bd39cda"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM3MDMwOQ==", "bodyText": "lets rename this to TelemetryAgent. Change all mentions of Metric Agent -> Telemetry Agent", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488370309", "createdAt": "2020-09-15T04:06:47Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAgent.java", "diffHunk": "@@ -0,0 +1,261 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = MetricsAgent.METRICS_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class MetricsAgent extends EvergreenService {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4d731cde8f9438c921195073cde509085bd39cda"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM3MDc1OQ==", "bodyText": "Filter out the active metric file as well. We don't want any partial reads.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488370759", "createdAt": "2020-09-15T04:08:42Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,246 @@\n+/*\n+ * Copyright Amazon.com Inc. or its affiliates.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.EvergreenStructuredLogMessage;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private final ObjectMapper objectMapper = new ObjectMapper();\n+    MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+\n+    /**\n+     * This method stores the aggregated data points of the metrics emitted over the interval.\n+     *\n+     * @param lastAgg       timestamp at which the last aggregation was done.\n+     * @param currTimestamp timestamp at which the current aggregation is initiated.\n+     */\n+    protected void aggregateMetrics(long lastAgg, long currTimestamp) {\n+        for (TelemetryNamespace namespace : TelemetryNamespace.values()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<Metric>> metrics = new HashMap<>();\n+            Metric mdp;\n+            try {\n+                List<Path> paths = Files\n+                        .walk(TelemetryConfig.getTelemetryDirectory())\n+                        .filter(Files::isRegularFile)\n+                        .filter(path -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4d731cde8f9438c921195073cde509085bd39cda"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM3MTEwOA==", "bodyText": "use logger.atError().cause(e).log() here and everywhere", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488371108", "createdAt": "2020-09-15T04:10:11Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,246 @@\n+/*\n+ * Copyright Amazon.com Inc. or its affiliates.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.EvergreenStructuredLogMessage;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private final ObjectMapper objectMapper = new ObjectMapper();\n+    MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+\n+    /**\n+     * This method stores the aggregated data points of the metrics emitted over the interval.\n+     *\n+     * @param lastAgg       timestamp at which the last aggregation was done.\n+     * @param currTimestamp timestamp at which the current aggregation is initiated.\n+     */\n+    protected void aggregateMetrics(long lastAgg, long currTimestamp) {\n+        for (TelemetryNamespace namespace : TelemetryNamespace.values()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<Metric>> metrics = new HashMap<>();\n+            Metric mdp;\n+            try {\n+                List<Path> paths = Files\n+                        .walk(TelemetryConfig.getTelemetryDirectory())\n+                        .filter(Files::isRegularFile)\n+                        .filter(path -> {\n+                            Object fileName = null;\n+                            if (path != null) {\n+                                fileName = path.getFileName();\n+                            }\n+                            if (fileName == null) {\n+                                fileName = \"\";\n+                            }\n+                            return fileName.toString().startsWith(namespace.toString());\n+                        }).collect(Collectors.toList());\n+                for (Path path : paths) {\n+                    // Read from the Telemetry/namespace*.log file.\n+                    // TODO : Read only those files that are modified after the last aggregation.\n+                    // file.lastModified() behavior is platform dependent.\n+                    List<String> logs = Files.lines(Paths.get(path.toString())).collect(Collectors.toList());\n+                    for (String log : logs) {\n+                        try {\n+                            /*\n+                              {\"thread\":\"pool-3-thread-4\",\"level\":\"TRACE\",\"eventType\":null,\n+\n+                              \"message\":\"{\\\"NS\\\":\\\"SystemMetrics\\\",\\\"N\\\":\\\"TotalNumberOfFDs\\\",\\\"U\\\":\\\"Count\\\",\n+\n+                              \\\"A\\\":\\\"Average\\\",\\\"V\\\":4583,\\\"TS\\\":1600127641506}\",\"contexts\":{},\n+\n+                              \"loggerName\":\"Metrics-SystemMetrics\",\"timestamp\":1600127641506,\"cause\":null}\n+                             */\n+                            EvergreenStructuredLogMessage egLog = objectMapper.readValue(log,\n+                                    EvergreenStructuredLogMessage.class);\n+                            mdp = objectMapper.readValue(egLog.getMessage(), Metric.class);\n+                            // Avoid the metrics that are emitted at/after the currTimestamp and before the\n+                            // aggregation interval\n+                            if (mdp != null && currTimestamp > mdp.getTimestamp() && mdp.getTimestamp() >= lastAgg) {\n+                                metrics.computeIfAbsent(mdp.getName(), k -> new ArrayList<>()).add(mdp);\n+                            }\n+                        } catch (IOException e) {\n+                            logger.atError().log(\"Unable to parse the metric log.\", e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4d731cde8f9438c921195073cde509085bd39cda"}, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM3MTczOA==", "bodyText": "Also, is this going to read and aggregate all the metrics every time it runs?", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488371738", "createdAt": "2020-09-15T04:12:26Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,246 @@\n+/*\n+ * Copyright Amazon.com Inc. or its affiliates.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.EvergreenStructuredLogMessage;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private final ObjectMapper objectMapper = new ObjectMapper();\n+    MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+\n+    /**\n+     * This method stores the aggregated data points of the metrics emitted over the interval.\n+     *\n+     * @param lastAgg       timestamp at which the last aggregation was done.\n+     * @param currTimestamp timestamp at which the current aggregation is initiated.\n+     */\n+    protected void aggregateMetrics(long lastAgg, long currTimestamp) {\n+        for (TelemetryNamespace namespace : TelemetryNamespace.values()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<Metric>> metrics = new HashMap<>();\n+            Metric mdp;\n+            try {\n+                List<Path> paths = Files\n+                        .walk(TelemetryConfig.getTelemetryDirectory())\n+                        .filter(Files::isRegularFile)\n+                        .filter(path -> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODM3MDc1OQ=="}, "originalCommit": {"oid": "4d731cde8f9438c921195073cde509085bd39cda"}, "originalPosition": 61}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "68c490deccce8f729fb21d42c95811875a0e5d6f", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/68c490deccce8f729fb21d42c95811875a0e5d6f", "committedDate": "2020-09-15T17:13:31Z", "message": "rename MA to TelemetryAgent + path related comments addressed + removed buildMetrics()"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg4OTAxMDAx", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-488901001", "createdAt": "2020-09-15T17:19:53Z", "commit": {"oid": "68c490deccce8f729fb21d42c95811875a0e5d6f"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxNzoxOTo1M1rOHSL96Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxNzoyMjo0MlrOHSMJCg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODgzMjQ4OQ==", "bodyText": "[nit]\nReformat", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488832489", "createdAt": "2020-09-15T17:19:53Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.PeriodicMetricsEmitter;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+import javax.inject.Inject;\n+\n+public class KernelMetricsEmitter extends PeriodicMetricsEmitter {\n+    public static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+    private static final String KERNEL_COMPONENT_METRIC_STORE = TelemetryNamespace.KernelComponents.toString();\n+    private final Kernel kernel;\n+    private final MetricFactory mf = new MetricFactory(KERNEL_COMPONENT_METRIC_STORE);\n+\n+    /**\n+     * Constructor for kernel metrics emitter.\n+     *\n+     * @param kernel {@link Kernel}\n+     */\n+    @Inject\n+    public KernelMetricsEmitter(Kernel kernel) {\n+        super();\n+        this.kernel = kernel;\n+    }\n+\n+    /**\n+     * Emit kernel component state metrics.\n+     */\n+    @Override\n+    public void emitMetrics() {\n+        Map<TelemetryMetricName, Integer> data = new HashMap<>();\n+        Collection<EvergreenService> evergreenServices = kernel.orderedDependencies();\n+        for (EvergreenService evergreenService : evergreenServices) {\n+            /*\n+              State of the component returned is all caps(\"RUNNING\") but the corresponding Metric name is of the\n+              format \"NumberOfComponentsRunning\"; So we process the uppercase service state to sentence case\n+              and concatenate it with \"NumberOfComponents\" to form the metric name;\n+             */\n+            String serviceState = evergreenService.getState().toString();\n+            serviceState = serviceState.charAt(0) + serviceState.substring(1).toLowerCase();\n+            try {\n+                TelemetryMetricName telemetryMetricName =\n+                        TelemetryMetricName.valueOf(\"NumberOfComponents\" + serviceState);\n+                data.put(telemetryMetricName, data.getOrDefault(telemetryMetricName,0) + 1);\n+            } catch (IllegalArgumentException e) {\n+                logger.atError().log(\"Unable to find the metric name.\", e);\n+            }\n+        }\n+\n+        Metric metric = Metric.builder()\n+                .namespace(TelemetryNamespace.KernelComponents)\n+                .name(TelemetryMetricName.NumberOfComponentsStarting)\n+                .unit(TelemetryUnit.Count)\n+                .aggregation(TelemetryAggregation.Average)\n+                .build();\n+        mf.putMetricData(metric,data.get(TelemetryMetricName.NumberOfComponentsStarting));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "68c490deccce8f729fb21d42c95811875a0e5d6f"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODgzMzQ1NA==", "bodyText": "keep the messages that you had, otherwise it is difficult to know from the log, what exactly went wrong and what part of the code caused it.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488833454", "createdAt": "2020-09-15T17:20:58Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Copyright Amazon.com Inc. or its affiliates.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.EvergreenStructuredLogMessage;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private final ObjectMapper objectMapper = new ObjectMapper();\n+    MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+\n+    /**\n+     * This method stores the aggregated data points of the metrics emitted over the interval.\n+     *\n+     * @param lastAgg       timestamp at which the last aggregation was done.\n+     * @param currTimestamp timestamp at which the current aggregation is initiated.\n+     */\n+    protected void aggregateMetrics(long lastAgg, long currTimestamp) {\n+        for (TelemetryNamespace namespace : TelemetryNamespace.values()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<Metric>> metrics = new HashMap<>();\n+            try {\n+                List<Path> paths = Files\n+                        .walk(TelemetryConfig.getTelemetryDirectory())\n+                        .filter(Files::isRegularFile)\n+                        .filter((path) -> Coerce.toString(path.getFileName()).startsWith(namespace.toString()))\n+                        .collect(Collectors.toList());\n+                for (Path path : paths) {\n+                    // Read from the Telemetry/namespace*.log file.\n+                    // TODO : Read only those files that are modified after the last aggregation.\n+                    // file.lastModified() behavior is platform dependent.\n+                    Files.lines(path).forEach((log) -> {\n+                        try {\n+                            /*\n+                              {\"thread\":\"pool-3-thread-4\",\"level\":\"TRACE\",\"eventType\":null,\n+\n+                              \"message\":\"{\\\"NS\\\":\\\"SystemMetrics\\\",\\\"N\\\":\\\"TotalNumberOfFDs\\\",\\\"U\\\":\\\"Count\\\",\n+\n+                              \\\"A\\\":\\\"Average\\\",\\\"V\\\":4583,\\\"TS\\\":1600127641506}\",\"contexts\":{},\n+\n+                              \"loggerName\":\"Metrics-SystemMetrics\",\"timestamp\":1600127641506,\"cause\":null}\n+                             */\n+                            EvergreenStructuredLogMessage egLog = objectMapper.readValue(log,\n+                                    EvergreenStructuredLogMessage.class);\n+                            Metric mdp = objectMapper.readValue(egLog.getMessage(), Metric.class);\n+                            // Avoid the metrics that are emitted at/after the currTimestamp and before the\n+                            // aggregation interval\n+                            if (mdp != null && currTimestamp > mdp.getTimestamp() && mdp.getTimestamp() >= lastAgg) {\n+                                metrics.computeIfAbsent(mdp.getName(), k -> new ArrayList<>()).add(mdp);\n+                            }\n+                        } catch (IOException e) {\n+                            logger.atError().cause(e).log();\n+                        }\n+                    });\n+                }\n+                aggMetrics.setMetricNamespace(namespace);\n+                aggMetrics.setTimestamp(currTimestamp);\n+                aggMetrics.setMetrics(doAggregation(metrics));\n+                metricFactory.logMetrics(new TelemetryLoggerMessage(aggMetrics));\n+            } catch (IOException e) {\n+                logger.atError().cause(e).log();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "68c490deccce8f729fb21d42c95811875a0e5d6f"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODgzMzY0Nw==", "bodyText": "messages, again put them back here any everywhere else.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488833647", "createdAt": "2020-09-15T17:21:09Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Copyright Amazon.com Inc. or its affiliates.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.EvergreenStructuredLogMessage;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private final ObjectMapper objectMapper = new ObjectMapper();\n+    MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+\n+    /**\n+     * This method stores the aggregated data points of the metrics emitted over the interval.\n+     *\n+     * @param lastAgg       timestamp at which the last aggregation was done.\n+     * @param currTimestamp timestamp at which the current aggregation is initiated.\n+     */\n+    protected void aggregateMetrics(long lastAgg, long currTimestamp) {\n+        for (TelemetryNamespace namespace : TelemetryNamespace.values()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<Metric>> metrics = new HashMap<>();\n+            try {\n+                List<Path> paths = Files\n+                        .walk(TelemetryConfig.getTelemetryDirectory())\n+                        .filter(Files::isRegularFile)\n+                        .filter((path) -> Coerce.toString(path.getFileName()).startsWith(namespace.toString()))\n+                        .collect(Collectors.toList());\n+                for (Path path : paths) {\n+                    // Read from the Telemetry/namespace*.log file.\n+                    // TODO : Read only those files that are modified after the last aggregation.\n+                    // file.lastModified() behavior is platform dependent.\n+                    Files.lines(path).forEach((log) -> {\n+                        try {\n+                            /*\n+                              {\"thread\":\"pool-3-thread-4\",\"level\":\"TRACE\",\"eventType\":null,\n+\n+                              \"message\":\"{\\\"NS\\\":\\\"SystemMetrics\\\",\\\"N\\\":\\\"TotalNumberOfFDs\\\",\\\"U\\\":\\\"Count\\\",\n+\n+                              \\\"A\\\":\\\"Average\\\",\\\"V\\\":4583,\\\"TS\\\":1600127641506}\",\"contexts\":{},\n+\n+                              \"loggerName\":\"Metrics-SystemMetrics\",\"timestamp\":1600127641506,\"cause\":null}\n+                             */\n+                            EvergreenStructuredLogMessage egLog = objectMapper.readValue(log,\n+                                    EvergreenStructuredLogMessage.class);\n+                            Metric mdp = objectMapper.readValue(egLog.getMessage(), Metric.class);\n+                            // Avoid the metrics that are emitted at/after the currTimestamp and before the\n+                            // aggregation interval\n+                            if (mdp != null && currTimestamp > mdp.getTimestamp() && mdp.getTimestamp() >= lastAgg) {\n+                                metrics.computeIfAbsent(mdp.getName(), k -> new ArrayList<>()).add(mdp);\n+                            }\n+                        } catch (IOException e) {\n+                            logger.atError().cause(e).log();\n+                        }\n+                    });\n+                }\n+                aggMetrics.setMetricNamespace(namespace);\n+                aggMetrics.setTimestamp(currTimestamp);\n+                aggMetrics.setMetrics(doAggregation(metrics));\n+                metricFactory.logMetrics(new TelemetryLoggerMessage(aggMetrics));\n+            } catch (IOException e) {\n+                logger.atError().cause(e).log();\n+            }\n+        }\n+    }\n+\n+    private List<AggregatedMetric.Metric> doAggregation(Map<TelemetryMetricName, List<Metric>> metrics) {\n+        List<AggregatedMetric.Metric> aggMetrics = new ArrayList<>();\n+        for (Map.Entry<TelemetryMetricName, List<Metric>> metric : metrics.entrySet()) {\n+            TelemetryMetricName metricName = metric.getKey();\n+            List<Metric> mdp = metric.getValue();\n+            TelemetryAggregation telemetryAggregation = mdp.get(0).getAggregation();\n+            double aggregation = 0;\n+            if (telemetryAggregation.equals(TelemetryAggregation.Average)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> Coerce.toDouble(a.getValue()))\n+                        .sum();\n+                if (!mdp.isEmpty()) {\n+                    aggregation = aggregation / mdp.size();\n+                }\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Sum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> Coerce.toDouble(a.getValue()))\n+                        .sum();\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Maximum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> Coerce.toDouble(a.getValue()))\n+                        .max()\n+                        .getAsDouble();\n+            } else if (telemetryAggregation.equals(TelemetryAggregation.Minimum)) {\n+                aggregation = mdp\n+                        .stream()\n+                        .filter(Objects::nonNull)\n+                        .mapToDouble(a -> Coerce.toDouble(a.getValue()))\n+                        .min()\n+                        .getAsDouble();\n+            }\n+            AggregatedMetric.Metric m = AggregatedMetric.Metric.builder()\n+                    .metricName(metricName)\n+                    .metricUnit(mdp.get(0).getUnit())\n+                    .value(aggregation)\n+                    .build();\n+            aggMetrics.add(m);\n+        }\n+        return aggMetrics;\n+    }\n+\n+    /**\n+     * This function returns the set of all the aggregated metric data points that are to be published to the cloud\n+     * since the last upload.\n+     *\n+     * @param lastPublish   timestamp at which the last publish was done.\n+     * @param currTimestamp timestamp at which the current publish is initiated.\n+     */\n+    protected Map<Long, List<MetricsAggregator.AggregatedMetric>> getMetricsToPublish(long lastPublish,\n+                                                                                      long currTimestamp) {\n+        Map<Long, List<MetricsAggregator.AggregatedMetric>> aggUploadMetrics = new HashMap<>();\n+        try {\n+            List<Path> paths = Files\n+                    .walk(TelemetryConfig.getTelemetryDirectory())\n+                    .filter(Files::isRegularFile)\n+                    .filter((path) -> Coerce.toString(path.getFileName()).startsWith(AGGREGATE_METRICS_FILE))\n+                    .collect(Collectors.toList());\n+            for (Path path : paths) {\n+                // Read from the Telemetry/AggregatedMetrics.log file.\n+                // TODO : Read only those files that are modified after the last publish.\n+                Files.lines(path).forEach((log) -> {\n+                    try {\n+                        /*\n+\n+                        {\"thread\":\"main\",\"level\":\"TRACE\",\"eventType\":null,\n+\n+                        \"message\":\"{\\\"TS\\\":1599617227533,\\\"NS\\\":\\\"SystemMetrics\\\",\\\"M\\\":[{\\\"N\\\":\\\"CpuUsage\\\",\n+\n+                        \\\"V\\\":60.0,\\\"U\\\":\\\"Percent\\\"},{\\\"N\\\":\\\"TotalNumberOfFDs\\\",\\\"V\\\":6000.0,\\\"U\\\":\\\"Count\\\"},\n+\n+                        {\\\"N\\\":\\\"SystemMemUsage\\\",\\\"V\\\":3000.0,\\\"U\\\":\\\"Megabytes\\\"}]}\",\"contexts\":{},\"loggerName\":\n+\n+                        \"Metrics-AggregateMetrics\",\"timestamp\":1599617227595,\"cause\":null}\n+\n+                         */\n+                        EvergreenStructuredLogMessage egLog = objectMapper.readValue(log,\n+                                EvergreenStructuredLogMessage.class);\n+                        MetricsAggregator.AggregatedMetric am = objectMapper.readValue(egLog.getMessage(),\n+                                MetricsAggregator.AggregatedMetric.class);\n+                        // Avoid the metrics that are aggregated at/after the currTimestamp and before the\n+                        // upload interval\n+                        if (am != null && currTimestamp > am.getTimestamp() && am.getTimestamp() >= lastPublish) {\n+                            aggUploadMetrics.computeIfAbsent(currTimestamp, k -> new ArrayList<>()).add(am);\n+                        }\n+                    } catch (IOException e) {\n+                        logger.atError().cause(e).log();\n+                    }\n+                });\n+            }\n+        } catch (IOException e) {\n+            logger.atError().cause(e).log();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "68c490deccce8f729fb21d42c95811875a0e5d6f"}, "originalPosition": 194}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODgzNDkzMg==", "bodyText": "again, don't use RUNTIME_STORE_NAMESPACE_TOPIC. Use getRuntimeConfig", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488834932", "createdAt": "2020-09-15T17:22:20Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/TelemetryAgent.java", "diffHunk": "@@ -0,0 +1,258 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class TelemetryAgent extends EvergreenService {\n+    public static final String TELEMETRY_AGENT_SERVICE_TOPICS = \"TelemetryAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrassv2/health/json\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 3_600;\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 86_400;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter //used in e2e\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private final MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    private final List<PeriodicMetricsEmitter> periodicMetricsEmitters = new ArrayList<>();\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics              root configuration topic for this service\n+     * @param mqttClient          {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     * @param kernel              {@link Kernel}\n+     * @param ses                 {@link ScheduledExecutorService}\n+     */\n+    @Inject\n+    public TelemetryAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration, Kernel kernel,\n+                        ScheduledExecutorService ses) {\n+        super(topics);\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        periodicMetricsEmitters.add(new SystemMetricsEmitter());\n+        periodicMetricsEmitters.add(new KernelMetricsEmitter(kernel));\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        for (PeriodicMetricsEmitter emitter : periodicMetricsEmitters) {\n+            cancelJob(emitter.future, periodicAggregateMetricsInProgressLock, false);\n+        }\n+        cancelJob(periodicAggregateMetricsFuture, periodicAggregateMetricsInProgressLock, false);\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    for (PeriodicMetricsEmitter periodicMetricsEmitter : periodicMetricsEmitters) {\n+                        periodicMetricsEmitter.emitMetrics();\n+                    }\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            for (PeriodicMetricsEmitter emitter : periodicMetricsEmitters) {\n+                // Start emitting metrics with no delay. This is device specific where metrics are stored in files.\n+                emitter.future = ses.scheduleWithFixedDelay(emitter::emitMetrics, 0,\n+                        periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+            }\n+\n+            // As the time based metrics (eg. System metrics) are emitted with the same interval as aggregation, start\n+            // aggregating the metrics after at least one data point is emitted. So, the initial delay to aggregate the\n+            // metrics can be made equal to the interval. This is device specific where the metrics are stored in files.\n+            periodicAggregateMetricsFuture = ses.scheduleWithFixedDelay(this::aggregatePeriodicMetrics,\n+                    periodicAggregateMetricsIntervalSec, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        }\n+    }\n+\n+    /**\n+     * Schedules the publishing of metrics based on the configured publish interval or the mqtt connection status.\n+     */\n+    private void schedulePeriodicPublishMetrics(boolean isReconfiguredOrConnectionResumed) {\n+        // If we missed to publish the metrics due to connection loss or if the publish interval is reconfigured,\n+        // cancel the previously scheduled job.\n+        cancelJob(periodicPublishMetricsFuture, periodicPublishMetricsInProgressLock, false);\n+        if (isReconfiguredOrConnectionResumed) {\n+            synchronized (periodicPublishMetricsInProgressLock) {\n+                Instant lastPeriodicPubTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicPublishTimeTopic()));\n+                if (lastPeriodicPubTime.plusSeconds(periodicPublishMetricsIntervalSec).isBefore(Instant.now())) {\n+                    publishPeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Add some jitter as an initial delay. If the fleet has a lot of devices associated to it, we don't want\n+        // all the devices to send the periodic publish of metrics at the same time.\n+        long initialDelay = RandomUtils.nextLong(1, periodicPublishMetricsIntervalSec + 1);\n+        synchronized (periodicPublishMetricsInProgressLock) {\n+            periodicPublishMetricsFuture = ses.scheduleWithFixedDelay(this::publishPeriodicMetrics, initialDelay,\n+                    periodicPublishMetricsIntervalSec, TimeUnit.SECONDS);\n+        }\n+    }\n+\n+    /**\n+     * Helper for metrics aggregator. Also used in tests.\n+     */\n+    void aggregatePeriodicMetrics() {\n+        long timestamp = Instant.now().toEpochMilli();\n+        long lastAgg = Coerce.toLong(getPeriodicAggregateTimeTopic());\n+        metricsAggregator.aggregateMetrics(lastAgg, timestamp);\n+        getPeriodicAggregateTimeTopic().withValue(timestamp);\n+    }\n+\n+    /**\n+     * Helper for metrics uploader. Also used in tests.\n+     */\n+    void publishPeriodicMetrics() {\n+        if (!isConnected.get()) {\n+            logger.atDebug().log(\"Cannot publish the metrics. MQTT connection interrupted.\");\n+            return;\n+        }\n+        long timestamp = Instant.now().toEpochMilli();\n+        long lastPublish = Coerce.toLong(getPeriodicPublishTimeTopic());\n+        Map<Long, List<MetricsAggregator.AggregatedMetric>> metricsToPublishMap =\n+                metricsAggregator.getMetricsToPublish(lastPublish, timestamp);\n+        getPeriodicPublishTimeTopic().withValue(timestamp);\n+        // Publish only if the collected metrics are not empty.\n+        if (!metricsToPublishMap.get(timestamp).isEmpty()) {\n+            publisher.publish(MetricsPayload.builder().build(), metricsToPublishMap.get(timestamp));\n+        }\n+    }\n+\n+    private Topic getPeriodicPublishTimeTopic() {\n+        return config.lookup(RUNTIME_STORE_NAMESPACE_TOPIC, TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC)\n+                .dflt(Instant.now().toEpochMilli());\n+    }\n+\n+    private Topic getPeriodicAggregateTimeTopic() {\n+        return config.lookup(RUNTIME_STORE_NAMESPACE_TOPIC, TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "68c490deccce8f729fb21d42c95811875a0e5d6f"}, "originalPosition": 197}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODgzNTMzOA==", "bodyText": "this is not correct. The lock should be around this whole thing", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488835338", "createdAt": "2020-09-15T17:22:42Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/TelemetryAgent.java", "diffHunk": "@@ -0,0 +1,258 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class TelemetryAgent extends EvergreenService {\n+    public static final String TELEMETRY_AGENT_SERVICE_TOPICS = \"TelemetryAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrassv2/health/json\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 3_600;\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 86_400;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter //used in e2e\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private final MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    private final List<PeriodicMetricsEmitter> periodicMetricsEmitters = new ArrayList<>();\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics              root configuration topic for this service\n+     * @param mqttClient          {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     * @param kernel              {@link Kernel}\n+     * @param ses                 {@link ScheduledExecutorService}\n+     */\n+    @Inject\n+    public TelemetryAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration, Kernel kernel,\n+                        ScheduledExecutorService ses) {\n+        super(topics);\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        periodicMetricsEmitters.add(new SystemMetricsEmitter());\n+        periodicMetricsEmitters.add(new KernelMetricsEmitter(kernel));\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        for (PeriodicMetricsEmitter emitter : periodicMetricsEmitters) {\n+            cancelJob(emitter.future, periodicAggregateMetricsInProgressLock, false);\n+        }\n+        cancelJob(periodicAggregateMetricsFuture, periodicAggregateMetricsInProgressLock, false);\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    for (PeriodicMetricsEmitter periodicMetricsEmitter : periodicMetricsEmitters) {\n+                        periodicMetricsEmitter.emitMetrics();\n+                    }\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            for (PeriodicMetricsEmitter emitter : periodicMetricsEmitters) {\n+                // Start emitting metrics with no delay. This is device specific where metrics are stored in files.\n+                emitter.future = ses.scheduleWithFixedDelay(emitter::emitMetrics, 0,\n+                        periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+            }\n+\n+            // As the time based metrics (eg. System metrics) are emitted with the same interval as aggregation, start\n+            // aggregating the metrics after at least one data point is emitted. So, the initial delay to aggregate the\n+            // metrics can be made equal to the interval. This is device specific where the metrics are stored in files.\n+            periodicAggregateMetricsFuture = ses.scheduleWithFixedDelay(this::aggregatePeriodicMetrics,\n+                    periodicAggregateMetricsIntervalSec, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        }\n+    }\n+\n+    /**\n+     * Schedules the publishing of metrics based on the configured publish interval or the mqtt connection status.\n+     */\n+    private void schedulePeriodicPublishMetrics(boolean isReconfiguredOrConnectionResumed) {\n+        // If we missed to publish the metrics due to connection loss or if the publish interval is reconfigured,\n+        // cancel the previously scheduled job.\n+        cancelJob(periodicPublishMetricsFuture, periodicPublishMetricsInProgressLock, false);\n+        if (isReconfiguredOrConnectionResumed) {\n+            synchronized (periodicPublishMetricsInProgressLock) {\n+                Instant lastPeriodicPubTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicPublishTimeTopic()));\n+                if (lastPeriodicPubTime.plusSeconds(periodicPublishMetricsIntervalSec).isBefore(Instant.now())) {\n+                    publishPeriodicMetrics();\n+                }\n+            }\n+        }\n+        // Add some jitter as an initial delay. If the fleet has a lot of devices associated to it, we don't want\n+        // all the devices to send the periodic publish of metrics at the same time.\n+        long initialDelay = RandomUtils.nextLong(1, periodicPublishMetricsIntervalSec + 1);\n+        synchronized (periodicPublishMetricsInProgressLock) {\n+            periodicPublishMetricsFuture = ses.scheduleWithFixedDelay(this::publishPeriodicMetrics, initialDelay,\n+                    periodicPublishMetricsIntervalSec, TimeUnit.SECONDS);\n+        }\n+    }\n+\n+    /**\n+     * Helper for metrics aggregator. Also used in tests.\n+     */\n+    void aggregatePeriodicMetrics() {\n+        long timestamp = Instant.now().toEpochMilli();\n+        long lastAgg = Coerce.toLong(getPeriodicAggregateTimeTopic());\n+        metricsAggregator.aggregateMetrics(lastAgg, timestamp);\n+        getPeriodicAggregateTimeTopic().withValue(timestamp);\n+    }\n+\n+    /**\n+     * Helper for metrics uploader. Also used in tests.\n+     */\n+    void publishPeriodicMetrics() {\n+        if (!isConnected.get()) {\n+            logger.atDebug().log(\"Cannot publish the metrics. MQTT connection interrupted.\");\n+            return;\n+        }\n+        long timestamp = Instant.now().toEpochMilli();\n+        long lastPublish = Coerce.toLong(getPeriodicPublishTimeTopic());\n+        Map<Long, List<MetricsAggregator.AggregatedMetric>> metricsToPublishMap =\n+                metricsAggregator.getMetricsToPublish(lastPublish, timestamp);\n+        getPeriodicPublishTimeTopic().withValue(timestamp);\n+        // Publish only if the collected metrics are not empty.\n+        if (!metricsToPublishMap.get(timestamp).isEmpty()) {\n+            publisher.publish(MetricsPayload.builder().build(), metricsToPublishMap.get(timestamp));\n+        }\n+    }\n+\n+    private Topic getPeriodicPublishTimeTopic() {\n+        return config.lookup(RUNTIME_STORE_NAMESPACE_TOPIC, TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC)\n+                .dflt(Instant.now().toEpochMilli());\n+    }\n+\n+    private Topic getPeriodicAggregateTimeTopic() {\n+        return config.lookup(RUNTIME_STORE_NAMESPACE_TOPIC, TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC)\n+                .dflt(Instant.now().toEpochMilli());\n+    }\n+\n+    private void updateThingNameAndPublishTopic(String newThingName) {\n+        if (newThingName != null) {\n+            thingName = newThingName;\n+            updateTopic = telemetryMetricsPublishTopic.replace(\"{thingName}\", thingName);\n+            publisher.setUpdateTopic(updateTopic);\n+        }\n+    }\n+\n+    private void cancelJob(ScheduledFuture<?> future, Object lock, boolean immediately) {\n+        if (future != null) {\n+            synchronized (lock) {\n+                future.cancel(immediately);\n+            }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "68c490deccce8f729fb21d42c95811875a0e5d6f"}, "originalPosition": 213}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "17648ea0a4aaec4af11791cdbae1629387a34f0a", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/17648ea0a4aaec4af11791cdbae1629387a34f0a", "committedDate": "2020-09-15T18:40:19Z", "message": "Use getRuntimeConfig() + update tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e9fcaaae141dec0f0fa555548b7dbbc9211e9fed", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/e9fcaaae141dec0f0fa555548b7dbbc9211e9fed", "committedDate": "2020-09-15T19:46:09Z", "message": "reformat code + proper sync + default value for component state"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg5MDI0OTYw", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-489024960", "createdAt": "2020-09-15T19:58:00Z", "commit": {"oid": "e9fcaaae141dec0f0fa555548b7dbbc9211e9fed"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxOTo1ODowMVrOHSSYlw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxOTo1ODowMVrOHSSYlw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODkzNzYyMw==", "bodyText": "with static final, you can just make it public. No getter needed", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r488937623", "createdAt": "2020-09-15T19:58:01Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/TelemetryAgent.java", "diffHunk": "@@ -0,0 +1,258 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class TelemetryAgent extends EvergreenService {\n+    public static final String TELEMETRY_AGENT_SERVICE_TOPICS = \"TelemetryAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrassv2/health/json\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 3_600;\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e9fcaaae141dec0f0fa555548b7dbbc9211e9fed"}, "originalPosition": 43}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg5MDI1NjU0", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-489025654", "createdAt": "2020-09-15T19:59:01Z", "commit": {"oid": "e9fcaaae141dec0f0fa555548b7dbbc9211e9fed"}, "state": "DISMISSED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg5MjQ1NjEw", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-489245610", "createdAt": "2020-09-16T03:22:30Z", "commit": {"oid": "e9fcaaae141dec0f0fa555548b7dbbc9211e9fed"}, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQwMzoyMjozMFrOHSem3g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQwMzo1MjoyMFrOHSfEHg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTEzNzg4Ng==", "bodyText": "You don't need to do this to keep it in the map. you can just store it as a State object as the key since you have now hard coded the metrics below.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r489137886", "createdAt": "2020-09-16T03:22:30Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.PeriodicMetricsEmitter;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+import javax.inject.Inject;\n+\n+public class KernelMetricsEmitter extends PeriodicMetricsEmitter {\n+    public static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+    private static final String KERNEL_COMPONENT_METRIC_STORE = TelemetryNamespace.KernelComponents.toString();\n+    private final Kernel kernel;\n+    private final MetricFactory mf = new MetricFactory(KERNEL_COMPONENT_METRIC_STORE);\n+\n+    /**\n+     * Constructor for kernel metrics emitter.\n+     *\n+     * @param kernel {@link Kernel}\n+     */\n+    @Inject\n+    public KernelMetricsEmitter(Kernel kernel) {\n+        super();\n+        this.kernel = kernel;\n+    }\n+\n+    /**\n+     * Emit kernel component state metrics.\n+     */\n+    @Override\n+    public void emitMetrics() {\n+        Map<TelemetryMetricName, Integer> data = new HashMap<>();\n+        Collection<EvergreenService> evergreenServices = kernel.orderedDependencies();\n+        for (EvergreenService evergreenService : evergreenServices) {\n+            /*\n+              State of the component returned is all caps(\"RUNNING\") but the corresponding Metric name is of the\n+              format \"NumberOfComponentsRunning\"; So we process the uppercase service state to sentence case\n+              and concatenate it with \"NumberOfComponents\" to form the metric name;\n+             */\n+            String serviceState = evergreenService.getState().toString();\n+            serviceState = serviceState.charAt(0) + serviceState.substring(1).toLowerCase();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e9fcaaae141dec0f0fa555548b7dbbc9211e9fed"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTEzODY1OQ==", "bodyText": "Use Switch", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r489138659", "createdAt": "2020-09-16T03:25:35Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Copyright Amazon.com Inc. or its affiliates.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.EvergreenStructuredLogMessage;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private final ObjectMapper objectMapper = new ObjectMapper();\n+    MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+\n+    /**\n+     * This method stores the aggregated data points of the metrics emitted over the interval.\n+     *\n+     * @param lastAgg       timestamp at which the last aggregation was done.\n+     * @param currTimestamp timestamp at which the current aggregation is initiated.\n+     */\n+    protected void aggregateMetrics(long lastAgg, long currTimestamp) {\n+        for (TelemetryNamespace namespace : TelemetryNamespace.values()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<Metric>> metrics = new HashMap<>();\n+            try {\n+                List<Path> paths = Files\n+                        .walk(TelemetryConfig.getTelemetryDirectory())\n+                        .filter(Files::isRegularFile)\n+                        .filter((path) -> Coerce.toString(path.getFileName()).startsWith(namespace.toString()))\n+                        .collect(Collectors.toList());\n+                for (Path path : paths) {\n+                    // Read from the Telemetry/namespace*.log file.\n+                    // TODO : Read only those files that are modified after the last aggregation.\n+                    // file.lastModified() behavior is platform dependent.\n+                    Files.lines(path).forEach((log) -> {\n+                        try {\n+                            /*\n+                              {\"thread\":\"pool-3-thread-4\",\"level\":\"TRACE\",\"eventType\":null,\n+\n+                              \"message\":\"{\\\"NS\\\":\\\"SystemMetrics\\\",\\\"N\\\":\\\"TotalNumberOfFDs\\\",\\\"U\\\":\\\"Count\\\",\n+\n+                              \\\"A\\\":\\\"Average\\\",\\\"V\\\":4583,\\\"TS\\\":1600127641506}\",\"contexts\":{},\n+\n+                              \"loggerName\":\"Metrics-SystemMetrics\",\"timestamp\":1600127641506,\"cause\":null}\n+                             */\n+                            EvergreenStructuredLogMessage egLog = objectMapper.readValue(log,\n+                                    EvergreenStructuredLogMessage.class);\n+                            Metric mdp = objectMapper.readValue(egLog.getMessage(), Metric.class);\n+                            // Avoid the metrics that are emitted at/after the currTimestamp and before the\n+                            // aggregation interval\n+                            if (mdp != null && currTimestamp > mdp.getTimestamp() && mdp.getTimestamp() >= lastAgg) {\n+                                metrics.computeIfAbsent(mdp.getName(), k -> new ArrayList<>()).add(mdp);\n+                            }\n+                        } catch (IOException e) {\n+                            logger.atError().cause(e).log(\"Unable to parse the metric log.\");\n+                        }\n+                    });\n+                }\n+                aggMetrics.setMetricNamespace(namespace);\n+                aggMetrics.setTimestamp(currTimestamp);\n+                aggMetrics.setMetrics(doAggregation(metrics));\n+                metricFactory.logMetrics(new TelemetryLoggerMessage(aggMetrics));\n+            } catch (IOException e) {\n+                logger.atError().cause(e).log(\"Unable to parse the emitted metric log file.\");\n+            }\n+        }\n+    }\n+\n+    private List<AggregatedMetric.Metric> doAggregation(Map<TelemetryMetricName, List<Metric>> metrics) {\n+        List<AggregatedMetric.Metric> aggMetrics = new ArrayList<>();\n+        for (Map.Entry<TelemetryMetricName, List<Metric>> metric : metrics.entrySet()) {\n+            TelemetryMetricName metricName = metric.getKey();\n+            List<Metric> mdp = metric.getValue();\n+            TelemetryAggregation telemetryAggregation = mdp.get(0).getAggregation();\n+            double aggregation = 0;\n+            if (telemetryAggregation.equals(TelemetryAggregation.Average)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e9fcaaae141dec0f0fa555548b7dbbc9211e9fed"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTEzOTg3OA==", "bodyText": "Change this to use the v1 topic.  $aws/things/{thingName}/greengrass/health/json", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r489139878", "createdAt": "2020-09-16T03:30:20Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/TelemetryAgent.java", "diffHunk": "@@ -0,0 +1,258 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class TelemetryAgent extends EvergreenService {\n+    public static final String TELEMETRY_AGENT_SERVICE_TOPICS = \"TelemetryAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrassv2/health/json\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e9fcaaae141dec0f0fa555548b7dbbc9211e9fed"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTE0MjM2Mg==", "bodyText": "You need to add accumulated data point for each namespace.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r489142362", "createdAt": "2020-09-16T03:39:58Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsAggregator.java", "diffHunk": "@@ -0,0 +1,225 @@\n+/*\n+ * Copyright Amazon.com Inc. or its affiliates.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.EvergreenStructuredLogMessage;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryMetricName;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryNamespace;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.fasterxml.jackson.annotation.JsonProperty;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import lombok.AllArgsConstructor;\n+import lombok.Builder;\n+import lombok.Data;\n+import lombok.NoArgsConstructor;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.stream.Collectors;\n+\n+public class MetricsAggregator {\n+    public static final Logger logger = LogManager.getLogger(MetricsAggregator.class);\n+    protected static final String AGGREGATE_METRICS_FILE = \"AggregateMetrics\";\n+    private final ObjectMapper objectMapper = new ObjectMapper();\n+    MetricFactory metricFactory = new MetricFactory(AGGREGATE_METRICS_FILE);\n+\n+    /**\n+     * This method stores the aggregated data points of the metrics emitted over the interval.\n+     *\n+     * @param lastAgg       timestamp at which the last aggregation was done.\n+     * @param currTimestamp timestamp at which the current aggregation is initiated.\n+     */\n+    protected void aggregateMetrics(long lastAgg, long currTimestamp) {\n+        for (TelemetryNamespace namespace : TelemetryNamespace.values()) {\n+            AggregatedMetric aggMetrics = new AggregatedMetric();\n+            HashMap<TelemetryMetricName, List<Metric>> metrics = new HashMap<>();\n+            try {\n+                List<Path> paths = Files\n+                        .walk(TelemetryConfig.getTelemetryDirectory())\n+                        .filter(Files::isRegularFile)\n+                        .filter((path) -> Coerce.toString(path.getFileName()).startsWith(namespace.toString()))\n+                        .collect(Collectors.toList());\n+                for (Path path : paths) {\n+                    // Read from the Telemetry/namespace*.log file.\n+                    // TODO : Read only those files that are modified after the last aggregation.\n+                    // file.lastModified() behavior is platform dependent.\n+                    Files.lines(path).forEach((log) -> {\n+                        try {\n+                            /*\n+                              {\"thread\":\"pool-3-thread-4\",\"level\":\"TRACE\",\"eventType\":null,\n+\n+                              \"message\":\"{\\\"NS\\\":\\\"SystemMetrics\\\",\\\"N\\\":\\\"TotalNumberOfFDs\\\",\\\"U\\\":\\\"Count\\\",\n+\n+                              \\\"A\\\":\\\"Average\\\",\\\"V\\\":4583,\\\"TS\\\":1600127641506}\",\"contexts\":{},\n+\n+                              \"loggerName\":\"Metrics-SystemMetrics\",\"timestamp\":1600127641506,\"cause\":null}\n+                             */\n+                            EvergreenStructuredLogMessage egLog = objectMapper.readValue(log,\n+                                    EvergreenStructuredLogMessage.class);\n+                            Metric mdp = objectMapper.readValue(egLog.getMessage(), Metric.class);\n+                            // Avoid the metrics that are emitted at/after the currTimestamp and before the\n+                            // aggregation interval\n+                            if (mdp != null && currTimestamp > mdp.getTimestamp() && mdp.getTimestamp() >= lastAgg) {\n+                                metrics.computeIfAbsent(mdp.getName(), k -> new ArrayList<>()).add(mdp);\n+                            }\n+                        } catch (IOException e) {\n+                            logger.atError().cause(e).log(\"Unable to parse the metric log.\");\n+                        }\n+                    });\n+                }\n+                aggMetrics.setMetricNamespace(namespace);\n+                aggMetrics.setTimestamp(currTimestamp);\n+                aggMetrics.setMetrics(doAggregation(metrics));\n+                metricFactory.logMetrics(new TelemetryLoggerMessage(aggMetrics));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e9fcaaae141dec0f0fa555548b7dbbc9211e9fed"}, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTE0NTExMg==", "bodyText": "nit: add java doc for param", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r489145112", "createdAt": "2020-09-16T03:51:09Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/TelemetryAgent.java", "diffHunk": "@@ -0,0 +1,258 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class TelemetryAgent extends EvergreenService {\n+    public static final String TELEMETRY_AGENT_SERVICE_TOPICS = \"TelemetryAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrassv2/health/json\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 3_600;\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 86_400;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private final List<PeriodicMetricsEmitter> periodicMetricsEmitters = new ArrayList<>();\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter //used in e2e\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private final MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics              root configuration topic for this service\n+     * @param mqttClient          {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     * @param kernel              {@link Kernel}\n+     * @param ses                 {@link ScheduledExecutorService}\n+     */\n+    @Inject\n+    public TelemetryAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration, Kernel kernel,\n+                          ScheduledExecutorService ses) {\n+        super(topics);\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        periodicMetricsEmitters.add(new SystemMetricsEmitter());\n+        periodicMetricsEmitters.add(new KernelMetricsEmitter(kernel));\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e9fcaaae141dec0f0fa555548b7dbbc9211e9fed"}, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTE0NTE2NQ==", "bodyText": "nit: add java doc for param", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r489145165", "createdAt": "2020-09-16T03:51:23Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/TelemetryAgent.java", "diffHunk": "@@ -0,0 +1,258 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class TelemetryAgent extends EvergreenService {\n+    public static final String TELEMETRY_AGENT_SERVICE_TOPICS = \"TelemetryAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrassv2/health/json\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 3_600;\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 86_400;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private final List<PeriodicMetricsEmitter> periodicMetricsEmitters = new ArrayList<>();\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter //used in e2e\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private final MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics              root configuration topic for this service\n+     * @param mqttClient          {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     * @param kernel              {@link Kernel}\n+     * @param ses                 {@link ScheduledExecutorService}\n+     */\n+    @Inject\n+    public TelemetryAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration, Kernel kernel,\n+                          ScheduledExecutorService ses) {\n+        super(topics);\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        periodicMetricsEmitters.add(new SystemMetricsEmitter());\n+        periodicMetricsEmitters.add(new KernelMetricsEmitter(kernel));\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        for (PeriodicMetricsEmitter emitter : periodicMetricsEmitters) {\n+            cancelJob(emitter.future, periodicAggregateMetricsInProgressLock, false);\n+        }\n+        cancelJob(periodicAggregateMetricsFuture, periodicAggregateMetricsInProgressLock, false);\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    for (PeriodicMetricsEmitter periodicMetricsEmitter : periodicMetricsEmitters) {\n+                        periodicMetricsEmitter.emitMetrics();\n+                    }\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            for (PeriodicMetricsEmitter emitter : periodicMetricsEmitters) {\n+                // Start emitting metrics with no delay. This is device specific where metrics are stored in files.\n+                emitter.future = ses.scheduleWithFixedDelay(emitter::emitMetrics, 0,\n+                        periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+            }\n+\n+            // As the time based metrics (eg. System metrics) are emitted with the same interval as aggregation, start\n+            // aggregating the metrics after at least one data point is emitted. So, the initial delay to aggregate the\n+            // metrics can be made equal to the interval. This is device specific where the metrics are stored in files.\n+            periodicAggregateMetricsFuture = ses.scheduleWithFixedDelay(this::aggregatePeriodicMetrics,\n+                    periodicAggregateMetricsIntervalSec, periodicAggregateMetricsIntervalSec, TimeUnit.SECONDS);\n+        }\n+    }\n+\n+    /**\n+     * Schedules the publishing of metrics based on the configured publish interval or the mqtt connection status.\n+     */\n+    private void schedulePeriodicPublishMetrics(boolean isReconfiguredOrConnectionResumed) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e9fcaaae141dec0f0fa555548b7dbbc9211e9fed"}, "originalPosition": 141}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTE0NTM3NA==", "bodyText": "Shouldn't we wait for periodicAggregateMetricsIntervalSec before starting aggregation? Lets give the components some time to emit the metrics.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r489145374", "createdAt": "2020-09-16T03:52:20Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/TelemetryAgent.java", "diffHunk": "@@ -0,0 +1,258 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class TelemetryAgent extends EvergreenService {\n+    public static final String TELEMETRY_AGENT_SERVICE_TOPICS = \"TelemetryAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrassv2/health/json\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 3_600;\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter // Used in e2e\n+    private static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_AGGREGATION_TIME_TOPIC = \"lastPeriodicAggregationMetricsTime\";\n+    private static final int DEFAULT_PERIODIC_PUBLISH_INTERVAL_SEC = 86_400;\n+    private static final int MAX_PAYLOAD_LENGTH_BYTES = 128_000;\n+    private static int periodicPublishMetricsIntervalSec = 0;\n+    private static int periodicAggregateMetricsIntervalSec = 0;\n+    private final MqttClient mqttClient;\n+    private final MetricsAggregator metricsAggregator = new MetricsAggregator();\n+    private final AtomicBoolean isConnected = new AtomicBoolean(true);\n+    private final Object periodicPublishMetricsInProgressLock = new Object();\n+    private final Object periodicAggregateMetricsInProgressLock = new Object();\n+    private final MqttChunkedPayloadPublisher<MetricsAggregator.AggregatedMetric> publisher;\n+    private final ScheduledExecutorService ses;\n+    private final List<PeriodicMetricsEmitter> periodicMetricsEmitters = new ArrayList<>();\n+    @Getter(AccessLevel.PACKAGE)\n+    private ScheduledFuture<?> periodicAggregateMetricsFuture = null;\n+    @Getter //used in e2e\n+    private ScheduledFuture<?> periodicPublishMetricsFuture = null;\n+    private final MqttClientConnectionEvents callbacks = new MqttClientConnectionEvents() {\n+        @Override\n+        public void onConnectionInterrupted(int errorCode) {\n+            isConnected.set(false);\n+        }\n+\n+        @Override\n+        public void onConnectionResumed(boolean sessionPresent) {\n+            isConnected.set(true);\n+            schedulePeriodicPublishMetrics(true);\n+        }\n+    };\n+    private String updateTopic;\n+    private String thingName;\n+    private String telemetryMetricsPublishTopic = DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+\n+    /**\n+     * Constructor for metrics agent.\n+     *\n+     * @param topics              root configuration topic for this service\n+     * @param mqttClient          {@link MqttClient}\n+     * @param deviceConfiguration {@link DeviceConfiguration}\n+     * @param kernel              {@link Kernel}\n+     * @param ses                 {@link ScheduledExecutorService}\n+     */\n+    @Inject\n+    public TelemetryAgent(Topics topics, MqttClient mqttClient, DeviceConfiguration deviceConfiguration, Kernel kernel,\n+                          ScheduledExecutorService ses) {\n+        super(topics);\n+        this.mqttClient = mqttClient;\n+        this.publisher = new MqttChunkedPayloadPublisher<>(this.mqttClient);\n+        this.publisher.setMaxPayloadLengthBytes(MAX_PAYLOAD_LENGTH_BYTES);\n+        this.ses = ses;\n+        periodicMetricsEmitters.add(new SystemMetricsEmitter());\n+        periodicMetricsEmitters.add(new KernelMetricsEmitter(kernel));\n+        getPeriodicAggregateTimeTopic();\n+        getPeriodicPublishTimeTopic();\n+        updateThingNameAndPublishTopic(Coerce.toString(deviceConfiguration.getThingName()));\n+    }\n+\n+    /**\n+     * Schedules the aggregation of metrics based on the configured aggregation interval.\n+     */\n+    private void schedulePeriodicAggregateMetrics(boolean isReconfigured) {\n+        for (PeriodicMetricsEmitter emitter : periodicMetricsEmitters) {\n+            cancelJob(emitter.future, periodicAggregateMetricsInProgressLock, false);\n+        }\n+        cancelJob(periodicAggregateMetricsFuture, periodicAggregateMetricsInProgressLock, false);\n+        if (isReconfigured) {\n+            synchronized (periodicAggregateMetricsInProgressLock) {\n+                Instant lastPeriodicAggTime = Instant.ofEpochMilli(Coerce.toLong(getPeriodicAggregateTimeTopic()));\n+                if (lastPeriodicAggTime.plusSeconds(periodicAggregateMetricsIntervalSec).isBefore(Instant.now())) {\n+                    for (PeriodicMetricsEmitter periodicMetricsEmitter : periodicMetricsEmitters) {\n+                        periodicMetricsEmitter.emitMetrics();\n+                    }\n+                    aggregatePeriodicMetrics();\n+                }\n+            }\n+        }\n+        synchronized (periodicAggregateMetricsInProgressLock) {\n+            for (PeriodicMetricsEmitter emitter : periodicMetricsEmitters) {\n+                // Start emitting metrics with no delay. This is device specific where metrics are stored in files.\n+                emitter.future = ses.scheduleWithFixedDelay(emitter::emitMetrics, 0,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e9fcaaae141dec0f0fa555548b7dbbc9211e9fed"}, "originalPosition": 126}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e4bc81d293832036debe4b86d053ebad08b8344c", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/e4bc81d293832036debe4b86d053ebad08b8344c", "committedDate": "2020-09-16T05:27:53Z", "message": "switch case for aggregation + update publish topic + update tests for more coverage + added java doc param + map in kernel metrics"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "56b72b68f420806806b2c9447052c6f068109c1c", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/56b72b68f420806806b2c9447052c6f068109c1c", "committedDate": "2020-09-16T05:34:26Z", "message": "switch case for aggregation + update publish topic + update tests for more coverage + added java doc param + map in kernel metrics"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7a23cbccdac26eb206dd24da8979435966a62b3c", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/7a23cbccdac26eb206dd24da8979435966a62b3c", "committedDate": "2020-09-16T05:35:00Z", "message": "Merge branch 'telemetry-logs' of github.com:aws/aws-greengrass-kernel into telemetry-logs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7d84d640dd1ef07491a1eee14d870d782d367c8e", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/7d84d640dd1ef07491a1eee14d870d782d367c8e", "committedDate": "2020-09-16T05:36:27Z", "message": "format code"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg5Mjg4MTcx", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-489288171", "createdAt": "2020-09-16T05:38:09Z", "commit": {"oid": "7d84d640dd1ef07491a1eee14d870d782d367c8e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQwNTozODowOVrOHSg1zw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQwNTozODowOVrOHSg1zw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTE3NDQ3OQ==", "bodyText": "remove the space before spdx", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r489174479", "createdAt": "2020-09-16T05:38:09Z", "author": {"login": "MikeDombo"}, "path": "src/integrationtests/java/com/aws/iot/evergreen/integrationtests/e2e/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/*\n+ *  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *   SPDX-License-Identifier: Apache-2.0", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d84d640dd1ef07491a1eee14d870d782d367c8e"}, "originalPosition": 3}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg5Mjg4NTY3", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-489288567", "createdAt": "2020-09-16T05:39:19Z", "commit": {"oid": "7d84d640dd1ef07491a1eee14d870d782d367c8e"}, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg5OTE3MjE4", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-489917218", "createdAt": "2020-09-16T18:30:39Z", "commit": {"oid": "7d84d640dd1ef07491a1eee14d870d782d367c8e"}, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxODozMDozOVrOHS9W5w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxODozNzo1NVrOHS95OA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTY0MTcwMw==", "bodyText": "nit: rename", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r489641703", "createdAt": "2020-09-16T18:30:39Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -40,23 +41,11 @@ public KernelMetricsEmitter(Kernel kernel) {\n      */\n     @Override\n     public void emitMetrics() {\n-        Map<TelemetryMetricName, Integer> data = new HashMap<>();\n+        Map<State, Integer> data = new HashMap<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d84d640dd1ef07491a1eee14d870d782d367c8e"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTY0MjY1NQ==", "bodyText": "nit: don't need the extra variable. Can be done in a single line.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r489642655", "createdAt": "2020-09-16T18:31:25Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -40,23 +41,11 @@ public KernelMetricsEmitter(Kernel kernel) {\n      */\n     @Override\n     public void emitMetrics() {\n-        Map<TelemetryMetricName, Integer> data = new HashMap<>();\n+        Map<State, Integer> data = new HashMap<>();\n         Collection<EvergreenService> evergreenServices = kernel.orderedDependencies();\n         for (EvergreenService evergreenService : evergreenServices) {\n-            /*\n-              State of the component returned is all caps(\"RUNNING\") but the corresponding Metric name is of the\n-              format \"NumberOfComponentsRunning\"; So we process the uppercase service state to sentence case\n-              and concatenate it with \"NumberOfComponents\" to form the metric name;\n-             */\n-            String serviceState = evergreenService.getState().toString();\n-            serviceState = serviceState.charAt(0) + serviceState.substring(1).toLowerCase();\n-            try {\n-                TelemetryMetricName telemetryMetricName =\n-                        TelemetryMetricName.valueOf(\"NumberOfComponents\" + serviceState);\n-                data.put(telemetryMetricName, data.getOrDefault(telemetryMetricName, 0) + 1);\n-            } catch (IllegalArgumentException e) {\n-                logger.atError().log(\"Unable to find the metric name.\", e);\n-            }\n+            State state = evergreenService.getState();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d84d640dd1ef07491a1eee14d870d782d367c8e"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTY0NjIzMA==", "bodyText": "nit: remove space", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r489646230", "createdAt": "2020-09-16T18:34:26Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/MetricsPayload.java", "diffHunk": "@@ -0,0 +1,32 @@\n+/*\n+ *  Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *   SPDX-License-Identifier: Apache-2.0", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d84d640dd1ef07491a1eee14d870d782d367c8e"}, "originalPosition": 3}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTY0Njc1OQ==", "bodyText": "Telemetry Agent.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r489646759", "createdAt": "2020-09-16T18:34:51Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/README.md", "diffHunk": "@@ -0,0 +1,114 @@\n+# Telemetry\n+\n+Metrics agent(MA) is a service that is responsible for publishing telemetry data from the device to the IoT cloud via an MQTT topic. MA periodically aggregates and publishes various types of metrics related to kernel, system, mqtt and so on based on the telemetric configuration set by the customer.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d84d640dd1ef07491a1eee14d870d782d367c8e"}, "originalPosition": 3}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTY0NzQ2NQ==", "bodyText": "Can Kernel periodic metrics as well", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r489647465", "createdAt": "2020-09-16T18:35:25Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/README.md", "diffHunk": "@@ -0,0 +1,114 @@\n+# Telemetry\n+\n+Metrics agent(MA) is a service that is responsible for publishing telemetry data from the device to the IoT cloud via an MQTT topic. MA periodically aggregates and publishes various types of metrics related to kernel, system, mqtt and so on based on the telemetric configuration set by the customer.\n+\n+## Workflow\n+There are three major steps involved in order for the MA to publish the telemetry data.\n+  - Creating a metric and emitting the data points\n+  - Aggregating the emitted metrics\n+  - Publishing the aggregated metrics\n+\n+### Creating a metric and emitting the data points\n+Typically, metric creation and emission are component/service specific(excluding system metrcis. MA takes care of System metrics).", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d84d640dd1ef07491a1eee14d870d782d367c8e"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTY0OTk2Mw==", "bodyText": "Also mention accumulated data points.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r489649963", "createdAt": "2020-09-16T18:37:28Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/README.md", "diffHunk": "@@ -0,0 +1,114 @@\n+# Telemetry\n+\n+Metrics agent(MA) is a service that is responsible for publishing telemetry data from the device to the IoT cloud via an MQTT topic. MA periodically aggregates and publishes various types of metrics related to kernel, system, mqtt and so on based on the telemetric configuration set by the customer.\n+\n+## Workflow\n+There are three major steps involved in order for the MA to publish the telemetry data.\n+  - Creating a metric and emitting the data points\n+  - Aggregating the emitted metrics\n+  - Publishing the aggregated metrics\n+\n+### Creating a metric and emitting the data points\n+Typically, metric creation and emission are component/service specific(excluding system metrcis. MA takes care of System metrics).\n+##### Create a metric\n+Each metric has to be specified with its name, namespace it belongs to, aggregation type that we want to perform on it and unit of the metric. It is enough to create a metric just once.\n+```\n+    Metric metric = Metric.builder()\n+            .namespace(TelemetryNamespace.KernelComponents)\n+            .name(TelemetryMetricName.NumberOfComponentsInstalled)\n+            .unit(TelemetryUnit.Count)\n+            .aggregation(TelemetryAggregation.Average)\n+            .build();\n+```\n+##### Emit a metric\n+Emitting a metric data point is nothing but assiging a value to the metric and writing it to the file.\n+- The name of the file is always going to be the namespace of the metric and it always resides inside the `Telemetry/` directory.\n+```\n+    Telemetry\n+    |___ generic.log\n+    |___ KernelComponents.log\n+    |___ SystemMetrics.log\n+    |___ ...\n+```\n+- The file to which the metric has to be written is specified using the `MetricFactory`. If nothing is specified, then the metrics are written to \"generic.log\" file.\n+    ```\n+    MetricFactory metricFactory = new MetricFactory(\"KernelComponents\");\n+    ```\n+- Emitting a metric can be done in two ways. \n+1. Assign a value and timestamp to the metric before emitting it.\n+    ```\n+    metric.setValue(10);\n+    metric.setTimestamp(Instant.now().toEpochMilli());\n+    \n+    metricFactory.putMetricData(metric);\n+    ```\n+2. No need to assign the timestamp or value to the metric. Pass in the metric along with the value. Current timestamp will be assigned.\n+    ```\n+    metricFactory.putMetricData(metric,10);\n+    ```\n+Sample contents of the file `Telemetry/KernelComponents.log`\n+```\n+{\n+    \"thread\": \"pool-1-thread-1\",\n+    \"level\": \"TRACE\",\n+    \"eventType\": null,\n+    \"message\":\"{\\\"NS\\\":\\\"KernelComponents\\\",\\\"N\\\":\\\"NumberOfComponentsInstalled\\\",\\\"U\\\":\\\"Count\\\",\\\"A\\\":\\\"Average\\\",\\\"V\\\":1,\\\"TS\\\":1600127551482}\",\n+    \"contexts\": {},\n+    \"loggerName\": \"Metrics-KernelComponents\",\n+    \"timestamp\": 1599814408616,\n+    \"cause\": null\n+}\n+```\n+Message part of the log corresponds to the following structure\n+```\n+Metric \n+|___ namespace\n+|___ name\n+|___ unit\n+|___ Aggregation\n+|___ value\n+|___ timestamp\n+```\n+### Aggregating the emitted metrics\n+Aggregation on the metric logs is performed based on the interval configured by the customer. By default, metrics are aggregated once in every one hour.\n+\n+- Read the log files present in the Telemetry directory.\n+- Aggregate only those metrics that are emitted after the last aggregation and before the current time. This aggregation is metric specific.\n+- Example: The metric `NumberOfComponentsInstalled` has 100 occurrences in the `Telemetry/KernelComponents.log` file out of which 70 are emitted after the last aggregation. Based on the aggregation type of the metric specified, here `Average`, we need to perform average on all of these 70 values. So, we make a map with `NumberOfComponentsInstalled` as the key and the list of these 70 entries as the value and pass this list to a function where aggregation is performed(average,sum,max..)\n+- Once the metrics are aggregated for that interval, group them based on their namespace and write them to a file called `Telemetry/AggregateMetrics.log`.\n+```\n+{\n+    \"thread\": \"pool-3-thread-3\",\n+    \"level\": \"TRACE\",\n+    \"eventType\": null,\n+    \"message\": \"{\\\"TS\\\":1599790572560,\\\"NS\\\":\\\"KernelComponents\\\",\\\"M\\\":[{\\\"N\\\":\\\"NumberOfComponentsStopping\\\",\\\"V\\\":0.0,\\\"U\\\":\\\"Count\\\"},{\\\"N\\\":\\\"NumberOfComponentsFinished\\\",\\\"V\\\":1.0,\\\"U\\\":\\\"Count\\\"},{\\\"N\\\":\\\"NumberOfComponentsRunning\\\",\\\"V\\\":11.0,\\\"U\\\":\\\"Count\\\"},{\\\"N\\\":\\\"NumberOfComponentsNew\\\",\\\"V\\\":0.0,\\\"U\\\":\\\"Count\\\"},{\\\"N\\\":\\\"NumberOfComponentsBroken\\\",\\\"V\\\":0.0,\\\"U\\\":\\\"Count\\\"},{\\\"N\\\":\\\"NumberOfComponentsErrored\\\",\\\"V\\\":0.0,\\\"U\\\":\\\"Count\\\"},{\\\"N\\\":\\\"NumberOfComponentsStarting\\\",\\\"V\\\":0.0,\\\"U\\\":\\\"Count\\\"},{\\\"N\\\":\\\"NumberOfComponentsInstalled\\\",\\\"V\\\":0.0,\\\"U\\\":\\\"Count\\\"},{\\\"N\\\":\\\"NumberOfComponentsStateless\\\",\\\"V\\\":0.0,\\\"U\\\":\\\"Count\\\"}]}\",\n+    \"contexts\": {},\n+    \"loggerName\": \"Metrics-AggregateMetrics\",\n+    \"timestamp\": 1599790572565,\n+    \"cause\": null\n+}\n+```\n+Message part of the log corresponds to the following structure.\n+```\n+Aggregated metric data point\n+|__ Timestamp\n+|__ Namespace(KernelComponents)\n+|___List\n+    |__ Metric 1 (NumberOfComponentsNew)\n+    |   |__ name\n+    |   |__ aggregated value\n+    |   |__ unit\n+    |__ Metric 2 (NumberOfComponentsBroken)\n+    |   |__ name\n+    |   |__ aggregated value\n+    |___|__ unit\n+```\n+Thus, in the given aggregation interval, we will write n logs to the AggregateMetrics.log file where n is the total number of metric namespaces available. Each of these n logs will contain the aggregation of metrics of that namespace(At present there are 4 namespaces).", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d84d640dd1ef07491a1eee14d870d782d367c8e"}, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTY1MDQ4OA==", "bodyText": "Here also mention accumulated data points.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r489650488", "createdAt": "2020-09-16T18:37:55Z", "author": {"login": "nikkhilmuthye"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/README.md", "diffHunk": "@@ -0,0 +1,114 @@\n+# Telemetry\n+\n+Metrics agent(MA) is a service that is responsible for publishing telemetry data from the device to the IoT cloud via an MQTT topic. MA periodically aggregates and publishes various types of metrics related to kernel, system, mqtt and so on based on the telemetric configuration set by the customer.\n+\n+## Workflow\n+There are three major steps involved in order for the MA to publish the telemetry data.\n+  - Creating a metric and emitting the data points\n+  - Aggregating the emitted metrics\n+  - Publishing the aggregated metrics\n+\n+### Creating a metric and emitting the data points\n+Typically, metric creation and emission are component/service specific(excluding system metrcis. MA takes care of System metrics).\n+##### Create a metric\n+Each metric has to be specified with its name, namespace it belongs to, aggregation type that we want to perform on it and unit of the metric. It is enough to create a metric just once.\n+```\n+    Metric metric = Metric.builder()\n+            .namespace(TelemetryNamespace.KernelComponents)\n+            .name(TelemetryMetricName.NumberOfComponentsInstalled)\n+            .unit(TelemetryUnit.Count)\n+            .aggregation(TelemetryAggregation.Average)\n+            .build();\n+```\n+##### Emit a metric\n+Emitting a metric data point is nothing but assiging a value to the metric and writing it to the file.\n+- The name of the file is always going to be the namespace of the metric and it always resides inside the `Telemetry/` directory.\n+```\n+    Telemetry\n+    |___ generic.log\n+    |___ KernelComponents.log\n+    |___ SystemMetrics.log\n+    |___ ...\n+```\n+- The file to which the metric has to be written is specified using the `MetricFactory`. If nothing is specified, then the metrics are written to \"generic.log\" file.\n+    ```\n+    MetricFactory metricFactory = new MetricFactory(\"KernelComponents\");\n+    ```\n+- Emitting a metric can be done in two ways. \n+1. Assign a value and timestamp to the metric before emitting it.\n+    ```\n+    metric.setValue(10);\n+    metric.setTimestamp(Instant.now().toEpochMilli());\n+    \n+    metricFactory.putMetricData(metric);\n+    ```\n+2. No need to assign the timestamp or value to the metric. Pass in the metric along with the value. Current timestamp will be assigned.\n+    ```\n+    metricFactory.putMetricData(metric,10);\n+    ```\n+Sample contents of the file `Telemetry/KernelComponents.log`\n+```\n+{\n+    \"thread\": \"pool-1-thread-1\",\n+    \"level\": \"TRACE\",\n+    \"eventType\": null,\n+    \"message\":\"{\\\"NS\\\":\\\"KernelComponents\\\",\\\"N\\\":\\\"NumberOfComponentsInstalled\\\",\\\"U\\\":\\\"Count\\\",\\\"A\\\":\\\"Average\\\",\\\"V\\\":1,\\\"TS\\\":1600127551482}\",\n+    \"contexts\": {},\n+    \"loggerName\": \"Metrics-KernelComponents\",\n+    \"timestamp\": 1599814408616,\n+    \"cause\": null\n+}\n+```\n+Message part of the log corresponds to the following structure\n+```\n+Metric \n+|___ namespace\n+|___ name\n+|___ unit\n+|___ Aggregation\n+|___ value\n+|___ timestamp\n+```\n+### Aggregating the emitted metrics\n+Aggregation on the metric logs is performed based on the interval configured by the customer. By default, metrics are aggregated once in every one hour.\n+\n+- Read the log files present in the Telemetry directory.\n+- Aggregate only those metrics that are emitted after the last aggregation and before the current time. This aggregation is metric specific.\n+- Example: The metric `NumberOfComponentsInstalled` has 100 occurrences in the `Telemetry/KernelComponents.log` file out of which 70 are emitted after the last aggregation. Based on the aggregation type of the metric specified, here `Average`, we need to perform average on all of these 70 values. So, we make a map with `NumberOfComponentsInstalled` as the key and the list of these 70 entries as the value and pass this list to a function where aggregation is performed(average,sum,max..)\n+- Once the metrics are aggregated for that interval, group them based on their namespace and write them to a file called `Telemetry/AggregateMetrics.log`.\n+```\n+{\n+    \"thread\": \"pool-3-thread-3\",\n+    \"level\": \"TRACE\",\n+    \"eventType\": null,\n+    \"message\": \"{\\\"TS\\\":1599790572560,\\\"NS\\\":\\\"KernelComponents\\\",\\\"M\\\":[{\\\"N\\\":\\\"NumberOfComponentsStopping\\\",\\\"V\\\":0.0,\\\"U\\\":\\\"Count\\\"},{\\\"N\\\":\\\"NumberOfComponentsFinished\\\",\\\"V\\\":1.0,\\\"U\\\":\\\"Count\\\"},{\\\"N\\\":\\\"NumberOfComponentsRunning\\\",\\\"V\\\":11.0,\\\"U\\\":\\\"Count\\\"},{\\\"N\\\":\\\"NumberOfComponentsNew\\\",\\\"V\\\":0.0,\\\"U\\\":\\\"Count\\\"},{\\\"N\\\":\\\"NumberOfComponentsBroken\\\",\\\"V\\\":0.0,\\\"U\\\":\\\"Count\\\"},{\\\"N\\\":\\\"NumberOfComponentsErrored\\\",\\\"V\\\":0.0,\\\"U\\\":\\\"Count\\\"},{\\\"N\\\":\\\"NumberOfComponentsStarting\\\",\\\"V\\\":0.0,\\\"U\\\":\\\"Count\\\"},{\\\"N\\\":\\\"NumberOfComponentsInstalled\\\",\\\"V\\\":0.0,\\\"U\\\":\\\"Count\\\"},{\\\"N\\\":\\\"NumberOfComponentsStateless\\\",\\\"V\\\":0.0,\\\"U\\\":\\\"Count\\\"}]}\",\n+    \"contexts\": {},\n+    \"loggerName\": \"Metrics-AggregateMetrics\",\n+    \"timestamp\": 1599790572565,\n+    \"cause\": null\n+}\n+```\n+Message part of the log corresponds to the following structure.\n+```\n+Aggregated metric data point\n+|__ Timestamp\n+|__ Namespace(KernelComponents)\n+|___List\n+    |__ Metric 1 (NumberOfComponentsNew)\n+    |   |__ name\n+    |   |__ aggregated value\n+    |   |__ unit\n+    |__ Metric 2 (NumberOfComponentsBroken)\n+    |   |__ name\n+    |   |__ aggregated value\n+    |___|__ unit\n+```\n+Thus, in the given aggregation interval, we will write n logs to the AggregateMetrics.log file where n is the total number of metric namespaces available. Each of these n logs will contain the aggregation of metrics of that namespace(At present there are 4 namespaces).\n+\n+### Publishing the aggregated metrics\n+Publishing the aggregated metrics is performed based on the interval configured by the customer. By default, metrics are published once in every day.\n+- Read `AggregateMetrics.log` present in the Telemetry directory.\n+- Publish only those metrics that are aggregated after the last publish and before the current time. This is essentially list of the above aggregated metrics.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d84d640dd1ef07491a1eee14d870d782d367c8e"}, "originalPosition": 111}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ad90414f8ba518dde69091471e0c47217de999eb", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/ad90414f8ba518dde69091471e0c47217de999eb", "committedDate": "2020-09-16T19:24:09Z", "message": "format copyright + update e2e test to use a working topic + fix a potential bug wrt to publish topic"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fe9fe579cd6807fbd46d474d642e7ff041b69d77", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/fe9fe579cd6807fbd46d474d642e7ff041b69d77", "committedDate": "2020-09-16T19:37:48Z", "message": "update readme + rename variable in KME"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "918beb4eaa1172d9e102607ce3ab12ac92c3df4e", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/918beb4eaa1172d9e102607ce3ab12ac92c3df4e", "committedDate": "2020-09-16T20:35:13Z", "message": "Merge branch 'master' into telemetry-logs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "32129a4dfc7cb417bf32c271500e9e176f3af163", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/32129a4dfc7cb417bf32c271500e9e176f3af163", "committedDate": "2020-09-16T20:36:29Z", "message": "Merge branch 'master' of github.com:/aws/aws-greengrass-kernel into telemetry-logs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "618f3f9935d9bf101f7d0c50fd6d7a907f1ad291", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/618f3f9935d9bf101f7d0c50fd6d7a907f1ad291", "committedDate": "2020-09-16T20:37:03Z", "message": "Merge branch 'telemetry-logs' of github.com:/aws/aws-greengrass-kernel into telemetry-logs"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDkwMDE3OTAz", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-490017903", "createdAt": "2020-09-16T21:01:57Z", "commit": {"oid": "618f3f9935d9bf101f7d0c50fd6d7a907f1ad291"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQyMTowMTo1OFrOHTEFtw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQyMTowMTo1OFrOHTEFtw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTc1MTk5MQ==", "bodyText": "don't bother. The default timeout is 5 minutes already.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r489751991", "createdAt": "2020-09-16T21:01:58Z", "author": {"login": "MikeDombo"}, "path": "src/integrationtests/java/com/aws/iot/evergreen/integrationtests/e2e/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -0,0 +1,125 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.integrationtests.e2e.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.State;\n+import com.aws.iot.evergreen.integrationtests.e2e.BaseE2ETestCase;\n+import com.aws.iot.evergreen.kernel.exceptions.ServiceLoadException;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.mqtt.SubscribeRequest;\n+import com.aws.iot.evergreen.telemetry.MetricsPayload;\n+import com.aws.iot.evergreen.telemetry.TelemetryAgent;\n+import com.aws.iot.evergreen.testcommons.testutilities.EGExtension;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import org.junit.jupiter.api.AfterEach;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Tag;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.Timeout;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import software.amazon.awssdk.crt.mqtt.MqttMessage;\n+\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.concurrent.atomic.AtomicReference;\n+\n+import static com.aws.iot.evergreen.kernel.EvergreenService.RUNTIME_STORE_NAMESPACE_TOPIC;\n+import static com.aws.iot.evergreen.kernel.EvergreenService.SERVICES_NAMESPACE_TOPIC;\n+import static com.aws.iot.evergreen.telemetry.TelemetryAgent.DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC;\n+import static com.aws.iot.evergreen.telemetry.TelemetryAgent.TELEMETRY_METRICS_PUBLISH_TOPICS;\n+import static com.aws.iot.evergreen.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC;\n+import static com.aws.iot.evergreen.telemetry.TelemetryAgent.TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertNotNull;\n+import static org.junit.jupiter.api.Assertions.assertTrue;\n+\n+@SuppressWarnings(\"PMD.CloseResource\")\n+@ExtendWith(EGExtension.class)\n+@Tag(\"E2E\")\n+public class TelemetryAgentTest extends BaseE2ETestCase {\n+    private static final ObjectMapper DESERIALIZER = new ObjectMapper();\n+\n+    @AfterEach\n+    void afterEach() {\n+        try {\n+            if (kernel != null) {\n+                kernel.shutdown();\n+            }\n+        } finally {\n+            // Cleanup all IoT thing resources we created\n+            cleanup();\n+        }\n+    }\n+\n+    @BeforeEach\n+    void launchKernel() throws Exception {\n+        initKernel();\n+        kernel.launch();\n+    }\n+\n+    @Timeout(value = 3, unit = TimeUnit.MINUTES)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "618f3f9935d9bf101f7d0c50fd6d7a907f1ad291"}, "originalPosition": 69}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6ca39b79162b19a788ca0710e2f5d7a455c4dfb3", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/6ca39b79162b19a788ca0710e2f5d7a455c4dfb3", "committedDate": "2020-09-16T22:37:09Z", "message": "Merge branch 'master' of github.com:/aws/aws-greengrass-kernel into telemetry-logs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "baa24ad4850896756274ebc396c35c2711abf572", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/baa24ad4850896756274ebc396c35c2711abf572", "committedDate": "2020-09-16T23:38:45Z", "message": "may be fix resource close"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f7edc11d1d0639470beb83acbddc0ca4184d3287", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/f7edc11d1d0639470beb83acbddc0ca4184d3287", "committedDate": "2020-09-16T23:45:20Z", "message": "format code"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9ec9d6474e607a4034bcbb3f6447adb277bc54b6", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/9ec9d6474e607a4034bcbb3f6447adb277bc54b6", "committedDate": "2020-09-17T00:38:46Z", "message": "try-resource in tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bc605049daf2b96b3b1bd1b70325be2cdddd4278", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/bc605049daf2b96b3b1bd1b70325be2cdddd4278", "committedDate": "2020-09-17T02:47:32Z", "message": "stop log appenders in tests"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDkwMjA2NjI4", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-490206628", "createdAt": "2020-09-17T02:49:56Z", "commit": {"oid": "bc605049daf2b96b3b1bd1b70325be2cdddd4278"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QwMjo0OTo1NlrOHTNgaw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QwMjo0OTo1NlrOHTNgaw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTkwNjI4Mw==", "bodyText": "I don't see how this can possibly work. You need to close the context which is actually used, not this context that you just created", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r489906283", "createdAt": "2020-09-17T02:49:56Z", "author": {"login": "MikeDombo"}, "path": "src/test/java/com/aws/iot/evergreen/telemetry/MetricsAggregatorTest.java", "diffHunk": "@@ -45,12 +47,18 @@\n     private static final ObjectMapper mapper = new ObjectMapper();\n     @TempDir\n     protected Path tempRootDir;\n+    private final LoggerContext loggerContext = new LoggerContext();\n \n     @BeforeEach\n     public void setup() {\n         System.setProperty(\"root\", tempRootDir.toAbsolutePath().toString());\n     }\n \n+    @AfterEach\n+    public void cleanup() {\n+        loggerContext.getLogger(\"Metrics-AggregateMetrics\").detachAndStopAllAppenders();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc605049daf2b96b3b1bd1b70325be2cdddd4278"}, "originalPosition": 29}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a2c3c3b09979197ac10ac0251aab21b97b2a26d6", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/a2c3c3b09979197ac10ac0251aab21b97b2a26d6", "committedDate": "2020-09-18T17:32:18Z", "message": "Create ~root/telemetry + Set telemetry directory path + add try catch for invalidMetricException + update tests + add accumulated data point logic + stop log appenders after each test + update read me"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "000381241095f37a8693d0119fecbad90061f855", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/000381241095f37a8693d0119fecbad90061f855", "committedDate": "2020-09-18T17:37:20Z", "message": "refer telemetry branch of sdk"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDkxNjYxMjAy", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-491661202", "createdAt": "2020-09-18T17:39:45Z", "commit": {"oid": "000381241095f37a8693d0119fecbad90061f855"}, "state": "COMMENTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxNzozOTo0NlrOHUWMzg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxNzo1MDoyMVrOHUWisg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTA5NzI5NA==", "bodyText": "shouldn't be static", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r491097294", "createdAt": "2020-09-18T17:39:46Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/TelemetryAgent.java", "diffHunk": "@@ -0,0 +1,275 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import lombok.Setter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class TelemetryAgent extends EvergreenService {\n+    public static final String TELEMETRY_AGENT_SERVICE_TOPICS = \"TelemetryAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrass/health/json\";\n+    public static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    public static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    public static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter\n+    @Setter\n+    private static final Set<String> TELEMETRY_NAMESPACES = new HashSet<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "000381241095f37a8693d0119fecbad90061f855"}, "originalPosition": 46}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTA5NzQ5MQ==", "bodyText": "don't add getters for static fields. Make the field package-private instead.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r491097491", "createdAt": "2020-09-18T17:40:07Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/TelemetryAgent.java", "diffHunk": "@@ -0,0 +1,275 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import lombok.Setter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class TelemetryAgent extends EvergreenService {\n+    public static final String TELEMETRY_AGENT_SERVICE_TOPICS = \"TelemetryAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrass/health/json\";\n+    public static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    public static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    public static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter\n+    @Setter\n+    private static final Set<String> TELEMETRY_NAMESPACES = new HashSet<>();\n+    @Getter(AccessLevel.PACKAGE)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "000381241095f37a8693d0119fecbad90061f855"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTA5NzU2Mg==", "bodyText": "same", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r491097562", "createdAt": "2020-09-18T17:40:15Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/TelemetryAgent.java", "diffHunk": "@@ -0,0 +1,275 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import lombok.Setter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class TelemetryAgent extends EvergreenService {\n+    public static final String TELEMETRY_AGENT_SERVICE_TOPICS = \"TelemetryAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrass/health/json\";\n+    public static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    public static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    public static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter\n+    @Setter\n+    private static final Set<String> TELEMETRY_NAMESPACES = new HashSet<>();\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 3_600;\n+    @Getter(AccessLevel.PACKAGE)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "000381241095f37a8693d0119fecbad90061f855"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTA5NzYyNQ==", "bodyText": "same", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r491097625", "createdAt": "2020-09-18T17:40:21Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/TelemetryAgent.java", "diffHunk": "@@ -0,0 +1,275 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.config.Topic;\n+import com.aws.iot.evergreen.config.Topics;\n+import com.aws.iot.evergreen.dependency.ImplementsService;\n+import com.aws.iot.evergreen.deployment.DeviceConfiguration;\n+import com.aws.iot.evergreen.kernel.EvergreenService;\n+import com.aws.iot.evergreen.kernel.Kernel;\n+import com.aws.iot.evergreen.kernel.KernelMetricsEmitter;\n+import com.aws.iot.evergreen.mqtt.MqttClient;\n+import com.aws.iot.evergreen.util.Coerce;\n+import com.aws.iot.evergreen.util.MqttChunkedPayloadPublisher;\n+import lombok.AccessLevel;\n+import lombok.Getter;\n+import lombok.Setter;\n+import org.apache.commons.lang3.RandomUtils;\n+import software.amazon.awssdk.crt.mqtt.MqttClientConnectionEvents;\n+\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import javax.inject.Inject;\n+\n+@ImplementsService(name = TelemetryAgent.TELEMETRY_AGENT_SERVICE_TOPICS, version = \"1.0.0\", autostart = true)\n+public class TelemetryAgent extends EvergreenService {\n+    public static final String TELEMETRY_AGENT_SERVICE_TOPICS = \"TelemetryAgent\";\n+    public static final String DEFAULT_TELEMETRY_METRICS_PUBLISH_TOPIC =\n+            \"$aws/things/{thingName}/greengrass/health/json\";\n+    public static final String TELEMETRY_PERIODIC_AGGREGATE_INTERVAL_SEC = \"periodicAggregateMetricsIntervalSec\";\n+    public static final String TELEMETRY_PERIODIC_PUBLISH_INTERVAL_SEC = \"periodicPublishMetricsIntervalSec\";\n+    public static final String TELEMETRY_METRICS_PUBLISH_TOPICS = \"telemetryMetricsPublishTopic\";\n+    @Getter\n+    @Setter\n+    private static final Set<String> TELEMETRY_NAMESPACES = new HashSet<>();\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final int DEFAULT_PERIODIC_AGGREGATE_INTERVAL_SEC = 3_600;\n+    @Getter(AccessLevel.PACKAGE)\n+    private static final String TELEMETRY_LAST_PERIODIC_PUBLISH_TIME_TOPIC = \"lastPeriodicPublishMetricsTime\";\n+    @Getter(AccessLevel.PACKAGE)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "000381241095f37a8693d0119fecbad90061f855"}, "originalPosition": 51}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTA5NzkwMg==", "bodyText": "TELEMETRY_NAMESPACES shouldn't be static", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r491097902", "createdAt": "2020-09-18T17:40:56Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/kernel/KernelMetricsEmitter.java", "diffHunk": "@@ -0,0 +1,126 @@\n+/* Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0 */\n+\n+package com.aws.iot.evergreen.kernel;\n+\n+import com.aws.iot.evergreen.dependency.State;\n+import com.aws.iot.evergreen.logging.api.Logger;\n+import com.aws.iot.evergreen.logging.impl.LogManager;\n+import com.aws.iot.evergreen.telemetry.PeriodicMetricsEmitter;\n+import com.aws.iot.evergreen.telemetry.TelemetryAgent;\n+import com.aws.iot.evergreen.telemetry.impl.InvalidMetricException;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.Map;\n+import javax.inject.Inject;\n+\n+public class KernelMetricsEmitter extends PeriodicMetricsEmitter {\n+    public static final Logger logger = LogManager.getLogger(KernelMetricsEmitter.class);\n+    private static final String NAMESPACE = \"KernelComponents\";\n+    private final Kernel kernel;\n+    private final MetricFactory mf = new MetricFactory(NAMESPACE);\n+\n+    /**\n+     * Constructor for kernel metrics emitter.\n+     *\n+     * @param kernel {@link Kernel}\n+     */\n+    @Inject\n+    public KernelMetricsEmitter(Kernel kernel) {\n+        super();\n+        this.kernel = kernel;\n+        TelemetryAgent.getTELEMETRY_NAMESPACES().add(NAMESPACE);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "000381241095f37a8693d0119fecbad90061f855"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTEwMDU3Mg==", "bodyText": "fix formatting", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r491100572", "createdAt": "2020-09-18T17:45:48Z", "author": {"login": "MikeDombo"}, "path": "src/test/java/com/aws/iot/evergreen/telemetry/MetricsAggregatorTest.java", "diffHunk": "@@ -0,0 +1,261 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.impl.EvergreenStructuredLogMessage;\n+import com.aws.iot.evergreen.telemetry.impl.InvalidMetricException;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.testcommons.testutilities.EGExtension;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.junit.jupiter.api.extension.ExtensionContext;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.aws.iot.evergreen.telemetry.MetricsAggregator.AGGREGATE_METRICS_FILE;\n+import static com.aws.iot.evergreen.telemetry.MetricsAggregator.AggregatedMetric;\n+import static com.aws.iot.evergreen.testcommons.testutilities.ExceptionLogProtector.ignoreExceptionOfType;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n+\n+@ExtendWith({MockitoExtension.class, EGExtension.class})\n+public class MetricsAggregatorTest {\n+    private static final ObjectMapper mapper = new ObjectMapper();\n+    private static final  String sm = \"SystemMetrics\";\n+    @TempDir\n+    protected Path tempRootDir;\n+\n+    @BeforeEach\n+    public void setup() {\n+        TelemetryConfig.setRoot(tempRootDir);\n+        TelemetryAgent.getTELEMETRY_NAMESPACES().add(sm);    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "000381241095f37a8693d0119fecbad90061f855"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTEwMDkwNA==", "bodyText": "what's the difference between setting root and setting the telemetry path? That's confusing that there are 2 very similar options.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r491100904", "createdAt": "2020-09-18T17:46:21Z", "author": {"login": "MikeDombo"}, "path": "src/test/java/com/aws/iot/evergreen/telemetry/MetricsAggregatorTest.java", "diffHunk": "@@ -0,0 +1,261 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.impl.EvergreenStructuredLogMessage;\n+import com.aws.iot.evergreen.telemetry.impl.InvalidMetricException;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.testcommons.testutilities.EGExtension;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.junit.jupiter.api.extension.ExtensionContext;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.aws.iot.evergreen.telemetry.MetricsAggregator.AGGREGATE_METRICS_FILE;\n+import static com.aws.iot.evergreen.telemetry.MetricsAggregator.AggregatedMetric;\n+import static com.aws.iot.evergreen.testcommons.testutilities.ExceptionLogProtector.ignoreExceptionOfType;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n+\n+@ExtendWith({MockitoExtension.class, EGExtension.class})\n+public class MetricsAggregatorTest {\n+    private static final ObjectMapper mapper = new ObjectMapper();\n+    private static final  String sm = \"SystemMetrics\";\n+    @TempDir\n+    protected Path tempRootDir;\n+\n+    @BeforeEach\n+    public void setup() {\n+        TelemetryConfig.setRoot(tempRootDir);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "000381241095f37a8693d0119fecbad90061f855"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTEwMTI1NQ==", "bodyText": "you can just use Files.readAllLines", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r491101255", "createdAt": "2020-09-18T17:47:00Z", "author": {"login": "MikeDombo"}, "path": "src/test/java/com/aws/iot/evergreen/telemetry/MetricsAggregatorTest.java", "diffHunk": "@@ -0,0 +1,261 @@\n+/*\n+ * Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ * SPDX-License-Identifier: Apache-2.0\n+ */\n+\n+package com.aws.iot.evergreen.telemetry;\n+\n+import com.aws.iot.evergreen.logging.impl.EvergreenStructuredLogMessage;\n+import com.aws.iot.evergreen.telemetry.impl.InvalidMetricException;\n+import com.aws.iot.evergreen.telemetry.impl.Metric;\n+import com.aws.iot.evergreen.telemetry.impl.MetricFactory;\n+import com.aws.iot.evergreen.telemetry.impl.TelemetryLoggerMessage;\n+import com.aws.iot.evergreen.telemetry.impl.config.TelemetryConfig;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryAggregation;\n+import com.aws.iot.evergreen.telemetry.models.TelemetryUnit;\n+import com.aws.iot.evergreen.testcommons.testutilities.EGExtension;\n+import com.fasterxml.jackson.databind.ObjectMapper;\n+import com.fasterxml.jackson.databind.exc.MismatchedInputException;\n+import org.junit.jupiter.api.BeforeEach;\n+import org.junit.jupiter.api.Test;\n+import org.junit.jupiter.api.extension.ExtendWith;\n+import org.junit.jupiter.api.extension.ExtensionContext;\n+import org.junit.jupiter.api.io.TempDir;\n+import org.mockito.junit.jupiter.MockitoExtension;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.time.Instant;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+\n+import static com.aws.iot.evergreen.telemetry.MetricsAggregator.AGGREGATE_METRICS_FILE;\n+import static com.aws.iot.evergreen.telemetry.MetricsAggregator.AggregatedMetric;\n+import static com.aws.iot.evergreen.testcommons.testutilities.ExceptionLogProtector.ignoreExceptionOfType;\n+import static org.junit.jupiter.api.Assertions.assertEquals;\n+import static org.junit.jupiter.api.Assertions.assertFalse;\n+\n+@ExtendWith({MockitoExtension.class, EGExtension.class})\n+public class MetricsAggregatorTest {\n+    private static final ObjectMapper mapper = new ObjectMapper();\n+    private static final  String sm = \"SystemMetrics\";\n+    @TempDir\n+    protected Path tempRootDir;\n+\n+    @BeforeEach\n+    public void setup() {\n+        TelemetryConfig.setRoot(tempRootDir);\n+        TelemetryAgent.getTELEMETRY_NAMESPACES().add(sm);    }\n+\n+    @Test\n+    public void GIVEN_system_metrics_WHEN_aggregate_THEN_aggregate_only_the_latest_values()\n+            throws InterruptedException, IOException, InvalidMetricException {\n+        //Create a sample file with system metrics so we can test the freshness of the file and logs\n+        //with respect to the current timestamp\n+        long lastAgg = Instant.now().toEpochMilli();\n+        Metric m1 = new Metric(sm, \"CpuUsage\", TelemetryUnit.Percent, TelemetryAggregation.Sum);\n+        MetricFactory mf = new MetricFactory(\"SystemMetrics\");\n+        Metric m2 = new Metric(sm, \"SystemMemUsage\", TelemetryUnit.Megabytes,\n+                TelemetryAggregation.Average);\n+        Metric m3 = new Metric(sm, \"TotalNumberOfFDs\", TelemetryUnit.Count, TelemetryAggregation.Maximum);\n+        mf.putMetricData(m1, 10);\n+        mf.putMetricData(m2, 2000);\n+        mf.putMetricData(m3, 4000);\n+        mf.putMetricData(m1, 20);\n+        mf.putMetricData(m2, 3000);\n+        mf.putMetricData(m3, 5000);\n+        mf.putMetricData(m1, 30);\n+        mf.putMetricData(m2, 4000);\n+        mf.putMetricData(m3, 6000);\n+        MetricsAggregator ma = new MetricsAggregator();\n+        long currTimestamp = Instant.now().toEpochMilli();\n+        ma.aggregateMetrics(lastAgg, currTimestamp);\n+        Path path = Paths.get(TelemetryConfig.getTelemetryDirectory().toString()).resolve(\"AggregateMetrics.log\");\n+        List<String> list;\n+        try (Stream<String> listing = Files.lines(path)) {\n+            list = listing.collect(Collectors.toList());\n+            assertEquals(TelemetryAgent.getTELEMETRY_NAMESPACES().size(), list.size()); // Metrics are aggregated based on the namespace.\n+            for (String s : list) {\n+                AggregatedMetric am = mapper.readValue(mapper.readTree(s).get(\"message\").asText(),\n+                        AggregatedMetric.class);\n+                if (am.getNamespace().equals(sm)) {\n+                    assertEquals(3, am.getMetrics().size()); // Three system metrics\n+                    for (AggregatedMetric.Metric metrics : am.getMetrics()) {\n+                        if (metrics.getName().equals(\"CpuUsage\")) {\n+                            assertEquals((double) 60, metrics.getValue().get(\"Sum\"));\n+                        } else if (metrics.getName().equals(\"SystemMemUsage\")) {\n+                            assertEquals((double) 3000, metrics.getValue().get(\"Average\"));\n+                        } else if (metrics.getName().equals(\"TotalNumberOfFDs\")) {\n+                            assertEquals((double) 6000, metrics.getValue().get(\"Maximum\"));\n+                        }\n+                    }\n+                }\n+            }\n+        }\n+        lastAgg = currTimestamp;\n+        Thread.sleep(1000);\n+        currTimestamp = Instant.now().toEpochMilli();\n+        // Aggregate values within 1 second interval at this timestamp with 1\n+        ma.aggregateMetrics(lastAgg, currTimestamp);\n+        try (Stream<String> listing = Files.lines(path)) {\n+            list = listing.collect(Collectors.toList());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "000381241095f37a8693d0119fecbad90061f855"}, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTEwMjg5OA==", "bodyText": "add a comment here for why you are doing it.", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r491102898", "createdAt": "2020-09-18T17:50:21Z", "author": {"login": "MikeDombo"}, "path": "src/test/java/com/aws/iot/evergreen/testcommons/testutilities/ExceptionLogProtector.java", "diffHunk": "@@ -148,7 +149,7 @@ public void beforeEach(ExtensionContext context) throws Exception {\n     @SneakyThrows\n     public void afterEach(ExtensionContext context) throws Exception {\n         Slf4jLogAdapter.removeGlobalListener(getListener(context));\n-\n+        TelemetryConfig.getInstance().close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "000381241095f37a8693d0119fecbad90061f855"}, "originalPosition": 13}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "30d37ae9f2a50bc4721e19fabe0655d8f074e121", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/30d37ae9f2a50bc4721e19fabe0655d8f074e121", "committedDate": "2020-09-19T01:28:07Z", "message": "Add separate class for Namespace + update tests + clean up"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "29665834a5d62cf08ad9a1d315e3c67e9389099b", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/29665834a5d62cf08ad9a1d315e3c67e9389099b", "committedDate": "2020-09-19T01:32:16Z", "message": "Merge branch 'master' of github.com:/aws/aws-greengrass-kernel into telemetry-logs"}, "afterCommit": {"oid": "30d37ae9f2a50bc4721e19fabe0655d8f074e121", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/30d37ae9f2a50bc4721e19fabe0655d8f074e121", "committedDate": "2020-09-19T01:28:07Z", "message": "Add separate class for Namespace + update tests + clean up"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f2e0e4d7e639d0443c9da30ab83a2e50780e0d55", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/f2e0e4d7e639d0443c9da30ab83a2e50780e0d55", "committedDate": "2020-09-19T03:09:05Z", "message": "Merge branch 'master' of github.com:/aws/aws-greengrass-kernel into telemetry-logs"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDkxOTE3MTg2", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#pullrequestreview-491917186", "createdAt": "2020-09-19T04:28:01Z", "commit": {"oid": "30d37ae9f2a50bc4721e19fabe0655d8f074e121"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOVQwNDoyODowMVrOHUglyg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOVQwNDozMDoxMVrOHUgmeA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTI2NzUzMA==", "bodyText": "this is not necessary", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r491267530", "createdAt": "2020-09-19T04:28:01Z", "author": {"login": "MikeDombo"}, "path": "src/main/java/com/aws/iot/evergreen/telemetry/NamespaceSet.java", "diffHunk": "@@ -0,0 +1,21 @@\n+package com.aws.iot.evergreen.telemetry;\n+\n+import lombok.Getter;\n+\n+import java.util.HashSet;\n+import java.util.Set;\n+import javax.inject.Inject;\n+\n+public class NamespaceSet {\n+    @Getter\n+    private Set<String> namespaces = new HashSet<>();\n+\n+    @Inject\n+    public NamespaceSet() {\n+        super();\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "30d37ae9f2a50bc4721e19fabe0655d8f074e121"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTI2NzcwNA==", "bodyText": "be sure to close this in the afterEach", "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/pull/378#discussion_r491267704", "createdAt": "2020-09-19T04:30:11Z", "author": {"login": "MikeDombo"}, "path": "src/test/java/com/aws/iot/evergreen/telemetry/TelemetryAgentTest.java", "diffHunk": "@@ -62,17 +63,22 @@\n     private ArgumentCaptor<PublishRequest> publishRequestArgumentCaptor;\n     @Captor\n     private ArgumentCaptor<MqttClientConnectionEvents> mqttClientConnectionEventsArgumentCaptor;\n-    private TelemetryAgent telemetryAgent;\n     @Mock\n     private ScheduledExecutorService ses;\n-    @Mock\n-    private Kernel kernel;\n+    private TelemetryAgent telemetryAgent;\n+    private SystemMetricsEmitter sme;\n+    private KernelMetricsEmitter kme;\n+    private MetricsAggregator ma;\n \n     @BeforeEach\n     public void setup() {\n         serviceFullName = \"MetricsAgentService\";\n         initializeMockedConfig();\n         ses = new ScheduledThreadPoolExecutor(3);\n+        context = new Context();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "30d37ae9f2a50bc4721e19fabe0655d8f074e121"}, "originalPosition": 44}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9f4f9bd0c40f8e1460d42657186e7987bb4e5941", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/9f4f9bd0c40f8e1460d42657186e7987bb4e5941", "committedDate": "2020-09-21T03:10:56Z", "message": "close context + remove constructor"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "807de4537377a0f7d5c288032240faf97368a29e", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/807de4537377a0f7d5c288032240faf97368a29e", "committedDate": "2020-09-21T03:11:10Z", "message": "Merge branch 'master' of github.com:/aws/aws-greengrass-kernel into telemetry-logs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "245af4dcf92ef9d1e5d310583f2ec5dcc262adc5", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/245af4dcf92ef9d1e5d310583f2ec5dcc262adc5", "committedDate": "2020-09-21T04:14:59Z", "message": "change tempdir"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6d0cb59cea3ad18d790de9e1b55083120d513609", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/6d0cb59cea3ad18d790de9e1b55083120d513609", "committedDate": "2020-09-21T08:07:21Z", "message": "update telemetry root path"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9b675dcad3da5c7984cdfe3cc59969fff24aef95", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/9b675dcad3da5c7984cdfe3cc59969fff24aef95", "committedDate": "2020-09-21T17:24:43Z", "message": "Merge branch 'master' of github.com:/aws/aws-greengrass-kernel into telemetry-logs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dd49c445ad65e37dc7dad12658d9797fb8a2f8f9", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/dd49c445ad65e37dc7dad12658d9797fb8a2f8f9", "committedDate": "2020-09-21T17:30:04Z", "message": "update TA e2e test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "efcbb7c0d667bd49b2aec35f5abe315e8b11df9f", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/efcbb7c0d667bd49b2aec35f5abe315e8b11df9f", "committedDate": "2020-09-21T19:04:17Z", "message": "Merge branch 'master' of github.com:/aws/aws-greengrass-kernel into telemetry-logs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4bd6acdf82fa70cd39634b7060d653ef8a8eb6d9", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/4bd6acdf82fa70cd39634b7060d653ef8a8eb6d9", "committedDate": "2020-09-21T21:31:17Z", "message": "remove telemetry directory after each test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bb845796b57c19a0756ef3408b64af22f47c5f28", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/bb845796b57c19a0756ef3408b64af22f47c5f28", "committedDate": "2020-09-22T01:37:10Z", "message": "Merge branch 'master' of github.com:/aws/aws-greengrass-kernel into telemetry-logs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8d12f9423168f747630c7135fac94c353233e1b6", "author": {"user": {"login": "saranyailla", "name": "Saranya"}}, "url": "https://github.com/aws-greengrass/aws-greengrass-nucleus/commit/8d12f9423168f747630c7135fac94c353233e1b6", "committedDate": "2020-09-22T01:42:19Z", "message": "change the configurabletopics to paramters"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3175, "cost": 1, "resetAt": "2021-11-01T11:59:11Z"}}}